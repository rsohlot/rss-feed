{
  "sources": [
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Blog",
      "feedUrl": "http://machinelearningmastery.com/blog/feed",
      "siteUrl": "https://machinelearningmastery.com/blog/",
      "articles": [
        {
          "id": "https://machinelearningmastery.com/?p=14330",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "The gradient descent algorithm is one of the most popular techniques for training deep neural networks. It has many applications in fields such as computer vision, speech recognition, and natural language processing. While the idea of gradient descent has been around for decades, it’s only recently that it’s been applied to applications related to deep […]\nThe post Implementing Gradient Descent in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/implementing-gradient-descent-in-pytorch/",
          "publishedOn": "2022-11-26T20:28:14.000Z",
          "wordCount": 7592,
          "title": "Implementing Gradient Descent in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/michael-behrens-DA-iYgv8kjE-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14318",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a simple yet powerful technique for predicting the values of variables based on other variables. It is often used for modeling relationships between two or more continuous variables, such as the relationship between income and age, or the relationship between weight and height. Likewise, linear regression can be used to predict continuous […]\nThe post Training a Linear Regression Model in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/training-a-linear-regression-model-in-pytorch/",
          "publishedOn": "2022-11-24T17:24:24.000Z",
          "wordCount": 7119,
          "title": "Training a Linear Regression Model in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/ryan-tasto-chbXE4o0ryU-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14311",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a statistical technique for estimating the relationship between two variables. A simple example of linear regression is to predict the height of someone based on the square root of the person’s weight (that’s what BMI is based on). To do this, we need to find the slope and intercept of the line. […]\nThe post Making Linear Predictions in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/making-linear-predictions-in-pytorch/",
          "publishedOn": "2022-11-24T04:11:30.000Z",
          "wordCount": 6417,
          "title": "Making Linear Predictions in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/daryan-shamkhali-pMCbPPPBSkA-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14301",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Structuring the data pipeline in a way that it can be effortlessly linked to your deep learning model is an important aspect of any deep learning-based system. PyTorch packs everything to do just that. While in the previous tutorial, we used simple datasets, we’ll need to work with larger datasets in real world scenarios in […]\nThe post Loading and Providing Datasets in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/loading-and-providing-datasets-in-pytorch/",
          "publishedOn": "2022-11-19T01:57:22.000Z",
          "wordCount": 5933,
          "title": "Loading and Providing Datasets in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/uriel-sc-11KDtiUWRq4-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14298",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "In machine learning and deep learning problems, a lot of effort goes into preparing the data. Data is usually messy and needs to be preprocessed before it can be used for training a model. If the data is not prepared correctly, the model won’t be able to generalize well. Some of the common steps required […]\nThe post Using Dataset Classes in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/using-dataset-classes-in-pytorch/",
          "publishedOn": "2022-11-17T01:55:54.000Z",
          "wordCount": 6445,
          "title": "Using Dataset Classes in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/nasa-1lfI7wkGWZ4-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13195",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Derivatives are one of the most fundamental concepts in calculus. They describe how changes in the variable inputs affect the function outputs. The objective of this article is to provide a high-level introduction to calculating derivatives in PyTorch for those who are new to the framework. PyTorch offers a convenient way to calculate derivatives for […]\nThe post Calculating Derivatives in PyTorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/calculating-derivatives-in-pytorch/",
          "publishedOn": "2022-11-11T21:30:18.000Z",
          "wordCount": 6011,
          "title": "Calculating Derivatives in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/jossuha-theophile-H-CZjCQfsFw-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13183",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Two-dimensional tensors are analogous to two-dimensional metrics. Like a two-dimensional metric, a two-dimensional tensor also has $n$ number of rows and columns. Let’s take a gray-scale image as an example, which is a two-dimensional matrix of numeric values, commonly known as pixels. Ranging from ‘0’ to ‘255’, each number represents a pixel intensity value. Here, […]\nThe post Two-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/two-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-09T21:30:51.000Z",
          "wordCount": 6286,
          "title": "Two-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/dylan-nolte-NIrgENd0sAY-unsplash-scaled.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13157",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "PyTorch is an open-source deep learning framework based on Python language. It allows you to build, train, and deploy deep learning models, offering a lot of versatility and efficiency. PyTorch is primarily focused on tensor operations while a tensor can be a number, matrix, or a multi-dimensional array. In this tutorial, we will perform some […]\nThe post One-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/one-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-07T21:30:13.000Z",
          "wordCount": 6633,
          "title": "One-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2021/12/jo-szczepanska-9OKGEVJiTKk-unsplash.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14064",
          "author": "MLM Team",
          "description": "Sponsored Post   The unlimited access initiative presents a risk-free way to break into data science.     The online educational platform 365 Data Science launches the #21DaysFREE campaign and provides 100% free unlimited access to all content for three weeks. From November 1 to 21, you can take courses from renowned instructors and earn […]\nThe post 365 Data Science courses free until November 21 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/365-data-science-courses-free-until-november-21/",
          "publishedOn": "2022-11-02T15:50:51.000Z",
          "wordCount": 4628,
          "title": "365 Data Science courses free until November 21",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/mlm-365ds-20221102-1.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14006",
          "author": "MLM Team",
          "description": "Sponsored Post      Attend the Data Science Symposium 2022 on November 8 The Center for Business Analytics at the University of Cincinnati will present its annual Data Science Symposium 2022 on November 8. This all day in-person event will have three featured speakers and two tech talk tracks with four concurrent presentations in each track. The […]\nThe post Attend the Data Science Symposium 2022, November 8 in Cincinnati appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/uccsb-data-science-symposium-2022-cincinnati/",
          "publishedOn": "2022-11-01T15:16:00.000Z",
          "wordCount": 3115,
          "title": "Attend the Data Science Symposium 2022, November 8 in Cincinnati",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/10/mlm-uccsb-221018.png"
        }
      ]
    },
    {
      "title": "Machine Learning Archives - Uber Engineering Blog",
      "feedUrl": "https://eng.uber.com/tag/machine-learning/feed",
      "siteUrl": null,
      "articles": []
    },
    {
      "title": "AWS Machine Learning Blog",
      "feedUrl": "https://aws.amazon.com/blogs/machine-learning/feed",
      "siteUrl": "https://aws.amazon.com/blogs/machine-learning/",
      "articles": [
        {
          "id": "0dbcc48b5b8c26c52760bab227c123d328b95b6b",
          "author": "Chris Lott",
          "description": "Your contact center serves as the vital link between your business and your customers. Every call to your contact center is an opportunity to learn more about your customers’ needs and how well you are meeting those needs. Most contact centers require their agents to summarize their conversation after every call. Call summarization is a valuable tool that helps contact centers understand and gain insights from customer calls. Additionally, accurate call summaries enhance the customer journey by eliminating the need for customers to repeat information when transferred to another agent. In this post, we explain how to use the power of generative AI to reduce the effort and improve the accuracy of creating call summaries and call dispositions. We also show how to get started quickly using the latest version of our open source solution, Live Call Analytics with Agent Assist.",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-generative-ai-to-increase-agent-productivity-through-automated-call-summarization/",
          "publishedOn": "2023-11-06T23:10:06.000Z",
          "wordCount": 2361,
          "title": "Use generative AI to increase agent productivity through automated call summarization",
          "enclosure": {
            "length": "8292531",
            "type": "video/mp4",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-15703/LCA_-_Summarization_demo.mp4"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/11/06/featured-images-ml15703-1120x630.jpg"
        },
        {
          "id": "59923b682d381a8b912b6acc338e4da40eded223",
          "author": "Shibin Michaelraj",
          "description": "Amazon Textract is a machine learning (ML) service that automatically extracts text, handwriting, and data from scanned documents. Queries is a feature that enables you to extract specific pieces of information from varying, complex documents using natural language. Custom Queries provides a way for you to customize the Queries feature for your business-specific, non-standard documents […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/customize-amazon-textract-with-business-specific-documents-using-custom-queries/",
          "publishedOn": "2023-11-06T16:29:12.000Z",
          "wordCount": 2837,
          "title": "Customize Amazon Textract with business-specific documents using Custom Queries",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/11/06/customize-amazon-textract-custom-queries.jpg"
        },
        {
          "id": "cc16ece334b6cb2938bca7b8d49d99a7d63bd78f",
          "author": "Rachna Chadha",
          "description": "We are excited to announce that Amazon SageMaker JumpStart can now stream large language model (LLM) inference responses. Token streaming allows you to see the model response output as it is being generated instead of waiting for LLMs to finish the response generation before it is made available for you to use or display. The […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/stream-large-language-model-responses-in-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-11-06T16:26:23.000Z",
          "wordCount": 2112,
          "title": "Stream large language model responses in Amazon SageMaker JumpStart",
          "enclosure": {
            "length": "1306712",
            "type": "video/mp4",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-15839/No+Streaming.mp4"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/11/06/stream-large-language-models-1.jpg"
        },
        {
          "id": "7827c542e5c2ff983ca8faf0a466f83faecf3d30",
          "author": "Tareq Haschemi",
          "description": "There’s a kind of magic that surrounds a soccer shot so powerful, it leaves spectators, players, and even commentators in a momentary state of awe. Think back to a moment when the sheer force of a strike left an entire Bundesliga stadium buzzing with energy. What exactly captures our imagination with such intensity? While there […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/bundesliga-match-facts-shot-speed-who-fires-the-hardest-shots-in-the-bundesliga/",
          "publishedOn": "2023-11-03T08:50:12.000Z",
          "wordCount": 2891,
          "title": "Bundesliga Match Facts Shot Speed – Who fires the hardest shots in the Bundesliga?",
          "enclosure": {
            "length": "17436080",
            "type": "video/mp4",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-15427/VIDEO_1.mp4"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/31/ml-15427-IMG04-1019x630.jpg"
        },
        {
          "id": "023c42c7f7041c11e2b5936f36f4303e4054a092",
          "author": "Janisha Anand",
          "description": "Amazon SageMaker Canvas now supports deploying machine learning (ML) models to real-time inferencing endpoints, allowing you take your ML models to production and drive action based on ML-powered insights. SageMaker Canvas is a no-code workspace that enables analysts and citizen data scientists to generate accurate ML predictions for their business needs. Until now, SageMaker Canvas […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/deploy-ml-models-built-in-amazon-sagemaker-canvas-to-amazon-sagemaker-real-time-endpoints/",
          "publishedOn": "2023-11-02T18:16:06.000Z",
          "wordCount": 1786,
          "title": "Deploy ML models built in Amazon SageMaker Canvas to Amazon SageMaker real-time endpoints",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/11/02/deploy-ml-models-built-in-sagemaker-canvas-1260x630.jpg"
        },
        {
          "id": "27793976c24a6719eab24b08b8ab4e8c31d48e62",
          "author": "Jeff Li",
          "description": "Recently, teachers and institutions have looked for different ways to incorporate artificial intelligence (AI) into their curriculums, whether it be teaching about machine learning (ML) or incorporating it into creating lesson plans, grading, or other educational applications. Generative AI models, in particular large language models (LLMs), have dramatically sped up AI’s impact on education. Generative […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/develop-generative-ai-applications-to-improve-teaching-and-learning-experiences/",
          "publishedOn": "2023-11-02T16:36:43.000Z",
          "wordCount": 2274,
          "title": "Develop generative AI applications to improve teaching and learning experiences",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/27/ml-14559-image1a.jpg"
        },
        {
          "id": "6d69745c2ef35e37cc9072f680a21bfea762fd6e",
          "author": "Alfred Shen",
          "description": "Visual language processing (VLP) is at the forefront of generative AI, driving advancements in multimodal learning that encompasses language intelligence, vision understanding, and processing. Combined with large language models (LLM) and Contrastive Language-Image Pre-Training (CLIP) trained with a large quantity of multimodality data, visual language models (VLMs) are particularly adept at tasks like image captioning, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/dialogue-guided-visual-language-processing-with-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-11-01T16:54:51.000Z",
          "wordCount": 4859,
          "title": "Dialogue-guided visual language processing with Amazon SageMaker JumpStart",
          "enclosure": {
            "length": "111581874",
            "type": "video/mp4",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-15508/dgvlp_norm.mp4"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/11/01/dialogue-guided-visual-language-1260x628.jpg"
        },
        {
          "id": "877fcef2bf511df06b7f7a74b15d8dd8e93f62f1",
          "author": "Aman Tiwari",
          "description": "Today, personally identifiable information (PII) is everywhere. PII is in emails, slack messages, videos, PDFs, and so on. It refers to any data or information that can be used to identify a specific individual. PII is sensitive in nature and includes various types of personal data, such as name, contact information, identification numbers, financial information, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-reveals-logikcull-used-amazon-comprehend-to-detect-and-redact-pii-from-legal-documents-at-scale/",
          "publishedOn": "2023-11-01T16:45:00.000Z",
          "wordCount": 2352,
          "title": "How Reveal’s Logikcull used Amazon Comprehend to detect and redact PII from legal documents at scale",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/23/Second-Pass-Detection-ML-13421-825x630.png"
        },
        {
          "id": "0ee22bfffc23c323e900066240efa1d226978d05",
          "author": "Anthony Medeiros",
          "description": "This post was co-written with Anthony Medeiros, Manager of Solutions Engineering and Architecture for North America Artificial Intelligence, and Blake Santschi, Business Intelligence Manager, from Schneider Electric. Additional Schneider Electric experts include Jesse Miller, Somik Chowdhury, Shaswat Babhulgaonkar, David Watkins, Mark Carlson and Barbara Sleczkowski.  Enterprise Resource Planning (ERP) systems are used by companies to […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/schneider-electric-leverages-retrieval-augmented-llms-on-sagemaker-to-ensure-real-time-updates-in-their-erp-systems/",
          "publishedOn": "2023-10-31T15:31:45.000Z",
          "wordCount": 2864,
          "title": "Schneider Electric leverages Retrieval Augmented LLMs on SageMaker to ensure real-time updates in their ERP systems",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/31/schneider-electric-1260x625.jpg"
        },
        {
          "id": "cb4a24158e09308bca4afd98583cb061e98057df",
          "author": "Ram Vittal",
          "description": "Amazon Bedrock is a fully managed service provided by AWS that offers developers access to foundation models (FMs) and the tools to customize them for specific applications. It allows developers to build and scale generative AI applications using FMs through an API, without managing infrastructure. You can choose from various FMs from Amazon and leading […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-aws-privatelink-to-set-up-private-access-to-amazon-bedrock/",
          "publishedOn": "2023-10-30T17:50:59.000Z",
          "wordCount": 2455,
          "title": "Use AWS PrivateLink to set up private access to Amazon Bedrock",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/30/set-up-private-access-to-bedrock-1260x630.jpg"
        },
        {
          "id": "a14fb779f40a978ddca3a43637da02f6e3200996",
          "author": "Evan Kravitz",
          "description": "We are excited to announce a simplified version of the Amazon SageMaker JumpStart SDK that makes it straightforward to build, train, and deploy foundation models. The code for prediction is also simplified. In this post, we demonstrate how you can use the simplified SageMaker Jumpstart SDK to get started with using foundation models in just a couple of lines of code.",
          "link": "https://aws.amazon.com/blogs/machine-learning/deploy-and-fine-tune-foundation-models-in-amazon-sagemaker-jumpstart-with-two-lines-of-code/",
          "publishedOn": "2023-10-30T17:33:11.000Z",
          "wordCount": 2177,
          "title": "Deploy and fine-tune foundation models in Amazon SageMaker JumpStart with two lines of code",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/30/deploy-and-tune-foundation-models-1258x630.jpg"
        },
        {
          "id": "c8f5084a920727dc607715d95a03a7c5af343eca",
          "author": "Ba'Carri Johnson",
          "description": "Generative artificial intelligence is transforming how enterprises do business. Organizations are using AI to improve data-driven decisions, enhance omnichannel experiences, and drive next-generation product development. Enterprises are using generative AI specifically to power their marketing efforts through emails, push notifications, and other outbound communication channels. Gartner predicts that “by 2025, 30% of outbound marketing messages […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/elevate-your-marketing-solutions-with-amazon-personalize-and-generative-ai/",
          "publishedOn": "2023-10-27T16:30:52.000Z",
          "wordCount": 2300,
          "title": "Elevate your marketing solutions with Amazon Personalize and generative AI",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/27/elevate-your-marketing-1260x630.jpg"
        },
        {
          "id": "e69d903525d682df7cd9db492b9f19e0a55ed94f",
          "author": "Channa Basavaraja",
          "description": "Amazon Kendra is an intelligent search service powered by machine learning (ML). Amazon Kendra helps you easily aggregate content from a variety of content repositories into a centralized index that lets you quickly search all your enterprise data and find the most accurate answer. Drupal is a content management software. It’s used to make many […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/intelligently-search-drupal-content-using-amazon-kendra/",
          "publishedOn": "2023-10-26T17:37:27.000Z",
          "wordCount": 2167,
          "title": "Intelligently search Drupal content using Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/20/ml-13088-image003-1178x630.jpg"
        },
        {
          "id": "2e1abf2525294fbbdf909a4f84dbb71855ec6e2d",
          "author": "Jose Benitez",
          "description": "This is a guest post by Jose Benitez, Founder and Director of AI and Mattias Ponchon, Head of Infrastructure at Intuitivo. Intuitivo, a pioneer in retail innovation, is revolutionizing shopping with its cloud-based AI and machine learning (AI/ML) transactional processing system. This groundbreaking technology enables us to operate millions of autonomous points of purchase (A-POPs) […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/intuitivo-achieves-higher-throughput-while-saving-on-ai-ml-costs-using-aws-inferentia-and-pytorch/",
          "publishedOn": "2023-10-26T17:23:19.000Z",
          "wordCount": 2503,
          "title": "Intuitivo achieves higher throughput while saving on AI/ML costs using AWS Inferentia and PyTorch",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/23/ML15012_APop-842x630.png"
        },
        {
          "id": "014c2ae344a6ff50cb497774092856a4b918278d",
          "author": "Davide Gallitelli",
          "description": "Enterprises seek to harness the potential of Machine Learning (ML) to solve complex problems and improve outcomes. Until recently, building and deploying ML models required deep levels of technical and coding skills, including tuning ML models and maintaining operational pipelines. Since its introduction in 2021, Amazon SageMaker Canvas has enabled business analysts to build, deploy, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/empower-your-business-users-to-extract-insights-from-company-documents-using-amazon-sagemaker-canvas-generative-ai/",
          "publishedOn": "2023-10-26T17:16:42.000Z",
          "wordCount": 2428,
          "title": "Empower your business users to extract insights from company documents using Amazon SageMaker Canvas Generative AI",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/24/ML-15763-image017-971x630.png"
        },
        {
          "id": "d17f5048164c69bf3e9133fa165254ce0437b6e5",
          "author": "Karsten Schroer",
          "description": "Methane (CH4) is a major anthropogenic greenhouse gas that‘s a by-product of oil and gas extraction, coal mining, large-scale animal farming, and waste disposal, among other sources. The global warming potential of CH4 is 86 times that of CO2 and the Intergovernmental Panel on Climate Change (IPCC) estimates that methane is responsible for 30 percent of observed […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/detection-and-high-frequency-monitoring-of-methane-emission-point-sources-using-amazon-sagemaker-geospatial-capabilities/",
          "publishedOn": "2023-10-25T18:46:52.000Z",
          "wordCount": 3732,
          "title": "Detection and high-frequency monitoring of methane emission point sources using Amazon SageMaker geospatial capabilities",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/04/ML-15188-figure-01-1260x560.jpg"
        },
        {
          "id": "fd38fb1f95610e27afc699bd48fa09b6963a4838",
          "author": "Sonali Sahu",
          "description": "In today’s information age, the vast volumes of data housed in countless documents present both a challenge and an opportunity for businesses. Traditional document processing methods often fall short in efficiency and accuracy, leaving room for innovation, cost-efficiency, and optimizations. Document processing has witnessed significant advancements with the advent of Intelligent Document Processing (IDP). With […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/intelligent-document-processing-with-amazon-textract-amazon-bedrock-and-langchain/",
          "publishedOn": "2023-10-24T20:52:03.000Z",
          "wordCount": 5862,
          "title": "Intelligent document processing with Amazon Textract, Amazon Bedrock, and LangChain",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/13/map-reduce-workflow-1260x604.png"
        },
        {
          "id": "965b9ff827f2e9047ee6f03512dd20912d159d0d",
          "author": "Dhurjati Brahma",
          "description": "This post is co-authored by Dhurjati Brahma, Senior Systems Architect at T-Mobile US, Inc and Jim Chao, Principal Engineer/Architect at T-Mobile US, Inc and Nicholas Zellerhoff Associate Systems Architect at T-Mobile US, Inc. T-Mobile US, Inc. provides a Voicemail to Text service to its customers, which allows customers to quickly read through their voicemails and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/t-mobile-us-inc-uses-artificial-intelligence-through-amazon-transcribe-and-amazon-translate-to-deliver-voicemail-in-the-language-of-their-customers-choice/",
          "publishedOn": "2023-10-24T16:23:59.000Z",
          "wordCount": 1967,
          "title": "T-Mobile US, Inc. uses artificial intelligence through Amazon Transcribe and Amazon Translate to deliver voicemail in the language of their customers’ choice",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/24/t-mobile-voicemail.jpg"
        },
        {
          "id": "e7bb51c56e2e2b1bbfe9df22a65d3e21c6de66f4",
          "author": "Yi Xiang",
          "description": "This post is co-authored by Anatoly Khomenko, Machine Learning Engineer, and Abdenour Bezzouh, Chief Technology Officer at Talent.com. Founded in 2011, Talent.com is one of the world’s largest sources of employment. The company combines paid job listings from their clients with public job listings into a single searchable platform. With over 30 million jobs listed […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/from-text-to-dream-job-building-an-nlp-based-job-recommender-at-talent-com-with-amazon-sagemaker/",
          "publishedOn": "2023-10-23T21:33:28.000Z",
          "wordCount": 3634,
          "title": "From text to dream job: Building an NLP-based job recommender at Talent.com with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/16/ml-14927-image001-1260x422.png"
        },
        {
          "id": "16591370cdafab2fc7272925545c0644a06d6e27",
          "author": "Ram Vittal",
          "description": "Customers of every size and industry are innovating on AWS by infusing machine learning (ML) into their products and services. Recent developments in generative AI models have further sped up the need of ML adoption across industries. However, implementing security, data privacy, and governance controls are still key challenges faced by customers when implementing ML […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/governing-the-ml-lifecycle-at-scale-part-1-a-framework-for-architecting-ml-workloads-using-amazon-sagemaker/",
          "publishedOn": "2023-10-20T17:30:59.000Z",
          "wordCount": 4812,
          "title": "Governing the ML lifecycle at scale, Part 1: A framework for architecting ML workloads using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/05/image001-1146x630.png"
        },
        {
          "id": "d7d157d3ca5e8424ebdb05083c4fd8ecb5fd56f1",
          "author": "Utkarsh Agrawal",
          "description": "This is a guest post co-written by Rama Badrinath, Divay Jindal and Utkarsh Agrawal at Meesho. Meesho is India’s fastest growing ecommerce company with a mission to democratize internet commerce for everyone and make it accessible to the next billion users of India. Meesho was founded in 2015 and today focuses on buyers and sellers […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-meesho-built-a-generalized-feed-ranker-using-amazon-sagemaker-inference/",
          "publishedOn": "2023-10-20T17:18:26.000Z",
          "wordCount": 1943,
          "title": "How Meesho built a generalized feed ranker using Amazon SageMaker inference",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/20/meesho-sagemaker-1260x628.jpg"
        },
        {
          "id": "e2bcf4362e7e60f9963cf8751678af424ead1e3c",
          "author": "Lana Zhang",
          "description": "Companies increasingly rely on user-generated images and videos for engagement. From ecommerce platforms encouraging customers to share product images to social media companies promoting user-generated videos and images, using user content for engagement is a powerful strategy. However, it can be challenging to ensure that this user-generated content is consistent with your policies and fosters […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/announcing-rekogniton-custom-moderation-enhance-accuracy-of-pre-trained-rekognition-moderation-models-with-your-data/",
          "publishedOn": "2023-10-19T22:47:25.000Z",
          "wordCount": 2245,
          "title": "Announcing Rekogniton Custom Moderation: Enhance accuracy of pre-trained Rekognition moderation models with your data",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/18/ml-15641-6-1.png"
        },
        {
          "id": "6882dcd3f5ffd98e092fa93530aab539a7a7fb6b",
          "author": "Andreas Karagounis",
          "description": "High-resolution imagery is very prevalent in today’s world, from satellite imagery to drones and DLSR cameras. From this imagery, we can capture damage due to natural disasters, anomalies in manufacturing equipment, or very small defects such as defects on printed circuit boards (PCBs) or semiconductors. Building anomaly detection models using high-resolution imagery can be challenging […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/defect-detection-in-high-resolution-imagery-using-two-stage-amazon-rekognition-custom-labels-models/",
          "publishedOn": "2023-10-19T18:00:36.000Z",
          "wordCount": 2371,
          "title": "Defect detection in high-resolution imagery using two-stage Amazon Rekognition Custom Labels models",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/19/high-resolution-two-stage-1260x630.jpg"
        },
        {
          "id": "a6c178033994ad61e906ed8ad00ff93d8abd0468",
          "author": "Tricia Jamison",
          "description": "Customers increasingly want to use deep learning approaches such as large language models (LLMs) to automate the extraction of data and insights. For many industries, data that is useful for machine learning (ML) may contain personally identifiable information (PII). To ensure customer privacy and maintain regulatory compliance while training, fine-tuning, and using deep learning models, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automatically-redact-pii-for-machine-learning-using-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2023-10-19T16:57:49.000Z",
          "wordCount": 3517,
          "title": "Automatically redact PII for machine learning using Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/11/sagemaker-pipelines.png"
        },
        {
          "id": "054b1f9ced560f2b18481d3f8fa07562e572850a",
          "author": "Mason Cahill",
          "description": "Purina US, a subsidiary of Nestlé, has a long history of enabling people to more easily adopt pets through Petfinder, a digital marketplace of over 11,000 animal shelters and rescue groups across the US, Canada, and Mexico. As the leading pet adoption platform, Petfinder has helped millions of pets find their forever homes. Purina consistently […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/optimize-pet-profiles-for-purinas-petfinder-application-using-amazon-rekognition-custom-labels-and-aws-step-functions/",
          "publishedOn": "2023-10-18T16:00:44.000Z",
          "wordCount": 2587,
          "title": "Optimize pet profiles for Purina’s Petfinder application using Amazon Rekognition Custom Labels and AWS Step Functions",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/18/petfinder-dogs.jpg"
        },
        {
          "id": "c8e8335028a2065122b24ebf754e06211ef2b0cd",
          "author": "Burak Gozluklu",
          "description": "Amazon Pharmacy is a full-service pharmacy on Amazon.com that offers transparent pricing, clinical and customer support, and free delivery right to your door. Customer care agents play a crucial role in quickly and accurately retrieving information related to pharmacy information, including prescription clarifications and transfer status, order and dispensing details, and patient profile information, in […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/learn-how-amazon-pharmacy-created-their-llm-based-chat-bot-using-amazon-sagemaker/",
          "publishedOn": "2023-10-17T19:43:52.000Z",
          "wordCount": 2541,
          "title": "Learn how Amazon Pharmacy created their LLM-based chat-bot using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/17/ML-15416-pic4-arch-1-1170x630.png"
        },
        {
          "id": "a4918b4d88c3b09b68431e6a485c20ca9f74cc02",
          "author": "Hao Huang",
          "description": "At Amazon Web Services (AWS), not only are we passionate about providing customers with a variety of comprehensive technical solutions, but we’re also keen on deeply understanding our customers’ business processes. We adopt a third-party perspective and objective judgment to help customers sort out their value propositions, collect pain points, propose appropriate solutions, and create […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/keeping-an-eye-on-your-cattle-using-ai-technology/",
          "publishedOn": "2023-10-17T19:40:30.000Z",
          "wordCount": 4903,
          "title": "Keeping an eye on your cattle using AI technology",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/07/process.png"
        },
        {
          "id": "20d350c5be42ba78896aab8753d9e03ddb68e2a4",
          "author": "Shreeya Sharma",
          "description": "Amazon Personalize has launched a new integration with Amazon OpenSearch Service that enables you to personalize search results for each user and assists in predicting their search needs. The Amazon Personalize Search Ranking plugin within OpenSearch Service allows you to improve the end-user engagement and conversion from your website and app search by taking advantage […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/personalize-your-search-results-with-amazon-personalize-and-amazon-opensearch-service-integration/",
          "publishedOn": "2023-10-17T19:33:03.000Z",
          "wordCount": 1972,
          "title": "Personalize your search results with Amazon Personalize and Amazon OpenSearch Service integration",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/17/personalize-personalize.jpg"
        },
        {
          "id": "d7275290cb2b3aafe167dc7e96c44fc8f137a4ac",
          "author": "Ricard Borràs",
          "description": "Veriff is an identity verification platform partner for innovative growth-driven organizations, including pioneers in financial services, FinTech, crypto, gaming, mobility, and online marketplaces. In this post, we show you how Veriff standardized their model deployment workflow using Amazon SageMaker, reducing costs and development time.",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-veriff-decreased-deployment-time-by-80-using-amazon-sagemaker-multi-model-endpoints/",
          "publishedOn": "2023-10-16T19:30:47.000Z",
          "wordCount": 2516,
          "title": "How Veriff decreased deployment time by 80% using Amazon SageMaker multi-model endpoints",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/10/MLBLOG64069-im01-1260x532.png"
        },
        {
          "id": "26f6bce232483d6777c2e86268fa4b4222390aab",
          "author": "Abhi Shivaditya",
          "description": "What is the optimal framework and configuration for hosting large language models (LLMs) for text-generating generative AI applications? Despite the abundance of options for serving LLMs, this is a hard question to answer due to the size of the models, varying model architectures, performance requirements of applications, and more. The Amazon SageMaker Large Model Inference […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/improve-performance-of-falcon-models-with-amazon-sagemaker/",
          "publishedOn": "2023-10-11T16:28:05.000Z",
          "wordCount": 3961,
          "title": "Improve performance of Falcon models with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/11/improve-falcon-performance-1257x630.jpg"
        },
        {
          "id": "3fc93bffa4117e4687f3a09d0dc8af011798dc3e",
          "author": "Jiten Dedhia",
          "description": "In this post, we show how to index information stored in websites and use the intelligent search in Amazon Kendra to search for answers from content stored in internal and external websites. In addition, the ML-powered intelligent search can accurately get answers for your questions from unstructured documents with natural language narrative content, for which keyword search is not very effective.",
          "link": "https://aws.amazon.com/blogs/machine-learning/index-your-web-crawled-content-using-the-new-web-crawler-for-amazon-kendra/",
          "publishedOn": "2023-10-11T16:15:29.000Z",
          "wordCount": 2053,
          "title": "Index your web crawled content using the new Web Crawler for Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/11/web-crawled-content-kendra.jpg"
        },
        {
          "id": "145ebaed28dda5de4846c2e0dd8e4a54f97b1216",
          "author": "Anand Iyer",
          "description": "Launched in 2021, Amazon SageMaker Canvas is a visual, point-and-click service that allows business analysts and citizen data scientists to use ready-to-use machine learning (ML) models and build custom ML models to generate accurate predictions without the need to write any code. Ready-to-use models enable you to derive immediate insights from text, image, and document […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/new-no-code-generative-ai-capabilities-now-available-in-amazon-sagemaker-canvas/",
          "publishedOn": "2023-10-10T17:20:10.000Z",
          "wordCount": 2138,
          "title": "New – No-code generative AI capabilities now available in Amazon SageMaker Canvas",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/l-ml-15314-image001-881x630.png"
        },
        {
          "id": "6fbdc7b2c25e72984d866afa8c3024fda8a29b5f",
          "author": "Hemant Singh",
          "description": "Today, we’re excited to announce that the OpenAI Whisper foundation model is available for customers using Amazon SageMaker JumpStart. Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680 thousand hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/whisper-models-for-automatic-speech-recognition-now-available-in-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-10-10T17:09:35.000Z",
          "wordCount": 3269,
          "title": "Whisper models for automatic speech recognition now available in Amazon SageMaker JumpStart",
          "enclosure": {
            "length": "1280078",
            "type": "audio/wav",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-15311/sample1.wav"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/02/ML-15311-image001-1225x630.jpg"
        },
        {
          "id": "38ddfd3589f3778d8f34f15c640e9e2097fcaabe",
          "author": "Qiong Zhang",
          "description": "In this blog, you will learn to build a cloud-native FL architecture on AWS. By using infrastructure as code (IaC) tools on AWS, you can deploy FL architectures with ease. Also, a cloud-native architecture takes full advantage of a variety of AWS services with proven security and operational excellence, thereby simplifying the development of FL.",
          "link": "https://aws.amazon.com/blogs/machine-learning/reinventing-a-cloud-native-federated-learning-architecture-on-aws/",
          "publishedOn": "2023-10-10T17:01:51.000Z",
          "wordCount": 3708,
          "title": "Reinventing a cloud-native federated learning architecture on AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/26/fl-arch.png"
        },
        {
          "id": "f6379ad2217c7af13a0224391c6b4156d9af2a3d",
          "author": "Kyle Ulrich",
          "description": "Today, we are excited to announce that the Mistral 7B foundation models, developed by Mistral AI, are available for customers through Amazon SageMaker JumpStart to deploy with one click for running inference. With 7 billion parameters, Mistral 7B can be easily customized and quickly deployed. You can try out this model with SageMaker JumpStart, a […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-10-09T21:37:48.000Z",
          "wordCount": 4168,
          "title": "Mistral 7B foundation models from Mistral AI are now available in Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/mistral-7b-sagemaker-jumpstart.jpg"
        },
        {
          "id": "c5e6ca49ccc13a7f87d34949c97eec679ed55d46",
          "author": "Gavin Satur",
          "description": "According to Gartner, 85% of software buyers trust online reviews as much as personal recommendations. Customers provide feedback and reviews about products they have purchased through many channels, including review websites, vendor websites, sales calls, social media, and many others. The problem with the increasing volume of customer reviews across multiple channels is that it […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-no-code-machine-learning-to-derive-insights-from-product-reviews-using-amazon-sagemaker-canvas-sentiment-analysis-and-text-analysis-models/",
          "publishedOn": "2023-10-09T17:49:32.000Z",
          "wordCount": 2206,
          "title": "Use no-code machine learning to derive insights from product reviews using Amazon SageMaker Canvas sentiment analysis and text analysis models",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/no-code-sentiment-reviews.jpg"
        },
        {
          "id": "433fa61bee27e013db333bccd4fcf2d6c6952342",
          "author": "Maysara Hamdan",
          "description": "A recommendation engine is only as good as the data used to prepare it. Transforming raw data into a format that is suitable for a model is key to getting better personalized recommendations for end-users. In this post, we walk through how to prepare and import the MovieLens dataset, a dataset prepared by GroupLens research […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/prepare-your-data-for-amazon-personalize-with-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2023-10-09T17:45:27.000Z",
          "wordCount": 3264,
          "title": "Prepare your data for Amazon Personalize with Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/prepare-amazon-personalize-data-wrangler.jpg"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2305.17560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zijie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_D/0/1/0/all/0/1\">Dule Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1\">Amir Barati Farimani</a>",
          "description": "Transformer has shown state-of-the-art performance on various applications\nand has recently emerged as a promising tool for surrogate modeling of partial\ndifferential equations (PDEs). Despite the introduction of linear-complexity\nattention, applying Transformer to problems with a large number of grid points\ncan be numerically unstable and computationally expensive. In this work, we\npropose Factorized Transformer (FactFormer), which is based on an axial\nfactorized kernel integral. Concretely, we introduce a learnable projection\noperator that decomposes the input function into multiple sub-functions with\none-dimensional domain. These sub-functions are then evaluated and used to\ncompute the instance-based kernel with an axial factorized scheme. We showcase\nthat the proposed model is able to simulate 2D Kolmogorov flow on a $256\\times\n256$ grid and 3D smoke buoyancy on a $64\\times64\\times64$ grid with good\naccuracy and efficiency. The proposed factorized scheme can serve as a\ncomputationally efficient low-rank surrogate for the full attention scheme when\ndealing with multi-dimensional problems.",
          "link": "http://arxiv.org/abs/2305.17560",
          "publishedOn": "2023-11-07T00:44:10.437Z",
          "wordCount": 663,
          "title": "Scalable Transformer for PDE Surrogate Modeling. (arXiv:2305.17560v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.13139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khalife_S/0/1/0/all/0/1\">Sammy Khalife</a>",
          "description": "The expressivity of Graph Neural Networks (GNNs) can be entirely\ncharacterized by appropriate fragments of the first-order logic. Namely, any\nquery of the two variable fragment of graded modal logic (GC2) interpreted over\nlabeled graphs can be expressed using a GNN whose size depends only on the\ndepth of the query. As pointed out by [Barcelo & Al., 2020, Grohe, 2021], this\ndescription holds for a family of activation functions, leaving the possibility\nfor a hierarchy of logics expressible by GNNs depending on the chosen\nactivation function. In this article, we show that such hierarchy indeed exists\nby proving that GC2 queries cannot be expressed by GNNs with polynomial\nactivation functions. This implies a separation between polynomial and popular\nnon-polynomial activations (such as ReLUs, sigmoid and hyperbolic tan and\nothers) and answers an open question formulated by [Grohe, 2021].",
          "link": "http://arxiv.org/abs/2310.13139",
          "publishedOn": "2023-11-07T00:44:10.394Z",
          "wordCount": 650,
          "title": "Graph Neural Networks with polynomial activations have limited expressivity. (arXiv:2310.13139v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.08761",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1\">Junwoo Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nam_S/0/1/0/all/0/1\">Seungtae Nam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hyunmo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Seok-Bae Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Youngjoon Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1\">Eunbyung Park</a>",
          "description": "Physics-informed neural networks (PINNs) have emerged as new data-driven PDE\nsolvers for both forward and inverse problems. While promising, the expensive\ncomputational costs to obtain solutions often restrict their broader\napplicability. We demonstrate that the computations in automatic\ndifferentiation (AD) can be significantly reduced by leveraging forward-mode AD\nwhen training PINN. However, a naive application of forward-mode AD to\nconventional PINNs results in higher computation, losing its practical benefit.\nTherefore, we propose a network architecture, called separable PINN (SPINN),\nwhich can facilitate forward-mode AD for more efficient computation. SPINN\noperates on a per-axis basis instead of point-wise processing in conventional\nPINNs, decreasing the number of network forward passes. Besides, while the\ncomputation and memory costs of standard PINNs grow exponentially along with\nthe grid resolution, that of our model is remarkably less susceptible,\nmitigating the curse of dimensionality. We demonstrate the effectiveness of our\nmodel in various PDE systems by significantly reducing the training run-time\nwhile achieving comparable accuracy. Project page:\nhttps://jwcho5576.github.io/spinn/",
          "link": "http://arxiv.org/abs/2211.08761",
          "publishedOn": "2023-11-07T00:44:10.387Z",
          "wordCount": 736,
          "title": "Separable PINN: Mitigating the Curse of Dimensionality in Physics-Informed Neural Networks. (arXiv:2211.08761v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.14201",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yifan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yiming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chengfeng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhennan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bin Dong</a>",
          "description": "Prompt Engineering (PE) has emerged as a critical technique for guiding Large\nLanguage Models (LLMs) in solving intricate tasks. Its importance is\nhighlighted by its potential to significantly enhance the efficiency and\neffectiveness of human-machine interaction. As tasks grow increasingly complex,\nrecent advanced PE methods have extended beyond the limitations of single-round\ninteractions to embrace multi-round interactions, which allows for a deeper and\nmore nuanced engagement with LLMs. In this paper, we propose an optimal control\nframework tailored for multi-round interactions with LLMs. This framework\nprovides a unified mathematical structure that not only systematizes the\nexisting PE methods but also sets the stage for rigorous analytical\nimprovements. Furthermore, we extend this framework to include PE via ensemble\nmethods and multi-agent collaboration, thereby enlarging the scope of\napplicability. By adopting an optimal control perspective, we offer fresh\ninsights into existing PE methods and highlight theoretical challenges that\nwarrant future research. Besides, our work lays a foundation for the\ndevelopment of more effective and interpretable PE methods.",
          "link": "http://arxiv.org/abs/2310.14201",
          "publishedOn": "2023-11-07T00:44:10.285Z",
          "wordCount": 692,
          "title": "Prompt Engineering Through the Lens of Optimal Control. (arXiv:2310.14201v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.13484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jinghan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alnaasan_N/0/1/0/all/0/1\">Nawras Alnaasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafi_A/0/1/0/all/0/1\">Aamir Shafi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramoni_H/0/1/0/all/0/1\">Hari Subramoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+K%2E_D/0/1/0/all/0/1\">Dhabaleswar K.</a> (DK) <a href=\"http://arxiv.org/find/cs/1/au:+Panda/0/1/0/all/0/1\">Panda</a>",
          "description": "Autoregressive models, despite their commendable performance in a myriad of\ngenerative tasks, face challenges stemming from their inherently sequential\nstructure. Inference on these models, by design, harnesses a temporal\ndependency, where the current token's probability distribution is conditioned\non preceding tokens. This inherent characteristic severely impedes\ncomputational efficiency during inference as a typical inference request can\nrequire more than thousands of tokens, where generating each token requires a\nload of entire model weights, making the inference more memory-bound. The large\noverhead becomes profound in real deployment where requests arrive randomly,\nnecessitating various generation lengths. Existing solutions, such as dynamic\nbatching and concurrent instances, introduce significant response delays and\nbandwidth contention, falling short of achieving optimal latency and\nthroughput. To address these shortcomings, we propose Flover -- a temporal\nfusion framework for efficiently inferring multiple requests in parallel. We\ndeconstruct the general generation pipeline into pre-processing and token\ngeneration, and equip the framework with a dedicated work scheduler for fusing\nthe generation process temporally across all requests. By orchestrating the\ntoken-level parallelism, Flover exhibits optimal hardware efficiency and\nsignificantly spares the system resources. By further employing a fast buffer\nreordering algorithm that allows memory eviction of finished tasks, it brings\nover 11x inference speedup on GPT and 16x on LLAMA compared to the cutting-edge\nsolutions provided by NVIDIA FasterTransformer. Crucially, by leveraging the\nadvanced tensor parallel technique, Flover proves efficacious across diverse\ncomputational landscapes, from single-GPU setups to distributed scenarios,\nthereby offering robust performance optimization that adapts to variable use\ncases.",
          "link": "http://arxiv.org/abs/2305.13484",
          "publishedOn": "2023-11-07T00:44:10.266Z",
          "wordCount": 829,
          "title": "Flover: A Temporal Fusion Framework for Efficient Autoregressive Model Parallel Inference. (arXiv:2305.13484v3 [cs.DC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.18860",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tew_S/0/1/0/all/0/1\">Shu Yu Tew</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Boley_M/0/1/0/all/0/1\">Mario Boley</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schmidt_D/0/1/0/all/0/1\">Daniel F. Schmidt</a>",
          "description": "We present a novel method for tuning the regularization hyper-parameter,\n$\\lambda$, of a ridge regression that is faster to compute than leave-one-out\ncross-validation (LOOCV) while yielding estimates of the regression parameters\nof equal, or particularly in the setting of sparse covariates, superior quality\nto those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from\nmultiple and bad local minima for finite $n$ and thus requires the\nspecification of a set of candidate $\\lambda$, which can fail to provide good\nsolutions. In contrast, we show that the proposed method is guaranteed to find\na unique optimal solution for large enough $n$, under relatively mild\nconditions, without requiring the specification of any difficult to determine\nhyper-parameters. This is based on a Bayesian formulation of ridge regression\nthat we prove to have a unimodal posterior for large enough $n$, allowing for\nboth the optimal $\\lambda$ and the regression coefficients to be jointly\nlearned within an iterative expectation maximization (EM) procedure.\nImportantly, we show that by utilizing an appropriate preprocessing step, a\nsingle iteration of the main EM loop can be implemented in $O(\\min(n, p))$\noperations, for input data with $n$ rows and $p$ columns. In contrast,\nevaluating a single value of $\\lambda$ using fast LOOCV costs $O(n \\min(n, p))$\noperations when using the same preprocessing. This advantage amounts to an\nasymptotic improvement of a factor of $l$ for $l$ candidate values for\n$\\lambda$ (in the regime $q, p \\in O(\\sqrt{n})$ where $q$ is the number of\nregression targets).",
          "link": "http://arxiv.org/abs/2310.18860",
          "publishedOn": "2023-11-07T00:44:10.257Z",
          "wordCount": 784,
          "title": "Bayes beats Cross Validation: Efficient and Accurate Ridge Regression via Expectation Maximization. (arXiv:2310.18860v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.19589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jung Yeon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1\">Lawson L.S. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1\">Robin Walters</a>",
          "description": "Data over non-Euclidean manifolds, often discretized as surface meshes,\nnaturally arise in computer graphics and biological and physical systems. In\nparticular, solutions to partial differential equations (PDEs) over manifolds\ndepend critically on the underlying geometry. While graph neural networks have\nbeen successfully applied to PDEs, they do not incorporate surface geometry and\ndo not consider local gauge symmetries of the manifold. Alternatively, recent\nworks on gauge equivariant convolutional and attentional architectures on\nmeshes leverage the underlying geometry but underperform in modeling surface\nPDEs with complex nonlinear dynamics. To address these issues, we introduce a\nnew gauge equivariant architecture using nonlinear message passing. Our novel\narchitecture achieves higher performance than either convolutional or\nattentional networks on domains with highly complex and nonlinear dynamics.\nHowever, similar to the non-mesh case, design trade-offs favor convolutional,\nattentional, or message passing networks for different tasks; we investigate in\nwhich circumstances our message passing method provides the most benefit.",
          "link": "http://arxiv.org/abs/2310.19589",
          "publishedOn": "2023-11-07T00:44:10.250Z",
          "wordCount": 688,
          "title": "Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message Passing. (arXiv:2310.19589v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.09136",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Atsidakou_A/0/1/0/all/0/1\">Alexia Atsidakou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katariya_S/0/1/0/all/0/1\">Sumeet Katariya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caramanis_C/0/1/0/all/0/1\">Constantine Caramanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanghavi_S/0/1/0/all/0/1\">Sujay Sanghavi</a>",
          "description": "We derive the first finite-time logarithmic Bayes regret upper bounds for\nBayesian bandits. In Gaussian bandits, we obtain $O(c_\\Delta \\log n)$ and\n$O(c_h \\log^2 n)$ bounds for an upper confidence bound algorithm, where $c_h$\nand $c_\\Delta$ are constants depending on the prior distribution and the gaps\nof random bandit instances sampled from it, respectively. The latter bound\nasymptotically matches the lower bound of Lai (1987). Our proofs are a major\ntechnical departure from prior works, while being simple and general. To show\nthe generality of our techniques, we apply them to linear bandits. Our results\nprovide insights on the value of prior in the Bayesian setting, both in the\nobjective and as a side information given to the learner. They significantly\nimprove upon existing $\\tilde{O}(\\sqrt{n})$ bounds, which have become standard\nin the literature despite the existing lower bounds.",
          "link": "http://arxiv.org/abs/2306.09136",
          "publishedOn": "2023-11-07T00:44:10.240Z",
          "wordCount": 658,
          "title": "Finite-Time Logarithmic Bayes Regret Upper Bounds. (arXiv:2306.09136v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.01466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Andr&#xe9;s C. Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAronco_S/0/1/0/all/0/1\">Stefano D&#x27;Aronco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daudt_R/0/1/0/all/0/1\">Rodrigo Caye Daudt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wegner_J/0/1/0/all/0/1\">Jan D. Wegner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1\">Konrad Schindler</a>",
          "description": "We exploit field guides to learn bird species recognition, in particular\nzero-shot recognition of unseen species. Illustrations contained in field\nguides deliberately focus on discriminative properties of each species, and can\nserve as side information to transfer knowledge from seen to unseen bird\nspecies. We study two approaches: (1) a contrastive encoding of illustrations,\nwhich can be fed into standard zero-shot learning schemes; and (2) a novel\nmethod that leverages the fact that illustrations are also images and as such\nstructurally more similar to photographs than other kinds of side information.\nOur results show that illustrations from field guides, which are readily\navailable for a wide range of species, are indeed a competitive source of side\ninformation for zero-shot learning. On a subset of the iNaturalist2021 dataset\nwith 749 seen and 739 unseen species, we obtain a classification accuracy of\nunseen bird species of $12\\%$ @top-1 and $38\\%$ @top-10, which shows the\npotential of field guides for challenging real-world scenarios with many\nspecies. Our code is available at https://github.com/ac-rodriguez/zsl_billow",
          "link": "http://arxiv.org/abs/2206.01466",
          "publishedOn": "2023-11-07T00:44:10.233Z",
          "wordCount": 712,
          "title": "Recognition of Unseen Bird Species by Learning from Field Guides. (arXiv:2206.01466v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14283",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Triguero_I/0/1/0/all/0/1\">Isaac Triguero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molina_D/0/1/0/all/0/1\">Daniel Molina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poyatos_J/0/1/0/all/0/1\">Javier Poyatos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ser_J/0/1/0/all/0/1\">Javier Del Ser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herrera_F/0/1/0/all/0/1\">Francisco Herrera</a>",
          "description": "Most applications of Artificial Intelligence (AI) are designed for a confined\nand specific task. However, there are many scenarios that call for a more\ngeneral AI, capable of solving a wide array of tasks without being specifically\ndesigned for them. The term General-Purpose Artificial Intelligence Systems\n(GPAIS) has been defined to refer to these AI systems. To date, the possibility\nof an Artificial General Intelligence, powerful enough to perform any\nintellectual task as if it were human, or even improve it, has remained an\naspiration, fiction, and considered a risk for our society. Whilst we might\nstill be far from achieving that, GPAIS is a reality and sitting at the\nforefront of AI research. This work discusses existing definitions for GPAIS\nand proposes a new definition that allows for a gradual differentiation among\ntypes of GPAIS according to their properties and limitations. We distinguish\nbetween closed-world and open-world GPAIS, characterising their degree of\nautonomy and ability based on several factors such as adaptation to new tasks,\ncompetence in domains not intentionally trained for, ability to learn from few\ndata, or proactive acknowledgment of their own limitations. We propose a\ntaxonomy of approaches to realise GPAIS, describing research trends such as the\nuse of AI techniques to improve another AI (AI-powered AI) or (single)\nfoundation models. As a prime example, we delve into GenAI, aligning them with\nthe concepts presented in the taxonomy. We explore multi-modality, which\ninvolves fusing various types of data sources to expand the capabilities of\nGPAIS. Through the proposed definition and taxonomy, our aim is to facilitate\nresearch collaboration across different areas that are tackling general purpose\ntasks, as they share many common aspects. Finally, we discuss the state of\nGPAIS, prospects, societal implications, and the need for regulation and\ngovernance.",
          "link": "http://arxiv.org/abs/2307.14283",
          "publishedOn": "2023-11-07T00:44:10.192Z",
          "wordCount": 836,
          "title": "General Purpose Artificial Intelligence Systems (GPAIS): Properties, Definition, Taxonomy, Societal Implications and Responsible Governance. (arXiv:2307.14283v2 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2106.12915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bertoin_D/0/1/0/all/0/1\">David Bertoin</a> (ISAE-SUPAERO), <a href=\"http://arxiv.org/find/cs/1/au:+Bolte_J/0/1/0/all/0/1\">J&#xe9;r&#xf4;me Bolte</a> (TSE-R), <a href=\"http://arxiv.org/find/cs/1/au:+Gerchinovitz_S/0/1/0/all/0/1\">S&#xe9;bastien Gerchinovitz</a> (IMT), <a href=\"http://arxiv.org/find/cs/1/au:+Pauwels_E/0/1/0/all/0/1\">Edouard Pauwels</a> (IRIT-ADRIA)",
          "description": "In theory, the choice of ReLU(0) in [0, 1] for a neural network has a\nnegligible influence both on backpropagation and training. Yet, in the real\nworld, 32 bits default precision combined with the size of deep learning\nproblems makes it a hyperparameter of training methods. We investigate the\nimportance of the value of ReLU'(0) for several precision levels (16, 32, 64\nbits), on various networks (fully connected, VGG, ResNet) and datasets (MNIST,\nCIFAR10, SVHN, ImageNet). We observe considerable variations of backpropagation\noutputs which occur around half of the time in 32 bits precision. The effect\ndisappears with double precision, while it is systematic at 16 bits. For\nvanilla SGD training, the choice ReLU'(0) = 0 seems to be the most efficient.\nFor our experiments on ImageNet the gain in test accuracy over ReLU'(0) = 1 was\nmore than 10 points (two runs). We also evidence that reconditioning approaches\nas batch-norm or ADAM tend to buffer the influence of ReLU'(0)'s value.\nOverall, the message we convey is that algorithmic differentiation of nonsmooth\nproblems potentially hides parameters that could be tuned advantageously.",
          "link": "http://arxiv.org/abs/2106.12915",
          "publishedOn": "2023-11-07T00:44:10.185Z",
          "wordCount": 748,
          "title": "Numerical influence of ReLU'(0) on backpropagation. (arXiv:2106.12915v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rojas_Campos_A/0/1/0/all/0/1\">Adrian Rojas-Campos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stelz_L/0/1/0/all/0/1\">Lukas Stelz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nieters_P/0/1/0/all/0/1\">Pascal Nieters</a>",
          "description": "Highly-interconnected societies difficult to model the spread of infectious\ndiseases such as COVID-19. Single-region SIR models fail to account for\nincoming forces of infection and expanding them to a large number of\ninteracting regions involves many assumptions that do not hold in the real\nworld. We propose using Universal Differential Equations (UDEs) to capture the\ninfluence of neighboring regions and improve the model's predictions in a\ncombined SIR+UDE model. UDEs are differential equations totally or partially\ndefined by a deep neural network (DNN). We include an additive term to the SIR\nequations composed by a DNN that learns the incoming force of infection from\nthe other regions. The learning is performed using automatic differentiation\nand gradient descent to approach the change in the target system caused by the\nstate of the neighboring regions. We compared the proposed model using a\nsimulated COVID-19 outbreak against a single-region SIR and a fully data-driven\nmodel composed only of a DNN. The proposed UDE+SIR model generates predictions\nthat capture the outbreak dynamic more accurately, but a decay in performance\nis observed at the last stages of the outbreak. The single-area SIR and the\nfully data-driven approach do not capture the proper dynamics accurately. Once\nthe predictions were obtained, we employed the SINDy algorithm to substitute\nthe DNN with a regression, removing the black box element of the model with no\nconsiderable increase in the error levels.",
          "link": "http://arxiv.org/abs/2310.16804",
          "publishedOn": "2023-11-07T00:44:10.177Z",
          "wordCount": 821,
          "title": "Learning COVID-19 Regional Transmission Using Universal Differential Equations in a SIR model. (arXiv:2310.16804v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shih-Min Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magnusson_M/0/1/0/all/0/1\">Martin Magnusson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stork_J/0/1/0/all/0/1\">Johannes A. Stork</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_T/0/1/0/all/0/1\">Todor Stoyanov</a>",
          "description": "Many practically relevant robot grasping problems feature a target object for\nwhich all grasps are occluded, e.g., by the environment. Single-shot grasp\nplanning invariably fails in such scenarios. Instead, it is necessary to first\nmanipulate the object into a configuration that affords a grasp. We solve this\nproblem by learning a sequence of actions that utilize the environment to\nchange the object's pose. Concretely, we employ hierarchical reinforcement\nlearning to combine a sequence of learned parameterized manipulation\nprimitives. By learning the low-level manipulation policies, our approach can\ncontrol the object's state through exploiting interactions between the object,\nthe gripper, and the environment. Designing such a complex behavior\nanalytically would be infeasible under uncontrolled conditions, as an analytic\napproach requires accurate physical modeling of the interaction and contact\ndynamics. In contrast, we learn a hierarchical policy model that operates\ndirectly on depth perception data, without the need for object detection, pose\nestimation, or manual design of controllers. We evaluate our approach on\npicking box-shaped objects of various weight, shape, and friction properties\nfrom a constrained table-top workspace. Our method transfers to a real robot\nand is able to successfully complete the object picking task in 98\\% of\nexperimental trials.",
          "link": "http://arxiv.org/abs/2310.17785",
          "publishedOn": "2023-11-07T00:44:10.134Z",
          "wordCount": 708,
          "title": "Learning Extrinsic Dexterity with Parameterized Manipulation Primitives. (arXiv:2310.17785v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2111.08452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yun William Yu</a>",
          "description": "Minimizers and convolutional neural networks (CNNs) are two quite distinct\npopular techniques that have both been employed to analyze categorical\nbiological sequences. At face value, the methods seem entirely dissimilar.\nMinimizers use min-wise hashing on a rolling window to extract a single\nimportant k-mer feature per window. CNNs start with a wide array of randomly\ninitialized convolutional filters, paired with a pooling operation, and then\nmultiple additional neural layers to learn both the filters themselves and how\nthey can be used to classify the sequence.\n\nHere, our main result is a careful mathematical analysis of hash function\nproperties showing that for sequences over a categorical alphabet, random\nGaussian initialization of convolutional filters with max-pooling is equivalent\nto choosing a minimizer ordering such that selected k-mers are (in Hamming\ndistance) far from the k-mers within the sequence but close to other\nminimizers. In empirical experiments, we find that this property manifests as\ndecreased density in repetitive regions, both in simulation and on real human\ntelomeres. We additionally train from scratch a CNN embedding of synthetic\nshort-reads from the SARS-CoV-2 genome into 3D Euclidean space that locally\nrecapitulates the linear sequence distance of the read origins, a modest step\ntowards building a deep learning assembler, though it is at present too slow to\nbe practical. In total, this manuscript provides a partial explanation for the\neffectiveness of CNNs in categorical sequence analysis.",
          "link": "http://arxiv.org/abs/2111.08452",
          "publishedOn": "2023-11-07T00:44:10.107Z",
          "wordCount": 856,
          "title": "On minimizers and convolutional filters: theoretical connections and applications to genome analysis. (arXiv:2111.08452v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16789",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ajith_A/0/1/0/all/0/1\">Anirudh Ajith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Mengzhou Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yangsibo Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Daogao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blevins_T/0/1/0/all/0/1\">Terra Blevins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>",
          "description": "Although large language models (LLMs) are widely deployed, the data used to\ntrain them is rarely disclosed. Given the incredible scale of this data, up to\ntrillions of tokens, it is all but certain that it includes potentially\nproblematic text such as copyrighted materials, personally identifiable\ninformation, and test data for widely reported reference benchmarks. However,\nwe currently have no way to know which data of these types is included or in\nwhat proportions. In this paper, we study the pretraining data detection\nproblem: given a piece of text and black-box access to an LLM without knowing\nthe pretraining data, can we determine if the model was trained on the provided\ntext? To facilitate this study, we introduce a dynamic benchmark WIKIMIA that\nuses data created before and after model training to support gold truth\ndetection. We also introduce a new detection method Min-K% Prob based on a\nsimple hypothesis: an unseen example is likely to contain a few outlier words\nwith low probabilities under the LLM, while a seen example is less likely to\nhave words with such low probabilities. Min-K% Prob can be applied without any\nknowledge about the pretraining corpus or any additional training, departing\nfrom previous detection methods that require training a reference model on data\nthat is similar to the pretraining data. Moreover, our experiments demonstrate\nthat Min-K% Prob achieves a 7.4% improvement on WIKIMIA over these previous\nmethods. We apply Min-K% Prob to three real-world scenarios, copyrighted book\ndetection, contaminated downstream example detection and privacy auditing of\nmachine unlearning, and find it a consistently effective solution.",
          "link": "http://arxiv.org/abs/2310.16789",
          "publishedOn": "2023-11-07T00:44:10.056Z",
          "wordCount": 788,
          "title": "Detecting Pretraining Data from Large Language Models. (arXiv:2310.16789v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leidinger_A/0/1/0/all/0/1\">Alina Leidinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rooij_R/0/1/0/all/0/1\">Robert van Rooij</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1\">Ekaterina Shutova</a>",
          "description": "The latest generation of LLMs can be prompted to achieve impressive zero-shot\nor few-shot performance in many NLP tasks. However, since performance is highly\nsensitive to the choice of prompts, considerable effort has been devoted to\ncrowd-sourcing prompts or designing methods for prompt optimisation. Yet, we\nstill lack a systematic understanding of how linguistic properties of prompts\ncorrelate with task performance. In this work, we investigate how LLMs of\ndifferent sizes, pre-trained and instruction-tuned, perform on prompts that are\nsemantically equivalent, but vary in linguistic structure. We investigate both\ngrammatical properties such as mood, tense, aspect and modality, as well as\nlexico-semantic variation through the use of synonyms. Our findings contradict\nthe common assumption that LLMs achieve optimal performance on lower perplexity\nprompts that reflect language use in pretraining or instruction-tuning data.\nPrompts transfer poorly between datasets or models, and performance cannot\ngenerally be explained by perplexity, word frequency, ambiguity or prompt\nlength. Based on our results, we put forward a proposal for a more robust and\ncomprehensive evaluation standard for prompting research.",
          "link": "http://arxiv.org/abs/2311.01967",
          "publishedOn": "2023-11-07T00:44:10.013Z",
          "wordCount": 693,
          "title": "The language of prompting: What linguistic properties make a prompt successful?. (arXiv:2311.01967v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1\">Mingze Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_P/0/1/0/all/0/1\">Peng Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jiajia Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yunhao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zifan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jie Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bin Dong</a>",
          "description": "With the rapid development of artificial intelligence, large language models\n(LLMs) have shown promising capabilities in mimicking human-level language\ncomprehension and reasoning. This has sparked significant interest in applying\nLLMs to enhance various aspects of healthcare, ranging from medical education\nto clinical decision support. However, medicine involves multifaceted data\nmodalities and nuanced reasoning skills, presenting challenges for integrating\nLLMs. This paper provides a comprehensive review on the applications and\nimplications of LLMs in medicine. It begins by examining the fundamental\napplications of general-purpose and specialized LLMs, demonstrating their\nutilities in knowledge retrieval, research support, clinical workflow\nautomation, and diagnostic assistance. Recognizing the inherent multimodality\nof medicine, the review then focuses on multimodal LLMs, investigating their\nability to process diverse data types like medical imaging and EHRs to augment\ndiagnostic accuracy. To address LLMs' limitations regarding personalization and\ncomplex clinical reasoning, the paper explores the emerging development of\nLLM-powered autonomous agents for healthcare. Furthermore, it summarizes the\nevaluation methodologies for assessing LLMs' reliability and safety in medical\ncontexts. Overall, this review offers an extensive analysis on the\ntransformative potential of LLMs in modern medicine. It also highlights the\npivotal need for continuous optimizations and ethical oversight before these\nmodels can be effectively integrated into clinical practice. Visit\nhttps://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanying\nGitHub repository containing latest papers.",
          "link": "http://arxiv.org/abs/2311.01918",
          "publishedOn": "2023-11-07T00:44:09.987Z",
          "wordCount": 763,
          "title": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review. (arXiv:2311.01918v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01900",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Concha_A/0/1/0/all/0/1\">Alejandro de la Concha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vayatis_N/0/1/0/all/0/1\">Nicolas Vayatis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kalogeratos_A/0/1/0/all/0/1\">Argyris Kalogeratos</a>",
          "description": "Quantifying the difference between two probability density functions, $p$ and\n$q$, using available data, is a fundamental problem in Statistics and Machine\nLearning. A usual approach for addressing this problem is the likelihood-ratio\nestimation (LRE) between $p$ and $q$, which -- to our best knowledge -- has\nbeen investigated mainly for the offline case. This paper contributes by\nintroducing a new framework for online non-parametric LRE (OLRE) for the\nsetting where pairs of iid observations $(x_t \\sim p, x'_t \\sim q)$ are\nobserved over time. The non-parametric nature of our approach has the advantage\nof being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on the\nrecent advances in Kernel Methods and functional minimization to develop an\nestimator that can be efficiently updated online. We provide theoretical\nguarantees for the performance of the OLRE method along with empirical\nvalidation in synthetic experiments.",
          "link": "http://arxiv.org/abs/2311.01900",
          "publishedOn": "2023-11-07T00:44:09.948Z",
          "wordCount": 652,
          "title": "Online non-parametric likelihood-ratio estimation by Pearson-divergence functional minimization. (arXiv:2311.01900v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.20258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seunghun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_J/0/1/0/all/0/1\">Jaewon Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sihyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1\">Juyeon Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo J. Kim</a>",
          "description": "Bayesian optimization is a powerful method for optimizing black-box functions\nwith limited function evaluations. Recent works have shown that optimization in\na latent space through deep generative models such as variational autoencoders\nleads to effective and efficient Bayesian optimization for structured or\ndiscrete data. However, as the optimization does not take place in the input\nspace, it leads to an inherent gap that results in potentially suboptimal\nsolutions. To alleviate the discrepancy, we propose Correlated latent space\nBayesian Optimization (CoBO), which focuses on learning correlated latent\nspaces characterized by a strong correlation between the distances in the\nlatent space and the distances within the objective function. Specifically, our\nmethod introduces Lipschitz regularization, loss weighting, and trust region\nrecoordination to minimize the inherent gap around the promising areas. We\ndemonstrate the effectiveness of our approach on several optimization tasks in\ndiscrete data, such as molecule design and arithmetic expression fitting, and\nachieve high performance within a small budget.",
          "link": "http://arxiv.org/abs/2310.20258",
          "publishedOn": "2023-11-07T00:44:09.933Z",
          "wordCount": null,
          "title": "Advancing Bayesian Optimization via Learning Correlated Latent Space. (arXiv:2310.20258v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Soselia_D/0/1/0/all/0/1\">Davit Soselia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saifullah_K/0/1/0/all/0/1\">Khalid Saifullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>",
          "description": "Automated reverse engineering of HTML/CSS code from UI screenshots is an\nimportant yet challenging problem with broad applications in website\ndevelopment and design. In this paper, we propose a novel vision-code\ntransformer (ViCT) composed of a vision encoder processing the screenshots and\na language decoder to generate the code. They are initialized by pre-trained\nmodels such as ViT/DiT and GPT-2/LLaMA but aligning the two modalities requires\nend-to-end finetuning, which aims to minimize the visual discrepancy between\nthe code-rendered webpage and the original screenshot. However, the rendering\nis non-differentiable and causes costly overhead. We address this problem by\nactor-critic fine-tuning where a visual critic without rendering (ViCR) is\ndeveloped to predict visual discrepancy given the original and generated code.\nTo train and evaluate our models, we created two synthetic datasets of varying\ncomplexity, with over 75,000 unique (code, screenshot) pairs. We evaluate the\nUI-to-Code performance using a combination of automated metrics such as MSE,\nBLEU, IoU, and a novel htmlBLEU score. ViCT outperforms a strong baseline model\nDiT-GPT2, improving IoU from 0.64 to 0.79 and lowering MSE from 12.25 to 9.02.\nWith much lower computational cost, it can achieve comparable performance as\nwhen using a larger decoder such as LLaMA.",
          "link": "http://arxiv.org/abs/2305.14637",
          "publishedOn": "2023-11-07T00:44:09.932Z",
          "wordCount": 724,
          "title": "Learning UI-to-Code Reverse Generator Using Visual Critic Without Rendering. (arXiv:2305.14637v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.20380",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhengpeng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Changdong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_W/0/1/0/all/0/1\">Weizheng Qiao</a>",
          "description": "Policy-based reinforcement learning algorithms are widely used in various\nfields. Among them, mainstream policy optimization algorithms such as TRPO and\nPPO introduce importance sampling into policy iteration, which allows the reuse\nof historical data. However, this can also lead to a high variance of the\nsurrogate objective and indirectly affects the stability and convergence of the\nalgorithm. In this paper, we first derived an upper bound of the surrogate\nobjective variance, which can grow quadratically with the increase of the\nsurrogate objective. Next, we proposed the dropout technique to avoid the\nexcessive increase of the surrogate objective variance caused by importance\nsampling. Then, we introduced a general reinforcement learning framework\napplicable to mainstream policy optimization methods, and applied the dropout\ntechnique to the PPO algorithm to obtain the D-PPO variant. Finally, we conduct\ncomparative experiments between D-PPO and PPO algorithms in the Atari 2600\nenvironment, and the results show that D-PPO achieved significant performance\nimprovements compared to PPO, and effectively limited the excessive increase of\nthe surrogate objective variance during training.",
          "link": "http://arxiv.org/abs/2310.20380",
          "publishedOn": "2023-11-07T00:44:09.932Z",
          "wordCount": null,
          "title": "Dropout Strategy in Reinforcement Learning: Limiting the Surrogate Objective Variance in Policy Optimization Methods. (arXiv:2310.20380v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.20550",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qiying Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Quan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaosong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yufeng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yue Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinlong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>",
          "description": "Large multimodal models demonstrate remarkable generalist ability to perform\ndiverse multimodal tasks in a zero-shot manner. Large-scale web-based\nimage-text pairs contribute fundamentally to this success, but suffer from\nexcessive noise. Recent studies use alternative captions synthesized by\ncaptioning models and have achieved notable benchmark performance. However, our\nexperiments reveal significant Scalability Deficiency and World Knowledge Loss\nissues in models trained with synthetic captions, which have been largely\nobscured by their initial benchmark success. Upon closer examination, we\nidentify the root cause as the overly-simplified language structure and lack of\nknowledge details in existing synthetic captions. To provide higher-quality and\nmore scalable multimodal pretraining data, we propose CapsFusion, an advanced\nframework that leverages large language models to consolidate and refine\ninformation from both web-based image-text pairs and synthetic captions.\nExtensive experiments show that CapsFusion captions exhibit remarkable\nall-round superiority over existing captions in terms of model performance\n(e.g., 18.8 and 18.3 improvements in CIDEr score on COCO and NoCaps), sample\nefficiency (requiring 11-16 times less computation than baselines), world\nknowledge depth, and scalability. These effectiveness, efficiency and\nscalability advantages position CapsFusion as a promising candidate for future\nscaling of LMM training.",
          "link": "http://arxiv.org/abs/2310.20550",
          "publishedOn": "2023-11-07T00:44:09.916Z",
          "wordCount": null,
          "title": "CapsFusion: Rethinking Image-Text Data at Scale. (arXiv:2310.20550v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00060",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Leon_V/0/1/0/all/0/1\">Victor J. Leon</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ford_N/0/1/0/all/0/1\">Noah Ford</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mrema_H/0/1/0/all/0/1\">Honest Mrema</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gilbert_J/0/1/0/all/0/1\">Jeffrey Gilbert</a>, <a href=\"http://arxiv.org/find/physics/1/au:+New_A/0/1/0/all/0/1\">Alexander New</a>",
          "description": "High-fidelity computational simulations and physical experiments of\nhypersonic flows are resource intensive. Training scientific machine learning\n(SciML) models on limited high-fidelity data offers one approach to rapidly\npredict behaviors for situations that have not been seen before. However,\nhigh-fidelity data is itself in limited quantity to validate all outputs of the\nSciML model in unexplored input space. As such, an uncertainty-aware SciML\nmodel is desired. The SciML model's output uncertainties could then be used to\nassess the reliability and confidence of the model's predictions. In this\nstudy, we extend a DeepONet using three different uncertainty quantification\nmechanisms: mean-variance estimation, evidential uncertainty, and ensembling.\nThe uncertainty aware DeepONet models are trained and evaluated on the\nhypersonic flow around a blunt cone object with data generated via\ncomputational fluid dynamics over a wide range of Mach numbers and altitudes.\nWe find that ensembling outperforms the other two uncertainty models in terms\nof minimizing error and calibrating uncertainty in both interpolative and\nextrapolative regimes.",
          "link": "http://arxiv.org/abs/2311.00060",
          "publishedOn": "2023-11-07T00:44:09.916Z",
          "wordCount": null,
          "title": "Ensemble models outperform single model uncertainties and predictions for operator-learning of hypersonic flows. (arXiv:2311.00060v2 [physics.flu-dyn] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tiboni_G/0/1/0/all/0/1\">Gabriele Tiboni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klink_P/0/1/0/all/0/1\">Pascal Klink</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jan Peters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tommasi_T/0/1/0/all/0/1\">Tatiana Tommasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DEramo_C/0/1/0/all/0/1\">Carlo D&#x27;Eramo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalvatzaki_G/0/1/0/all/0/1\">Georgia Chalvatzaki</a>",
          "description": "Varying dynamics parameters in simulation is a popular Domain Randomization\n(DR) approach for overcoming the reality gap in Reinforcement Learning (RL).\nNevertheless, DR heavily hinges on the choice of the sampling distribution of\nthe dynamics parameters, since high variability is crucial to regularize the\nagent's behavior but notoriously leads to overly conservative policies when\nrandomizing excessively. In this paper, we propose a novel approach to address\nsim-to-real transfer, which automatically shapes dynamics distributions during\ntraining in simulation without requiring real-world data. We introduce DOmain\nRAndomization via Entropy MaximizatiON (DORAEMON), a constrained optimization\nproblem that directly maximizes the entropy of the training distribution while\nretaining generalization capabilities. In achieving this, DORAEMON gradually\nincreases the diversity of sampled dynamics parameters as long as the\nprobability of success of the current policy is sufficiently high. We\nempirically validate the consistent benefits of DORAEMON in obtaining highly\nadaptive and generalizable policies, i.e. solving the task at hand across the\nwidest range of dynamics parameters, as opposed to representative baselines\nfrom the DR literature. Notably, we also demonstrate the Sim2Real applicability\nof DORAEMON through its successful zero-shot transfer in a robotic manipulation\nsetup under unknown real-world parameters.",
          "link": "http://arxiv.org/abs/2311.01885",
          "publishedOn": "2023-11-07T00:44:09.885Z",
          "wordCount": 697,
          "title": "Domain Randomization via Entropy Maximization. (arXiv:2311.01885v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hinton_G/0/1/0/all/0/1\">Geoffrey Hinton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1\">Andrew Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harari_Y/0/1/0/all/0/1\">Yuval Noah Harari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ya-Qin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1\">Lan Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalev_Shwartz_S/0/1/0/all/0/1\">Shai Shalev-Shwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadfield_G/0/1/0/all/0/1\">Gillian Hadfield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1\">Jeff Clune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maharaj_T/0/1/0/all/0/1\">Tegan Maharaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baydin_A/0/1/0/all/0/1\">At&#x131;l&#x131;m G&#xfc;ne&#x15f; Baydin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McIlraith_S/0/1/0/all/0/1\">Sheila McIlraith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1\">Ashwin Acharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krueger_D/0/1/0/all/0/1\">David Krueger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca Dragan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1\">Stuart Russell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahneman_D/0/1/0/all/0/1\">Daniel Kahneman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brauner_J/0/1/0/all/0/1\">Jan Brauner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mindermann_S/0/1/0/all/0/1\">S&#xf6;ren Mindermann</a>",
          "description": "In this short consensus paper, we outline risks from upcoming, advanced AI\nsystems. We examine large-scale social harms and malicious uses, as well as an\nirreversible loss of human control over autonomous AI systems. In light of\nrapid and continuing AI progress, we propose priorities for AI R&D and\ngovernance.",
          "link": "http://arxiv.org/abs/2310.17688",
          "publishedOn": "2023-11-07T00:44:09.860Z",
          "wordCount": null,
          "title": "Managing AI Risks in an Era of Rapid Progress. (arXiv:2310.17688v1 [cs.CY] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ni_T/0/1/0/all/0/1\">Tianwei Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Michel Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1\">Benjamin Eysenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacon_P/0/1/0/all/0/1\">Pierre-Luc Bacon</a>",
          "description": "Reinforcement learning (RL) algorithms face two distinct challenges: learning\neffective representations of past and present observations, and determining how\nactions influence future returns. Both challenges involve modeling long-term\ndependencies. The Transformer architecture has been very successful to solve\nproblems that involve long-term dependencies, including in the RL domain.\nHowever, the underlying reason for the strong performance of Transformer-based\nRL methods remains unclear: is it because they learn effective memory, or\nbecause they perform effective credit assignment? After introducing formal\ndefinitions of memory length and credit assignment length, we design simple\nconfigurable tasks to measure these distinct quantities. Our empirical results\nreveal that Transformers can enhance the memory capability of RL algorithms,\nscaling up to tasks that require memorizing observations $1500$ steps ago.\nHowever, Transformers do not improve long-term credit assignment. In summary,\nour results provide an explanation for the success of Transformers in RL, while\nalso highlighting an important area for future research and benchmark design.\nOur code is open-sourced at https://github.com/twni2016/Memory-RL",
          "link": "http://arxiv.org/abs/2307.03864",
          "publishedOn": "2023-11-07T00:44:09.206Z",
          "wordCount": 717,
          "title": "When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment. (arXiv:2307.03864v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.02345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lv_O/0/1/0/all/0/1\">Outongyi Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bingxin Zhou</a>",
          "description": "Modern reinforcement learning (RL) can be categorized into online and offline\nvariants. As a pivotal aspect of both online and offline RL, current research\non the Bellman equation revolves primarily around optimization techniques and\nperformance enhancement rather than exploring the inherent structural\nproperties of the Bellman error, such as its distribution characteristics. This\nstudy investigates the distribution of the Bellman approximation error in both\nonline and offline settings through iterative exploration of the Bellman\nequation. We observed that both in online RL and offline RL, the Bellman error\nconforms to a Logistic distribution. Building upon this discovery, this study\nemployed the Logistics maximum likelihood function (LLoss) as an alternative to\nthe commonly used MSE Loss, assuming that Bellman errors adhere to a normal\ndistribution. We validated our hypotheses through extensive numerical\nexperiments across diverse online and offline environments. In particular, we\napplied corrections to the loss function across various baseline algorithms and\nconsistently observed that the loss function with Logistic corrections\noutperformed the MSE counterpart significantly. Additionally, we conducted\nKolmogorov-Smirnov tests to confirm the reliability of the Logistic\ndistribution. This study's theoretical and empirical insights provide valuable\ngroundwork for future investigations and enhancements centered on the\ndistribution of Bellman errors.",
          "link": "http://arxiv.org/abs/2307.02345",
          "publishedOn": "2023-11-07T00:44:09.199Z",
          "wordCount": 722,
          "title": "LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning. (arXiv:2307.02345v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.18144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castanyer_R/0/1/0/all/0/1\">Roger Creus Castanyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romoff_J/0/1/0/all/0/1\">Joshua Romoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berseth_G/0/1/0/all/0/1\">Glen Berseth</a>",
          "description": "Exploration bonuses in reinforcement learning guide long-horizon exploration\nby defining custom intrinsic objectives. Count-based methods use the frequency\nof state visits to derive an exploration bonus. In this paper, we identify that\nany intrinsic reward function derived from count-based methods is\nnon-stationary and hence induces a difficult objective to optimize for the\nagent. The key contribution of our work lies in transforming the original\nnon-stationary rewards into stationary rewards through an augmented state\nrepresentation. For this purpose, we introduce the Stationary Objectives For\nExploration (SOFE) framework. SOFE requires identifying sufficient statistics\nfor different exploration bonuses and finding an efficient encoding of these\nstatistics to use as input to a deep network. SOFE is based on proposing state\naugmentations that expand the state space but hold the promise of simplifying\nthe optimization of the agent's objective. Our experiments show that SOFE\nimproves the agents' performance in challenging exploration problems, including\nsparse-reward tasks, pixel-based observations, 3D navigation, and procedurally\ngenerated environments.",
          "link": "http://arxiv.org/abs/2310.18144",
          "publishedOn": "2023-11-07T00:44:08.582Z",
          "wordCount": 680,
          "title": "Improving Intrinsic Exploration by Creating Stationary Objectives. (arXiv:2310.18144v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsai_J/0/1/0/all/0/1\">Jui-Yi Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1\">Ya-Wen Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yew_H/0/1/0/all/0/1\">Ho Chiok Yew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">De-Nian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lydia Y. Chen</a>",
          "description": "The social graphs synthesized by the generative models are increasingly in\ndemand due to data scarcity and concerns over user privacy. One of the key\nperformance criteria for generating social networks is the fidelity to\nspecified conditionals, such as users with certain membership and financial\nstatus. While recent diffusion models have shown remarkable performance in\ngenerating images, their effectiveness in synthesizing graphs has not yet been\nexplored in the context of conditional social graphs. In this paper, we propose\nthe first kind of conditional diffusion model for social networks, CDGraph,\nwhich trains and synthesizes graphs based on two specified conditions. We\npropose the co-evolution dependency in the denoising process of CDGraph to\ncapture the mutual dependencies between the dual conditions and further\nincorporate social homophily and social contagion to preserve the connectivity\nbetween nodes while satisfying the specified conditions. Moreover, we introduce\na novel classifier loss, which guides the training of the diffusion process\nthrough the mutual dependency of dual conditions. We evaluate CDGraph against\nfour existing graph generative methods, i.e., SPECTRE, GSM, EDGE, and DiGress,\non four datasets. Our results show that the generated graphs from CDGraph\nachieve much higher dual-conditional validity and lower discrepancy in various\nsocial network metrics than the baselines, thus demonstrating its proficiency\nin generating dual-conditional social graphs.",
          "link": "http://arxiv.org/abs/2311.01729",
          "publishedOn": "2023-11-07T00:44:08.472Z",
          "wordCount": 724,
          "title": "CDGraph: Dual Conditional Social Graph Synthesizing via Diffusion Model. (arXiv:2311.01729v1 [cs.SI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.10763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_L/0/1/0/all/0/1\">Lakshya A Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanade_A/0/1/0/all/0/1\">Aditya Kanade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1\">Navin Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahiri_S/0/1/0/all/0/1\">Shuvendu K. Lahiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajamani_S/0/1/0/all/0/1\">Sriram K. Rajamani</a>",
          "description": "Language models of code (LMs) work well when the surrounding code provides\nsufficient context. This is not true when it becomes necessary to use types,\nfunctionality or APIs defined elsewhere in the repository or a linked library,\nespecially those not seen during training. LMs suffer from limited awareness of\nsuch global context and end up hallucinating.\n\nIntegrated development environments (IDEs) assist developers in understanding\nrepository context using static analysis. We extend this assistance, enjoyed by\ndevelopers, to LMs. We propose monitor-guided decoding (MGD) where a monitor\nuses static analysis to guide the decoding. We construct a repository-level\ndataset PragmaticCode for method-completion in Java and evaluate MGD on it. On\nmodels of varying parameter scale, by monitoring for type-consistent object\ndereferences, MGD consistently improves compilation rates and agreement with\nground truth. Further, LMs with fewer parameters, when augmented with MGD, can\noutperform larger LMs. With MGD, SantaCoder-1.1B achieves better compilation\nrate and next-identifier match than the much larger text-davinci-003 model.\n\nWe also conduct a generalizability study to evaluate the ability of MGD to\ngeneralize to multiple programming languages (Java, C# and Rust), coding\nscenarios (e.g., correct number of arguments to method calls), and to enforce\nricher semantic constraints (e.g., stateful API protocols). Our data and\nimplementation are available at https://github.com/microsoft/monitors4codegen .",
          "link": "http://arxiv.org/abs/2306.10763",
          "publishedOn": "2023-11-07T00:44:08.428Z",
          "wordCount": 801,
          "title": "Guiding Language Models of Code with Global Context using Monitors. (arXiv:2306.10763v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.05812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shumaylov_Z/0/1/0/all/0/1\">Zakhar Shumaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budd_J/0/1/0/all/0/1\">Jeremy Budd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhadip Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola-Bibiane Sch&#xf6;nlieb</a>",
          "description": "An emerging new paradigm for solving inverse problems is via the use of deep\nlearning to learn a regularizer from data. This leads to high-quality results,\nbut often at the cost of provable guarantees. In this work, we show how\nwell-posedness and convergent regularization arises within the convex-nonconvex\n(CNC) framework for inverse problems. We introduce a novel input weakly convex\nneural network (IWCNN) construction to adapt the method of learned adversarial\nregularization to the CNC framework. Empirically we show that our method\novercomes numerical issues of previous adversarial methods.",
          "link": "http://arxiv.org/abs/2310.05812",
          "publishedOn": "2023-11-07T00:44:08.418Z",
          "wordCount": 622,
          "title": "Provably Convergent Data-Driven Convex-Nonconvex Regularization. (arXiv:2310.05812v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.00180",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruochu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lembke_C/0/1/0/all/0/1\">Chad Lembke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fumin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edwards_C/0/1/0/all/0/1\">Catherine Edwards</a>",
          "description": "Underwater gliders have been widely used in oceanography for a range of\napplications. However, unpredictable events like shark strikes or remora\nattachments can lead to abnormal glider behavior or even loss of the\ninstrument. This paper employs an anomaly detection algorithm to assess\noperational conditions of underwater gliders in the real-world ocean\nenvironment. Prompt alerts are provided to glider pilots upon detecting any\nanomaly, so that they can take control of the glider to prevent further harm.\nThe detection algorithm is applied to multiple datasets collected in real\nglider deployments led by the University of Georgia's Skidaway Institute of\nOceanography (SkIO) and the University of South Florida (USF). In order to\ndemonstrate the algorithm generality, the experimental evaluation is applied to\nfour glider deployment datasets, each highlighting various anomalies happening\nin different scenes. Specifically, we utilize high resolution datasets only\navailable post-recovery to perform detailed analysis of the anomaly and compare\nit with pilot logs. Additionally, we simulate the online detection based on the\nreal-time subsets of data transmitted from the glider at the surfacing events.\nWhile the real-time data may not contain as much rich information as the\npost-recovery one, the online detection is of great importance as it allows\nglider pilots to monitor potential abnormal conditions in real time.",
          "link": "http://arxiv.org/abs/2308.00180",
          "publishedOn": "2023-11-07T00:44:08.409Z",
          "wordCount": 753,
          "title": "General Anomaly Detection of Underwater Gliders Validated by Large-scale Deployment Datasets. (arXiv:2308.00180v3 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.02899",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jiang_Y/0/1/0/all/0/1\">Yibo Jiang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aragam_B/0/1/0/all/0/1\">Bryon Aragam</a>",
          "description": "We establish conditions under which latent causal graphs are\nnonparametrically identifiable and can be reconstructed from unknown\ninterventions in the latent space. Our primary focus is the identification of\nthe latent structure in measurement models without parametric assumptions such\nas linearity or Gaussianity. Moreover, we do not assume the number of hidden\nvariables is known, and we show that at most one unknown intervention per\nhidden variable is needed. This extends a recent line of work on learning\ncausal representations from observations and interventions. The proofs are\nconstructive and introduce two new graphical concepts -- imaginary subsets and\nisolated edges -- that may be useful in their own right. As a matter of\nindependent interest, the proofs also involve a novel characterization of the\nlimits of edge orientations within the equivalence class of DAGs induced by\nunknown interventions. These are the first results to characterize the\nconditions under which causal representations are identifiable without making\nany parametric assumptions in a general setting with unknown interventions and\nwithout faithfulness.",
          "link": "http://arxiv.org/abs/2306.02899",
          "publishedOn": "2023-11-07T00:44:08.392Z",
          "wordCount": 687,
          "title": "Learning nonparametric latent causal graphs with unknown interventions. (arXiv:2306.02899v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.02017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mehra_A/0/1/0/all/0/1\">Ashman Mehra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Snehanshu Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raychoudhury_V/0/1/0/all/0/1\">Vaskar Raychoudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathur_A/0/1/0/all/0/1\">Archana Mathur</a>",
          "description": "Delivery of items from the producer to the consumer has experienced\nsignificant growth over the past decade and has been greatly fueled by the\nrecent pandemic. Amazon Fresh, Shopify, UberEats, InstaCart, and DoorDash are\nrapidly growing and are sharing the same business model of consumer items or\nfood delivery. Existing food delivery methods are sub-optimal because each\ndelivery is individually optimized to go directly from the producer to the\nconsumer via the shortest time path. We observe a significant scope for\nreducing the costs associated with completing deliveries under the current\nmodel. We model our food delivery problem as a multi-objective optimization,\nwhere consumer satisfaction and delivery costs, both, need to be optimized.\nTaking inspiration from the success of ride-sharing in the taxi industry, we\npropose DeliverAI - a reinforcement learning-based path-sharing algorithm.\nUnlike previous attempts for path-sharing, DeliverAI can provide real-time,\ntime-efficient decision-making using a Reinforcement learning-enabled agent\nsystem. Our novel agent interaction scheme leverages path-sharing among\ndeliveries to reduce the total distance traveled while keeping the delivery\ncompletion time under check. We generate and test our methodology vigorously on\na simulation setup using real data from the city of Chicago. Our results show\nthat DeliverAI can reduce the delivery fleet size by 12\\%, the distance\ntraveled by 13%, and achieve 50% higher fleet utilization compared to the\nbaselines.",
          "link": "http://arxiv.org/abs/2311.02017",
          "publishedOn": "2023-11-07T00:44:08.224Z",
          "wordCount": null,
          "title": "DeliverAI: Reinforcement Learning Based Distributed Path-Sharing Network for Food Deliveries. (arXiv:2311.02017v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pengfei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tongxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1\">Adam Wierman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shaolei Ren</a>",
          "description": "This paper studies the problem of Anytime-Competitive Markov Decision Process\n(A-CMDP). Existing works on Constrained Markov Decision Processes (CMDPs) aim\nto optimize the expected reward while constraining the expected cost over\nrandom dynamics, but the cost in a specific episode can still be\nunsatisfactorily high. In contrast, the goal of A-CMDP is to optimize the\nexpected reward while guaranteeing a bounded cost in each round of any episode\nagainst a policy prior. We propose a new algorithm, called Anytime-Competitive\nReinforcement Learning (ACRL), which provably guarantees the anytime cost\nconstraints. The regret analysis shows the policy asymptotically matches the\noptimal reward achievable under the anytime competitive constraints.\nExperiments on the application of carbon-intelligent computing verify the\nreward performance and cost constraint guarantee of ACRL.",
          "link": "http://arxiv.org/abs/2311.01568",
          "publishedOn": "2023-11-07T00:44:08.223Z",
          "wordCount": null,
          "title": "Anytime-Competitive Reinforcement Learning with Policy Prior. (arXiv:2311.01568v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.07738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Budd_J/0/1/0/all/0/1\">Jobie Budd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baker_K/0/1/0/all/0/1\">Kieran Baker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karoune_E/0/1/0/all/0/1\">Emma Karoune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coppock_H/0/1/0/all/0/1\">Harry Coppock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1\">Selina Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canadas_A/0/1/0/all/0/1\">Ana Tendero Ca&#xf1;adas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Titcomb_A/0/1/0/all/0/1\">Alexander Titcomb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Payne_R/0/1/0/all/0/1\">Richard Payne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hurley_D/0/1/0/all/0/1\">David Hurley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Egglestone_S/0/1/0/all/0/1\">Sabrina Egglestone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Butler_L/0/1/0/all/0/1\">Lorraine Butler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mellor_J/0/1/0/all/0/1\">Jonathon Mellor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nicholson_G/0/1/0/all/0/1\">George Nicholson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiskin_I/0/1/0/all/0/1\">Ivan Kiskin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koutra_V/0/1/0/all/0/1\">Vasiliki Koutra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jersakova_R/0/1/0/all/0/1\">Radka Jersakova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKendry_R/0/1/0/all/0/1\">Rachel A. McKendry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diggle_P/0/1/0/all/0/1\">Peter Diggle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richardson_S/0/1/0/all/0/1\">Sylvia Richardson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1\">Bj&#xf6;rn W. Schuller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilmour_S/0/1/0/all/0/1\">Steven Gilmour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pigoli_D/0/1/0/all/0/1\">Davide Pigoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Packham_J/0/1/0/all/0/1\">Josef Packham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thornley_T/0/1/0/all/0/1\">Tracey Thornley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmes_C/0/1/0/all/0/1\">Chris Holmes</a>",
          "description": "The UK COVID-19 Vocal Audio Dataset is designed for the training and\nevaluation of machine learning models that classify SARS-CoV-2 infection status\nor associated respiratory symptoms using vocal audio. The UK Health Security\nAgency recruited voluntary participants through the national Test and Trace\nprogramme and the REACT-1 survey in England from March 2021 to March 2022,\nduring dominant transmission of the Alpha and Delta SARS-CoV-2 variants and\nsome Omicron variant sublineages. Audio recordings of volitional coughs,\nexhalations, and speech were collected in the 'Speak up to help beat\ncoronavirus' digital survey alongside demographic, self-reported symptom and\nrespiratory condition data, and linked to SARS-CoV-2 test results. The UK\nCOVID-19 Vocal Audio Dataset represents the largest collection of SARS-CoV-2\nPCR-referenced audio recordings to date. PCR results were linked to 70,794 of\n72,999 participants and 24,155 of 25,776 positive cases. Respiratory symptoms\nwere reported by 45.62% of participants. This dataset has additional potential\nuses for bioacoustics research, with 11.30% participants reporting asthma, and\n27.20% with linked influenza PCR test results.",
          "link": "http://arxiv.org/abs/2212.07738",
          "publishedOn": "2023-11-07T00:44:08.223Z",
          "wordCount": null,
          "title": "A large-scale and PCR-referenced vocal audio dataset for COVID-19. (arXiv:2212.07738v4 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DInca_M/0/1/0/all/0/1\">Moreno D&#x27;Inc&#xe0;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzelepis_C/0/1/0/all/0/1\">Christos Tzelepis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patras_I/0/1/0/all/0/1\">Ioannis Patras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1\">Nicu Sebe</a>",
          "description": "Fairness is crucial when training a deep-learning discriminative model,\nespecially in the facial domain. Models tend to correlate specific\ncharacteristics (such as age and skin color) with unrelated attributes\n(downstream tasks), resulting in biases which do not correspond to reality. It\nis common knowledge that these correlations are present in the data and are\nthen transferred to the models during training. This paper proposes a method to\nmitigate these correlations to improve fairness. To do so, we learn\ninterpretable and meaningful paths lying in the semantic space of a pre-trained\ndiffusion model (DiffAE) -- such paths being supervised by contrastive text\ndipoles. That is, we learn to edit protected characteristics (age and skin\ncolor). These paths are then applied to augment images to improve the fairness\nof a given dataset. We test the proposed method on CelebA-HQ and UTKFace on\nseveral downstream tasks with age and skin color as protected characteristics.\nAs a proxy for fairness, we compute the difference in accuracy with respect to\nthe protected characteristics. Quantitative results show how the augmented\nimages help the model improve the overall accuracy, the aforementioned metric,\nand the disparity of equal opportunity. Code is available at:\nhttps://github.com/Moreno98/Vision-Language-Bias-Control.",
          "link": "http://arxiv.org/abs/2311.01573",
          "publishedOn": "2023-11-07T00:44:08.222Z",
          "wordCount": null,
          "title": "Improving Fairness using Vision-Language Driven Image Augmentation. (arXiv:2311.01573v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.01264",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_H/0/1/0/all/0/1\">Haochuan Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Qian_J/0/1/0/all/0/1\">Jian Qian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tian_Y/0/1/0/all/0/1\">Yi Tian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rakhlin_A/0/1/0/all/0/1\">Alexander Rakhlin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jadbabaie_A/0/1/0/all/0/1\">Ali Jadbabaie</a>",
          "description": "Classical analysis of convex and non-convex optimization methods often\nrequires the Lipshitzness of the gradient, which limits the analysis to\nfunctions bounded by quadratics. Recent work relaxed this requirement to a\nnon-uniform smoothness condition with the Hessian norm bounded by an affine\nfunction of the gradient norm, and proved convergence in the non-convex setting\nvia gradient clipping, assuming bounded noise. In this paper, we further\ngeneralize this non-uniform smoothness condition and develop a simple, yet\npowerful analysis technique that bounds the gradients along the trajectory,\nthereby leading to stronger results for both convex and non-convex optimization\nproblems. In particular, we obtain the classical convergence rates for\n(stochastic) gradient descent and Nesterov's accelerated gradient method in the\nconvex and/or non-convex setting under this general smoothness condition. The\nnew analysis approach does not require gradient clipping and allows\nheavy-tailed noise with bounded variance in the stochastic setting.",
          "link": "http://arxiv.org/abs/2306.01264",
          "publishedOn": "2023-11-07T00:44:08.222Z",
          "wordCount": null,
          "title": "Convex and Non-convex Optimization Under Generalized Smoothness. (arXiv:2306.01264v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.02618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Devunuri_S/0/1/0/all/0/1\">Saipraneeth Devunuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiam_S/0/1/0/all/0/1\">Shirin Qiam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehe_L/0/1/0/all/0/1\">Lewis Lehe</a>",
          "description": "The General Transit Feed Specification (GTFS) standard for publishing transit\ndata is ubiquitous. GTFS being tabular data, with information spread across\ndifferent files, necessitates specialized tools or packages to retrieve\ninformation. Concurrently, the use of Large Language Models(LLMs) for text and\ninformation retrieval is growing. The idea of this research is to see if the\ncurrent widely adopted LLMs (ChatGPT) are able to understand GTFS and retrieve\ninformation from GTFS using natural language instructions without explicitly\nproviding information. In this research, we benchmark OpenAI's GPT-3.5-Turbo\nand GPT-4 LLMs which are the backbone of ChatGPT. ChatGPT demonstrates a\nreasonable understanding of GTFS by answering 59.7% (GPT-3.5-Turbo) and 73.3%\n(GPT-4) of our multiple-choice questions (MCQ) correctly. Furthermore, we\nevaluated the LLMs on information extraction tasks using a filtered GTFS feed\ncontaining four routes. We found that program synthesis techniques outperformed\nzero-shot approaches, achieving up to 93% (90%) accuracy for simple queries and\n61% (41%) for complex ones using GPT-4 (GPT-3.5-Turbo).",
          "link": "http://arxiv.org/abs/2308.02618",
          "publishedOn": "2023-11-07T00:44:08.222Z",
          "wordCount": null,
          "title": "ChatGPT for GTFS: Benchmarking LLMs on GTFS Understanding and Retrieval. (arXiv:2308.02618v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.14082",
          "author": "<a href=\"http://arxiv.org/find/hep-lat/1/au:+Nicoli_K/0/1/0/all/0/1\">Kim A. Nicoli</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Anders_C/0/1/0/all/0/1\">Christopher J. Anders</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Hartung_T/0/1/0/all/0/1\">Tobias Hartung</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Jansen_K/0/1/0/all/0/1\">Karl Jansen</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Kessel_P/0/1/0/all/0/1\">Pan Kessel</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Nakajima_S/0/1/0/all/0/1\">Shinichi Nakajima</a>",
          "description": "We study the consequences of mode-collapse of normalizing flows in the\ncontext of lattice field theory. Normalizing flows allow for independent\nsampling. For this reason, it is hoped that they can avoid the tunneling\nproblem of local-update MCMC algorithms for multi-modal distributions. In this\nwork, we first point out that the tunneling problem is also present for\nnormalizing flows but is shifted from the sampling to the training phase of the\nalgorithm. Specifically, normalizing flows often suffer from mode-collapse for\nwhich the training process assigns vanishingly low probability mass to relevant\nmodes of the physical distribution. This may result in a significant bias when\nthe flow is used as a sampler in a Markov-Chain or with Importance Sampling. We\npropose a metric to quantify the degree of mode-collapse and derive a bound on\nthe resulting bias. Furthermore, we propose various mitigation strategies in\nparticular in the context of estimating thermodynamic observables, such as the\nfree energy.",
          "link": "http://arxiv.org/abs/2302.14082",
          "publishedOn": "2023-11-07T00:44:08.221Z",
          "wordCount": null,
          "title": "Detecting and Mitigating Mode-Collapse for Flow-based Sampling of Lattice Field Theories. (arXiv:2302.14082v2 [hep-lat] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.02108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_R/0/1/0/all/0/1\">Ruohan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1\">Emma Brunskill</a>",
          "description": "In many applications, e.g. in healthcare and e-commerce, the goal of a\ncontextual bandit may be to learn an optimal treatment assignment policy at the\nend of the experiment. That is, to minimize simple regret. However, this\nobjective remains understudied. We propose a new family of computationally\nefficient bandit algorithms for the stochastic contextual bandit setting, where\na tuning parameter determines the weight placed on cumulative regret\nminimization (where we establish near-optimal minimax guarantees) versus simple\nregret minimization (where we establish state-of-the-art guarantees). Our\nalgorithms work with any function class, are robust to model misspecification,\nand can be used in continuous arm settings. This flexibility comes from\nconstructing and relying on \"conformal arm sets\" (CASs). CASs provide a set of\narms for every context, encompassing the context-specific optimal arm with a\ncertain probability across the context distribution. Our positive results on\nsimple and cumulative regret guarantees are contrasted with a negative result,\nwhich shows that no algorithm can achieve instance-dependent simple regret\nguarantees while simultaneously achieving minimax optimal cumulative regret\nguarantees.",
          "link": "http://arxiv.org/abs/2307.02108",
          "publishedOn": "2023-11-07T00:44:08.221Z",
          "wordCount": null,
          "title": "Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization. (arXiv:2307.02108v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01968",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lee_D/0/1/0/all/0/1\">Daesoo Lee</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ovanger_O/0/1/0/all/0/1\">Oscar Ovanger</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Eidsvik_J/0/1/0/all/0/1\">Jo Eidsvik</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Aune_E/0/1/0/all/0/1\">Erlend Aune</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Skauvold_J/0/1/0/all/0/1\">Jacob Skauvold</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hauge_R/0/1/0/all/0/1\">Ragnar Hauge</a>",
          "description": "Creating accurate and geologically realistic reservoir facies based on\nlimited measurements is crucial for field development and reservoir management,\nespecially in the oil and gas sector. Traditional two-point geostatistics,\nwhile foundational, often struggle to capture complex geological patterns.\nMulti-point statistics offers more flexibility, but comes with its own\nchallenges. With the rise of Generative Adversarial Networks (GANs) and their\nsuccess in various fields, there has been a shift towards using them for facies\ngeneration. However, recent advances in the computer vision domain have shown\nthe superiority of diffusion models over GANs. Motivated by this, a novel\nLatent Diffusion Model is proposed, which is specifically designed for\nconditional generation of reservoir facies. The proposed model produces\nhigh-fidelity facies realizations that rigorously preserve conditioning data.\nIt significantly outperforms a GAN-based alternative.",
          "link": "http://arxiv.org/abs/2311.01968",
          "publishedOn": "2023-11-07T00:44:08.220Z",
          "wordCount": null,
          "title": "Latent Diffusion Model for Conditional Reservoir Facies Generation. (arXiv:2311.01968v1 [physics.geo-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pedramfar_M/0/1/0/all/0/1\">Mohammad Pedramfar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quinn_C/0/1/0/all/0/1\">Christopher John Quinn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1\">Vaneet Aggarwal</a>",
          "description": "This paper presents a unified approach for maximizing continuous\nDR-submodular functions that encompasses a range of settings and oracle access\ntypes. Our approach includes a Frank-Wolfe type offline algorithm for both\nmonotone and non-monotone functions, with different restrictions on the general\nconvex set. We consider settings where the oracle provides access to either the\ngradient of the function or only the function value, and where the oracle\naccess is either deterministic or stochastic. We determine the number of\nrequired oracle accesses in all cases. Our approach gives new/improved results\nfor nine out of the sixteen considered cases, avoids computationally expensive\nprojections in two cases, with the proposed framework matching performance of\nstate-of-the-art approaches in the remaining five cases. Notably, our approach\nfor the stochastic function value-based oracle enables the first regret bounds\nwith bandit feedback for stochastic DR-submodular functions.",
          "link": "http://arxiv.org/abs/2305.16671",
          "publishedOn": "2023-11-07T00:44:08.220Z",
          "wordCount": null,
          "title": "A Unified Approach for Maximizing Continuous DR-submodular Functions. (arXiv:2305.16671v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05374",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Srivallapanondh_S/0/1/0/all/0/1\">Sasipim Srivallapanondh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Freire_P/0/1/0/all/0/1\">Pedro J. Freire</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alam_A/0/1/0/all/0/1\">Ashraful Alam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Costa_N/0/1/0/all/0/1\">Nelson Costa</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Spinnler_B/0/1/0/all/0/1\">Bernhard Spinnler</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Napoli_A/0/1/0/all/0/1\">Antonio Napoli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sedov_E/0/1/0/all/0/1\">Egor Sedov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Turitsyn_S/0/1/0/all/0/1\">Sergei K. Turitsyn</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prilepsky_J/0/1/0/all/0/1\">Jaroslaw E. Prilepsky</a>",
          "description": "For the first time, multi-task learning is proposed to improve the\nflexibility of NN-based equalizers in coherent systems. A \"single\" NN-based\nequalizer improves Q-factor by up to 4 dB compared to CDC, without re-training,\neven with variations in launch power, symbol rate, or transmission distance.",
          "link": "http://arxiv.org/abs/2307.05374",
          "publishedOn": "2023-11-07T00:44:08.220Z",
          "wordCount": null,
          "title": "Multi-Task Learning to Enhance Generalizability of Neural Network Equalizers in Coherent Optical Systems. (arXiv:2307.05374v3 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01050",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nusken_N/0/1/0/all/0/1\">Nikolas N&#xfc;sken</a>",
          "description": "This paper explores the connections between optimal transport and variational\ninference, with a focus on forward and reverse time stochastic differential\nequations and Girsanov transformations.We present a principled and systematic\nframework for sampling and generative modelling centred around divergences on\npath space. Our work culminates in the development of a novel score-based\nannealed flow technique (with connections to Jarzynski and Crooks identities\nfrom statistical physics) and a regularised iterative proportional fitting\n(IPF)-type objective, departing from the sequential nature of standard IPF.\nThrough a series of generative modelling examples and a double-well-based rare\nevent task, we showcase the potential of the proposed methods.",
          "link": "http://arxiv.org/abs/2307.01050",
          "publishedOn": "2023-11-07T00:44:08.219Z",
          "wordCount": null,
          "title": "Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\\\"odinger Bridges. (arXiv:2307.01050v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04532",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chaudhry_H/0/1/0/all/0/1\">Hamza Tahir Chaudhry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zavatone_Veth_J/0/1/0/all/0/1\">Jacob A. Zavatone-Veth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krotov_D/0/1/0/all/0/1\">Dmitry Krotov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "Sequence memory is an essential attribute of natural and artificial\nintelligence that enables agents to encode, store, and retrieve complex\nsequences of stimuli and actions. Computational models of sequence memory have\nbeen proposed where recurrent Hopfield-like neural networks are trained with\ntemporally asymmetric Hebbian rules. However, these networks suffer from\nlimited sequence capacity (maximal length of the stored sequence) due to\ninterference between the memories. Inspired by recent work on Dense Associative\nMemories, we expand the sequence capacity of these models by introducing a\nnonlinear interaction term, enhancing separation between the patterns. We\nderive novel scaling laws for sequence capacity with respect to network size,\nsignificantly outperforming existing scaling laws for models based on\ntraditional Hopfield networks, and verify these theoretical results with\nnumerical simulation. Moreover, we introduce a generalized pseudoinverse rule\nto recall sequences of highly correlated patterns. Finally, we extend this\nmodel to store sequences with variable timing between states' transitions and\ndescribe a biologically-plausible implementation, with connections to motor\nneuroscience.",
          "link": "http://arxiv.org/abs/2306.04532",
          "publishedOn": "2023-11-07T00:44:08.219Z",
          "wordCount": null,
          "title": "Long Sequence Hopfield Memory. (arXiv:2306.04532v2 [cs.NE] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03609",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kang_T/0/1/0/all/0/1\">Taegyu Kang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1\">Sehwan Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sohn_J/0/1/0/all/0/1\">Jinwon Sohn</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Awan_J/0/1/0/all/0/1\">Jordan Awan</a>",
          "description": "This paper is the first to attempt differentially private (DP) topological\ndata analysis (TDA), producing near-optimal private persistence diagrams. We\nanalyze the sensitivity of persistence diagrams in terms of the bottleneck\ndistance, and we show that the commonly used \\v{C}ech complex has sensitivity\nthat does not decrease as the sample size $n$ increases. This makes it\nchallenging for the persistence diagrams of \\v{C}ech complexes to be\nprivatized. As an alternative, we show that the persistence diagram obtained by\nthe $L^1$-distance to measure (DTM) has sensitivity $O(1/n)$. Based on the\nsensitivity analysis, we propose using the exponential mechanism whose utility\nfunction is defined in terms of the bottleneck distance of the $L^1$-DTM\npersistence diagrams. We also derive upper and lower bounds of the accuracy of\nour privacy mechanism; the obtained bounds indicate that the privacy error of\nour mechanism is near-optimal. We demonstrate the performance of our privatized\npersistence diagrams through simulations as well as on a real dataset tracking\nhuman movement.",
          "link": "http://arxiv.org/abs/2305.03609",
          "publishedOn": "2023-11-07T00:44:08.218Z",
          "wordCount": null,
          "title": "Differentially Private Topological Data Analysis. (arXiv:2305.03609v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dubinski_J/0/1/0/all/0/1\">Jan Dubi&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pawlak_S/0/1/0/all/0/1\">Stanis&#x142;aw Pawlak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boenisch_F/0/1/0/all/0/1\">Franziska Boenisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1\">Tomasz Trzci&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dziedzic_A/0/1/0/all/0/1\">Adam Dziedzic</a>",
          "description": "Machine Learning as a Service (MLaaS) APIs provide ready-to-use and\nhigh-utility encoders that generate vector representations for given inputs.\nSince these encoders are very costly to train, they become lucrative targets\nfor model stealing attacks during which an adversary leverages query access to\nthe API to replicate the encoder locally at a fraction of the original training\ncosts. We propose Bucks for Buckets (B4B), the first active defense that\nprevents stealing while the attack is happening without degrading\nrepresentation quality for legitimate API users. Our defense relies on the\nobservation that the representations returned to adversaries who try to steal\nthe encoder's functionality cover a significantly larger fraction of the\nembedding space than representations of legitimate users who utilize the\nencoder to solve a particular downstream task.vB4B leverages this to adaptively\nadjust the utility of the returned representations according to a user's\ncoverage of the embedding space. To prevent adaptive adversaries from eluding\nour defense by simply creating multiple user accounts (sybils), B4B also\nindividually transforms each user's representations. This prevents the\nadversary from directly aggregating representations over multiple accounts to\ncreate their stolen encoder copy. Our active defense opens a new path towards\nsecurely sharing and democratizing encoders over public APIs.",
          "link": "http://arxiv.org/abs/2310.08571",
          "publishedOn": "2023-11-07T00:44:08.218Z",
          "wordCount": null,
          "title": "Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders. (arXiv:2310.08571v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01996",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Haque_A/0/1/0/all/0/1\">AKM Enzam-Ul Haque</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rabbany_G/0/1/0/all/0/1\">Golam Rabbany</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Siam_M/0/1/0/all/0/1\">Md. Siam</a>",
          "description": "One of the most serious corneal disorders, keratoconus is difficult to\ndiagnose in its early stages and can result in blindness. This illness, which\noften appears in the second decade of life, affects people of all sexes and\nraces. Convolutional neural networks (CNNs), one of the deep learning\napproaches, have recently come to light as particularly promising tools for the\naccurate and timely diagnosis of keratoconus. The purpose of this study was to\nevaluate how well different D-CNN models identified keratoconus-related\ndiseases. To be more precise, we compared five different CNN-based deep\nlearning architectures (DenseNet201, InceptionV3, MobileNetV2, VGG19,\nXception). In our comprehensive experimental analysis, the DenseNet201-based\nmodel performed very well in keratoconus disease identification in our\nextensive experimental research. This model outperformed its D-CNN equivalents,\nwith an astounding accuracy rate of 89.14% in three crucial classes:\nKeratoconus, Normal, and Suspect. The results demonstrate not only the\nstability and robustness of the model but also its practical usefulness in\nreal-world applications for accurate and dependable keratoconus identification.\nIn addition, D-CNN DenseNet201 performs extraordinarily well in terms of\nprecision, recall rates, and F1 scores in addition to accuracy. These measures\nvalidate the model's usefulness as an effective diagnostic tool by highlighting\nits capacity to reliably detect instances of keratoconus and to reduce false\npositives and negatives.",
          "link": "http://arxiv.org/abs/2311.01996",
          "publishedOn": "2023-11-07T00:44:08.214Z",
          "wordCount": null,
          "title": "Detection of keratoconus Diseases using deep Learning. (arXiv:2311.01996v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.02019",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Huggins_J/0/1/0/all/0/1\">Jonathan H. Huggins</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Miller_J/0/1/0/all/0/1\">Jeffrey W. Miller</a>",
          "description": "Under model misspecification, it is known that Bayesian posteriors often do\nnot properly quantify uncertainty about true or pseudo-true parameters. Even\nmore fundamentally, misspecification leads to a lack of reproducibility in the\nsense that the same model will yield contradictory posteriors on independent\ndata sets from the true distribution. To define a criterion for reproducible\nuncertainty quantification under misspecification, we consider the probability\nthat two confidence sets constructed from independent data sets have nonempty\noverlap, and we establish a lower bound on this overlap probability that holds\nfor any valid confidence sets. We prove that credible sets from the standard\nposterior can strongly violate this bound, particularly in high-dimensional\nsettings (i.e., with dimension increasing with sample size), indicating that it\nis not internally coherent under misspecification. To improve reproducibility\nin an easy-to-use and widely applicable way, we propose to apply bagging to the\nBayesian posterior (\"BayesBag\"'); that is, to use the average of posterior\ndistributions conditioned on bootstrapped datasets. We motivate BayesBag from\nfirst principles based on Jeffrey conditionalization and show that the bagged\nposterior typically satisfies the overlap lower bound. Further, we prove a\nBernstein--Von Mises theorem for the bagged posterior, establishing its\nasymptotic normal distribution. We demonstrate the benefits of BayesBag via\nsimulation experiments and an application to crime rate prediction.",
          "link": "http://arxiv.org/abs/2311.02019",
          "publishedOn": "2023-11-07T00:44:08.214Z",
          "wordCount": null,
          "title": "Reproducible Parameter Inference Using Bagged Posteriors. (arXiv:2311.02019v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marton_S/0/1/0/all/0/1\">Sascha Marton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludtke_S/0/1/0/all/0/1\">Stefan L&#xfc;dtke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartelt_C/0/1/0/all/0/1\">Christian Bartelt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stuckenschmidt_H/0/1/0/all/0/1\">Heiner Stuckenschmidt</a>",
          "description": "Decision Trees (DTs) are commonly used for many machine learning tasks due to\ntheir high degree of interpretability. However, learning a DT from data is a\ndifficult optimization problem, as it is non-convex and non-differentiable.\nTherefore, common approaches learn DTs using a greedy growth algorithm that\nminimizes the impurity locally at each internal node. Unfortunately, this\ngreedy procedure can lead to inaccurate trees. In this paper, we present a\nnovel approach for learning hard, axis-aligned DTs with gradient descent. The\nproposed method uses backpropagation with a straight-through operator on a\ndense DT representation, to jointly optimize all tree parameters. Our approach\noutperforms existing methods on binary classification benchmarks and achieves\ncompetitive results for multi-class tasks. The method is available under:\nhttps://github.com/s-marton/GradTree",
          "link": "http://arxiv.org/abs/2305.03515",
          "publishedOn": "2023-11-07T00:44:08.214Z",
          "wordCount": null,
          "title": "GradTree: Learning Axis-Aligned Decision Trees with Gradient Descent. (arXiv:2305.03515v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.02041",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Furrutter_F/0/1/0/all/0/1\">Florian F&#xfc;rrutter</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Munoz_Gil_G/0/1/0/all/0/1\">Gorka Mu&#xf1;oz-Gil</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Briegel_H/0/1/0/all/0/1\">Hans J. Briegel</a>",
          "description": "Quantum computing has recently emerged as a transformative technology. Yet,\nits promised advantages rely on efficiently translating quantum operations into\nviable physical realizations. In this work, we use generative machine learning\nmodels, specifically denoising diffusion models (DMs), to facilitate this\ntransformation. Leveraging text-conditioning, we steer the model to produce\ndesired quantum operations within gate-based quantum circuits. Notably, DMs\nallow to sidestep during training the exponential overhead inherent in the\nclassical simulation of quantum dynamics -- a consistent bottleneck in\npreceding ML techniques. We demonstrate the model's capabilities across two\ntasks: entanglement generation and unitary compilation. The model excels at\ngenerating new circuits and supports typical DM extensions such as masking and\nediting to, for instance, align the circuit generation to the constraints of\nthe targeted quantum device. Given their flexibility and generalization\nabilities, we envision DMs as pivotal in quantum circuit synthesis, enhancing\nboth practical applications but also insights into theoretical quantum\ncomputation.",
          "link": "http://arxiv.org/abs/2311.02041",
          "publishedOn": "2023-11-07T00:44:08.213Z",
          "wordCount": null,
          "title": "Quantum circuit synthesis with diffusion models. (arXiv:2311.02041v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.07596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yuxuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simpson_E/0/1/0/all/0/1\">Edwin Simpson</a>",
          "description": "This paper introduces a novel pipeline for summarising timelines of events\nreported by multiple news sources. Transformer-based models for abstractive\nsummarisation generate coherent and concise summaries of long documents but can\nfail to outperform established extractive methods on specialised tasks such as\ntimeline summarisation (TLS). While extractive summaries are more faithful to\ntheir sources, they may be less readable and contain redundant or unnecessary\ninformation. This paper proposes a preference-based reinforcement learning\n(PBRL) method for adapting pretrained abstractive summarisers to TLS, which can\novercome the drawbacks of extractive timeline summaries. We define a compound\nreward function that learns from keywords of interest and pairwise preference\nlabels, which we use to fine-tune a pretrained abstractive summariser via\noffline reinforcement learning. We carry out both automated and human\nevaluation on three datasets, finding that our method outperforms a comparable\nextractive TLS method on two of the three benchmark datasets, and participants\nprefer our method's summaries to those of both the extractive TLS method and\nthe pretrained abstractive model. The method does not require expensive\nreference summaries and needs only a small number of preferences to align the\ngenerated summaries with human preferences.",
          "link": "http://arxiv.org/abs/2211.07596",
          "publishedOn": "2023-11-07T00:44:08.213Z",
          "wordCount": null,
          "title": "Towards Abstractive Timeline Summarisation using Preference-based Reinforcement Learning. (arXiv:2211.07596v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciosici_M/0/1/0/all/0/1\">Manuel R. Ciosici</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hedges_A/0/1/0/all/0/1\">Alex Hedges</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kankanampati_Y/0/1/0/all/0/1\">Yash Kankanampati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1\">Justin Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freedman_M/0/1/0/all/0/1\">Marjorie Freedman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weischedel_R/0/1/0/all/0/1\">Ralph Weischedel</a>",
          "description": "We explore using a moderately sized large language model (GPT-J 6B\nparameters) to create a plan for a simulated robot to achieve 30 classes of\ngoals in ScienceWorld, a text game simulator for elementary science\nexperiments. Previously published empirical work claimed that large language\nmodels (LLMs) are a poor fit (Wang et al., 2022) compared to reinforcement\nlearning. Using the Markov assumption (a single previous step), the LLM\noutperforms the reinforcement learning-based approach by a factor of 1.4. When\nwe fill the LLM's input buffer with as many prior steps as possible,\nimprovement rises to 3.5x. Even when training on only 6.5% of the training\ndata, we observe a 2.2x improvement over the reinforcement-learning-based\napproach. Our experiments show that performance varies widely across the 30\nclasses of actions, indicating that averaging over tasks can hide significant\nperformance issues. In work contemporaneous with ours, Lin et al. (2023)\ndemonstrated a two-part approach (SwiftSage) that uses a small LLM (T5-large)\ncomplemented by OpenAI's massive LLMs to achieve outstanding results in\nScienceWorld. Our 6-B parameter, single-stage GPT-J matches the performance of\nSwiftSage's two-stage architecture when it incorporates GPT-3.5 turbo which has\n29-times more parameters than GPT-J.",
          "link": "http://arxiv.org/abs/2311.01468",
          "publishedOn": "2023-11-07T00:44:08.212Z",
          "wordCount": null,
          "title": "Remember what you did so you know what to do next. (arXiv:2311.01468v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1\">Siqi Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chennan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weiquan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yongquan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1\">Songzhu Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinwang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng Wang</a>",
          "description": "Multi-agent systems are characterized by environmental uncertainty, varying\npolicies of agents, and partial observability, which result in significant\nrisks. In the context of Multi-Agent Reinforcement Learning (MARL), learning\ncoordinated and decentralized policies that are sensitive to risk is\nchallenging. To formulate the coordination requirements in risk-sensitive MARL,\nwe introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a\ngeneralization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM)\nprinciples. This principle requires that the collection of risk-sensitive\naction selections of each agent should be equivalent to the risk-sensitive\naction selection of the central policy. Current MARL value factorization\nmethods do not satisfy the RIGM principle for common risk metrics such as the\nValue at Risk (VaR) metric or distorted risk measurements. Therefore, we\npropose RiskQ to address this limitation, which models the joint return\ndistribution by modeling quantiles of it as weighted quantile mixtures of\nper-agent return distribution utilities. RiskQ satisfies the RIGM principle for\nthe VaR and distorted risk metrics. We show that RiskQ can obtain promising\nperformance through extensive experiments. The source code of RiskQ is\navailable in https://github.com/xmu-rl-3dv/RiskQ.",
          "link": "http://arxiv.org/abs/2311.01753",
          "publishedOn": "2023-11-07T00:44:08.212Z",
          "wordCount": null,
          "title": "RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization. (arXiv:2311.01753v1 [cs.MA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.02061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lange_C/0/1/0/all/0/1\">Christian Lange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cole_E/0/1/0/all/0/1\">Elijah Cole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horn_G/0/1/0/all/0/1\">Grant Van Horn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1\">Oisin Mac Aodha</a>",
          "description": "We propose a new active learning approach for efficiently estimating the\ngeographic range of a species from a limited number of on the ground\nobservations. We model the range of an unmapped species of interest as the\nweighted combination of estimated ranges obtained from a set of different\nspecies. We show that it is possible to generate this candidate set of ranges\nby using models that have been trained on large weakly supervised community\ncollected observation data. From this, we develop a new active querying\napproach that sequentially selects geographic locations to visit that best\nreduce our uncertainty over an unmapped species' range. We conduct a detailed\nevaluation of our approach and compare it to existing active learning methods\nusing an evaluation dataset containing expert-derived ranges for one thousand\nspecies. Our results demonstrate that our method outperforms alternative active\nlearning methods and approaches the performance of end-to-end trained models,\neven when only using a fraction of the data. This highlights the utility of\nactive learning via transfer learned spatial representations for species range\nestimation. It also emphasizes the value of leveraging emerging large-scale\ncrowdsourced datasets, not only for modeling a species' range, but also for\nactively discovering them.",
          "link": "http://arxiv.org/abs/2311.02061",
          "publishedOn": "2023-11-07T00:44:08.212Z",
          "wordCount": null,
          "title": "Active Learning-Based Species Range Estimation. (arXiv:2311.02061v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_W/0/1/0/all/0/1\">Wilka Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lampinen_A/0/1/0/all/0/1\">Andrew Lampinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikiforou_K/0/1/0/all/0/1\">Kyriacos Nikiforou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1\">Felix Hill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1\">Murray Shanahan</a>",
          "description": "Many important tasks are defined in terms of object. To generalize across\nthese tasks, a reinforcement learning (RL) agent needs to exploit the structure\nthat the objects induce. Prior work has either hard-coded object-centric\nfeatures, used complex object-centric generative models, or updated state using\nlocal spatial features. However, these approaches have had limited success in\nenabling general RL agents. Motivated by this, we introduce \"Feature-Attending\nRecurrent Modules\" (FARM), an architecture for learning state representations\nthat relies on simple, broadly applicable inductive biases for capturing\nspatial and temporal regularities. FARM learns a state representation that is\ndistributed across multiple modules that each attend to spatiotemporal features\nwith an expressive feature attention mechanism. We show that this improves an\nRL agent's ability to generalize across object-centric tasks. We study task\nsuites in both 2D and 3D environments and find that FARM better generalizes\ncompared to competing architectures that leverage attention or multiple\nmodules.",
          "link": "http://arxiv.org/abs/2112.08369",
          "publishedOn": "2023-11-07T00:44:08.212Z",
          "wordCount": null,
          "title": "Feature-Attending Recurrent Modules for Generalization in Reinforcement Learning. (arXiv:2112.08369v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Litian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yao Qin</a>",
          "description": "Out-of-distribution (OOD) detection is essential for the safe deployment of\nAI. Particularly, OOD detectors should generalize effectively across diverse\nscenarios. To improve upon the generalizability of existing OOD detectors, we\nintroduce a highly versatile OOD detector, called Neural Collapse inspired OOD\ndetector (NC-OOD). We extend the prevalent observation that in-distribution\n(ID) features tend to form clusters, whereas OOD features are far away.\nParticularly, based on the recent observation, Neural Collapse, we further\ndemonstrate that ID features tend to cluster in proximity to weight vectors.\nFrom our extended observation, we propose to detect OOD based on feature\nproximity to weight vectors. To further rule out OOD samples, we leverage the\nobservation that OOD features tend to reside closer to the origin than ID\nfeatures. Extensive experiments show that our approach enhances the\ngeneralizability of existing work and can consistently achieve state-of-the-art\nOOD detection performance across a wide range of OOD Benchmarks over different\nclassification tasks, training losses, and model architectures.",
          "link": "http://arxiv.org/abs/2311.01479",
          "publishedOn": "2023-11-07T00:44:08.211Z",
          "wordCount": null,
          "title": "Detecting Out-of-Distribution Through the Lens of Neural Collapse. (arXiv:2311.01479v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zihan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xianhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yue Gao</a>",
          "description": "Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.",
          "link": "http://arxiv.org/abs/2311.01483",
          "publishedOn": "2023-11-07T00:44:08.211Z",
          "wordCount": null,
          "title": "FedSN: A General Federated Learning Framework over LEO Satellite Networks. (arXiv:2311.01483v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01854",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Moayedi_B/0/1/0/all/0/1\">Behzad Moayedi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Keramatfar_A/0/1/0/all/0/1\">Abdalsamad Keramatfar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goldani_M/0/1/0/all/0/1\">Mohammad Hadi Goldani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fallahi_M/0/1/0/all/0/1\">Mohammad Javad Fallahi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jahangirisisakht_A/0/1/0/all/0/1\">Alborz Jahangirisisakht</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Saboori_M/0/1/0/all/0/1\">Mohammad Saboori</a>, <a href=\"http://arxiv.org/find/eess/1/au:+badiei_L/0/1/0/all/0/1\">Leyla badiei</a>",
          "description": "The rapid spread of COVID-19 and the emergence of new variants underscore the\nimportance of effective screening measures. Rapid diagnosis and subsequent\nquarantine of infected individuals can prevent further spread of the virus in\nsociety. While PCR tests are the gold standard for COVID-19 diagnosis, they are\ncostly and time-consuming. In contrast, urine test strips are an inexpensive,\nnon-invasive, and rapidly obtainable screening method that can provide\nimportant information about a patient's health status. In this study, we\ncollected a new dataset and used the RGB (Red Green Blue) color space of urine\ntest strips parameters to detect the health status of individuals. To improve\nthe accuracy of our model, we converted the RGB space to 10 additional color\nspaces. After evaluating four different machine learning models, we proposed a\nnew ensemble model based on a multi-layer perceptron neural network. Although\nthe initial results were not strong, we were able to improve the model's\nscreening performance for COVID-19 by removing uncertain regions of the model\nspace. Ultimately, our model achieved a screening accuracy of 80% based on\nurine parameters. Our results suggest that urine test strips can be a useful\ntool for COVID-19 screening, particularly in resource-constrained settings\nwhere PCR testing may not be feasible. Further research is needed to validate\nour findings and explore the potential role of urine test strips in COVID-19\ndiagnosis and management.",
          "link": "http://arxiv.org/abs/2311.01854",
          "publishedOn": "2023-11-07T00:44:08.210Z",
          "wordCount": null,
          "title": "An Ensemble Machine Learning Approach for Screening Covid-19 based on Urine Parameters. (arXiv:2311.01854v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.02058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wan_W/0/1/0/all/0/1\">Weikang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yifeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rutav Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>",
          "description": "We introduce LOTUS, a continual imitation learning algorithm that empowers a\nphysical robot to continuously and efficiently learn to solve new manipulation\ntasks throughout its lifespan. The core idea behind LOTUS is constructing an\never-growing skill library from a sequence of new tasks with a small number of\nhuman demonstrations. LOTUS starts with a continual skill discovery process\nusing an open-vocabulary vision model, which extracts skills as recurring\npatterns presented in unsegmented demonstrations. Continual skill discovery\nupdates existing skills to avoid catastrophic forgetting of previous tasks and\nadds new skills to solve novel tasks. LOTUS trains a meta-controller that\nflexibly composes various skills to tackle vision-based manipulation tasks in\nthe lifelong learning process. Our comprehensive experiments show that LOTUS\noutperforms state-of-the-art baselines by over 11% in success rate, showing its\nsuperior knowledge transfer ability compared to prior methods. More results and\nvideos can be found on the project website:\nhttps://ut-austin-rpl.github.io/Lotus/.",
          "link": "http://arxiv.org/abs/2311.02058",
          "publishedOn": "2023-11-07T00:44:08.210Z",
          "wordCount": null,
          "title": "LOTUS: Continual Imitation Learning for Robot Manipulation Through Unsupervised Skill Discovery. (arXiv:2311.02058v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.00265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Banghua Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Mingyu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobson_P/0/1/0/all/0/1\">Philip Jacobson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Ming Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1\">Wei Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jiantao Jiao</a>",
          "description": "Self-training is an important technique for solving semi-supervised learning\nproblems. It leverages unlabeled data by generating pseudo-labels and combining\nthem with a limited labeled dataset for training. The effectiveness of\nself-training heavily relies on the accuracy of these pseudo-labels. In this\npaper, we introduce doubly robust self-training, a novel semi-supervised\nalgorithm that provably balances between two extremes. When the pseudo-labels\nare entirely incorrect, our method reduces to a training process solely using\nlabeled data. Conversely, when the pseudo-labels are completely accurate, our\nmethod transforms into a training process utilizing all pseudo-labeled data and\nlabeled data, thus increasing the effective sample size. Through empirical\nevaluations on both the ImageNet dataset for image classification and the\nnuScenes autonomous driving dataset for 3D object detection, we demonstrate the\nsuperiority of the doubly robust loss over the standard self-training baseline.",
          "link": "http://arxiv.org/abs/2306.00265",
          "publishedOn": "2023-11-07T00:44:08.210Z",
          "wordCount": null,
          "title": "Doubly Robust Self-Training. (arXiv:2306.00265v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01742",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Bertsimas_D/0/1/0/all/0/1\">Dimitris Bertsimas</a>, <a href=\"http://arxiv.org/find/math/1/au:+Margaritis_G/0/1/0/all/0/1\">Georgios Margaritis</a>",
          "description": "Many approaches for addressing Global Optimization problems typically rely on\nrelaxations of nonlinear constraints over specific mathematical primitives.\nThis is restricting in applications with constraints that are black-box,\nimplicit or consist of more general primitives. Trying to address such\nlimitations, Bertsimas and Ozturk (2023) proposed OCTHaGOn as a way of solving\nblack-box global optimization problems by approximating the nonlinear\nconstraints using hyperplane-based Decision-Trees and then using those trees to\nconstruct a unified mixed integer optimization (MIO) approximation of the\noriginal problem. We provide extensions to this approach, by (i) approximating\nthe original problem using other MIO-representable ML models besides Decision\nTrees, such as Gradient Boosted Trees, Multi Layer Perceptrons and Suport\nVector Machines, (ii) proposing adaptive sampling procedures for more accurate\nmachine learning-based constraint approximations, (iii) utilizing robust\noptimization to account for the uncertainty of the sample-dependent training of\nthe ML models, and (iv) leveraging a family of relaxations to address the\ninfeasibilities of the final MIO approximation. We then test the enhanced\nframework in 81 Global Optimization instances. We show improvements in solution\nfeasibility and optimality in the majority of instances. We also compare\nagainst BARON, showing improved optimality gaps or solution times in 11\ninstances.",
          "link": "http://arxiv.org/abs/2311.01742",
          "publishedOn": "2023-11-07T00:44:08.208Z",
          "wordCount": null,
          "title": "Global Optimization: A Machine Learning Approach. (arXiv:2311.01742v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadikaj_Y/0/1/0/all/0/1\">Ylli Sadikaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velaj_Y/0/1/0/all/0/1\">Yllka Velaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behzadi_S/0/1/0/all/0/1\">Sahar Behzadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plant_C/0/1/0/all/0/1\">Claudia Plant</a>",
          "description": "Graph clustering aims at discovering a natural grouping of the nodes such\nthat similar nodes are assigned to a common cluster. Many different algorithms\nhave been proposed in the literature: for simple graphs, for graphs with\nattributes associated to nodes, and for graphs where edges represent different\ntypes of relations among nodes. However, complex data in many domains can be\nrepresented as both attributed and multi-relational networks.\n\nIn this paper, we propose SpectralMix, a joint dimensionality reduction\ntechnique for multi-relational graphs with categorical node attributes.\nSpectralMix integrates all information available from the attributes, the\ndifferent types of relations, and the graph structure to enable a sound\ninterpretation of the clustering results. Moreover, it generalizes existing\ntechniques: it reduces to spectral embedding and clustering when only applied\nto a single graph and to homogeneity analysis when applied to categorical data.\nExperiments conducted on several real-world datasets enable us to detect\ndependencies between graph structure and categorical attributes, moreover, they\nexhibit the superiority of SpectralMix over existing methods.",
          "link": "http://arxiv.org/abs/2311.01840",
          "publishedOn": "2023-11-07T00:44:08.208Z",
          "wordCount": null,
          "title": "Spectral Clustering of Attributed Multi-relational Graphs. (arXiv:2311.01840v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01759",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianlei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_J/0/1/0/all/0/1\">Jiacheng Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_F/0/1/0/all/0/1\">Fanding Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Meichen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_L/0/1/0/all/0/1\">Lingkun Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_H/0/1/0/all/0/1\">Han Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Weisheng Zhao</a>",
          "description": "Developing deep learning models on tiny devices (e.g. Microcontroller units,\nMCUs) has attracted much attention in various embedded IoT applications.\nHowever, it is challenging to efficiently design and deploy recent advanced\nmodels (e.g. transformers) on tiny devices due to their severe hardware\nresource constraints. In this work, we propose TinyFormer, a framework\nspecifically designed to develop and deploy resource-efficient transformers on\nMCUs. TinyFormer mainly consists of SuperNAS, SparseNAS and SparseEngine.\nSeparately, SuperNAS aims to search for an appropriate supernet from a vast\nsearch space. SparseNAS evaluates the best sparse single-path model including\ntransformer architecture from the identified supernet. Finally, SparseEngine\nefficiently deploys the searched sparse models onto MCUs. To the best of our\nknowledge, SparseEngine is the first deployment framework capable of performing\ninference of sparse models with transformer on MCUs. Evaluation results on the\nCIFAR-10 dataset demonstrate that TinyFormer can develop efficient transformers\nwith an accuracy of $96.1\\%$ while adhering to hardware constraints of $1$MB\nstorage and $320$KB memory. Additionally, TinyFormer achieves significant\nspeedups in sparse inference, up to $12.2\\times$, when compared to the CMSIS-NN\nlibrary. TinyFormer is believed to bring powerful transformers into TinyML\nscenarios and greatly expand the scope of deep learning applications.",
          "link": "http://arxiv.org/abs/2311.01759",
          "publishedOn": "2023-11-07T00:44:08.207Z",
          "wordCount": null,
          "title": "TinyFormer: Efficient Transformer Design and Deployment on Tiny Devices. (arXiv:2311.01759v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.08627",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhu_Q/0/1/0/all/0/1\">Qiuyun Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Atchade_Y/0/1/0/all/0/1\">Yves Atchade</a>",
          "description": "Canonical correlation analysis (CCA) is a popular statistical technique for\nexploring relationships between datasets. In recent years, the estimation of\nsparse canonical vectors has emerged as an important but challenging variant of\nthe CCA problem, with widespread applications. Unfortunately, existing\nrate-optimal estimators for sparse canonical vectors have high computational\ncost. We propose a quasi-Bayesian estimation procedure that not only achieves\nthe minimax estimation rate, but also is easy to compute by Markov Chain Monte\nCarlo (MCMC). The method builds on Tan et al. (2018) and uses a re-scaled\nRayleigh quotient function as the quasi-log-likelihood. However, unlike Tan et\nal. (2018), we adopt a Bayesian framework that combines this\nquasi-log-likelihood with a spike-and-slab prior to regularize the inference\nand promote sparsity. We investigate the empirical behavior of the proposed\nmethod on both continuous and truncated data, and we demonstrate that it\noutperforms several state-of-the-art methods. As an application, we use the\nproposed methodology to maximally correlate clinical variables and proteomic\ndata for better understanding the Covid-19 disease.",
          "link": "http://arxiv.org/abs/2010.08627",
          "publishedOn": "2023-11-07T00:44:08.207Z",
          "wordCount": null,
          "title": "Minimax Quasi-Bayesian estimation in sparse canonical correlation analysis via a Rayleigh quotient function. (arXiv:2010.08627v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.03843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prystawski_B/0/1/0/all/0/1\">Ben Prystawski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Michael Y. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>",
          "description": "Humans have a powerful and mysterious capacity to reason. Working through a\nset of mental steps enables us to make inferences we would not be capable of\nmaking directly even though we get no additional data from the world.\nSimilarly, when large language models generate intermediate steps (a chain of\nthought) before answering a question, they often produce better answers than\nthey would directly. We investigate why and how chain-of-thought reasoning is\nuseful in language models, testing the hypothesis that reasoning is effective\nwhen training data consists of overlapping local clusters of variables that\ninfluence each other strongly. These training conditions enable the chaining of\naccurate local inferences to estimate relationships between variables that were\nnot seen together in training. We prove that there will exist a \"reasoning\ngap\", where reasoning through intermediate variables reduces bias, for the\nsimple case of an autoregressive density estimator trained on local samples\nfrom a chain-structured probabilistic model. We then test our hypothesis\nexperimentally in more complex models, training an autoregressive language\nmodel on samples from Bayes nets but only including a subset of variables in\neach sample. We test language models' ability to match conditional\nprobabilities with and without intermediate reasoning steps, finding that\nintermediate steps are only helpful when the training data is locally\nstructured with respect to dependencies between variables. The combination of\nlocally structured observations and reasoning is much more data-efficient than\ntraining on all variables. Our results illustrate how the effectiveness of\nreasoning step by step is rooted in the local statistical structure of the\ntraining data.",
          "link": "http://arxiv.org/abs/2304.03843",
          "publishedOn": "2023-11-07T00:44:08.207Z",
          "wordCount": null,
          "title": "Why think step by step? Reasoning emerges from the locality of experience. (arXiv:2304.03843v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">J. Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">J. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">M. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jadhav_S/0/1/0/all/0/1\">S. Jadhav</a>",
          "description": "Functional Data Analysis (FDA) is a statistical domain developed to handle\nfunctional data characterized by high dimensionality and complex data\nstructures. Sequential Neural Networks (SNNs) are specialized neural networks\ncapable of processing sequence data, a fundamental aspect of functional data.\nDespite their great flexibility in modeling functional data, SNNs have been\ninadequately employed in the FDA community. One notable advantage of SNNs is\nthe ease of implementation, making them accessible to a broad audience beyond\nacademia. Conversely, FDA-based methodologies present challenges, particularly\nfor practitioners outside the field, due to their intricate complexity. In\nlight of this, we propose utilizing SNNs in FDA applications and demonstrate\ntheir effectiveness through comparative analyses against popular FDA regression\nmodels based on numerical experiments and real-world data analysis. SNN\narchitectures allow us to surpass the limitations of traditional FDA methods,\noffering scalability, flexibility, and improved analytical performance. Our\nfindings highlight the potential of SNN-based methodologies as powerful tools\nfor data applications involving functional data.",
          "link": "http://arxiv.org/abs/2311.01875",
          "publishedOn": "2023-11-07T00:44:08.206Z",
          "wordCount": null,
          "title": "Enhancing Functional Data Analysis with Sequential Neural Networks: Advantages and Comparative Study. (arXiv:2311.01875v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cheng Zhang</a>",
          "description": "The gold standard for causal model evaluation involves comparing model\npredictions with true effects estimated from randomized controlled trials\n(RCT). However, RCTs are not always feasible or ethical to perform. In\ncontrast, conditionally randomized experiments based on inverse probability\nweighting (IPW) offer a more realistic approach but may suffer from high\nestimation variance. To tackle this challenge and enhance causal model\nevaluation in real-world conditional randomization settings, we introduce a\nnovel low-variance estimator for causal error, dubbed as the pairs estimator.\nBy applying the same IPW estimator to both the model and true experimental\neffects, our estimator effectively cancels out the variance due to IPW and\nachieves a smaller asymptotic variance. Empirical studies demonstrate the\nimproved of our estimator, highlighting its potential on achieving near-RCT\nperformance. Our method offers a simple yet powerful solution to evaluate\ncausal inference models in conditional randomization settings without\ncomplicated modification of the IPW estimator itself, paving the way for more\nrobust and reliable model assessments.",
          "link": "http://arxiv.org/abs/2311.01902",
          "publishedOn": "2023-11-07T00:44:08.206Z",
          "wordCount": null,
          "title": "High Precision Causal Model Evaluation with Conditional Randomization. (arXiv:2311.01902v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carr_J/0/1/0/all/0/1\">Jonathan Colaco Carr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panangaden_P/0/1/0/all/0/1\">Prakash Panangaden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>",
          "description": "Learning from Preferential Feedback (LfPF) plays an essential role in\ntraining Large Language Models, as well as certain types of interactive\nlearning agents. However, a substantial gap exists between the theory and\napplication of LfPF algorithms. Current results guaranteeing the existence of\noptimal policies in LfPF problems assume that both the preferences and\ntransition dynamics are determined by a Markov Decision Process. We introduce\nthe Direct Preference Process, a new framework for analyzing LfPF problems in\npartially-observable, non-Markovian environments. Within this framework, we\nestablish conditions that guarantee the existence of optimal policies by\nconsidering the ordinal structure of the preferences. Using the von\nNeumann-Morgenstern Expected Utility Theorem, we show that the Direct\nPreference Process generalizes the standard reinforcement learning problem. Our\nfindings narrow the gap between the empirical success and theoretical\nunderstanding of LfPF algorithms and provide future practitioners with the\ntools necessary for a more principled design of LfPF agents.",
          "link": "http://arxiv.org/abs/2311.01990",
          "publishedOn": "2023-11-07T00:44:08.206Z",
          "wordCount": null,
          "title": "Conditions on Preference Relations that Guarantee the Existence of Optimal Policies. (arXiv:2311.01990v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01777",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Singh_S/0/1/0/all/0/1\">Sanskriti Singh</a>",
          "description": "The global challenge in chest radiograph X-ray (CXR) abnormalities often\nbeing misdiagnosed is primarily associated with perceptual errors, where\nhealthcare providers struggle to accurately identify the location of\nabnormalities, rather than misclassification errors. We currently address this\nproblem through disease-specific segmentation models. Unfortunately, these\nmodels cannot be released in the field due to their lack of generalizability\nacross all thoracic diseases. A binary model tends to perform poorly when it\nencounters a disease that isn't represented in the dataset. We present\nCheX-nomaly: a binary localization U-net model that leverages transfer learning\ntechniques with the incorporation of an innovative contrastive learning\napproach. Trained on the VinDr-CXR dataset, which encompasses 14 distinct\ndiseases in addition to 'no finding' cases, my model achieves generalizability\nacross these 14 diseases and others it has not seen before. We show that we can\nsignificantly improve the generalizability of an abnormality localization model\nby incorporating a contrastive learning method and dissociating the bounding\nboxes with its disease class. We also introduce a new loss technique to apply\nto enhance the U-nets performance on bounding box segmentation. By introducing\nCheX-nomaly, we offer a promising solution to enhance the precision of chest\ndisease diagnosis, with a specific focus on reducing the significant number of\nperceptual errors in healthcare.",
          "link": "http://arxiv.org/abs/2311.01777",
          "publishedOn": "2023-11-07T00:44:08.205Z",
          "wordCount": null,
          "title": "CheX-Nomaly: Segmenting Lung Abnormalities from Chest Radiographs using Machine Learning. (arXiv:2311.01777v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dooley_S/0/1/0/all/0/1\">Samuel Dooley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_G/0/1/0/all/0/1\">Gurnoor Singh Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohapatra_C/0/1/0/all/0/1\">Chirag Mohapatra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naidu_S/0/1/0/all/0/1\">Siddartha Naidu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1\">Colin White</a>",
          "description": "The vast majority of time-series forecasting approaches require a substantial\ntraining dataset. However, many real-life forecasting applications have very\nlittle initial observations, sometimes just 40 or fewer. Thus, the\napplicability of most forecasting methods is restricted in data-sparse\ncommercial applications. While there is recent work in the setting of very\nlimited initial data (so-called `zero-shot' forecasting), its performance is\ninconsistent depending on the data used for pretraining. In this work, we take\na different approach and devise ForecastPFN, the first zero-shot forecasting\nmodel trained purely on a novel synthetic data distribution. ForecastPFN is a\nprior-data fitted network, trained to approximate Bayesian inference, which can\nmake predictions on a new time series dataset in a single forward pass. Through\nextensive experiments, we show that zero-shot predictions made by ForecastPFN\nare more accurate and faster compared to state-of-the-art forecasting methods,\neven when the other methods are allowed to train on hundreds of additional\nin-distribution data points.",
          "link": "http://arxiv.org/abs/2311.01933",
          "publishedOn": "2023-11-07T00:44:08.205Z",
          "wordCount": null,
          "title": "ForecastPFN: Synthetically-Trained Zero-Shot Forecasting. (arXiv:2311.01933v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01994",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dash_S/0/1/0/all/0/1\">Sanjeeb Dash</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1\">Soumyadip Ghosh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Goncalves_J/0/1/0/all/0/1\">Joao Goncalves</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Squillante_M/0/1/0/all/0/1\">Mark S. Squillante</a>",
          "description": "Model explainability is crucial for human users to be able to interpret how a\nproposed classifier assigns labels to data based on its feature values. We\nstudy generalized linear models constructed using sets of feature value rules,\nwhich can capture nonlinear dependencies and interactions. An inherent\ntrade-off exists between rule set sparsity and its prediction accuracy. It is\ncomputationally expensive to find the right choice of sparsity -- e.g., via\ncross-validation -- with existing methods. We propose a new formulation to\nlearn an ensemble of rule sets that simultaneously addresses these competing\nfactors. Good generalization is ensured while keeping computational costs low\nby utilizing distributionally robust optimization. The formulation utilizes\ncolumn generation to efficiently search the space of rule sets and constructs a\nsparse ensemble of rule sets, in contrast with techniques like random forests\nor boosting and their variants. We present theoretical results that motivate\nand justify the use of our distributionally robust formulation. Extensive\nnumerical experiments establish that our method improves over competing methods\n-- on a large set of publicly available binary classification problem instances\n-- with respect to one or more of the following metrics: generalization\nquality, computational cost, and explainability.",
          "link": "http://arxiv.org/abs/2311.01994",
          "publishedOn": "2023-11-07T00:44:08.205Z",
          "wordCount": null,
          "title": "Obtaining Explainable Classification Models using Distributionally Robust Optimization. (arXiv:2311.01994v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.04750",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_A/0/1/0/all/0/1\">Aditya Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rauber_P/0/1/0/all/0/1\">Paulo Rauber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conserva_M/0/1/0/all/0/1\">Michelangelo Conserva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>",
          "description": "An agent in a nonstationary contextual bandit problem should balance between\nexploration and the exploitation of (periodic or structured) patterns present\nin its previous experiences. Handcrafting an appropriate historical context is\nan attractive alternative to transform a nonstationary problem into a\nstationary problem that can be solved efficiently. However, even a carefully\ndesigned historical context may introduce spurious relationships or lack a\nconvenient representation of crucial information. In order to address these\nissues, we propose an approach that learns to represent the relevant context\nfor a decision based solely on the raw history of interactions between the\nagent and the environment. This approach relies on a combination of features\nextracted by recurrent neural networks with a contextual linear bandit\nalgorithm based on posterior sampling. Our experiments on a diverse selection\nof contextual and noncontextual nonstationary problems show that our recurrent\napproach consistently outperforms its feedforward counterpart, which requires\nhandcrafted historical contexts, while being more widely applicable than\nconventional nonstationary bandit algorithms. Although it is very difficult to\nprovide theoretical performance guarantees for our new approach, we also prove\na novel regret bound for linear posterior sampling with measurement error that\nmay serve as a foundation for future theoretical work.",
          "link": "http://arxiv.org/abs/2007.04750",
          "publishedOn": "2023-11-07T00:44:08.204Z",
          "wordCount": null,
          "title": "Recurrent Neural-Linear Posterior Sampling for Nonstationary Contextual Bandits. (arXiv:2007.04750v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.06177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Platonov_O/0/1/0/all/0/1\">Oleg Platonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuznedelev_D/0/1/0/all/0/1\">Denis Kuznedelev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1\">Artem Babenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1\">Liudmila Prokhorenkova</a>",
          "description": "Homophily is a graph property describing the tendency of edges to connect\nsimilar nodes; the opposite is called heterophily. It is often believed that\nheterophilous graphs are challenging for standard message-passing graph neural\nnetworks (GNNs), and much effort has been put into developing efficient methods\nfor this setting. However, there is no universally agreed-upon measure of\nhomophily in the literature. In this work, we show that commonly used homophily\nmeasures have critical drawbacks preventing the comparison of homophily levels\nacross different datasets. For this, we formalize desirable properties for a\nproper homophily measure and verify which measures satisfy which properties. In\nparticular, we show that a measure that we call adjusted homophily satisfies\nmore desirable properties than other popular homophily measures while being\nrarely used in graph machine learning literature. Then, we go beyond the\nhomophily-heterophily dichotomy and propose a new characteristic that allows\none to further distinguish different sorts of heterophily. The proposed label\ninformativeness (LI) characterizes how much information a neighbor's label\nprovides about a node's label. We prove that this measure satisfies important\ndesirable properties. We also observe empirically that LI better agrees with\nGNN performance compared to homophily measures, which confirms that it is a\nuseful characteristic of the graph structure.",
          "link": "http://arxiv.org/abs/2209.06177",
          "publishedOn": "2023-11-07T00:44:08.204Z",
          "wordCount": null,
          "title": "Characterizing Graph Datasets for Node Classification: Homophily-Heterophily Dichotomy and Beyond. (arXiv:2209.06177v3 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ingvarsson_G/0/1/0/all/0/1\">Gar&#xf0;ar Ingvarsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samvelyan_M/0/1/0/all/0/1\">Mikayel Samvelyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_B/0/1/0/all/0/1\">Bryan Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flageat_M/0/1/0/all/0/1\">Manon Flageat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cully_A/0/1/0/all/0/1\">Antoine Cully</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1\">Tim Rockt&#xe4;schel</a>",
          "description": "In many real-world systems, such as adaptive robotics, achieving a single,\noptimised solution may be insufficient. Instead, a diverse set of\nhigh-performing solutions is often required to adapt to varying contexts and\nrequirements. This is the realm of Quality-Diversity (QD), which aims to\ndiscover a collection of high-performing solutions, each with their own unique\ncharacteristics. QD methods have recently seen success in many domains,\nincluding robotics, where they have been used to discover damage-adaptive\nlocomotion controllers. However, most existing work has focused on single-agent\nsettings, despite many tasks of interest being multi-agent. To this end, we\nintroduce Mix-ME, a novel multi-agent variant of the popular MAP-Elites\nalgorithm that forms new solutions using a crossover-like operator by mixing\ntogether agents from different teams. We evaluate the proposed methods on a\nvariety of partially observable continuous control tasks. Our evaluation shows\nthat these multi-agent variants obtained by Mix-ME not only compete with\nsingle-agent baselines but also often outperform them in multi-agent settings\nunder partial observability.",
          "link": "http://arxiv.org/abs/2311.01829",
          "publishedOn": "2023-11-07T00:44:08.203Z",
          "wordCount": null,
          "title": "Mix-ME: Quality-Diversity for Multi-Agent Learning. (arXiv:2311.01829v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.02000",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hong_Y/0/1/0/all/0/1\">Yusu Hong</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lin_J/0/1/0/all/0/1\">Junhong Lin</a>",
          "description": "In this paper, we study the convergence of the Adaptive Moment Estimation\n(Adam) algorithm under unconstrained non-convex smooth stochastic\noptimizations. Despite the widespread usage in machine learning areas, its\ntheoretical properties remain limited. Prior researches primarily investigated\nAdam's convergence from an expectation view, often necessitating strong\nassumptions like uniformly stochastic bounded gradients or problem-dependent\nknowledge in prior. As a result, the applicability of these findings in\npractical real-world scenarios has been constrained. To overcome these\nlimitations, we provide a deep analysis and show that Adam could converge to\nthe stationary point in high probability with a rate of $\\mathcal{O}\\left({\\rm\npoly}(\\log T)/\\sqrt{T}\\right)$ under coordinate-wise \"affine\" variance noise,\nnot requiring any bounded gradient assumption and any problem-dependent\nknowledge in prior to tune hyper-parameters. Additionally, it is revealed that\nAdam confines its gradients' magnitudes within an order of\n$\\mathcal{O}\\left({\\rm poly}(\\log T)\\right)$. Finally, we also investigate a\nsimplified version of Adam without one of the corrective terms and obtain a\nconvergence rate that is adaptive to the noise level.",
          "link": "http://arxiv.org/abs/2311.02000",
          "publishedOn": "2023-11-07T00:44:08.203Z",
          "wordCount": null,
          "title": "High Probability Convergence of Adam Under Unbounded Gradients and Affine Variance Noise. (arXiv:2311.02000v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.02002",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Maskan_H/0/1/0/all/0/1\">Hoomaan Maskan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zygalakis_K/0/1/0/all/0/1\">Konstantinos C. Zygalakis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yurtsever_A/0/1/0/all/0/1\">Alp Yurtsever</a>",
          "description": "We consider unconstrained minimization of smooth convex functions. We propose\na novel variational perspective using forced Euler-Lagrange equation that\nallows for studying high-resolution ODEs. Through this, we obtain a faster\nconvergence rate for gradient norm minimization using Nesterov's accelerated\ngradient method. Additionally, we show that Nesterov's method can be\ninterpreted as a rate-matching discretization of an appropriately chosen\nhigh-resolution ODE. Finally, using the results from the new variational\nperspective, we propose a stochastic method for noisy gradients. Several\nnumerical experiments compare and illustrate our stochastic algorithm with\nstate of the art methods.",
          "link": "http://arxiv.org/abs/2311.02002",
          "publishedOn": "2023-11-07T00:44:08.203Z",
          "wordCount": null,
          "title": "A Variational Perspective on High-Resolution ODEs. (arXiv:2311.02002v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01722",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Desai_A/0/1/0/all/0/1\">Aditya Desai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meisburger_B/0/1/0/all/0/1\">Benjamin Meisburger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zichang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1\">Anshumali Shrivastava</a>",
          "description": "Recommendation systems (RS) for items (e.g., movies, books) and ads are\nwidely used to tailor content to users on various internet platforms.\nTraditionally, recommendation models are trained on a central server. However,\ndue to rising concerns for data privacy and regulations like the GDPR,\nfederated learning is an increasingly popular paradigm in which data never\nleaves the client device. Applying federated learning to recommendation models\nis non-trivial due to large embedding tables, which often exceed the memory\nconstraints of most user devices. To include data from all devices in federated\nlearning, we must enable collective training of embedding tables on devices\nwith heterogeneous memory capacities. Current solutions to heterogeneous\nfederated learning can only accommodate a small range of capacities and thus\nlimit the number of devices that can participate in training. We present\nFederated Averaging in Random subspaces (FAIR), which allows arbitrary\ncompression of embedding tables based on device capacity and ensures the\nparticipation of all devices in training. FAIR uses what we call consistent and\ncollapsible subspaces defined by hashing-based random projections to jointly\ntrain large embedding tables while using varying amounts of compression on user\ndevices. We evaluate FAIR on Neural Collaborative Filtering tasks with multiple\ndatasets and verify that FAIR can gather and share information from a wide\nrange of devices with varying capacities, allowing for seamless collaboration.\nWe prove the convergence of FAIR in the homogeneous setting with non-i.i.d data\ndistribution. Our code is open source at {https://github.com/apd10/FLCF}",
          "link": "http://arxiv.org/abs/2311.01722",
          "publishedOn": "2023-11-07T00:44:08.202Z",
          "wordCount": null,
          "title": "Heterogeneous federated collaborative filtering using FAIR: Federated Averaging in Random Subspaces. (arXiv:2311.01722v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.12247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brack_M/0/1/0/all/0/1\">Manuel Brack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedrich_F/0/1/0/all/0/1\">Felix Friedrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hintersdorf_D/0/1/0/all/0/1\">Dominik Hintersdorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Struppek_L/0/1/0/all/0/1\">Lukas Struppek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schramowski_P/0/1/0/all/0/1\">Patrick Schramowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>",
          "description": "Text-to-image diffusion models have recently received a lot of interest for\ntheir astonishing ability to produce high-fidelity images from text only.\nHowever, achieving one-shot generation that aligns with the user's intent is\nnearly impossible, yet small changes to the input prompt often result in very\ndifferent images. This leaves the user with little semantic control. To put the\nuser in control, we show how to interact with the diffusion process to flexibly\nsteer it along semantic directions. This semantic guidance (SEGA) generalizes\nto any generative architecture using classifier-free guidance. More\nimportantly, it allows for subtle and extensive edits, changes in composition\nand style, as well as optimizing the overall artistic conception. We\ndemonstrate SEGA's effectiveness on both latent and pixel-based diffusion\nmodels such as Stable Diffusion, Paella, and DeepFloyd-IF using a variety of\ntasks, thus providing strong evidence for its versatility, flexibility, and\nimprovements over existing methods.",
          "link": "http://arxiv.org/abs/2301.12247",
          "publishedOn": "2023-11-07T00:44:08.202Z",
          "wordCount": null,
          "title": "SEGA: Instructing Text-to-Image Models using Semantic Guidance. (arXiv:2301.12247v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.04370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_K/0/1/0/all/0/1\">Kai Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jianchao Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Juntao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zelong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "Human Intelligence (HI) excels at combining basic skills to solve complex\ntasks. This capability is vital for Artificial Intelligence (AI) and should be\nembedded in comprehensive AI Agents, enabling them to harness expert models for\ncomplex task-solving towards Artificial General Intelligence (AGI). Large\nLanguage Models (LLMs) show promising learning and reasoning abilities, and can\neffectively use external models, tools, plugins, or APIs to tackle complex\nproblems. In this work, we introduce OpenAGI, an open-source AGI research and\ndevelopment platform designed for solving multi-step, real-world tasks.\nSpecifically, OpenAGI uses a dual strategy, integrating standard benchmark\ntasks for benchmarking and evaluation, and open-ended tasks including more\nexpandable models, tools, plugins, or APIs for creative problem-solving. Tasks\nare presented as natural language queries to the LLM, which then selects and\nexecutes appropriate models. We also propose a Reinforcement Learning from Task\nFeedback (RLTF) mechanism that uses task results to improve the LLM's\ntask-solving ability, which creates a self-improving AI feedback loop. While we\nacknowledge that AGI is a broad and multifaceted research challenge with no\nsingularly defined solution path, the integration of LLMs with domain-specific\nexpert models, inspired by mirroring the blend of general and specialized\nintelligence in humans, offers a promising approach towards AGI. We are\nopen-sourcing the OpenAGI project's code, dataset, benchmarks, evaluation\nmethods, and the UI demo to foster community involvement in AGI advancement:\nhttps://github.com/agiresearch/OpenAGI.",
          "link": "http://arxiv.org/abs/2304.04370",
          "publishedOn": "2023-11-07T00:44:08.201Z",
          "wordCount": null,
          "title": "OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v6 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17584",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cipriani_C/0/1/0/all/0/1\">Cristina Cipriani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Scagliotti_A/0/1/0/all/0/1\">Alessandro Scagliotti</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wohrer_T/0/1/0/all/0/1\">Tobias W&#xf6;hrer</a>",
          "description": "In this paper, we address the adversarial training of neural ODEs from a\nrobust control perspective. This is an alternative to the classical training\nvia empirical risk minimization, and it is widely used to enforce reliable\noutcomes for input perturbations. Neural ODEs allow the interpretation of deep\nneural networks as discretizations of control systems, unlocking powerful tools\nfrom control theory for the development and the understanding of machine\nlearning. In this specific case, we formulate the adversarial training with\nperturbed data as a minimax optimal control problem, for which we derive first\norder optimality conditions in the form of Pontryagin's Maximum Principle. We\nprovide a novel interpretation of robust training leading to an alternative\nweighted technique, which we test on a low-dimensional classification task.",
          "link": "http://arxiv.org/abs/2310.17584",
          "publishedOn": "2023-11-07T00:44:08.201Z",
          "wordCount": null,
          "title": "A minimax optimal control approach for robust neural ODEs. (arXiv:2310.17584v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01476",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lin_F/0/1/0/all/0/1\">Fangyuan Lin</a>",
          "description": "A stochastic process that arises by composing a function with a Markov\nprocess is called an aggregated Markov process (AMP). The purpose of composing\na Markov process with a function can be a reduction of dimensions, e.g., a\nprojection onto certain coordinates. The theory around AMP has been extensively\nstudied e.g. by Dynkin, Cameron, Rogers and Pitman, and Kelly, all of whom\nprovided sufficient conditions for an AMP to remain Markov. In another\ndirection, Larget provided a canonical representation for AMP, which can be\nused to verify the equivalence of two AMPs. The purpose of this paper is to\ndescribe how the theory of AMP can be applied to stochastic learning theory as\nthey learn a particular task.",
          "link": "http://arxiv.org/abs/2311.01476",
          "publishedOn": "2023-11-07T00:44:08.185Z",
          "wordCount": null,
          "title": "Applications of the Theory of Aggregated Markov Processes in Stochastic Learning Theory. (arXiv:2311.01476v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01698",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_J/0/1/0/all/0/1\">Jinhang Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuchuang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Cheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1\">John C.S. Lui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1\">Mohammad Hajiesmaili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1\">Adam Wierman</a>",
          "description": "Cooperative multi-agent multi-armed bandits (CMA2B) consider the\ncollaborative efforts of multiple agents in a shared multi-armed bandit game.\nWe study latent vulnerabilities exposed by this collaboration and consider\nadversarial attacks on a few agents with the goal of influencing the decisions\nof the rest. More specifically, we study adversarial attacks on CMA2B in both\nhomogeneous settings, where agents operate with the same arm set, and\nheterogeneous settings, where agents have distinct arm sets. In the homogeneous\nsetting, we propose attack strategies that, by targeting just one agent,\nconvince all agents to select a particular target arm $T-o(T)$ times while\nincurring $o(T)$ attack costs in $T$ rounds. In the heterogeneous setting, we\nprove that a target arm attack requires linear attack costs and propose attack\nstrategies that can force a maximum number of agents to suffer linear regrets\nwhile incurring sublinear costs and only manipulating the observations of a few\ntarget agents. Numerical experiments validate the effectiveness of our proposed\nattack strategies.",
          "link": "http://arxiv.org/abs/2311.01698",
          "publishedOn": "2023-11-07T00:44:08.184Z",
          "wordCount": null,
          "title": "Adversarial Attacks on Cooperative Multi-agent Bandits. (arXiv:2311.01698v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kaiqiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullah_M/0/1/0/all/0/1\">Muhammad Asad Ullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alves_H/0/1/0/all/0/1\">Hirley Alves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikhaylov_K/0/1/0/all/0/1\">Konstantin Mikhaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_T/0/1/0/all/0/1\">Tong Hao</a>",
          "description": "The integration of subterranean LoRaWAN and non-terrestrial networks (NTN)\ndelivers substantial economic and societal benefits in remote agriculture and\ndisaster rescue operations. The LoRa modulation leverages quasi-orthogonal\nspreading factors (SFs) to optimize data rates, airtime, coverage and energy\nconsumption. However, it is still challenging to effectively assign SFs to end\ndevices for minimizing co-SF interference in massive subterranean LoRaWAN NTN.\nTo address this, we investigate a reinforcement learning (RL)-based SFs\nallocation scheme to optimize the system's energy efficiency (EE). To\nefficiently capture the device-to-environment interactions in dense networks,\nwe proposed an SFs allocation technique using the multi-agent dueling double\ndeep Q-network (MAD3QN) and the multi-agent advantage actor-critic (MAA2C)\nalgorithms based on an analytical reward mechanism. Our proposed RL-based SFs\nallocation approach evinces better performance compared to four benchmarks in\nthe extreme underground direct-to-satellite scenario. Remarkably, MAD3QN shows\npromising potentials in surpassing MAA2C in terms of convergence rate and EE.",
          "link": "http://arxiv.org/abs/2311.01743",
          "publishedOn": "2023-11-07T00:44:08.183Z",
          "wordCount": null,
          "title": "Energy Efficiency Optimization for Subterranean LoRaWAN Using A Reinforcement Learning Approach: A Direct-to-Satellite Scenario. (arXiv:2311.01743v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Bobby He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1\">Thomas Hofmann</a>",
          "description": "A simple design recipe for deep Transformers is to compose identical building\nblocks. But standard transformer blocks are far from simple, interweaving\nattention and MLP sub-blocks with skip connections & normalisation layers in\nprecise arrangements. This complexity leads to brittle architectures, where\nseemingly minor changes can significantly reduce training speed, or render\nmodels untrainable.\n\nIn this work, we ask to what extent the standard transformer block can be\nsimplified? Combining signal propagation theory and empirical observations, we\nmotivate modifications that allow many block components to be removed with no\nloss of training speed, including skip connections, projection or value\nparameters, sequential sub-blocks and normalisation layers. In experiments on\nboth autoregressive decoder-only and BERT encoder-only models, our simplified\ntransformers emulate the per-update training speed and performance of standard\ntransformers, while enjoying 15% faster training throughput, and using 15%\nfewer parameters.",
          "link": "http://arxiv.org/abs/2311.01906",
          "publishedOn": "2023-11-07T00:44:08.183Z",
          "wordCount": null,
          "title": "Simplifying Transformer Blocks. (arXiv:2311.01906v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lopardo_G/0/1/0/all/0/1\">Gianluigi Lopardo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precioso_F/0/1/0/all/0/1\">Frederic Precioso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garreau_D/0/1/0/all/0/1\">Damien Garreau</a>",
          "description": "Interpretability is essential for machine learning models to be trusted and\ndeployed in critical domains. However, existing methods for interpreting text\nmodels are often complex, lack solid mathematical foundations, and their\nperformance is not guaranteed. In this paper, we propose FRED (Faithful and\nRobust Explainer for textual Documents), a novel method for interpreting\npredictions over text. FRED identifies key words in a document that\nsignificantly impact the prediction when removed. We establish the reliability\nof FRED through formal definitions and theoretical analyses on interpretable\nclassifiers. Additionally, our empirical evaluation against state-of-the-art\nmethods demonstrates the effectiveness of FRED in providing insights into text\nmodels.",
          "link": "http://arxiv.org/abs/2311.01605",
          "publishedOn": "2023-11-07T00:44:08.182Z",
          "wordCount": null,
          "title": "Faithful and Robust Local Interpretability for Textual Predictions. (arXiv:2311.01605v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruisong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jin Zhang</a>",
          "description": "We propose a new class of physics-informed neural networks, called\nPhysics-Informed Generator-Encoder Adversarial Networks, to effectively address\nthe challenges posed by forward, inverse, and mixed problems in stochastic\ndifferential equations. In these scenarios, while the governing equations are\nknown, the available data consist of only a limited set of snapshots for system\nparameters. Our model consists of two key components: the generator and the\nencoder, both updated alternately by gradient descent. In contrast to previous\napproaches of directly matching the approximated solutions with real snapshots,\nwe employ an indirect matching that operates within the lower-dimensional\nlatent feature space. This method circumvents challenges associated with\nhigh-dimensional inputs and complex data distributions, while yielding more\naccurate solutions compared to existing neural network solvers. In addition,\nthe approach also mitigates the training instability issues encountered in\nprevious adversarial frameworks in an efficient manner. Numerical results\nprovide compelling evidence of the effectiveness of the proposed method in\nsolving different types of stochastic differential equations.",
          "link": "http://arxiv.org/abs/2311.01708",
          "publishedOn": "2023-11-07T00:44:08.182Z",
          "wordCount": null,
          "title": "Physics-Informed Generator-Encoder Adversarial Networks with Latent Space Matching for Stochastic Differential Equations. (arXiv:2311.01708v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wasserman_I/0/1/0/all/0/1\">Isaac Wasserman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neto_J/0/1/0/all/0/1\">Jeova Farias Sales Rocha Neto</a>",
          "description": "Unsupervised image segmentation aims at grouping different semantic patterns\nin an image without the use of human annotation. Similarly, image clustering\nsearches for groupings of images based on their semantic content without\nsupervision. Classically, both problems have captivated researchers as they\ndrew from sound mathematical concepts to produce concrete applications. With\nthe emergence of deep learning, the scientific community turned its attention\nto complex neural network-based solvers that achieved impressive results in\nthose domains but rarely leveraged the advances made by classical methods. In\nthis work, we propose a patch-based unsupervised image segmentation strategy\nthat bridges advances in unsupervised feature extraction from deep clustering\nmethods with the algorithmic help of classical graph-based methods. We show\nthat a simple convolutional neural network, trained to classify image patches\nand iteratively regularized using graph cuts, naturally leads to a\nstate-of-the-art fully-convolutional unsupervised pixel-level segmenter.\nFurthermore, we demonstrate that this is the ideal setting for leveraging the\npatch-level pairwise features generated by vision transformer models. Our\nresults on real image data demonstrate the effectiveness of our proposed\nmethodology.",
          "link": "http://arxiv.org/abs/2311.01475",
          "publishedOn": "2023-11-07T00:44:08.181Z",
          "wordCount": null,
          "title": "Patch-Based Deep Unsupervised Image Segmentation using Graph Cuts. (arXiv:2311.01475v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01489",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bica_I/0/1/0/all/0/1\">Ioana Bica</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jarrett_D/0/1/0/all/0/1\">Daniel Jarrett</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Consider learning an imitation policy on the basis of demonstrated behavior\nfrom multiple environments, with an eye towards deployment in an unseen\nenvironment. Since the observable features from each setting may be different,\ndirectly learning individual policies as mappings from features to actions is\nprone to spurious correlations -- and may not generalize well. However, the\nexpert's policy is often a function of a shared latent structure underlying\nthose observable features that is invariant across settings. By leveraging data\nfrom multiple environments, we propose Invariant Causal Imitation Learning\n(ICIL), a novel technique in which we learn a feature representation that is\ninvariant across domains, on the basis of which we learn an imitation policy\nthat matches expert behavior. To cope with transition dynamics mismatch, ICIL\nlearns a shared representation of causal features (for all training\nenvironments), that is disentangled from the specific representations of noise\nvariables (for each of those environments). Moreover, to ensure that the\nlearned policy matches the observation distribution of the expert's policy,\nICIL estimates the energy of the expert's observations and uses a\nregularization term that minimizes the imitator policy's next state energy.\nExperimentally, we compare our methods against several benchmarks in control\nand healthcare tasks and show its effectiveness in learning imitation policies\ncapable of generalizing to unseen environments.",
          "link": "http://arxiv.org/abs/2311.01489",
          "publishedOn": "2023-11-07T00:44:08.181Z",
          "wordCount": null,
          "title": "Invariant Causal Imitation Learning for Generalizable Policies. (arXiv:2311.01489v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dammu_P/0/1/0/all/0/1\">Preetam Prabhu Srikar Dammu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_C/0/1/0/all/0/1\">Chirag Shah</a>",
          "description": "Often machine learning models tend to automatically learn associations\npresent in the training data without questioning their validity or\nappropriateness. This undesirable property is the root cause of the\nmanifestation of spurious correlations, which render models unreliable and\nprone to failure in the presence of distribution shifts. Research shows that\nmost methods attempting to remedy spurious correlations are only effective for\na model's known spurious associations. Current spurious correlation detection\nalgorithms either rely on extensive human annotations or are too restrictive in\ntheir formulation. Moreover, they rely on strict definitions of visual\nartifacts that may not apply to data produced by generative models, as they are\nknown to hallucinate contents that do not conform to standard specifications.\nIn this work, we introduce a general-purpose method that efficiently detects\npotential spurious correlations, and requires significantly less human\ninterference in comparison to the prior art. Additionally, the proposed method\nprovides intuitive explanations while eliminating the need for pixel-level\nannotations. We demonstrate the proposed method's tolerance to the peculiarity\nof AI-generated images, which is a considerably challenging task, one where\nmost of the existing methods fall short. Consequently, our method is also\nsuitable for detecting spurious correlations that may propagate to downstream\napplications originating from generative models.",
          "link": "http://arxiv.org/abs/2311.01655",
          "publishedOn": "2023-11-07T00:44:08.181Z",
          "wordCount": null,
          "title": "Detecting Spurious Correlations via Robust Visual Concepts in Real and AI-Generated Image Classification. (arXiv:2311.01655v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_M/0/1/0/all/0/1\">Muhammad Aurangzeb Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yaramis_I/0/1/0/all/0/1\">Ilker Yaramis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_T/0/1/0/all/0/1\">Taposh Dutta Roy</a>",
          "description": "Large language models have proliferated across multiple domains in as short\nperiod of time. There is however hesitation in the medical and healthcare\ndomain towards their adoption because of issues like factuality, coherence, and\nhallucinations. Give the high stakes nature of healthcare, many researchers\nhave even cautioned against its usage until these issues are resolved. The key\nto the implementation and deployment of LLMs in healthcare is to make these\nmodels trustworthy, transparent (as much possible) and explainable. In this\npaper we describe the key elements in creating reliable, trustworthy, and\nunbiased models as a necessary condition for their adoption in healthcare.\nSpecifically we focus on the quantification, validation, and mitigation of\nhallucinations in the context in healthcare. Lastly, we discuss how the future\nof LLMs in healthcare may look like.",
          "link": "http://arxiv.org/abs/2311.01463",
          "publishedOn": "2023-11-07T00:44:08.180Z",
          "wordCount": null,
          "title": "Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI. (arXiv:2311.01463v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vinella_A/0/1/0/all/0/1\">Avalon Vinella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Capetz_M/0/1/0/all/0/1\">Margaret Capetz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pattichis_R/0/1/0/all/0/1\">Rebecca Pattichis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chance_C/0/1/0/all/0/1\">Christina Chance</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1\">Reshmi Ghosh</a>",
          "description": "In recent years, climate change repercussions have increasingly captured\npublic interest. Consequently, corporations are emphasizing their environmental\nefforts in sustainability reports to bolster their public image. Yet, the\nabsence of stringent regulations in review of such reports allows potential\ngreenwashing. In this study, we introduce a novel methodology to train a\nlanguage model on generated labels for greenwashing risk. Our primary\ncontributions encompass: developing a mathematical formulation to quantify\ngreenwashing risk, a fine-tuned ClimateBERT model for this problem, and a\ncomparative analysis of results. On a test set comprising of sustainability\nreports, our best model achieved an average accuracy score of 86.34% and F1\nscore of 0.67, demonstrating that our methods show a promising direction of\nexploration for this task.",
          "link": "http://arxiv.org/abs/2311.01469",
          "publishedOn": "2023-11-07T00:44:08.180Z",
          "wordCount": null,
          "title": "Leveraging Language Models to Detect Greenwashing. (arXiv:2311.01469v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meshkinnejad_R/0/1/0/all/0/1\">Rouzbeh Meshkinnejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_J/0/1/0/all/0/1\">Jie Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lizotte_D/0/1/0/all/0/1\">Daniel Lizotte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohsenzadeh_Y/0/1/0/all/0/1\">Yalda Mohsenzadeh</a>",
          "description": "Contrastive representation learning has emerged as a promising technique for\ncontinual learning as it can learn representations that are robust to\ncatastrophic forgetting and generalize well to unseen future tasks. Previous\nwork in continual learning has addressed forgetting by using previous task data\nand trained models. Inspired by event models created and updated in the brain,\nwe propose a new mechanism that takes place during task boundaries, i.e., when\none task finishes and another starts. By observing the redundancy-inducing\nability of contrastive loss on the output of a neural network, our method\nleverages the first few samples of the new task to identify and retain\nparameters contributing most to the transfer ability of the neural network,\nfreeing up the remaining parts of the network to learn new features. We\nevaluate the proposed methods on benchmark computer vision datasets including\nCIFAR10 and TinyImagenet and demonstrate state-of-the-art performance in the\ntask-incremental, class-incremental, and domain-incremental continual learning\nscenarios.",
          "link": "http://arxiv.org/abs/2311.01617",
          "publishedOn": "2023-11-07T00:44:08.179Z",
          "wordCount": null,
          "title": "Look-Ahead Selective Plasticity for Continual Learning of Visual Tasks. (arXiv:2311.01617v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yangxi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Junping Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zhe Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1\">Zhenhui Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weikang Chen</a>",
          "description": "Epidemic decision-making can effectively help the government to\ncomprehensively consider public security and economic development to respond to\npublic health and safety emergencies. Epidemic decision-making can effectively\nhelp the government to comprehensively consider public security and economic\ndevelopment to respond to public health and safety emergencies. Some studies\nhave shown that intensive learning can effectively help the government to make\nepidemic decision, thus achieving the balance between health security and\neconomic development. Some studies have shown that intensive learning can\neffectively help the government to make epidemic decision, thus achieving the\nbalance between health security and economic development. However, epidemic\ndata often has the characteristics of limited samples and high privacy.\nHowever, epidemic data often has the characteristics of limited samples and\nhigh privacy. This model can combine the epidemic situation data of various\nprovinces for cooperative training to use as an enhanced learning model for\nepidemic situation decision, while protecting the privacy of data. The\nexperiment shows that the enhanced federated learning can obtain more optimized\nperformance and return than the enhanced learning, and the enhanced federated\nlearning can also accelerate the training convergence speed of the training\nmodel. accelerate the training convergence speed of the client. At the same\ntime, through the experimental comparison, A2C is the most suitable\nreinforcement learning model for the epidemic situation decision-making.\nlearning model for the epidemic situation decision-making scenario, followed by\nthe PPO model, and the performance of DDPG is unsatisfactory.",
          "link": "http://arxiv.org/abs/2311.01749",
          "publishedOn": "2023-11-07T00:44:08.179Z",
          "wordCount": null,
          "title": "Epidemic Decision-making System Based Federated Reinforcement Learning. (arXiv:2311.01749v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deiseroth_B/0/1/0/all/0/1\">Bj&#xf6;rn Deiseroth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meuer_M/0/1/0/all/0/1\">Max Meuer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gritsch_N/0/1/0/all/0/1\">Nikolas Gritsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eichenberg_C/0/1/0/all/0/1\">Constantin Eichenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schramowski_P/0/1/0/all/0/1\">Patrick Schramowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assenmacher_M/0/1/0/all/0/1\">Matthias A&#xdf;enmacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>",
          "description": "Large Language Models (LLMs) have reshaped natural language processing with\ntheir impressive capabilities. Their ever-increasing size, however, raised\nconcerns about their effective deployment and the need for LLM compressions.\nThis study introduces the Divergent Token metrics (DTMs), a novel approach for\nassessing compressed LLMs, addressing the limitations of traditional measures\nlike perplexity that fail to accurately reflect text generation quality. DTMs\nfocus on token divergence, providing deeper insights into the subtleties of\nmodel compression. Our results indicate that significant levels of precision\nand sparsity can be achieved without compromising text generation quality.\nMoreover, DTMs offers a more precise evaluation of each component's impact\nindividually. Utilizing the First Divergent Token metric (FDTM) in model\nsparsification reveals that nearly 20% of all components can be pruned over\n90%. In terms of quantization, the FDTM suggests that over 80% of parameters\ncan be straightforwardly transformed to int8 without special outlier\nmanagement.",
          "link": "http://arxiv.org/abs/2311.01544",
          "publishedOn": "2023-11-07T00:44:08.178Z",
          "wordCount": null,
          "title": "Divergent Token Metrics: Measuring degradation to prune away LLM components -- and optimize quantization. (arXiv:2311.01544v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01473",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiakai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Donghua Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Siyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1\">Tingsong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Wen Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Aishan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xianglong Liu</a>",
          "description": "Deep neural networks (DNNs) have demonstrated high vulnerability to\nadversarial examples. Besides the attacks in the digital world, the practical\nimplications of adversarial examples in the physical world present significant\nchallenges and safety concerns. However, current research on physical\nadversarial examples (PAEs) lacks a comprehensive understanding of their unique\ncharacteristics, leading to limited significance and understanding. In this\npaper, we address this gap by thoroughly examining the characteristics of PAEs\nwithin a practical workflow encompassing training, manufacturing, and\nre-sampling processes. By analyzing the links between physical adversarial\nattacks, we identify manufacturing and re-sampling as the primary sources of\ndistinct attributes and particularities in PAEs. Leveraging this knowledge, we\ndevelop a comprehensive analysis and classification framework for PAEs based on\ntheir specific characteristics, covering over 100 studies on physical-world\nadversarial examples. Furthermore, we investigate defense strategies against\nPAEs and identify open challenges and opportunities for future research. We aim\nto provide a fresh, thorough, and systematic understanding of PAEs, thereby\npromoting the development of robust adversarial learning and its application in\nopen-world scenarios.",
          "link": "http://arxiv.org/abs/2311.01473",
          "publishedOn": "2023-11-07T00:44:08.177Z",
          "wordCount": null,
          "title": "Adversarial Examples in the Physical World: A Survey. (arXiv:2311.01473v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01500",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Pandya_S/0/1/0/all/0/1\">Sneh Pandya</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Patel_P/0/1/0/all/0/1\">Purvik Patel</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+O_F/0/1/0/all/0/1\">Franc O</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Blazek_J/0/1/0/all/0/1\">Jonathan Blazek</a>",
          "description": "We propose the use of group convolutional neural network architectures\n(GCNNs) equivariant to the 2D Euclidean group, $E(2)$, for the task of galaxy\nmorphology classification by utilizing symmetries of the data present in galaxy\nimages as an inductive bias in the architecture. We conduct robustness studies\nby introducing artificial perturbations via Poisson noise insertion and\none-pixel adversarial attacks to simulate the effects of limited observational\ncapabilities. We train, validate, and test GCNNs equivariant to discrete\nsubgroups of $E(2)$ - the cyclic and dihedral groups of order $N$ - on the\nGalaxy10 DECals dataset and find that GCNNs achieve higher classification\naccuracy and are consistently more robust than their non-equivariant\ncounterparts, with an architecture equivariant to the group $D_{16}$ achieving\na $95.52 \\pm 0.18\\%$ test-set accuracy. We also find that the model loses\n$<6\\%$ accuracy on a $50\\%$-noise dataset and all GCNNs are less susceptible to\none-pixel perturbations than an identically constructed CNN. Our code is\npublicly available at https://github.com/snehjp2/GCNNMorphology.",
          "link": "http://arxiv.org/abs/2311.01500",
          "publishedOn": "2023-11-07T00:44:08.177Z",
          "wordCount": null,
          "title": "E(2) Equivariant Neural Networks for Robust Galaxy Morphology Classification. (arXiv:2311.01500v1 [astro-ph.GA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rigutini_L/0/1/0/all/0/1\">Leonardo Rigutini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papini_T/0/1/0/all/0/1\">Tiziano Papini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maggini_M/0/1/0/all/0/1\">Marco Maggini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarselli_F/0/1/0/all/0/1\">Franco Scarselli</a>",
          "description": "The problem of relevance ranking consists of sorting a set of objects with\nrespect to a given criterion. Since users may prefer different relevance\ncriteria, the ranking algorithms should be adaptable to the user needs. Two\nmain approaches exist in literature for the task of learning to rank: 1) a\nscore function, learned by examples, which evaluates the properties of each\nobject yielding an absolute relevance value that can be used to order the\nobjects or 2) a pairwise approach, where a \"preference function\" is learned\nusing pairs of objects to define which one has to be ranked first. In this\npaper, we present SortNet, an adaptive ranking algorithm which orders objects\nusing a neural network as a comparator. The neural network training set\nprovides examples of the desired ordering between pairs of items and it is\nconstructed by an iterative procedure which, at each iteration, adds the most\ninformative training examples. Moreover, the comparator adopts a connectionist\narchitecture that is particularly suited for implementing a preference\nfunction. We also prove that such an architecture has the universal\napproximation property and can implement a wide class of functions. Finally,\nthe proposed algorithm is evaluated on the LETOR dataset showing promising\nperformances in comparison with other state of the art algorithms.",
          "link": "http://arxiv.org/abs/2311.01864",
          "publishedOn": "2023-11-07T00:44:08.177Z",
          "wordCount": null,
          "title": "SortNet: Learning To Rank By a Neural-Based Sorting Algorithm. (arXiv:2311.01864v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01727",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Liao_M/0/1/0/all/0/1\">Manwen Liao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhu_Y/0/1/0/all/0/1\">Yan Zhu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Chiribella_G/0/1/0/all/0/1\">Giulio Chiribella</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Yang_Y/0/1/0/all/0/1\">Yuxiang Yang</a>",
          "description": "Neural networks have shown their effectiveness in various tasks in the realm\nof quantum computing. However, their application in quantum error mitigation, a\ncrucial step towards realizing practical quantum advancements, has been\nrestricted by reliance on noise-free statistics. To tackle this critical\nchallenge, we propose a data augmentation empowered neural model for error\nmitigation (DAEM). Our model does not require any prior knowledge about the\nspecific noise type and measurement settings and can estimate noise-free\nstatistics solely from the noisy measurement results of the target quantum\nprocess, rendering it highly suitable for practical implementation. In\nnumerical experiments, we show the model's superior performance in mitigating\nvarious types of noise, including Markovian noise and Non-Markovian noise,\ncompared with previous error mitigation methods. We further demonstrate its\nversatility by employing the model to mitigate errors in diverse types of\nquantum processes, including those involving large-scale quantum systems and\ncontinuous-variable quantum states. This powerful data augmentation-empowered\nneural model for error mitigation establishes a solid foundation for realizing\nmore reliable and robust quantum technologies in practical applications.",
          "link": "http://arxiv.org/abs/2311.01727",
          "publishedOn": "2023-11-07T00:44:08.175Z",
          "wordCount": null,
          "title": "Flexible Error Mitigation of Quantum Processes with Data Augmentation Empowered Neural Model. (arXiv:2311.01727v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yeyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dingmin Wang</a>",
          "description": "As a powerful framework for graph representation learning, Graph Neural\nNetworks (GNNs) have garnered significant attention in recent years. However,\nto the best of our knowledge, there has been no formal analysis of the logical\nexpressiveness of GNNs as Boolean node classifiers over multi-relational\ngraphs, where each edge carries a specific relation type. In this paper, we\ninvestigate $\\mathcal{FOC}_2$, a fragment of first-order logic with two\nvariables and counting quantifiers. On the negative side, we demonstrate that\nthe R$^2$-GNN architecture, which extends the local message passing GNN by\nincorporating global readout, fails to capture $\\mathcal{FOC}_2$ classifiers in\nthe general case. Nevertheless, on the positive side, we establish that\nR$^2$-GNNs models are equivalent to $\\mathcal{FOC}_2$ classifiers under certain\nrestricted yet reasonable scenarios. To address the limitations of R$^2$-GNNs\nregarding expressiveness, we propose a simple graph transformation technique,\nakin to a preprocessing step, which can be executed in linear time. This\ntransformation enables R$^2$-GNNs to effectively capture any $\\mathcal{FOC}_2$\nclassifiers when applied to the \"transformed\" input graph. Moreover, we extend\nour analysis of expressiveness and graph transformation to temporal graphs,\nexploring several temporal GNN architectures and providing an expressiveness\nhierarchy for them. To validate our findings, we implement R$^2$-GNNs and the\ngraph transformation technique and conduct empirical tests in node\nclassification tasks against various well-known GNN architectures that support\nmulti-relational or temporal graphs. Our experimental results consistently\ndemonstrate that R$^2$-GNN with the graph transformation outperforms the\nbaseline methods on both synthetic and real-world datasets",
          "link": "http://arxiv.org/abs/2311.01647",
          "publishedOn": "2023-11-07T00:44:08.174Z",
          "wordCount": null,
          "title": "Calibrate and Boost Logical Expressiveness of GNN Over Multi-Relational and Temporal Graphs. (arXiv:2311.01647v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01588",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Roncoli_A/0/1/0/all/0/1\">Andrea Roncoli</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ciprijanovic_A/0/1/0/all/0/1\">Aleksandra &#x106;iprijanovi&#x107;</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Voetberg_M/0/1/0/all/0/1\">Maggie Voetberg</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Villaescusa_Navarro_F/0/1/0/all/0/1\">Francisco Villaescusa-Navarro</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Nord_B/0/1/0/all/0/1\">Brian Nord</a>",
          "description": "Deep learning models have been shown to outperform methods that rely on\nsummary statistics, like the power spectrum, in extracting information from\ncomplex cosmological data sets. However, due to differences in the subgrid\nphysics implementation and numerical approximations across different simulation\nsuites, models trained on data from one cosmological simulation show a drop in\nperformance when tested on another. Similarly, models trained on any of the\nsimulations would also likely experience a drop in performance when applied to\nobservational data. Training on data from two different suites of the CAMELS\nhydrodynamic cosmological simulations, we examine the generalization\ncapabilities of Domain Adaptive Graph Neural Networks (DA-GNNs). By utilizing\nGNNs, we capitalize on their capacity to capture structured scale-free\ncosmological information from galaxy distributions. Moreover, by including\nunsupervised domain adaptation via Maximum Mean Discrepancy (MMD), we enable\nour models to extract domain-invariant features. We demonstrate that DA-GNN\nachieves higher accuracy and robustness on cross-dataset tasks (up to $28\\%$\nbetter relative error and up to almost an order of magnitude better $\\chi^2$).\nUsing data visualizations, we show the effects of domain adaptation on proper\nlatent space data alignment. This shows that DA-GNNs are a promising method for\nextracting domain-independent cosmological information, a vital step toward\nrobust deep learning for real cosmic survey data.",
          "link": "http://arxiv.org/abs/2311.01588",
          "publishedOn": "2023-11-07T00:44:08.173Z",
          "wordCount": null,
          "title": "Domain Adaptive Graph Neural Networks for Constraining Cosmological Parameters Across Multiple Data Sets. (arXiv:2311.01588v1 [astro-ph.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01683",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Viswanathan_M/0/1/0/all/0/1\">Malvika Viswanathan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yin_L/0/1/0/all/0/1\">Leqi Yin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kurmi_Y/0/1/0/all/0/1\">Yashwant Kurmi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zu_Z/0/1/0/all/0/1\">Zhongliang Zu</a>",
          "description": "Machine learning (ML) has been increasingly used to quantify chemical\nexchange saturation transfer (CEST) effect. ML models are typically trained\nusing either measured data or fully simulated data. However, training with\nmeasured data often lacks sufficient training data, while training with fully\nsimulated data may introduce bias due to limited simulations pools. This study\nintroduces a new platform that combines simulated and measured components to\ngenerate partially synthetic CEST data, and to evaluate its feasibility for\ntraining ML models to predict amide proton transfer (APT) effect. Partially\nsynthetic CEST signals were created using an inverse summation of APT effects\nfrom simulations and the other components from measurements. Training data were\ngenerated by varying APT simulation parameters and applying scaling factors to\nadjust the measured components, achieving a balance between simulation\nflexibility and fidelity. First, tissue-mimicking CEST signals along with\nground truth information were created using multiple-pool model simulations to\nvalidate this method. Second, an ML model was trained individually on partially\nsynthetic data, in vivo data, and fully simulated data, to predict APT effect\nin rat brains bearing 9L tumors. Experiments on tissue-mimicking data suggest\nthat the ML method using the partially synthetic data is accurate in predicting\nAPT. In vivo experiments suggest that our method provides more accurate and\nrobust prediction than the training using in vivo data and fully synthetic\ndata. Partially synthetic CEST data can address the challenges in conventional\nML methods.",
          "link": "http://arxiv.org/abs/2311.01683",
          "publishedOn": "2023-11-07T00:44:08.173Z",
          "wordCount": null,
          "title": "Amide Proton Transfer (APT) imaging in tumor with a machine learning approach using partially synthetic data. (arXiv:2311.01683v1 [physics.med-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lemkhenter_A/0/1/0/all/0/1\">Abdelhak Lemkhenter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Manchen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zancato_L/0/1/0/all/0/1\">Luca Zancato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_G/0/1/0/all/0/1\">Gurumurthy Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Favaro_P/0/1/0/all/0/1\">Paolo Favaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modolo_D/0/1/0/all/0/1\">Davide Modolo</a>",
          "description": "In this paper we introduce SemiGPC, a distribution-aware label refinement\nstrategy based on Gaussian Processes where the predictions of the model are\nderived from the labels posterior distribution. Differently from other\nbuffer-based semi-supervised methods such as CoMatch and SimMatch, our SemiGPC\nincludes a normalization term that addresses imbalances in the global data\ndistribution while maintaining local sensitivity. This explicit control allows\nSemiGPC to be more robust to confirmation bias especially under class\nimbalance. We show that SemiGPC improves performance when paired with different\nSemi-Supervised methods such as FixMatch, ReMixMatch, SimMatch and FreeMatch\nand different pre-training strategies including MSN and Dino. We also show that\nSemiGPC achieves state of the art results under different degrees of class\nimbalance on standard CIFAR10-LT/CIFAR100-LT especially in the low data-regime.\nUsing SemiGPC also results in about 2% avg.accuracy increase compared to a new\ncompetitive baseline on the more challenging benchmarks SemiAves, SemiCUB,\nSemiFungi and Semi-iNat.",
          "link": "http://arxiv.org/abs/2311.01646",
          "publishedOn": "2023-11-07T00:44:08.172Z",
          "wordCount": null,
          "title": "SemiGPC: Distribution-Aware Label Refinement for Imbalanced Semi-Supervised Learning Using Gaussian Processes. (arXiv:2311.01646v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Shubhr Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinmetz_C/0/1/0/all/0/1\">Christian J. Steinmetz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benetos_E/0/1/0/all/0/1\">Emmanouil Benetos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_H/0/1/0/all/0/1\">Huy Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stowell_D/0/1/0/all/0/1\">Dan Stowell</a>",
          "description": "Deep learning models such as CNNs and Transformers have achieved impressive\nperformance for end-to-end audio tagging. Recent works have shown that despite\nstacking multiple layers, the receptive field of CNNs remains severely limited.\nTransformers on the other hand are able to map global context through\nself-attention, but treat the spectrogram as a sequence of patches which is not\nflexible enough to capture irregular audio objects. In this work, we treat the\nspectrogram in a more flexible way by considering it as graph structure and\nprocess it with a novel graph neural architecture called ATGNN. ATGNN not only\ncombines the capability of CNNs with the global information sharing ability of\nGraph Neural Networks, but also maps semantic relationships between learnable\nclass embeddings and corresponding spectrogram regions. We evaluate ATGNN on\ntwo audio tagging tasks, where it achieves 0.585 mAP on the FSD50K dataset and\n0.335 mAP on the AudioSet-balanced dataset, achieving comparable results to\nTransformer based models with significantly lower number of learnable\nparameters.",
          "link": "http://arxiv.org/abs/2311.01526",
          "publishedOn": "2023-11-07T00:44:08.171Z",
          "wordCount": null,
          "title": "ATGNN: Audio Tagging Graph Neural Network. (arXiv:2311.01526v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01491",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Rothchild_D/0/1/0/all/0/1\">Daniel Rothchild</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rosen_A/0/1/0/all/0/1\">Andrew S. Rosen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Taw_E/0/1/0/all/0/1\">Eric Taw</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Robinson_C/0/1/0/all/0/1\">Connie Robinson</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Krishnapriyan_A/0/1/0/all/0/1\">Aditi S. Krishnapriyan</a>",
          "description": "We present an investigation into diffusion models for molecular generation,\nwith the aim of better understanding how their predictions compare to the\nresults of physics-based calculations. The investigation into these models is\ndriven by their potential to significantly accelerate electronic structure\ncalculations using machine learning, without requiring expensive\nfirst-principles datasets for training interatomic potentials. We find that the\ninference process of a popular diffusion model for de novo molecular generation\nis divided into an exploration phase, where the model chooses the atomic\nspecies, and a relaxation phase, where it adjusts the atomic coordinates to\nfind a low-energy geometry. As training proceeds, we show that the model\ninitially learns about the first-order structure of the potential energy\nsurface, and then later learns about higher-order structure. We also find that\nthe relaxation phase of the diffusion model can be re-purposed to sample the\nBoltzmann distribution over conformations and to carry out structure\nrelaxations. For structure relaxations, the model finds geometries with ~10x\nlower energy than those produced by a classical force field for small organic\nmolecules. Initializing a density functional theory (DFT) relaxation at the\ndiffusion-produced structures yields a >2x speedup to the DFT relaxation when\ncompared to initializing at structures relaxed with a classical force field.",
          "link": "http://arxiv.org/abs/2311.01491",
          "publishedOn": "2023-11-07T00:44:08.170Z",
          "wordCount": null,
          "title": "Investigating the Behavior of Diffusion Models for Accelerating Electronic Structure Calculations. (arXiv:2311.01491v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chavez_Galaviz_J/0/1/0/all/0/1\">Jalil Chavez-Galaviz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianwen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergman_M/0/1/0/all/0/1\">Matthew Bergman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mengdibayev_M/0/1/0/all/0/1\">Miras Mengdibayev</a>",
          "description": "Underwater docking is critical to enable the persistent operation of\nAutonomous Underwater Vehicles (AUVs). For this, the AUV must be capable of\ndetecting and localizing the docking station, which is complex due to the\nhighly dynamic undersea environment. Image-based solutions offer a high\nacquisition rate and versatile alternative to adapt to this environment;\nhowever, the underwater environment presents challenges such as low visibility,\nhigh turbidity, and distortion. In addition to this, field experiments to\nvalidate underwater docking capabilities can be costly and dangerous due to the\nspecialized equipment and safety considerations required to conduct the\nexperiments. This work compares different deep-learning architectures to\nperform underwater docking detection and classification. The architecture with\nthe best performance is then compressed using knowledge distillation under the\nteacher-student paradigm to reduce the network's memory footprint, allowing\nreal-time implementation. To reduce the simulation-to-reality gap, a Generative\nAdversarial Network (GAN) is used to do image-to-image translation, converting\nthe Gazebo simulation image into a realistic underwater-looking image. The\nobtained image is then processed using an underwater image formation model to\nsimulate image attenuation over distance under different water types. The\nproposed method is finally evaluated according to the AUV docking success rate\nand compared with classical vision methods. The simulation results show an\nimprovement of 20% in the high turbidity scenarios regardless of the underwater\ncurrents. Furthermore, we show the performance of the proposed approach by\nshowing experimental results on the off-the-shelf AUV Iver3.",
          "link": "http://arxiv.org/abs/2311.01522",
          "publishedOn": "2023-11-07T00:44:08.168Z",
          "wordCount": null,
          "title": "An Efficient Detection and Control System for Underwater Docking using Machine Learning and Realistic Simulation: A Comprehensive Approach. (arXiv:2311.01522v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chase_Z/0/1/0/all/0/1\">Zachary Chase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chornomaz_B/0/1/0/all/0/1\">Bogdan Chornomaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1\">Shay Moran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yehudayoff_A/0/1/0/all/0/1\">Amir Yehudayoff</a>",
          "description": "We use and adapt the Borsuk-Ulam Theorem from topology to derive limitations\non list-replicable and globally stable learning algorithms. We further\ndemonstrate the applicability of our methods in combinatorics and topology.\n\nWe show that, besides trivial cases, both list-replicable and globally stable\nlearning are impossible in the agnostic PAC setting. This is in contrast with\nthe realizable case where it is known that any class with a finite Littlestone\ndimension can be learned by such algorithms. In the realizable PAC setting, we\nsharpen previous impossibility results and broaden their scope. Specifically,\nwe establish optimal bounds for list replicability and global stability numbers\nin finite classes. This provides an exponential improvement over previous works\nand implies an exponential separation from the Littlestone dimension. We\nfurther introduce lower bounds for weak learners, i.e., learners that are only\nmarginally better than random guessing. Lower bounds from previous works apply\nonly to stronger learners.\n\nTo offer a broader and more comprehensive view of our topological approach,\nwe prove a local variant of the Borsuk-Ulam theorem in topology and a result in\ncombinatorics concerning Kneser colorings. In combinatorics, we prove that if\n$c$ is a coloring of all non-empty subsets of $[n]$ such that disjoint sets\nhave different colors, then there is a chain of subsets that receives at least\n$1+ \\lfloor n/2\\rfloor$ colors (this bound is sharp). In topology, we prove\ne.g. that for any open antipodal-free cover of the $d$-dimensional sphere,\nthere is a point $x$ that belongs to at least $t=\\lceil\\frac{d+3}{2}\\rceil$\nsets.",
          "link": "http://arxiv.org/abs/2311.01599",
          "publishedOn": "2023-11-07T00:44:08.168Z",
          "wordCount": null,
          "title": "Local Borsuk-Ulam, Stability, and Replicability. (arXiv:2311.01599v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.11957",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Zhao_G/0/1/0/all/0/1\">Guangyuan Zhao</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shu_X/0/1/0/all/0/1\">Xin Shu</a>",
          "description": "Optical computing systems can provide high-speed and low-energy data\nprocessing but face deficiencies in computationally demanding training and\nsimulation-to-reality gap. We propose a model-free solution for lightweight in\nsitu optimization of optical computing systems based on the score gradient\nestimation algorithm. This approach treats the system as a black box and\nback-propagates loss directly to the optical weights' probabilistic\ndistributions, hence circumventing the need for computation-heavy and biased\nsystem simulation. We demonstrate a superior classification accuracy on the\nMNIST and FMNIST datasets through experiments on a single-layer diffractive\noptical computing system. Furthermore, we show its potential for image-free and\nhigh-speed cell analysis. The inherent simplicity of our proposed method,\ncombined with its low demand for computational resources, expedites the\ntransition of optical computing from laboratory demonstrations to real-world\napplications.",
          "link": "http://arxiv.org/abs/2307.11957",
          "publishedOn": "2023-11-07T00:44:08.140Z",
          "wordCount": 666,
          "title": "High-performance real-world optical computing trained by in situ model-free optimization. (arXiv:2307.11957v3 [physics.optics] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.15457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wei-Chao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1\">Tan-Ha Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hsuan-Tien Lin</a>",
          "description": "Given imbalanced data, it is hard to train a good classifier using deep\nlearning because of the poor generalization of minority classes. Traditionally,\nthe well-known synthetic minority oversampling technique (SMOTE) for data\naugmentation, a data mining approach for imbalanced learning, has been used to\nimprove this generalization. However, it is unclear whether SMOTE also benefits\ndeep learning. In this work, we study why the original SMOTE is insufficient\nfor deep learning, and enhance SMOTE using soft labels. Connecting the\nresulting soft SMOTE with Mixup, a modern data augmentation technique, leads to\na unified framework that puts traditional and modern data augmentation\ntechniques under the same umbrella. A careful study within this framework shows\nthat Mixup improves generalization by implicitly achieving uneven margins\nbetween majority and minority classes. We then propose a novel margin-aware\nMixup technique that more explicitly achieves uneven margins. Extensive\nexperimental results demonstrate that our proposed technique yields\nstate-of-the-art performance on deep imbalanced classification while achieving\nsuperior performance on extremely imbalanced data. The code is open-sourced in\nour developed package https://github.com/ntucllab/imbalanced-DL to foster\nfuture research in this direction.",
          "link": "http://arxiv.org/abs/2308.15457",
          "publishedOn": "2023-11-07T00:44:08.127Z",
          "wordCount": null,
          "title": "From SMOTE to Mixup for Deep Imbalanced Classification. (arXiv:2308.15457v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zharmagambetov_A/0/1/0/all/0/1\">Arman Zharmagambetov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amos_B/0/1/0/all/0/1\">Brandon Amos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferber_A/0/1/0/all/0/1\">Aaron Ferber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Taoan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1\">Bistra Dilkina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>",
          "description": "Recent works in learning-integrated optimization have shown promise in\nsettings where the optimization problem is only partially observed or where\ngeneral-purpose optimizers perform poorly without expert tuning. By learning an\noptimizer $\\mathbf{g}$ to tackle these challenging problems with $f$ as the\nobjective, the optimization process can be substantially accelerated by\nleveraging past experience. The optimizer can be trained with supervision from\nknown optimal solutions or implicitly by optimizing the compound function\n$f\\circ \\mathbf{g}$. The implicit approach may not require optimal solutions as\nlabels and is capable of handling problem uncertainty; however, it is slow to\ntrain and deploy due to frequent calls to optimizer $\\mathbf{g}$ during both\ntraining and testing. The training is further challenged by sparse gradients of\n$\\mathbf{g}$, especially for combinatorial solvers. To address these\nchallenges, we propose using a smooth and learnable Landscape Surrogate $M$ as\na replacement for $f\\circ \\mathbf{g}$. This surrogate, learnable by neural\nnetworks, can be computed faster than the solver $\\mathbf{g}$, provides dense\nand smooth gradients during training, can generalize to unseen optimization\nproblems, and is efficiently learned via alternating optimization. We test our\napproach on both synthetic problems, including shortest path and\nmultidimensional knapsack, and real-world problems such as portfolio\noptimization, achieving comparable or superior objective values compared to\nstate-of-the-art baselines while reducing the number of calls to $\\mathbf{g}$.\nNotably, our approach outperforms existing methods for computationally\nexpensive high-dimensional problems.",
          "link": "http://arxiv.org/abs/2307.08964",
          "publishedOn": "2023-11-07T00:44:08.118Z",
          "wordCount": 772,
          "title": "Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information. (arXiv:2307.08964v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.00424",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kone_C/0/1/0/all/0/1\">Cyrille Kone</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaufmann_E/0/1/0/all/0/1\">Emilie Kaufmann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Richert_L/0/1/0/all/0/1\">Laura Richert</a>",
          "description": "In this paper we revisit the fixed-confidence identification of the Pareto\noptimal set in a multi-objective multi-armed bandit model. As the sample\ncomplexity to identify the exact Pareto set can be very large, a relaxation\nallowing to output some additional near-optimal arms has been studied. In this\nwork we also tackle alternative relaxations that allow instead to identify a\nrelevant subset of the Pareto set. Notably, we propose a single sampling\nstrategy, called Adaptive Pareto Exploration, that can be used in conjunction\nwith different stopping rules to take into account different relaxations of the\nPareto Set Identification problem. We analyze the sample complexity of these\ndifferent combinations, quantifying in particular the reduction in sample\ncomplexity that occurs when one seeks to identify at most $k$ Pareto optimal\narms. We showcase the good practical performance of Adaptive Pareto Exploration\non a real-world scenario, in which we adaptively explore several vaccination\nstrategies against Covid-19 in order to find the optimal ones when multiple\nimmunogenicity criteria are taken into account.",
          "link": "http://arxiv.org/abs/2307.00424",
          "publishedOn": "2023-11-07T00:44:08.111Z",
          "wordCount": 726,
          "title": "Adaptive Algorithms for Relaxed Pareto Set Identification. (arXiv:2307.00424v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.01827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Buzaglo_G/0/1/0/all/0/1\">Gon Buzaglo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haim_N/0/1/0/all/0/1\">Niv Haim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yehudai_G/0/1/0/all/0/1\">Gilad Yehudai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardi_G/0/1/0/all/0/1\">Gal Vardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oz_Y/0/1/0/all/0/1\">Yakir Oz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikankin_Y/0/1/0/all/0/1\">Yaniv Nikankin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irani_M/0/1/0/all/0/1\">Michal Irani</a>",
          "description": "Memorization of training data is an active research area, yet our\nunderstanding of the inner workings of neural networks is still in its infancy.\nRecently, Haim et al. (2022) proposed a scheme to reconstruct training samples\nfrom multilayer perceptron binary classifiers, effectively demonstrating that a\nlarge portion of training samples are encoded in the parameters of such\nnetworks. In this work, we extend their findings in several directions,\nincluding reconstruction from multiclass and convolutional neural networks. We\nderive a more general reconstruction scheme which is applicable to a wider\nrange of loss functions such as regression losses. Moreover, we study the\nvarious factors that contribute to networks' susceptibility to such\nreconstruction schemes. Intriguingly, we observe that using weight decay during\ntraining increases reconstructability both in terms of quantity and quality.\nAdditionally, we examine the influence of the number of neurons relative to the\nnumber of training samples on the reconstructability. Code:\nhttps://github.com/gonbuzaglo/decoreco",
          "link": "http://arxiv.org/abs/2307.01827",
          "publishedOn": "2023-11-07T00:44:08.098Z",
          "wordCount": 695,
          "title": "Deconstructing Data Reconstruction: Multiclass, Weight Decay and General Losses. (arXiv:2307.01827v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ates_H/0/1/0/all/0/1\">Halim Cagri Ates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhargava_S/0/1/0/all/0/1\">Shruti Bhargava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Site Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiarui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddula_S/0/1/0/all/0/1\">Siddhardha Maddula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moniz_J/0/1/0/all/0/1\">Joel Ruben Antony Moniz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nalamalapu_A/0/1/0/all/0/1\">Anil Kumar Nalamalapu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_R/0/1/0/all/0/1\">Roman Hoang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozyildirim_M/0/1/0/all/0/1\">Melis Ozyildirim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1\">Alkesh Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piraviperumal_D/0/1/0/all/0/1\">Dhivya Piraviperumal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Renkens_V/0/1/0/all/0/1\">Vincent Renkens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samal_A/0/1/0/all/0/1\">Ankit Samal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Thy Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_B/0/1/0/all/0/1\">Bo-Hsiang Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_R/0/1/0/all/0/1\">Rong Zou</a>",
          "description": "Successfully handling context is essential for any dialog understanding task.\nThis context maybe be conversational (relying on previous user queries or\nsystem responses), visual (relying on what the user sees, for example, on their\nscreen), or background (based on signals such as a ringing alarm or playing\nmusic). In this work, we present an overview of MARRS, or Multimodal Reference\nResolution System, an on-device framework within a Natural Language\nUnderstanding system, responsible for handling conversational, visual and\nbackground context. In particular, we present different machine learning models\nto enable handing contextual queries; specifically, one to enable reference\nresolution, and one to handle context via query rewriting. We also describe how\nthese models complement each other to form a unified, coherent, lightweight\nsystem that can understand context while preserving user privacy.",
          "link": "http://arxiv.org/abs/2311.01650",
          "publishedOn": "2023-11-07T00:44:08.056Z",
          "wordCount": null,
          "title": "MARRS: Multimodal Reference Resolution System. (arXiv:2311.01650v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yudong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guiliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1\">Pascal Poupart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yangchen Pan</a>",
          "description": "Restricting the variance of a policy's return is a popular choice in\nrisk-averse Reinforcement Learning (RL) due to its clear mathematical\ndefinition and easy interpretability. Traditional methods directly restrict the\ntotal return variance. Recent methods restrict the per-step reward variance as\na proxy. We thoroughly examine the limitations of these variance-based methods,\nsuch as sensitivity to numerical scale and hindering of policy learning, and\npropose to use an alternative risk measure, Gini deviation, as a substitute. We\nstudy various properties of this new risk measure and derive a policy gradient\nalgorithm to minimize it. Empirical evaluation in domains where risk-aversion\ncan be clearly defined, shows that our algorithm can mitigate the limitations\nof variance-based risk measures and achieves high return with low risk in terms\nof variance and Gini deviation when others fail to learn a reasonable policy.",
          "link": "http://arxiv.org/abs/2307.08873",
          "publishedOn": "2023-11-07T00:44:08.049Z",
          "wordCount": 683,
          "title": "An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient. (arXiv:2307.08873v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.00687",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ryan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yen_H/0/1/0/all/0/1\">Howard Yen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marjieh_R/0/1/0/all/0/1\">Raja Marjieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1\">Thomas L. Griffiths</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1\">Ranjay Krishna</a>",
          "description": "How do we communicate with others to achieve our goals? We use our prior\nexperience or advice from others, or construct a candidate utterance by\npredicting how it will be received. However, our experiences are limited and\nbiased, and reasoning about potential outcomes can be difficult and cognitively\nchallenging. In this paper, we explore how we can leverage Large Language Model\n(LLM) simulations to help us communicate better. We propose the\nExplore-Generate-Simulate (EGS) framework, which takes as input any scenario\nwhere an individual is communicating to an audience with a goal they want to\nachieve. EGS (1) explores the solution space by producing a diverse set of\nadvice relevant to the scenario, (2) generates communication candidates\nconditioned on subsets of the advice, and (3) simulates the reactions from\nvarious audiences to determine both the best candidate and advice to use. We\nevaluate the framework on eight scenarios spanning the ten fundamental\nprocesses of interpersonal communication. For each scenario, we collect a\ndataset of human evaluations across candidates and baselines, and showcase that\nour framework's chosen candidate is preferred over popular generation\nmechanisms including Chain-of-Thought. We also find that audience simulations\nachieve reasonably high agreement with human raters across 5 of the 8\nscenarios. Finally, we demonstrate the generality of our framework by applying\nit to real-world scenarios described by users on web forums. Through\nevaluations and demonstrations, we show that EGS enhances the effectiveness and\noutcomes of goal-oriented communication across a variety of situations, thus\nopening up new possibilities for the application of large language models in\nrevolutionizing communication and decision-making processes.",
          "link": "http://arxiv.org/abs/2311.00687",
          "publishedOn": "2023-11-07T00:44:08.031Z",
          "wordCount": null,
          "title": "Improving Interpersonal Communication by Simulating Audiences with Language Models. (arXiv:2311.00687v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.18381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yue Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong-Lu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1\">Kaitong Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Cewu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1\">Yu-Wing Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chi-Keung Tang</a>",
          "description": "Data-efficient learning has drawn significant attention, especially given the\ncurrent trend of large multi-modal models, where dataset distillation can be an\neffective solution. However, the dataset distillation process itself is still\nvery inefficient. In this work, we model the distillation problem with\nreference to information transport. Observing that severe data redundancy\nexists in dataset distillation, we argue to put more emphasis on the utility of\nthe training samples. We propose a family of methods to exploit the most\nvaluable samples, which is validated by our comprehensive analysis of the\noptimal data selection. The new strategy significantly reduces the training\ncost and extends a variety of existing distillation algorithms to larger and\nmore diversified datasets, e.g., in some cases only 0.04% training data is\nsufficient for comparable distillation performance. Moreover, our strategy\nconsistently enhances the performance, which may open up new analyses on the\ndynamics of distillation and networks. Our method is able to extend the\ndistillation algorithms to much larger-scale datasets and more heterogeneous\ndatasets, e.g., ImageNet-1K and Kinetics-400. Our code is available on\nhttps://github.com/silicx/GoldFromOres.",
          "link": "http://arxiv.org/abs/2305.18381",
          "publishedOn": "2023-11-07T00:44:08.030Z",
          "wordCount": null,
          "title": "Distill Gold from Massive Ores: Efficient Dataset Distillation via Critical Samples Selection. (arXiv:2305.18381v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.09599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paat_H/0/1/0/all/0/1\">Helbert Paat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_Q/0/1/0/all/0/1\">Qing Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Weilong Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tong Zhang</a>",
          "description": "Advancements in deep learning-based 3D object detection necessitate the\navailability of large-scale datasets. However, this requirement introduces the\nchallenge of manual annotation, which is often both burdensome and\ntime-consuming. To tackle this issue, the literature has seen the emergence of\nseveral weakly supervised frameworks for 3D object detection which can\nautomatically generate pseudo labels for unlabeled data. Nevertheless, these\ngenerated pseudo labels contain noise and are not as accurate as those labeled\nby humans. In this paper, we present the first approach that addresses the\ninherent ambiguities present in pseudo labels by introducing an Evidential Deep\nLearning (EDL) based uncertainty estimation framework. Specifically, we propose\nMEDL-U, an EDL framework based on MTrans, which not only generates pseudo\nlabels but also quantifies the associated uncertainties. However, applying EDL\nto 3D object detection presents three primary challenges: (1) relatively lower\npseudolabel quality in comparison to other autolabelers; (2) excessively high\nevidential uncertainty estimates; and (3) lack of clear interpretability and\neffective utilization of uncertainties for downstream tasks. We tackle these\nissues through the introduction of an uncertainty-aware IoU-based loss, an\nevidence-aware multi-task loss function, and the implementation of a\npost-processing stage for uncertainty refinement. Our experimental results\ndemonstrate that probabilistic detectors trained using the outputs of MEDL-U\nsurpass deterministic detectors trained using outputs from previous 3D\nannotators on the KITTI val set for all difficulty levels. Moreover, MEDL-U\nachieves state-of-the-art results on the KITTI official test set compared to\nexisting 3D automatic annotators.",
          "link": "http://arxiv.org/abs/2309.09599",
          "publishedOn": "2023-11-07T00:44:08.029Z",
          "wordCount": null,
          "title": "MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential Deep Learning. (arXiv:2309.09599v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10683",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Feng_S/0/1/0/all/0/1\">Shikun Feng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ni_Y/0/1/0/all/0/1\">Yuyan Ni</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lan_Y/0/1/0/all/0/1\">Yanyan Lan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_Z/0/1/0/all/0/1\">Zhi-Ming Ma</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_W/0/1/0/all/0/1\">Wei-Ying Ma</a>",
          "description": "Coordinate denoising is a promising 3D molecular pre-training method, which\nhas achieved remarkable performance in various downstream drug discovery tasks.\nTheoretically, the objective is equivalent to learning the force field, which\nis revealed helpful for downstream tasks. Nevertheless, there are two\nchallenges for coordinate denoising to learn an effective force field, i.e. low\ncoverage samples and isotropic force field. The underlying reason is that\nmolecular distributions assumed by existing denoising methods fail to capture\nthe anisotropic characteristic of molecules. To tackle these challenges, we\npropose a novel hybrid noise strategy, including noises on both dihedral angel\nand coordinate. However, denoising such hybrid noise in a traditional way is no\nmore equivalent to learning the force field. Through theoretical deductions, we\nfind that the problem is caused by the dependency of the input conformation for\ncovariance. To this end, we propose to decouple the two types of noise and\ndesign a novel fractional denoising method (Frad), which only denoises the\nlatter coordinate part. In this way, Frad enjoys both the merits of sampling\nmore low-energy structures and the force field equivalence. Extensive\nexperiments show the effectiveness of Frad in molecular representation, with a\nnew state-of-the-art on 9 out of 12 tasks of QM9 and on 7 out of 8 targets of\nMD17.",
          "link": "http://arxiv.org/abs/2307.10683",
          "publishedOn": "2023-11-07T00:44:08.021Z",
          "wordCount": 742,
          "title": "Fractional Denoising for 3D Molecular Pre-training. (arXiv:2307.10683v2 [q-bio.QM] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1\">Bin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1\">Kui Jia</a>",
          "description": "Foundation models (e.g., CLIP or DINOv2) have shown their impressive learning\nand transfer capabilities in a wide range of visual tasks, by training on a\nlarge corpus of data and adapting to specific downstream tasks. It is, however,\ninteresting that foundation models have not been fully explored for universal\ndomain adaptation (UniDA), which is to learn models using labeled data in a\nsource domain and unlabeled data in a target one, such that the learned models\ncan successfully adapt to the target data. In this paper, we make comprehensive\nempirical studies of state-of-the-art UniDA methods using foundation models. We\nfirst observe that, unlike fine-tuning from ImageNet pre-trained models, as\nprevious methods do, fine-tuning from foundation models yields significantly\npoorer results, sometimes even worse than training from scratch. While freezing\nthe backbones, we demonstrate that although the foundation models greatly\nimprove the performance of the baseline method that trains the models on the\nsource data alone, existing UniDA methods generally fail to improve over the\nbaseline. This suggests that new research efforts are very necessary for UniDA\nusing foundation models. Based on these findings, we introduce \\textit{CLIP\ndistillation}, a parameter-free method specifically designed to distill target\nknowledge from CLIP models. The core of our \\textit{CLIP distillation} lies in\na self-calibration technique for automatic temperature scaling, a feature that\nsignificantly enhances the baseline's out-class detection capability. Although\nsimple, our method outperforms previous approaches in most benchmark tasks,\nexcelling in evaluation metrics including H-score/H$^3$-score and the newly\nproposed universal classification rate (UCR) metric. We hope that our\ninvestigation and the proposed simple framework can serve as a strong baseline\nto facilitate future studies in this field.",
          "link": "http://arxiv.org/abs/2305.11092",
          "publishedOn": "2023-11-07T00:44:07.999Z",
          "wordCount": null,
          "title": "Universal Domain Adaptation from Foundation Models: A Baseline Study. (arXiv:2305.11092v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.11143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Capozzi_G/0/1/0/all/0/1\">Gianluca Capozzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DElia_D/0/1/0/all/0/1\">Daniele Cono D&#x27;Elia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luna_G/0/1/0/all/0/1\">Giuseppe Antonio Di Luna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Querzoni_L/0/1/0/all/0/1\">Leonardo Querzoni</a>",
          "description": "In recent years, binary analysis gained traction as a fundamental approach to\ninspect software and guarantee its security. Due to the exponential increase of\ndevices running software, much research is now moving towards new autonomous\nsolutions based on deep learning models, as they have been showing\nstate-of-the-art performances in solving binary analysis problems. One of the\nhot topics in this context is binary similarity, which consists in determining\nif two functions in assembly code are compiled from the same source code.\nHowever, it is unclear how deep learning models for binary similarity behave in\nan adversarial context. In this paper, we study the resilience of binary\nsimilarity models against adversarial examples, showing that they are\nsusceptible to both targeted and untargeted attacks (w.r.t. similarity goals)\nperformed by black-box and white-box attackers. In more detail, we extensively\ntest three current state-of-the-art solutions for binary similarity against two\nblack-box greedy attacks, including a new technique that we call Spatial\nGreedy, and one white-box attack in which we repurpose a gradient-guided\nstrategy used in attacks to image classifiers.",
          "link": "http://arxiv.org/abs/2303.11143",
          "publishedOn": "2023-11-07T00:44:07.985Z",
          "wordCount": null,
          "title": "Adversarial Attacks against Binary Similarity Systems. (arXiv:2303.11143v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01574",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Murugesan_G/0/1/0/all/0/1\">Gowtham Krishnan Murugesan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McCrumb_D/0/1/0/all/0/1\">Diana McCrumb</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brunner_E/0/1/0/all/0/1\">Eric Brunner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_J/0/1/0/all/0/1\">Jithendra Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Soni_R/0/1/0/all/0/1\">Rahul Soni</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Grigorash_V/0/1/0/all/0/1\">Vasily Grigorash</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moore_S/0/1/0/all/0/1\">Stephen Moore</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Oss_J/0/1/0/all/0/1\">Jeff Van Oss</a>",
          "description": "Automatic segmentation of lesions in FDG-18 Whole Body (WB) PET/CT scans\nusing deep learning models is instrumental for determining treatment response,\noptimizing dosimetry, and advancing theranostic applications in oncology.\nHowever, the presence of organs with elevated radiotracer uptake, such as the\nliver, spleen, brain, and bladder, often leads to challenges, as these regions\nare often misidentified as lesions by deep learning models. To address this\nissue, we propose a novel approach of segmenting both organs and lesions,\naiming to enhance the performance of automatic lesion segmentation methods. In\nthis study, we assessed the effectiveness of our proposed method using the\nAutoPET II challenge dataset, which comprises 1014 subjects. We evaluated the\nimpact of inclusion of additional labels and data in the segmentation\nperformance of the model. In addition to the expert-annotated lesion labels, we\nintroduced eight additional labels for organs, including the liver, kidneys,\nurinary bladder, spleen, lung, brain, heart, and stomach. These labels were\nintegrated into the dataset, and a 3D UNET model was trained within the nnUNet\nframework. Our results demonstrate that our method achieved the top ranking in\nthe held-out test dataset, underscoring the potential of this approach to\nsignificantly improve lesion segmentation accuracy in FDG-18 Whole-Body PET/CT\nscans, ultimately benefiting cancer patients and advancing clinical practice.",
          "link": "http://arxiv.org/abs/2311.01574",
          "publishedOn": "2023-11-07T00:44:07.984Z",
          "wordCount": null,
          "title": "Improving Lesion Segmentation in FDG-18 Whole-Body PET/CT scans using Multilabel approach: AutoPET II challenge. (arXiv:2311.01574v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarlos_T/0/1/0/all/0/1\">Tamas Sarlos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyou Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David Woodruff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiuyi/0/1/0/all/0/1\">Qiuyi</a> (Richard) <a href=\"http://arxiv.org/find/cs/1/au:+Zhang/0/1/0/all/0/1\">Zhang</a>",
          "description": "Inspired by fast algorithms in natural language processing, we study low rank\napproximation in the entrywise transformed setting where we want to find a good\nrank $k$ approximation to $f(U \\cdot V)$, where $U, V^\\top \\in \\mathbb{R}^{n\n\\times r}$ are given, $r = O(\\log(n))$, and $f(x)$ is a general scalar\nfunction. Previous work in sublinear low rank approximation has shown that if\nboth (1) $U = V^\\top$ and (2) $f(x)$ is a PSD kernel function, then there is an\n$O(nk^{\\omega-1})$ time constant relative error approximation algorithm, where\n$\\omega \\approx 2.376$ is the exponent of matrix multiplication. We give the\nfirst conditional time hardness results for this problem, demonstrating that\nboth conditions (1) and (2) are in fact necessary for getting better than\n$n^{2-o(1)}$ time for a relative error low rank approximation for a wide class\nof functions. We give novel reductions from the Strong Exponential Time\nHypothesis (SETH) that rely on lower bounding the leverage scores of flat\nsparse vectors and hold even when the rank of the transformed matrix $f(UV)$\nand the target rank are $n^{o(1)}$, and when $U = V^\\top$. Furthermore, even\nwhen $f(x) = x^p$ is a simple polynomial, we give runtime lower bounds in the\ncase when $U \\neq V^\\top$ of the form $\\Omega(\\min(n^{2-o(1)}, \\Omega(2^p)))$.\nLastly, we demonstrate that our lower bounds are tight by giving an $O(n \\cdot\n\\text{poly}(k, 2^p, 1/\\epsilon))$ time relative error approximation algorithm\nand a fast $O(n \\cdot \\text{poly}(k, p, 1/\\epsilon))$ additive error\napproximation using fast tensor-based sketching. Additionally, since our low\nrank algorithms rely on matrix-vector product subroutines, our lower bounds\nextend to show that computing $f(UV)W$, for even a small matrix $W$, requires\n$\\Omega(n^{2-o(1)})$ time.",
          "link": "http://arxiv.org/abs/2311.01960",
          "publishedOn": "2023-11-07T00:44:07.983Z",
          "wordCount": null,
          "title": "Hardness of Low Rank Approximation of Entrywise Transformed Matrix Products. (arXiv:2311.01960v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.02076",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalra_D/0/1/0/all/0/1\">Dayal Singh Kalra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tianyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barkeshli_M/0/1/0/all/0/1\">Maissam Barkeshli</a>",
          "description": "In gradient descent dynamics of neural networks, the top eigenvalue of the\nHessian of the loss (sharpness) displays a variety of robust phenomena\nthroughout training. This includes early time regimes where the sharpness may\ndecrease during early periods of training (sharpness reduction), and later time\nbehavior such as progressive sharpening and edge of stability. We demonstrate\nthat a simple $2$-layer linear network (UV model) trained on a single training\nexample exhibits all of the essential sharpness phenomenology observed in\nreal-world scenarios. By analyzing the structure of dynamical fixed points in\nfunction space and the vector field of function updates, we uncover the\nunderlying mechanisms behind these sharpness trends. Our analysis reveals (i)\nthe mechanism behind early sharpness reduction and progressive sharpening, (ii)\nthe required conditions for edge of stability, and (iii) a period-doubling\nroute to chaos on the edge of stability manifold as learning rate is increased.\nFinally, we demonstrate that various predictions from this simplified model\ngeneralize to real-world scenarios and discuss its limitations.",
          "link": "http://arxiv.org/abs/2311.02076",
          "publishedOn": "2023-11-07T00:44:07.981Z",
          "wordCount": null,
          "title": "Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos. (arXiv:2311.02076v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Katsch_T/0/1/0/all/0/1\">Tobias Katsch</a>",
          "description": "Linear Recurrence has proven to be a powerful tool for modeling long\nsequences efficiently. In this work, we show that existing models fail to take\nfull advantage of its potential. Motivated by this finding, we develop\nGateLoop, a foundational sequence model that generalizes linear recurrent\nmodels such as S4, S5, LRU and RetNet, by employing data-controlled state\ntransitions. Utilizing this theoretical advance, GateLoop empirically\noutperforms existing models for auto-regressive language modeling. Our method\ncomes with a low-cost $O(l)$ recurrent mode and an efficient $O(l \\log_{2} l)$\nparallel mode making use of highly optimized associative scan implementations.\nFurthermore, we derive an $O(l^2)$ surrogate attention mode, revealing\nremarkable implications for Transformer and recently proposed architectures.\nSpecifically, we prove that our approach can be interpreted as providing\ndata-controlled relative-positional information to Attention. While many\nexisting models solely rely on data-controlled cumulative sums for context\naggregation, our findings suggest that incorporating data-controlled complex\ncumulative products may be a crucial step towards more powerful sequence\nmodels.",
          "link": "http://arxiv.org/abs/2311.01927",
          "publishedOn": "2023-11-07T00:44:07.980Z",
          "wordCount": null,
          "title": "GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling. (arXiv:2311.01927v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.03374",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadrtdinov_I/0/1/0/all/0/1\">Ildus Sadrtdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pozdeev_D/0/1/0/all/0/1\">Dmitrii Pozdeev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lobacheva_E/0/1/0/all/0/1\">Ekaterina Lobacheva</a>",
          "description": "Transfer learning and ensembling are two popular techniques for improving the\nperformance and robustness of neural networks. Due to the high cost of\npre-training, ensembles of models fine-tuned from a single pre-trained\ncheckpoint are often used in practice. Such models end up in the same basin of\nthe loss landscape, which we call the pre-train basin, and thus have limited\ndiversity. In this work, we show that ensembles trained from a single\npre-trained checkpoint may be improved by better exploring the pre-train basin,\nhowever, leaving the basin results in losing the benefits of transfer learning\nand in degradation of the ensemble quality. Based on the analysis of existing\nexploration methods, we propose a more effective modification of the Snapshot\nEnsembles (SSE) for transfer learning setup, StarSSE, which results in stronger\nensembles and uniform model soups.",
          "link": "http://arxiv.org/abs/2303.03374",
          "publishedOn": "2023-11-07T00:44:07.978Z",
          "wordCount": null,
          "title": "To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning. (arXiv:2303.03374v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01762",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Allerbo_O/0/1/0/all/0/1\">Oskar Allerbo</a>",
          "description": "Kernel ridge regression, KRR, is a generalization of linear ridge regression\nthat is non-linear in the data, but linear in the parameters. The solution can\nbe obtained either as a closed-form solution, which includes a matrix\ninversion, or iteratively through gradient descent. Using the iterative\napproach opens up for changing the kernel during training, something that is\ninvestigated in this paper. We theoretically address the effects this has on\nmodel complexity and generalization. Based on our findings, we propose an\nupdate scheme for the bandwidth of translational-invariant kernels, where we\nlet the bandwidth decrease to zero during training, thus circumventing the need\nfor hyper-parameter selection. We demonstrate on real and synthetic data how\ndecreasing the bandwidth during training outperforms using a constant\nbandwidth, selected by cross-validation and marginal likelihood maximization.\nWe also show theoretically and empirically that using a decreasing bandwidth,\nwe are able to achieve both zero training error in combination with good\ngeneralization, and a double descent behavior, phenomena that do not occur for\nKRR with constant bandwidth but are known to appear for neural networks.",
          "link": "http://arxiv.org/abs/2311.01762",
          "publishedOn": "2023-11-07T00:44:07.924Z",
          "wordCount": null,
          "title": "Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel. (arXiv:2311.01762v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yongtao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fanghui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chrysos_G/0/1/0/all/0/1\">Grigorios G Chrysos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cevher_V/0/1/0/all/0/1\">Volkan Cevher</a>",
          "description": "In this paper, we aim to build the global convergence theory of encoder-only\nshallow Transformers under a realistic setting from the perspective of\narchitectures, initialization, and scaling under a finite width regime. The\ndifficulty lies in how to tackle the softmax in self-attention mechanism, the\ncore ingredient of Transformer. In particular, we diagnose the scaling scheme,\ncarefully tackle the input/output of softmax, and prove that quadratic\noverparameterization is sufficient for global convergence of our shallow\nTransformers under commonly-used He/LeCun initialization in practice. Besides,\nneural tangent kernel (NTK) based analysis is also given, which facilitates a\ncomprehensive comparison. Our theory demonstrates the separation on the\nimportance of different scaling schemes and initialization. We believe our\nresults can pave the way for a better understanding of modern Transformers,\nparticularly on training dynamics.",
          "link": "http://arxiv.org/abs/2311.01575",
          "publishedOn": "2023-11-07T00:44:07.923Z",
          "wordCount": null,
          "title": "On the Convergence of Encoder-only Shallow Transformers. (arXiv:2311.01575v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01796",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qizhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zhen Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yonggang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>",
          "description": "Open-world classification systems should discern out-of-distribution (OOD)\ndata whose labels deviate from those of in-distribution (ID) cases, motivating\nrecent studies in OOD detection. Advanced works, despite their promising\nprogress, may still fail in the open world, owing to the lack of knowledge\nabout unseen OOD data in advance. Although one can access auxiliary OOD data\n(distinct from unseen ones) for model training, it remains to analyze how such\nauxiliary data will work in the open world. To this end, we delve into such a\nproblem from a learning theory perspective, finding that the distribution\ndiscrepancy between the auxiliary and the unseen real OOD data is the key to\naffecting the open-world detection performance. Accordingly, we propose\nDistributional-Augmented OOD Learning (DAL), alleviating the OOD distribution\ndiscrepancy by crafting an OOD distribution set that contains all distributions\nin a Wasserstein ball centered on the auxiliary OOD distribution. We justify\nthat the predictor trained over the worst OOD data in the ball can shrink the\nOOD distribution discrepancy, thus improving the open-world detection\nperformance given only the auxiliary OOD data. We conduct extensive evaluations\nacross representative OOD detection setups, demonstrating the superiority of\nour DAL over its advanced counterparts.",
          "link": "http://arxiv.org/abs/2311.01796",
          "publishedOn": "2023-11-07T00:44:07.922Z",
          "wordCount": null,
          "title": "Learning to Augment Distributions for Out-of-Distribution Detection. (arXiv:2311.01796v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01591",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lina_D/0/1/0/all/0/1\">Debolina Halder Lina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1\">Arlei Silva</a>",
          "description": "This paper addresses the problem of learning fair Graph Neural Networks\n(GNNs) under missing protected attributes. GNNs have achieved state-of-the-art\nresults in many relevant tasks where decisions might disproportionately impact\nspecific communities. However, existing work on fair GNNs assumes that either\nprotected attributes are fully-observed or that the missing data imputation is\nfair. In practice, biases in the imputation will be propagated to the model\noutcomes, leading them to overestimate the fairness of their predictions. We\naddress this challenge by proposing Better Fair than Sorry (BFtS), a fair\nmissing data imputation model for protected attributes used by fair GNNs. The\nkey design principle behind BFtS is that imputations should approximate the\nworst-case scenario for the fair GNN -- i.e. when optimizing fairness is the\nhardest. We implement this idea using a 3-player adversarial scheme where two\nadversaries collaborate against the fair GNN. Experiments using synthetic and\nreal datasets show that BFtS often achieves a better fairness $\\times$ accuracy\ntrade-off than existing alternatives.",
          "link": "http://arxiv.org/abs/2311.01591",
          "publishedOn": "2023-11-07T00:44:07.918Z",
          "wordCount": null,
          "title": "Better Fair than Sorry: Adversarial Missing Data Imputation for Fair GNNs. (arXiv:2311.01591v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.03626",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Zhu_Y/0/1/0/all/0/1\">Ying Zhu</a>",
          "description": "When the unknown regression function of a single variable is known to have\nderivatives up to the $(\\gamma+1)$th order bounded in absolute values by a\ncommon constant everywhere or a.e. (i.e., $(\\gamma+1)$th degree of smoothness),\nthe minimax optimal rate of the mean integrated squared error (MISE) is stated\nas $\\left(\\frac{1}{n}\\right)^{\\frac{2\\gamma+2}{2\\gamma+3}}$ in the literature.\nThis paper shows that: (i) if $n\\leq\\left(\\gamma+1\\right)^{2\\gamma+3}$, the\nminimax optimal MISE rate is $\\frac{\\log n}{n\\log(\\log n)}$ and the optimal\ndegree of smoothness to exploit is roughly $\\max\\left\\{ \\left\\lfloor \\frac{\\log\nn}{2\\log\\left(\\log n\\right)}\\right\\rfloor ,\\,1\\right\\} $; (ii) if\n$n>\\left(\\gamma+1\\right)^{2\\gamma+3}$, the minimax optimal MISE rate is\n$\\left(\\frac{1}{n}\\right)^{\\frac{2\\gamma+2}{2\\gamma+3}}$ and the optimal degree\nof smoothness to exploit is $\\gamma+1$. The fundamental contribution of this\npaper is a set of metric entropy bounds we develop for smooth function classes.\nSome of our bounds are original, and some of them improve and/or generalize the\nones in the literature (e.g., Kolmogorov and Tikhomirov, 1959). Our metric\nentropy bounds allow us to show phase transitions in the minimax optimal MISE\nrates associated with some commonly seen smoothness classes as well as\nnon-standard smoothness classes, and can also be of independent interest\noutside the nonparametric regression problems.",
          "link": "http://arxiv.org/abs/2112.03626",
          "publishedOn": "2023-11-07T00:44:07.917Z",
          "wordCount": null,
          "title": "Phase transitions in nonparametric regressions. (arXiv:2112.03626v7 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_B/0/1/0/all/0/1\">Bryan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereida_K/0/1/0/all/0/1\">Karime Pereida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergstra_J/0/1/0/all/0/1\">James Bergstra</a>",
          "description": "Transferring representation for multitask imitation learning has the\npotential to provide improved sample efficiency on learning new tasks, when\ncompared to learning from scratch. In this work, we provide a statistical\nguarantee indicating that we can indeed achieve improved sample efficiency on\nthe target task when a representation is trained using sufficiently diverse\nsource tasks. Our theoretical results can be readily extended to account for\ncommonly used neural network architectures with realistic assumptions. We\nconduct empirical analyses that align with our theoretical findings on four\nsimulated environments$\\unicode{x2014}$in particular leveraging more data from\nsource tasks can improve sample efficiency on learning in the new task.",
          "link": "http://arxiv.org/abs/2311.01589",
          "publishedOn": "2023-11-07T00:44:07.916Z",
          "wordCount": null,
          "title": "A Statistical Guarantee for Representation Transfer in Multitask Imitation Learning. (arXiv:2311.01589v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1\">Qianxin Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yiyang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Shaojie Tang</a>",
          "description": "In this paper, we aim to build a novel bandits algorithm that is capable of\nfully harnessing the power of multi-dimensional data and the inherent\nnon-linearity of reward functions to provide high-usable and accountable\ndecision-making services. To this end, we introduce a generalized low-rank\ntensor contextual bandits model in which an action is formed from three feature\nvectors, and thus can be represented by a tensor. In this formulation, the\nreward is determined through a generalized linear function applied to the inner\nproduct of the action's feature tensor and a fixed but unknown parameter tensor\nwith a low tubal rank. To effectively achieve the trade-off between exploration\nand exploitation, we introduce a novel algorithm called \"Generalized Low-Rank\nTensor Exploration Subspace then Refine\" (G-LowTESTR). This algorithm first\ncollects raw data to explore the intrinsic low-rank tensor subspace information\nembedded in the decision-making scenario, and then converts the original\nproblem into an almost lower-dimensional generalized linear contextual bandits\nproblem. Rigorous theoretical analysis shows that the regret bound of\nG-LowTESTR is superior to those in vectorization and matricization cases. We\nconduct a series of simulations and real data experiments to further highlight\nthe effectiveness of G-LowTESTR, leveraging its ability to capitalize on the\nlow-rank tensor structure for enhanced learning.",
          "link": "http://arxiv.org/abs/2311.01771",
          "publishedOn": "2023-11-07T00:44:07.915Z",
          "wordCount": null,
          "title": "Efficient Generalized Low-Rank Tensor Contextual Bandits. (arXiv:2311.01771v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1\">Aakriti Shah</a>",
          "description": "Physical adversarial attacks on road signs are continuously exploiting\nvulnerabilities in modern day autonomous vehicles (AVs) and impeding their\nability to correctly classify what type of road sign they encounter. Current\nmodels cannot generalize input data well, resulting in overfitting or\nunderfitting. In overfitting, the model memorizes the input data but cannot\ngeneralize to new scenarios. In underfitting, the model does not learn enough\nof the input data to accurately classify these road signs. This paper explores\nthe resilience of autonomous driving systems against three main physical\nadversarial attacks (tape, graffiti, illumination), specifically targeting\nobject classifiers. Several machine learning models were developed and\nevaluated on two distinct datasets: road signs (stop signs, speed limit signs,\ntraffic lights, and pedestrian crosswalk signs) and geometric shapes (octagons,\ncircles, squares, and triangles). The study compared algorithm performance\nunder different conditions, including clean and adversarial training and\ntesting on these datasets. To build robustness against attacks, defense\ntechniques like adversarial training and transfer learning were implemented.\nResults demonstrated transfer learning models played a crucial role in\nperformance by allowing knowledge gained from shape training to improve\ngeneralizability of road sign classification, despite the datasets being\ncompletely different. The paper suggests future research directions, including\nhuman-in-the-loop validation, security analysis, real-world testing, and\nexplainable AI for transparency. This study aims to contribute to improving\nsecurity and robustness of object classifiers in autonomous vehicles and\nmitigating adversarial example impacts on driving systems.",
          "link": "http://arxiv.org/abs/2311.01478",
          "publishedOn": "2023-11-07T00:44:07.914Z",
          "wordCount": null,
          "title": "Adversary ML Resilience in Autonomous Driving Through Human Centered Perception Mechanisms. (arXiv:2311.01478v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01888",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Velychko_D/0/1/0/all/0/1\">Dmytro Velychko</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Damm_S/0/1/0/all/0/1\">Simon Damm</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fischer_A/0/1/0/all/0/1\">Asja Fischer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lucke_J/0/1/0/all/0/1\">J&#xf6;rg L&#xfc;cke</a>",
          "description": "Standard probabilistic sparse coding assumes a Laplace prior, a linear\nmapping from latents to observables, and Gaussian observable distributions. We\nhere derive a solely entropy-based learning objective for the parameters of\nstandard sparse coding. The novel variational objective has the following\nfeatures: (A) unlike MAP approximations, it uses non-trivial posterior\napproximations for probabilistic inference; (B) unlike for previous non-trivial\napproximations, the novel objective is fully analytical; and (C) the objective\nallows for a novel principled form of annealing. The objective is derived by\nfirst showing that the standard ELBO objective converges to a sum of entropies,\nwhich matches similar recent results for generative models with Gaussian\npriors. The conditions under which the ELBO becomes equal to entropies are then\nshown to have analytical solutions, which leads to the fully analytical\nobjective. Numerical experiments are used to demonstrate the feasibility of\nlearning with such entropy-based ELBOs. We investigate different posterior\napproximations including Gaussians with correlated latents and deep amortized\napproximations. Furthermore, we numerically investigate entropy-based annealing\nwhich results in improved learning. Our main contributions are theoretical,\nhowever, and they are twofold: (1) for non-trivial posterior approximations, we\nprovide the (to the knowledge of the authors) first analytical ELBO objective\nfor standard probabilistic sparse coding; and (2) we provide the first\ndemonstration on how a recently shown convergence of the ELBO to entropy sums\ncan be used for learning.",
          "link": "http://arxiv.org/abs/2311.01888",
          "publishedOn": "2023-11-07T00:44:07.913Z",
          "wordCount": null,
          "title": "Learning Sparse Codes with Entropy-Based ELBOs. (arXiv:2311.01888v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenshuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhiyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannala_J/0/1/0/all/0/1\">Juho Kannala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1\">Joni Pajarinen</a>",
          "description": "\\textit{Relative overgeneralization} (RO) occurs in cooperative multi-agent\nlearning tasks when agents converge towards a suboptimal joint policy due to\noverfitting to suboptimal behavior of other agents. In early work, optimism has\nbeen shown to mitigate the \\textit{RO} problem when using tabular Q-learning.\nHowever, with function approximation optimism can amplify overestimation and\nthus fail on complex tasks. On the other hand, recent deep multi-agent policy\ngradient (MAPG) methods have succeeded in many complex tasks but may fail with\nsevere \\textit{RO}. We propose a general, yet simple, framework to enable\noptimistic updates in MAPG methods and alleviate the RO problem. Specifically,\nwe employ a \\textit{Leaky ReLU} function where a single hyperparameter selects\nthe degree of optimism to reshape the advantages when updating the policy.\nIntuitively, our method remains optimistic toward individual actions with lower\nreturns which are potentially caused by other agents' sub-optimal behavior\nduring learning. The optimism prevents the individual agents from quickly\nconverging to a local optimum. We also provide a formal analysis from an\noperator view to understand the proposed advantage transformation. In extensive\nevaluations on diverse sets of tasks, including illustrative matrix games,\ncomplex \\textit{Multi-agent MuJoCo} and \\textit{Overcooked} benchmarks, the\nproposed method\\footnote{Code can be found at\n\\url{https://github.com/wenshuaizhao/optimappo}.} outperforms strong baselines\non 13 out of 19 tested tasks and matches the performance on the rest.",
          "link": "http://arxiv.org/abs/2311.01953",
          "publishedOn": "2023-11-07T00:44:07.912Z",
          "wordCount": null,
          "title": "Optimistic Multi-Agent Policy Gradient for Cooperative Tasks. (arXiv:2311.01953v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhenting Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hanchen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pengzhan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padmanabhan_A/0/1/0/all/0/1\">Arthi Padmanabhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1\">Hugo Latapie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Harry Xu</a>",
          "description": "Video analytics is widely used in contemporary systems and services. At the\nforefront of video analytics are video queries that users develop to find\nobjects of particular interest. Building upon the insight that video objects\n(e.g., human, animals, cars, etc.), the center of video analytics, are similar\nin spirit to objects modeled by traditional object-oriented languages, we\npropose to develop an object-oriented approach to video analytics. This\napproach, named VQPy, consists of a frontend$\\unicode{x2015}$a Python variant\nwith constructs that make it easy for users to express video objects and their\ninteractions$\\unicode{x2015}$as well as an extensible backend that can\nautomatically construct and optimize pipelines based on video objects. We have\nimplemented and open-sourced VQPy, which has been productized in Cisco as part\nof its DeepVision framework.",
          "link": "http://arxiv.org/abs/2311.01623",
          "publishedOn": "2023-11-07T00:44:07.911Z",
          "wordCount": null,
          "title": "VQPy: An Object-Oriented Approach to Modern Video Analytics. (arXiv:2311.01623v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ketenci_M/0/1/0/all/0/1\">Mert Ketenci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhave_S/0/1/0/all/0/1\">Shreyas Bhave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhadad_N/0/1/0/all/0/1\">No&#xe9;mie Elhadad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perotte_A/0/1/0/all/0/1\">Adler Perotte</a>",
          "description": "Survival analysis is a widely-used technique for analyzing time-to-event data\nin the presence of censoring. In recent years, numerous survival analysis\nmethods have emerged which scale to large datasets and relax traditional\nassumptions such as proportional hazards. These models, while being performant,\nare very sensitive to model hyperparameters including: (1) number of bins and\nbin size for discrete models and (2) number of cluster assignments for\nmixture-based models. Each of these choices requires extensive tuning by\npractitioners to achieve optimal performance. In addition, we demonstrate in\nempirical studies that: (1) optimal bin size may drastically differ based on\nthe metric of interest (e.g., concordance vs brier score), and (2) mixture\nmodels may suffer from mode collapse and numerical instability. We propose a\nsurvival analysis approach which eliminates the need to tune hyperparameters\nsuch as mixture assignments and bin sizes, reducing the burden on\npractitioners. We show that the proposed approach matches or outperforms\nbaselines on several real-world datasets.",
          "link": "http://arxiv.org/abs/2311.01660",
          "publishedOn": "2023-11-07T00:44:07.909Z",
          "wordCount": null,
          "title": "Maximum Likelihood Estimation of Flexible Survival Densities with Importance Sampling. (arXiv:2311.01660v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simsek_B/0/1/0/all/0/1\">Berfin &#x15e;im&#x15f;ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendjeddou_A/0/1/0/all/0/1\">Amire Bendjeddou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstner_W/0/1/0/all/0/1\">Wulfram Gerstner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brea_J/0/1/0/all/0/1\">Johanni Brea</a>",
          "description": "Any continuous function $f^*$ can be approximated arbitrarily well by a\nneural network with sufficiently many neurons $k$. We consider the case when\n$f^*$ itself is a neural network with one hidden layer and $k$ neurons.\nApproximating $f^*$ with a neural network with $n< k$ neurons can thus be seen\nas fitting an under-parameterized \"student\" network with $n$ neurons to a\n\"teacher\" network with $k$ neurons. As the student has fewer neurons than the\nteacher, it is unclear, whether each of the $n$ student neurons should copy one\nof the teacher neurons or rather average a group of teacher neurons. For\nshallow neural networks with erf activation function and for the standard\nGaussian input distribution, we prove that \"copy-average\" configurations are\ncritical points if the teacher's incoming vectors are orthonormal and its\noutgoing weights are unitary. Moreover, the optimum among such configurations\nis reached when $n-1$ student neurons each copy one teacher neuron and the\n$n$-th student neuron averages the remaining $k-n+1$ teacher neurons. For the\nstudent network with $n=1$ neuron, we provide additionally a closed-form\nsolution of the non-trivial critical point(s) for commonly used activation\nfunctions through solving an equivalent constrained optimization problem.\nEmpirically, we find for the erf activation function that gradient flow\nconverges either to the optimal copy-average critical point or to another point\nwhere each student neuron approximately copies a different teacher neuron.\nFinally, we find similar results for the ReLU activation function, suggesting\nthat the optimal solution of underparameterized networks has a universal\nstructure.",
          "link": "http://arxiv.org/abs/2311.01644",
          "publishedOn": "2023-11-07T00:44:07.908Z",
          "wordCount": null,
          "title": "Should Under-parameterized Student Networks Copy or Average Teacher Weights?. (arXiv:2311.01644v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jiawei Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1\">Qin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Joey Tianyi Zhou</a>",
          "description": "Dataset distillation is a newly emerging task that synthesizes a small-size\ndataset used in training deep neural networks (DNNs) for reducing data storage\nand model training costs. The synthetic datasets are expected to capture the\nessence of the knowledge contained in real-world datasets such that the former\nyields a similar performance as the latter. Recent advancements in distillation\nmethods have produced notable improvements in generating synthetic datasets.\nHowever, current state-of-the-art methods treat the entire synthetic dataset as\na unified entity and optimize each synthetic instance equally. This static\noptimization approach may lead to performance degradation in dataset\ndistillation. Specifically, we argue that static optimization can give rise to\na coupling issue within the synthetic data, particularly when a larger amount\nof synthetic data is being optimized. This coupling issue, in turn, leads to\nthe failure of the distilled dataset to extract the high-level features learned\nby the deep neural network (DNN) in the latter epochs.\n\nIn this study, we propose a new dataset distillation strategy called\nSequential Subset Matching (SeqMatch), which tackles this problem by adaptively\noptimizing the synthetic data to encourage sequential acquisition of knowledge\nduring dataset distillation. Our analysis indicates that SeqMatch effectively\naddresses the coupling issue by sequentially generating the synthetic\ninstances, thereby enhancing its performance significantly. Our proposed\nSeqMatch outperforms state-of-the-art methods in various datasets, including\nSVNH, CIFAR-10, CIFAR-100, and Tiny ImageNet. Our code is available at\nhttps://github.com/shqii1j/seqmatch.",
          "link": "http://arxiv.org/abs/2311.01570",
          "publishedOn": "2023-11-07T00:44:07.906Z",
          "wordCount": null,
          "title": "Sequential Subset Matching for Dataset Distillation. (arXiv:2311.01570v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01642",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddi_A/0/1/0/all/0/1\">Aryaman Reddi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tolle_M/0/1/0/all/0/1\">Maximilian T&#xf6;lle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jan Peters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalvatzaki_G/0/1/0/all/0/1\">Georgia Chalvatzaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DEramo_C/0/1/0/all/0/1\">Carlo D&#x27;Eramo</a>",
          "description": "Robustness against adversarial attacks and distribution shifts is a\nlong-standing goal of Reinforcement Learning (RL). To this end, Robust\nAdversarial Reinforcement Learning (RARL) trains a protagonist against\ndestabilizing forces exercised by an adversary in a competitive zero-sum Markov\ngame, whose optimal solution, i.e., rational strategy, corresponds to a Nash\nequilibrium. However, finding Nash equilibria requires facing complex saddle\npoint optimization problems, which can be prohibitive to solve, especially for\nhigh-dimensional control. In this paper, we propose a novel approach for\nadversarial RL based on entropy regularization to ease the complexity of the\nsaddle point optimization problem. We show that the solution of this\nentropy-regularized problem corresponds to a Quantal Response Equilibrium\n(QRE), a generalization of Nash equilibria that accounts for bounded\nrationality, i.e., agents sometimes play random actions instead of optimal\nones. Crucially, the connection between the entropy-regularized objective and\nQRE enables free modulation of the rationality of the agents by simply tuning\nthe temperature coefficient. We leverage this insight to propose our novel\nalgorithm, Quantal Adversarial RL (QARL), which gradually increases the\nrationality of the adversary in a curriculum fashion until it is fully\nrational, easing the complexity of the optimization problem while retaining\nrobustness. We provide extensive evidence of QARL outperforming RARL and recent\nbaselines across several MuJoCo locomotion and navigation problems in overall\nperformance and robustness.",
          "link": "http://arxiv.org/abs/2311.01642",
          "publishedOn": "2023-11-07T00:44:07.844Z",
          "wordCount": null,
          "title": "Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula. (arXiv:2311.01642v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01537",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mitsuzawa_K/0/1/0/all/0/1\">Kensuke Mitsuzawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanagawa_M/0/1/0/all/0/1\">Motonobu Kanagawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bortoli_S/0/1/0/all/0/1\">Stefano Bortoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Grossi_M/0/1/0/all/0/1\">Margherita Grossi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papotti_P/0/1/0/all/0/1\">Paolo Papotti</a>",
          "description": "Two-sample testing decides whether two datasets are generated from the same\ndistribution. This paper studies variable selection for two-sample testing, the\ntask being to identify the variables (or dimensions) responsible for the\ndiscrepancies between the two distributions. This task is relevant to many\nproblems of pattern analysis and machine learning, such as dataset shift\nadaptation, causal inference and model validation. Our approach is based on a\ntwo-sample test based on the Maximum Mean Discrepancy (MMD). We optimise the\nAutomatic Relevance Detection (ARD) weights defined for individual variables to\nmaximise the power of the MMD-based test. For this optimisation, we introduce\nsparse regularisation and propose two methods for dealing with the issue of\nselecting an appropriate regularisation parameter. One method determines the\nregularisation parameter in a data-driven way, and the other aggregates the\nresults of different regularisation parameters. We confirm the validity of the\nproposed methods by systematic comparisons with baseline methods, and\ndemonstrate their usefulness in exploratory analysis of high-dimensional\ntraffic simulation data. Preliminary theoretical analyses are also provided,\nincluding a rigorous definition of variable selection for two-sample testing.",
          "link": "http://arxiv.org/abs/2311.01537",
          "publishedOn": "2023-11-07T00:44:07.843Z",
          "wordCount": null,
          "title": "Variable Selection in Maximum Mean Discrepancy for Interpretable Distribution Comparison. (arXiv:2311.01537v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.02013",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sikchi_H/0/1/0/all/0/1\">Harshit Sikchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chitnis_R/0/1/0/all/0/1\">Rohan Chitnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Touati_A/0/1/0/all/0/1\">Ahmed Touati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geramifard_A/0/1/0/all/0/1\">Alborz Geramifard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1\">Scott Niekum</a>",
          "description": "Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with\nlearning to achieve multiple goals in an environment purely from offline\ndatasets using sparse reward functions. Offline GCRL is pivotal for developing\ngeneralist agents capable of leveraging pre-existing datasets to learn diverse\nand reusable skills without hand-engineering reward functions. However,\ncontemporary approaches to GCRL based on supervised learning and contrastive\nlearning are often suboptimal in the offline setting. An alternative\nperspective on GCRL optimizes for occupancy matching, but necessitates learning\na discriminator, which subsequently serves as a pseudo-reward for downstream\nRL. Inaccuracies in the learned discriminator can cascade, negatively\ninfluencing the resulting policy. We present a novel approach to GCRL under a\nnew lens of mixture-distribution matching, leading to our discriminator-free\nmethod: SMORe. The key insight is combining the occupancy matching perspective\nof GCRL with a convex dual formulation to derive a learning objective that can\nbetter leverage suboptimal offline data. SMORe learns scores or unnormalized\ndensities representing the importance of taking an action at a state for\nreaching a particular goal. SMORe is principled and our extensive experiments\non the fully offline GCRL benchmark composed of robot manipulation and\nlocomotion tasks, including high-dimensional observations, show that SMORe can\noutperform state-of-the-art baselines by a significant margin.",
          "link": "http://arxiv.org/abs/2311.02013",
          "publishedOn": "2023-11-07T00:44:07.843Z",
          "wordCount": null,
          "title": "Score Models for Offline Goal-Conditioned Reinforcement Learning. (arXiv:2311.02013v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Ortega_J/0/1/0/all/0/1\">Jos&#xe9; Rodr&#xed;guez-Ortega</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Khaldi_R/0/1/0/all/0/1\">Rohaifa Khaldi</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Alcaraz_Segura_D/0/1/0/all/0/1\">Domingo Alcaraz-Segura</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Tabik_S/0/1/0/all/0/1\">Siham Tabik</a> (1) ((1) Department of Computer Science and Artificial Intelligence, DaSCI, University of Granada, Granada, Spain, (2) LifeWatch-ERIC ICT Core, Seville, Spain, (3) Department of Botany, Faculty of Science, University of Granada, Granada, Spain)",
          "description": "Remotely sensed data are dominated by mixed Land Use and Land Cover (LULC)\ntypes. Spectral unmixing is a technique to extract information from mixed\npixels into their constituent LULC types and corresponding abundance fractions.\nTraditionally, solving this task has relied on either classical methods that\nrequire prior knowledge of endmembers or machine learning methods that avoid\nexplicit endmembers calculation, also known as blind spectral unmixing (BSU).\nMost BSU studies based on Deep Learning (DL) focus on one time-step\nhyperspectral or multispectral data. To our knowledge, here we provide the\nfirst study on BSU of LULC classes using MODIS multispectral time series, in\npresence of missing data, with end-to-end DL models. We further boost the\nperformance of a Long-Short Term Memory (LSTM)-based model by incorporating\ngeographic plus topographic (geo-topographic) and climatic ancillary\ninformation. Our experiments show that combining spectral-temporal input data\ntogether with geo-topographic and climatic information substantially improves\nthe abundance estimation of LULC classes in mixed pixels. To carry out this\nstudy, we built a new labeled dataset of the region of Andalusia (Spain) with\nmonthly multispectral time series of pixels for the year 2013 from MODIS at\n460m resolution, for two hierarchical levels of LULC classes, named Andalusia\nMultiSpectral MultiTemporal Unmixing (Andalusia-MSMTU). This dataset provides,\nat the pixel level, a multispectral time series plus ancillary information\nannotated with the abundance of each LULC class inside each pixel. The dataset\n(https://zenodo.org/record/7752348##.ZBmkkezMLdo) and code\n(https://github.com/jrodriguezortega/MSMTU) are available to the public.",
          "link": "http://arxiv.org/abs/2310.07223",
          "publishedOn": "2023-11-07T00:44:07.468Z",
          "wordCount": 852,
          "title": "Deep Learning for blind spectral unmixing of LULC classes with MODIS multispectral time series and ancillary data. (arXiv:2310.07223v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.17514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cook_T/0/1/0/all/0/1\">Thomas Cook</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_H/0/1/0/all/0/1\">Harsh Vardhan Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Ji Ah Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1\">Guangyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tingting Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flaherty_P/0/1/0/all/0/1\">Patrick Flaherty</a>",
          "description": "We consider the problem of sequential multiple hypothesis testing with\nnontrivial data collection costs. This problem appears, for example, when\nconducting biological experiments to identify differentially expressed genes of\na disease process. This work builds on the generalized $\\alpha$-investing\nframework which enables control of the false discovery rate in a sequential\ntesting setting. We make a theoretical analysis of the long term asymptotic\nbehavior of $\\alpha$-wealth which motivates a consideration of sample size in\nthe $\\alpha$-investing decision rule. Posing the testing process as a game with\nnature, we construct a decision rule that optimizes the expected\n$\\alpha$-wealth reward (ERO) and provides an optimal sample size for each test.\nEmpirical results show that a cost-aware ERO decision rule correctly rejects\nmore false null hypotheses than other methods for $n=1$ where $n$ is the sample\nsize. When the sample size is not fixed cost-aware ERO uses a prior on the null\nhypothesis to adaptively allocate of the sample budget to each test. We extend\ncost-aware ERO investing to finite-horizon testing which enables the decision\nrule to allocate samples in a non-myopic manner. Finally, empirical tests on\nreal data sets from biological experiments show that cost-aware ERO balances\nthe allocation of samples to an individual test against the allocation of\nsamples across multiple tests.",
          "link": "http://arxiv.org/abs/2210.17514",
          "publishedOn": "2023-11-07T00:44:07.363Z",
          "wordCount": null,
          "title": "Cost-aware Generalized $\\alpha$-investing for Multiple Hypothesis Testing. (arXiv:2210.17514v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01806",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Yang_Y/0/1/0/all/0/1\">Yingzhen Yang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>",
          "description": "Randomized algorithms are important for solving large-scale optimization\nproblems. In this paper, we propose a fast sketching algorithm for least square\nproblems regularized by convex or nonconvex regularization functions, Sketching\nfor Regularized Optimization (SRO). Our SRO algorithm first generates a sketch\nof the original data matrix, then solves the sketched problem. Different from\nexisting randomized algorithms, our algorithm handles general Frechet\nsubdifferentiable regularization functions in an unified framework. We present\ngeneral theoretical result for the approximation error between the optimization\nresults of the original problem and the sketched problem for regularized least\nsquare problems which can be convex or nonconvex. For arbitrary convex\nregularizer, relative-error bound is proved for the approximation error.\nImportantly, minimax rates for sparse signal estimation by solving the sketched\nsparse convex or nonconvex learning problems are also obtained using our\ngeneral theoretical result under mild conditions. To the best of our knowledge,\nour results are among the first to demonstrate minimax rates for convex or\nnonconvex sparse learning problem by sketching under a unified theoretical\nframework. We further propose an iterative sketching algorithm which reduces\nthe approximation error exponentially by iteratively invoking the sketching\nalgorithm. Experimental results demonstrate the effectiveness of the proposed\nSRO and Iterative SRO algorithms.",
          "link": "http://arxiv.org/abs/2311.01806",
          "publishedOn": "2023-11-07T00:44:07.362Z",
          "wordCount": null,
          "title": "Sketching for Convex and Nonconvex Regularized Least Squares with Sharp Guarantees. (arXiv:2311.01806v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Puheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huishuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>",
          "description": "Diffusion models are a class of generative models that serve to establish a\nstochastic transport map between an empirically observed, yet unknown, target\ndistribution and a known prior. Despite their remarkable success in real-world\napplications, a theoretical understanding of their generalization capabilities\nremains underdeveloped. This work embarks on a comprehensive theoretical\nexploration of the generalization attributes of diffusion models. We establish\ntheoretical estimates of the generalization gap that evolves in tandem with the\ntraining dynamics of score-based diffusion models, suggesting a polynomially\nsmall generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$\nand the model capacity $m$, evading the curse of dimensionality (i.e., not\nexponentially large in the data dimension) when early-stopped. Furthermore, we\nextend our quantitative analysis to a data-dependent scenario, wherein target\ndistributions are portrayed as a succession of densities with progressively\nincreasing distances between modes. This precisely elucidates the adverse\neffect of \"modes shift\" in ground truths on the model generalization. Moreover,\nthese estimates are not solely theoretical constructs but have also been\nconfirmed through numerical simulations. Our findings contribute to the\nrigorous understanding of diffusion models' generalization properties and\nprovide insights that may guide practical applications.",
          "link": "http://arxiv.org/abs/2311.01797",
          "publishedOn": "2023-11-07T00:44:07.360Z",
          "wordCount": null,
          "title": "On the Generalization Properties of Diffusion Models. (arXiv:2311.01797v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.09698",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wei Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zexi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Yunqi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Ambuj Singh</a>",
          "description": "Graph Convolutional Networks (GCN) is a pioneering model for graph-based\nsemi-supervised learning. However, GCN does not perform well on\nsparsely-labeled graphs. Its two-layer version cannot effectively propagate the\nlabel information to the whole graph structure (i.e., the under-smoothing\nproblem) while its deep version over-smoothens and is hard to train (i.e., the\nover-smoothing problem). To solve these two issues, we propose a new graph\nneural network called GND-Nets (for Graph Neural Diffusion Networks) that\nexploits the local and global neighborhood information of a vertex in a single\nlayer. Exploiting the shallow network mitigates the over-smoothing problem\nwhile exploiting the local and global neighborhood information mitigates the\nunder-smoothing problem. The utilization of the local and global neighborhood\ninformation of a vertex is achieved by a new graph diffusion method called\nneural diffusions, which integrate neural networks into the conventional linear\nand nonlinear graph diffusions. The adoption of neural networks makes neural\ndiffusions adaptable to different datasets. Extensive experiments on various\nsparsely-labeled graphs verify the effectiveness and efficiency of GND-Nets\ncompared to state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2201.09698",
          "publishedOn": "2023-11-07T00:44:07.067Z",
          "wordCount": 704,
          "title": "Graph Neural Diffusion Networks for Semi-supervised Learning. (arXiv:2201.09698v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.10834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jindong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_F/0/1/0/all/0/1\">Fei Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1\">Gautam Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Sungjin Ahn</a>",
          "description": "The recent success of transformer-based image generative models in\nobject-centric learning highlights the importance of powerful image generators\nfor handling complex scenes. However, despite the high expressiveness of\ndiffusion models in image generation, their integration into object-centric\nlearning remains largely unexplored in this domain. In this paper, we explore\nthe feasibility and potential of integrating diffusion models into\nobject-centric learning and investigate the pros and cons of this approach. We\nintroduce Latent Slot Diffusion (LSD), a novel model that serves dual purposes:\nit is the first object-centric learning model to replace conventional slot\ndecoders with a latent diffusion model conditioned on object slots, and it is\nalso the first unsupervised compositional conditional diffusion model that\noperates without the need for supervised annotations like text. Through\nexperiments on various object-centric tasks, including the first application of\nthe FFHQ dataset in this field, we demonstrate that LSD significantly\noutperforms state-of-the-art transformer-based decoders, particularly in more\ncomplex scenes, and exhibits superior unsupervised compositional generation\nquality. In addition, we conduct a preliminary investigation into the\nintegration of pre-trained diffusion models in LSD and demonstrate its\neffectiveness in real-world image segmentation and generation. Project page is\navailable at https://latentslotdiffusion.github.io",
          "link": "http://arxiv.org/abs/2303.10834",
          "publishedOn": "2023-11-07T00:44:07.052Z",
          "wordCount": 735,
          "title": "Object-Centric Slot Diffusion. (arXiv:2303.10834v5 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.17130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marton_S/0/1/0/all/0/1\">Sascha Marton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludtke_S/0/1/0/all/0/1\">Stefan L&#xfc;dtke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartelt_C/0/1/0/all/0/1\">Christian Bartelt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stuckenschmidt_H/0/1/0/all/0/1\">Heiner Stuckenschmidt</a>",
          "description": "Despite the success of deep learning for text and image data, tree-based\nensemble models are still state-of-the-art for machine learning with\nheterogeneous tabular data. However, there is a significant need for\ntabular-specific gradient-based methods due to their high flexibility. In this\npaper, we propose $\\text{GRANDE}$, $\\text{GRA}$die$\\text{N}$t-Based\n$\\text{D}$ecision Tree $\\text{E}$nsembles, a novel approach for learning hard,\naxis-aligned decision tree ensembles using end-to-end gradient descent. GRANDE\nis based on a dense representation of tree ensembles, which affords to use\nbackpropagation with a straight-through operator to jointly optimize all model\nparameters. Our method combines axis-aligned splits, which is a useful\ninductive bias for tabular data, with the flexibility of gradient-based\noptimization. Furthermore, we introduce an advanced instance-wise weighting\nthat facilitates learning representations for both, simple and complex\nrelations, within a single model. We conducted an extensive evaluation on a\npredefined benchmark with 19 classification datasets and demonstrate that our\nmethod outperforms existing gradient-boosting and deep learning frameworks on\nmost datasets. The method is available under:\nhttps://github.com/s-marton/GRANDE",
          "link": "http://arxiv.org/abs/2309.17130",
          "publishedOn": "2023-11-07T00:44:07.038Z",
          "wordCount": 672,
          "title": "GRANDE: Gradient-Based Decision Tree Ensembles. (arXiv:2309.17130v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16150",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liang_Z/0/1/0/all/0/1\">Ziyun Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Anthony_H/0/1/0/all/0/1\">Harry Anthony</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wagner_F/0/1/0/all/0/1\">Felix Wagner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamnitsas_K/0/1/0/all/0/1\">Konstantinos Kamnitsas</a>",
          "description": "Unsupervised anomaly segmentation aims to detect patterns that are distinct\nfrom any patterns processed during training, commonly called abnormal or\nout-of-distribution patterns, without providing any associated manual\nsegmentations. Since anomalies during deployment can lead to model failure,\ndetecting the anomaly can enhance the reliability of models, which is valuable\nin high-risk domains like medical imaging. This paper introduces Masked\nModality Cycles with Conditional Diffusion (MMCCD), a method that enables\nsegmentation of anomalies across diverse patterns in multimodal MRI. The method\nis based on two fundamental ideas. First, we propose the use of cyclic modality\ntranslation as a mechanism for enabling abnormality detection.\nImage-translation models learn tissue-specific modality mappings, which are\ncharacteristic of tissue physiology. Thus, these learned mappings fail to\ntranslate tissues or image patterns that have never been encountered during\ntraining, and the error enables their segmentation. Furthermore, we combine\nimage translation with a masked conditional diffusion model, which attempts to\n`imagine' what tissue exists under a masked area, further exposing unknown\npatterns as the generative model fails to recreate them. We evaluate our method\non a proxy task by training on healthy-looking slices of BraTS2021\nmulti-modality MRIs and testing on slices with tumors. We show that our method\ncompares favorably to previous unsupervised approaches based on image\nreconstruction and denoising with autoencoders and diffusion models.",
          "link": "http://arxiv.org/abs/2308.16150",
          "publishedOn": "2023-11-07T00:44:07.027Z",
          "wordCount": 785,
          "title": "Modality Cycles with Masked Conditional Diffusion for Unsupervised Anomaly Segmentation in MRI. (arXiv:2308.16150v3 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.07317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_S/0/1/0/all/0/1\">Shuai Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1\">Saurabh Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowak_R/0/1/0/all/0/1\">Robert Nowak</a>",
          "description": "Label efficiency has become an increasingly important objective in deep\nlearning applications. Active learning aims to reduce the number of labeled\nexamples needed to train deep networks, but the empirical performance of active\nlearning algorithms can vary dramatically across datasets and applications. It\nis difficult to know in advance which active learning strategy will perform\nwell or best in a given application. To address this, we propose the first\nadaptive algorithm selection strategy for deep active learning. For any\nunlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning\nalgORithm selection) iteratively and adaptively chooses among a set of\ncandidate active learning algorithms. TAILOR uses novel reward functions aimed\nat gathering class-balanced examples. Extensive experiments in multi-class and\nmulti-label applications demonstrate TAILOR's effectiveness in achieving\naccuracy comparable or better than that of the best of the candidate\nalgorithms. Our implementation of TAILOR is open-sourced at\nhttps://github.com/jifanz/TAILOR.",
          "link": "http://arxiv.org/abs/2302.07317",
          "publishedOn": "2023-11-07T00:44:06.879Z",
          "wordCount": 681,
          "title": "Algorithm Selection for Deep Active Learning with Imbalanced Datasets. (arXiv:2302.07317v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.16578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Ningyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenhao Li</a>",
          "description": "We consider a decision maker allocating one unit of renewable and divisible\nresource in each period on a number of arms. The arms have unknown and random\nrewards whose means are proportional to the allocated resource and whose\nvariances are proportional to an order $b$ of the allocated resource. In\nparticular, if the decision maker allocates resource $A_i$ to arm $i$ in a\nperiod, then the reward $Y_i$ is$Y_i(A_i)=A_i \\mu_i+A_i^b \\xi_{i}$, where\n$\\mu_i$ is the unknown mean and the noise $\\xi_{i}$ is independent and\nsub-Gaussian. When the order $b$ ranges from 0 to 1, the framework smoothly\nbridges the standard stochastic multi-armed bandit and online learning with\nfull feedback. We design two algorithms that attain the optimal gap-dependent\nand gap-independent regret bounds for $b\\in [0,1]$, and demonstrate a phase\ntransition at $b=1/2$. The theoretical results hinge on a novel concentration\ninequality we have developed that bounds a linear combination of sub-Gaussian\nrandom variables whose weights are fractional, adapted to the filtration, and\nmonotonic.",
          "link": "http://arxiv.org/abs/2306.16578",
          "publishedOn": "2023-11-07T00:44:06.778Z",
          "wordCount": 699,
          "title": "Allocating Divisible Resources on Arms with Unknown and Random Rewards. (arXiv:2306.16578v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dang_Z/0/1/0/all/0/1\">Zhuohang Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Minnan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chengyou Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_G/0/1/0/all/0/1\">Guang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jihong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xiaojun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingdong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1\">Qinghua Zheng</a>",
          "description": "Encoding only the task-related information from the raw data, \\ie,\ndisentangled representation learning, can greatly contribute to the robustness\nand generalizability of models. Although significant advances have been made by\nregularizing the information in representations with information theory, two\nmajor challenges remain: 1) the representation compression inevitably leads to\nperformance drop; 2) the disentanglement constraints on representations are in\ncomplicated optimization. To these issues, we introduce Bayesian networks with\ntransmitted information to formulate the interaction among input and\nrepresentations during disentanglement. Building upon this framework, we\npropose \\textbf{DisTIB} (\\textbf{T}ransmitted \\textbf{I}nformation\n\\textbf{B}ottleneck for \\textbf{Dis}entangled representation learning), a novel\nobjective that navigates the balance between information compression and\npreservation. We employ variational inference to derive a tractable estimation\nfor DisTIB. This estimation can be simply optimized via standard gradient\ndescent with a reparameterization trick. Moreover, we theoretically prove that\nDisTIB can achieve optimal disentanglement, underscoring its superior efficacy.\nTo solidify our claims, we conduct extensive experiments on various downstream\ntasks to demonstrate the appealing efficacy of DisTIB and validate our\ntheoretical analyses.",
          "link": "http://arxiv.org/abs/2311.01686",
          "publishedOn": "2023-11-07T00:44:06.770Z",
          "wordCount": 679,
          "title": "Disentangled Representation Learning with Transmitted Information Bottleneck. (arXiv:2311.01686v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.08473",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bonavita_M/0/1/0/all/0/1\">Massimo Bonavita</a>",
          "description": "As in many other areas of engineering and applied science, Machine Learning\n(ML) is having a profound impact in the domain of Weather and Climate\nPrediction. A very recent development in this area has been the emergence of\nfully data-driven ML prediction models which routinely claim superior\nperformance to that of traditional physics-based models. In this work, we\nexamine some aspects of the forecasts produced by an exemplar of the current\ngeneration of ML models, Pangu-Weather, with a focus on the fidelity and\nphysical consistency of those forecasts and how these characteristics relate to\nperceived forecast performance. The main conclusion is that Pangu-Weather\nforecasts, and possibly those of similar ML models, do not have the fidelity\nand physical consistency of physics-based models and their advantage in\naccuracy on traditional deterministic metrics of forecast skill can be at least\npartly attributed to these peculiarities. Balancing forecast skill and physical\nconsistency of ML-driven predictions will be an important consideration for\nfuture ML models. However, and similarly to other modern post-processing\ntechnologies, the current ML models appear to be already able to add value to\nstandard NWP output for specific forecast applications and combined with their\nextremely low computational cost during deployment, are set to provide an\nadditional, useful source of forecast information. .",
          "link": "http://arxiv.org/abs/2309.08473",
          "publishedOn": "2023-11-07T00:44:06.744Z",
          "wordCount": 726,
          "title": "On some limitations of data-driven weather forecasting models. (arXiv:2309.08473v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhenpeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jie M. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarro_F/0/1/0/all/0/1\">Federica Sarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harman_M/0/1/0/all/0/1\">Mark Harman</a>",
          "description": "Existing research mostly improves the fairness of Machine Learning (ML)\nsoftware regarding a single protected attribute at a time, but this is\nunrealistic given that many users have multiple protected attributes. This\npaper conducts an extensive study of fairness improvement regarding multiple\nprotected attributes, covering 11 state-of-the-art fairness improvement\nmethods. We analyze the effectiveness of these methods with different datasets,\nmetrics, and ML models when considering multiple protected attributes. The\nresults reveal that improving fairness for a single protected attribute can\nlargely decrease fairness regarding unconsidered protected attributes. This\ndecrease is observed in up to 88.3% of scenarios (57.5% on average). More\nsurprisingly, we find little difference in accuracy loss when considering\nsingle and multiple protected attributes, indicating that accuracy can be\nmaintained in the multiple-attribute paradigm. However, the effect on precision\nand recall when handling multiple protected attributes is about 5 times and 8\ntimes that of a single attribute. This has important implications for future\nfairness research: reporting only accuracy as the ML performance metric, which\nis currently common in the literature, is inadequate.",
          "link": "http://arxiv.org/abs/2308.01923",
          "publishedOn": "2023-11-07T00:44:06.737Z",
          "wordCount": 747,
          "title": "Fairness Improvement with Multiple Protected Attributes: How Far Are We?. (arXiv:2308.01923v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.05062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lindner_D/0/1/0/all/0/1\">David Lindner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kramar_J/0/1/0/all/0/1\">J&#xe1;nos Kram&#xe1;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1\">Sebastian Farquhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahtz_M/0/1/0/all/0/1\">Matthew Rahtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McGrath_T/0/1/0/all/0/1\">Thomas McGrath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikulik_V/0/1/0/all/0/1\">Vladimir Mikulik</a>",
          "description": "We show how to \"compile\" human-readable programs into standard decoder-only\ntransformer models. Our compiler, Tracr, generates models with known structure.\nThis structure can be used to design experiments. For example, we use it to\nstudy \"superposition\" in transformers that execute multi-step algorithms.\nAdditionally, the known structure of Tracr-compiled models can serve as\nground-truth for evaluating interpretability methods. Commonly, because the\n\"programs\" learned by transformers are unknown it is unclear whether an\ninterpretation succeeded. We demonstrate our approach by implementing and\nexamining programs including computing token frequencies, sorting, and\nparenthesis checking. We provide an open-source implementation of Tracr at\nhttps://github.com/google-deepmind/tracr.",
          "link": "http://arxiv.org/abs/2301.05062",
          "publishedOn": "2023-11-07T00:44:06.719Z",
          "wordCount": 688,
          "title": "Tracr: Compiled Transformers as a Laboratory for Interpretability. (arXiv:2301.05062v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.03028",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sevilla_Salcedo_C/0/1/0/all/0/1\">Carlos Sevilla-Salcedo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gallardo_Antolin_A/0/1/0/all/0/1\">Ascensi&#xf3;n Gallardo-Antol&#xed;n</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gomez_Verdejo_V/0/1/0/all/0/1\">Vanessa G&#xf3;mez-Verdejo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Parrado_Hernandez_E/0/1/0/all/0/1\">Emilio Parrado-Hern&#xe1;ndez</a>",
          "description": "This paper introduces a novel approach for multi-task regression that\nconnects Kernel Machines (KMs) and Extreme Learning Machines (ELMs) through the\nexploitation of the Random Fourier Features (RFFs) approximation of the RBF\nkernel. In this sense, one of the contributions of this paper shows that for\nthe proposed models, the KM and the ELM formulations can be regarded as two\nsides of the same coin. These proposed models, termed RFF-BLR, stand on a\nBayesian framework that simultaneously addresses two main design goals. On the\none hand, it fits multitask regressors based on KMs endowed with RBF kernels.\nOn the other hand, it enables the introduction of a common-across-tasks prior\nthat promotes multioutput sparsity in the ELM view. This Bayesian approach\nfacilitates the simultaneous consideration of both the KM and ELM perspectives\nenabling (i) the optimisation of the RBF kernel parameter $\\gamma$ within a\nprobabilistic framework, (ii) the optimisation of the model complexity, and\n(iii) an efficient transfer of knowledge across tasks. The experimental results\nshow that this framework can lead to significant performance improvements\ncompared to the state-of-the-art methods in multitask nonlinear regression.",
          "link": "http://arxiv.org/abs/2209.03028",
          "publishedOn": "2023-11-07T00:44:06.713Z",
          "wordCount": 700,
          "title": "Bayesian learning of feature spaces for multitasks problems. (arXiv:2209.03028v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chuanhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>",
          "description": "Federated optimization studies the problem of collaborative function\noptimization among multiple clients (e.g. mobile devices or organizations)\nunder the coordination of a central server. Since the data is collected\nseparately by each client and always remains decentralized, federated\noptimization preserves data privacy and allows for large-scale computing, which\nmakes it a promising decentralized machine learning paradigm. Though it is\noften deployed for tasks that are online in nature, e.g., next-word prediction\non keyboard apps, most works formulate it as an offline problem. The few\nexceptions that consider federated bandit optimization are limited to very\nsimplistic function classes, e.g., linear, generalized linear, or\nnon-parametric function class with bounded RKHS norm, which severely hinders\nits practical usage. In this paper, we propose a new algorithm, named\nFed-GO-UCB, for federated bandit optimization with generic non-linear objective\nfunction. Under some mild conditions, we rigorously prove that Fed-GO-UCB is\nable to achieve sub-linear rate for both cumulative regret and communication\ncost. At the heart of our theoretical analysis are distributed regression\noracle and individual confidence set construction, which can be of independent\ninterests. Empirical evaluations also demonstrate the effectiveness of the\nproposed algorithm.",
          "link": "http://arxiv.org/abs/2311.01695",
          "publishedOn": "2023-11-07T00:44:06.706Z",
          "wordCount": 689,
          "title": "Communication-Efficient Federated Non-Linear Bandit Optimization. (arXiv:2311.01695v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.02231",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Banghua Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_H/0/1/0/all/0/1\">Hiteshi Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frujeri_F/0/1/0/all/0/1\">Felipe Vieira Frujeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1\">Shi Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jiantao Jiao</a>",
          "description": "Reinforcement learning from human feedback (RLHF) has emerged as a reliable\napproach to aligning large language models (LLMs) to human preferences. Among\nthe plethora of RLHF techniques, proximal policy optimization (PPO) is of the\nmost widely used methods. Despite its popularity, however, PPO may suffer from\nmode collapse, instability, and poor sample efficiency. We show that these\nissues can be alleviated by a novel algorithm that we refer to as\nAdvantage-Induced Policy Alignment (APA), which leverages a squared error loss\nfunction based on the estimated advantages. We demonstrate empirically that APA\nconsistently outperforms PPO in language tasks by a large margin, when a\nseparate reward model is employed as the evaluator. In addition, compared with\nPPO, APA offers a more stable form of control over the deviation from the\nmodel's initial policy, ensuring that the model improves its performance\nwithout collapsing to deterministic output. In addition to empirical results,\nwe also provide a theoretical justification supporting the design of our loss\nfunction.",
          "link": "http://arxiv.org/abs/2306.02231",
          "publishedOn": "2023-11-07T00:44:06.699Z",
          "wordCount": 705,
          "title": "Fine-Tuning Language Models with Advantage-Induced Policy Alignment. (arXiv:2306.02231v3 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.00586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hanna_M/0/1/0/all/0/1\">Michael Hanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_O/0/1/0/all/0/1\">Ollie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Variengien_A/0/1/0/all/0/1\">Alexandre Variengien</a>",
          "description": "Pre-trained language models can be surprisingly adept at tasks they were not\nexplicitly trained on, but how they implement these capabilities is poorly\nunderstood. In this paper, we investigate the basic mathematical abilities\noften acquired by pre-trained language models. Concretely, we use mechanistic\ninterpretability techniques to explain the (limited) mathematical abilities of\nGPT-2 small. As a case study, we examine its ability to take in sentences such\nas \"The war lasted from the year 1732 to the year 17\", and predict valid\ntwo-digit end years (years > 32). We first identify a circuit, a small subset\nof GPT-2 small's computational graph that computes this task's output. Then, we\nexplain the role of each circuit component, showing that GPT-2 small's final\nmulti-layer perceptrons boost the probability of end years greater than the\nstart year. Finally, we find related tasks that activate our circuit. Our\nresults suggest that GPT-2 small computes greater-than using a complex but\ngeneral mechanism that activates across diverse contexts.",
          "link": "http://arxiv.org/abs/2305.00586",
          "publishedOn": "2023-11-04T00:42:37.868Z",
          "wordCount": null,
          "title": "How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. (arXiv:2305.00586v5 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15208",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gao_R/0/1/0/all/0/1\">Richard Gao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deistler_M/0/1/0/all/0/1\">Michael Deistler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Macke_J/0/1/0/all/0/1\">Jakob H. Macke</a>",
          "description": "Simulation-based inference (SBI) enables amortized Bayesian inference for\nsimulators with implicit likelihoods. But when we are primarily interested in\nthe quality of predictive simulations, or when the model cannot exactly\nreproduce the observed data (i.e., is misspecified), targeting the Bayesian\nposterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims\nto robustify inference for (misspecified) simulator models, replacing the\nlikelihood-function with a cost function that evaluates the goodness of\nparameters relative to data. However, GBI methods generally require running\nmultiple simulations to estimate the cost function at each parameter value\nduring inference, making the approach computationally infeasible for even\nmoderately complex simulators. Here, we propose amortized cost estimation (ACE)\nfor GBI to address this challenge: We train a neural network to approximate the\ncost function, which we define as the expected distance between simulations\nproduced by a parameter and observed data. The trained network can then be used\nwith MCMC to infer GBI posteriors for any observation without running\nadditional simulations. We show that, on several benchmark tasks, ACE\naccurately predicts cost and provides predictive simulations that are closer to\nsynthetic observations than other SBI methods, especially for misspecified\nsimulators. Finally, we apply ACE to infer parameters of the Hodgkin-Huxley\nmodel given real intracellular recordings from the Allen Cell Types Database.\nACE identifies better data-matching parameters while being an order of\nmagnitude more simulation-efficient than a standard SBI method. In summary, ACE\ncombines the strengths of SBI methods and GBI to perform robust and\nsimulation-amortized inference for scientific simulators.",
          "link": "http://arxiv.org/abs/2305.15208",
          "publishedOn": "2023-11-04T00:42:37.868Z",
          "wordCount": null,
          "title": "Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation. (arXiv:2305.15208v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.00806",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yunbei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeevi_A/0/1/0/all/0/1\">Assaf Zeevi</a>",
          "description": "We develop a general theory to optimize the frequentist regret for sequential\nlearning problems, where efficient bandit and reinforcement learning algorithms\ncan be derived from unified Bayesian principles. We propose a novel\noptimization approach to generate \"algorithmic beliefs\" at each round, and use\nBayesian posteriors to make decisions. The optimization objective to create\n\"algorithmic beliefs,\" which we term \"Algorithmic Information Ratio,\"\nrepresents an intrinsic complexity measure that effectively characterizes the\nfrequentist regret of any algorithm. To the best of our knowledge, this is the\nfirst systematical approach to make Bayesian-type algorithms prior-free and\napplicable to adversarial settings, in a generic and optimal manner. Moreover,\nthe algorithms are simple and often efficient to implement. As a major\napplication, we present a novel algorithm for multi-armed bandits that achieves\nthe \"best-of-all-worlds\" empirical performance in the stochastic, adversarial,\nand non-stationary environments. And we illustrate how these principles can be\nused in linear bandits, bandit convex optimization, and reinforcement learning.",
          "link": "http://arxiv.org/abs/2310.00806",
          "publishedOn": "2023-11-04T00:42:37.867Z",
          "wordCount": null,
          "title": "Bayesian Design Principles for Frequentist Sequential Learning. (arXiv:2310.00806v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.10284",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gregoratti_D/0/1/0/all/0/1\">David Gregoratti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mestre_X/0/1/0/all/0/1\">Xavier Mestre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buelga_C/0/1/0/all/0/1\">Carlos Buelga</a>",
          "description": "A structured variable selection problem is considered in which the\ncovariates, divided into predefined groups, activate according to sparse\npatterns with few nonzero entries per group. Capitalizing on the concept of\natomic norm, a composite norm can be properly designed to promote such\nexclusive group sparsity patterns. The resulting norm lends itself to efficient\nand flexible regularized optimization algorithms for support recovery, like the\nproximal algorithm. Moreover, an active set algorithm is proposed that builds\nthe solution by successively including structure atoms into the estimated\nsupport. It is also shown that such an algorithm can be tailored to match more\nrigid structures than plain exclusive group sparsity. Asymptotic consistency\nanalysis (with both the number of parameters as well as the number of groups\ngrowing with the observation size) establishes the effectiveness of the\nproposed solution in terms of signed support recovery under conventional\nassumptions. Finally, a set of numerical simulations further corroborates the\nresults.",
          "link": "http://arxiv.org/abs/2108.10284",
          "publishedOn": "2023-11-04T00:42:37.864Z",
          "wordCount": null,
          "title": "Exclusive Group Lasso for Structured Variable Selection. (arXiv:2108.10284v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neururer_D/0/1/0/all/0/1\">Daniel Neururer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dellwo_V/0/1/0/all/0/1\">Volker Dellwo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stadelmann_T/0/1/0/all/0/1\">Thilo Stadelmann</a>",
          "description": "While deep neural networks have shown impressive results in automatic speaker\nrecognition and related tasks, it is dissatisfactory how little is understood\nabout what exactly is responsible for these results. Part of the success has\nbeen attributed in prior work to their capability to model supra-segmental\ntemporal information (SST), i.e., learn rhythmic-prosodic characteristics of\nspeech in addition to spectral features. In this paper, we (i) present and\napply a novel test to quantify to what extent the performance of\nstate-of-the-art neural networks for speaker recognition can be explained by\nmodeling SST; and (ii) present several means to force respective nets to focus\nmore on SST and evaluate their merits. We find that a variety of CNN- and\nRNN-based neural network architectures for speaker recognition do not model SST\nto any sufficient degree, even when forced. The results provide a highly\nrelevant basis for impactful future research into better exploitation of the\nfull speech signal and give insights into the inner workings of such networks,\nenhancing explainability of deep learning for speech technologies.",
          "link": "http://arxiv.org/abs/2311.00489",
          "publishedOn": "2023-11-04T00:42:37.862Z",
          "wordCount": null,
          "title": "Deep Neural Networks for Automatic Speaker Recognition Do Not Learn Supra-Segmental Temporal Features. (arXiv:2311.00489v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.12874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gazdieva_M/0/1/0/all/0/1\">Milena Gazdieva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1\">Alexander Korotin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selikhanovych_D/0/1/0/all/0/1\">Daniil Selikhanovych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>",
          "description": "In many unpaired image domain translation problems, e.g., style transfer or\nsuper-resolution, it is important to keep the translated image similar to its\nrespective input image. We propose the extremal transport (ET) which is a\nmathematical formalization of the theoretically best possible unpaired\ntranslation between a pair of domains w.r.t. the given similarity function.\nInspired by the recent advances in neural optimal transport (OT), we propose a\nscalable algorithm to approximate ET maps as a limit of partial OT maps. We\ntest our algorithm on toy examples and on the unpaired image-to-image\ntranslation task. The code is publicly available at\nhttps://github.com/milenagazdieva/ExtremalNeuralOptimalTransport",
          "link": "http://arxiv.org/abs/2301.12874",
          "publishedOn": "2023-11-04T00:42:37.860Z",
          "wordCount": null,
          "title": "Extremal Domain Translation with Neural Optimal Transport. (arXiv:2301.12874v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.14724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Olatunji_I/0/1/0/all/0/1\">Iyiola E. Olatunji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rathee_M/0/1/0/all/0/1\">Mandeep Rathee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funke_T/0/1/0/all/0/1\">Thorben Funke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khosla_M/0/1/0/all/0/1\">Megha Khosla</a>",
          "description": "Privacy and interpretability are two important ingredients for achieving\ntrustworthy machine learning. We study the interplay of these two aspects in\ngraph machine learning through graph reconstruction attacks. The goal of the\nadversary here is to reconstruct the graph structure of the training data given\naccess to model explanations. Based on the different kinds of auxiliary\ninformation available to the adversary, we propose several graph reconstruction\nattacks. We show that additional knowledge of post-hoc feature explanations\nsubstantially increases the success rate of these attacks. Further, we\ninvestigate in detail the differences between attack performance with respect\nto three different classes of explanation methods for graph neural networks:\ngradient-based, perturbation-based, and surrogate model-based methods. While\ngradient-based explanations reveal the most in terms of the graph structure, we\nfind that these explanations do not always score high in utility. For the other\ntwo classes of explanations, privacy leakage increases with an increase in\nexplanation utility. Finally, we propose a defense based on a randomized\nresponse mechanism for releasing the explanations, which substantially reduces\nthe attack success rate. Our code is available at\nhttps://github.com/iyempissy/graph-stealing-attacks-with-explanation",
          "link": "http://arxiv.org/abs/2206.14724",
          "publishedOn": "2023-11-04T00:42:37.859Z",
          "wordCount": null,
          "title": "Private Graph Extraction via Feature Explanations. (arXiv:2206.14724v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.09750",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beltran_E/0/1/0/all/0/1\">Enrique Tom&#xe1;s Mart&#xed;nez Beltr&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1\">&#xc1;ngel Luis Perales G&#xf3;mez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1\">Chao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_P/0/1/0/all/0/1\">Pedro Miguel S&#xe1;nchez S&#xe1;nchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernal_S/0/1/0/all/0/1\">Sergio L&#xf3;pez Bernal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bovet_G/0/1/0/all/0/1\">G&#xe9;r&#xf4;me Bovet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1\">Manuel Gil P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_G/0/1/0/all/0/1\">Gregorio Mart&#xed;nez P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celdran_A/0/1/0/all/0/1\">Alberto Huertas Celdr&#xe1;n</a>",
          "description": "In 2016, Google proposed Federated Learning (FL) as a novel paradigm to train\nMachine Learning (ML) models across the participants of a federation while\npreserving data privacy. Since its birth, Centralized FL (CFL) has been the\nmost used approach, where a central entity aggregates participants' models to\ncreate a global one. However, CFL presents limitations such as communication\nbottlenecks, single point of failure, and reliance on a central server.\nDecentralized Federated Learning (DFL) addresses these issues by enabling\ndecentralized model aggregation and minimizing dependency on a central entity.\nDespite these advances, current platforms training DFL models struggle with key\nissues such as managing heterogeneous federation network topologies. To\novercome these challenges, this paper presents Fedstellar, a novel platform\ndesigned to train FL models in a decentralized, semi-decentralized, and\ncentralized fashion across diverse federations of physical or virtualized\ndevices. The Fedstellar implementation encompasses a web application with an\ninteractive graphical interface, a controller for deploying federations of\nnodes using physical or virtual devices, and a core deployed on each device\nwhich provides the logic needed to train, aggregate, and communicate in the\nnetwork. The effectiveness of the platform has been demonstrated in two\nscenarios: a physical deployment involving single-board devices such as\nRaspberry Pis for detecting cyberattacks, and a virtualized deployment\ncomparing various FL approaches in a controlled environment using MNIST and\nCIFAR-10 datasets. In both scenarios, Fedstellar demonstrated consistent\nperformance and adaptability, achieving F1 scores of 91%, 98%, and 91.2% using\nDFL for detecting cyberattacks and classifying MNIST and CIFAR-10,\nrespectively, reducing training time by 32% compared to centralized approaches.",
          "link": "http://arxiv.org/abs/2306.09750",
          "publishedOn": "2023-11-04T00:42:37.859Z",
          "wordCount": null,
          "title": "Fedstellar: A Platform for Decentralized Federated Learning. (arXiv:2306.09750v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahmani_A/0/1/0/all/0/1\">Abdellah Rahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1\">Pascal Frossard</a>",
          "description": "The task of uncovering causal relationships among multivariate time series\ndata stands as an essential and challenging objective that cuts across a broad\narray of disciplines ranging from climate science to healthcare. Such data\nentails linear or non-linear relationships, and usually follow multiple a\npriori unknown regimes. Existing causal discovery methods can infer summary\ncausal graphs from heterogeneous data with known regimes, but they fall short\nin comprehensively learning both regimes and the corresponding causal graph. In\nthis paper, we introduce CASTOR, a novel framework designed to learn causal\nrelationships in heterogeneous time series data composed of various regimes,\neach governed by a distinct causal graph. Through the maximization of a score\nfunction via the EM algorithm, CASTOR infers the number of regimes and learns\nlinear or non-linear causal relationships in each regime. We demonstrate the\nrobust convergence properties of CASTOR, specifically highlighting its\nproficiency in accurately identifying unique regimes. Empirical evidence,\ngarnered from exhaustive synthetic experiments and two real-world benchmarks,\nconfirm CASTOR's superior performance in causal discovery compared to baseline\nmethods. By learning a full temporal causal graph for each regime, CASTOR\nestablishes itself as a distinctly interpretable method for causal discovery in\nheterogeneous time series.",
          "link": "http://arxiv.org/abs/2311.01412",
          "publishedOn": "2023-11-04T00:42:37.858Z",
          "wordCount": null,
          "title": "Castor: Causal Temporal Regime Structure Learning. (arXiv:2311.01412v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.06950",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yang_R/0/1/0/all/0/1\">Ruihan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "This paper outlines an end-to-end optimized lossy image compression framework\nusing diffusion generative models. The approach relies on the transform coding\nparadigm, where an image is mapped into a latent space for entropy coding and,\nfrom there, mapped back to the data space for reconstruction. In contrast to\nVAE-based neural compression, where the (mean) decoder is a deterministic\nneural network, our decoder is a conditional diffusion model. Our approach thus\nintroduces an additional \"content\" latent variable on which the reverse\ndiffusion process is conditioned and uses this variable to store information\nabout the image. The remaining \"texture\" variables characterizing the diffusion\nprocess are synthesized at decoding time. We show that the model's performance\ncan be tuned toward perceptual metrics of interest. Our extensive experiments\ninvolving multiple datasets and image quality assessment metrics show that our\napproach yields stronger reported FID scores than the GAN-based model, while\nalso yielding competitive performance with VAE-based models in several\ndistortion metrics. Furthermore, training the diffusion with X-parameterization\nenables high-quality reconstructions in only a handful of decoding steps,\ngreatly affecting the model's practicality.",
          "link": "http://arxiv.org/abs/2209.06950",
          "publishedOn": "2023-11-04T00:42:37.856Z",
          "wordCount": null,
          "title": "Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v6 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.04037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Di_S/0/1/0/all/0/1\">Sheng Di</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">Sian Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1\">Kai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zizhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cappello_F/0/1/0/all/0/1\">Franck Cappello</a>",
          "description": "The fast growth of computational power and scales of modern super-computing\nsystems have raised great challenges for the management of exascale scientific\ndata. To maintain the usability of scientific data, error-bound lossy\ncompression is proposed and developed as an essential technique for the size\nreduction of scientific data with constrained data distortion. Among the\ndiverse datasets generated by various scientific simulations, certain datasets\ncannot be effectively compressed by existing error-bounded lossy compressors\nwith traditional techniques. The recent success of Artificial Intelligence has\ninspired several researchers to integrate neural networks into error-bounded\nlossy compressors. However, those works still suffer from limited compression\nratios and/or extremely low efficiencies. To address those issues and improve\nthe compression on the hard-to-compress datasets, in this paper, we propose\nSRN-SZ, which is a deep learning-based scientific error-bounded lossy\ncompressor leveraging the hierarchical data grid expansion paradigm implemented\nby super-resolution neural networks. SRN-SZ applies the most advanced\nsuper-resolution network HAT for its compression, which is free of time-costing\nper-data training. In experiments compared with various state-of-the-art\ncompressors, SRN-SZ achieves up to 75% compression ratio improvements under the\nsame error bound and up to 80% compression ratio improvements under the same\nPSNR than the second-best compressor.",
          "link": "http://arxiv.org/abs/2309.04037",
          "publishedOn": "2023-11-04T00:42:37.855Z",
          "wordCount": null,
          "title": "SRN-SZ: Deep Leaning-Based Scientific Error-bounded Lossy Compression with Super-resolution Neural Networks. (arXiv:2309.04037v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Javier Gonz&#xe1;lez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1\">Cliff Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gero_Z/0/1/0/all/0/1\">Zelalem Gero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagga_J/0/1/0/all/0/1\">Jass Bagga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueno_R/0/1/0/all/0/1\">Risa Ueno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_I/0/1/0/all/0/1\">Isabel Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orakvin_E/0/1/0/all/0/1\">Eduard Orakvin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiciman_E/0/1/0/all/0/1\">Emre Kiciman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nori_A/0/1/0/all/0/1\">Aditya Nori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weerasinghe_R/0/1/0/all/0/1\">Roshanthi Weerasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leidner_R/0/1/0/all/0/1\">Rom S. Leidner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piening_B/0/1/0/all/0/1\">Brian Piening</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumann_T/0/1/0/all/0/1\">Tristan Naumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bifulco_C/0/1/0/all/0/1\">Carlo Bifulco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>",
          "description": "The rapid digitization of real-world data offers an unprecedented opportunity\nfor optimizing healthcare delivery and accelerating biomedical discovery. In\npractice, however, such data is most abundantly available in unstructured\nforms, such as clinical notes in electronic medical records (EMRs), and it is\ngenerally plagued by confounders. In this paper, we present TRIALSCOPE, a\nunifying framework for distilling real-world evidence from population-level\nobservational data. TRIALSCOPE leverages biomedical language models to\nstructure clinical text at scale, employs advanced probabilistic modeling for\ndenoising and imputation, and incorporates state-of-the-art causal inference\ntechniques to combat common confounders. Using clinical trial specification as\ngeneric representation, TRIALSCOPE provides a turn-key solution to generate and\nreason with clinical hypotheses using observational data. In extensive\nexperiments and analyses on a large-scale real-world dataset with over one\nmillion cancer patients from a large US healthcare network, we show that\nTRIALSCOPE can produce high-quality structuring of real-world data and\ngenerates comparable results to marquee cancer trials. In addition to\nfacilitating in-silicon clinical trial design and optimization, TRIALSCOPE may\nbe used to empower synthetic controls, pragmatic trials, post-market\nsurveillance, as well as support fine-grained patient-like-me reasoning in\nprecision diagnosis and treatment.",
          "link": "http://arxiv.org/abs/2311.01301",
          "publishedOn": "2023-11-04T00:42:37.852Z",
          "wordCount": null,
          "title": "TRIALSCOPE A Unifying Causal Framework for Scaling Real-World Evidence Generation with Biomedical Language Models. (arXiv:2311.01301v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nie_S/0/1/0/all/0/1\">Shen Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hanzhong Allan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Cheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chenyu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chongxuan Li</a>",
          "description": "We present a unified probabilistic formulation for diffusion-based image\nediting, where a latent variable is edited in a task-specific manner and\ngenerally deviates from the corresponding marginal distribution induced by the\noriginal stochastic or ordinary differential equation (SDE or ODE). Instead, it\ndefines a corresponding SDE or ODE for editing. In the formulation, we prove\nthat the Kullback-Leibler divergence between the marginal distributions of the\ntwo SDEs gradually decreases while that for the ODEs remains as the time\napproaches zero, which shows the promise of SDE in image editing. Inspired by\nit, we provide the SDE counterparts for widely used ODE baselines in various\ntasks including inpainting and image-to-image translation, where SDE shows a\nconsistent and substantial improvement. Moreover, we propose SDE-Drag -- a\nsimple yet effective method built upon the SDE formulation for point-based\ncontent dragging. We build a challenging benchmark (termed DragBench) with\nopen-set natural, art, and AI-generated images for evaluation. A user study on\nDragBench indicates that SDE-Drag significantly outperforms our ODE baseline,\nexisting diffusion-based methods, and the renowned DragGAN. Our results\ndemonstrate the superiority and versatility of SDE in image editing and push\nthe boundary of diffusion-based editing methods.",
          "link": "http://arxiv.org/abs/2311.01410",
          "publishedOn": "2023-11-04T00:42:37.836Z",
          "wordCount": null,
          "title": "The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing. (arXiv:2311.01410v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.09259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ashkboos_S/0/1/0/all/0/1\">Saleh Ashkboos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1\">Ilia Markov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frantar_E/0/1/0/all/0/1\">Elias Frantar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_T/0/1/0/all/0/1\">Tingxuan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xincheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1\">Torsten Hoefler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>",
          "description": "Large Language Models (LLMs) from the GPT family have become extremely\npopular, leading to a race towards reducing their inference costs to allow for\nefficient local computation. Yet, the vast majority of existing work focuses on\nweight-only quantization, which can reduce runtime costs in the memory-bound\none-token-at-a-time generative setting, but does not address them in\ncompute-bound scenarios, such as batched inference or prompt processing. In\nthis paper, we address the general quantization problem, where both weights and\nactivations should be quantized. We show, for the first time, that the majority\nof inference computations for large generative models such as LLaMA, OPT, and\nFalcon can be performed with both weights and activations being cast to 4 bits,\nin a way that leads to practical speedups, while at the same time maintaining\ngood accuracy. We achieve this via a hybrid quantization strategy called QUIK,\nwhich compresses most of the weights and activations to 4-bit, while keeping\nsome outlier weights and activations in higher-precision. The key feature of\nour scheme is that it is designed with computational efficiency in mind: we\nprovide GPU kernels matching the QUIK format with highly-efficient layer-wise\nruntimes, which lead to practical end-to-end throughput improvements of up to\n3.4x relative to FP16 execution. We provide detailed studies for models from\nthe OPT, LLaMA-2 and Falcon families, as well as a first instance of accurate\ninference using quantization plus 2:4 sparsity. Code is available at:\nhttps://github.com/IST-DASLab/QUIK.",
          "link": "http://arxiv.org/abs/2310.09259",
          "publishedOn": "2023-11-04T00:42:37.832Z",
          "wordCount": null,
          "title": "QUIK: Towards End-to-End 4-Bit Inference on Generative Large Language Models. (arXiv:2310.09259v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.07828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dohi_K/0/1/0/all/0/1\">Kota Dohi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imoto_K/0/1/0/all/0/1\">Keisuke Imoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harada_N/0/1/0/all/0/1\">Noboru Harada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niizumi_D/0/1/0/all/0/1\">Daisuke Niizumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koizumi_Y/0/1/0/all/0/1\">Yuma Koizumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishida_T/0/1/0/all/0/1\">Tomoya Nishida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purohit_H/0/1/0/all/0/1\">Harsh Purohit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanabe_R/0/1/0/all/0/1\">Ryo Tanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Endo_T/0/1/0/all/0/1\">Takashi Endo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_Y/0/1/0/all/0/1\">Yohei Kawaguchi</a>",
          "description": "We present the task description of the Detection and Classification of\nAcoustic Scenes and Events (DCASE) 2023 Challenge Task 2: ``First-shot\nunsupervised anomalous sound detection (ASD) for machine condition\nmonitoring''. The main goal is to enable rapid deployment of ASD systems for\nnew kinds of machines without the need for hyperparameter tuning. In the past\nASD tasks, developed methods tuned hyperparameters for each machine type, as\nthe development and evaluation datasets had the same machine types. However,\ncollecting normal and anomalous data as the development dataset can be\ninfeasible in practice. In 2023 Task 2, we focus on solving the first-shot\nproblem, which is the challenge of training a model on a completely novel\nmachine type. Specifically, (i) each machine type has only one section (a\nsubset of machine type) and (ii) machine types in the development and\nevaluation datasets are completely different. Analysis of 86 submissions from\n23 teams revealed that the keys to outperform baselines were: 1) sampling\ntechniques for dealing with class imbalances across different domains and\nattributes, 2) generation of synthetic samples for robust detection, and 3) use\nof multiple large pre-trained models to extract meaningful embeddings for the\nanomaly detector.",
          "link": "http://arxiv.org/abs/2305.07828",
          "publishedOn": "2023-11-04T00:42:37.827Z",
          "wordCount": null,
          "title": "Description and Discussion on DCASE 2023 Challenge Task 2: First-Shot Unsupervised Anomalous Sound Detection for Machine Condition Monitoring. (arXiv:2305.07828v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.13425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1\">Han Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1\">Shu Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiacheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zichao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahnoun_N/0/1/0/all/0/1\">Naim Dahnoun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiren Zhao</a>",
          "description": "Millimetre-wave (mmWave) radar has emerged as an attractive and\ncost-effective alternative for human activity sensing compared to traditional\ncamera-based systems. mmWave radars are also non-intrusive, providing better\nprotection for user privacy. However, as a Radio Frequency (RF) based\ntechnology, mmWave radars rely on capturing reflected signals from objects,\nmaking them more prone to noise compared to cameras. This raises an intriguing\nquestion for the deep learning community: Can we develop more effective point\nset-based deep learning methods for such attractive sensors?\n\nTo answer this question, our work, termed MiliPoint, delves into this idea by\nproviding a large-scale, open dataset for the community to explore how mmWave\nradars can be utilised for human activity recognition. Moreover, MiliPoint\nstands out as it is larger in size than existing datasets, has more diverse\nhuman actions represented, and encompasses all three key tasks in human\nactivity recognition. We have also established a range of point-based deep\nneural networks such as DGCNN, PointNet++ and PointTransformer, on MiliPoint,\nwhich can serve to set the ground baseline for further development.",
          "link": "http://arxiv.org/abs/2309.13425",
          "publishedOn": "2023-11-04T00:42:37.824Z",
          "wordCount": null,
          "title": "MiliPoint: A Point Cloud Dataset for mmWave Radar. (arXiv:2309.13425v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.13441",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cheng_T/0/1/0/all/0/1\">Taoli Cheng</a>",
          "description": "The application of machine learning in sciences has seen exciting advances in\nrecent years. As a widely applicable technique, anomaly detection has been long\nstudied in the machine learning community. Especially, deep neural nets-based\nout-of-distribution detection has made great progress for high-dimensional\ndata. Recently, these techniques have been showing their potential in\nscientific disciplines. We take a critical look at their applicative prospects\nincluding data universality, experimental protocols, model robustness, etc. We\ndiscuss examples that display transferable practices and domain-specific\nchallenges simultaneously, providing a starting point for establishing a novel\ninterdisciplinary research paradigm in the near future.",
          "link": "http://arxiv.org/abs/2210.13441",
          "publishedOn": "2023-11-04T00:42:37.821Z",
          "wordCount": null,
          "title": "Bridging Machine Learning and Sciences: Opportunities and Challenges. (arXiv:2210.13441v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.04015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Javanmard_A/0/1/0/all/0/1\">Adel Javanmard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1\">Vahab Mirrokni</a>",
          "description": "While personalized recommendations systems have become increasingly popular,\nensuring user data protection remains a top concern in the development of these\nlearning systems. A common approach to enhancing privacy involves training\nmodels using anonymous data rather than individual data. In this paper, we\nexplore a natural technique called \\emph{look-alike clustering}, which involves\nreplacing sensitive features of individuals with the cluster's average values.\nWe provide a precise analysis of how training models using anonymous cluster\ncenters affects their generalization capabilities. We focus on an asymptotic\nregime where the size of the training set grows in proportion to the features\ndimension. Our analysis is based on the Convex Gaussian Minimax Theorem (CGMT)\nand allows us to theoretically understand the role of different model\ncomponents on the generalization error. In addition, we demonstrate that in\ncertain high-dimensional regimes, training over anonymous cluster centers acts\nas a regularization and improves generalization error of the trained models.\nFinally, we corroborate our asymptotic theory with finite-sample numerical\nexperiments where we observe a perfect match when the sample size is only of\norder of a few hundreds.",
          "link": "http://arxiv.org/abs/2310.04015",
          "publishedOn": "2023-11-04T00:42:37.818Z",
          "wordCount": null,
          "title": "Anonymous Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization. (arXiv:2310.04015v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.18333",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tennenholtz_G/0/1/0/all/0/1\">Guy Tennenholtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mladenov_M/0/1/0/all/0/1\">Martin Mladenov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merlis_N/0/1/0/all/0/1\">Nadav Merlis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Axtell_R/0/1/0/all/0/1\">Robert L. Axtell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1\">Craig Boutilier</a>",
          "description": "While popularity bias is recognized to play a crucial role in recommmender\n(and other ranking-based) systems, detailed analysis of its impact on\ncollective user welfare has largely been lacking. We propose and theoretically\nanalyze a general mechanism, rooted in many of the models proposed in the\nliterature, by which item popularity, item quality, and position bias jointly\nimpact user choice. We focus on a standard setting in which user utility is\nlargely driven by item quality, and a recommender attempts to estimate it given\nuser behavior. Formulating the problem as a non-stationary contextual bandit,\nwe study the ability of a recommender policy to maximize user welfare under\nthis model. We highlight the importance of exploration, not to eliminate\npopularity bias, but to mitigate its negative impact on welfare. We first show\nthat naive popularity-biased recommenders induce linear regret by conflating\nitem quality and popularity. More generally, we show that, even in linear\nsettings, identifiability of item quality may not be possible due to the\nconfounding effects of popularity bias. However, under sufficient variability\nassumptions, we develop an efficient optimistic algorithm and prove efficient\nregret guarantees w.r.t. user welfare. We complement our analysis with several\nsimulation studies, which demonstrate the negative impact of popularity bias on\nthe performance of several natural recommender policies.",
          "link": "http://arxiv.org/abs/2305.18333",
          "publishedOn": "2023-11-04T00:42:37.815Z",
          "wordCount": null,
          "title": "Ranking with Popularity Bias: User Welfare under Self-Amplification Dynamics. (arXiv:2305.18333v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.11104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulvicius_T/0/1/0/all/0/1\">Tomas Kulvicius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamosiunaite_M/0/1/0/all/0/1\">Minija Tamosiunaite</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Worgotter_F/0/1/0/all/0/1\">Florentin W&#xf6;rg&#xf6;tter</a>",
          "description": "Finding optimal paths in connected graphs requires determining the smallest\ntotal cost for traveling along the graph's edges. This problem can be solved by\nseveral classical algorithms where, usually, costs are predefined for all\nedges. Conventional planning methods can, thus, normally not be used when\nwanting to change costs in an adaptive way following the requirements of some\ntask. Here we show that one can define a neural network representation of path\nfinding problems by transforming cost values into synaptic weights, which\nallows for online weight adaptation using network learning mechanisms. When\nstarting with an initial activity value of one, activity propagation in this\nnetwork will lead to solutions, which are identical to those found by the\nBellman-Ford algorithm. The neural network has the same algorithmic complexity\nas Bellman-Ford and, in addition, we can show that network learning mechanisms\n(such as Hebbian learning) can adapt the weights in the network augmenting the\nresulting paths according to some task at hand. We demonstrate this by learning\nto navigate in an environment with obstacles as well as by learning to follow\ncertain sequences of path nodes. Hence, the here-presented novel algorithm may\nopen up a different regime of applications where path-augmentation (by\nlearning) is directly coupled with path finding in a natural way.",
          "link": "http://arxiv.org/abs/2201.11104",
          "publishedOn": "2023-11-04T00:42:37.814Z",
          "wordCount": null,
          "title": "Combining Optimal Path Search With Task-Dependent Learning in a Neural Network. (arXiv:2201.11104v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.03698",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boker_J/0/1/0/all/0/1\">Jan B&#xf6;ker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levie_R/0/1/0/all/0/1\">Ron Levie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_N/0/1/0/all/0/1\">Ningyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villar_S/0/1/0/all/0/1\">Soledad Villar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_C/0/1/0/all/0/1\">Christopher Morris</a>",
          "description": "Numerous recent works have analyzed the expressive power of message-passing\ngraph neural networks (MPNNs), primarily utilizing combinatorial techniques\nsuch as the $1$-dimensional Weisfeiler-Leman test ($1$-WL) for the graph\nisomorphism problem. However, the graph isomorphism objective is inherently\nbinary, not giving insights into the degree of similarity between two given\ngraphs. This work resolves this issue by considering continuous extensions of\nboth $1$-WL and MPNNs to graphons. Concretely, we show that the continuous\nvariant of $1$-WL delivers an accurate topological characterization of the\nexpressive power of MPNNs on graphons, revealing which graphs these networks\ncan distinguish and the level of difficulty in separating them. We identify the\nfinest topology where MPNNs separate points and prove a universal approximation\ntheorem. Consequently, we provide a theoretical framework for graph and graphon\nsimilarity combining various topological variants of classical\ncharacterizations of the $1$-WL. In particular, we characterize the expressive\npower of MPNNs in terms of the tree distance, which is a graph distance based\non the concept of fractional isomorphisms, and substructure counts via tree\nhomomorphisms, showing that these concepts have the same expressive power as\nthe $1$-WL and MPNNs on graphons. Empirically, we validate our theoretical\nfindings by showing that randomly initialized MPNNs, without training, exhibit\ncompetitive performance compared to their trained counterparts. Moreover, we\nevaluate different MPNN architectures based on their ability to preserve graph\ndistances, highlighting the significance of our continuous $1$-WL test in\nunderstanding MPNNs' expressivity.",
          "link": "http://arxiv.org/abs/2306.03698",
          "publishedOn": "2023-11-04T00:42:37.814Z",
          "wordCount": null,
          "title": "Fine-grained Expressivity of Graph Neural Networks. (arXiv:2306.03698v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1\">Kai Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1\">Alexander G. Schwing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiong Wang</a>",
          "description": "Offline imitation from observations aims to solve MDPs where only\ntask-specific expert states and task-agnostic non-expert state-action pairs are\navailable. Offline imitation is useful in real-world scenarios where arbitrary\ninteractions are costly and expert actions are unavailable. The\nstate-of-the-art \"DIstribution Correction Estimation\" (DICE) methods minimize\ndivergence of state occupancy between expert and learner policies and retrieve\na policy with weighted behavior cloning; however, their results are unstable\nwhen learning from incomplete trajectories, due to a non-robust optimization in\nthe dual domain. To address the issue, in this paper, we propose\nTrajectory-Aware Imitation Learning from Observations (TAILO). TAILO uses a\ndiscounted sum along the future trajectory as the weight for weighted behavior\ncloning. The terms for the sum are scaled by the output of a discriminator,\nwhich aims to identify expert states. Despite simplicity, TAILO works well if\nthere exist trajectories or segments of expert behavior in the task-agnostic\ndata, a common assumption in prior work. In experiments across multiple\ntestbeds, we find TAILO to be more robust and effective, particularly with\nincomplete trajectories.",
          "link": "http://arxiv.org/abs/2311.01329",
          "publishedOn": "2023-11-04T00:42:37.809Z",
          "wordCount": null,
          "title": "A Simple Solution for Offline Imitation from Observations and Examples with Possibly Incomplete Trajectories. (arXiv:2311.01329v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.05147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_Q/0/1/0/all/0/1\">Qingfeng Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tosatto_S/0/1/0/all/0/1\">Samuele Tosatto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farrahi_H/0/1/0/all/0/1\">Homayoon Farrahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1\">A. Rupam Mahmood</a>",
          "description": "Despite the increasing popularity of policy gradient methods, they are yet to\nbe widely utilized in sample-scarce applications, such as robotics. The sample\nefficiency could be improved by making best usage of available information. As\na key component in reinforcement learning, the reward function is usually\ndevised carefully to guide the agent. Hence, the reward function is usually\nknown, allowing access to not only scalar reward signals but also reward\ngradients. To benefit from reward gradients, previous works require the\nknowledge of environment dynamics, which are hard to obtain. In this work, we\ndevelop the \\textit{Reward Policy Gradient} estimator, a novel approach that\nintegrates reward gradients without learning a model. Bypassing the model\ndynamics allows our estimator to achieve a better bias-variance trade-off,\nwhich results in a higher sample efficiency, as shown in the empirical\nanalysis. Our method also boosts the performance of Proximal Policy\nOptimization on different MuJoCo control tasks.",
          "link": "http://arxiv.org/abs/2103.05147",
          "publishedOn": "2023-11-04T00:42:37.809Z",
          "wordCount": null,
          "title": "Model-free Policy Learning with Reward Gradients. (arXiv:2103.05147v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.19793",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bietti_A/0/1/0/all/0/1\">Alberto Bietti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1\">Loucas Pillaud-Vivien</a>",
          "description": "We study gradient flow on the multi-index regression problem for\nhigh-dimensional Gaussian data. Multi-index functions consist of a composition\nof an unknown low-rank linear projection and an arbitrary unknown,\nlow-dimensional link function. As such, they constitute a natural template for\nfeature learning in neural networks.\n\nWe consider a two-timescale algorithm, whereby the low-dimensional link\nfunction is learnt with a non-parametric model infinitely faster than the\nsubspace parametrizing the low-rank projection. By appropriately exploiting the\nmatrix semigroup structure arising over the subspace correlation matrices, we\nestablish global convergence of the resulting Grassmannian population gradient\nflow dynamics, and provide a quantitative description of its associated\n`saddle-to-saddle' dynamics. Notably, the timescales associated with each\nsaddle can be explicitly characterized in terms of an appropriate Hermite\ndecomposition of the target link function. In contrast with these positive\nresults, we also show that the related \\emph{planted} problem, where the link\nfunction is known and fixed, in fact has a rough optimization landscape, in\nwhich gradient flow dynamics might get trapped with high probability.",
          "link": "http://arxiv.org/abs/2310.19793",
          "publishedOn": "2023-11-04T00:42:37.809Z",
          "wordCount": null,
          "title": "On Learning Gaussian Multi-index Models with Gradient Flow. (arXiv:2310.19793v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarva_J/0/1/0/all/0/1\">Jay Sarva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingkang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1\">James Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yuwen Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manivasagam_S/0/1/0/all/0/1\">Sivabalan Manivasagam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1\">Raquel Urtasun</a>",
          "description": "Self-driving vehicles (SDVs) must be rigorously tested on a wide range of\nscenarios to ensure safe deployment. The industry typically relies on\nclosed-loop simulation to evaluate how the SDV interacts on a corpus of\nsynthetic and real scenarios and verify it performs properly. However, they\nprimarily only test the system's motion planning module, and only consider\nbehavior variations. It is key to evaluate the full autonomy system in\nclosed-loop, and to understand how variations in sensor data based on scene\nappearance, such as the shape of actors, affect system performance. In this\npaper, we propose a framework, Adv3D, that takes real world scenarios and\nperforms closed-loop sensor simulation to evaluate autonomy performance, and\nfinds vehicle shapes that make the scenario more challenging, resulting in\nautonomy failures and uncomfortable SDV maneuvers. Unlike prior works that add\ncontrived adversarial shapes to vehicle roof-tops or roadside to harm\nperception only, we optimize a low-dimensional shape representation to modify\nthe vehicle shape itself in a realistic manner to degrade autonomy performance\n(e.g., perception, prediction, and motion planning). Moreover, we find that the\nshape variations found with Adv3D optimized in closed-loop are much more\neffective than those in open-loop, demonstrating the importance of finding\nscene appearance variations that affect autonomy in the interactive setting.",
          "link": "http://arxiv.org/abs/2311.01446",
          "publishedOn": "2023-11-04T00:42:37.807Z",
          "wordCount": null,
          "title": "Adv3D: Generating Safety-Critical 3D Objects through Closed-Loop Simulation. (arXiv:2311.01446v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.05163",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Ren_Y/0/1/0/all/0/1\">Yuanfang Ren</a> (1) (2), <a href=\"http://arxiv.org/find/q-bio/1/au:+Balch_J/0/1/0/all/0/1\">Jeremy Balch</a> (3), <a href=\"http://arxiv.org/find/q-bio/1/au:+Abbott_K/0/1/0/all/0/1\">Kenneth L. Abbott</a> (3), <a href=\"http://arxiv.org/find/q-bio/1/au:+Loftus_T/0/1/0/all/0/1\">Tyler J. Loftus</a> (1) (3), <a href=\"http://arxiv.org/find/q-bio/1/au:+Shickel_B/0/1/0/all/0/1\">Benjamin Shickel</a> (1) (2), <a href=\"http://arxiv.org/find/q-bio/1/au:+Rashidi_P/0/1/0/all/0/1\">Parisa Rashidi</a> (1) (4), <a href=\"http://arxiv.org/find/q-bio/1/au:+Bihorac_A/0/1/0/all/0/1\">Azra Bihorac</a> (1) (2), <a href=\"http://arxiv.org/find/q-bio/1/au:+Ozrazgat_Baslanti_T/0/1/0/all/0/1\">Tezcan Ozrazgat-Baslanti</a> (1) (2) ((1) Intelligent Clinical Care Center (IC3), University of Florida, Gainesville, FL, USA, (2) Department of Medicine, College of Medicine, University of Florida, Gainesville, FL, USA, (3) Department of Surgery, College of Medicine, University of Florida, Gainesville, FL, USA, (4) J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, FL)",
          "description": "Continuous monitoring and patient acuity assessments are key aspects of\nIntensive Care Unit (ICU) practice, but both are limited by time constraints\nimposed on healthcare providers. Moreover, anticipating clinical trajectories\nremains imprecise. The objectives of this study are to (1) develop an\nelectronic phenotype of acuity using automated variable retrieval within the\nelectronic health records and (2) describe transitions between acuity states\nthat illustrate the clinical trajectories of ICU patients. We gathered two\nsingle-center, longitudinal electronic health record datasets for 51,372 adult\nICU patients admitted to the University of Florida Health (UFH) Gainesville\n(GNV) and Jacksonville (JAX). We developed algorithms to quantify acuity status\nat four-hour intervals for each ICU admission and identify acuity phenotypes\nusing continuous acuity status and k-means clustering approach. 51,073\nadmissions for 38,749 patients in the UFH GNV dataset and 22,219 admissions for\n12,623 patients in the UFH JAX dataset had at least one ICU stay lasting more\nthan four hours. There were three phenotypes: persistently stable, persistently\nunstable, and transitioning from unstable to stable. For stable patients,\napproximately 0.7%-1.7% would transition to unstable, 0.02%-0.1% would expire,\n1.2%-3.4% would be discharged, and the remaining 96%-97% would remain stable in\nthe ICU every four hours. For unstable patients, approximately 6%-10% would\ntransition to stable, 0.4%-0.5% would expire, and the remaining 89%-93% would\nremain unstable in the ICU in the next four hours. We developed phenotyping\nalgorithms for patient acuity status every four hours while admitted to the\nICU. This approach may be useful in developing prognostic and clinical\ndecision-support tools to aid patients, caregivers, and providers in shared\ndecision-making processes regarding escalation of care and patient values.",
          "link": "http://arxiv.org/abs/2005.05163",
          "publishedOn": "2023-11-04T00:42:37.807Z",
          "wordCount": null,
          "title": "Computable Phenotypes of Patient Acuity in the Intensive Care Unit. (arXiv:2005.05163v2 [q-bio.QM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.12358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Haowei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingzhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Benben Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaobo Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_G/0/1/0/all/0/1\">Gengang Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xuebing Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Dongxu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_G/0/1/0/all/0/1\">Guannan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_M/0/1/0/all/0/1\">Minggao Ouyang</a>",
          "description": "Electric vehicles (EVs) play an important role in reducing carbon emissions.\nAs EV adoption accelerates, safety issues caused by EV batteries have become an\nimportant research topic. In order to benchmark and develop data-driven methods\nfor this task, we introduce a large and comprehensive dataset of EV batteries.\nOur dataset includes charging records collected from hundreds of EVs from three\nmanufacturers over several years. Our dataset is the first large-scale public\ndataset on real-world battery data, as existing data either include only\nseveral vehicles or is collected in the lab environment. Meanwhile, our dataset\nfeatures two types of labels, corresponding to two key tasks - battery health\nestimation and battery capacity estimation. In addition to demonstrating how\nexisting deep learning algorithms can be applied to this task, we further\ndevelop an algorithm that exploits the data structure of battery systems. Our\nalgorithm achieves better results and shows that a customized method can\nimprove model performances. We hope that this public dataset provides valuable\nresources for researchers, policymakers, and industry professionals to better\nunderstand the dynamics of EV battery aging and support the transition toward a\nsustainable transportation system.",
          "link": "http://arxiv.org/abs/2201.12358",
          "publishedOn": "2023-11-04T00:42:37.807Z",
          "wordCount": null,
          "title": "EVBattery: A Large-Scale Electric Vehicle Dataset for Battery Health and Capacity Estimation. (arXiv:2201.12358v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01327",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wanteng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_D/0/1/0/all/0/1\">Dong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jiashuo Jiang</a>",
          "description": "We study the contextual bandits with knapsack (CBwK) problem under the\nhigh-dimensional setting where the dimension of the feature is large. The\nreward of pulling each arm equals the multiplication of a sparse\nhigh-dimensional weight vector and the feature of the current arrival, with\nadditional random noise. In this paper, we investigate how to exploit this\nsparsity structure to achieve improved regret for the CBwK problem. To this\nend, we first develop an online variant of the hard thresholding algorithm that\nperforms the sparse estimation in an online manner. We further combine our\nonline estimator with a primal-dual framework, where we assign a dual variable\nto each knapsack constraint and utilize an online learning algorithm to update\nthe dual variable, thereby controlling the consumption of the knapsack\ncapacity. We show that this integrated approach allows us to achieve a\nsublinear regret that depends logarithmically on the feature dimension, thus\nimproving the polynomial dependency established in the previous literature. We\nalso apply our framework to the high-dimension contextual bandit problem\nwithout the knapsack constraint and achieve optimal regret in both the\ndata-poor regime and the data-rich regime. We finally conduct numerical\nexperiments to show the efficient empirical performance of our algorithms under\nthe high dimensional setting.",
          "link": "http://arxiv.org/abs/2311.01327",
          "publishedOn": "2023-11-04T00:42:37.803Z",
          "wordCount": null,
          "title": "High-dimensional Linear Bandits with Knapsacks. (arXiv:2311.01327v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.18497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1\">Dongyang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendler_Dunner_C/0/1/0/all/0/1\">Celestine Mendler-D&#xfc;nner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>",
          "description": "We consider a collaborative learning setting where the goal of each agent is\nto improve their own model by leveraging the expertise of collaborators, in\naddition to their own training data. To facilitate the exchange of expertise\namong agents, we propose a distillation-based method leveraging shared\nunlabeled auxiliary data, which is pseudo-labeled by the collective. Central to\nour method is a trust weighting scheme that serves to adaptively weigh the\ninfluence of each collaborator on the pseudo-labels until a consensus on how to\nlabel the auxiliary data is reached. We demonstrate empirically that our\ncollaboration scheme is able to significantly boost individual models'\nperformance in the target domain from which the auxiliary data is sampled. At\nthe same time, it can provably mitigate the negative impact of bad models on\nthe collective. By design, our method adeptly accommodates heterogeneity in\nmodel architectures and substantially reduces communication overhead compared\nto typical collaborative learning methods.",
          "link": "http://arxiv.org/abs/2305.18497",
          "publishedOn": "2023-11-04T00:42:37.799Z",
          "wordCount": null,
          "title": "Collaborative Learning via Prediction Consensus. (arXiv:2305.18497v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.07210",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cornish_R/0/1/0/all/0/1\">Rob Cornish</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Taufiq_M/0/1/0/all/0/1\">Muhammad Faaiz Taufiq</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1\">Chris Holmes</a>",
          "description": "Digital twins are virtual systems designed to predict how a real-world\nprocess will evolve in response to interventions. This modelling paradigm holds\nsubstantial promise in many applications, but rigorous procedures for assessing\ntheir accuracy are essential for safety-critical settings. We consider how to\nassess the accuracy of a digital twin using real-world data. We formulate this\nas causal inference problem, which leads to a precise definition of what it\nmeans for a twin to be \"correct\" appropriate for many applications.\nUnfortunately, fundamental results from causal inference mean observational\ndata cannot be used to certify that a twin is correct in this sense unless\npotentially tenuous assumptions are made, such as that the data are\nunconfounded. To avoid these assumptions, we propose instead to find situations\nin which the twin is not correct, and present a general-purpose statistical\nprocedure for doing so. Our approach yields reliable and actionable information\nabout the twin under only the assumption of an i.i.d. dataset of observational\ntrajectories, and remains sound even if the data are confounded. We apply our\nmethodology to a large-scale, real-world case study involving sepsis modelling\nwithin the Pulse Physiology Engine, which we assess using the MIMIC-III dataset\nof ICU patients.",
          "link": "http://arxiv.org/abs/2301.07210",
          "publishedOn": "2023-11-04T00:42:37.798Z",
          "wordCount": null,
          "title": "Causal Falsification of Digital Twins. (arXiv:2301.07210v4 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenlong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruohan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunzhu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>",
          "description": "Large language models (LLMs) are shown to possess a wealth of actionable\nknowledge that can be extracted for robot manipulation in the form of reasoning\nand planning. Despite the progress, most still rely on pre-defined motion\nprimitives to carry out the physical interactions with the environment, which\nremains a major bottleneck. In this work, we aim to synthesize robot\ntrajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a\nlarge variety of manipulation tasks given an open-set of instructions and an\nopen-set of objects. We achieve this by first observing that LLMs excel at\ninferring affordances and constraints given a free-form language instruction.\nMore importantly, by leveraging their code-writing capabilities, they can\ninteract with a vision-language model (VLM) to compose 3D value maps to ground\nthe knowledge into the observation space of the agent. The composed value maps\nare then used in a model-based planning framework to zero-shot synthesize\nclosed-loop robot trajectories with robustness to dynamic perturbations. We\nfurther demonstrate how the proposed framework can benefit from online\nexperiences by efficiently learning a dynamics model for scenes that involve\ncontact-rich interactions. We present a large-scale study of the proposed\nmethod in both simulated and real-robot environments, showcasing the ability to\nperform a large variety of everyday manipulation tasks specified in free-form\nnatural language. Videos and code at https://voxposer.github.io",
          "link": "http://arxiv.org/abs/2307.05973",
          "publishedOn": "2023-11-04T00:42:37.798Z",
          "wordCount": null,
          "title": "VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models. (arXiv:2307.05973v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.12835",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Barp_A/0/1/0/all/0/1\">Alessandro Barp</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Simon_Gabriel_C/0/1/0/all/0/1\">Carl-Johann Simon-Gabriel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">Mark Girolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "Maximum mean discrepancies (MMDs) like the kernel Stein discrepancy (KSD)\nhave grown central to a wide range of applications, including hypothesis\ntesting, sampler selection, distribution approximation, and variational\ninference. In each setting, these kernel-based discrepancy measures are\nrequired to (i) separate a target P from other probability measures or even\n(ii) control weak convergence to P. In this article we derive new sufficient\nand necessary conditions to ensure (i) and (ii). For MMDs on separable metric\nspaces, we characterize those kernels that separate Bochner embeddable measures\nand introduce simple conditions for separating all measures with unbounded\nkernels and for controlling convergence with bounded kernels. We use these\nresults on $\\mathbb{R}^d$ to substantially broaden the known conditions for KSD\nseparation and convergence control and to develop the first KSDs known to\nexactly metrize weak convergence to P. Along the way, we highlight the\nimplications of our results for hypothesis testing, measuring and improving\nsample quality, and sampling with Stein variational gradient descent.",
          "link": "http://arxiv.org/abs/2209.12835",
          "publishedOn": "2023-11-04T00:42:37.796Z",
          "wordCount": null,
          "title": "Targeted Separation and Convergence with Kernel Discrepancies. (arXiv:2209.12835v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choquette_Choo_C/0/1/0/all/0/1\">Christopher A. Choquette-Choo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_A/0/1/0/all/0/1\">Arun Ganesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKenna_R/0/1/0/all/0/1\">Ryan McKenna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McMahan_H/0/1/0/all/0/1\">H. Brendan McMahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_K/0/1/0/all/0/1\">Keith Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thakurta_A/0/1/0/all/0/1\">Abhradeep Thakurta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zheng Xu</a>",
          "description": "Matrix factorization (MF) mechanisms for differential privacy (DP) have\nsubstantially improved the state-of-the-art in privacy-utility-computation\ntradeoffs for ML applications in a variety of scenarios, but in both the\ncentralized and federated settings there remain instances where either MF\ncannot be easily applied, or other algorithms provide better tradeoffs\n(typically, as $\\epsilon$ becomes small). In this work, we show how MF can\nsubsume prior state-of-the-art algorithms in both federated and centralized\ntraining settings, across all privacy budgets. The key technique throughout is\nthe construction of MF mechanisms with banded matrices (lower-triangular\nmatrices with at most $\\hat{b}$ nonzero bands including the main diagonal). For\ncross-device federated learning (FL), this enables multiple-participations with\na relaxed device participation schema compatible with practical FL\ninfrastructure (as demonstrated by a production deployment). In the centralized\nsetting, we prove that banded matrices enjoy the same privacy amplification\nresults as the ubiquitous DP-SGD algorithm, but can provide strictly better\nperformance in most scenarios -- this lets us always at least match DP-SGD, and\noften outperform it.",
          "link": "http://arxiv.org/abs/2306.08153",
          "publishedOn": "2023-11-04T00:42:37.796Z",
          "wordCount": null,
          "title": "(Amplified) Banded Matrix Factorization: A unified approach to private training. (arXiv:2306.08153v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sjarif_N/0/1/0/all/0/1\">Nilam Nur Amir Sjarif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_R/0/1/0/all/0/1\">Roslina Ibrahim</a>",
          "description": "Multi-step stock index forecasting is vital in finance for informed\ndecision-making. Current forecasting methods on this task frequently produce\nunsatisfactory results due to the inherent data randomness and instability,\nthereby underscoring the demand for advanced forecasting models. Given the\nsuperiority of capsule network (CapsNet) over CNN in various forecasting and\nclassification tasks, this study investigates the potential of integrating a 1D\nCapsNet with an LSTM network for multi-step stock index forecasting. To this\nend, a hybrid 1D-CapsNet-LSTM model is introduced, which utilizes a 1D CapsNet\nto generate high-level capsules from sequential data and a LSTM network to\ncapture temporal dependencies. To maintain stochastic dependencies over\ndifferent forecasting horizons, a multi-input multi-output (MIMO) strategy is\nemployed. The model's performance is evaluated on real-world stock market\nindices, including S&P 500, DJIA, IXIC, and NYSE, and compared to baseline\nmodels, including LSTM, RNN, and CNN-LSTM, using metrics such as RMSE, MAE,\nMAPE, and TIC. The proposed 1D-CapsNet-LSTM model consistently outperforms\nbaseline models in two key aspects. It exhibits significant reductions in\nforecasting errors compared to baseline models. Furthermore, it displays a\nslower rate of error increase with lengthening forecast horizons, indicating\nincreased robustness for multi-step forecasting tasks.",
          "link": "http://arxiv.org/abs/2310.02090",
          "publishedOn": "2023-11-04T00:42:37.796Z",
          "wordCount": null,
          "title": "1D-CapsNet-LSTM: A Deep Learning-Based Model for Multi-Step Stock Index Forecasting. (arXiv:2310.02090v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingkang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manivasagam_S/0/1/0/all/0/1\">Sivabalan Manivasagam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ze Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barsan_I/0/1/0/all/0/1\">Ioan Andrei B&#xe2;rsan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">Anqi Joyce Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wei-Chiu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1\">Raquel Urtasun</a>",
          "description": "Realistic simulation is key to enabling safe and scalable development of %\nself-driving vehicles. A core component is simulating the sensors so that the\nentire autonomy system can be tested in simulation. Sensor simulation involves\nmodeling traffic participants, such as vehicles, with high quality appearance\nand articulated geometry, and rendering them in real time. The self-driving\nindustry has typically employed artists to build these assets. However, this is\nexpensive, slow, and may not reflect reality. Instead, reconstructing assets\nautomatically from sensor data collected in the wild would provide a better\npath to generating a diverse and large set with good real-world coverage.\nNevertheless, current reconstruction approaches struggle on in-the-wild sensor\ndata, due to its sparsity and noise. To tackle these issues, we present CADSim,\nwhich combines part-aware object-class priors via a small set of CAD models\nwith differentiable rendering to automatically reconstruct vehicle geometry,\nincluding articulated wheels, with high-quality appearance. Our experiments\nshow our method recovers more accurate shapes from sparse data compared to\nexisting approaches. Importantly, it also trains and renders efficiently. We\ndemonstrate our reconstructed vehicles in several applications, including\naccurate testing of autonomy perception systems.",
          "link": "http://arxiv.org/abs/2311.01447",
          "publishedOn": "2023-11-04T00:42:37.795Z",
          "wordCount": null,
          "title": "CADSim: Robust and Scalable in-the-wild 3D Reconstruction for Controllable Sensor Simulation. (arXiv:2311.01447v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Shaojie Tang</a>",
          "description": "The objective of a two-stage submodular maximization problem is to reduce the\nground set using provided training functions that are submodular, with the aim\nof ensuring that optimizing new objective functions over the reduced ground set\nyields results comparable to those obtained over the original ground set. This\nproblem has applications in various domains including data summarization.\nExisting studies often assume the monotonicity of the objective function,\nwhereas our work pioneers the extension of this research to accommodate\nnon-monotone submodular functions. We have introduced the first constant-factor\napproximation algorithms for this more general case.",
          "link": "http://arxiv.org/abs/2309.05183",
          "publishedOn": "2023-11-04T00:42:37.795Z",
          "wordCount": null,
          "title": "Data Summarization beyond Monotonicity: Non-monotone Two-Stage Submodular Maximization. (arXiv:2309.05183v2 [cs.DS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13398",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Chernozhukov_V/0/1/0/all/0/1\">Victor Chernozhukov</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Cinelli_C/0/1/0/all/0/1\">Carlos Cinelli</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Newey_W/0/1/0/all/0/1\">Whitney Newey</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Sharma_A/0/1/0/all/0/1\">Amit Sharma</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Syrgkanis_V/0/1/0/all/0/1\">Vasilis Syrgkanis</a>",
          "description": "We derive general, yet simple, sharp bounds on the size of the omitted\nvariable bias for a broad class of causal parameters that can be identified as\nlinear functionals of the conditional expectation function of the outcome. Such\nfunctionals encompass many of the traditional targets of investigation in\ncausal inference studies, such as, for example, (weighted) average of potential\noutcomes, average treatment effects (including subgroup effects, such as the\neffect on the treated), (weighted) average derivatives, and policy effects from\nshifts in covariate distribution -- all for general, nonparametric causal\nmodels. Our construction relies on the Riesz-Frechet representation of the\ntarget functional. Specifically, we show how the bound on the bias depends only\non the additional variation that the latent variables create both in the\noutcome and in the Riesz representer for the parameter of interest. Moreover,\nin many important cases (e.g, average treatment effects and avearage\nderivatives) the bound is shown to depend on easily interpretable quantities\nthat measure the explanatory power of the omitted variables. Therefore, simple\nplausibility judgments on the maximum explanatory power of omitted variables\n(in explaining treatment and outcome variation) are sufficient to place overall\nbounds on the size of the bias. Furthermore, we use debiased machine learning\nto provide flexible and efficient statistical inference on learnable components\nof the bounds. Finally, empirical examples demonstrate the usefulness of the\napproach.",
          "link": "http://arxiv.org/abs/2112.13398",
          "publishedOn": "2023-11-04T00:42:37.792Z",
          "wordCount": null,
          "title": "Long Story Short: Omitted Variable Bias in Causal Machine Learning. (arXiv:2112.13398v4 [econ.EM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.10068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Duo Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dayou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Miao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruoyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fangxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shuguang Cui</a>",
          "description": "The high-accuracy and resource-intensive deep neural networks (DNNs) have\nbeen widely adopted by live video analytics (VA), where camera videos are\nstreamed over the network to resource-rich edge/cloud servers for DNN\ninference. Common video encoding configurations (e.g., resolution and frame\nrate) have been identified with significant impacts on striking the balance\nbetween bandwidth consumption and inference accuracy and therefore their\nadaption scheme has been a focus of optimization. However, previous\nprofiling-based solutions suffer from high profiling cost, while existing deep\nreinforcement learning (DRL) based solutions may achieve poor performance due\nto the usage of fixed reward function for training the agent, which fails to\ncraft the application goals in various scenarios. In this paper, we propose\nILCAS, the first imitation learning (IL) based configuration-adaptive VA\nstreaming system. Unlike DRL-based solutions, ILCAS trains the agent with\ndemonstrations collected from the expert which is designed as an offline\noptimal policy that solves the configuration adaption problem through dynamic\nprogramming. To tackle the challenge of video content dynamics, ILCAS derives\nmotion feature maps based on motion vectors which allow ILCAS to visually\n``perceive'' video content changes. Moreover, ILCAS incorporates a cross-camera\ncollaboration scheme to exploit the spatio-temporal correlations of cameras for\nmore proper configuration selection. Extensive experiments confirm the\nsuperiority of ILCAS compared with state-of-the-art solutions, with 2-20.9%\nimprovement of mean accuracy and 19.9-85.3% reduction of chunk upload lag.",
          "link": "http://arxiv.org/abs/2308.10068",
          "publishedOn": "2023-11-04T00:42:37.792Z",
          "wordCount": null,
          "title": "ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for Live Video Analytics with Cross-Camera Collaboration. (arXiv:2308.10068v2 [cs.NI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01344",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joud_R/0/1/0/all/0/1\">Raphael Joud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moellic_P/0/1/0/all/0/1\">Pierre-Alain Moellic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pontie_S/0/1/0/all/0/1\">Simon Pontie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigaud_J/0/1/0/all/0/1\">Jean-Baptiste Rigaud</a>",
          "description": "Model extraction is a growing concern for the security of AI systems. For\ndeep neural network models, the architecture is the most important information\nan adversary aims to recover. Being a sequence of repeated computation blocks,\nneural network models deployed on edge-devices will generate distinctive\nside-channel leakages. The latter can be exploited to extract critical\ninformation when targeted platforms are physically accessible. By combining\ntheoretical knowledge about deep learning practices and analysis of a\nwidespread implementation library (ARM CMSIS-NN), our purpose is to answer this\ncritical question: how far can we extract architecture information by simply\nexamining an EM side-channel trace? For the first time, we propose an\nextraction methodology for traditional MLP and CNN models running on a high-end\n32-bit microcontroller (Cortex-M7) that relies only on simple pattern\nrecognition analysis. Despite few challenging cases, we claim that, contrary to\nparameters extraction, the complexity of the attack is relatively low and we\nhighlight the urgent need for practicable protections that could fit the strong\nmemory and latency requirements of such platforms.",
          "link": "http://arxiv.org/abs/2311.01344",
          "publishedOn": "2023-11-04T00:42:37.791Z",
          "wordCount": null,
          "title": "Like an Open Book? Read Neural Network Architecture with Simple Power Analysis on 32-bit Microcontrollers. (arXiv:2311.01344v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ludke_D/0/1/0/all/0/1\">David L&#xfc;dke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilos_M/0/1/0/all/0/1\">Marin Bilo&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shchur_O/0/1/0/all/0/1\">Oleksandr Shchur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lienen_M/0/1/0/all/0/1\">Marten Lienen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>",
          "description": "Autoregressive neural networks within the temporal point process (TPP)\nframework have become the standard for modeling continuous-time event data.\nEven though these models can expressively capture event sequences in a\none-step-ahead fashion, they are inherently limited for long-term forecasting\napplications due to the accumulation of errors caused by their sequential\nnature. To overcome these limitations, we derive ADD-THIN, a principled\nprobabilistic denoising diffusion model for TPPs that operates on entire event\nsequences. Unlike existing diffusion approaches, ADD-THIN naturally handles\ndata with discrete and continuous components. In experiments on synthetic and\nreal-world datasets, our model matches the state-of-the-art TPP models in\ndensity estimation and strongly outperforms them in forecasting.",
          "link": "http://arxiv.org/abs/2311.01139",
          "publishedOn": "2023-11-04T00:42:37.790Z",
          "wordCount": null,
          "title": "Add and Thin: Diffusion for Temporal Point Processes. (arXiv:2311.01139v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.09253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prabhu_A/0/1/0/all/0/1\">Ameya Prabhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zhipeng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dokania_P/0/1/0/all/0/1\">Puneet Dokania</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koltun_V/0/1/0/all/0/1\">Vladlen Koltun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sener_O/0/1/0/all/0/1\">Ozan Sener</a>",
          "description": "Traditional online continual learning (OCL) research has primarily focused on\nmitigating catastrophic forgetting with fixed and limited storage allocation\nthroughout an agent's lifetime. However, a broad range of real-world\napplications are primarily constrained by computational costs rather than\nstorage limitations. In this paper, we target such applications, investigating\nthe online continual learning problem under relaxed storage constraints and\nlimited computational budgets. We contribute a simple algorithm, which updates\na kNN classifier continually along with a fixed, pretrained feature extractor.\nWe selected this algorithm due to its exceptional suitability for online\ncontinual learning. It can adapt to rapidly changing streams, has zero\nstability gap, operates within tiny computational budgets, has low storage\nrequirements by only storing features, and has a consistency property: It never\nforgets previously seen data. These attributes yield significant improvements,\nallowing our proposed algorithm to outperform existing methods by over 20% in\naccuracy on two large-scale OCL datasets: Continual LOCalization (CLOC) with\n39M images and 712 classes and Continual Google Landmarks V2 (CGLM) with 580K\nimages and 10,788 classes, even when existing methods retain all previously\nseen images. Furthermore, we achieve this superior performance with\nconsiderably reduced computational and storage expenses. We provide code to\nreproduce our results at github.com/drimpossible/ACM.",
          "link": "http://arxiv.org/abs/2305.09253",
          "publishedOn": "2023-11-04T00:42:37.790Z",
          "wordCount": null,
          "title": "Online Continual Learning Without the Storage Constraint. (arXiv:2305.09253v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhanke Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jiangchao Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaxu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiawei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1\">Quanming Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Li He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bo Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>",
          "description": "Although link prediction on graphs has achieved great success with the\ndevelopment of graph neural networks (GNNs), the potential robustness under the\nedge noise is still less investigated. To close this gap, we first conduct an\nempirical study to disclose that the edge noise bilaterally perturbs both input\ntopology and target label, yielding severe performance degradation and\nrepresentation collapse. To address this dilemma, we propose an\ninformation-theory-guided principle, Robust Graph Information Bottleneck\n(RGIB), to extract reliable supervision signals and avoid representation\ncollapse. Different from the basic information bottleneck, RGIB further\ndecouples and balances the mutual dependence among graph topology, target\nlabels, and representation, building new learning objectives for robust\nrepresentation against the bilateral noise. Two instantiations, RGIB-SSL and\nRGIB-REP, are explored to leverage the merits of different methodologies, i.e.,\nself-supervised learning and data reparameterization, for implicit and explicit\ndata denoising, respectively. Extensive experiments on six datasets and three\nGNNs with diverse noisy scenarios verify the effectiveness of our RGIB\ninstantiations. The code is publicly available at:\nhttps://github.com/tmlr-group/RGIB.",
          "link": "http://arxiv.org/abs/2311.01196",
          "publishedOn": "2023-11-04T00:42:37.789Z",
          "wordCount": null,
          "title": "Combating Bilateral Edge Noise for Robust Link Prediction. (arXiv:2311.01196v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15572",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kaiwen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kyurae Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garnett_R/0/1/0/all/0/1\">Roman Garnett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1\">Jacob R. Gardner</a>",
          "description": "A recent development in Bayesian optimization is the use of local\noptimization strategies, which can deliver strong empirical performance on\nhigh-dimensional problems compared to traditional global strategies. The \"folk\nwisdom\" in the literature is that the focus on local optimization sidesteps the\ncurse of dimensionality; however, little is known concretely about the expected\nbehavior or convergence of Bayesian local optimization routines. We first study\nthe behavior of the local approach, and find that the statistics of individual\nlocal solutions of Gaussian process sample paths are surprisingly good compared\nto what we would expect to recover from global methods. We then present the\nfirst rigorous analysis of such a Bayesian local optimization algorithm\nrecently proposed by M\\\"uller et al. (2021), and derive convergence rates in\nboth the noisy and noiseless settings.",
          "link": "http://arxiv.org/abs/2305.15572",
          "publishedOn": "2023-11-04T00:42:37.787Z",
          "wordCount": null,
          "title": "The Behavior and Convergence of Local Bayesian Optimization. (arXiv:2305.15572v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.04040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yiheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jialu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1\">Chaowen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jiahuan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Chang-Yu Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_T/0/1/0/all/0/1\">Tingjun Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>",
          "description": "Many crucial scientific problems involve designing novel molecules with\ndesired properties, which can be formulated as a black-box optimization problem\nover the discrete chemical space. In practice, multiple conflicting objectives\nand costly evaluations (e.g., wet-lab experiments) make the diversity of\ncandidates paramount. Computational methods have achieved initial success but\nstill struggle with considering diversity in both objective and search space.\nTo fill this gap, we propose a multi-objective Bayesian optimization (MOBO)\nalgorithm leveraging the hypernetwork-based GFlowNets (HN-GFN) as an\nacquisition function optimizer, with the purpose of sampling a diverse batch of\ncandidate molecular graphs from an approximate Pareto front. Using a single\npreference-conditioned hypernetwork, HN-GFN learns to explore various\ntrade-offs between objectives. We further propose a hindsight-like off-policy\nstrategy to share high-performing molecules among different preferences in\norder to speed up learning for HN-GFN. We empirically illustrate that HN-GFN\nhas adequate capacity to generalize over preferences. Moreover, experiments in\nvarious real-world MOBO settings demonstrate that our framework predominantly\noutperforms existing methods in terms of candidate quality and sample\nefficiency. The code is available at https://github.com/violet-sto/HN-GFN.",
          "link": "http://arxiv.org/abs/2302.04040",
          "publishedOn": "2023-11-04T00:42:37.786Z",
          "wordCount": null,
          "title": "Sample-efficient Multi-objective Molecular Optimization with GFlowNets. (arXiv:2302.04040v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.02028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wornow_M/0/1/0/all/0/1\">Michael Wornow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapa_R/0/1/0/all/0/1\">Rahul Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinberg_E/0/1/0/all/0/1\">Ethan Steinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fries_J/0/1/0/all/0/1\">Jason A. Fries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Nigam H. Shah</a>",
          "description": "While the general machine learning (ML) community has benefited from public\ndatasets, tasks, and models, the progress of ML in healthcare has been hampered\nby a lack of such shared assets. The success of foundation models creates new\nchallenges for healthcare ML by requiring access to shared pretrained models to\nvalidate performance benefits. We help address these challenges through three\ncontributions. First, we publish a new dataset, EHRSHOT, which contains\ndeidentified structured data from the electronic health records (EHRs) of 6,739\npatients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR\ndatasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients.\nSecond, we publish the weights of CLMBR-T-base, a 141M parameter clinical\nfoundation model pretrained on the structured EHR data of 2.57M patients. We\nare one of the first to fully release such a model for coded EHR data; in\ncontrast, most prior models released for clinical data (e.g. GatorTron,\nClinicalBERT) only work with unstructured text and cannot process the rich,\nstructured data within an EHR. We provide an end-to-end pipeline for the\ncommunity to validate and build upon its performance. Third, we define 15\nfew-shot clinical prediction tasks, enabling evaluation of foundation models on\nbenefits such as sample efficiency and task adaptation. Our model and dataset\nare available via a research data use agreement from the Stanford AIMI Center.\nCode to reproduce our results are available at our Github repo:\nhttps://github.com/som-shahlab/ehrshot-benchmark",
          "link": "http://arxiv.org/abs/2307.02028",
          "publishedOn": "2023-11-04T00:42:37.762Z",
          "wordCount": null,
          "title": "EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models. (arXiv:2307.02028v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perino_M/0/1/0/all/0/1\">Michela Perino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginolfi_M/0/1/0/all/0/1\">Michele Ginolfi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Felici_A/0/1/0/all/0/1\">Anna Candida Felici</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosellini_M/0/1/0/all/0/1\">Michela Rosellini</a>",
          "description": "Palimpsests refer to historical manuscripts where erased writings have been\npartially covered by the superimposition of a second writing. By employing\nimaging techniques, e.g., multispectral imaging, it becomes possible to\nidentify features that are imperceptible to the naked eye, including faded and\nerased inks. When dealing with overlapping inks, Artificial Intelligence\ntechniques can be utilized to disentangle complex nodes of overlapping letters.\nIn this work, we propose deep learning-based semantic segmentation as a method\nfor identifying and segmenting individual letters in overlapping characters.\nThe experiment was conceived as a proof of concept, focusing on the palimpsests\nof the Ars Grammatica by Prisciano as a case study. Furthermore, caveats and\nprospects of our approach combined with multispectral imaging are also\ndiscussed.",
          "link": "http://arxiv.org/abs/2311.01130",
          "publishedOn": "2023-11-04T00:42:37.749Z",
          "wordCount": null,
          "title": "A deep learning experiment for semantic segmentation of overlapping characters in palimpsests. (arXiv:2311.01130v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Baisong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingwang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haixiao Xu</a>",
          "description": "Large language models(LLMs) exhibit excellent performance across a variety of\ntasks, but they come with significant computational and storage costs.\nQuantizing these models is an effective way to alleviate this issue. However,\nexisting methods struggle to strike a balance between model accuracy and\nhardware efficiency. This is where we introduce AWEQ, a post-training method\nthat requires no additional training overhead. AWEQ excels in both\nultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization.\nThere is an observation that weight quantization is less challenging than\nactivation quantization. AWEQ transfers the difficulty of activation\nquantization to weights using channel equalization, achieving a balance between\nthe quantization difficulties of both, and thereby maximizing performance. We\nhave further refined the equalization method to mitigate quantization bias\nerror, ensuring the robustness of the model. Extensive experiments on popular\nmodels such as LLaMA and OPT demonstrate that AWEQ outperforms all existing\npost-training quantization methods for large models.",
          "link": "http://arxiv.org/abs/2311.01305",
          "publishedOn": "2023-11-04T00:42:37.740Z",
          "wordCount": null,
          "title": "AWEQ: Post-Training Quantization with Activation-Weight Equalization for Large Language Models. (arXiv:2311.01305v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00862",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Shenoy_N/0/1/0/all/0/1\">Nikhil Shenoy</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tossou_P/0/1/0/all/0/1\">Prudencio Tossou</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Noutahi_E/0/1/0/all/0/1\">Emmanuel Noutahi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mary_H/0/1/0/all/0/1\">Hadrien Mary</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Beaini_D/0/1/0/all/0/1\">Dominique Beaini</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ding_J/0/1/0/all/0/1\">Jiarui Ding</a>",
          "description": "In the field of Machine Learning Interatomic Potentials (MLIPs),\nunderstanding the intricate relationship between data biases, specifically\nconformational and structural diversity, and model generalization is critical\nin improving the quality of Quantum Mechanics (QM) data generation efforts. We\ninvestigate these dynamics through two distinct experiments: a fixed budget\none, where the dataset size remains constant, and a fixed molecular set one,\nwhich focuses on fixed structural diversity while varying conformational\ndiversity. Our results reveal nuanced patterns in generalization metrics.\nNotably, for optimal structural and conformational generalization, a careful\nbalance between structural and conformational diversity is required, but\nexisting QM datasets do not meet that trade-off. Additionally, our results\nhighlight the limitation of the MLIP models at generalizing beyond their\ntraining distribution, emphasizing the importance of defining applicability\ndomain during model deployment. These findings provide valuable insights and\nguidelines for QM data generation efforts.",
          "link": "http://arxiv.org/abs/2311.00862",
          "publishedOn": "2023-11-04T00:42:37.735Z",
          "wordCount": null,
          "title": "Role of Structural and Conformational Diversity for Machine Learning Potentials. (arXiv:2311.00862v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Puranik_B/0/1/0/all/0/1\">Bhagyashree Puranik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madhow_U/0/1/0/all/0/1\">Upamanyu Madhow</a>",
          "description": "State-of-the-art techniques for enhancing robustness of deep networks mostly\nrely on empirical risk minimization with suitable data augmentation. In this\npaper, we propose a complementary approach motivated by communication theory,\naimed at enhancing the signal-to-noise ratio at the output of a neural network\nlayer via neural competition during learning and inference. In addition to\nminimization of a standard end-to-end cost, neurons compete to sparsely\nrepresent layer inputs by maximization of a tilted exponential (TEXP) objective\nfunction for the layer. TEXP learning can be interpreted as maximum likelihood\nestimation of matched filters under a Gaussian model for data noise. Inference\nin a TEXP layer is accomplished by replacing batch norm by a tilted softmax,\nwhich can be interpreted as computation of posterior probabilities for the\ncompeting signaling hypotheses represented by each neuron. After providing\ninsights via simplified models, we show, by experimentation on standard image\ndatasets, that TEXP learning and inference enhances robustness against noise\nand other common corruptions, without requiring data augmentation. Further\ncumulative gains in robustness against this array of distortions can be\nobtained by appropriately combining TEXP with data augmentation techniques.",
          "link": "http://arxiv.org/abs/2311.01047",
          "publishedOn": "2023-11-04T00:42:37.732Z",
          "wordCount": null,
          "title": "Improving Robustness via Tilted Exponential Layer: A Communication-Theoretic Perspective. (arXiv:2311.01047v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00754",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1\">Stephen Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Michelle Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">C. Karen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>",
          "description": "When limited by their own morphologies, humans and some species of animals\nhave the remarkable ability to use objects from the environment toward\naccomplishing otherwise impossible tasks. Robots might similarly unlock a range\nof additional capabilities through tool use. Recent techniques for jointly\noptimizing morphology and control via deep learning are effective at designing\nlocomotion agents. But while outputting a single morphology makes sense for\nlocomotion, manipulation involves a variety of strategies depending on the task\ngoals at hand. A manipulation agent must be capable of rapidly prototyping\nspecialized tools for different goals. Therefore, we propose learning a\ndesigner policy, rather than a single design. A designer policy is conditioned\non task information and outputs a tool design that helps solve the task. A\ndesign-conditioned controller policy can then perform manipulation using these\ntools. In this work, we take a step towards this goal by introducing a\nreinforcement learning framework for jointly learning these policies. Through\nsimulated manipulation tasks, we show that this framework is more sample\nefficient than prior methods in multi-goal or multi-variant settings, can\nperform zero-shot interpolation or fine-tuning to tackle previously unseen\ngoals, and allows tradeoffs between the complexity of design and control\npolicies under practical constraints. Finally, we deploy our learned policies\nonto a real robot. Please see our supplementary video and website at\nhttps://robotic-tool-design.github.io/ for visualizations.",
          "link": "http://arxiv.org/abs/2311.00754",
          "publishedOn": "2023-11-04T00:42:37.731Z",
          "wordCount": null,
          "title": "Learning to Design and Use Tools for Robotic Manipulation. (arXiv:2311.00754v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01425",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Soofi_A/0/1/0/all/0/1\">Aized Amin Soofi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fazal-e-Amin/0/1/0/all/0/1\">Fazal-e-Amin</a>",
          "description": "Glaucoma is one of the primary causes of vision loss around the world,\nnecessitating accurate and efficient detection methods. Traditional manual\ndetection approaches have limitations in terms of cost, time, and subjectivity.\nRecent developments in deep learning approaches demonstrate potential in\nautomating glaucoma detection by detecting relevant features from retinal\nfundus images. This article provides a comprehensive overview of cutting-edge\ndeep learning methods used for the segmentation, classification, and detection\nof glaucoma. By analyzing recent studies, the effectiveness and limitations of\nthese techniques are evaluated, key findings are highlighted, and potential\nareas for further research are identified. The use of deep learning algorithms\nmay significantly improve the efficacy, usefulness, and accuracy of glaucoma\ndetection. The findings from this research contribute to the ongoing\nadvancements in automated glaucoma detection and have implications for\nimproving patient outcomes and reducing the global burden of glaucoma.",
          "link": "http://arxiv.org/abs/2311.01425",
          "publishedOn": "2023-11-04T00:42:37.731Z",
          "wordCount": null,
          "title": "Exploring Deep Learning Techniques for Glaucoma Detection: A Comprehensive Review. (arXiv:2311.01425v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.18230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saez_Maldonado_F/0/1/0/all/0/1\">Francisco Javier S&#xe1;ez-Maldonado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maronas_J/0/1/0/all/0/1\">Juan Maro&#xf1;as</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1\">Daniel Hern&#xe1;ndez-Lobato</a>",
          "description": "Transformed Gaussian Processes (TGPs) are stochastic processes specified by\ntransforming samples from the joint distribution from a prior process\n(typically a GP) using an invertible transformation; increasing the flexibility\nof the base process.\n\nFurthermore, they achieve competitive results compared with Deep Gaussian\nProcesses (DGPs), which are another generalization constructed by a\nhierarchical concatenation of GPs. In this work, we propose a generalization of\nTGPs named Deep Transformed Gaussian Processes (DTGPs), which follows the trend\nof concatenating layers of stochastic processes. More precisely, we obtain a\nmulti-layer model in which each layer is a TGP. This generalization implies an\nincrement of flexibility with respect to both TGPs and DGPs. Exact inference in\nsuch a model is intractable. However, we show that one can use variational\ninference to approximate the required computations yielding a straightforward\nextension of the popular DSVI inference algorithm Salimbeni et al (2017). The\nexperiments conducted evaluate the proposed novel DTGPs in multiple regression\ndatasets, achieving good scalability and performance.",
          "link": "http://arxiv.org/abs/2310.18230",
          "publishedOn": "2023-11-04T00:42:37.731Z",
          "wordCount": null,
          "title": "Deep Transformed Gaussian Processes. (arXiv:2310.18230v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.20280",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Palaskar_S/0/1/0/all/0/1\">Santosh Palaskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ekambaram_V/0/1/0/all/0/1\">Vijay Ekambaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jati_A/0/1/0/all/0/1\">Arindam Jati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gantayat_N/0/1/0/all/0/1\">Neelamadhav Gantayat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Avirup Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagar_S/0/1/0/all/0/1\">Seema Nagar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Nam H. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dayama_P/0/1/0/all/0/1\">Pankaj Dayama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sindhgatta_R/0/1/0/all/0/1\">Renuka Sindhgatta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohapatra_P/0/1/0/all/0/1\">Prateeti Mohapatra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_H/0/1/0/all/0/1\">Harshit Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalagnanam_J/0/1/0/all/0/1\">Jayant Kalagnanam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hemachandra_N/0/1/0/all/0/1\">Nandyala Hemachandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangaraj_N/0/1/0/all/0/1\">Narayan Rangaraj</a>",
          "description": "The efficiency of business processes relies on business key performance\nindicators (Biz-KPIs), that can be negatively impacted by IT failures. Business\nand IT Observability (BizITObs) data fuses both Biz-KPIs and IT event channels\ntogether as multivariate time series data. Forecasting Biz-KPIs in advance can\nenhance efficiency and revenue through proactive corrective measures. However,\nBizITObs data generally exhibit both useful and noisy inter-channel\ninteractions between Biz-KPIs and IT events that need to be effectively\ndecoupled. This leads to suboptimal forecasting performance when existing\nmultivariate forecasting models are employed. To address this, we introduce\nAutoMixer, a time-series Foundation Model (FM) approach, grounded on the novel\ntechnique of channel-compressed pretrain and finetune workflows. AutoMixer\nleverages an AutoEncoder for channel-compressed pretraining and integrates it\nwith the advanced TSMixer model for multivariate time series forecasting. This\nfusion greatly enhances the potency of TSMixer for accurate forecasts and also\ngeneralizes well across several downstream tasks. Through detailed experiments\nand dashboard analytics, we show AutoMixer's capability to consistently improve\nthe Biz-KPI's forecasting accuracy (by 11-15\\%) which directly translates to\nactionable business insights.",
          "link": "http://arxiv.org/abs/2310.20280",
          "publishedOn": "2023-11-04T00:42:37.731Z",
          "wordCount": null,
          "title": "AutoMixer for Improved Multivariate Time-Series Forecasting on Business and IT Observability Data. (arXiv:2310.20280v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yujia Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>",
          "description": "Nonlinear independent component analysis (ICA) aims to uncover the true\nlatent sources from their observable nonlinear mixtures. Despite its\nsignificance, the identifiability of nonlinear ICA is known to be impossible\nwithout additional assumptions. Recent advances have proposed conditions on the\nconnective structure from sources to observed variables, known as Structural\nSparsity, to achieve identifiability in an unsupervised manner. However, the\nsparsity constraint may not hold universally for all sources in practice.\nFurthermore, the assumptions of bijectivity of the mixing process and\nindependence among all sources, which arise from the setting of ICA, may also\nbe violated in many real-world scenarios. To address these limitations and\ngeneralize nonlinear ICA, we propose a set of new identifiability results in\nthe general settings of undercompleteness, partial sparsity and source\ndependence, and flexible grouping structures. Specifically, we prove\nidentifiability when there are more observed variables than sources\n(undercomplete), and when certain sparsity and/or source independence\nassumptions are not met for some changing sources. Moreover, we show that even\nin cases with flexible grouping structures (e.g., part of the sources can be\ndivided into irreducible independent groups with various sizes), appropriate\nidentifiability results can also be established. Theoretical claims are\nsupported empirically on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2311.00866",
          "publishedOn": "2023-11-04T00:42:37.730Z",
          "wordCount": null,
          "title": "Generalizing Nonlinear ICA Beyond Structural Sparsity. (arXiv:2311.00866v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yadlowsky_S/0/1/0/all/0/1\">Steve Yadlowsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_L/0/1/0/all/0/1\">Lyric Doshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tripuraneni_N/0/1/0/all/0/1\">Nilesh Tripuraneni</a>",
          "description": "Transformer models, notably large language models (LLMs), have the remarkable\nability to perform in-context learning (ICL) -- to perform new tasks when\nprompted with unseen input-output examples without any explicit model training.\nIn this work, we study how effectively transformers can bridge between their\npretraining data mixture, comprised of multiple distinct task families, to\nidentify and learn new tasks in-context which are both inside and outside the\npretraining distribution. Building on previous work, we investigate this\nquestion in a controlled setting, where we study transformer models trained on\nsequences of $(x, f(x))$ pairs rather than natural language. Our empirical\nresults show transformers demonstrate near-optimal unsupervised model selection\ncapabilities, in their ability to first in-context identify different task\nfamilies and in-context learn within them when the task families are\nwell-represented in their pretraining data. However when presented with tasks\nor functions which are out-of-domain of their pretraining data, we demonstrate\nvarious failure modes of transformers and degradation of their generalization\nfor even simple extrapolation tasks. Together our results highlight that the\nimpressive ICL abilities of high-capacity sequence models may be more closely\ntied to the coverage of their pretraining data mixtures than inductive biases\nthat create fundamental generalization capabilities.",
          "link": "http://arxiv.org/abs/2311.00871",
          "publishedOn": "2023-11-04T00:42:37.730Z",
          "wordCount": null,
          "title": "Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models. (arXiv:2311.00871v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chuizheng Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yihe Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1\">Sercan &#xd6;. Ar&#x131;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>",
          "description": "Estimation of temporal counterfactual outcomes from observed history is\ncrucial for decision-making in many domains such as healthcare and e-commerce,\nparticularly when randomized controlled trials (RCTs) suffer from high cost or\nimpracticality. For real-world datasets, modeling time-dependent confounders is\nchallenging due to complex dynamics, long-range dependencies and both past\ntreatments and covariates affecting the future outcomes. In this paper, we\nintroduce COunterfactual Self-supervised TrAnsformeR (COSTAR), a novel approach\nthat integrates self-supervised learning for improved historical\nrepresentations. The proposed framework combines temporal and feature-wise\nattention with a component-wise contrastive loss tailored for temporal\ntreatment outcome observations, yielding superior performance in estimation\naccuracy and generalization to out-of-distribution data compared to existing\nmodels, as validated by empirical results on both synthetic and real-world\ndatasets.",
          "link": "http://arxiv.org/abs/2311.00886",
          "publishedOn": "2023-11-04T00:42:37.730Z",
          "wordCount": null,
          "title": "COSTAR: Improved Temporal Counterfactual Estimation with Self-Supervised Learning. (arXiv:2311.00886v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.04926",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mishra_D/0/1/0/all/0/1\">Dipti Mishra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singh_S/0/1/0/all/0/1\">Satish Kumar Singh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singh_R/0/1/0/all/0/1\">Rajat Kumar Singh</a>",
          "description": "We propose a learning-based compression scheme that envelopes a standard\ncodec between pre and post-processing deep CNNs. Specifically, we demonstrate\nimprovements over prior approaches utilizing a compression-decompression\nnetwork by introducing: (a) an edge-aware loss function to prevent blurring\nthat is commonly occurred in prior works & (b) a super-resolution convolutional\nneural network (CNN) for post-processing along with a corresponding\npre-processing network for improved rate-distortion performance in the low rate\nregime. The algorithm is assessed on a variety of datasets varying from low to\nhigh resolution namely Set 5, Set 7, Classic 5, Set 14, Live 1, Kodak, General\n100, CLIC 2019. When compared to JPEG, JPEG2000, BPG, and recent CNN approach,\nthe proposed algorithm contributes significant improvement in PSNR with an\napproximate gain of 20.75%, 8.47%, 3.22%, 3.23% and 24.59%, 14.46%, 10.14%,\n8.57% at low and high bit-rates respectively. Similarly, this improvement in\nMS-SSIM is approximately 71.43%, 50%, 36.36%, 23.08%, 64.70% and 64.47%,\n61.29%, 47.06%, 51.52%, 16.28% at low and high bit-rates respectively. With\nCLIC 2019 dataset, PSNR is found to be superior with approximately 16.67%,\n10.53%, 6.78%, and 24.62%, 17.39%, 14.08% at low and high bit-rates\nrespectively, over JPEG2000, BPG, and recent CNN approach. Similarly, the\nMS-SSIM is found to be superior with approximately 72%, 45.45%, 39.13%, 18.52%,\nand 71.43%, 50%, 41.18%, 17.07% at low and high bit-rates respectively,\ncompared to the same approaches. A similar type of improvement is achieved with\nother datasets also.",
          "link": "http://arxiv.org/abs/2104.04926",
          "publishedOn": "2023-11-04T00:42:37.729Z",
          "wordCount": null,
          "title": "Deep learning-based Edge-aware pre and post-processing methods for JPEG compressed images. (arXiv:2104.04926v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">Dongmin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Seola Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Doyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hwanjun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-Gil Lee</a>",
          "description": "Data pruning, which aims to downsize a large training set into a small\ninformative subset, is crucial for reducing the enormous computational costs of\nmodern deep learning. Though large-scale data collections invariably contain\nannotation noise and numerous robust learning methods have been developed, data\npruning for the noise-robust learning scenario has received little attention.\nWith state-of-the-art Re-labeling methods that self-correct erroneous labels\nwhile training, it is challenging to identify which subset induces the most\naccurate re-labeling of erroneous labels in the entire training set. In this\npaper, we formalize the problem of data pruning with re-labeling. We first show\nthat the likelihood of a training example being correctly re-labeled is\nproportional to the prediction confidence of its neighborhood in the subset.\nTherefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a\nsubset maximizing the total neighborhood confidence of all training examples,\nthereby maximizing the re-labeling accuracy and generalization performance.\nExtensive experiments on four real and one synthetic noisy datasets show that\n\\algname{} outperforms the baselines with Re-labeling models by up to 9.1% as\nwell as those with a standard model by up to 21.6%.",
          "link": "http://arxiv.org/abs/2311.01002",
          "publishedOn": "2023-11-04T00:42:37.728Z",
          "wordCount": null,
          "title": "Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy. (arXiv:2311.01002v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.06534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wolf_D/0/1/0/all/0/1\">Daniel Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Payer_T/0/1/0/all/0/1\">Tristan Payer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lisson_C/0/1/0/all/0/1\">Catharina Silvia Lisson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lisson_C/0/1/0/all/0/1\">Christoph Gerhard Lisson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beer_M/0/1/0/all/0/1\">Meinrad Beer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotz_M/0/1/0/all/0/1\">Michael G&#xf6;tz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1\">Timo Ropinski</a>",
          "description": "Deep learning in medical imaging has the potential to minimize the risk of\ndiagnostic errors, reduce radiologist workload, and accelerate diagnosis.\nTraining such deep learning models requires large and accurate datasets, with\nannotations for all training samples. However, in the medical imaging domain,\nannotated datasets for specific tasks are often small due to the high\ncomplexity of annotations, limited access, or the rarity of diseases. To\naddress this challenge, deep learning models can be pre-trained on large image\ndatasets without annotations using methods from the field of self-supervised\nlearning. After pre-training, small annotated datasets are sufficient to\nfine-tune the models for a specific task. The most popular self-supervised\npre-training approaches in medical imaging are based on contrastive learning.\nHowever, recent studies in natural image processing indicate a strong potential\nfor masked autoencoder approaches. Our work compares state-of-the-art\ncontrastive learning methods with the recently introduced masked autoencoder\napproach \"SparK\" for convolutional neural networks (CNNs) on medical images.\nTherefore we pre-train on a large unannotated CT image dataset and fine-tune on\nseveral CT classification tasks. Due to the challenge of obtaining sufficient\nannotated training data in medical imaging, it is of particular interest to\nevaluate how the self-supervised pre-training methods perform when fine-tuning\non small datasets. By experimenting with gradually reducing the training\ndataset size for fine-tuning, we find that the reduction has different effects\ndepending on the type of pre-training chosen. The SparK pre-training method is\nmore robust to the training dataset size than the contrastive methods. Based on\nour results, we propose the SparK pre-training for medical imaging tasks with\nonly small annotated datasets.",
          "link": "http://arxiv.org/abs/2308.06534",
          "publishedOn": "2023-11-04T00:42:37.728Z",
          "wordCount": null,
          "title": "Self-Supervised Pre-Training with Contrastive and Masked Autoencoder Methods for Dealing with Small Datasets in Deep Learning for Medical Imaging. (arXiv:2308.06534v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.00733",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Taghanaki_S/0/1/0/all/0/1\">Saeid Asgari Taghanaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khani_A/0/1/0/all/0/1\">Aliasghar Khani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasahmadi_A/0/1/0/all/0/1\">Amir Khasahmadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanghi_A/0/1/0/all/0/1\">Aditya Sanghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willis_K/0/1/0/all/0/1\">Karl D.D. Willis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahdavi_Amiri_A/0/1/0/all/0/1\">Ali Mahdavi-Amiri</a>",
          "description": "Interpreting the learned features of vision models has posed a longstanding\nchallenge in the field of machine learning. To address this issue, we propose a\nnovel method that leverages the capabilities of large language models (LLMs) to\ninterpret the learned features of pre-trained image classifiers. Our method,\ncalled TExplain, tackles this task by training a neural network to establish a\nconnection between the feature space of image classifiers and LLMs. Then,\nduring inference, our approach generates a vast number of sentences to explain\nthe features learned by the classifier for a given image. These sentences are\nthen used to extract the most frequent words, providing a comprehensive\nunderstanding of the learned features and patterns within the classifier. Our\nmethod, for the first time, utilizes these frequent words corresponding to a\nvisual representation to provide insights into the decision-making process of\nthe independently trained classifier, enabling the detection of spurious\ncorrelations, biases, and a deeper comprehension of its behavior. To validate\nthe effectiveness of our approach, we conduct experiments on diverse datasets,\nincluding ImageNet-9L and Waterbirds. The results demonstrate the potential of\nour method to enhance the interpretability and robustness of image classifiers.",
          "link": "http://arxiv.org/abs/2309.00733",
          "publishedOn": "2023-11-04T00:42:37.728Z",
          "wordCount": null,
          "title": "Learned Visual Features to Textual Explanations. (arXiv:2309.00733v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hanzhong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Cheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_F/0/1/0/all/0/1\">Fan Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1\">Tianyu Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shuicheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1\">Chao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chongxuan Li</a>",
          "description": "Recently, diffusion models have achieved great success in generative tasks.\nSampling from diffusion models is equivalent to solving the reverse diffusion\nstochastic differential equations (SDEs) or the corresponding probability flow\nordinary differential equations (ODEs). In comparison, SDE-based solvers can\ngenerate samples of higher quality and are suited for image translation tasks\nlike stroke-based synthesis. During inference, however, existing SDE-based\nsolvers are severely constrained by the efficiency-effectiveness dilemma. Our\ninvestigation suggests that this is because the Gaussian assumption in the\nreverse transition kernel is frequently violated (even in the case of simple\nmixture data) given a limited number of discretization steps. To overcome this\nlimitation, we introduce a novel class of SDE-based solvers called\n\\emph{Gaussian Mixture Solvers (GMS)} for diffusion models. Our solver\nestimates the first three-order moments and optimizes the parameters of a\nGaussian mixture transition kernel using generalized methods of moments in each\nstep during sampling. Empirically, our solver outperforms numerous SDE-based\nsolvers in terms of sample quality in image generation and stroke-based\nsynthesis in various diffusion models, which validates the motivation and\neffectiveness of GMS. Our code is available at\nhttps://github.com/Guohanzhong/GMS.",
          "link": "http://arxiv.org/abs/2311.00941",
          "publishedOn": "2023-11-04T00:42:37.727Z",
          "wordCount": null,
          "title": "Gaussian Mixture Solvers for Diffusion Models. (arXiv:2311.00941v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gultekin_S/0/1/0/all/0/1\">Sinan Gultekin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Globo_A/0/1/0/all/0/1\">Achille Globo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zugarini_A/0/1/0/all/0/1\">Andrea Zugarini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ernandes_M/0/1/0/all/0/1\">Marco Ernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigutini_L/0/1/0/all/0/1\">Leonardo Rigutini</a>",
          "description": "Most Machine Learning research evaluates the best solutions in terms of\nperformance. However, in the race for the best performing model, many important\naspects are often overlooked when, on the contrary, they should be carefully\nconsidered. In fact, sometimes the gaps in performance between different\napproaches are neglectable, whereas factors such as production costs, energy\nconsumption, and carbon footprint must take into consideration. Large Language\nModels (LLMs) are extensively adopted to address NLP problems in academia and\nindustry. In this work, we present a detailed quantitative comparison of LLM\nand traditional approaches (e.g. SVM) on the LexGLUE benchmark, which takes\ninto account both performance (standard indices) and alternative metrics such\nas timing, power consumption and cost, in a word: the carbon-footprint. In our\nanalysis, we considered the prototyping phase (model selection by\ntraining-validation-test iterations) and in-production phases separately, since\nthey follow different implementation procedures and also require different\nresources. The results indicate that very often, the simplest algorithms\nachieve performance very close to that of large LLMs but with very low power\nconsumption and lower resource demands. The results obtained could suggest\ncompanies to include additional evaluations in the choice of Machine Learning\n(ML) solutions.",
          "link": "http://arxiv.org/abs/2311.01256",
          "publishedOn": "2023-11-04T00:42:37.727Z",
          "wordCount": null,
          "title": "An energy-based comparative analysis of common approaches to text classification in the Legal domain. (arXiv:2311.01256v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramaniam_G/0/1/0/all/0/1\">Gargi Balasubramaniam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_H/0/1/0/all/0/1\">Haozhe Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>",
          "description": "Domain generalization asks for models trained over a set of training\nenvironments to generalize well in unseen test environments. Recently, a series\nof algorithms such as Invariant Risk Minimization (IRM) have been proposed for\ndomain generalization. However, Rosenfeld et al. (2021) shows that in a simple\nlinear data model, even if non-convexity issues are ignored, IRM and its\nextensions cannot generalize to unseen environments with less than $d_s+1$\ntraining environments, where $d_s$ is the dimension of the spurious-feature\nsubspace. In this work, we propose Invariant-feature Subspace Recovery (ISR): a\nnew class of algorithms to achieve provable domain generalization across the\nsettings of classification and regression problems. First, in the binary\nclassification setup of Rosenfeld et al. (2021), we show that our first\nalgorithm, ISR-Mean, can identify the subspace spanned by invariant features\nfrom the first-order moments of the class-conditional distributions, and\nachieve provable domain generalization with $d_s+1$ training environments. Our\nsecond algorithm, ISR-Cov, further reduces the required number of training\nenvironments to $O(1)$ using the information of second-order moments. Notably,\nunlike IRM, our algorithms bypass non-convexity issues and enjoy global\nconvergence guarantees. Next, we extend ISR-Mean to the more general setting of\nmulti-class classification and propose ISR-Multiclass, which leverages class\ninformation and provably recovers the invariant-feature subspace with $\\lceil\nd_s/k\\rceil+1$ training environments for $k$-class classification. Finally, for\nregression problems, we propose ISR-Regression that can identify the\ninvariant-feature subspace with $d_s+1$ training environments. Empirically, we\ndemonstrate the superior performance of our ISRs on synthetic benchmarks.\nFurther, ISR can be used as post-processing methods for feature extractors such\nas neural nets.",
          "link": "http://arxiv.org/abs/2311.00966",
          "publishedOn": "2023-11-04T00:42:37.725Z",
          "wordCount": null,
          "title": "Invariant-Feature Subspace Recovery: A New Class of Provable Domain Generalization Algorithms. (arXiv:2311.00966v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yuan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morioka_N/0/1/0/all/0/1\">Nobuyuki Morioka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nanxin Chen</a>",
          "description": "We propose Easy End-to-End Diffusion-based Text to Speech, a simple and\nefficient end-to-end text-to-speech model based on diffusion. E3 TTS directly\ntakes plain text as input and generates an audio waveform through an iterative\nrefinement process. Unlike many prior work, E3 TTS does not rely on any\nintermediate representations like spectrogram features or alignment\ninformation. Instead, E3 TTS models the temporal structure of the waveform\nthrough the diffusion process. Without relying on additional conditioning\ninformation, E3 TTS could support flexible latent structure within the given\naudio. This enables E3 TTS to be easily adapted for zero-shot tasks such as\nediting without any additional training. Experiments show that E3 TTS can\ngenerate high-fidelity audio, approaching the performance of a state-of-the-art\nneural TTS system. Audio samples are available at https://e3tts.github.io.",
          "link": "http://arxiv.org/abs/2311.00945",
          "publishedOn": "2023-11-04T00:42:37.723Z",
          "wordCount": null,
          "title": "E3 TTS: Easy End-to-End Diffusion-based Text to Speech. (arXiv:2311.00945v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1\">Dinesh Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1\">Ankit Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalappa_C/0/1/0/all/0/1\">Chaitra Gopalappa</a>",
          "description": "Human immunodeficiency virus (HIV) is a major public health concern in the\nUnited States, with about 1.2 million people living with HIV and 35,000 newly\ninfected each year. There are considerable geographical disparities in HIV\nburden and care access across the U.S. The 2019 Ending the HIV Epidemic (EHE)\ninitiative aims to reduce new infections by 90% by 2030, by improving coverage\nof diagnoses, treatment, and prevention interventions and prioritizing\njurisdictions with high HIV prevalence. Identifying optimal scale-up of\nintervention combinations will help inform resource allocation. Existing HIV\ndecision analytic models either evaluate specific cities or the overall\nnational population, thus overlooking jurisdictional interactions or\ndifferences. In this paper, we propose a multi-agent reinforcement learning\n(MARL) model, that enables jurisdiction-specific decision analyses but in an\nenvironment with cross-jurisdictional epidemiological interactions. In\nexperimental analyses, conducted on jurisdictions within California and\nFlorida, optimal policies from MARL were significantly different than those\ngenerated from single-agent RL, highlighting the influence of jurisdictional\nvariations and interactions. By using comprehensive modeling of HIV and\nformulations of state space, action space, and reward functions, this work\nhelps demonstrate the strengths and applicability of MARL for informing public\nhealth policies, and provides a framework for expanding to the national-level\nto inform the EHE.",
          "link": "http://arxiv.org/abs/2311.00855",
          "publishedOn": "2023-11-04T00:42:37.722Z",
          "wordCount": null,
          "title": "A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S. Ending the HIV Epidemic Plan. (arXiv:2311.00855v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karella_T/0/1/0/all/0/1\">Tomas Karella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sroubek_F/0/1/0/all/0/1\">Filip Sroubek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flusser_J/0/1/0/all/0/1\">Jan Flusser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blazek_J/0/1/0/all/0/1\">Jan Blazek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosik_V/0/1/0/all/0/1\">Vasek Kosik</a>",
          "description": "The widespread popularity of equivariant networks underscores the\nsignificance of parameter efficient models and effective use of training data.\nAt a time when robustness to unseen deformations is becoming increasingly\nimportant, we present H-NeXt, which bridges the gap between equivariance and\ninvariance. H-NeXt is a parameter-efficient roto-translation invariant network\nthat is trained without a single augmented image in the training set. Our\nnetwork comprises three components: an equivariant backbone for learning\nroto-translation independent features, an invariant pooling layer for\ndiscarding roto-translation information, and a classification layer. H-NeXt\noutperforms the state of the art in classification on unaugmented training sets\nand augmented test sets of MNIST and CIFAR-10.",
          "link": "http://arxiv.org/abs/2311.01111",
          "publishedOn": "2023-11-04T00:42:37.722Z",
          "wordCount": null,
          "title": "H-NeXt: The next step towards roto-translation invariant networks. (arXiv:2311.01111v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zhongxiang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quoc Phong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_S/0/1/0/all/0/1\">Sebastian Shenghong Tay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urano_D/0/1/0/all/0/1\">Daisuke Urano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leong_R/0/1/0/all/0/1\">Richalynn Leong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Low_B/0/1/0/all/0/1\">Bryan Kian Hsiang Low</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaillet_P/0/1/0/all/0/1\">Patrick Jaillet</a>",
          "description": "Many real-world experimental design problems (a) evaluate multiple\nexperimental conditions in parallel and (b) replicate each condition multiple\ntimes due to large and heteroscedastic observation noise. Given a fixed total\nbudget, this naturally induces a trade-off between evaluating more unique\nconditions while replicating each of them fewer times vs. evaluating fewer\nunique conditions and replicating each more times. Moreover, in these problems,\npractitioners may be risk-averse and hence prefer an input with both good\naverage performance and small variability. To tackle both challenges, we\npropose the Batch Thompson Sampling for Replicable Experimental Design\n(BTS-RED) framework, which encompasses three algorithms. Our BTS-RED-Known and\nBTS-RED-Unknown algorithms, for, respectively, known and unknown noise\nvariance, choose the number of replications adaptively rather than\ndeterministically such that an input with a larger noise variance is replicated\nmore times. As a result, despite the noise heteroscedasticity, both algorithms\nenjoy a theoretical guarantee and are asymptotically no-regret. Our\nMean-Var-BTS-RED algorithm aims at risk-averse optimization and is also\nasymptotically no-regret. We also show the effectiveness of our algorithms in\ntwo practical real-world applications: precision agriculture and AutoML.",
          "link": "http://arxiv.org/abs/2311.01195",
          "publishedOn": "2023-11-04T00:42:37.722Z",
          "wordCount": null,
          "title": "Batch Bayesian Optimization for Replicable Experimental Design. (arXiv:2311.01195v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00750",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotar_K/0/1/0/all/0/1\">Klemen Kotar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1\">Stephen Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong-Xing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamins_D/0/1/0/all/0/1\">Daniel L.K. Yamins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>",
          "description": "The human visual system can effortlessly recognize an object under different\nextrinsic factors such as lighting, object poses, and background, yet current\ncomputer vision systems often struggle with these variations. An important step\nto understanding and improving artificial vision systems is to measure image\nsimilarity purely based on intrinsic object properties that define object\nidentity. This problem has been studied in the computer vision literature as\nre-identification, though mostly restricted to specific object categories such\nas people and cars. We propose to extend it to general object categories,\nexploring an image similarity metric based on object intrinsics. To benchmark\nsuch measurements, we collect the Common paired objects Under differenT\nExtrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different\nextrinsic factors such as lighting, poses, and imaging conditions. While\nexisting methods such as LPIPS and CLIP scores do not measure object intrinsics\nwell, we find that combining deep features learned from contrastive\nself-supervised learning with foreground filtering is a simple yet effective\napproach to approximating the similarity. We conduct an extensive survey of\npre-trained features and foreground extraction methods to arrive at a strong\nbaseline that best measures intrinsic object-centric image similarity among\ncurrent methods. Finally, we demonstrate that our approach can aid in\ndownstream applications such as acting as an analog for human subjects and\nimproving generalizable re-identification. Please see our project website at\nhttps://s-tian.github.io/projects/cute/ for visualizations of the data and\ndemos of our metric.",
          "link": "http://arxiv.org/abs/2311.00750",
          "publishedOn": "2023-11-04T00:42:37.720Z",
          "wordCount": null,
          "title": "Are These the Same Apple? Comparing Images Based on Object Intrinsics. (arXiv:2311.00750v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01050",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singhal_C/0/1/0/all/0/1\">Chetna Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barick_S/0/1/0/all/0/1\">Subhrajit Barick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonkar_R/0/1/0/all/0/1\">Rishabh Sonkar</a>",
          "description": "The battery-less Internet of Things (IoT) devices are a key element in the\nsustainable green initiative for the next-generation wireless networks. These\nbattery-free devices use the ambient energy, harvested from the environment.\nThe energy harvesting environment is dynamic and causes intermittent task\nexecution. The harvested energy is stored in small capacitors and it is\nchallenging to assure the application task execution. The main goal is to\nprovide a mechanism to aggregate the sensor data and provide a sustainable\napplication support in the distributed battery-less IoT network. We model the\ndistributed IoT network system consisting of many battery-free IoT sensor\nhardware modules and heterogeneous IoT applications that are being supported in\nthe device-edge-cloud continuum. The applications require sensor data from a\ndistributed set of battery-less hardware modules and there is provision of\njoint control over the module actuators. We propose an application-aware task\nand energy manager (ATEM) for the IoT devices and a vector-synchronization\nbased data aggregator (VSDA). The ATEM is supported by device-level federated\nenergy harvesting and system-level energy-aware heterogeneous application\nmanagement. In our proposed framework the data aggregator forecasts the\navailable power from the ambient energy harvester using long-short-term-memory\n(LSTM) model and sets the device profile as well as the application task rates\naccordingly. Our proposed scheme meets the heterogeneous application\nrequirements with negligible overhead; reduces the data loss and packet delay;\nincreases the hardware component availability; and makes the components\navailable sooner as compared to the state-of-the-art.",
          "link": "http://arxiv.org/abs/2311.01050",
          "publishedOn": "2023-11-04T00:42:37.719Z",
          "wordCount": null,
          "title": "Application and Energy-Aware Data Aggregation using Vector Synchronization in Distributed Battery-less IoT Networks. (arXiv:2311.01050v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xinghang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanbo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Cunjun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hongtao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheang_C/0/1/0/all/0/1\">Chilam Cheang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_Y/0/1/0/all/0/1\">Ya Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weinan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huaping Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_T/0/1/0/all/0/1\">Tao Kong</a>",
          "description": "Recent progress in vision language foundation models has shown their ability\nto understand multimodal data and resolve complicated vision language tasks,\nincluding robotics manipulation. We seek a straightforward way of making use of\nexisting vision-language models (VLMs) with simple fine-tuning on robotics\ndata. To this end, we derive a simple and novel vision-language manipulation\nframework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo.\nUnlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step\nvision-language comprehension, models sequential history information with an\nexplicit policy head, and is slightly fine-tuned by imitation learning only on\nlanguage-conditioned manipulation datasets. Such a decomposition provides\nRoboFlamingo the flexibility for open-loop control and deployment on\nlow-performance platforms. By exceeding the state-of-the-art performance with a\nlarge margin on the tested benchmark, we show RoboFlamingo can be an effective\nand competitive alternative to adapt VLMs to robot control. Our extensive\nexperimental results also reveal several interesting conclusions regarding the\nbehavior of different pre-trained VLMs on manipulation tasks. We believe\nRoboFlamingo has the potential to be a cost-effective and easy-to-use solution\nfor robotics manipulation, empowering everyone with the ability to fine-tune\ntheir own robotics policy.",
          "link": "http://arxiv.org/abs/2311.01378",
          "publishedOn": "2023-11-04T00:42:37.692Z",
          "wordCount": null,
          "title": "Vision-Language Foundation Models as Effective Robot Imitators. (arXiv:2311.01378v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00944",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_M/0/1/0/all/0/1\">Minhui Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiawei Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1\">Cong Shen</a>",
          "description": "In recent years, federated minimax optimization has attracted growing\ninterest due to its extensive applications in various machine learning tasks.\nWhile Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved\nits success in centralized nonconvex minimax optimization, how and whether\nsmoothing technique could be helpful in federated setting remains unexplored.\nIn this paper, we propose a new algorithm termed Federated Stochastic Smoothed\nGradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for\nfederated minimax optimization. We prove that FESS-GDA can be uniformly used to\nsolve several classes of federated minimax problems and prove new or better\nanalytical convergence results for these settings. We showcase the practical\nefficiency of FESS-GDA in practical federated learning tasks of training\ngenerative adversarial networks (GANs) and fair classification.",
          "link": "http://arxiv.org/abs/2311.00944",
          "publishedOn": "2023-11-04T00:42:37.691Z",
          "wordCount": null,
          "title": "Stochastic Smoothed Gradient Descent Ascent for Federated Minimax Optimization. (arXiv:2311.00944v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.12783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Auer_A/0/1/0/all/0/1\">Andreas Auer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gauch_M/0/1/0/all/0/1\">Martin Gauch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klotz_D/0/1/0/all/0/1\">Daniel Klotz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>",
          "description": "To quantify uncertainty, conformal prediction methods are gaining\ncontinuously more interest and have already been successfully applied to\nvarious domains. However, they are difficult to apply to time series as the\nautocorrelative structure of time series violates basic assumptions required by\nconformal prediction. We propose HopCPT, a novel conformal prediction approach\nfor time series that not only copes with temporal structures but leverages\nthem. We show that our approach is theoretically well justified for time series\nwhere temporal dependencies are present. In experiments, we demonstrate that\nour new approach outperforms state-of-the-art conformal prediction methods on\nmultiple real-world time series datasets from four different domains.",
          "link": "http://arxiv.org/abs/2303.12783",
          "publishedOn": "2023-11-04T00:42:37.691Z",
          "wordCount": null,
          "title": "Conformal Prediction for Time Series with Modern Hopfield Networks. (arXiv:2303.12783v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Viviani_P/0/1/0/all/0/1\">Paolo Viviani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gesmundo_I/0/1/0/all/0/1\">Ilaria Gesmundo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghinato_E/0/1/0/all/0/1\">Elios Ghinato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agudelo_Toro_A/0/1/0/all/0/1\">Andres Agudelo-Toro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vercellino_C/0/1/0/all/0/1\">Chiara Vercellino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vitali_G/0/1/0/all/0/1\">Giacomo Vitali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergamasco_L/0/1/0/all/0/1\">Letizia Bergamasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scionti_A/0/1/0/all/0/1\">Alberto Scionti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghislieri_M/0/1/0/all/0/1\">Marco Ghislieri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agostini_V/0/1/0/all/0/1\">Valentina Agostini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Terzo_O/0/1/0/all/0/1\">Olivier Terzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherberger_H/0/1/0/all/0/1\">Hansj&#xf6;rg Scherberger</a>",
          "description": "Neural decoding involves correlating signals acquired from the brain to\nvariables in the physical world like limb movement or robot control in Brain\nMachine Interfaces. In this context, this work starts from a specific\npre-existing dataset of neural recordings from monkey motor cortex and presents\na Deep Learning-based approach to the decoding of neural signals for grasp type\nclassification. Specifically, we propose here an approach that exploits LSTM\nnetworks to classify time series containing neural data (i.e., spike trains)\ninto classes representing the object being grasped. The main goal of the\npresented approach is to improve over state-of-the-art decoding accuracy\nwithout relying on any prior neuroscience knowledge, and leveraging only the\ncapability of deep learning models to extract correlations from data. The paper\npresents the results achieved for the considered dataset and compares them with\nprevious works on the same dataset, showing a significant improvement in\nclassification accuracy, even if considering simulated real-time decoding.",
          "link": "http://arxiv.org/abs/2311.01061",
          "publishedOn": "2023-11-04T00:42:37.684Z",
          "wordCount": null,
          "title": "Deep Learning for real-time neural decoding of grasp. (arXiv:2311.01061v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gogoulou_E/0/1/0/all/0/1\">Evangelia Gogoulou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lesort_T/0/1/0/all/0/1\">Timoth&#xe9;e Lesort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boman_M/0/1/0/all/0/1\">Magnus Boman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nivre_J/0/1/0/all/0/1\">Joakim Nivre</a>",
          "description": "The recent increase in data and model scale for language model pre-training\nhas led to huge training costs. In scenarios where new data become available\nover time, updating a model instead of fully retraining it would therefore\nprovide significant gains. In this paper, we study the benefits and downsides\nof updating a language model when new data comes from new languages - the case\nof continual learning under language shift. Starting from a monolingual English\nlanguage model, we incrementally add data from Norwegian and Icelandic to\ninvestigate how forward and backward transfer effects depend on the\npre-training order and characteristics of languages, for different model sizes\nand learning rate schedulers. Our results show that, while forward transfer is\nlargely positive and independent of language order, backward transfer can be\neither positive or negative depending on the order and characteristics of new\nlanguages. To explain these patterns we explore several language similarity\nmetrics and find that syntactic similarity appears to have the best correlation\nwith our results.",
          "link": "http://arxiv.org/abs/2311.01200",
          "publishedOn": "2023-11-04T00:42:37.684Z",
          "wordCount": null,
          "title": "A Study of Continual Learning Under Language Shift. (arXiv:2311.01200v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01367",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Islam_M/0/1/0/all/0/1\">Md Zobaer Islam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Martin_B/0/1/0/all/0/1\">Brenden Martin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gotcher_C/0/1/0/all/0/1\">Carly Gotcher</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Martinez_T/0/1/0/all/0/1\">Tyler Martinez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+OHara_J/0/1/0/all/0/1\">John F. O&#x27;Hara</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ekin_S/0/1/0/all/0/1\">Sabit Ekin</a>",
          "description": "In this study, we present a non-contact respiratory anomaly detection method\nusing incoherent light-wave signals reflected from the chest of a mechanical\nrobot that can breathe like human beings. In comparison to existing radar and\ncamera-based sensing systems for vitals monitoring, this technology uses only a\nlow-cost ubiquitous light source (e.g., infrared light emitting diode) and\nsensor (e.g., photodetector). This light-wave sensing (LWS) system recognizes\ndifferent breathing anomalies from the variations of light intensity reflected\nfrom the chest of the robot within a 0.5m-1.5m range. The anomaly detection\nmodel demonstrates up to 96.6% average accuracy in classifying 7 different\ntypes of breathing data using machine learning. The model can also detect\nfaulty data collected by the system that does not contain breathing\ninformation. The developed system can be utilized at home or healthcare\nfacilities as a smart, non-contact and discreet respiration monitoring method.",
          "link": "http://arxiv.org/abs/2311.01367",
          "publishedOn": "2023-11-04T00:42:37.684Z",
          "wordCount": null,
          "title": "Respiratory Anomaly Detection using Reflected Infrared Light-wave Signals. (arXiv:2311.01367v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.10725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Harun_M/0/1/0/all/0/1\">Md Yousuf Harun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallardo_J/0/1/0/all/0/1\">Jhair Gallardo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayes_T/0/1/0/all/0/1\">Tyler L. Hayes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kemker_R/0/1/0/all/0/1\">Ronald Kemker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanan_C/0/1/0/all/0/1\">Christopher Kanan</a>",
          "description": "In supervised continual learning, a deep neural network (DNN) is updated with\nan ever-growing data stream. Unlike the offline setting where data is shuffled,\nwe cannot make any distributional assumptions about the data stream. Ideally,\nonly one pass through the dataset is needed for computational efficiency.\nHowever, existing methods are inadequate and make many assumptions that cannot\nbe made for real-world applications, while simultaneously failing to improve\ncomputational efficiency. In this paper, we propose a novel continual learning\nmethod, SIESTA based on wake/sleep framework for training, which is well\naligned to the needs of on-device learning. The major goal of SIESTA is to\nadvance compute efficient continual learning so that DNNs can be updated\nefficiently using far less time and energy. The principal innovations of SIESTA\nare: 1) rapid online updates using a rehearsal-free, backpropagation-free, and\ndata-driven network update rule during its wake phase, and 2) expedited memory\nconsolidation using a compute-restricted rehearsal policy during its sleep\nphase. For memory efficiency, SIESTA adapts latent rehearsal using memory\nindexing from REMIND. Compared to REMIND and prior arts, SIESTA is far more\ncomputationally efficient, enabling continual learning on ImageNet-1K in under\n2 hours on a single GPU; moreover, in the augmentation-free setting it matches\nthe performance of the offline learner, a milestone critical to driving\nadoption of continual learning in real-world applications.",
          "link": "http://arxiv.org/abs/2303.10725",
          "publishedOn": "2023-11-04T00:42:37.679Z",
          "wordCount": null,
          "title": "SIESTA: Efficient Online Continual Learning with Sleep. (arXiv:2303.10725v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quirke_L/0/1/0/all/0/1\">Lucia Quirke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heindrich_L/0/1/0/all/0/1\">Lovis Heindrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurnee_W/0/1/0/all/0/1\">Wes Gurnee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nanda_N/0/1/0/all/0/1\">Neel Nanda</a>",
          "description": "Prior work has shown the existence of contextual neurons in language models,\nincluding a neuron that activates on German text. We show that this neuron\nexists within a broader contextual n-gram circuit: we find late layer neurons\nwhich recognize and continue n-grams common in German text, but which only\nactivate if the German neuron is active. We investigate the formation of this\ncircuit throughout training and find that it is an example of what we call a\nsecond-order circuit. In particular, both the constituent n-gram circuits and\nthe German detection circuit which culminates in the German neuron form with\nindependent functions early in training - the German detection circuit\npartially through modeling German unigram statistics, and the n-grams by\nboosting appropriate completions. Only after both circuits have already formed\ndo they fit together into a second-order circuit. Contrary to the hypotheses\npresented in prior work, we find that the contextual n-gram circuit forms\ngradually rather than in a sudden phase transition. We further present a range\nof anomalous observations such as a simultaneous phase transition in many tasks\ncoinciding with the learning rate warm-up, and evidence that many context\nneurons form simultaneously early in training but are later unlearned.",
          "link": "http://arxiv.org/abs/2311.00863",
          "publishedOn": "2023-11-04T00:42:37.678Z",
          "wordCount": null,
          "title": "Training Dynamics of Contextual N-Grams in Language Models. (arXiv:2311.00863v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_K/0/1/0/all/0/1\">Keqing Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenguang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xinyu Yang</a>",
          "description": "The fusion of causal models with deep learning introducing increasingly\nintricate data sets, such as the causal associations within images or between\ntextual components, has surfaced as a focal research area. Nonetheless, the\nbroadening of original causal concepts and theories to such complex,\nnon-statistical data has been met with serious challenges. In response, our\nstudy proposes redefinitions of causal data into three distinct categories from\nthe standpoint of causal structure and representation: definite data,\nsemi-definite data, and indefinite data. Definite data chiefly pertains to\nstatistical data used in conventional causal scenarios, while semi-definite\ndata refers to a spectrum of data formats germane to deep learning, including\ntime-series, images, text, and others. Indefinite data is an emergent research\nsphere inferred from the progression of data forms by us. To comprehensively\npresent these three data paradigms, we elaborate on their formal definitions,\ndifferences manifested in datasets, resolution pathways, and development of\nresearch. We summarize key tasks and achievements pertaining to definite and\nsemi-definite data from myriad research undertakings, present a roadmap for\nindefinite data, beginning with its current research conundrums. Lastly, we\nclassify and scrutinize the key datasets presently utilized within these three\nparadigms.",
          "link": "http://arxiv.org/abs/2311.00923",
          "publishedOn": "2023-11-04T00:42:37.671Z",
          "wordCount": null,
          "title": "A Review and Roadmap of Deep Causal Model from Different Causal Structures and Representations. (arXiv:2311.00923v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1\">Wonjun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yifei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1\">Dongmian Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerman_G/0/1/0/all/0/1\">Gilad Lerman</a>",
          "description": "Generative Adversarial Networks (GANs) are powerful tools for creating new\ncontent, but they face challenges such as sensitivity to starting conditions\nand mode collapse. To address these issues, we propose a deep generative model\nthat utilizes the Gromov-Monge embedding (GME). It helps identify the\nlow-dimensional structure of the underlying measure of the data and then maps\nit, while preserving its geometry, into a measure in a low-dimensional latent\nspace, which is then optimally transported to the reference measure. We\nguarantee the preservation of the underlying geometry by the GME and\n$c$-cyclical monotonicity of the generative map, where $c$ is an intrinsic\nembedding cost employed by the GME. The latter property is a first step in\nguaranteeing better robustness to initialization of parameters and mode\ncollapse. Numerical experiments demonstrate the effectiveness of our approach\nin generating high-quality images, avoiding mode collapse, and exhibiting\nrobustness to different starting conditions.",
          "link": "http://arxiv.org/abs/2311.01375",
          "publishedOn": "2023-11-04T00:42:37.670Z",
          "wordCount": null,
          "title": "Monotone Generative Modeling via a Gromov-Monge Embedding. (arXiv:2311.01375v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.03152",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Biswas_N/0/1/0/all/0/1\">Niloy Biswas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "Markov chain Monte Carlo (MCMC) provides asymptotically consistent estimates\nof intractable posterior expectations as the number of iterations tends to\ninfinity. However, in large data applications, MCMC can be computationally\nexpensive per iteration. This has catalyzed interest in approximating MCMC in a\nmanner that improves computational speed per iteration but does not produce\nasymptotically consistent estimates. In this article, we propose estimators\nbased on couplings of Markov chains to assess the quality of such\nasymptotically biased sampling methods. The estimators give empirical upper\nbounds of the Wasserstein distance between the limiting distribution of the\nasymptotically biased sampling method and the original target distribution of\ninterest. We establish theoretical guarantees for our upper bounds and show\nthat our estimators can remain effective in high dimensions. We apply our\nquality measures to stochastic gradient MCMC, variational Bayes, and Laplace\napproximations for tall data and to approximate MCMC for Bayesian logistic\nregression in 4500 dimensions and Bayesian linear regression in 50000\ndimensions.",
          "link": "http://arxiv.org/abs/2112.03152",
          "publishedOn": "2023-11-04T00:42:37.670Z",
          "wordCount": null,
          "title": "Bounding Wasserstein distance with couplings. (arXiv:2112.03152v3 [stat.CO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Homaei_M/0/1/0/all/0/1\">MohammadHossein Homaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_O/0/1/0/all/0/1\">Oscar Mogollon Gutierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nunez_J/0/1/0/all/0/1\">Jose Carlos Sancho Nunez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vegas_M/0/1/0/all/0/1\">Mar Avila Vegas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindo_A/0/1/0/all/0/1\">Andres Caro Lindo</a>",
          "description": "The potential of digital twin technology is yet to be fully realized due to\nits diversity and untapped potential. Digital twins enable systems' analysis,\ndesign, optimization, and evolution to be performed digitally or in conjunction\nwith a cyber-physical approach to improve speed, accuracy, and efficiency over\ntraditional engineering methods. Industry 4.0, factories of the future, and\ndigital twins continue to benefit from the technology and provide enhanced\nefficiency within existing systems. Due to the lack of information and security\nstandards associated with the transition to cyber digitization, cybercriminals\nhave been able to take advantage of the situation. Access to a digital twin of\na product or service is equivalent to threatening the entire collection. There\nis a robust interaction between digital twins and artificial intelligence\ntools, which leads to strong interaction between these technologies, so it can\nbe used to improve the cybersecurity of these digital platforms based on their\nintegration with these technologies. This study aims to investigate the role of\nartificial intelligence in providing cybersecurity for digital twin versions of\nvarious industries, as well as the risks associated with these versions. In\naddition, this research serves as a road map for researchers and others\ninterested in cybersecurity and digital security.",
          "link": "http://arxiv.org/abs/2311.01154",
          "publishedOn": "2023-11-04T00:42:37.669Z",
          "wordCount": null,
          "title": "A Review of Digital Twins and their Application in Cybersecurity based on Artificial Intelligence. (arXiv:2311.01154v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01201",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saylam_B/0/1/0/all/0/1\">Berrenur Saylam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Incel_O/0/1/0/all/0/1\">&#xd6;zlem Durmaz &#x130;ncel</a>",
          "description": "The ability to monitor ambient characteristics, interact with them, and\nderive information about the surroundings has been made possible by the rapid\nproliferation of edge sensing devices like IoT, mobile, and wearable devices\nand their measuring capabilities with integrated sensors. Even though these\ndevices are small and have less capacity for data storage and processing, they\nproduce vast amounts of data. Some example application areas where sensor data\nis collected and processed include healthcare, environmental (including air\nquality and pollution levels), automotive, industrial, aerospace, and\nagricultural applications. These enormous volumes of sensing data collected\nfrom the edge devices are analyzed using a variety of Machine Learning (ML) and\nDeep Learning (DL) approaches. However, analyzing them on the cloud or a server\npresents challenges related to privacy, hardware, and connectivity limitations.\nFederated Learning (FL) is emerging as a solution to these problems while\npreserving privacy by jointly training a model without sharing raw data. In\nthis paper, we review the FL strategies from the perspective of edge sensing\ndevices to get over the limitations of conventional machine learning\ntechniques. We focus on the key FL principles, software frameworks, and\ntestbeds. We also explore the current sensor technologies, properties of the\nsensing devices and sensing applications where FL is utilized. We conclude with\na discussion on open issues and future research directions on FL for further\nstudies",
          "link": "http://arxiv.org/abs/2311.01201",
          "publishedOn": "2023-11-04T00:42:37.669Z",
          "wordCount": null,
          "title": "Federated Learning on Edge Sensing Devices: A Review. (arXiv:2311.01201v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhengbang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hanye Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Haoran He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yichao Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shenyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weinan Zhang</a>",
          "description": "Diffusion models have emerged as a prominent class of generative models,\nsurpassing previous methods regarding sample quality and training stability.\nRecent works have shown the advantages of diffusion models in improving\nreinforcement learning (RL) solutions, including as trajectory planners,\nexpressive policy classes, data synthesizers, etc. This survey aims to provide\nan overview of the advancements in this emerging field and hopes to inspire new\navenues of research. First, we examine several challenges encountered by\ncurrent RL algorithms. Then, we present a taxonomy of existing methods based on\nthe roles played by diffusion models in RL and explore how the existing\nchallenges are addressed. We further outline successful applications of\ndiffusion models in various RL-related tasks while discussing the limitations\nof current approaches. Finally, we conclude the survey and offer insights into\nfuture research directions, focusing on enhancing model performance and\napplying diffusion models to broader tasks. We are actively maintaining a\nGitHub repository for papers and other related resources in applying diffusion\nmodels in RL: https://github.com/apexrl/Diff4RLSurvey .",
          "link": "http://arxiv.org/abs/2311.01223",
          "publishedOn": "2023-11-04T00:42:37.669Z",
          "wordCount": null,
          "title": "Diffusion Models for Reinforcement Learning: A Survey. (arXiv:2311.01223v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.08907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Olatunji_I/0/1/0/all/0/1\">Iyiola E. Olatunji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funke_T/0/1/0/all/0/1\">Thorben Funke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khosla_M/0/1/0/all/0/1\">Megha Khosla</a>",
          "description": "With the increasing popularity of graph neural networks (GNNs) in several\nsensitive applications like healthcare and medicine, concerns have been raised\nover the privacy aspects of trained GNNs. More notably, GNNs are vulnerable to\nprivacy attacks, such as membership inference attacks, even if only black-box\naccess to the trained model is granted. We propose PrivGNN, a\nprivacy-preserving framework for releasing GNN models in a centralized setting.\nAssuming an access to a public unlabeled graph, PrivGNN provides a framework to\nrelease GNN models trained explicitly on public data along with knowledge\nobtained from the private data in a privacy preserving manner. PrivGNN combines\nthe knowledge-distillation framework with the two noise mechanisms, random\nsubsampling, and noisy labeling, to ensure rigorous privacy guarantees. We\ntheoretically analyze our approach in the Renyi differential privacy framework.\nBesides, we show the solid experimental performance of our method compared to\nseveral baselines adapted for graph-structured data. Our code is available at\nhttps://github.com/iyempissy/privGnn.",
          "link": "http://arxiv.org/abs/2109.08907",
          "publishedOn": "2023-11-04T00:42:37.669Z",
          "wordCount": null,
          "title": "Releasing Graph Neural Networks with Differential Privacy Guarantees. (arXiv:2109.08907v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01853",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rozet_F/0/1/0/all/0/1\">Fran&#xe7;ois Rozet</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Louppe_G/0/1/0/all/0/1\">Gilles Louppe</a>",
          "description": "Data assimilation addresses the problem of identifying plausible state\ntrajectories of dynamical systems given noisy or incomplete observations. In\ngeosciences, it presents challenges due to the high-dimensionality of\ngeophysical dynamical systems, often exceeding millions of dimensions. This\nwork assesses the scalability of score-based data assimilation (SDA), a novel\ndata assimilation method, in the context of such systems. We propose\nmodifications to the score network architecture aimed at significantly reducing\nmemory consumption and execution time. We demonstrate promising results for a\ntwo-layer quasi-geostrophic model.",
          "link": "http://arxiv.org/abs/2310.01853",
          "publishedOn": "2023-11-04T00:42:37.668Z",
          "wordCount": null,
          "title": "Score-based Data Assimilation for a Two-Layer Quasi-Geostrophic Model. (arXiv:2310.01853v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Feiyu Yang</a>",
          "description": "The single-track railway train timetabling problem (TTP) is an important and\ncomplex problem. This article proposes an integrated Monte Carlo Tree Search\n(MCTS) computing framework that combines heuristic methods, unsupervised\nlearning methods, and supervised learning methods for solving TTP in discrete\naction spaces. This article first describes the mathematical model and\nsimulation system dynamics of TTP, analyzes the characteristics of the solution\nfrom the perspective of MCTS, and proposes some heuristic methods to improve\nMCTS. This article considers these methods as planners in the proposed\nframework. Secondly, this article utilizes deep convolutional neural networks\nto approximate the value of nodes and further applies them to the MCTS search\nprocess, referred to as learners. The experiment shows that the proposed\nheuristic MCTS method is beneficial for solving TTP; The algorithm framework\nthat integrates planners and learners can improve the data efficiency of\nsolving TTP; The proposed method provides a new paradigm for solving TTP.",
          "link": "http://arxiv.org/abs/2311.00971",
          "publishedOn": "2023-11-04T00:42:37.662Z",
          "wordCount": null,
          "title": "An Integrated Framework Integrating Monte Carlo Tree Search and Supervised Learning for Train Timetabling Problem. (arXiv:2311.00971v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00865",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gerstgrasser_M/0/1/0/all/0/1\">Matthias Gerstgrasser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danino_T/0/1/0/all/0/1\">Tom Danino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keren_S/0/1/0/all/0/1\">Sarah Keren</a>",
          "description": "We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized\nExperience Relay, in which agents share with other agents a limited number of\ntransitions they observe during training. The intuition behind this is that\neven a small number of relevant experiences from other agents could help each\nagent learn. Unlike many other multi-agent RL algorithms, this approach allows\nfor largely decentralized training, requiring only a limited communication\nchannel between agents. We show that our approach outperforms baseline\nno-sharing decentralized training and state-of-the art multi-agent RL\nalgorithms. Further, sharing only a small number of highly relevant experiences\noutperforms sharing all experiences between agents, and the performance uplift\nfrom selective experience sharing is robust across a range of hyperparameters\nand DQN variants. A reference implementation of our algorithm is available at\nhttps://github.com/mgerstgrasser/super.",
          "link": "http://arxiv.org/abs/2311.00865",
          "publishedOn": "2023-11-04T00:42:37.661Z",
          "wordCount": null,
          "title": "Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning. (arXiv:2311.00865v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.01632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoppe_J/0/1/0/all/0/1\">Josef Hoppe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaub_M/0/1/0/all/0/1\">Michael T. Schaub</a>",
          "description": "Obtaining sparse, interpretable representations of observable data is crucial\nin many machine learning and signal processing tasks. For data representing\nflows along the edges of a graph, an intuitively interpretable way to obtain\nsuch representations is to lift the graph structure to a simplicial complex:\nThe eigenvectors of the associated Hodge-Laplacian, respectively the incidence\nmatrices of the corresponding simplicial complex then induce a Hodge\ndecomposition, which can be used to represent the observed data in terms of\ngradient, curl, and harmonic flows. In this paper, we generalize this approach\nto cellular complexes and introduce the flow representation learning problem,\ni.e., the problem of augmenting the observed graph by a set of cells, such that\nthe eigenvectors of the associated Hodge Laplacian provide a sparse,\ninterpretable representation of the observed edge flows on the graph. We show\nthat this problem is NP-hard and introduce an efficient approximation algorithm\nfor its solution. Experiments on real-world and synthetic data demonstrate that\nour algorithm outperforms state-of-the-art methods with respect to\napproximation error, while being computationally efficient.",
          "link": "http://arxiv.org/abs/2309.01632",
          "publishedOn": "2023-11-04T00:42:37.659Z",
          "wordCount": null,
          "title": "Representing Edge Flows on Graphs via Sparse Cell Complexes. (arXiv:2309.01632v3 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1\">Bohui Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xubiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Pengfei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shirui Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xinchong Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangsong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiaoyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bingxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiegen Liu</a>",
          "description": "Positron emission tomography (PET), as an imaging technique with high\nbiochemical sensitivity, has been widely used in diagnosis of encephalopathy\nand brain science research used in brain disease diagnosis and brain science\nresearch. Since different tracers present different effects on the same focal\narea, the choice of tracers is getting more significant for PET imaging.\nNowadays, with the wide application of PET imaging in neuropsychiatric\ntreatment, 6-18F-fluoro-3, 4-dihydroxy-L-phenylalanine (DOPA) has been found to\nbe more effective than 18F-labeled fluorine-2-deoxyglucose (FDG) in this field.\nHowever, due to the complexity of its preparation and other limitations, DOPA\nis far less widely used than FDG. To address this issue, a tracer conversion\ninvertible neural network (TC-INN) for image projection is developed to map FDG\nimages to DOPA images through deep learning. More diagnostic information is\nobtained by generating PET images from FDG to DOPA. Specifically, the proposed\nTC-INN consists of two separate phases, one for training the traceable data,\nthe other for re-building the new data. The reference DOPA PET image is used as\nthe learning target for the corresponding network during the training process\nof tracer conversion. Mean-while, the invertible network iteratively estimates\nthe resultant DOPA PET data and compares it to the reference DOPA PET data.\nNotably, the reversible model employed variable enhancement techniques to\nachieve better power generation. Moreover, image registration needs to be\nperformed before training due to the angular deviation of the acquired FDG and\nDOPA data information. Experimental results show generative ability in mapping\nbe-tween FDG images and DOPA images. It demonstrates great potential for PET\nimage conversion in the case of limited tracer applications.",
          "link": "http://arxiv.org/abs/2311.00735",
          "publishedOn": "2023-11-04T00:42:37.658Z",
          "wordCount": null,
          "title": "PET Tracer Conversion among Brain PET via Variable Augmented Invertible Network. (arXiv:2311.00735v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00807",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Unni_S/0/1/0/all/0/1\">Suraj Jyothi Unni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moraffah_R/0/1/0/all/0/1\">Raha Moraffah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>",
          "description": "Visual question answering (VQA) models are designed to demonstrate\nvisual-textual reasoning capabilities. However, their real-world applicability\nis hindered by a lack of comprehensive benchmark datasets. Existing domain\ngeneralization datasets for VQA exhibit a unilateral focus on textual shifts\nwhile VQA being a multi-modal task contains shifts across both visual and\ntextual domains. We propose VQA-GEN, the first ever multi-modal benchmark\ndataset for distribution shift generated through a shift induced pipeline.\nExperiments demonstrate VQA-GEN dataset exposes the vulnerability of existing\nmethods to joint multi-modal distribution shifts. validating that comprehensive\nmulti-modal shifts are critical for robust VQA generalization. Models trained\non VQA-GEN exhibit improved cross-domain and in-domain performance, confirming\nthe value of VQA-GEN. Further, we analyze the importance of each shift\ntechnique of our pipeline contributing to the generalization of the model.",
          "link": "http://arxiv.org/abs/2311.00807",
          "publishedOn": "2023-11-04T00:42:37.658Z",
          "wordCount": null,
          "title": "VQA-GEN: A Visual Question Answering Benchmark for Domain Generalization. (arXiv:2311.00807v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiacheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1\">Ninghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1\">Bruno Ribeiro</a>",
          "description": "In Member Inference (MI) attacks, the adversary try to determine whether an\ninstance is used to train a machine learning (ML) model. MI attacks are a major\nprivacy concern when using private data to train ML models. Most MI attacks in\nthe literature take advantage of the fact that ML models are trained to fit the\ntraining data well, and thus have very low loss on training instances. Most\ndefenses against MI attacks therefore try to make the model fit the training\ndata less well. Doing so, however, generally results in lower accuracy. We\nobserve that training instances have different degrees of vulnerability to MI\nattacks. Most instances will have low loss even when not included in training.\nFor these instances, the model can fit them well without concerns of MI\nattacks. An effective defense only needs to (possibly implicitly) identify\ninstances that are vulnerable to MI attacks and avoids overfitting them. A\nmajor challenge is how to achieve such an effect in an efficient training\nprocess. Leveraging two distinct recent advancements in representation\nlearning: counterfactually-invariant representations and subspace learning\nmethods, we introduce a novel Membership-Invariant Subspace Training (MIST)\nmethod to defend against MI attacks. MIST avoids overfitting the vulnerable\ninstances without significant impact on other instances. We have conducted\nextensive experimental studies, comparing MIST with various other\nstate-of-the-art (SOTA) MI defenses against several SOTA MI attacks. We find\nthat MIST outperforms other defenses while resulting in minimal reduction in\ntesting accuracy.",
          "link": "http://arxiv.org/abs/2311.00919",
          "publishedOn": "2023-11-04T00:42:37.658Z",
          "wordCount": null,
          "title": "MIST: Defending Against Membership Inference Attacks Through Membership-Invariant Subspace Training. (arXiv:2311.00919v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Li Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1\">Ruida Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1\">Chao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Cong Shen</a>",
          "description": "We study a federated linear bandits model, where $M$ clients communicate with\na central server to solve a linear contextual bandits problem with finite\nadversarial action sets that may be different across clients. To address the\nunique challenges of adversarial finite action sets, we propose the\nFedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL\nalgorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a\ntotal regret of $\\tilde{O}(\\sqrt{d T})$, where $T$ is the total number of arm\npulls from all clients, and $d$ is the ambient dimension of the linear model.\nThis matches the minimax lower bound and thus is order-optimal (up to polylog\nterms). We study both asynchronous and synchronous cases and show that the\ncommunication cost can be controlled as $O(d M^2 \\log(d)\\log(T))$ and\n$O(\\sqrt{d^3 M^3} \\log(d))$, respectively. The FedSupLinUCB design is further\nextended to two scenarios: (1) variance-adaptive, where a total regret of\n$\\tilde{O} (\\sqrt{d \\sum \\nolimits_{t=1}^{T} \\sigma_t^2})$ can be achieved with\n$\\sigma_t^2$ being the noise variance of round $t$; and (2) adversarial\ncorruption, where a total regret of $\\tilde{O}(\\sqrt{dT} + d C_p)$ can be\nachieved with $C_p$ being the total corruption budget. Experiment results\ncorroborate the theoretical analysis and demonstrate the effectiveness of\nFedSupLinUCB on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2311.00973",
          "publishedOn": "2023-11-04T00:42:37.658Z",
          "wordCount": null,
          "title": "Federated Linear Bandits with Finite Adversarial Actions. (arXiv:2311.00973v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00975",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Poole_W/0/1/0/all/0/1\">William Poole</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ouldridge_T/0/1/0/all/0/1\">Thomas E. Ouldridge</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gopalkrishnan_M/0/1/0/all/0/1\">Manoj Gopalkrishnan</a>",
          "description": "Can a micron sized sack of interacting molecules autonomously learn an\ninternal model of a complex and fluctuating environment? We draw insights from\ncontrol theory, machine learning theory, chemical reaction network theory, and\nstatistical physics to develop a general architecture whereby a broad class of\nchemical systems can autonomously learn complex distributions. Our construction\ntakes the form of a chemical implementation of machine learning's optimization\nworkhorse: gradient descent on the relative entropy cost function. We show how\nthis method can be applied to optimize any detailed balanced chemical reaction\nnetwork and that the construction is capable of using hidden units to learn\ncomplex distributions. This result is then recast as a form of integral\nfeedback control. Finally, due to our use of an explicit physical model of\nlearning, we are able to derive thermodynamic costs and trade-offs associated\nto this process.",
          "link": "http://arxiv.org/abs/2311.00975",
          "publishedOn": "2023-11-04T00:42:37.655Z",
          "wordCount": null,
          "title": "Autonomous Learning of Generative Models with Chemical Reaction Network Ensembles. (arXiv:2311.00975v1 [q-bio.MN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiarong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Renhong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuxuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Carl Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chunping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>",
          "description": "Pre-training on graph neural networks (GNNs) aims to learn transferable\nknowledge for downstream tasks with unlabeled data, and it has recently become\nan active research area. The success of graph pre-training models is often\nattributed to the massive amount of input data. In this paper, however, we\nidentify the curse of big data phenomenon in graph pre-training: more training\ndata do not necessarily lead to better downstream performance. Motivated by\nthis observation, we propose a better-with-less framework for graph\npre-training: fewer, but carefully chosen data are fed into a GNN model to\nenhance pre-training. The proposed pre-training pipeline is called the\ndata-active graph pre-training (APT) framework, and is composed of a graph\nselector and a pre-training model. The graph selector chooses the most\nrepresentative and instructive data points based on the inherent properties of\ngraphs as well as predictive uncertainty. The proposed predictive uncertainty,\nas feedback from the pre-training model, measures the confidence level of the\nmodel in the data. When fed with the chosen data, on the other hand, the\npre-training model grasps an initial understanding of the new, unseen data, and\nat the same time attempts to remember the knowledge learned from previous data.\nTherefore, the integration and interaction between these two components form a\nunified framework (APT), in which graph pre-training is performed in a\nprogressive and iterative way. Experiment results show that the proposed APT is\nable to obtain an efficient pre-training model with fewer training data and\nbetter downstream performance.",
          "link": "http://arxiv.org/abs/2311.01038",
          "publishedOn": "2023-11-04T00:42:37.655Z",
          "wordCount": null,
          "title": "Better with Less: A Data-Active Perspective on Pre-Training Graph Neural Networks. (arXiv:2311.01038v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01409",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ketenci_M/0/1/0/all/0/1\">Mert Ketenci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perotte_A/0/1/0/all/0/1\">Adler Perotte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhadad_N/0/1/0/all/0/1\">No&#xe9;mie Elhadad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urteaga_I/0/1/0/all/0/1\">I&#xf1;igo Urteaga</a>",
          "description": "We present a novel stochastic variational Gaussian process ($\\mathcal{GP}$)\ninference method, based on a posterior over a learnable set of weighted pseudo\ninput-output points (coresets). Instead of a free-form variational family, the\nproposed coreset-based, variational tempered family for $\\mathcal{GP}$s (CVTGP)\nis defined in terms of the $\\mathcal{GP}$ prior and the data-likelihood; hence,\naccommodating the modeling inductive biases. We derive CVTGP's lower bound for\nthe log-marginal likelihood via marginalization of the proposed posterior over\nlatent $\\mathcal{GP}$ coreset variables, and show it is amenable to stochastic\noptimization. CVTGP reduces the learnable parameter size to $\\mathcal{O}(M)$,\nenjoys numerical stability, and maintains $\\mathcal{O}(M^3)$ time- and\n$\\mathcal{O}(M^2)$ space-complexity, by leveraging a coreset-based tempered\nposterior that, in turn, provides sparse and explainable representations of the\ndata. Results on simulated and real-world regression problems with Gaussian\nobservation noise validate that CVTGP provides better evidence lower-bound\nestimates and predictive root mean squared error than alternative stochastic\n$\\mathcal{GP}$ inference methods.",
          "link": "http://arxiv.org/abs/2311.01409",
          "publishedOn": "2023-11-04T00:42:37.655Z",
          "wordCount": null,
          "title": "A Coreset-based, Tempered Variational Posterior for Accurate and Scalable Stochastic Gaussian Process Inference. (arXiv:2311.01409v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.13018",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Sucholutsky_I/0/1/0/all/0/1\">Ilia Sucholutsky</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Muttenthaler_L/0/1/0/all/0/1\">Lukas Muttenthaler</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Peng_A/0/1/0/all/0/1\">Andi Peng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bobu_A/0/1/0/all/0/1\">Andreea Bobu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kim_B/0/1/0/all/0/1\">Been Kim</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Love_B/0/1/0/all/0/1\">Bradley C. Love</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Grant_E/0/1/0/all/0/1\">Erin Grant</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Groen_I/0/1/0/all/0/1\">Iris Groen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Achterberg_J/0/1/0/all/0/1\">Jascha Achterberg</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Collins_K/0/1/0/all/0/1\">Katherine M. Collins</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hermann_K/0/1/0/all/0/1\">Katherine L. Hermann</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Oktar_K/0/1/0/all/0/1\">Kerem Oktar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Greff_K/0/1/0/all/0/1\">Klaus Greff</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hebart_M/0/1/0/all/0/1\">Martin N. Hebart</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jacoby_N/0/1/0/all/0/1\">Nori Jacoby</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiuyi Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Marjieh_R/0/1/0/all/0/1\">Raja Marjieh</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Geirhos_R/0/1/0/all/0/1\">Robert Geirhos</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1\">Sherol Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kornblith_S/0/1/0/all/0/1\">Simon Kornblith</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Rane_S/0/1/0/all/0/1\">Sunayana Rane</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Konkle_T/0/1/0/all/0/1\">Talia Konkle</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+OConnell_T/0/1/0/all/0/1\">Thomas P. O&#x27;Connell</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Unterthiner_T/0/1/0/all/0/1\">Thomas Unterthiner</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lampinen_A/0/1/0/all/0/1\">Andrew K. Lampinen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Muller_K/0/1/0/all/0/1\">Klaus-Robert M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Toneva_M/0/1/0/all/0/1\">Mariya Toneva</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Griffiths_T/0/1/0/all/0/1\">Thomas L. Griffiths</a>",
          "description": "Biological and artificial information processing systems form representations\nthat they can use to categorize, reason, plan, navigate, and make decisions.\nHow can we measure the extent to which the representations formed by these\ndiverse systems agree? Do similarities in representations then translate into\nsimilar behavior? How can a system's representations be modified to better\nmatch those of another system? These questions pertaining to the study of\nrepresentational alignment are at the heart of some of the most active research\nareas in cognitive science, neuroscience, and machine learning. For example,\ncognitive scientists measure the representational alignment of multiple\nindividuals to identify shared cognitive priors, neuroscientists align fMRI\nresponses from multiple individuals into a shared representational space for\ngroup-level analyses, and ML researchers distill knowledge from teacher models\ninto student models by increasing their alignment. Unfortunately, there is\nlimited knowledge transfer between research communities interested in\nrepresentational alignment, so progress in one field often ends up being\nrediscovered independently in another. Thus, greater cross-field communication\nwould be advantageous. To improve communication between these fields, we\npropose a unifying framework that can serve as a common language between\nresearchers studying representational alignment. We survey the literature from\nall three fields and demonstrate how prior work fits into this framework.\nFinally, we lay out open problems in representational alignment where progress\ncan benefit all three of these fields. We hope that our work can catalyze\ncross-disciplinary collaboration and accelerate progress for all communities\nstudying and developing information processing systems. We note that this is a\nworking paper and encourage readers to reach out with their suggestions for\nfuture revisions.",
          "link": "http://arxiv.org/abs/2310.13018",
          "publishedOn": "2023-11-04T00:42:37.655Z",
          "wordCount": null,
          "title": "Getting aligned on representational alignment. (arXiv:2310.13018v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.18477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yian Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1\">Tingting Mu</a>",
          "description": "The strategy of ensemble has become popular in adversarial defense, which\ntrains multiple base classifiers to defend against adversarial attacks in a\ncooperative manner. Despite the empirical success, theoretical explanations on\nwhy an ensemble of adversarially trained classifiers is more robust than single\nones remain unclear. To fill in this gap, we develop a new error theory\ndedicated to understanding ensemble adversarial defense, demonstrating a\nprovable 0-1 loss reduction on challenging sample sets in an adversarial\ndefense scenario. Guided by this theory, we propose an effective approach to\nimprove ensemble adversarial defense, named interactive global adversarial\ntraining (iGAT). The proposal includes (1) a probabilistic distributing rule\nthat selectively allocates to different base classifiers adversarial examples\nthat are globally challenging to the ensemble, and (2) a regularization term to\nrescue the severest weaknesses of the base classifiers. Being tested over\nvarious existing ensemble adversarial defense techniques, iGAT is capable of\nboosting their performance by increases up to 17% evaluated using CIFAR10 and\nCIFAR100 datasets under both white-box and black-box attacks.",
          "link": "http://arxiv.org/abs/2310.18477",
          "publishedOn": "2023-11-04T00:42:37.655Z",
          "wordCount": null,
          "title": "Understanding and Improving Ensemble Adversarial Defense. (arXiv:2310.18477v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00938",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_N/0/1/0/all/0/1\">Niket Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salamanca_L/0/1/0/all/0/1\">Luis Salamanca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barba_L/0/1/0/all/0/1\">Luis Barba</a>",
          "description": "Diffusion models have emerged as a pivotal advancement in generative models,\nsetting new standards to the quality of the generated instances. In the current\npaper we aim to underscore a discrepancy between conventional training methods\nand the desired conditional sampling behavior of these models. While the\nprevalent classifier-free guidance technique works well, it's not without\nflaws. At higher values for the guidance scale parameter $w$, we often get out\nof distribution samples and mode collapse, whereas at lower values for $w$ we\nmay not get the desired specificity. To address these challenges, we introduce\nan updated loss function that better aligns training objectives with sampling\nbehaviors. Experimental validation with FID scores on CIFAR-10 elucidates our\nmethod's ability to produce higher quality samples with fewer sampling\ntimesteps, and be more robust to the choice of guidance scale $w$. We also\nexperiment with fine-tuning Stable Diffusion on the proposed loss, to provide\nearly evidence that large diffusion models may also benefit from this refined\nloss function.",
          "link": "http://arxiv.org/abs/2311.00938",
          "publishedOn": "2023-11-04T00:42:37.654Z",
          "wordCount": null,
          "title": "Bridging the Gap: Addressing Discrepancies in Diffusion Model Training for Classifier-Free Guidance. (arXiv:2311.00938v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.04366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perrine_P/0/1/0/all/0/1\">Patrick Perrine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirkby_T/0/1/0/all/0/1\">Trevor Kirkby</a>",
          "description": "Digitally synthesizing human motion is an inherently complex process, which\ncan create obstacles in application areas such as virtual reality. We offer a\nnew approach for predicting human motion, KP-RNN, a neural network which can\nintegrate easily with existing image processing and generation pipelines. We\nutilize a new human motion dataset of performance art, Take The Lead, as well\nas the motion generation pipeline, the Everybody Dance Now system, to\ndemonstrate the effectiveness of KP-RNN's motion predictions. We have found\nthat our neural network can predict human dance movements effectively, which\nserves as a baseline result for future works using the Take The Lead dataset.\nSince KP-RNN can work alongside a system such as Everybody Dance Now, we argue\nthat our approach could inspire new methods for rendering human avatar\nanimation. This work also serves to benefit the visualization of performance\nart in digital platforms by utilizing accessible neural networks.",
          "link": "http://arxiv.org/abs/2210.04366",
          "publishedOn": "2023-11-04T00:42:37.654Z",
          "wordCount": null,
          "title": "KP-RNN: A Deep Learning Pipeline for Human Motion Prediction and Synthesis of Performance Art. (arXiv:2210.04366v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.06157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kelshaw_D/0/1/0/all/0/1\">Daniel Kelshaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magri_L/0/1/0/all/0/1\">Luca Magri</a>",
          "description": "Manifolds discovered by machine learning models provide a compact\nrepresentation of the underlying data. Geodesics on these manifolds define\nlocally length-minimising curves and provide a notion of distance, which are\nkey for reduced-order modelling, statistical inference, and interpolation. In\nthis work, we propose a model-based parameterisation for distance fields and\ngeodesic flows on manifolds, exploiting solutions of a manifold-augmented\nEikonal equation. We demonstrate how the geometry of the manifold impacts the\ndistance field, and exploit the geodesic flow to obtain globally\nlength-minimising curves directly. This work opens opportunities for statistics\nand reduced-order modelling on differentiable manifolds.",
          "link": "http://arxiv.org/abs/2310.06157",
          "publishedOn": "2023-11-04T00:42:37.654Z",
          "wordCount": null,
          "title": "Manifold-augmented Eikonal Equations: Geodesic Distances and Flows on Differentiable Manifolds. (arXiv:2310.06157v2 [cs.CG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_X/0/1/0/all/0/1\">Xueying Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_Q/0/1/0/all/0/1\">Quang Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oktavian_G/0/1/0/all/0/1\">Grady Oktavian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_D/0/1/0/all/0/1\">Daniel F. Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergmeir_C/0/1/0/all/0/1\">Christoph Bergmeir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godahewa_R/0/1/0/all/0/1\">Rakshitha Godahewa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong Per Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1\">Kaifeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Condylis_P/0/1/0/all/0/1\">Paul Condylis</a>",
          "description": "The recent M5 competition has advanced the state-of-the-art in retail\nforecasting. However, we notice important differences between the competition\nchallenge and the challenges we face in a large e-commerce company. The\ndatasets in our scenario are larger (hundreds of thousands of time series), and\ne-commerce can afford to have a larger assortment than brick-and-mortar\nretailers, leading to more intermittent data. To scale to larger dataset sizes\nwith feasible computational effort, firstly, we investigate a two-layer\nhierarchy and propose a top-down approach to forecasting at an aggregated level\nwith less amount of series and intermittency, and then disaggregating to obtain\nthe decision-level forecasts. Probabilistic forecasts are generated under\ndistributional assumptions. Secondly, direct training at the lower level with\nsubsamples can also be an alternative way of scaling. Performance of modelling\nwith subsets is evaluated with the main dataset. Apart from a proprietary\ndataset, the proposed scalable methods are evaluated using the Favorita dataset\nand the M5 dataset. We are able to show the differences in characteristics of\nthe e-commerce and brick-and-mortar retail datasets. Notably, our top-down\nforecasting framework enters the top 50 of the original M5 competition, even\nwith models trained at a higher level under a much simpler setting.",
          "link": "http://arxiv.org/abs/2311.00993",
          "publishedOn": "2023-11-04T00:42:37.653Z",
          "wordCount": null,
          "title": "Scalable Probabilistic Forecasting in Retail with Gradient Boosted Trees: A Practitioner's Approach. (arXiv:2311.00993v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07050",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Neklyudov_K/0/1/0/all/0/1\">Kirill Neklyudov</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nys_J/0/1/0/all/0/1\">Jannes Nys</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Thiede_L/0/1/0/all/0/1\">Luca Thiede</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Carrasquilla_J/0/1/0/all/0/1\">Juan Carrasquilla</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Makhzani_A/0/1/0/all/0/1\">Alireza Makhzani</a>",
          "description": "Solving the quantum many-body Schr\\\"odinger equation is a fundamental and\nchallenging problem in the fields of quantum physics, quantum chemistry, and\nmaterial sciences. One of the common computational approaches to this problem\nis Quantum Variational Monte Carlo (QVMC), in which ground-state solutions are\nobtained by minimizing the energy of the system within a restricted family of\nparameterized wave functions. Deep learning methods partially address the\nlimitations of traditional QVMC by representing a rich family of wave functions\nin terms of neural networks. However, the optimization objective in QVMC\nremains notoriously hard to minimize and requires second-order optimization\nmethods such as natural gradient. In this paper, we first reformulate energy\nfunctional minimization in the space of Born distributions corresponding to\nparticle-permutation (anti-)symmetric wave functions, rather than the space of\nwave functions. We then interpret QVMC as the Fisher-Rao gradient flow in this\ndistributional space, followed by a projection step onto the variational\nmanifold. This perspective provides us with a principled framework to derive\nnew QMC algorithms, by endowing the distributional space with better metrics,\nand following the projected gradient flow induced by those metrics. More\nspecifically, we propose \"Wasserstein Quantum Monte Carlo\" (WQMC), which uses\nthe gradient flow induced by the Wasserstein metric, rather than Fisher-Rao\nmetric, and corresponds to transporting the probability mass, rather than\nteleporting it. We demonstrate empirically that the dynamics of WQMC results in\nfaster convergence to the ground state of molecular systems.",
          "link": "http://arxiv.org/abs/2307.07050",
          "publishedOn": "2023-11-04T00:42:37.653Z",
          "wordCount": null,
          "title": "Wasserstein Quantum Monte Carlo: A Novel Approach for Solving the Quantum Many-Body Schr\\\"odinger Equation. (arXiv:2307.07050v3 [physics.comp-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gretta_L/0/1/0/all/0/1\">Lucas Gretta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Price_E/0/1/0/all/0/1\">Eric Price</a>",
          "description": "We revisit the noisy binary search model of Karp and Kleinberg, in which we\nhave $n$ coins with unknown probabilities $p_i$ that we can flip. The coins are\nsorted by increasing $p_i$, and we would like to find where the probability\ncrosses (to within $\\varepsilon$) of a target value $\\tau$. This generalized\nthe fixed-noise model of Burnashev and Zigangirov , in which $p_i = \\frac{1}{2}\n\\pm \\varepsilon$, to a setting where coins near the target may be\nindistinguishable from it. Karp and Kleinberg showed that\n$\\Theta(\\frac{1}{\\varepsilon^2} \\log n)$ samples are necessary and sufficient\nfor this task.\n\nWe produce a practical algorithm by solving two theoretical challenges:\nhigh-probability behavior and sharp constants. We give an algorithm that\nsucceeds with probability $1-\\delta$ from\n\n\\[\n\n\\frac{1}{C_{\\tau, \\varepsilon}} \\cdot \\left(\\lg n + O(\\log^{2/3} n \\log^{1/3}\n\\frac{1}{\\delta} + \\log \\frac{1}{\\delta})\\right)\n\n\\]\n\nsamples, where $C_{\\tau, \\varepsilon}$ is the optimal such constant\nachievable. For $\\delta > n^{-o(1)}$ this is within $1 + o(1)$ of optimal, and\nfor $\\delta \\ll 1$ it is the first bound within constant factors of optimal.",
          "link": "http://arxiv.org/abs/2311.00840",
          "publishedOn": "2023-11-04T00:42:37.622Z",
          "wordCount": null,
          "title": "Sharp Noisy Binary Search with Monotonic Probabilities. (arXiv:2311.00840v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.07897",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Struski_L/0/1/0/all/0/1\">&#x141;ukasz Struski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Knop_S/0/1/0/all/0/1\">Szymon Knop</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tabor_J/0/1/0/all/0/1\">Jacek Tabor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Daniec_W/0/1/0/all/0/1\">Wiktor Daniec</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Spurek_P/0/1/0/all/0/1\">Przemys&#x142;aw Spurek</a>",
          "description": "In the paper we construct a fully convolutional GAN model: LocoGAN, which\nlatent space is given by noise-like images of possibly different resolutions.\nThe learning is local, i.e. we process not the whole noise-like image, but the\nsub-images of a fixed size. As a consequence LocoGAN can produce images of\narbitrary dimensions e.g. LSUN bedroom data set. Another advantage of our\napproach comes from the fact that we use the position channels, which allows\nthe generation of fully periodic (e.g. cylindrical panoramic images) or almost\nperiodic ,,infinitely long\" images (e.g. wall-papers).",
          "link": "http://arxiv.org/abs/2002.07897",
          "publishedOn": "2023-11-04T00:42:37.612Z",
          "wordCount": null,
          "title": "LocoGAN -- Locally Convolutional GAN. (arXiv:2002.07897v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.01267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Haimin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zixu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakamura_K/0/1/0/all/0/1\">Kensuke Nakamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bajcsy_A/0/1/0/all/0/1\">Andrea Bajcsy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisac_J/0/1/0/all/0/1\">Jaime F. Fisac</a>",
          "description": "An outstanding challenge for the widespread deployment of robotic systems\nlike autonomous vehicles is ensuring safe interaction with humans without\nsacrificing performance. Existing safety methods often neglect the robot's\nability to learn and adapt at runtime, leading to overly conservative behavior.\nThis paper proposes a new closed-loop paradigm for synthesizing safe control\npolicies that explicitly account for the robot's evolving uncertainty and its\nability to quickly respond to future scenarios as they arise, by jointly\nconsidering the physical dynamics and the robot's learning algorithm. We\nleverage adversarial reinforcement learning for tractable safety analysis under\nhigh-dimensional learning dynamics and demonstrate our framework's ability to\nwork with both Bayesian belief propagation and implicit learning through large\npre-trained neural trajectory predictors.",
          "link": "http://arxiv.org/abs/2309.01267",
          "publishedOn": "2023-11-04T00:42:37.608Z",
          "wordCount": null,
          "title": "Deception Game: Closing the Safety-Learning Loop in Interactive Robot Autonomy. (arXiv:2309.01267v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.10649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oostrum_J/0/1/0/all/0/1\">Jesse van Oostrum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hintum_P/0/1/0/all/0/1\">Peter van Hintum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ay_N/0/1/0/all/0/1\">Nihat Ay</a>",
          "description": "Variational autoencoders and Helmholtz machines use a recognition network\n(encoder) to approximate the posterior distribution of a generative model\n(decoder). In this paper we study the necessary and sufficient properties of a\nrecognition network so that it can model the true posterior distribution\nexactly. These results are derived in the general context of probabilistic\ngraphical modelling / Bayesian networks, for which the network represents a set\nof conditional independence statements. We derive both global conditions, in\nterms of d-separation, and local conditions for the recognition network to have\nthe desired qualities. It turns out that for the local conditions the property\nperfectness (for every node, all parents are joined) plays an important role.",
          "link": "http://arxiv.org/abs/2212.10649",
          "publishedOn": "2023-11-04T00:42:37.595Z",
          "wordCount": null,
          "title": "Inversion of Bayesian Networks. (arXiv:2212.10649v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07962",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dauner_D/0/1/0/all/0/1\">Daniel Dauner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hallgarten_M/0/1/0/all/0/1\">Marcel Hallgarten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1\">Andreas Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chitta_K/0/1/0/all/0/1\">Kashyap Chitta</a>",
          "description": "The release of nuPlan marks a new era in vehicle motion planning research,\noffering the first large-scale real-world dataset and evaluation schemes\nrequiring both precise short-term planning and long-horizon ego-forecasting.\nExisting systems struggle to simultaneously meet both requirements. Indeed, we\nfind that these tasks are fundamentally misaligned and should be addressed\nindependently. We further assess the current state of closed-loop planning in\nthe field, revealing the limitations of learning-based methods in complex\nreal-world scenarios and the value of simple rule-based priors such as\ncenterline selection through lane graph search algorithms. More surprisingly,\nfor the open-loop sub-task, we observe that the best results are achieved when\nusing only this centerline as scene context (i.e., ignoring all information\nregarding the map and other agents). Combining these insights, we propose an\nextremely simple and efficient planner which outperforms an extensive set of\ncompetitors, winning the nuPlan planning challenge 2023.",
          "link": "http://arxiv.org/abs/2306.07962",
          "publishedOn": "2023-11-04T00:42:37.595Z",
          "wordCount": null,
          "title": "Parting with Misconceptions about Learning-based Vehicle Motion Planning. (arXiv:2306.07962v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.07843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuangning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niell_L/0/1/0/all/0/1\">Lluis Salvat Niell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Sung Won Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nahum_Shani_I/0/1/0/all/0/1\">Inbal Nahum-Shani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shani_G/0/1/0/all/0/1\">Guy Shani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_S/0/1/0/all/0/1\">Susan Murphy</a>",
          "description": "Mobile health aims to enhance health outcomes by delivering interventions to\nindividuals as they go about their daily life. The involvement of care partners\nand social support networks often proves crucial in helping individuals\nmanaging burdensome medical conditions. This presents opportunities in mobile\nhealth to design interventions that target the dyadic relationship -- the\nrelationship between a target person and their care partner -- with the aim of\nenhancing social support. In this paper, we develop dyadic RL, an online\nreinforcement learning algorithm designed to personalize intervention delivery\nbased on contextual factors and past responses of a target person and their\ncare partner. Here, multiple sets of interventions impact the dyad across\nmultiple time intervals. The developed dyadic RL is Bayesian and hierarchical.\nWe formally introduce the problem setup, develop dyadic RL and establish a\nregret bound. We demonstrate dyadic RL's empirical performance through\nsimulation studies on both toy scenarios and on a realistic test bed\nconstructed from data collected in a mobile health study.",
          "link": "http://arxiv.org/abs/2308.07843",
          "publishedOn": "2023-11-04T00:42:37.593Z",
          "wordCount": null,
          "title": "Dyadic Reinforcement Learning. (arXiv:2308.07843v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01404",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Scagliotti_A/0/1/0/all/0/1\">Alessandro Scagliotti</a>, <a href=\"http://arxiv.org/find/math/1/au:+Farinelli_S/0/1/0/all/0/1\">Sara Farinelli</a>",
          "description": "The term \"Normalizing Flows\" is related to the task of constructing\ninvertible transport maps between probability measures by means of deep neural\nnetworks. In this paper, we consider the problem of recovering the\n$W_2$-optimal transport map $T$ between absolutely continuous measures\n$\\mu,\\nu\\in\\mathcal{P}(\\mathbb{R}^n)$ as the flow of a linear-control neural\nODE. We first show that, under suitable assumptions on $\\mu,\\nu$ and on the\ncontrolled vector fields, the optimal transport map is contained in the\n$C^0_c$-closure of the flows generated by the system. Assuming that discrete\napproximations $\\mu_N,\\nu_N$ of the original measures $\\mu,\\nu$ are available,\nwe use a discrete optimal coupling $\\gamma_N$ to define an optimal control\nproblem. With a $\\Gamma$-convergence argument, we prove that its solutions\ncorrespond to flows that approximate the optimal transport map $T$. Finally,\ntaking advantage of the Pontryagin Maximum Principle, we propose an iterative\nnumerical scheme for the resolution of the optimal control problem, resulting\nin an algorithm for the practical computation of the approximated optimal\ntransport map.",
          "link": "http://arxiv.org/abs/2311.01404",
          "publishedOn": "2023-11-04T00:42:37.591Z",
          "wordCount": null,
          "title": "Normalizing flows as approximations of optimal transport maps via linear-control neural ODEs. (arXiv:2311.01404v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Evangelou_N/0/1/0/all/0/1\">Nikolaos Evangelou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_T/0/1/0/all/0/1\">Tianqi Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bello_Rivas_J/0/1/0/all/0/1\">Juan M. Bello-Rivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makeev_A/0/1/0/all/0/1\">Alexei Makeev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kevrekidis_I/0/1/0/all/0/1\">Ioannis G. Kevrekidis</a>",
          "description": "We study the tipping point collective dynamics of an adaptive\nsusceptible-infected-susceptible (SIS) epidemiological network in a\ndata-driven, machine learning-assisted manner. We identify a\nparameter-dependent effective stochastic differential equation (eSDE) in terms\nof physically meaningful coarse mean-field variables through a deep-learning\nResNet architecture inspired by numerical stochastic integrators. We construct\nan approximate effective bifurcation diagram based on the identified drift term\nof the eSDE and contrast it with the mean-field SIS model bifurcation diagram.\nWe observe a subcritical Hopf bifurcation in the evolving network's effective\nSIS dynamics, that causes the tipping point behavior; this takes the form of\nlarge amplitude collective oscillations that spontaneously -- yet rarely --\narise from the neighborhood of a (noisy) stationary state. We study the\nstatistics of these rare events both through repeated brute force simulations\nand by using established mathematical/computational tools exploiting the\nright-hand-side of the identified SDE. We demonstrate that such a collective\nSDE can also be identified (and the rare events computations also performed) in\nterms of data-driven coarse observables, obtained here via manifold learning\ntechniques, in particular Diffusion Maps. The workflow of our study is\nstraightforwardly applicable to other complex dynamics problems exhibiting\ntipping point dynamics.",
          "link": "http://arxiv.org/abs/2311.00797",
          "publishedOn": "2023-11-04T00:42:37.590Z",
          "wordCount": null,
          "title": "Tipping Points of Evolving Epidemiological Networks: Machine Learning-Assisted, Data-Driven Effective Modeling. (arXiv:2311.00797v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mozannar_H/0/1/0/all/0/1\">Hussein Mozannar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jimin J Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Dennis Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1\">Prasanna Sattigeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Subhro Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1\">David Sontag</a>",
          "description": "People are relying on AI agents to assist them with various tasks. The human\nmust know when to rely on the agent, collaborate with the agent, or ignore its\nsuggestions. In this work, we propose to learn rules grounded in data regions\nand described in natural language that illustrate how the human should\ncollaborate with the AI. Our novel region discovery algorithm finds local\nregions in the data as neighborhoods in an embedding space that corrects the\nhuman prior. Each region is then described using an iterative and contrastive\nprocedure where a large language model describes the region. We then teach\nthese rules to the human via an onboarding stage. Through user studies on\nobject detection and question-answering tasks, we show that our method can lead\nto more accurate human-AI teams. We also evaluate our region discovery and\ndescription algorithms separately.",
          "link": "http://arxiv.org/abs/2311.01007",
          "publishedOn": "2023-11-04T00:42:37.590Z",
          "wordCount": null,
          "title": "Effective Human-AI Teams via Learned Natural Language Rules and Onboarding. (arXiv:2311.01007v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Margolis_G/0/1/0/all/0/1\">Gabriel B. Margolis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xiang Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yandong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Pulkit Agrawal</a>",
          "description": "Knowledge of terrain's physical properties inferred from color images can aid\nin making efficient robotic locomotion plans. However, unlike image\nclassification, it is unintuitive for humans to label image patches with\nphysical properties. Without labeled data, building a vision system that takes\nas input the observed terrain and predicts physical properties remains\nchallenging. We present a method that overcomes this challenge by\nself-supervised labeling of images captured by robots during real-world\ntraversal with physical property estimators trained in simulation. To ensure\naccurate labeling, we introduce Active Sensing Motor Policies (ASMP), which are\ntrained to explore locomotion behaviors that increase the accuracy of\nestimating physical parameters. For instance, the quadruped robot learns to\nswipe its foot against the ground to estimate the friction coefficient\naccurately. We show that the visual system trained with a small amount of\nreal-world traversal data accurately predicts physical parameters. The trained\nsystem is robust and works even with overhead images captured by a drone\ndespite being trained on data collected by cameras attached to a quadruped\nrobot walking on the ground.",
          "link": "http://arxiv.org/abs/2311.01405",
          "publishedOn": "2023-11-04T00:42:37.589Z",
          "wordCount": null,
          "title": "Learning to See Physical Properties with Active Sensing Motor Policies. (arXiv:2311.01405v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.15092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jati_A/0/1/0/all/0/1\">Arindam Jati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ekambaram_V/0/1/0/all/0/1\">Vijay Ekambaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1\">Shaonli Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quanz_B/0/1/0/all/0/1\">Brian Quanz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gifford_W/0/1/0/all/0/1\">Wesley M. Gifford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harsha_P/0/1/0/all/0/1\">Pavithra Harsha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siegel_S/0/1/0/all/0/1\">Stuart Siegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Sumanta Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanaswami_C/0/1/0/all/0/1\">Chandra Narayanaswami</a>",
          "description": "Selecting the right set of hyperparameters is crucial in time series\nforecasting. The classical temporal cross-validation framework for\nhyperparameter optimization (HPO) often leads to poor test performance because\nof a possible mismatch between validation and test periods. To address this\ntest-validation mismatch, we propose a novel technique, H-Pro to drive HPO via\ntest proxies by exploiting data hierarchies often associated with time series\ndatasets. Since higher-level aggregated time series often show less\nirregularity and better predictability as compared to the lowest-level time\nseries which can be sparse and intermittent, we optimize the hyperparameters of\nthe lowest-level base-forecaster by leveraging the proxy forecasts for the test\nperiod generated from the forecasters at higher levels. H-Pro can be applied on\nany off-the-shelf machine learning model to perform HPO. We validate the\nefficacy of our technique with extensive empirical evaluation on five publicly\navailable hierarchical forecasting datasets. Our approach outperforms existing\nstate-of-the-art methods in Tourism, Wiki, and Traffic datasets, and achieves\ncompetitive result in Tourism-L dataset, without any model-specific\nenhancements. Moreover, our method outperforms the winning method of the M5\nforecast accuracy competition.",
          "link": "http://arxiv.org/abs/2211.15092",
          "publishedOn": "2023-11-04T00:42:37.589Z",
          "wordCount": null,
          "title": "Hierarchical Proxy Modeling for Improved HPO in Time Series Forecasting. (arXiv:2211.15092v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.17760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guohao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hammoud_H/0/1/0/all/0/1\">Hasan Abed Al Kader Hammoud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Itani_H/0/1/0/all/0/1\">Hani Itani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khizbullin_D/0/1/0/all/0/1\">Dmitrii Khizbullin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>",
          "description": "The rapid advancement of chat-based language models has led to remarkable\nprogress in complex task-solving. However, their success heavily relies on\nhuman input to guide the conversation, which can be challenging and\ntime-consuming. This paper explores the potential of building scalable\ntechniques to facilitate autonomous cooperation among communicative agents, and\nprovides insight into their \"cognitive\" processes. To address the challenges of\nachieving autonomous cooperation, we propose a novel communicative agent\nframework named role-playing. Our approach involves using inception prompting\nto guide chat agents toward task completion while maintaining consistency with\nhuman intentions. We showcase how role-playing can be used to generate\nconversational data for studying the behaviors and capabilities of a society of\nagents, providing a valuable resource for investigating conversational language\nmodels. In particular, we conduct comprehensive studies on\ninstruction-following cooperation in multi-agent settings. Our contributions\ninclude introducing a novel communicative agent framework, offering a scalable\napproach for studying the cooperative behaviors and capabilities of multi-agent\nsystems, and open-sourcing our library to support research on communicative\nagents and beyond: https://github.com/camel-ai/camel.",
          "link": "http://arxiv.org/abs/2303.17760",
          "publishedOn": "2023-11-04T00:42:37.589Z",
          "wordCount": null,
          "title": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society. (arXiv:2303.17760v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00286",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xudong Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>",
          "description": "In this paper, we present JADE, a targeted linguistic fuzzing platform which\nstrengthens the linguistic complexity of seed questions to simultaneously and\nconsistently break a wide range of widely-used LLMs categorized in three\ngroups: eight open-sourced Chinese, six commercial Chinese and four commercial\nEnglish LLMs. JADE generates three safety benchmarks for the three groups of\nLLMs, which contain unsafe questions that are highly threatening: the questions\nsimultaneously trigger harmful generation of multiple LLMs, with an average\nunsafe generation ratio of $70\\%$ (please see the table below), while are still\nnatural questions, fluent and preserving the core unsafe semantics. We release\nthe benchmark demos generated for commercial English LLMs and open-sourced\nEnglish LLMs in the following link: https://github.com/whitzard-ai/jade-db. For\nreaders who are interested in evaluating on more questions generated by JADE,\nplease contact us.\n\nJADE is based on Noam Chomsky's seminal theory of transformational-generative\ngrammar. Given a seed question with unsafe intention, JADE invokes a sequence\nof generative and transformational rules to increment the complexity of the\nsyntactic structure of the original question, until the safety guardrail is\nbroken. Our key insight is: Due to the complexity of human language, most of\nthe current best LLMs can hardly recognize the invariant evil from the infinite\nnumber of different syntactic structures which form an unbound example space\nthat can never be fully covered. Technically, the generative/transformative\nrules are constructed by native speakers of the languages, and, once developed,\ncan be used to automatically grow and transform the parse tree of a given\nquestion, until the guardrail is broken. For more evaluation results and demo,\nplease check our website: https://whitzard-ai.github.io/jade.html.",
          "link": "http://arxiv.org/abs/2311.00286",
          "publishedOn": "2023-11-04T00:42:37.588Z",
          "wordCount": null,
          "title": "JADE: A Linguistics-based Safety Evaluation Platform for LLM. (arXiv:2311.00286v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00727",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alwis_B/0/1/0/all/0/1\">Benji Alwis</a>",
          "description": "Over the past decade, the field of machine learning has experienced\nremarkable advancements. While image recognition systems have achieved\nimpressive levels of accuracy, they continue to rely on extensive training\ndatasets. Additionally, a significant challenge has emerged in the form of poor\nout-of-distribution performance, which necessitates retraining neural networks\nwhen they encounter conditions that deviate from their training data. This\nlimitation has notably contributed to the slow progress in self-driving car\ntechnology. These pressing issues have sparked considerable interest in methods\nthat enable neural networks to learn effectively from limited data. This paper\npresents the outcomes of an extensive investigation designed to compare two\ndistinct approaches, transfer learning and meta learning, as potential\nsolutions to this problem. The overarching objective was to establish a robust\ncriterion for selecting the most suitable method in diverse machine learning\nscenarios. Building upon prior research, I expanded the comparative analysis by\nintroducing a new meta learning method into the investigation. Subsequently, I\nassessed whether the findings remained consistent under varying conditions.\nFinally, I delved into the impact of altering the size of the training dataset\non the relative performance of these methods. This comprehensive exploration\nhas yielded insights into the conditions favoring each approach, thereby\nfacilitating the development of a criterion for selecting the most appropriate\nmethod in any given situation",
          "link": "http://arxiv.org/abs/2311.00727",
          "publishedOn": "2023-11-04T00:42:37.587Z",
          "wordCount": null,
          "title": "Investigating Relative Performance of Transfer and Meta Learning. (arXiv:2311.00727v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00774",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diamant_N/0/1/0/all/0/1\">Nathaniel Diamant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajiramezanali_E/0/1/0/all/0/1\">Ehsan Hajiramezanali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biancalani_T/0/1/0/all/0/1\">Tommaso Biancalani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scalia_G/0/1/0/all/0/1\">Gabriele Scalia</a>",
          "description": "Uncertainty estimation is critical in high-stakes machine learning\napplications. One effective way to estimate uncertainty is conformal\nprediction, which can provide predictive inference with statistical coverage\nguarantees. We present a new conformal regression method, Spline Prediction\nIntervals via Conformal Estimation (SPICE), that estimates the conditional\ndensity using neural-network-parameterized splines. We prove universal\napproximation and optimality results for SPICE, which are empirically validated\nby our experiments. SPICE is compatible with two different efficient-to-compute\nconformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the\nother asymptotically optimal for conditional coverage (SPICE-HPD). Results on\nbenchmark datasets demonstrate SPICE-ND models achieve the smallest average\nprediction set sizes, including average size reductions of nearly 50% for some\ndatasets compared to the next best baseline. SPICE-HPD models achieve the best\nconditional coverage compared to baselines. The SPICE implementation is made\navailable.",
          "link": "http://arxiv.org/abs/2311.00774",
          "publishedOn": "2023-11-04T00:42:37.587Z",
          "wordCount": null,
          "title": "Conformalized Deep Splines for Optimal and Efficient Prediction Sets. (arXiv:2311.00774v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00802",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_S/0/1/0/all/0/1\">Shangjie Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shuo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kachana_P/0/1/0/all/0/1\">Pujith Kachana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Danfei Xu</a>",
          "description": "We present a learning-based dynamics model for granular material\nmanipulation. Inspired by the Eulerian approach commonly used in fluid\ndynamics, our method adopts a fully convolutional neural network that operates\non a density field-based representation of object piles and pushers, allowing\nit to exploit the spatial locality of inter-object interactions as well as the\ntranslation equivariance through convolution operations. Furthermore, our\ndifferentiable action rendering module makes the model fully differentiable and\ncan be directly integrated with a gradient-based trajectory optimization\nalgorithm. We evaluate our model with a wide array of piles manipulation tasks\nboth in simulation and real-world experiments and demonstrate that it\nsignificantly exceeds existing latent or particle-based methods in both\naccuracy and computation efficiency, and exhibits zero-shot generalization\ncapabilities across various environments and tasks.",
          "link": "http://arxiv.org/abs/2311.00802",
          "publishedOn": "2023-11-04T00:42:37.586Z",
          "wordCount": null,
          "title": "Neural Field Dynamics Model for Granular Object Piles Manipulation. (arXiv:2311.00802v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Borui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_B/0/1/0/all/0/1\">Baotong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wenzhao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiwen Lu</a>",
          "description": "Shapley values have emerged as a widely accepted and trustworthy tool,\ngrounded in theoretical axioms, for addressing challenges posed by black-box\nmodels like deep neural networks. However, computing Shapley values encounters\nexponential complexity in the number of features. Various approaches, including\nApproSemivalue, KernelSHAP, and FastSHAP, have been explored to expedite the\ncomputation. We analyze the consistency of existing works and conclude that\nstochastic estimators can be unified as the linear transformation of importance\nsampling of feature subsets. Based on this, we investigate the possibility of\ndesigning simple amortized estimators and propose a straightforward and\nefficient one, SimSHAP, by eliminating redundant techniques. Extensive\nexperiments conducted on tabular and image datasets validate the effectiveness\nof our SimSHAP, which significantly accelerates the computation of accurate\nShapley values.",
          "link": "http://arxiv.org/abs/2311.01010",
          "publishedOn": "2023-11-04T00:42:37.586Z",
          "wordCount": null,
          "title": "Exploring Unified Perspective For Fast Shapley Value Estimation. (arXiv:2311.01010v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shomer_H/0/1/0/all/0/1\">Harry Shomer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanhui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bo Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1\">Charu C. Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>",
          "description": "Knowledge graph completion (KGC) aims to predict unseen edges in knowledge\ngraphs (KGs), resulting in the discovery of new facts. A new class of methods\nhave been proposed to tackle this problem by aggregating path information.\nThese methods have shown tremendous ability in the task of KGC. However they\nare plagued by efficiency issues. Though there are a few recent attempts to\naddress this through learnable path pruning, they often sacrifice the\nperformance to gain efficiency. In this work, we identify two intrinsic\nlimitations of these methods that affect the efficiency and representation\nquality. To address the limitations, we introduce a new method, TAGNet, which\nis able to efficiently propagate information. This is achieved by only\naggregating paths in a fixed window for each source-target pair. We demonstrate\nthat the complexity of TAGNet is independent of the number of layers. Extensive\nexperiments demonstrate that TAGNet can cut down on the number of propagated\nmessages by as much as 90% while achieving competitive performance on multiple\nKG datasets. The code is available at https://github.com/HarryShomer/TAGNet.",
          "link": "http://arxiv.org/abs/2311.01024",
          "publishedOn": "2023-11-04T00:42:37.586Z",
          "wordCount": null,
          "title": "Distance-Based Propagation for Efficient Knowledge Graph Reasoning. (arXiv:2311.01024v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00787",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Ward_L/0/1/0/all/0/1\">Logan Ward</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Blaiszik_B/0/1/0/all/0/1\">Ben Blaiszik</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Lee_C/0/1/0/all/0/1\">Cheng-Wei Lee</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Martin_T/0/1/0/all/0/1\">Troy Martin</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Foster_I/0/1/0/all/0/1\">Ian Foster</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Schleife_A/0/1/0/all/0/1\">Andr&#xe9; Schleife</a>",
          "description": "Knowing the rate at which particle radiation releases energy in a material,\nthe stopping power, is key to designing nuclear reactors, medical treatments,\nsemiconductor and quantum materials, and many other technologies. While the\nnuclear contribution to stopping power, i.e., elastic scattering between atoms,\nis well understood in the literature, the route for gathering data on the\nelectronic contribution has for decades remained costly and reliant on many\nsimplifying assumptions, including that materials are isotropic. We establish a\nmethod that combines time-dependent density functional theory (TDDFT) and\nmachine learning to reduce the time to assess new materials to mere hours on a\nsupercomputer and provides valuable data on how atomic details influence\nelectronic stopping. Our approach uses TDDFT to compute the electronic stopping\ncontributions to stopping power from first principles in several directions and\nthen machine learning to interpolate to other directions at rates 10 million\ntimes higher. We demonstrate the combined approach in a study of proton\nirradiation in aluminum and employ it to predict how the depth of maximum\nenergy deposition, the \"Bragg Peak,\" varies depending on incident angle -- a\nquantity otherwise inaccessible to modelers. The lack of any experimental\ninformation requirement makes our method applicable to most materials, and its\nspeed makes it a prime candidate for enabling quantum-to-continuum models of\nradiation damage. The prospect of reusing valuable TDDFT data for training the\nmodel make our approach appealing for applications in the age of materials data\nscience.",
          "link": "http://arxiv.org/abs/2311.00787",
          "publishedOn": "2023-11-04T00:42:37.585Z",
          "wordCount": null,
          "title": "Accelerating Electronic Stopping Power Predictions by 10 Million Times with a Combination of Time-Dependent Density Functional Theory and Machine Learning. (arXiv:2311.00787v1 [cond-mat.mtrl-sci])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xingjian Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coester_C/0/1/0/all/0/1\">Christian Coester</a>",
          "description": "We explore the fundamental problem of sorting through the lens of\nlearning-augmented algorithms, where algorithms can leverage possibly erroneous\npredictions to improve their efficiency. We consider two different settings: In\nthe first setting, each item is provided a prediction of its position in the\nsorted list. In the second setting, we assume there is a \"quick-and-dirty\" way\nof comparing items, in addition to slow-and-exact comparisons. For both\nsettings, we design new and simple algorithms using only $O(\\sum_i \\log\n\\eta_i)$ exact comparisons, where $\\eta_i$ is a suitably defined prediction\nerror for the $i$th element. In particular, as the quality of predictions\ndeteriorates, the number of comparisons degrades smoothly from $O(n)$ to\n$O(n\\log n)$. We prove that the comparison complexity is theoretically optimal\nwith respect to the examined error measures. An experimental evaluation against\nexisting adaptive and non-adaptive sorting algorithms demonstrates the\npotential of applying learning-augmented algorithms in sorting tasks.",
          "link": "http://arxiv.org/abs/2311.00749",
          "publishedOn": "2023-11-04T00:42:37.583Z",
          "wordCount": null,
          "title": "Sorting with Predictions. (arXiv:2311.00749v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Tongtong Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1\">Nan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Distribution shift (DS) may have two levels: the distribution itself changes,\nand the support (i.e., the set where the probability density is non-zero) also\nchanges. When considering the support change between the training and test\ndistributions, there can be four cases: (i) they exactly match; (ii) the\ntraining support is wider (and thus covers the test support); (iii) the test\nsupport is wider; (iv) they partially overlap. Existing methods are good at\ncases (i) and (ii), while cases (iii) and (iv) are more common nowadays but\nstill under-explored. In this paper, we generalize importance weighting (IW), a\ngolden solver for cases (i) and (ii), to a universal solver for all cases.\nSpecifically, we first investigate why IW might fail in cases (iii) and (iv);\nbased on the findings, we propose generalized IW (GIW) that could handle cases\n(iii) and (iv) and would reduce to IW in cases (i) and (ii). In GIW, the test\nsupport is split into an in-training (IT) part and an out-of-training (OOT)\npart, and the expected risk is decomposed into a weighted classification term\nover the IT part and a standard classification term over the OOT part, which\nguarantees the risk consistency of GIW. Then, the implementation of GIW\nconsists of three components: (a) the split of validation data is carried out\nby the one-class support vector machine, (b) the first term of the empirical\nrisk can be handled by any IW algorithm given training data and IT validation\ndata, and (c) the second term just involves OOT validation data. Experiments\ndemonstrate that GIW is a universal solver for DS problems, outperforming IW\nmethods in cases (iii) and (iv).",
          "link": "http://arxiv.org/abs/2305.14690",
          "publishedOn": "2023-11-04T00:42:37.583Z",
          "wordCount": null,
          "title": "Generalizing Importance Weighting to A Universal Solver for Distribution Shift Problems. (arXiv:2305.14690v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00902",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_J/0/1/0/all/0/1\">Jinchao Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kulick_C/0/1/0/all/0/1\">Charles Kulick</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tang_S/0/1/0/all/0/1\">Sui Tang</a>",
          "description": "In this paper, we focus on the data-driven discovery of a general\nsecond-order particle-based model that contains many state-of-the-art models\nfor modeling the aggregation and collective behavior of interacting agents of\nsimilar size and body type. This model takes the form of a high-dimensional\nsystem of ordinary differential equations parameterized by two interaction\nkernels that appraise the alignment of positions and velocities. We propose a\nGaussian Process-based approach to this problem, where the unknown model\nparameters are marginalized by using two independent Gaussian Process (GP)\npriors on latent interaction kernels constrained to dynamics and observational\ndata. This results in a nonparametric model for interacting dynamical systems\nthat accounts for uncertainty quantification. We also develop acceleration\ntechniques to improve scalability. Moreover, we perform a theoretical analysis\nto interpret the methodology and investigate the conditions under which the\nkernels can be recovered. We demonstrate the effectiveness of the proposed\napproach on various prototype systems, including the selection of the order of\nthe systems and the types of interactions. In particular, we present\napplications to modeling two real-world fish motion datasets that display\nflocking and milling patterns up to 248 dimensions. Despite the use of small\ndata sets, the GP-based approach learns an effective representation of the\nnonlinear dynamics in these spaces and outperforms competitor methods.",
          "link": "http://arxiv.org/abs/2311.00902",
          "publishedOn": "2023-11-04T00:42:37.582Z",
          "wordCount": null,
          "title": "Data-Driven Model Selections of Second-Order Particle Dynamics via Integrating Gaussian Processes with Low-Dimensional Interacting Structures. (arXiv:2311.00902v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1\">Siming Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1\">Qi Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiaming Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shaohui Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yunkai Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Ruizhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1\">Zidong Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xishan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Ling Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunji Chen</a>",
          "description": "In the field of multi-task reinforcement learning, the modular principle,\nwhich involves specializing functionalities into different modules and\ncombining them appropriately, has been widely adopted as a promising approach\nto prevent the negative transfer problem that performance degradation due to\nconflicts between tasks. However, most of the existing multi-task RL methods\nonly combine shared modules at the task level, ignoring that there may be\nconflicts within the task. In addition, these methods do not take into account\nthat without constraints, some modules may learn similar functions, resulting\nin restricting the model's expressiveness and generalization capability of\nmodular methods. In this paper, we propose the Contrastive Modules with\nTemporal Attention(CMTA) method to address these limitations. CMTA constrains\nthe modules to be different from each other by contrastive learning and\ncombining shared modules at a finer granularity than the task level with\ntemporal attention, alleviating the negative transfer within the task and\nimproving the generalization ability and the performance for multi-task RL. We\nconducted the experiment on Meta-World, a multi-task RL benchmark containing\nvarious robotics manipulation tasks. Experimental results show that CMTA\noutperforms learning each task individually for the first time and achieves\nsubstantial performance improvements over the baselines.",
          "link": "http://arxiv.org/abs/2311.01075",
          "publishedOn": "2023-11-04T00:42:37.582Z",
          "wordCount": null,
          "title": "Contrastive Modules with Temporal Attention for Multi-Task Reinforcement Learning. (arXiv:2311.01075v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xinyuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1\">Santosh S. Vempala</a>",
          "description": "We give a polynomial-time algorithm for learning high-dimensional halfspaces\nwith margins in $d$-dimensional space to within desired TV distance when the\nambient distribution is an unknown affine transformation of the $d$-fold\nproduct of an (unknown) symmetric one-dimensional logconcave distribution, and\nthe halfspace is introduced by deleting at least an $\\epsilon$ fraction of the\ndata in one of the component distributions. Notably, our algorithm does not\nneed labels and establishes the unique (and efficient) identifiability of the\nhidden halfspace under this distributional assumption. The sample and time\ncomplexity of the algorithm are polynomial in the dimension and $1/\\epsilon$.\nThe algorithm uses only the first two moments of suitable re-weightings of the\nempirical distribution, which we call contrastive moments; its analysis uses\nclassical facts about generalized Dirichlet polynomials and relies crucially on\na new monotonicity property of the moment ratio of truncations of logconcave\ndistributions. Such algorithms, based only on first and second moments were\nsuggested in earlier work, but hitherto eluded rigorous guarantees.\n\nPrior work addressed the special case when the underlying distribution is\nGaussian via Non-Gaussian Component Analysis. We improve on this by providing\npolytime guarantees based on Total Variation (TV) distance, in place of\nexisting moment-bound guarantees that can be super-polynomial. Our work is also\nthe first to go beyond Gaussians in this setting.",
          "link": "http://arxiv.org/abs/2311.01435",
          "publishedOn": "2023-11-04T00:42:37.581Z",
          "wordCount": null,
          "title": "Contrastive Moments: Unsupervised Halfspace Learning in Polynomial Time. (arXiv:2311.01435v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mostafavi_A/0/1/0/all/0/1\">Ali Mostafavi</a>",
          "description": "The standard model of infrastructure resilience, the resilience triangle, has\nbeen the primary way of characterizing and quantifying infrastructure\nresilience. However, the theoretical model merely provides a one-size-fits-all\nframework for all infrastructure systems. Most of the existing studies examine\nthe characteristics of infrastructure resilience curves based on analytical\nmodels constructed upon simulated system performance. Limited empirical studies\nhindered our ability to fully understand and predict resilience characteristics\nin infrastructure systems. To address this gap, this study examined over 200\nresilience curves related to power outages in three major extreme weather\nevents. Using unsupervised machine learning, we examined different curve\narchetypes, as well as the fundamental properties of each resilience curve\narchetype. The results show two primary archetypes for power system resilience\ncurves, triangular, and trapezoidal curves. Triangular curves characterize\nresilience behavior based on 1. critical functionality threshold, 2. critical\nfunctionality recovery rate, and 3. recovery pivot point. Trapezoidal\narchetypes explain resilience curves based on 1. duration of sustained function\nloss and 2. constant recovery rate. The longer the duration of sustained\nfunction loss, the slower the constant rate of recovery. The findings of this\nstudy provide novel perspectives enabling better understanding and prediction\nof resilience performance of power system infrastructures.",
          "link": "http://arxiv.org/abs/2310.10030",
          "publishedOn": "2023-11-04T00:42:37.581Z",
          "wordCount": null,
          "title": "Unraveling Fundamental Properties of Power System Resilience Curves using Unsupervised Machine Learning. (arXiv:2310.10030v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ablett_T/0/1/0/all/0/1\">Trevor Ablett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Limoyo_O/0/1/0/all/0/1\">Oliver Limoyo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sigal_A/0/1/0/all/0/1\">Adam Sigal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jilani_A/0/1/0/all/0/1\">Affan Jilani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1\">Jonathan Kelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddiqi_K/0/1/0/all/0/1\">Kaleem Siddiqi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hogan_F/0/1/0/all/0/1\">Francois Hogan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1\">Gregory Dudek</a>",
          "description": "Optical tactile sensors have emerged as an effective means to acquire dense\ncontact information during robotic manipulation. A recently-introduced\n`see-through-your-skin' (STS) variant of this type of sensor has both visual\nand tactile modes, enabled by leveraging a semi-transparent surface and\ncontrollable lighting. In this work, we investigate the benefits of pairing\nvisuotactile sensing with imitation learning for contact-rich manipulation\ntasks. First, we use tactile force measurements and a novel algorithm during\nkinesthetic teaching to yield a force profile that better matches that of the\nhuman demonstrator. Second, we add visual/tactile STS mode switching as a\ncontrol policy output, simplifying the application of the sensor. Finally, we\nstudy multiple observation configurations to compare and contrast the value of\nvisual/tactile data (both with and without mode switching) with visual data\nfrom a wrist-mounted eye-in-hand camera. We perform an extensive series of\nexperiments on a real robotic manipulator with door-opening and closing tasks,\nincluding over 3,000 real test episodes. Our results highlight the importance\nof tactile sensing for imitation learning, both for data collection to allow\nforce matching, and for policy execution to allow accurate task feedback.",
          "link": "http://arxiv.org/abs/2311.01248",
          "publishedOn": "2023-11-04T00:42:37.551Z",
          "wordCount": null,
          "title": "Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching. (arXiv:2311.01248v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.02305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lofstrom_H/0/1/0/all/0/1\">Helena Lofstrom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lofstrom_T/0/1/0/all/0/1\">Tuwe Lofstrom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_U/0/1/0/all/0/1\">Ulf Johansson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonstrod_C/0/1/0/all/0/1\">Cecilia Sonstrod</a>",
          "description": "While local explanations for AI models can offer insights into individual\npredictions, such as feature importance, they are plagued by issues like\ninstability. The unreliability of feature weights, often skewed due to poorly\ncalibrated ML models, deepens these challenges. Moreover, the critical aspect\nof feature importance uncertainty remains mostly unaddressed in Explainable AI\n(XAI). The novel feature importance explanation method presented in this paper,\ncalled Calibrated Explanations (CE), is designed to tackle these issues\nhead-on. Built on the foundation of Venn-Abers, CE not only calibrates the\nunderlying model but also delivers reliable feature importance explanations\nwith an exact definition of the feature weights. CE goes beyond conventional\nsolutions by addressing output uncertainty. It accomplishes this by providing\nuncertainty quantification for both feature weights and the model's probability\nestimates. Additionally, CE is model-agnostic, featuring easily comprehensible\nconditional rules and the ability to generate counterfactual explanations with\nembedded uncertainty quantification. Results from an evaluation with 25\nbenchmark datasets underscore the efficacy of CE, making it stand as a fast,\nreliable, stable, and robust solution.",
          "link": "http://arxiv.org/abs/2305.02305",
          "publishedOn": "2023-11-04T00:42:37.551Z",
          "wordCount": null,
          "title": "Calibrated Explanations: with Uncertainty Information and Counterfactuals. (arXiv:2305.02305v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Abhishek Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dong-Gyu Lee</a>",
          "description": "Contemporary deep clustering approaches often rely on either contrastive or\nnon-contrastive techniques to acquire effective representations for clustering\ntasks. Contrastive methods leverage negative pairs to achieve homogenous\nrepresentations but can introduce class collision issues, potentially\ncompromising clustering performance. On the contrary, non-contrastive\ntechniques prevent class collisions but may produce non-uniform representations\nthat lead to clustering collapse. In this work, we propose a novel end-to-end\ndeep clustering approach named PIPCDR, designed to harness the strengths of\nboth approaches while mitigating their limitations. PIPCDR incorporates a\npositive instance proximity loss and a cluster dispersion regularizer. The\npositive instance proximity loss ensures alignment between augmented views of\ninstances and their sampled neighbors, enhancing within-cluster compactness by\nselecting genuinely positive pairs within the embedding space. Meanwhile, the\ncluster dispersion regularizer maximizes inter-cluster distances while\nminimizing within-cluster compactness, promoting uniformity in the learned\nrepresentations. PIPCDR excels in producing well-separated clusters, generating\nuniform representations, avoiding class collision issues, and enhancing\nwithin-cluster compactness. We extensively validate the effectiveness of PIPCDR\nwithin an end-to-end Majorize-Minimization framework, demonstrating its\ncompetitive performance on moderate-scale clustering benchmark datasets and\nestablishing new state-of-the-art results on large-scale datasets.",
          "link": "http://arxiv.org/abs/2311.00731",
          "publishedOn": "2023-11-04T00:42:37.550Z",
          "wordCount": null,
          "title": "Enhancing Clustering Representations with Positive Proximity and Cluster Dispersion Learning. (arXiv:2311.00731v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Behfar_S/0/1/0/all/0/1\">Stefan Kambiz Behfar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowcroft_J/0/1/0/all/0/1\">Jon Crowcroft</a>",
          "description": "Blockchain technology has revolutionized the way information is propagated in\ndecentralized networks. Ethereum plays a pivotal role in facilitating smart\ncontracts and decentralized applications. Understanding information propagation\ndynamics in Ethereum is crucial for ensuring network efficiency, security, and\nscalability. In this study, we propose an innovative approach that utilizes\nGraph Convolutional Networks (GCNs) to analyze the information propagation\npatterns in the Ethereum network. The first phase of our research involves data\ncollection from the Ethereum blockchain, consisting of blocks, transactions,\nand node degrees. We construct a transaction graph representation using\nadjacency matrices to capture the node embeddings; while our major contribution\nis to develop a combined Graph Attention Network (GAT) and Reinforcement\nLearning (RL) model to optimize the network efficiency and scalability. It\nlearns the best actions to take in various network states, ultimately leading\nto improved network efficiency, throughput, and optimize gas limits for block\nprocessing. In the experimental evaluation, we analyze the performance of our\nmodel on a large-scale Ethereum dataset. We investigate effectively aggregating\ninformation from neighboring nodes capturing graph structure and updating node\nembeddings using GCN with the objective of transaction pattern prediction,\naccounting for varying network loads and number of blocks. Not only we design a\ngas limit optimization model and provide the algorithm, but also to address\nscalability, we demonstrate the use and implementation of sparse matrices in\nGraphConv, GraphSAGE, and GAT. The results indicate that our designed GAT-RL\nmodel achieves superior results compared to other GCN models in terms of\nperformance. It effectively propagates information across the network,\noptimizing gas limits for block processing and improving network efficiency.",
          "link": "http://arxiv.org/abs/2311.01406",
          "publishedOn": "2023-11-04T00:42:37.550Z",
          "wordCount": null,
          "title": "Analysis of Information Propagation in Ethereum Network Using Combined Graph Attention Network and Reinforcement Learning to Optimize Network Efficiency and Scalability. (arXiv:2311.01406v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.18348",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tian Yu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trager_M/0/1/0/all/0/1\">Matthew Trager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1\">Alessandro Achille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perera_P/0/1/0/all/0/1\">Pramuditha Perera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zancato_L/0/1/0/all/0/1\">Luca Zancato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "We propose to extract meaning representations from autoregressive language\nmodels by considering the distribution of all possible trajectories extending\nan input text. This strategy is prompt-free, does not require fine-tuning, and\nis applicable to any pre-trained autoregressive model. Moreover, unlike\nvector-based representations, distribution-based representations can also model\nasymmetric relations (e.g., direction of logical entailment, hypernym/hyponym\nrelations) by using algebraic operations between likelihood functions. These\nideas are grounded in distributional perspectives on semantics and are\nconnected to standard constructions in automata theory, but to our knowledge\nthey have not been applied to modern language models. We empirically show that\nthe representations obtained from large models align well with human\nannotations, outperform other zero-shot and prompt-free methods on semantic\nsimilarity tasks, and can be used to solve more complex entailment and\ncontainment tasks that standard embeddings cannot handle. Finally, we extend\nour method to represent data from different modalities (e.g., image and text)\nusing multimodal autoregressive models.",
          "link": "http://arxiv.org/abs/2310.18348",
          "publishedOn": "2023-11-04T00:42:37.550Z",
          "wordCount": null,
          "title": "Meaning Representations from Trajectories in Autoregressive Models. (arXiv:2310.18348v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tavakoli_M/0/1/0/all/0/1\">Mohammadamin Tavakoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiu_Y/0/1/0/all/0/1\">Yin Ting T.Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmakov_A/0/1/0/all/0/1\">Alexander Shmakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlton_A/0/1/0/all/0/1\">Ann Marie Carlton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vranken_D/0/1/0/all/0/1\">David Van Vranken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldi_P/0/1/0/all/0/1\">Pierre Baldi</a>",
          "description": "Deep learning-based reaction predictors have undergone significant\narchitectural evolution. However, their reliance on reactions from the US\nPatent Office results in a lack of interpretable predictions and limited\ngeneralization capability to other chemistry domains, such as radical and\natmospheric chemistry. To address these challenges, we introduce a new reaction\npredictor system, RMechRP, that leverages contrastive learning in conjunction\nwith mechanistic pathways, the most interpretable representation of chemical\nreactions. Specifically designed for radical reactions, RMechRP provides\ndifferent levels of interpretation of chemical reactions. We develop and train\nmultiple deep-learning models using RMechDB, a public database of radical\nreactions, to establish the first benchmark for predicting radical reactions.\nOur results demonstrate the effectiveness of RMechRP in providing accurate and\ninterpretable predictions of radical reactions, and its potential for various\napplications in atmospheric chemistry.",
          "link": "http://arxiv.org/abs/2311.01118",
          "publishedOn": "2023-11-04T00:42:37.549Z",
          "wordCount": null,
          "title": "AI for Interpretable Chemistry: Predicting Radical Mechanistic Pathways via Contrastive Learning. (arXiv:2311.01118v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01282",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1\">Ke Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_G/0/1/0/all/0/1\">Guohao Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiaming Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1\">Qiuli Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kangdi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hanyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>",
          "description": "As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n\nWe present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.",
          "link": "http://arxiv.org/abs/2311.01282",
          "publishedOn": "2023-11-04T00:42:37.549Z",
          "wordCount": null,
          "title": "FlashDecoding++: Faster Large Language Model Inference on GPUs. (arXiv:2311.01282v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yinghua Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yuangang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1\">Ivor W. Tsang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1\">Xin Yao</a>",
          "description": "Real-world datasets inevitably contain biases that arise from different\nsources or conditions during data collection. Consequently, such inconsistency\nitself acts as a confounding factor that disturbs the cluster analysis.\nExisting methods eliminate the biases by projecting data onto the orthogonal\ncomplement of the subspace expanded by the confounding factor before\nclustering. Therein, the interested clustering factor and the confounding\nfactor are coarsely considered in the raw feature space, where the correlation\nbetween the data and the confounding factor is ideally assumed to be linear for\nconvenient solutions. These approaches are thus limited in scope as the data in\nreal applications is usually complex and non-linearly correlated with the\nconfounding factor. This paper presents a new clustering framework named\nSanitized Clustering Against confounding Bias (SCAB), which removes the\nconfounding factor in the semantic latent space of complex data through a\nnon-linear dependence measure. To be specific, we eliminate the bias\ninformation in the latent space by minimizing the mutual information between\nthe confounding factor and the latent representation delivered by Variational\nAuto-Encoder (VAE). Meanwhile, a clustering module is introduced to cluster\nover the purified latent representations. Extensive experiments on complex\ndatasets demonstrate that our SCAB achieves a significant gain in clustering\nperformance by removing the confounding bias. The code is available at\n\\url{https://github.com/EvaFlower/SCAB}.",
          "link": "http://arxiv.org/abs/2311.01252",
          "publishedOn": "2023-11-04T00:42:37.548Z",
          "wordCount": null,
          "title": "Sanitized Clustering against Confounding Bias. (arXiv:2311.01252v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1\">Zhijin Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaosen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_F/0/1/0/all/0/1\">Fanhua Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanyuan Liu</a>",
          "description": "Transfer-based attack adopts the adversarial examples generated on the\nsurrogate model to attack various models, making it applicable in the physical\nworld and attracting increasing interest. Recently, various adversarial attacks\nhave emerged to boost adversarial transferability from different perspectives.\nIn this work, inspired by the observation that flat local minima are correlated\nwith good generalization, we assume and empirically validate that adversarial\nexamples at a flat local region tend to have good transferability by\nintroducing a penalized gradient norm to the original loss function. Since\ndirectly optimizing the gradient regularization norm is computationally\nexpensive and intractable for generating adversarial examples, we propose an\napproximation optimization method to simplify the gradient update of the\nobjective function. Specifically, we randomly sample an example and adopt a\nfirst-order procedure to approximate the curvature of Hessian/vector product,\nwhich makes computing more efficient by interpolating two neighboring\ngradients. Meanwhile, in order to obtain a more stable gradient direction, we\nrandomly sample multiple examples and average the gradients of these examples\nto reduce the variance due to random sampling during the iterative process.\nExtensive experimental results on the ImageNet-compatible dataset show that the\nproposed method can generate adversarial examples at flat local regions, and\nsignificantly improve the adversarial transferability on either normally\ntrained models or adversarially trained models than the state-of-the-art\nattacks. Our codes are available at:\nhttps://github.com/Trustworthy-AI-Group/PGN.",
          "link": "http://arxiv.org/abs/2306.05225",
          "publishedOn": "2023-11-04T00:42:37.535Z",
          "wordCount": null,
          "title": "Boosting Adversarial Transferability by Achieving Flat Local Maxima. (arXiv:2306.05225v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.04391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>",
          "description": "In industry deep learning application, our manually labeled data has a\ncertain number of noisy data. To solve this problem and achieve more than 90\nscore in dev dataset, we present a simple method to find the noisy data and\nre-label the noisy data by human, given the model predictions as references in\nhuman labeling. In this paper, we illustrate our idea for a broad set of deep\nlearning tasks, includes classification, sequence tagging, object detection,\nsequence generation, click-through rate prediction. The dev dataset evaluation\nresults and human evaluation results verify our idea.",
          "link": "http://arxiv.org/abs/2302.04391",
          "publishedOn": "2023-11-04T00:42:37.530Z",
          "wordCount": null,
          "title": "The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haocheng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Wei Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngoc Dang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lan Du</a>",
          "description": "Active learning, a widely adopted technique for enhancing machine learning\nmodels in text and image classification tasks with limited annotation\nresources, has received relatively little attention in the domain of Named\nEntity Recognition (NER). The challenge of data imbalance in NER has hindered\nthe effectiveness of active learning, as sequence labellers lack sufficient\nlearning signals. To address these challenges, this paper presents a novel\nreweighting-based active learning strategy that assigns dynamic smoothed\nweights to individual tokens. This adaptable strategy is compatible with\nvarious token-level acquisition functions and contributes to the development of\nrobust active learners. Experimental results on multiple corpora demonstrate\nthe substantial performance improvement achieved by incorporating our\nre-weighting strategy into existing acquisition functions, validating its\npractical efficacy.",
          "link": "http://arxiv.org/abs/2311.00906",
          "publishedOn": "2023-11-04T00:42:37.529Z",
          "wordCount": null,
          "title": "Re-weighting Tokens: A Simple and Effective Active Learning Strategy for Named Entity Recognition. (arXiv:2311.00906v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_P/0/1/0/all/0/1\">Phat K. Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_V/0/1/0/all/0/1\">Vinh Duc An Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_K/0/1/0/all/0/1\">Kee Young Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1\">Nityanand Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Chau Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minh_L/0/1/0/all/0/1\">Le Huu Nhat Minh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_L/0/1/0/all/0/1\">Le Van Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_X/0/1/0/all/0/1\">Xuan Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dinh Hoang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dung_L/0/1/0/all/0/1\">Le Tien Dung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Trung Q. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_M/0/1/0/all/0/1\">Manh-Huong Phan</a>",
          "description": "The COVID-19 pandemic underscored the importance of reliable, noninvasive\ndiagnostic tools for robust public health interventions. In this work, we fused\nmagnetic respiratory sensing technology (MRST) with machine learning (ML) to\ncreate a diagnostic platform for real-time tracking and diagnosis of COVID-19\nand other respiratory diseases. The MRST precisely captures breathing patterns\nthrough three specific breath testing protocols: normal breath, holding breath,\nand deep breath. We collected breath data from both COVID-19 patients and\nhealthy subjects in Vietnam using this platform, which then served to train and\nvalidate ML models. Our evaluation encompassed multiple ML algorithms,\nincluding support vector machines and deep learning models, assessing their\nability to diagnose COVID-19. Our multi-model validation methodology ensures a\nthorough comparison and grants the adaptability to select the most optimal\nmodel, striking a balance between diagnostic precision with model\ninterpretability. The findings highlight the exceptional potential of our\ndiagnostic tool in pinpointing respiratory anomalies, achieving over 90%\naccuracy. This innovative sensor technology can be seamlessly integrated into\nhealthcare settings for patient monitoring, marking a significant enhancement\nfor the healthcare infrastructure.",
          "link": "http://arxiv.org/abs/2311.00737",
          "publishedOn": "2023-11-04T00:42:37.523Z",
          "wordCount": null,
          "title": "Real-Time Magnetic Tracking and Diagnosis of COVID-19 via Machine Learning. (arXiv:2311.00737v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.15856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Orlova_E/0/1/0/all/0/1\">Elena Orlova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haokun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossellini_R/0/1/0/all/0/1\">Raphael Rossellini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cash_B/0/1/0/all/0/1\">Benjamin Cash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willett_R/0/1/0/all/0/1\">Rebecca Willett</a>",
          "description": "Producing high-quality forecasts of key climate variables such as temperature\nand precipitation on subseasonal time scales has long been a gap in operational\nforecasting. Recent studies have shown promising results using machine learning\n(ML) models to advance subseasonal forecasting (SSF), but several open\nquestions remain. First, several past approaches use the average of an ensemble\nof physics-based forecasts as an input feature of these models. However,\nensemble forecasts contain information that can aid prediction beyond only the\nensemble mean. Second, past methods have focused on average performance,\nwhereas forecasts of extreme events are far more important for planning and\nmitigation purposes. Third, climate forecasts correspond to a spatially-varying\ncollection of forecasts, and different methods account for spatial variability\nin the response differently. Trade-offs between different approaches may be\nmitigated with model stacking. This paper describes the application of a\nvariety of ML methods used to predict monthly average precipitation and two\nmeter temperature using physics-based predictions (ensemble forecasts) and\nobservational data such as relative humidity, pressure at sea level, or\ngeopotential height, two weeks in advance for the whole continental United\nStates. Regression, quantile regression, and tercile classification tasks using\nlinear models, random forests, convolutional neural networks, and stacked\nmodels are considered. The proposed models outperform common baselines such as\nhistorical averages (or quantiles) and ensemble averages (or quantiles). This\npaper further includes an investigation of feature importance, trade-offs\nbetween using the full ensemble or only the ensemble average, and different\nmodes of accounting for spatial variability.",
          "link": "http://arxiv.org/abs/2211.15856",
          "publishedOn": "2023-11-04T00:42:37.523Z",
          "wordCount": null,
          "title": "Beyond Ensemble Averages: Leveraging Climate Model Ensembles for Subseasonal Forecasting. (arXiv:2211.15856v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_W/0/1/0/all/0/1\">Wenxuan Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pittaluga_F/0/1/0/all/0/1\">Francesco Pittaluga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+G_V/0/1/0/all/0/1\">Vijay Kumar B G</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bindschaedler_V/0/1/0/all/0/1\">Vincent Bindschaedler</a>",
          "description": "Data augmentation techniques, such as simple image transformations and\ncombinations, are highly effective at improving the generalization of computer\nvision models, especially when training data is limited. However, such\ntechniques are fundamentally incompatible with differentially private learning\napproaches, due to the latter's built-in assumption that each training image's\ncontribution to the learned model is bounded. In this paper, we investigate why\nnaive applications of multi-sample data augmentation techniques, such as mixup,\nfail to achieve good performance and propose two novel data augmentation\ntechniques specifically designed for the constraints of differentially private\nlearning. Our first technique, DP-Mix_Self, achieves SoTA classification\nperformance across a range of datasets and settings by performing mixup on\nself-augmented data. Our second technique, DP-Mix_Diff, further improves\nperformance by incorporating synthetic data from a pre-trained diffusion model\ninto the mixup process. We open-source the code at\nhttps://github.com/wenxuan-Bao/DP-Mix.",
          "link": "http://arxiv.org/abs/2311.01295",
          "publishedOn": "2023-11-04T00:42:37.522Z",
          "wordCount": null,
          "title": "DP-Mix: Mixup-based Data Augmentation for Differentially Private Learning. (arXiv:2311.01295v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teng_M/0/1/0/all/0/1\">M&#xe9;lisande Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmustafa_A/0/1/0/all/0/1\">Amna Elmustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akera_B/0/1/0/all/0/1\">Benjamin Akera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelwahed_H/0/1/0/all/0/1\">Hager Radi Abdelwahed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1\">Hugo Larochelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rolnick_D/0/1/0/all/0/1\">David Rolnick</a>",
          "description": "Biodiversity is declining at an unprecedented rate, impacting ecosystem\nservices necessary to ensure food, water, and human health and well-being.\nUnderstanding the distribution of species and their habitats is crucial for\nconservation policy planning. However, traditional methods in ecology for\nspecies distribution models (SDMs) generally focus either on narrow sets of\nspecies or narrow geographical areas and there remain significant knowledge\ngaps about the distribution of species. A major reason for this is the limited\navailability of data traditionally used, due to the prohibitive amount of\neffort and expertise required for traditional field monitoring. The wide\navailability of remote sensing data and the growing adoption of citizen science\ntools to collect species observations data at low cost offer an opportunity for\nimproving biodiversity monitoring and enabling the modelling of complex\necosystems. We introduce a novel task for mapping bird species to their\nhabitats by predicting species encounter rates from satellite images, and\npresent SatBird, a satellite dataset of locations in the USA with labels\nderived from presence-absence observation data from the citizen science\ndatabase eBird, considering summer (breeding) and winter seasons. We also\nprovide a dataset in Kenya representing low-data regimes. We additionally\nprovide environmental data and species range maps for each location. We\nbenchmark a set of baselines on our dataset, including SOTA models for remote\nsensing tasks. SatBird opens up possibilities for scalably modelling properties\nof ecosystems worldwide.",
          "link": "http://arxiv.org/abs/2311.00936",
          "publishedOn": "2023-11-04T00:42:37.518Z",
          "wordCount": null,
          "title": "SatBird: Bird Species Distribution Modeling with Remote Sensing and Citizen Science Data. (arXiv:2311.00936v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.19385",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Frezat_H/0/1/0/all/0/1\">Hugo Frezat</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Fablet_R/0/1/0/all/0/1\">Ronan Fablet</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Balarac_G/0/1/0/all/0/1\">Guillaume Balarac</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sommer_J/0/1/0/all/0/1\">Julien Le Sommer</a>",
          "description": "In this paper, we propose a generic algorithm to train machine learning-based\nsubgrid parametrizations online, i.e., with $\\textit{a posteriori}$ loss\nfunctions for non-differentiable numerical solvers. The proposed approach\nleverage neural emulators to train an approximation of the reduced state-space\nsolver, which is then used to allows gradient propagation through temporal\nintegration steps. The algorithm is able to recover most of the benefit of\nonline strategies without having to compute the gradient of the original\nsolver. It is demonstrated that training the neural emulator and\nparametrization components separately with respective loss quantities is\nnecessary in order to minimize the propagation of some approximation bias.",
          "link": "http://arxiv.org/abs/2310.19385",
          "publishedOn": "2023-11-04T00:42:37.518Z",
          "wordCount": null,
          "title": "Gradient-free online learning of subgrid-scale dynamics with neural emulators. (arXiv:2310.19385v2 [physics.comp-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.02598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lachapelle_S/0/1/0/all/0/1\">S&#xe9;bastien Lachapelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahajan_D/0/1/0/all/0/1\">Divyat Mahajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitliagkas_I/0/1/0/all/0/1\">Ioannis Mitliagkas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1\">Simon Lacoste-Julien</a>",
          "description": "We tackle the problems of latent variables identification and\n``out-of-support'' image generation in representation learning. We show that\nboth are possible for a class of decoders that we call additive, which are\nreminiscent of decoders used for object-centric representation learning (OCRL)\nand well suited for images that can be decomposed as a sum of object-specific\nimages. We provide conditions under which exactly solving the reconstruction\nproblem using an additive decoder is guaranteed to identify the blocks of\nlatent variables up to permutation and block-wise invertible transformations.\nThis guarantee relies only on very weak assumptions about the distribution of\nthe latent factors, which might present statistical dependencies and have an\nalmost arbitrarily shaped support. Our result provides a new setting where\nnonlinear independent component analysis (ICA) is possible and adds to our\ntheoretical understanding of OCRL methods. We also show theoretically that\nadditive decoders can generate novel images by recombining observed factors of\nvariations in novel ways, an ability we refer to as Cartesian-product\nextrapolation. We show empirically that additivity is crucial for both\nidentifiability and extrapolation on simulated data.",
          "link": "http://arxiv.org/abs/2307.02598",
          "publishedOn": "2023-11-04T00:42:37.517Z",
          "wordCount": null,
          "title": "Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation. (arXiv:2307.02598v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Annie S. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chada_G/0/1/0/all/0/1\">Govind Chada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1\">Laura Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Archit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zipeng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>",
          "description": "To succeed in the real world, robots must cope with situations that differ\nfrom those seen during training. We study the problem of adapting on-the-fly to\nsuch novel scenarios during deployment, by drawing upon a diverse repertoire of\npreviously learned behaviors. Our approach, RObust Autonomous Modulation\n(ROAM), introduces a mechanism based on the perceived value of pre-trained\nbehaviors to select and adapt pre-trained behaviors to the situation at hand.\nCrucially, this adaptation process all happens within a single episode at test\ntime, without any human supervision. We provide theoretical analysis of our\nselection mechanism and demonstrate that ROAM enables a robot to adapt rapidly\nto changes in dynamics both in simulation and on a real Go1 quadruped, even\nsuccessfully moving forward with roller skates on its feet. Our approach adapts\nover 2x as efficiently compared to existing methods when facing a variety of\nout-of-distribution situations during deployment by effectively choosing and\nadapting relevant behaviors on-the-fly.",
          "link": "http://arxiv.org/abs/2311.01059",
          "publishedOn": "2023-11-04T00:42:37.516Z",
          "wordCount": null,
          "title": "Adapt On-the-Go: Behavior Modulation for Single-Life Robot Deployment. (arXiv:2311.01059v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sevyeri_L/0/1/0/all/0/1\">Laya Rafiee Sevyeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_I/0/1/0/all/0/1\">Ivaxi Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahnak_F/0/1/0/all/0/1\">Farhood Farahnak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahou_S/0/1/0/all/0/1\">Samira Ebrahimi Kahou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Enger_S/0/1/0/all/0/1\">Shirin Abbasinejad Enger</a>",
          "description": "Advancements in deep learning techniques have given a boost to the\nperformance of anomaly detection. However, real-world and safety-critical\napplications demand a level of transparency and reasoning beyond accuracy. The\ntask of anomaly detection (AD) focuses on finding whether a given sample\nfollows the learned distribution. Existing methods lack the ability to reason\nwith clear explanations for their outcomes. Hence to overcome this challenge,\nwe propose Transparent {A}nomaly Detection {C}oncept {E}xplanations (ACE). ACE\nis able to provide human interpretable explanations in the form of concepts\nalong with anomaly prediction. To the best of our knowledge, this is the first\npaper that proposes interpretable by-design anomaly detection. In addition to\npromoting transparency in AD, it allows for effective human-model interaction.\nOur proposed model shows either higher or comparable results to black-box\nuninterpretable models. We validate the performance of ACE across three\nrealistic datasets - bird classification on CUB-200-2011, challenging\nhistopathology slide image classification on TIL-WSI-TCGA, and gender\nclassification on CelebA. We further demonstrate that our concept learning\nparadigm can be seamlessly integrated with other classification-based AD\nmethods.",
          "link": "http://arxiv.org/abs/2310.10702",
          "publishedOn": "2023-11-04T00:42:37.516Z",
          "wordCount": null,
          "title": "Transparent Anomaly Detection via Concept-based Explanations. (arXiv:2310.10702v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1\">Chengyao Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1\">Yin Lou</a>",
          "description": "Rules are widely used in Fintech institutions to make fraud prevention\ndecisions, since rules are highly interpretable thanks to their intuitive\nif-then structure. In practice, a two-stage framework of fraud prevention\ndecision rule set mining is usually employed in large Fintech institutions.\nThis paper is concerned with finding high-quality rule subsets in a\nbi-objective space (such as precision and recall) from an initial pool of\nrules. To this end, we adopt the concept of Pareto optimality and aim to find a\nset of non-dominated rule subsets, which constitutes a Pareto front. We propose\na heuristic-based framework called PORS and we identify that the core of PORS\nis the problem of solution selection on the front (SSF). We provide a\nsystematic categorization of the SSF problem and a thorough empirical\nevaluation of various SSF methods on both public and proprietary datasets. We\nalso introduce a novel variant of sequential covering algorithm called\nSpectralRules to encourage the diversity of the initial rule set and we\nempirically find that SpectralRules further improves the quality of the found\nPareto front. On two real application scenarios within Alipay, we demonstrate\nthe advantages of our proposed methodology compared to existing work.",
          "link": "http://arxiv.org/abs/2311.00964",
          "publishedOn": "2023-11-04T00:42:37.507Z",
          "wordCount": null,
          "title": "On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for Fintech Applications. (arXiv:2311.00964v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadov_K/0/1/0/all/0/1\">Konstantine Sadov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_M/0/1/0/all/0/1\">Matthew Hutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Near_A/0/1/0/all/0/1\">Asara Near</a>",
          "description": "We adapt the architectures of previous audio manipulation and generation\nneural networks to the task of real-time any-to-one voice conversion. Our\nresulting model, LLVC ($\\textbf{L}$ow-latency $\\textbf{L}$ow-resource\n$\\textbf{V}$oice $\\textbf{C}$onversion), has a latency of under 20ms at a\nbitrate of 16kHz and runs nearly 2.8x faster than real-time on a consumer CPU.\nLLVC uses both a generative adversarial architecture as well as knowledge\ndistillation in order to attain this performance. To our knowledge LLVC\nachieves both the lowest resource usage as well as the lowest latency of any\nopen-source voice conversion model. We provide open-source samples, code, and\npretrained model weights at https://github.com/KoeAI/LLVC.",
          "link": "http://arxiv.org/abs/2311.00873",
          "publishedOn": "2023-11-04T00:42:37.506Z",
          "wordCount": null,
          "title": "Low-latency Real-time Voice Conversion on CPU. (arXiv:2311.00873v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01428",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hussain_M/0/1/0/all/0/1\">Md Gulzar Hussain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiren_Y/0/1/0/all/0/1\">Ye Shiren</a>",
          "description": "Dementia, a prevalent neurodegenerative condition, is a major manifestation\nof Alzheimer's disease (AD). As the condition progresses from mild to severe,\nit significantly impairs the individual's ability to perform daily tasks\nindependently, necessitating the need for timely and accurate AD\nclassification. Machine learning or deep learning models have emerged as\neffective tools for this purpose. In this study, we suggested an approach for\nclassifying the four stages of dementia using RF, SVM, and CNN algorithms,\naugmented with watershed segmentation for feature extraction from MRI images.\nOur results reveal that SVM with watershed features achieves an impressive\naccuracy of 96.25%, surpassing other classification methods. The ADNI dataset\nis utilized to evaluate the effectiveness of our method, and we observed that\nthe inclusion of watershed segmentation contributes to the enhanced performance\nof the models.",
          "link": "http://arxiv.org/abs/2311.01428",
          "publishedOn": "2023-11-04T00:42:37.505Z",
          "wordCount": null,
          "title": "Identifying Alzheimer Disease Dementia Levels Using Machine Learning Methods. (arXiv:2311.01428v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.13009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hassid_M/0/1/0/all/0/1\">Michael Hassid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Remez_T/0/1/0/all/0/1\">Tal Remez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tu Anh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1\">Itai Gat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conneau_A/0/1/0/all/0/1\">Alexis Conneau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreuk_F/0/1/0/all/0/1\">Felix Kreuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Copet_J/0/1/0/all/0/1\">Jade Copet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Defossez_A/0/1/0/all/0/1\">Alexandre Defossez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1\">Emmanuel Dupoux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_R/0/1/0/all/0/1\">Roy Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>",
          "description": "Speech language models (SpeechLMs) process and generate acoustic data only,\nwithout textual supervision. In this work, we propose TWIST, a method for\ntraining SpeechLMs using a warm-start from a pretrained textual language\nmodels. We show using both automatic and human evaluations that TWIST\noutperforms a cold-start SpeechLM across the board. We empirically analyze the\neffect of different model design choices such as the speech tokenizer, the\npretrained textual model, and the dataset size. We find that model and dataset\nscale both play an important role in constructing better-performing SpeechLMs.\nBased on our observations, we present the largest (to the best of our\nknowledge) SpeechLM both in terms of number of parameters and training data. We\nadditionally introduce two spoken versions of the StoryCloze textual benchmark\nto further improve model evaluation and advance future research in the field.\nWe make speech samples, code and models publicly available:\nhttps://pages.cs.huji.ac.il/adiyoss-lab/twist/ .",
          "link": "http://arxiv.org/abs/2305.13009",
          "publishedOn": "2023-11-04T00:42:37.505Z",
          "wordCount": null,
          "title": "Textually Pretrained Speech Language Models. (arXiv:2305.13009v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01352",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1\">Yu Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sollman_J/0/1/0/all/0/1\">Jan Sollman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1\">Jianxu Chen</a>",
          "description": "With the fast development of modern microscopes and bioimaging techniques, an\nunprecedentedly large amount of imaging data are being generated, stored,\nanalyzed, and even shared through networks. The size of the data poses great\nchallenges for current data infrastructure. One common way to reduce the data\nsize is by image compression. This present study analyzes classic and deep\nlearning based image compression methods, and their impact on deep learning\nbased image processing models. Deep learning based label-free prediction models\n(i.e., predicting fluorescent images from bright field images) are used as an\nexample application for comparison and analysis. Effective image compression\nmethods could help reduce the data size significantly without losing necessary\ninformation, and therefore reduce the burden on data management infrastructure\nand permit fast transmission through the network for data sharing or cloud\ncomputing. To compress images in such a wanted way, multiple classical lossy\nimage compression techniques are compared to several AI-based compression\nmodels provided by and trained with the CompressAI toolbox using python. These\ndifferent compression techniques are compared in compression ratio, multiple\nimage similarity measures and, most importantly, the prediction accuracy from\nlabel-free models on compressed images. We found that AI-based compression\ntechniques largely outperform the classic ones and will minimally affect the\ndownstream label-free task in 2D cases. In the end, we hope the present study\ncould shed light on the potential of deep learning based image compression and\nthe impact of image compression on downstream deep learning based image\nanalysis models.",
          "link": "http://arxiv.org/abs/2311.01352",
          "publishedOn": "2023-11-04T00:42:37.497Z",
          "wordCount": null,
          "title": "Deep learning based Image Compression for Microscopy Images: An Empirical Study. (arXiv:2311.01352v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00839",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Delarue_F/0/1/0/all/0/1\">Fran&#xe7;ois Delarue</a>, <a href=\"http://arxiv.org/find/math/1/au:+Vasileiadis_A/0/1/0/all/0/1\">Athanasios Vasileiadis</a>",
          "description": "The goal of this paper is to demonstrate that common noise may serve as an\nexploration noise for learning the solution of a mean field game. This concept\nis here exemplified through a toy linear-quadratic model, for which a suitable\nform of common noise has already been proven to restore existence and\nuniqueness. We here go one step further and prove that the same form of common\nnoise may force the convergence of the learning algorithm called `fictitious\nplay', and this without any further potential or monotone structure. Several\nnumerical examples are provided in order to support our theoretical analysis.",
          "link": "http://arxiv.org/abs/2107.00839",
          "publishedOn": "2023-11-04T00:42:37.497Z",
          "wordCount": null,
          "title": "Exploration noise for learning linear-quadratic mean field games. (arXiv:2107.00839v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weber_T/0/1/0/all/0/1\">Tobias Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ingrisch_M/0/1/0/all/0/1\">Michael Ingrisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1\">David R&#xfc;gamer</a>",
          "description": "Purpose: To analyze and remove protected feature effects in chest radiograph\nembeddings of deep learning models.\n\nMaterials and Methods: An orthogonalization is utilized to remove the\ninfluence of protected features (e.g., age, sex, race) in chest radiograph\nembeddings, ensuring feature-independent results. To validate the efficacy of\nthe approach, we retrospectively study the MIMIC and CheXpert datasets using\nthree pre-trained models, namely a supervised contrastive, a self-supervised\ncontrastive, and a baseline classifier model. Our statistical analysis involves\ncomparing the original versus the orthogonalized embeddings by estimating\nprotected feature influences and evaluating the ability to predict race, age,\nor sex using the two types of embeddings.\n\nResults: Our experiments reveal a significant influence of protected features\non predictions of pathologies. Applying orthogonalization removes these feature\neffects. Apart from removing any influence on pathology classification, while\nmaintaining competitive predictive performance, orthogonalized embeddings\nfurther make it infeasible to directly predict protected attributes and\nmitigate subgroup disparities.\n\nConclusion: The presented work demonstrates the successful application and\nevaluation of the orthogonalization technique in the domain of chest X-ray\nclassification.",
          "link": "http://arxiv.org/abs/2311.01349",
          "publishedOn": "2023-11-04T00:42:37.486Z",
          "wordCount": null,
          "title": "Unreading Race: Purging Protected Features from Chest X-ray Embeddings. (arXiv:2311.01349v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pratihar_S/0/1/0/all/0/1\">Sudarson Roy Pratihar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1\">Subhadip Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dash_P/0/1/0/all/0/1\">Pranab Kumar Dash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amartya Kumar Das</a>",
          "description": "Telecom industries lose globally 46.3 Billion USD due to fraud. Data mining\nand machine learning techniques (apart from rules oriented approach) have been\nused in past, but efficiency has been low as fraud pattern changes very\nrapidly. This paper presents an industrialized solution approach with self\nadaptive data mining technique and application of big data technologies to\ndetect fraud and discover novel fraud patterns in accurate, efficient and cost\neffective manner. Solution has been successfully demonstrated to detect\nInternational Revenue Share Fraud with <5% false positive. More than 1 Terra\nBytes of Call Detail Record from a reputed wholesale carrier and overseas\ntelecom transit carrier has been used to conduct this study.",
          "link": "http://arxiv.org/abs/2311.00724",
          "publishedOn": "2023-11-04T00:42:37.485Z",
          "wordCount": null,
          "title": "Fraud Analytics Using Machine-learning & Engineering on Big Data (FAME) for Telecom. (arXiv:2311.00724v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weikang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Junping Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yingxia Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jia Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yangxi Zhou</a>",
          "description": "Federated learning enables a collaborative training and optimization of\nglobal models among a group of devices without sharing local data samples.\nHowever, the heterogeneity of data in federated learning can lead to unfair\nrepresentation of the global model across different devices. To address the\nfairness issue in federated learning, we propose a dynamic q fairness federated\nlearning algorithm with reinforcement learning, called DQFFL. DQFFL aims to\nmitigate the discrepancies in device aggregation and enhance the fairness of\ntreatment for all groups involved in federated learning. To quantify fairness,\nDQFFL leverages the performance of the global federated model on each device\nand incorporates {\\alpha}-fairness to transform the preservation of fairness\nduring federated aggregation into the distribution of client weights in the\naggregation process. Considering the sensitivity of parameters in measuring\nfairness, we propose to utilize reinforcement learning for dynamic parameters\nduring aggregation. Experimental results demonstrate that our DQFFL outperforms\nthe state-of-the-art methods in terms of overall performance, fairness and\nconvergence speed.",
          "link": "http://arxiv.org/abs/2311.00959",
          "publishedOn": "2023-11-04T00:42:37.485Z",
          "wordCount": null,
          "title": "Dynamic Fair Federated Learning Based on Reinforcement Learning. (arXiv:2311.00959v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qizhang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yiwen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1\">Wangmeng Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>",
          "description": "The adversarial vulnerability of deep neural networks (DNNs) has drawn great\nattention due to the security risk of applying these models in real-world\napplications. Based on transferability of adversarial examples, an increasing\nnumber of transfer-based methods have been developed to fool black-box DNN\nmodels whose architecture and parameters are inaccessible. Although tremendous\neffort has been exerted, there still lacks a standardized benchmark that could\nbe taken advantage of to compare these methods systematically, fairly, and\npractically. Our investigation shows that the evaluation of some methods needs\nto be more reasonable and more thorough to verify their effectiveness, to\navoid, for example, unfair comparison and insufficient consideration of\npossible substitute/victim models. Therefore, we establish a transfer-based\nattack benchmark (TA-Bench) which implements 30+ methods. In this paper, we\nevaluate and compare them comprehensively on 25 popular substitute/victim\nmodels on ImageNet. New insights about the effectiveness of these methods are\ngained and guidelines for future evaluations are provided. Code at:\nhttps://github.com/qizhangli/TA-Bench.",
          "link": "http://arxiv.org/abs/2311.01323",
          "publishedOn": "2023-11-04T00:42:37.485Z",
          "wordCount": null,
          "title": "Towards Evaluating Transfer-based Attacks Systematically, Practically, and Fairly. (arXiv:2311.01323v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.13410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qizhang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yiwen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1\">Wangmeng Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>",
          "description": "Intermediate-level attacks that attempt to perturb feature representations\nfollowing an adversarial direction drastically have shown favorable performance\nin crafting transferable adversarial examples. Existing methods in this\ncategory are normally formulated with two separate stages, where a directional\nguide is required to be determined at first and the scalar projection of the\nintermediate-level perturbation onto the directional guide is enlarged\nthereafter. The obtained perturbation deviates from the guide inevitably in the\nfeature space, and it is revealed in this paper that such a deviation may lead\nto sub-optimal attack. To address this issue, we develop a novel\nintermediate-level method that crafts adversarial examples within a single\nstage of optimization. In particular, the proposed method, named\nintermediate-level perturbation decay (ILPD), encourages the intermediate-level\nperturbation to be in an effective adversarial direction and to possess a great\nmagnitude simultaneously. In-depth discussion verifies the effectiveness of our\nmethod. Experimental results show that it outperforms state-of-the-arts by\nlarge margins in attacking various victim models on ImageNet (+10.07% on\naverage) and CIFAR-10 (+3.88% on average). Our code is at\nhttps://github.com/qizhangli/ILPD-attack.",
          "link": "http://arxiv.org/abs/2304.13410",
          "publishedOn": "2023-11-04T00:42:37.485Z",
          "wordCount": null,
          "title": "Improving Adversarial Transferability via Intermediate-level Perturbation Decay. (arXiv:2304.13410v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_C/0/1/0/all/0/1\">Cheng-Hao Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hong-You Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mai_Z/0/1/0/all/0/1\">Zheda Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_J/0/1/0/all/0/1\">Jike Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1\">Vardaan Pahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_Wolf_T/0/1/0/all/0/1\">Tanya Berger-Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Song Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stewart_C/0/1/0/all/0/1\">Charles Stewart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1\">Wei-Lun Chao</a>",
          "description": "We propose a learning problem involving adapting a pre-trained source model\nto the target domain for classifying all classes that appeared in the source\ndata, using target data that covers only a partial label space. This problem is\npractical, as it is unrealistic for the target end-users to collect data for\nall classes prior to adaptation. However, it has received limited attention in\nthe literature. To shed light on this issue, we construct benchmark datasets\nand conduct extensive experiments to uncover the inherent challenges. We found\na dilemma -- on the one hand, adapting to the new target domain is important to\nclaim better performance; on the other hand, we observe that preserving the\nclassification accuracy of classes missing in the target adaptation data is\nhighly challenging, let alone improving them. To tackle this, we identify two\nkey directions: 1) disentangling domain gradients from classification\ngradients, and 2) preserving class relationships. We present several effective\nsolutions that maintain the accuracy of the missing classes and enhance the\noverall performance, establishing solid baselines for holistic transfer of\npre-trained models with partial target data.",
          "link": "http://arxiv.org/abs/2311.01420",
          "publishedOn": "2023-11-04T00:42:37.484Z",
          "wordCount": null,
          "title": "Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial Target Data. (arXiv:2311.01420v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01052",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Letzelter_V/0/1/0/all/0/1\">Victor Letzelter</a> (S2A, IDS), <a href=\"http://arxiv.org/find/stat/1/au:+Fontaine_M/0/1/0/all/0/1\">Mathieu Fontaine</a> (S2A, IDS), <a href=\"http://arxiv.org/find/stat/1/au:+Chen_M/0/1/0/all/0/1\">Micka&#xeb;l Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Perez_P/0/1/0/all/0/1\">Patrick P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Richard_G/0/1/0/all/0/1\">Gael Richard</a> (S2A, IDS), <a href=\"http://arxiv.org/find/stat/1/au:+Essid_S/0/1/0/all/0/1\">Slim Essid</a> (IDS, S2A)",
          "description": "We introduce Resilient Multiple Choice Learning (rMCL), an extension of the\nMCL approach for conditional distribution estimation in regression settings\nwhere multiple targets may be sampled for each training input. Multiple Choice\nLearning is a simple framework to tackle multimodal density estimation, using\nthe Winner-Takes-All (WTA) loss for a set of hypotheses. In regression\nsettings, the existing MCL variants focus on merging the hypotheses, thereby\neventually sacrificing the diversity of the predictions. In contrast, our\nmethod relies on a novel learned scoring scheme underpinned by a mathematical\nframework based on Voronoi tessellations of the output space, from which we can\nderive a probabilistic interpretation. After empirically validating rMCL with\nexperiments on synthetic data, we further assess its merits on the sound source\nlocalization problem, demonstrating its practical usefulness and the relevance\nof its interpretation.",
          "link": "http://arxiv.org/abs/2311.01052",
          "publishedOn": "2023-11-04T00:42:37.480Z",
          "wordCount": null,
          "title": "Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis. (arXiv:2311.01052v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patro_B/0/1/0/all/0/1\">Badri N. Patro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agneeswaran_V/0/1/0/all/0/1\">Vijay Srinivas Agneeswaran</a>",
          "description": "Vision transformers have gained significant attention and achieved\nstate-of-the-art performance in various computer vision tasks, including image\nclassification, instance segmentation, and object detection. However,\nchallenges remain in addressing attention complexity and effectively capturing\nfine-grained information within images. Existing solutions often resort to\ndown-sampling operations, such as pooling, to reduce computational cost.\nUnfortunately, such operations are non-invertible and can result in information\nloss. In this paper, we present a novel approach called Scattering Vision\nTransformer (SVT) to tackle these challenges. SVT incorporates a spectrally\nscattering network that enables the capture of intricate image details. SVT\novercomes the invertibility issue associated with down-sampling operations by\nseparating low-frequency and high-frequency components. Furthermore, SVT\nintroduces a unique spectral gating network utilizing Einstein multiplication\nfor token and channel mixing, effectively reducing complexity. We show that SVT\nachieves state-of-the-art performance on the ImageNet dataset with a\nsignificant reduction in a number of parameters and FLOPS. SVT shows 2\\%\nimprovement over LiTv2 and iFormer. SVT-H-S reaches 84.2\\% top-1 accuracy,\nwhile SVT-H-B reaches 85.2\\% (state-of-art for base versions) and SVT-H-L\nreaches 85.7\\% (again state-of-art for large versions). SVT also shows\ncomparable results in other vision tasks such as instance segmentation. SVT\nalso outperforms other transformers in transfer learning on standard datasets\nsuch as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The\nproject page is available on this\nwebpage.\\url{https://badripatro.github.io/svt/}.",
          "link": "http://arxiv.org/abs/2311.01310",
          "publishedOn": "2023-11-04T00:42:37.463Z",
          "wordCount": null,
          "title": "Scattering Vision Transformer: Spectral Mixing Matters. (arXiv:2311.01310v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01442",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Assandri_V/0/1/0/all/0/1\">Valentino Assandri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heshmati_S/0/1/0/all/0/1\">Sam Heshmati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yaman_B/0/1/0/all/0/1\">Burhaneddin Yaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iakovlev_A/0/1/0/all/0/1\">Anton Iakovlev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Repetur_A/0/1/0/all/0/1\">Ariel Emiliano Repetur</a>",
          "description": "Deep learning models, particularly Transformers, have achieved impressive\nresults in various domains, including time series forecasting. While existing\ntime series literature primarily focuses on model architecture modifications\nand data augmentation techniques, this paper explores the training schema of\ndeep learning models for time series; how models are trained regardless of\ntheir architecture. We perform extensive experiments to investigate the\noccurrence of deep double descent in several Transformer models trained on\npublic time series data sets. We demonstrate epoch-wise deep double descent and\nthat overfitting can be reverted using more epochs. Leveraging these findings,\nwe achieve state-of-the-art results for long sequence time series forecasting\nin nearly 70% of the 72 benchmarks tested. This suggests that many models in\nthe literature may possess untapped potential. Additionally, we introduce a\ntaxonomy for classifying training schema modifications, covering data\naugmentation, model inputs, model targets, time series per model, and\ncomputational budget.",
          "link": "http://arxiv.org/abs/2311.01442",
          "publishedOn": "2023-11-04T00:42:37.440Z",
          "wordCount": null,
          "title": "Deep Double Descent for Time Series Forecasting: Avoiding Undertrained Models. (arXiv:2311.01442v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.08879",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Golyadkin_M/0/1/0/all/0/1\">Maksim Golyadkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pozdnyakov_V/0/1/0/all/0/1\">Vitaliy Pozdnyakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhukov_L/0/1/0/all/0/1\">Leonid Zhukov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makarov_I/0/1/0/all/0/1\">Ilya Makarov</a>",
          "description": "Modern industrial facilities generate large volumes of raw sensor data during\nthe production process. This data is used to monitor and control the processes\nand can be analyzed to detect and predict process abnormalities. Typically, the\ndata has to be annotated by experts in order to be used in predictive modeling.\nHowever, manual annotation of large amounts of data can be difficult in\nindustrial settings.\n\nIn this paper, we propose SensorSCAN, a novel method for unsupervised fault\ndetection and diagnosis, designed for industrial chemical process monitoring.\nWe demonstrate our model's performance on two publicly available datasets of\nthe Tennessee Eastman Process with various faults. The results show that our\nmethod significantly outperforms existing approaches (+0.2-0.3 TPR for a fixed\nFPR) and effectively detects most of the process faults without expert\nannotation. Moreover, we show that the model fine-tuned on a small fraction of\nlabeled data nearly reaches the performance of a SOTA model trained on the full\ndataset. We also demonstrate that our method is suitable for real-world\napplications where the number of faults is not known in advance. The code is\navailable at https://github.com/AIRI-Institute/sensorscan.",
          "link": "http://arxiv.org/abs/2208.08879",
          "publishedOn": "2023-11-04T00:42:37.440Z",
          "wordCount": null,
          "title": "SensorSCAN: Self-Supervised Learning and Deep Clustering for Fault Diagnosis in Chemical Processes. (arXiv:2208.08879v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07439",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Starck_S/0/1/0/all/0/1\">Sophie Starck</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kini_Y/0/1/0/all/0/1\">Yadunandan Vivekanand Kini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ritter_J/0/1/0/all/0/1\">Jessica Johanna Maria Ritter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Braren_R/0/1/0/all/0/1\">Rickmer Braren</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1\">Daniel Rueckert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mueller_T/0/1/0/all/0/1\">Tamara Mueller</a>",
          "description": "Age prediction is an important part of medical assessments and research. It\ncan aid in detecting diseases as well as abnormal ageing by highlighting the\ndiscrepancy between chronological and biological age. To gain a comprehensive\nunderstanding of age-related changes observed in various body parts, we\ninvestigate them on a larger scale by using whole-body 3D images. We utilise\nthe Grad-CAM interpretability method to determine the body areas most\npredictive of a person's age. We expand our analysis beyond individual subjects\nby employing registration techniques to generate population-wide\ninterpretability maps. Our findings reveal three primary areas of interest: the\nspine, the autochthonous back muscles, and the cardiac region, which exhibits\nthe highest importance.",
          "link": "http://arxiv.org/abs/2307.07439",
          "publishedOn": "2023-11-04T00:42:37.440Z",
          "wordCount": null,
          "title": "Atlas-Based Interpretable Age Prediction In Whole-Body MR Images. (arXiv:2307.07439v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1\">Kai Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1\">Alexander G. Schwing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-xiong Wang</a>",
          "description": "In real-world scenarios, arbitrary interactions with the environment can\noften be costly, and actions of expert demonstrations are not always available.\nTo reduce the need for both, Offline Learning from Observations (LfO) is\nextensively studied, where the agent learns to solve a task with only expert\nstates and \\textit{task-agnostic} non-expert state-action pairs. The\nstate-of-the-art DIstribution Correction Estimation (DICE) methods minimize the\nstate occupancy divergence between the learner and expert policies. However,\nthey are limited to either $f$-divergences (KL and $\\chi^2$) or Wasserstein\ndistance with Rubinstein duality, the latter of which constrains the underlying\ndistance metric crucial to the performance of Wasserstein-based solutions. To\naddress this problem, we propose Primal Wasserstein DICE (PW-DICE), which\nminimizes the primal Wasserstein distance between the expert and learner state\noccupancies with a pessimistic regularizer and leverages a contrastively\nlearned distance as the underlying metric for the Wasserstein distance.\nTheoretically, we prove that our framework is a generalization of the\nstate-of-the-art, SMODICE, and unifies $f$-divergence and Wasserstein\nminimization. Empirically, we find that PW-DICE improves upon several\nstate-of-the-art methods on multiple testbeds.",
          "link": "http://arxiv.org/abs/2311.01331",
          "publishedOn": "2023-11-04T00:42:37.437Z",
          "wordCount": null,
          "title": "Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching. (arXiv:2311.01331v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.18666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chen Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chone_Ducasse_G/0/1/0/all/0/1\">Gaspard Chon&#xe9;-Ducasse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1\">Mark Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "The popularity of bi-level optimization (BO) in deep learning has spurred a\ngrowing interest in studying gradient-based BO algorithms. However, existing\nalgorithms involve two coupled learning rates that can be affected by\napproximation errors when computing hypergradients, making careful fine-tuning\nnecessary to ensure fast convergence. To alleviate this issue, we investigate\nthe use of recently proposed adaptive step-size methods, namely stochastic line\nsearch (SLS) and stochastic Polyak step size (SPS), for computing both the\nupper and lower-level learning rates. First, we revisit the use of SLS and SPS\nin single-level optimization without the additional interpolation condition\nthat is typically assumed in prior works. For such settings, we investigate new\nvariants of SLS and SPS that improve upon existing suggestions in the\nliterature and are simpler to implement. Importantly, these two variants can be\nseen as special instances of general family of methods with an envelope-type\nstep-size. This unified envelope strategy allows for the extension of the\nalgorithms and their convergence guarantees to BO settings. Finally, our\nextensive experiments demonstrate that the new algorithms, which are available\nin both SGD and Adam versions, can find large learning rates with minimal\ntuning and converge faster than corresponding vanilla SGD or Adam BO algorithms\nthat require fine-tuning.",
          "link": "http://arxiv.org/abs/2305.18666",
          "publishedOn": "2023-11-04T00:42:37.437Z",
          "wordCount": null,
          "title": "BiSLS/SPS: Auto-tune Step Sizes for Stable Bi-level Optimization. (arXiv:2305.18666v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lunjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yuwen Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ze Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casas_S/0/1/0/all/0/1\">Sergio Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1\">Rui Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1\">Raquel Urtasun</a>",
          "description": "Learning world models can teach an agent how the world works in an\nunsupervised manner. Even though it can be viewed as a special case of sequence\nmodeling, progress for scaling world models on robotic applications such as\nautonomous driving has been somewhat less rapid than scaling language models\nwith Generative Pre-trained Transformers (GPT). We identify two reasons as\nmajor bottlenecks: dealing with complex and unstructured observation space, and\nhaving a scalable generative model. Consequently, we propose a novel world\nmodeling approach that first tokenizes sensor observations with VQVAE, then\npredicts the future via discrete diffusion. To efficiently decode and denoise\ntokens in parallel, we recast Masked Generative Image Transformer into the\ndiscrete diffusion framework with a few simple changes, resulting in notable\nimprovement. When applied to learning world models on point cloud observations,\nour model reduces prior SOTA Chamfer distance by more than 65% for 1s\nprediction, and more than 50% for 3s prediction, across NuScenes, KITTI\nOdometry, and Argoverse2 datasets. Our results demonstrate that discrete\ndiffusion on tokenized agent experience can unlock the power of GPT-like\nunsupervised learning for robotic agents.",
          "link": "http://arxiv.org/abs/2311.01017",
          "publishedOn": "2023-11-04T00:42:37.409Z",
          "wordCount": null,
          "title": "Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion. (arXiv:2311.01017v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01138",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stoverud_K/0/1/0/all/0/1\">Karen-Helene St&#xf8;verud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouget_D/0/1/0/all/0/1\">David Bouget</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedersen_A/0/1/0/all/0/1\">Andre Pedersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leira_H/0/1/0/all/0/1\">H&#xe5;kon Olav Leira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lango_T/0/1/0/all/0/1\">Thomas Lang&#xf8;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofstad_E/0/1/0/all/0/1\">Erlend Fagertun Hofstad</a>",
          "description": "To improve the prognosis of patients suffering from pulmonary diseases, such\nas lung cancer, early diagnosis and treatment are crucial. The analysis of CT\nimages is invaluable for diagnosis, whereas high quality segmentation of the\nairway tree are required for intervention planning and live guidance during\nbronchoscopy. Recently, the Multi-domain Airway Tree Modeling (ATM'22)\nchallenge released a large dataset, both enabling training of deep-learning\nbased models and bringing substantial improvement of the state-of-the-art for\nthe airway segmentation task. However, the ATM'22 dataset includes few patients\nwith severe pathologies affecting the airway tree anatomy. In this study, we\nintroduce a new public benchmark dataset (AeroPath), consisting of 27 CT images\nfrom patients with pathologies ranging from emphysema to large tumors, with\ncorresponding trachea and bronchi annotations. Second, we present a multiscale\nfusion design for automatic airway segmentation. Models were trained on the\nATM'22 dataset, tested on the AeroPath dataset, and further evaluated against\ncompetitive open-source methods. The same performance metrics as used in the\nATM'22 challenge were used to benchmark the different considered approaches.\nLastly, an open web application is developed, to easily test the proposed model\non new data. The results demonstrated that our proposed architecture predicted\ntopologically correct segmentations for all the patients included in the\nAeroPath dataset. The proposed method is robust and able to handle various\nanomalies, down to at least the fifth airway generation. In addition, the\nAeroPath dataset, featuring patients with challenging pathologies, will\ncontribute to development of new state-of-the-art methods. The AeroPath dataset\nand the web application are made openly available.",
          "link": "http://arxiv.org/abs/2311.01138",
          "publishedOn": "2023-11-04T00:42:37.382Z",
          "wordCount": null,
          "title": "AeroPath: An airway segmentation benchmark dataset with challenging pathology. (arXiv:2311.01138v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuzhou Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozannar_H/0/1/0/all/0/1\">Hussein Mozannar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Lei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Hongxin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bo An</a>",
          "description": "Enabling machine learning classifiers to defer their decision to a downstream\nexpert when the expert is more accurate will ensure improved safety and\nperformance. This objective can be achieved with the learning-to-defer\nframework which aims to jointly learn how to classify and how to defer to the\nexpert. In recent studies, it has been theoretically shown that popular\nestimators for learning to defer parameterized with softmax provide unbounded\nestimates for the likelihood of deferring which makes them uncalibrated.\nHowever, it remains unknown whether this is due to the widely used softmax\nparameterization and if we can find a softmax-based estimator that is both\nstatistically consistent and possesses a valid probability estimator. In this\nwork, we first show that the cause of the miscalibrated and unbounded estimator\nin prior literature is due to the symmetric nature of the surrogate losses used\nand not due to softmax. We then propose a novel statistically consistent\nasymmetric softmax-based surrogate loss that can produce valid estimates\nwithout the issue of unboundedness. We further analyze the non-asymptotic\nproperties of our method and empirically validate its performance and\ncalibration on benchmark datasets.",
          "link": "http://arxiv.org/abs/2311.01106",
          "publishedOn": "2023-11-04T00:42:37.381Z",
          "wordCount": null,
          "title": "In Defense of Softmax Parametrization for Calibrated and Consistent Learning to Defer. (arXiv:2311.01106v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.01638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiaxin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Ke Alexander Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_E/0/1/0/all/0/1\">Emily B. Fox</a>",
          "description": "Efficiently capturing the long-range patterns in sequential data sources\nsalient to a given task -- such as classification and generative modeling --\nposes a fundamental challenge. Popular approaches in the space tradeoff between\nthe memory burden of brute-force enumeration and comparison, as in\ntransformers, the computational burden of complicated sequential dependencies,\nas in recurrent neural networks, or the parameter burden of convolutional\nnetworks with many or large filters. We instead take inspiration from\nwavelet-based multiresolution analysis to define a new building block for\nsequence modeling, which we call a MultiresLayer. The key component of our\nmodel is the multiresolution convolution, capturing multiscale trends in the\ninput sequence. Our MultiresConv can be implemented with shared filters across\na dilated causal convolution tree. Thus it garners the computational advantages\nof convolutional networks and the principled theoretical motivation of wavelet\ndecompositions. Our MultiresLayer is straightforward to implement, requires\nsignificantly fewer parameters, and maintains at most a $\\mathcal{O}(N\\log N)$\nmemory footprint for a length $N$ sequence. Yet, by stacking such layers, our\nmodel yields state-of-the-art performance on a number of sequence\nclassification and autoregressive density estimation tasks using CIFAR-10,\nListOps, and PTB-XL datasets.",
          "link": "http://arxiv.org/abs/2305.01638",
          "publishedOn": "2023-11-04T00:42:37.373Z",
          "wordCount": null,
          "title": "Sequence Modeling with Multiresolution Convolutional Memory. (arXiv:2305.01638v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01394",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chris Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1\">James Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lunjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kelvin Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suo_S/0/1/0/all/0/1\">Simon Suo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1\">Raquel Urtasun</a>",
          "description": "Realistic traffic simulation is crucial for developing self-driving software\nin a safe and scalable manner prior to real-world deployment. Typically,\nimitation learning (IL) is used to learn human-like traffic agents directly\nfrom real-world observations collected offline, but without explicit\nspecification of traffic rules, agents trained from IL alone frequently display\nunrealistic infractions like collisions and driving off the road. This problem\nis exacerbated in out-of-distribution and long-tail scenarios. On the other\nhand, reinforcement learning (RL) can train traffic agents to avoid\ninfractions, but using RL alone results in unhuman-like driving behaviors. We\npropose Reinforcing Traffic Rules (RTR), a holistic closed-loop learning\nobjective to match expert demonstrations under a traffic compliance constraint,\nwhich naturally gives rise to a joint IL + RL approach, obtaining the best of\nboth worlds. Our method learns in closed-loop simulations of both nominal\nscenarios from real-world datasets as well as procedurally generated long-tail\nscenarios. Our experiments show that RTR learns more realistic and\ngeneralizable traffic simulation policies, achieving significantly better\ntradeoffs between human-like driving and traffic compliance in both nominal and\nlong-tail scenarios. Moreover, when used as a data generation tool for training\nprediction models, our learned traffic policy leads to considerably improved\ndownstream prediction metrics compared to baseline traffic agents. For more\ninformation, visit the project website: https://waabi.ai/rtr",
          "link": "http://arxiv.org/abs/2311.01394",
          "publishedOn": "2023-11-04T00:42:37.370Z",
          "wordCount": null,
          "title": "Learning Realistic Traffic Agents in Closed-loop. (arXiv:2311.01394v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Md Rakibul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1\">Md Zakir Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Shreya Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soon_S/0/1/0/all/0/1\">Susannah Soon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1\">Tom Gedeon</a>",
          "description": "Empathy is a social skill that indicates an individual's ability to\nunderstand others. Over the past few years, empathy has drawn attention from\nvarious disciplines, including but not limited to Affective Computing,\nCognitive Science and Psychology. Empathy is a context-dependent term; thus,\ndetecting or recognising empathy has potential applications in society,\nhealthcare and education. Despite being a broad and overlapping topic, the\navenue of empathy detection studies leveraging Machine Learning remains\nunderexplored from a holistic literature perspective. To this end, we\nsystematically collect and screen 801 papers from 10 well-known databases and\nanalyse the selected 54 papers. We group the papers based on input modalities\nof empathy detection systems, i.e., text, audiovisual, audio and physiological\nsignals. We examine modality-specific pre-processing and network architecture\ndesign protocols, popular dataset descriptions and availability details, and\nevaluation protocols. We further discuss the potential applications, deployment\nchallenges and research gaps in the Affective Computing-based empathy domain,\nwhich can facilitate new avenues of exploration. We believe that our work is a\nstepping stone to developing a privacy-preserving and unbiased empathic system\ninclusive of culture, diversity and multilingualism that can be deployed in\npractice to enhance the overall well-being of human life.",
          "link": "http://arxiv.org/abs/2311.00721",
          "publishedOn": "2023-11-04T00:42:37.361Z",
          "wordCount": null,
          "title": "Empathy Detection Using Machine Learning on Text, Audiovisual, Audio or Physiological Signals. (arXiv:2311.00721v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.10832",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Caldana_M/0/1/0/all/0/1\">Matteo Caldana</a>, <a href=\"http://arxiv.org/find/math/1/au:+Antonietti_P/0/1/0/all/0/1\">Paola F. Antonietti</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dede_L/0/1/0/all/0/1\">Luca Dede&#x27;</a>",
          "description": "Algebraic multigrid (AMG) methods are among the most efficient solvers for\nlinear systems of equations and they are widely used for the solution of\nproblems stemming from the discretization of Partial Differential Equations\n(PDEs). The most severe limitation of AMG methods is the dependence on\nparameters that require to be fine-tuned. In particular, the strong threshold\nparameter is the most relevant since it stands at the basis of the construction\nof successively coarser grids needed by the AMG methods. We introduce a novel\nDeep Learning algorithm that minimizes the computational cost of the AMG method\nwhen used as a finite element solver. We show that our algorithm requires\nminimal changes to any existing code. The proposed Artificial Neural Network\n(ANN) tunes the value of the strong threshold parameter by interpreting the\nsparse matrix of the linear system as a black-and-white image and exploiting a\npooling operator to transform it into a small multi-channel image. We\nexperimentally prove that the pooling successfully reduces the computational\ncost of processing a large sparse matrix and preserves the features needed for\nthe regression task at hand. We train the proposed algorithm on a large dataset\ncontaining problems with a highly heterogeneous diffusion coefficient defined\nin different three-dimensional geometries and discretized with unstructured\ngrids and linear elasticity problems with a highly heterogeneous Young's\nmodulus. When tested on problems with coefficients or geometries not present in\nthe training dataset, our approach reduces the computational time by up to 30%.",
          "link": "http://arxiv.org/abs/2304.10832",
          "publishedOn": "2023-11-04T00:42:37.349Z",
          "wordCount": null,
          "title": "A Deep Learning algorithm to accelerate Algebraic Multigrid methods in Finite Element solvers of 3D elliptic PDEs. (arXiv:2304.10832v3 [math.NA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.17020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lesci_P/0/1/0/all/0/1\">Pietro Lesci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujinuma_Y/0/1/0/all/0/1\">Yoshinari Fujinuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardalov_M/0/1/0/all/0/1\">Momchil Hardalov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_C/0/1/0/all/0/1\">Chao Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benajiba_Y/0/1/0/all/0/1\">Yassine Benajiba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marquez_L/0/1/0/all/0/1\">Lluis Marquez</a>",
          "description": "Sequence-to-sequence state-of-the-art systems for dialogue state tracking\n(DST) use the full dialogue history as input, represent the current state as a\nlist with all the slots, and generate the entire state from scratch at each\ndialogue turn. This approach is inefficient, especially when the number of\nslots is large and the conversation is long. We propose Diable, a new task\nformalisation that simplifies the design and implementation of efficient DST\nsystems and allows one to easily plug and play large language models. We\nrepresent the dialogue state as a table and formalise DST as a table\nmanipulation task. At each turn, the system updates the previous state by\ngenerating table operations based on the dialogue context. Extensive\nexperimentation on the MultiWoz datasets demonstrates that Diable (i)\noutperforms strong efficient DST baselines, (ii) is 2.4x more time efficient\nthan current state-of-the-art methods while retaining competitive Joint Goal\nAccuracy, and (iii) is robust to noisy data annotations due to the table\noperations approach.",
          "link": "http://arxiv.org/abs/2305.17020",
          "publishedOn": "2023-11-04T00:42:37.341Z",
          "wordCount": null,
          "title": "Diable: Efficient Dialogue State Tracking as Operations on Tables. (arXiv:2305.17020v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guan_N/0/1/0/all/0/1\">Naiqing Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kaiwen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koudas_N/0/1/0/all/0/1\">Nick Koudas</a>",
          "description": "Programmatic weak supervision methodologies facilitate the expedited labeling\nof extensive datasets through the use of label functions (LFs) that encapsulate\nheuristic data sources. Nonetheless, the creation of precise LFs necessitates\ndomain expertise and substantial endeavors. Recent advances in pre-trained\nlanguage models (PLMs) have exhibited substantial potential across diverse\ntasks. However, the capacity of PLMs to autonomously formulate accurate LFs\nremains an underexplored domain. In this research, we address this gap by\nintroducing DataSculpt, an interactive framework that harnesses PLMs for the\nautomated generation of LFs. Within DataSculpt, we incorporate an array of\nprompting techniques, instance selection strategies, and LF filtration methods\nto explore the expansive design landscape. Ultimately, we conduct a thorough\nassessment of DataSculpt's performance on 12 real-world datasets, encompassing\na range of tasks. This evaluation unveils both the strengths and limitations of\ncontemporary PLMs in LF design.",
          "link": "http://arxiv.org/abs/2311.00739",
          "publishedOn": "2023-11-04T00:42:37.340Z",
          "wordCount": null,
          "title": "Can Large Language Models Design Accurate Label Functions?. (arXiv:2311.00739v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alain_M/0/1/0/all/0/1\">Mathieu Alain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takao_S/0/1/0/all/0/1\">So Takao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paige_B/0/1/0/all/0/1\">Brooks Paige</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deisenroth_M/0/1/0/all/0/1\">Marc Peter Deisenroth</a>",
          "description": "In recent years, there has been considerable interest in developing machine\nlearning models on graphs in order to account for topological inductive biases.\nIn particular, recent attention was given to Gaussian processes on such\nstructures since they can additionally account for uncertainty. However, graphs\nare limited to modelling relations between two vertices. In this paper, we go\nbeyond this dyadic setting and consider polyadic relations that include\ninteractions between vertices, edges and one of their generalisations, known as\ncells. Specifically, we propose Gaussian processes on cellular complexes, a\ngeneralisation of graphs that captures interactions between these higher-order\ncells. One of our key contributions is the derivation of two novel kernels, one\nthat generalises the graph Mat\\'ern kernel and one that additionally mixes\ninformation of different cell types.",
          "link": "http://arxiv.org/abs/2311.01198",
          "publishedOn": "2023-11-04T00:42:37.339Z",
          "wordCount": null,
          "title": "Gaussian Processes on Cellular Complexes. (arXiv:2311.01198v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19913",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bartolucci_F/0/1/0/all/0/1\">Francesca Bartolucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1\">Emmanuel de B&#xe9;zenac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raonic_B/0/1/0/all/0/1\">Bogdan Raoni&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molinaro_R/0/1/0/all/0/1\">Roberto Molinaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Siddhartha Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alaifari_R/0/1/0/all/0/1\">Rima Alaifari</a>",
          "description": "Recently, operator learning, or learning mappings between\ninfinite-dimensional function spaces, has garnered significant attention,\nnotably in relation to learning partial differential equations from data.\nConceptually clear when outlined on paper, neural operators necessitate\ndiscretization in the transition to computer implementations. This step can\ncompromise their integrity, often causing them to deviate from the underlying\noperators. This research offers a fresh take on neural operators with a\nframework Representation equivalent Neural Operators (ReNO) designed to address\nthese issues. At its core is the concept of operator aliasing, which measures\ninconsistency between neural operators and their discrete representations. We\nexplore this for widely-used operator learning techniques. Our findings detail\nhow aliasing introduces errors when handling different discretizations and\ngrids and loss of crucial continuous structures. More generally, this framework\nnot only sheds light on existing challenges but, given its constructive and\nbroad nature, also potentially offers tools for developing new neural\noperators.",
          "link": "http://arxiv.org/abs/2305.19913",
          "publishedOn": "2023-11-04T00:42:37.337Z",
          "wordCount": null,
          "title": "Representation Equivalent Neural Operators: a Framework for Alias-free Operator Learning. (arXiv:2305.19913v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.14319",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Harkonen_M/0/1/0/all/0/1\">Marc H&#xe4;rk&#xf6;nen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lange_Hegermann_M/0/1/0/all/0/1\">Markus Lange-Hegermann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Raita_B/0/1/0/all/0/1\">Bogdan Rai&#x163;&#x103;</a>",
          "description": "Partial differential equations (PDEs) are important tools to model physical\nsystems and including them into machine learning models is an important way of\nincorporating physical knowledge. Given any system of linear PDEs with constant\ncoefficients, we propose a family of Gaussian process (GP) priors, which we\ncall EPGP, such that all realizations are exact solutions of this system. We\napply the Ehrenpreis-Palamodov fundamental principle, which works as a\nnon-linear Fourier transform, to construct GP kernels mirroring standard\nspectral methods for GPs. Our approach can infer probable solutions of linear\nPDE systems from any data such as noisy measurements, or pointwise defined\ninitial and boundary conditions. Constructing EPGP-priors is algorithmic,\ngenerally applicable, and comes with a sparse version (S-EPGP) that learns the\nrelevant spectral frequencies and works better for big data sets. We\ndemonstrate our approach on three families of systems of PDEs, the heat\nequation, wave equation, and Maxwell's equations, where we improve upon the\nstate of the art in computation time and precision, in some experiments by\nseveral orders of magnitude.",
          "link": "http://arxiv.org/abs/2212.14319",
          "publishedOn": "2023-11-04T00:42:37.330Z",
          "wordCount": null,
          "title": "Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients. (arXiv:2212.14319v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Glazkova_A/0/1/0/all/0/1\">Anna Glazkova</a>",
          "description": "The paper describes a system developed for Task 1 at SMM4H 2023. The goal of\nthe task is to automatically distinguish tweets that self-report a COVID-19\ndiagnosis (for example, a positive test, clinical diagnosis, or\nhospitalization) from those that do not. We investigate the use of different\ntechniques for preprocessing tweets using four transformer-based models. The\nensemble of fine-tuned language models obtained an F1-score of 84.5%, which is\n4.1% higher than the average value.",
          "link": "http://arxiv.org/abs/2311.00732",
          "publishedOn": "2023-11-04T00:42:37.311Z",
          "wordCount": null,
          "title": "tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for Detecting Tweets Self-reporting a COVID-19 Diagnosis. (arXiv:2311.00732v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tambon_F/0/1/0/all/0/1\">Florian Tambon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1\">Foutse Khomh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antoniol_G/0/1/0/all/0/1\">Giuliano Antoniol</a>",
          "description": "As the demand for verifiability and testability of neural networks continues\nto rise, an increasing number of methods for generating test sets are being\ndeveloped. However, each of these techniques tends to emphasize specific\ntesting aspects and can be quite time-consuming. A straightforward solution to\nmitigate this issue is to transfer test sets between some benchmarked models\nand a new model under test, based on a desirable property one wishes to\ntransfer. This paper introduces GIST (Generated Inputs Sets Transferability), a\nnovel approach for the efficient transfer of test sets among Deep Learning\nmodels. Given a property of interest that a user wishes to transfer (e.g.,\ncoverage criterion), GIST enables the selection of good test sets from the\npoint of view of this property among available ones from a benchmark. We\nempirically evaluate GIST on fault types coverage property with two modalities\nand different test set generation procedures to demonstrate the approach's\nfeasibility. Experimental results show that GIST can select an effective test\nset for the given property to transfer it to the model under test. Our results\nsuggest that GIST could be applied to transfer other properties and could\ngeneralize to different test sets' generation procedures and modalities",
          "link": "http://arxiv.org/abs/2311.00801",
          "publishedOn": "2023-11-04T00:42:37.311Z",
          "wordCount": null,
          "title": "GIST: Generated Inputs Sets Transferability in Deep Learning. (arXiv:2311.00801v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01388",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jarrett_D/0/1/0/all/0/1\">Daniel Jarrett</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bica_I/0/1/0/all/0/1\">Ioana Bica</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Consider learning a generative model for time-series data. The sequential\nsetting poses a unique challenge: Not only should the generator capture the\nconditional dynamics of (stepwise) transitions, but its open-loop rollouts\nshould also preserve the joint distribution of (multi-step) trajectories. On\none hand, autoregressive models trained by MLE allow learning and computing\nexplicit transition distributions, but suffer from compounding error during\nrollouts. On the other hand, adversarial models based on GAN training alleviate\nsuch exposure bias, but transitions are implicit and hard to assess. In this\nwork, we study a generative framework that seeks to combine the strengths of\nboth: Motivated by a moment-matching objective to mitigate compounding error,\nwe optimize a local (but forward-looking) transition policy, where the\nreinforcement signal is provided by a global (but stepwise-decomposable) energy\nmodel trained by contrastive estimation. At training, the two components are\nlearned cooperatively, avoiding the instabilities typical of adversarial\nobjectives. At inference, the learned policy serves as the generator for\niterative sampling, and the learned energy serves as a trajectory-level measure\nfor evaluating sample quality. By expressly training a policy to imitate\nsequential behavior of time-series features in a dataset, this approach\nembodies \"generation by imitation\". Theoretically, we illustrate the\ncorrectness of this formulation and the consistency of the algorithm.\nEmpirically, we evaluate its ability to generate predictively useful samples\nfrom real-world datasets, verifying that it performs at the standard of\nexisting benchmarks.",
          "link": "http://arxiv.org/abs/2311.01388",
          "publishedOn": "2023-11-04T00:42:37.311Z",
          "wordCount": null,
          "title": "Time-series Generation by Contrastive Imitation. (arXiv:2311.01388v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mclaughlin_C/0/1/0/all/0/1\">Connor Mclaughlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matterer_J/0/1/0/all/0/1\">Jason Matterer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yee_M/0/1/0/all/0/1\">Michael Yee</a>",
          "description": "While deep learning models have seen widespread success in controlled\nenvironments, there are still barriers to their adoption in open-world\nsettings. One critical task for safe deployment is the detection of anomalous\nor out-of-distribution samples that may require human intervention. In this\nwork, we present a novel loss function and recipe for training networks with\nimproved density-based out-of-distribution sensitivity. We demonstrate the\neffectiveness of our method on CIFAR-10, notably reducing the false-positive\nrate of the relative Mahalanobis distance method on far-OOD tasks by over 50%.",
          "link": "http://arxiv.org/abs/2311.00808",
          "publishedOn": "2023-11-04T00:42:37.302Z",
          "wordCount": null,
          "title": "Mahalanobis-Aware Training for Out-of-Distribution Detection. (arXiv:2311.00808v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00844",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Cignoni_E/0/1/0/all/0/1\">Edoardo Cignoni</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Suman_D/0/1/0/all/0/1\">Divya Suman</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nigam_J/0/1/0/all/0/1\">Jigyasa Nigam</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Cupellini_L/0/1/0/all/0/1\">Lorenzo Cupellini</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mennucci_B/0/1/0/all/0/1\">Benedetta Mennucci</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ceriotti_M/0/1/0/all/0/1\">Michele Ceriotti</a>",
          "description": "Data-driven techniques are increasingly used to replace electronic-structure\ncalculations of matter. In this context, a relevant question is whether machine\nlearning (ML) should be applied directly to predict the desired properties or\nbe combined explicitly with physically-grounded operations. We present an\nexample of an integrated modeling approach, in which a symmetry-adapted ML\nmodel of an effective Hamiltonian is trained to reproduce electronic\nexcitations from a quantum-mechanical calculation. The resulting model can make\npredictions for molecules that are much larger and more complex than those that\nit is trained on, and allows for dramatic computational savings by indirectly\ntargeting the outputs of well-converged calculations while using a\nparameterization corresponding to a minimal atom-centered basis. These results\nemphasize the merits of intertwining data-driven techniques with physical\napproximations, improving the transferability and interpretability of ML models\nwithout affecting their accuracy and computational efficiency, and providing a\nblueprint for developing ML-augmented electronic-structure methods.",
          "link": "http://arxiv.org/abs/2311.00844",
          "publishedOn": "2023-11-04T00:42:37.302Z",
          "wordCount": null,
          "title": "Electronic excited states from physically-constrained machine learning. (arXiv:2311.00844v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jinchao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_M/0/1/0/all/0/1\">Ming Zhong</a>",
          "description": "We present a review of a series of learning methods used to identify the\nstructure of dynamical systems, aiming to understand emergent behaviors in\ncomplex systems of interacting agents. These methods not only offer theoretical\nguarantees of convergence but also demonstrate computational efficiency in\nhandling high-dimensional observational data. They can manage observation data\nfrom both first- and second-order dynamical systems, accounting for\nobservation/stochastic noise, complex interaction rules, missing interaction\nfeatures, and real-world observations of interacting agent systems. The essence\nof developing such a series of learning methods lies in designing appropriate\nloss functions using the variational inverse problem approach, which inherently\nprovides dimension reduction capabilities to our learning methods.",
          "link": "http://arxiv.org/abs/2311.00875",
          "publishedOn": "2023-11-04T00:42:37.301Z",
          "wordCount": null,
          "title": "Learning Collective Behaviors from Observation. (arXiv:2311.00875v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhanke Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jiangchao Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1\">Yu Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>",
          "description": "Graph Neural Networks (GNNs) have been widely adopted for drug discovery with\nmolecular graphs. Nevertheless, current GNNs are mainly good at leveraging\nshort-range interactions (SRI) but struggle to capture long-range interactions\n(LRI), both of which are crucial for determining molecular properties. To\ntackle this issue, we propose a method that implicitly projects all original\natoms into a few Neural Atoms, which abstracts the collective information of\natomic groups within a molecule. Specifically, we explicitly exchange the\ninformation among neural atoms and project them back to the atoms'\nrepresentations as an enhancement. With this mechanism, neural atoms establish\nthe communication channels among distant nodes, effectively reducing the\ninteraction scope of arbitrary node pairs into a single hop. To provide an\ninspection of our method from a physical perspective, we reveal its connection\nwith the traditional LRI calculation method, Ewald Summation. We conduct\nextensive experiments on three long-range graph benchmarks, covering both\ngraph-level and link-level tasks on molecular graphs. We empirically justify\nthat our method can be equipped with an arbitrary GNN and help to capture LRI.",
          "link": "http://arxiv.org/abs/2311.01276",
          "publishedOn": "2023-11-04T00:42:37.301Z",
          "wordCount": null,
          "title": "Long-Range Neural Atom Learning for Molecular Graphs. (arXiv:2311.01276v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Torop_M/0/1/0/all/0/1\">Max Torop</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masoomi_A/0/1/0/all/0/1\">Aria Masoomi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hill_D/0/1/0/all/0/1\">Davin Hill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kose_K/0/1/0/all/0/1\">Kivanc Kose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ioannidis_S/0/1/0/all/0/1\">Stratis Ioannidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dy_J/0/1/0/all/0/1\">Jennifer Dy</a>",
          "description": "Several recent methods for interpretability model feature interactions by\nlooking at the Hessian of a neural network. This poses a challenge for ReLU\nnetworks, which are piecewise-linear and thus have a zero Hessian almost\neverywhere. We propose SmoothHess, a method of estimating second-order\ninteractions through Stein's Lemma. In particular, we estimate the Hessian of\nthe network convolved with a Gaussian through an efficient sampling algorithm,\nrequiring only network gradient calls. SmoothHess is applied post-hoc, requires\nno modifications to the ReLU network architecture, and the extent of smoothing\ncan be controlled explicitly. We provide a non-asymptotic bound on the sample\ncomplexity of our estimation procedure. We validate the superior ability of\nSmoothHess to capture interactions on benchmark datasets and a real-world\nmedical spirometry dataset.",
          "link": "http://arxiv.org/abs/2311.00858",
          "publishedOn": "2023-11-04T00:42:37.276Z",
          "wordCount": null,
          "title": "SmoothHess: ReLU Network Feature Interactions via Stein's Lemma. (arXiv:2311.00858v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">MD Shafikul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wasi_A/0/1/0/all/0/1\">Azmine Toushik Wasi</a>",
          "description": "Inventory Routing Problem (IRP) is a crucial challenge in supply chain\nmanagement as it involves optimizing efficient route selection while\nconsidering the uncertainty of inventory demand planning. To solve IRPs,\nusually a two-stage approach is employed, where demand is predicted using\nmachine learning techniques first, and then an optimization algorithm is used\nto minimize routing costs. Our experiment shows machine learning models fall\nshort of achieving perfect accuracy because inventory levels are influenced by\nthe dynamic business environment, which, in turn, affects the optimization\nproblem in the next stage, resulting in sub-optimal decisions. In this paper,\nwe formulate and propose a decision-focused learning-based approach to solving\nreal-world IRPs. This approach directly integrates inventory prediction and\nrouting optimization within an end-to-end system potentially ensuring a robust\nsupply chain strategy.",
          "link": "http://arxiv.org/abs/2311.00983",
          "publishedOn": "2023-11-04T00:42:37.275Z",
          "wordCount": null,
          "title": "Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural Networks. (arXiv:2311.00983v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01434",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bouniot_Q/0/1/0/all/0/1\">Quentin Bouniot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozharovskyi_P/0/1/0/all/0/1\">Pavlo Mozharovskyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1\">Florence d&#x27;Alch&#xe9;-Buc</a>",
          "description": "Data augmentation is an essential building block for learning efficient deep\nlearning models. Among all augmentation techniques proposed so far, linear\ninterpolation of training data points, also called mixup, has found to be\neffective for a large panel of applications. While the majority of works have\nfocused on selecting the right points to mix, or applying complex non-linear\ninterpolation, we are interested in mixing similar points more frequently and\nstrongly than less similar ones. To this end, we propose to dynamically change\nthe underlying distribution of interpolation coefficients through warping\nfunctions, depending on the similarity between data points to combine. We\ndefine an efficient and flexible framework to do so without losing in\ndiversity. We provide extensive experiments for classification and regression\ntasks, showing that our proposed method improves both performance and\ncalibration of models. Code available in\nhttps://github.com/ENSTA-U2IS/torch-uncertainty",
          "link": "http://arxiv.org/abs/2311.01434",
          "publishedOn": "2023-11-04T00:42:37.271Z",
          "wordCount": null,
          "title": "Tailoring Mixup to Data using Kernel Warping functions. (arXiv:2311.01434v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.12658",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bayraktar_E/0/1/0/all/0/1\">Erhan Bayraktar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Han_B/0/1/0/all/0/1\">Bingyan Han</a>",
          "description": "We develop a fitted value iteration (FVI) method to compute bicausal optimal\ntransport (OT) where couplings have an adapted structure. Based on the dynamic\nprogramming formulation, FVI adopts a function class to approximate the value\nfunctions in bicausal OT. Under the concentrability condition and approximate\ncompleteness assumption, we prove the sample complexity using (local)\nRademacher complexity. Furthermore, we demonstrate that multilayer neural\nnetworks with appropriate structures satisfy the crucial assumptions required\nin sample complexity proofs. Numerical experiments reveal that FVI outperforms\nlinear programming and adapted Sinkhorn methods in scalability as the time\nhorizon increases, while still maintaining acceptable accuracy.",
          "link": "http://arxiv.org/abs/2306.12658",
          "publishedOn": "2023-11-04T00:42:37.269Z",
          "wordCount": null,
          "title": "Fitted Value Iteration Methods for Bicausal Optimal Transport. (arXiv:2306.12658v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.09721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiaxin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "We provide the first finite-particle convergence rate for Stein variational\ngradient descent (SVGD), a popular algorithm for approximating a probability\ndistribution with a collection of particles. Specifically, whenever the target\ndistribution is sub-Gaussian with a Lipschitz score, SVGD with n particles and\nan appropriate step size sequence drives the kernel Stein discrepancy to zero\nat an order 1/sqrt(log log n) rate. We suspect that the dependence on n can be\nimproved, and we hope that our explicit, non-asymptotic proof strategy will\nserve as a template for future refinements.",
          "link": "http://arxiv.org/abs/2211.09721",
          "publishedOn": "2023-11-04T00:42:37.268Z",
          "wordCount": null,
          "title": "A Finite-Particle Convergence Rate for Stein Variational Gradient Descent. (arXiv:2211.09721v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.10180",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xiuding Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaoyao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Beimin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yu Yao</a>",
          "description": "Automated anesthesia promises to enable more precise and personalized\nanesthetic administration and free anesthesiologists from repetitive tasks,\nallowing them to focus on the most critical aspects of a patient's surgical\ncare. Current research has typically focused on creating simulated environments\nfrom which agents can learn. These approaches have demonstrated good\nexperimental results, but are still far from clinical application. In this\npaper, Policy Constraint Q-Learning (PCQL), a data-driven reinforcement\nlearning algorithm for solving the problem of learning anesthesia strategies on\nreal clinical datasets, is proposed. Conservative Q-Learning was first\nintroduced to alleviate the problem of Q function overestimation in an offline\ncontext. A policy constraint term is added to agent training to keep the policy\ndistribution of the agent and the anesthesiologist consistent to ensure safer\ndecisions made by the agent in anesthesia scenarios. The effectiveness of PCQL\nwas validated by extensive experiments on a real clinical anesthesia dataset.\nExperimental results show that PCQL is predicted to achieve higher gains than\nthe baseline approach while maintaining good agreement with the reference dose\ngiven by the anesthesiologist, using less total dose, and being more responsive\nto the patient's vital signs. In addition, the confidence intervals of the\nagent were investigated, which were able to cover most of the clinical\ndecisions of the anesthesiologist. Finally, an interpretable method, SHAP, was\nused to analyze the contributing components of the model predictions to\nincrease the transparency of the model.",
          "link": "http://arxiv.org/abs/2303.10180",
          "publishedOn": "2023-11-04T00:42:37.266Z",
          "wordCount": null,
          "title": "Towards Safe Propofol Dosing during General Anesthesia Using Deep Offline Reinforcement Learning. (arXiv:2303.10180v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01191",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yulan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1\">Sheng Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhirui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>",
          "description": "Class imbalance in graph data poses significant challenges for node\nclassification. Existing methods, represented by SMOTE-based approaches,\npartially alleviate this issue but still exhibit limitations during imbalanced\nscenario construction. Self-supervised learning (SSL) offers a promising\nsolution by synthesizing minority nodes from the data itself, yet its potential\nremains unexplored. In this paper, we analyze the limitations of SMOTE-based\napproaches and introduce VIGraph, a novel SSL model based on the\nself-supervised Variational Graph Auto-Encoder (VGAE) that leverages\nVariational Inference (VI) to generate minority nodes. Specifically, VIGraph\nstrictly adheres to the concept of imbalance when constructing imbalanced\ngraphs and utilizes the generative VGAE to generate minority nodes. Moreover,\nVIGraph introduces a novel Siamese contrastive strategy at the decoding phase\nto improve the overall quality of generated nodes. VIGraph can generate\nhigh-quality nodes without reintegrating them into the original graph,\neliminating the \"Generating, Reintegrating, and Retraining\" process found in\nSMOTE-based methods. Experiments on multiple real-world datasets demonstrate\nthat VIGraph achieves promising results for class-imbalanced node\nclassification tasks.",
          "link": "http://arxiv.org/abs/2311.01191",
          "publishedOn": "2023-11-04T00:42:37.265Z",
          "wordCount": null,
          "title": "VIGraph: Self-supervised Learning for Class-Imbalanced Node Classification. (arXiv:2311.01191v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.10381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Assaad_C/0/1/0/all/0/1\">Charles K. Assaad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devijver_E/0/1/0/all/0/1\">Emilie Devijver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaussier_E/0/1/0/all/0/1\">Eric Gaussier</a>",
          "description": "This study addresses the problem of learning a summary causal graph on time\nseries with potentially different sampling rates. To do so, we first propose a\nnew causal temporal mutual information measure for time series. We then show\nhow this measure relates to an entropy reduction principle that can be seen as\na special case of the probability raising principle. We finally combine these\ntwo ingredients in PC-like and FCI-like algorithms to construct the summary\ncausal graph. There algorithm are evaluated on several datasets, which shows\nboth their efficacy and efficiency.",
          "link": "http://arxiv.org/abs/2105.10381",
          "publishedOn": "2023-11-04T00:42:37.264Z",
          "wordCount": null,
          "title": "Entropy-based Discovery of Summary Causal Graphs in Time Series. (arXiv:2105.10381v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01356",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Geuchen_P/0/1/0/all/0/1\">Paul Geuchen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heindl_T/0/1/0/all/0/1\">Thomas Heindl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stoger_D/0/1/0/all/0/1\">Dominik St&#xf6;ger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Voigtlaender_F/0/1/0/all/0/1\">Felix Voigtlaender</a>",
          "description": "Empirical studies have widely demonstrated that neural networks are highly\nsensitive to small, adversarial perturbations of the input. The worst-case\nrobustness against these so-called adversarial examples can be quantified by\nthe Lipschitz constant of the neural network. However, only few theoretical\nresults regarding this quantity exist in the literature. In this paper, we\ninitiate the study of the Lipschitz constant of random ReLU neural networks,\ni.e., neural networks whose weights are chosen at random and which employ the\nReLU activation function. For shallow neural networks, we characterize the\nLipschitz constant up to an absolute numerical constant. Moreover, we extend\nour analysis to deep neural networks of sufficiently large width where we prove\nupper and lower bounds for the Lipschitz constant. These bounds match up to a\nlogarithmic factor that depends on the depth.",
          "link": "http://arxiv.org/abs/2311.01356",
          "publishedOn": "2023-11-04T00:42:37.243Z",
          "wordCount": null,
          "title": "On the Lipschitz constant of random neural networks. (arXiv:2311.01356v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alrashedy_K/0/1/0/all/0/1\">Kamel Alrashedy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hellendoorn_V/0/1/0/all/0/1\">Vincent J. Hellendoorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orso_A/0/1/0/all/0/1\">Alessandro Orso</a>",
          "description": "Pretrained models of code, such as CodeBERT and CodeT5, have become popular\nchoices for code understanding and generation tasks. Such models tend to be\nlarge and require commensurate volumes of training data, which are rarely\navailable for downstream tasks. Instead, it has become popular to train models\nwith far larger but less realistic datasets, such as functions with\nartificially injected bugs. Models trained on such data, however, tend to only\nperform well on similar data, while underperforming on real world programs. In\nthis paper, we conjecture that this discrepancy stems from the presence of\ndistracting samples that steer the model away from the real-world task\ndistribution. To investigate this conjecture, we propose an approach for\nidentifying the subsets of these large yet unrealistic datasets that are most\nsimilar to examples in real-world datasets based on their learned\nrepresentations. Our approach extracts high-dimensional embeddings of both\nreal-world and artificial programs using a neural model and scores artificial\nsamples based on their distance to the nearest real-world sample. We show that\ntraining on only the nearest, representationally most similar samples while\ndiscarding samples that are not at all similar in representations yields\nconsistent improvements across two popular pretrained models of code on two\ncode understanding tasks. Our results are promising, in that they show that\ntraining models on a representative subset of an unrealistic dataset can help\nus harness the power of large-scale synthetic data generation while preserving\ndownstream task performance. Finally, we highlight the limitations of applying\nAI models for predicting vulnerabilities and bugs in real-world applications",
          "link": "http://arxiv.org/abs/2311.00931",
          "publishedOn": "2023-11-04T00:42:37.196Z",
          "wordCount": null,
          "title": "Learning Defect Prediction from Unrealistic Data. (arXiv:2311.00931v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yurong Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burger_M/0/1/0/all/0/1\">Manuel Burger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1\">Gunnar R&#xe4;tsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuznetsova_R/0/1/0/all/0/1\">Rita Kuznetsova</a>",
          "description": "In research areas with scarce data, representation learning plays a\nsignificant role. This work aims to enhance representation learning for\nclinical time series by deriving universal embeddings for clinical features,\nsuch as heart rate and blood pressure. We use self-supervised training\nparadigms for language models to learn high-quality clinical feature\nembeddings, achieving a finer granularity than existing time-step and\npatient-level representation learning. We visualize the learnt embeddings via\nunsupervised dimension reduction techniques and observe a high degree of\nconsistency with prior clinical knowledge. We also evaluate the model\nperformance on the MIMIC-III benchmark and demonstrate the effectiveness of\nusing clinical feature embeddings. We publish our code online for replication.",
          "link": "http://arxiv.org/abs/2311.00768",
          "publishedOn": "2023-11-04T00:42:37.191Z",
          "wordCount": null,
          "title": "Language Model Training Paradigms for Clinical Feature Embeddings. (arXiv:2311.00768v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathiasen_A/0/1/0/all/0/1\">Alexander Mathiasen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helal_H/0/1/0/all/0/1\">Hatem Helal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klaser_K/0/1/0/all/0/1\">Kerstin Klaser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balanca_P/0/1/0/all/0/1\">Paul Balanca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dean_J/0/1/0/all/0/1\">Josef Dean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beaini_D/0/1/0/all/0/1\">Dominique Beaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fitzgibbon_A/0/1/0/all/0/1\">Andrew Fitzgibbon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1\">Dominic Masters</a>",
          "description": "The emergence of foundation models in Computer Vision and Natural Language\nProcessing have resulted in immense progress on downstream tasks. This progress\nwas enabled by datasets with billions of training examples. Similar benefits\nare yet to be unlocked for quantum chemistry, where the potential of deep\nlearning is constrained by comparatively small datasets with 100k to 20M\ntraining examples. These datasets are limited in size because the labels are\ncomputed using the accurate (but computationally demanding) predictions of\nDensity Functional Theory (DFT). Notably, prior DFT datasets were created using\nCPU supercomputers without leveraging hardware acceleration. In this paper, we\ntake a first step towards utilising hardware accelerators by introducing the\ndata generator PySCF$_{\\text{IPU}}$ using Intelligence Processing Units (IPUs).\nThis allowed us to create the dataset QM1B with one billion training examples\ncontaining 9-11 heavy atoms. We demonstrate that a simple baseline neural\nnetwork (SchNet 9M) improves its performance by simply increasing the amount of\ntraining data without additional inductive biases. To encourage future\nresearchers to use QM1B responsibly, we highlight several limitations of QM1B\nand emphasise the low-resolution of our DFT options, which also serves as\nmotivation for even larger, more accurate datasets. Code and dataset are\navailable on Github: this http URL",
          "link": "http://arxiv.org/abs/2311.01135",
          "publishedOn": "2023-11-04T00:42:37.150Z",
          "wordCount": null,
          "title": "Generating QM1B with PySCF$_{\\text{IPU}}$. (arXiv:2311.01135v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Ziqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guanlin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1\">Lifeng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weiyu Xu</a>",
          "description": "Finding optimal adversarial attack strategies is an important topic in\nreinforcement learning and the Markov decision process. Previous studies\nusually assume one all-knowing coordinator (attacker) for whom attacking\ndifferent recipient (victim) agents incurs uniform costs. However, in reality,\ninstead of using one limitless central attacker, the attacks often need to be\nperformed by distributed attack agents. We formulate the problem of performing\noptimal adversarial agent-to-agent attacks using distributed attack agents, in\nwhich we impose distinct cost constraints on each different attacker-victim\npair. We propose an optimal method integrating within-step static constrained\nattack-resource allocation optimization and between-step dynamic programming to\nachieve the optimal adversarial attack in a multi-agent system. Our numerical\nresults show that the proposed attacks can significantly reduce the rewards\nreceived by the attacked agents.",
          "link": "http://arxiv.org/abs/2311.00859",
          "publishedOn": "2023-11-04T00:42:37.070Z",
          "wordCount": null,
          "title": "Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems. (arXiv:2311.00859v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toyer_S/0/1/0/all/0/1\">Sam Toyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1\">Olivia Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendes_E/0/1/0/all/0/1\">Ethan Adrian Mendes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svegliato_J/0/1/0/all/0/1\">Justin Svegliato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bailey_L/0/1/0/all/0/1\">Luke Bailey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tiffany Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_I/0/1/0/all/0/1\">Isaac Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmaaroufi_K/0/1/0/all/0/1\">Karim Elmaaroufi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1\">Alan Ritter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1\">Stuart Russell</a>",
          "description": "While Large Language Models (LLMs) are increasingly being used in real-world\napplications, they remain vulnerable to prompt injection attacks: malicious\nthird party prompts that subvert the intent of the system designer. To help\nresearchers study this problem, we present a dataset of over 126,000 prompt\ninjection attacks and 46,000 prompt-based \"defenses\" against prompt injection,\nall created by players of an online game called Tensor Trust. To the best of\nour knowledge, this is currently the largest dataset of human-generated\nadversarial examples for instruction-following LLMs. The attacks in our dataset\nhave a lot of easily interpretable stucture, and shed light on the weaknesses\nof LLMs. We also use the dataset to create a benchmark for resistance to two\ntypes of prompt injection, which we refer to as prompt extraction and prompt\nhijacking. Our benchmark results show that many models are vulnerable to the\nattack strategies in the Tensor Trust dataset. Furthermore, we show that some\nattack strategies from the dataset generalize to deployed LLM-based\napplications, even though they have a very different set of constraints to the\ngame. We release all data and source code at https://tensortrust.ai/paper",
          "link": "http://arxiv.org/abs/2311.01011",
          "publishedOn": "2023-11-04T00:42:37.070Z",
          "wordCount": null,
          "title": "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game. (arXiv:2311.01011v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Futami_F/0/1/0/all/0/1\">Futoshi Futami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujisawa_M/0/1/0/all/0/1\">Masahiro Fujisawa</a>",
          "description": "We provide novel information-theoretic generalization bounds for stochastic\ngradient Langevin dynamics (SGLD) under the assumptions of smoothness and\ndissipativity, which are widely used in sampling and non-convex optimization\nstudies. Our bounds are time-independent and decay to zero as the sample size\nincreases, regardless of the number of iterations and whether the step size is\nfixed. Unlike previous studies, we derive the generalization error bounds by\nfocusing on the time evolution of the Kullback--Leibler divergence, which is\nrelated to the stability of datasets and is the upper bound of the mutual\ninformation between output parameters and an input dataset. Additionally, we\nestablish the first information-theoretic generalization bound when the\ntraining and test loss are the same by showing that a loss function of SGLD is\nsub-exponential. This bound is also time-independent and removes the\nproblematic step size dependence in existing work, leading to an improved\nexcess risk bound by combining our analysis with the existing non-convex\noptimization error bounds.",
          "link": "http://arxiv.org/abs/2311.01046",
          "publishedOn": "2023-11-04T00:42:37.070Z",
          "wordCount": null,
          "title": "Time-Independent Information-Theoretic Generalization Bounds for SGLD. (arXiv:2311.01046v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mhamed_J/0/1/0/all/0/1\">Jaafar Mhamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shangding Gu</a>",
          "description": "Incorporating safety is an essential prerequisite for broadening the\npractical applications of reinforcement learning in real-world scenarios. To\ntackle this challenge, Constrained Markov Decision Processes (CMDPs) are\nleveraged, which introduce a distinct cost function representing safety\nviolations. In CMDPs' settings, Lagrangian relaxation technique has been\nemployed in previous algorithms to convert constrained optimization problems\ninto unconstrained dual problems. However, these algorithms may inaccurately\npredict unsafe behavior, resulting in instability while learning the Lagrange\nmultiplier. This study introduces a novel safe reinforcement learning\nalgorithm, Safety Critic Policy Optimization (SCPO). In this study, we define\nthe safety critic, a mechanism that nullifies rewards obtained through\nviolating safety constraints. Furthermore, our theoretical analysis indicates\nthat the proposed algorithm can automatically balance the trade-off between\nadhering to safety constraints and maximizing rewards. The effectiveness of the\nSCPO algorithm is empirically validated by benchmarking it against strong\nbaselines.",
          "link": "http://arxiv.org/abs/2311.00880",
          "publishedOn": "2023-11-04T00:42:37.069Z",
          "wordCount": null,
          "title": "SCPO: Safe Reinforcement Learning with Safety Critic Policy Optimization. (arXiv:2311.00880v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.14274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luan_S/0/1/0/all/0/1\">Sitao Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_C/0/1/0/all/0/1\">Chenqing Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Minkai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1\">Qincheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiaqi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xiao-Wen Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1\">Jure Leskovec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>",
          "description": "Homophily principle, i.e., nodes with the same labels are more likely to be\nconnected, has been believed to be the main reason for the performance\nsuperiority of Graph Neural Networks (GNNs) over Neural Networks on node\nclassification tasks. Recent research suggests that, even in the absence of\nhomophily, the advantage of GNNs still exists as long as nodes from the same\nclass share similar neighborhood patterns. However, this argument only\nconsiders intra-class Node Distinguishability (ND) but neglects inter-class ND,\nwhich provides incomplete understanding of homophily on GNNs. In this paper, we\nfirst demonstrate such deficiency with examples and argue that an ideal\nsituation for ND is to have smaller intra-class ND than inter-class ND. To\nformulate this idea and study ND deeply, we propose Contextual Stochastic Block\nModel for Homophily (CSBM-H) and define two metrics, Probabilistic Bayes Error\n(PBE) and negative generalized Jeffreys divergence, to quantify ND. With the\nmetrics, we visualize and analyze how graph filters, node degree distributions\nand class variances influence ND, and investigate the combined effect of intra-\nand inter-class ND. Besides, we discovered the mid-homophily pitfall, which\noccurs widely in graph datasets. Furthermore, we verified that, in real-work\ntasks, the superiority of GNNs is indeed closely related to both intra- and\ninter-class ND regardless of homophily levels. Grounded in this observation, we\npropose a new hypothesis-testing based performance metric beyond homophily,\nwhich is non-linear, feature-based and can provide statistical threshold value\nfor GNNs' the superiority. Experiments indicate that it is significantly more\neffective than the existing homophily metrics on revealing the advantage and\ndisadvantage of graph-aware modes on both synthetic and benchmark real-world\ndatasets.",
          "link": "http://arxiv.org/abs/2304.14274",
          "publishedOn": "2023-11-04T00:42:37.069Z",
          "wordCount": null,
          "title": "When Do Graph Neural Networks Help with Node Classification? Investigating the Impact of Homophily Principle on Node Distinguishability. (arXiv:2304.14274v3 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Andy Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haohan Wang</a>",
          "description": "We propose a conceptually simple and lightweight framework for improving the\nrobustness of vision models through the combination of knowledge distillation\nand data augmentation. We address the conjecture that larger models do not make\nfor better teachers by showing strong gains in out-of-distribution robustness\nwhen distilling from pretrained foundation models. Following this finding, we\npropose Discrete Adversarial Distillation (DAD), which leverages a robust\nteacher to generate adversarial examples and a VQGAN to discretize them,\ncreating more informative samples than standard data augmentation techniques.\nWe provide a theoretical framework for the use of a robust teacher in the\nknowledge distillation with data augmentation setting and demonstrate strong\ngains in out-of-distribution robustness and clean accuracy across different\nstudent architectures. Notably, our method adds minor computational overhead\ncompared to similar techniques and can be easily combined with other data\naugmentations for further improvements.",
          "link": "http://arxiv.org/abs/2311.01441",
          "publishedOn": "2023-11-04T00:42:36.941Z",
          "wordCount": null,
          "title": "Distilling Out-of-Distribution Robustness from Vision-Language Foundation Models. (arXiv:2311.01441v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01205",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kummer_L/0/1/0/all/0/1\">Lorenz Kummer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moustafa_S/0/1/0/all/0/1\">Samir Moustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kriege_N/0/1/0/all/0/1\">Nils N. Kriege</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gansterer_W/0/1/0/all/0/1\">Wilfried N. Gansterer</a>",
          "description": "Prior attacks on graph neural networks have mostly focused on graph poisoning\nand evasion, neglecting the network's weights and biases. Traditional\nweight-based fault injection attacks, such as bit flip attacks used for\nconvolutional neural networks, do not consider the unique properties of graph\nneural networks. We propose the Injectivity Bit Flip Attack, the first bit flip\nattack designed specifically for graph neural networks. Our attack targets the\nlearnable neighborhood aggregation functions in quantized message passing\nneural networks, degrading their ability to distinguish graph structures and\nlosing the expressivity of the Weisfeiler-Lehman test. Our findings suggest\nthat exploiting mathematical properties specific to certain graph neural\nnetwork architectures can significantly increase their vulnerability to bit\nflip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive\nGraph Isomorphism Networks trained on various graph property prediction\ndatasets to random output by flipping only a small fraction of the network's\nbits, demonstrating its higher destructive power compared to a bit flip attack\ntransferred from convolutional neural networks. Our attack is transparent and\nmotivated by theoretical insights which are confirmed by extensive empirical\nresults.",
          "link": "http://arxiv.org/abs/2311.01205",
          "publishedOn": "2023-11-04T00:42:36.809Z",
          "wordCount": null,
          "title": "Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent. (arXiv:2311.01205v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1\">Marco Valentino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meadows_J/0/1/0/all/0/1\">Jordan Meadows</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andr&#xe9; Freitas</a>",
          "description": "This paper investigates the possibility of approximating multiple\nmathematical operations in latent space for expression derivation. To this end,\nwe introduce different multi-operational representation paradigms, modelling\nmathematical operations as explicit geometric transformations. By leveraging a\nsymbolic engine, we construct a large-scale dataset comprising 1.7M derivation\nsteps stemming from 61K premises and 6 operators, analysing the properties of\neach paradigm when instantiated with state-of-the-art neural encoders.\nSpecifically, we investigate how different encoding mechanisms can approximate\nequational reasoning in latent space, exploring the trade-off between learning\ndifferent operators and specialising within single operations, as well as the\nability to support multi-step derivations and out-of-distribution\ngeneralisation. Our empirical analysis reveals that the multi-operational\nparadigm is crucial for disentangling different operators, while discriminating\nthe conclusions for a single operation is achievable in the original expression\nencoder. Moreover, we show that architectural choices can heavily affect the\ntraining dynamics, structural organisation, and generalisation of the latent\nspace, resulting in significant variations across paradigms and classes of\nencoders.",
          "link": "http://arxiv.org/abs/2311.01230",
          "publishedOn": "2023-11-04T00:42:36.716Z",
          "wordCount": null,
          "title": "Multi-Operational Mathematical Derivations in Latent Space. (arXiv:2311.01230v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00811",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Leng_J/0/1/0/all/0/1\">Jiaqi Leng</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zheng_Y/0/1/0/all/0/1\">Yufan Zheng</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wu_X/0/1/0/all/0/1\">Xiaodi Wu</a>",
          "description": "In this paper, we identify a family of nonconvex continuous optimization\ninstances, each $d$-dimensional instance with $2^d$ local minima, to\ndemonstrate a quantum-classical performance separation. Specifically, we prove\nthat the recently proposed Quantum Hamiltonian Descent (QHD) algorithm [Leng et\nal., arXiv:2303.01471] is able to solve any $d$-dimensional instance from this\nfamily using $\\widetilde{\\mathcal{O}}(d^3)$ quantum queries to the function\nvalue and $\\widetilde{\\mathcal{O}}(d^4)$ additional 1-qubit and 2-qubit\nelementary quantum gates. On the other side, a comprehensive empirical study\nsuggests that representative state-of-the-art classical optimization\nalgorithms/solvers (including Gurobi) would require a super-polynomial time to\nsolve such optimization instances.",
          "link": "http://arxiv.org/abs/2311.00811",
          "publishedOn": "2023-11-04T00:42:36.693Z",
          "wordCount": null,
          "title": "A quantum-classical performance separation in nonconvex optimization. (arXiv:2311.00811v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fabian_Z/0/1/0/all/0/1\">Zalan Fabian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_Z/0/1/0/all/0/1\">Zhongqi Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuanhan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_A/0/1/0/all/0/1\">Andr&#xe9;s Hern&#xe1;ndez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montes_Rojas_A/0/1/0/all/0/1\">Andr&#xe9;s Montes-Rojas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Escucha_R/0/1/0/all/0/1\">Rafael Escucha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siabatto_L/0/1/0/all/0/1\">Laura Siabatto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Link_A/0/1/0/all/0/1\">Andr&#xe9;s Link</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1\">Pablo Arbel&#xe1;ez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodhia_R/0/1/0/all/0/1\">Rahul Dodhia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1\">Juan Lavista Ferres</a>",
          "description": "Due to deteriorating environmental conditions and increasing human activity,\nconservation efforts directed towards wildlife is crucial. Motion-activated\ncamera traps constitute an efficient tool for tracking and monitoring wildlife\npopulations across the globe. Supervised learning techniques have been\nsuccessfully deployed to analyze such imagery, however training such techniques\nrequires annotations from experts. Reducing the reliance on costly labelled\ndata therefore has immense potential in developing large-scale wildlife\ntracking solutions with markedly less human labor. In this work we propose\nWildMatch, a novel zero-shot species classification framework that leverages\nmultimodal foundation models. In particular, we instruction tune\nvision-language models to generate detailed visual descriptions of camera trap\nimages using similar terminology to experts. Then, we match the generated\ncaption to an external knowledge base of descriptions in order to determine the\nspecies in a zero-shot manner. We investigate techniques to build instruction\ntuning datasets for detailed animal description generation and propose a novel\nknowledge augmentation technique to enhance caption quality. We demonstrate the\nperformance of WildMatch on a new camera trap dataset collected in the\nMagdalena Medio region of Colombia.",
          "link": "http://arxiv.org/abs/2311.01064",
          "publishedOn": "2023-11-04T00:42:36.670Z",
          "wordCount": null,
          "title": "Multimodal Foundation Models for Zero-shot Animal Species Recognition in Camera Trap Images. (arXiv:2311.01064v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00860",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leng_K/0/1/0/all/0/1\">Kuangdai Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shankar_M/0/1/0/all/0/1\">Mallikarjun Shankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiyagalingam_J/0/1/0/all/0/1\">Jeyan Thiyagalingam</a>",
          "description": "Automatic differentiation (AD) is a critical step in physics-informed machine\nlearning, required for computing the high-order derivatives of network output\nw.r.t. coordinates. In this paper, we present a novel and lightweight algorithm\nto conduct such AD for physics-informed operator learning, as we call the trick\nof Zero Coordinate Shift (ZCS). Instead of making all sampled coordinates leaf\nvariables, ZCS introduces only one scalar-valued leaf variable for each spatial\nor temporal dimension, leading to a game-changing performance leap by\nsimplifying the wanted derivatives from \"many-roots-many-leaves\" to\n\"one-root-many-leaves\". ZCS is easy to implement with current deep learning\nlibraries; our own implementation is by extending the DeepXDE package. We carry\nout a comprehensive benchmark analysis and several case studies, training\nphysics-informed DeepONets to solve partial differential equations (PDEs)\nwithout data. The results show that ZCS has persistently brought down GPU\nmemory consumption and wall time for training by an order of magnitude, with\nthe savings increasing with problem scale (i.e., number of functions, number of\npoints and order of PDE). As a low-level optimisation, ZCS entails no\nrestrictions on data, physics (PDEs) or network architecture and does not\ncompromise training results from any aspect.",
          "link": "http://arxiv.org/abs/2311.00860",
          "publishedOn": "2023-11-04T00:42:36.647Z",
          "wordCount": null,
          "title": "Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning. (arXiv:2311.00860v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00775",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Schneider_A/0/1/0/all/0/1\">Aaron David Schneider</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Molliere_P/0/1/0/all/0/1\">Paul Molli&#xe8;re</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Louppe_G/0/1/0/all/0/1\">Gilles Louppe</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Carone_L/0/1/0/all/0/1\">Ludmila Carone</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Jorgensen_U/0/1/0/all/0/1\">Uffe Gr&#xe5;e J&#xf8;rgensen</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Decin_L/0/1/0/all/0/1\">Leen Decin</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Helling_C/0/1/0/all/0/1\">Christiane Helling</a>",
          "description": "To understand high precision observations of exoplanets and brown dwarfs, we\nneed detailed and complex general circulation models (GCMs) that incorporate\nhydrodynamics, chemistry, and radiation. In this study, we specifically examine\nthe coupling between chemistry and radiation in GCMs and compare different\nmethods for mixing opacities of different chemical species in the correlated-k\nassumption, when equilibrium chemistry cannot be assumed. We propose a fast\nmachine learning method based on DeepSets (DS), which effectively combines\nindividual correlated-k opacities (k-tables). We evaluate the DS method\nalongside other published methods like adaptive equivalent extinction (AEE) and\nrandom overlap with rebinning and resorting (RORR). We integrate these mixing\nmethods into our GCM (expeRT/MITgcm) and assess their accuracy and performance\nfor the example of the hot Jupiter HD~209458 b. Our findings indicate that the\nDS method is both accurate and efficient for GCM usage, whereas RORR is too\nslow. Additionally, we observe that the accuracy of AEE depends on its specific\nimplementation and may introduce numerical issues in achieving radiative\ntransfer solution convergence. We then apply the DS mixing method in a\nsimplified chemical disequilibrium situation, where we model the rainout of TiO\nand VO, and confirm that the rainout of TiO and VO would hinder the formation\nof a stratosphere. To further expedite the development of consistent\ndisequilibrium chemistry calculations in GCMs, we provide documentation and\ncode for coupling the DS mixing method with correlated-k radiative transfer\nsolvers. The DS method has been extensively tested to be accurate enough for\nGCMs, however, other methods might be needed for accelerating atmospheric\nretrievals.",
          "link": "http://arxiv.org/abs/2311.00775",
          "publishedOn": "2023-11-04T00:42:36.631Z",
          "wordCount": null,
          "title": "Harnessing machine learning for accurate treatment of overlapping opacity species in GCMs. (arXiv:2311.00775v1 [astro-ph.EP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wang-Tao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1\">Zhao Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1\">Ling Tian</a>",
          "description": "Continuous-time long-term event prediction plays an important role in many\napplication scenarios. Most existing works rely on autoregressive frameworks to\npredict event sequences, which suffer from error accumulation, thus\ncompromising prediction quality. Inspired by the success of denoising diffusion\nprobabilistic models, we propose a diffusion-based non-autoregressive temporal\npoint process model for long-term event prediction in continuous time. Instead\nof generating events one at a time in an autoregressive way, our model predicts\nthe future event sequence entirely as a whole. In order to perform diffusion\nprocesses on event sequences, we develop a bidirectional map between target\nevent sequences and the Euclidean vector space. Furthermore, we design a novel\ndenoising network to capture both sequential and contextual features for better\nsample quality. Extensive experiments are conducted to prove the superiority of\nour proposed model over state-of-the-art methods on long-term event prediction\nin continuous time. To the best of our knowledge, this is the first work to\napply diffusion methods to long-term event prediction problems.",
          "link": "http://arxiv.org/abs/2311.01033",
          "publishedOn": "2023-11-04T00:42:36.594Z",
          "wordCount": null,
          "title": "Non-Autoregressive Diffusion-based Temporal Point Processes for Continuous-Time Long-Term Event Prediction. (arXiv:2311.01033v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00927",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pham_T/0/1/0/all/0/1\">Thong Pham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shimizu_S/0/1/0/all/0/1\">Shohei Shimizu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hino_H/0/1/0/all/0/1\">Hideitsu Hino</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1\">Tam Le</a>",
          "description": "We consider the problem of estimating the counterfactual joint distribution\nof multiple quantities of interests (e.g., outcomes) in a multivariate causal\nmodel extended from the classical difference-in-difference design. Existing\nmethods for this task either ignore the correlation structures among dimensions\nof the multivariate outcome by considering univariate causal models on each\ndimension separately and hence produce incorrect counterfactual distributions,\nor poorly scale even for moderate-size datasets when directly dealing with such\nmultivariate causal model. We propose a method that alleviates both issues\nsimultaneously by leveraging a robust latent one-dimensional subspace of the\noriginal high-dimension space and exploiting the efficient estimation from the\nunivariate causal model on such space. Since the construction of the\none-dimensional subspace uses information from all the dimensions, our method\ncan capture the correlation structures and produce good estimates of the\ncounterfactual distribution. We demonstrate the advantages of our approach over\nexisting methods on both synthetic and real-world data.",
          "link": "http://arxiv.org/abs/2311.00927",
          "publishedOn": "2023-11-04T00:42:36.552Z",
          "wordCount": null,
          "title": "Scalable Counterfactual Distribution Estimation in Multivariate Causal Models. (arXiv:2311.00927v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khraisha_Q/0/1/0/all/0/1\">Qusai Khraisha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Put_S/0/1/0/all/0/1\">Sophie Put</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kappenberg_J/0/1/0/all/0/1\">Johanna Kappenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warraitch_A/0/1/0/all/0/1\">Azza Warraitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadfield_K/0/1/0/all/0/1\">Kristin Hadfield</a>",
          "description": "Systematic reviews are vital for guiding practice, research, and policy, yet\nthey are often slow and labour-intensive. Large language models (LLMs) could\noffer a way to speed up and automate systematic reviews, but their performance\nin such tasks has not been comprehensively evaluated against humans, and no\nstudy has tested GPT-4, the biggest LLM so far. This pre-registered study\nevaluates GPT-4's capability in title/abstract screening, full-text review, and\ndata extraction across various literature types and languages using a\n'human-out-of-the-loop' approach. Although GPT-4 had accuracy on par with human\nperformance in most tasks, results were skewed by chance agreement and dataset\nimbalance. After adjusting for these, there was a moderate level of performance\nfor data extraction, and - barring studies that used highly reliable prompts -\nscreening performance levelled at none to moderate for different stages and\nlanguages. When screening full-text literature using highly reliable prompts,\nGPT-4's performance was 'almost perfect.' Penalising GPT-4 for missing key\nstudies using highly reliable prompts improved its performance even more. Our\nfindings indicate that, currently, substantial caution should be used if LLMs\nare being used to conduct systematic reviews, but suggest that, for certain\nsystematic review tasks delivered under reliable prompts, LLMs can rival human\nperformance.",
          "link": "http://arxiv.org/abs/2310.17526",
          "publishedOn": "2023-10-28T00:41:33.643Z",
          "wordCount": 816,
          "title": "Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages. (arXiv:2310.17526v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xingchen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mithun_N/0/1/0/all/0/1\">Niluthpol Chowdhury Mithun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajvanshi_A/0/1/0/all/0/1\">Abhinav Rajvanshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiu_H/0/1/0/all/0/1\">Han-Pang Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samarasekera_S/0/1/0/all/0/1\">Supun Samarasekera</a>",
          "description": "Deep learning-based solutions for semantic segmentation suffer from\nsignificant performance degradation when tested on data with different\ncharacteristics than what was used during the training. Adapting the models\nusing annotated data from the new domain is not always practical. Unsupervised\nDomain Adaptation (UDA) approaches are crucial in deploying these models in the\nactual operating conditions. Recent state-of-the-art (SOTA) UDA methods employ\na teacher-student self-training approach, where a teacher model is used to\ngenerate pseudo-labels for the new data which in turn guide the training\nprocess of the student model. Though this approach has seen a lot of success,\nit suffers from the issue of noisy pseudo-labels being propagated in the\ntraining process. To address this issue, we propose an auxiliary pseudo-label\nrefinement network (PRN) for online refining of the pseudo labels and also\nlocalizing the pixels whose predicted labels are likely to be noisy. Being able\nto improve the quality of pseudo labels and select highly reliable ones, PRN\nhelps self-training of segmentation models to be robust against pseudo label\nnoise propagation during different stages of adaptation. We evaluate our\napproach on benchmark datasets with three different domain shifts, and our\napproach consistently performs significantly better than the previous\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2310.16979",
          "publishedOn": "2023-10-28T00:41:33.567Z",
          "wordCount": 746,
          "title": "Unsupervised Domain Adaptation for Semantic Segmentation with Pseudo Label Self-Refinement. (arXiv:2310.16979v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dass_S/0/1/0/all/0/1\">Shivin Dass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1\">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>",
          "description": "Robot learning methods have recently made great strides, but generalization\nand robustness challenges still hinder their widespread deployment. Failing to\ndetect and address potential failures renders state-of-the-art learning systems\nnot combat-ready for high-stakes tasks. Recent advances in interactive\nimitation learning have presented a promising framework for human-robot\nteaming, enabling the robots to operate safely and continually improve their\nperformances over long-term deployments. Nonetheless, existing methods\ntypically require constant human supervision and preemptive feedback, limiting\ntheir practicality in realistic domains. This work aims to endow a robot with\nthe ability to monitor and detect errors during task execution. We introduce a\nmodel-based runtime monitoring algorithm that learns from deployment data to\ndetect system anomalies and anticipate failures. Unlike prior work that cannot\nforesee future failures or requires failure experiences for training, our\nmethod learns a latent-space dynamics model and a failure classifier, enabling\nour method to simulate future action outcomes and detect out-of-distribution\nand high-risk states preemptively. We train our method within an interactive\nimitation learning framework, where it continually updates the model from the\nexperiences of the human-robot team collected using trustworthy deployments.\nConsequently, our method reduces the human workload needed over time while\nensuring reliable task execution. Our method outperforms the baselines across\nsystem-level and unit-test metrics, with 23% and 40% higher success rates in\nsimulation and on physical hardware, respectively. More information at\nhttps://ut-austin-rpl.github.io/sirius-runtime-monitor/",
          "link": "http://arxiv.org/abs/2310.17552",
          "publishedOn": "2023-10-28T00:41:33.532Z",
          "wordCount": 748,
          "title": "Model-Based Runtime Monitoring with Interactive Imitation Learning. (arXiv:2310.17552v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Okoroafor_P/0/1/0/all/0/1\">Princewill Okoroafor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinberg_R/0/1/0/all/0/1\">Robert Kleinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>",
          "description": "Predictive models in ML need to be trustworthy and reliable, which often at\nthe very least means outputting calibrated probabilities. This can be\nparticularly difficult to guarantee in the online prediction setting when the\noutcome sequence can be generated adversarially. In this paper we introduce a\ntechnique using Blackwell's approachability theorem for taking an online\npredictive model which might not be calibrated and transforming its predictions\nto calibrated predictions without much increase to the loss of the original\nmodel. Our proposed algorithm achieves calibration and accuracy at a faster\nrate than existing techniques arXiv:1607.03594 and is the first algorithm to\noffer a flexible tradeoff between calibration error and accuracy in the online\nsetting. We demonstrate this by characterizing the space of jointly achievable\ncalibration and regret using our technique.",
          "link": "http://arxiv.org/abs/2310.17002",
          "publishedOn": "2023-10-28T00:41:33.525Z",
          "wordCount": 656,
          "title": "Faster Recalibration of an Online Predictor via Approachability. (arXiv:2310.17002v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16870",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yunsheng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Juanwu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1\">Can Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ZHao_S/0/1/0/all/0/1\">Sicheng ZHao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wenqian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziran Wang</a>",
          "description": "Vehicle-to-vehicle (V2V) communications have greatly enhanced the perception\ncapabilities of connected and automated vehicles (CAVs) by enabling information\nsharing to \"see through the occlusions\", resulting in significant performance\nimprovements. However, developing and training complex multi-agent perception\nmodels from scratch can be expensive and unnecessary when existing single-agent\nmodels show remarkable generalization capabilities. In this paper, we propose a\nnew framework termed MACP, which equips a single-agent pre-trained model with\ncooperation capabilities. We approach this objective by identifying the key\nchallenges of shifting from single-agent to cooperative settings, adapting the\nmodel by freezing most of its parameters and adding a few lightweight modules.\nWe demonstrate in our experiments that the proposed framework can effectively\nutilize cooperative observations and outperform other state-of-the-art\napproaches in both simulated and real-world cooperative perception benchmarks\nwhile requiring substantially fewer tunable parameters with reduced\ncommunication costs. Our source code is available at\nhttps://github.com/PurdueDigitalTwin/MACP.",
          "link": "http://arxiv.org/abs/2310.16870",
          "publishedOn": "2023-10-28T00:41:33.475Z",
          "wordCount": 717,
          "title": "MACP: Efficient Model Adaptation for Cooperative Perception. (arXiv:2310.16870v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2205.15403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Asadulaev_A/0/1/0/all/0/1\">Arip Asadulaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1\">Alexander Korotin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Egiazarian_V/0/1/0/all/0/1\">Vage Egiazarian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mokrov_P/0/1/0/all/0/1\">Petr Mokrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>",
          "description": "We introduce a novel neural network-based algorithm to compute optimal\ntransport (OT) plans for general cost functionals. In contrast to common\nEuclidean costs, i.e., $\\ell^1$ or $\\ell^2$, such functionals provide more\nflexibility and allow using auxiliary information, such as class labels, to\nconstruct the required transport map. Existing methods for general costs are\ndiscrete and have limitations in practice, i.e. they do not provide an\nout-of-sample estimation. We address the challenge of designing a continuous OT\napproach for general costs that generalizes to new data points in\nhigh-dimensional spaces, such as images. Additionally, we provide the\ntheoretical error analysis for our recovered transport plans. As an\napplication, we construct a cost functional to map data distributions while\npreserving the class-wise structure.",
          "link": "http://arxiv.org/abs/2205.15403",
          "publishedOn": "2023-10-28T00:41:30.643Z",
          "wordCount": 674,
          "title": "Neural Optimal Transport with General Cost Functionals. (arXiv:2205.15403v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2106.11959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gorishniy_Y/0/1/0/all/0/1\">Yury Gorishniy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubachev_I/0/1/0/all/0/1\">Ivan Rubachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khrulkov_V/0/1/0/all/0/1\">Valentin Khrulkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1\">Artem Babenko</a>",
          "description": "The existing literature on deep learning for tabular data proposes a wide\nrange of novel architectures and reports competitive results on various\ndatasets. However, the proposed models are usually not properly compared to\neach other and existing works often use different benchmarks and experiment\nprotocols. As a result, it is unclear for both researchers and practitioners\nwhat models perform best. Additionally, the field still lacks effective\nbaselines, that is, the easy-to-use models that provide competitive performance\nacross different problems.\n\nIn this work, we perform an overview of the main families of DL architectures\nfor tabular data and raise the bar of baselines in tabular DL by identifying\ntwo simple and powerful deep architectures. The first one is a ResNet-like\narchitecture which turns out to be a strong baseline that is often missing in\nprior works. The second model is our simple adaptation of the Transformer\narchitecture for tabular data, which outperforms other solutions on most tasks.\nBoth models are compared to many existing architectures on a diverse set of\ntasks under the same training and tuning protocols. We also compare the best DL\nmodels with Gradient Boosted Decision Trees and conclude that there is still no\nuniversally superior solution.",
          "link": "http://arxiv.org/abs/2106.11959",
          "publishedOn": "2023-10-28T00:41:30.630Z",
          "wordCount": 795,
          "title": "Revisiting Deep Learning Models for Tabular Data. (arXiv:2106.11959v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2009.01742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_G/0/1/0/all/0/1\">Guanhua Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ward_O/0/1/0/all/0/1\">Owen G. Ward</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1\">Tian Zheng</a>",
          "description": "A common goal in network modeling is to uncover the latent community\nstructure present among nodes. For many real-world networks, the true\nconnections consist of events arriving as streams, which are then aggregated to\nform edges, ignoring the dynamic temporal component. A natural way to take\naccount of these temporal dynamics of interactions is to use point processes as\nthe foundation of network models for community detection. Computational\ncomplexity hampers the scalability of such approaches to large sparse networks.\nTo circumvent this challenge, we propose a fast online variational inference\nalgorithm for estimating the latent structure underlying dynamic event arrivals\non a network, using continuous-time point process latent network models. We\ndescribe this procedure for networks models capturing community structure. This\nstructure can be learned as new events are observed on the network, updating\nthe inferred community assignments. We investigate the theoretical properties\nof such an inference scheme, and provide regret bounds on the loss function of\nthis procedure. The proposed inference procedure is then thoroughly compared,\nusing both simulation studies and real data, to non-online variants. We\ndemonstrate that online inference can obtain comparable performance, in terms\nof community recovery, to non-online variants, while realising computational\ngains. Our proposed inference framework can also be readily modified to\nincorporate other popular network structures.",
          "link": "http://arxiv.org/abs/2009.01742",
          "publishedOn": "2023-10-28T00:41:30.615Z",
          "wordCount": 807,
          "title": "Online Estimation and Community Detection of Network Point Processes for Event Streams. (arXiv:2009.01742v3 [cs.SI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.10813",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bian_Y/0/1/0/all/0/1\">Yijun Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_A/0/1/0/all/0/1\">Anqi Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nanguang Chen</a>",
          "description": "The concern about underlying discrimination hidden in machine learning (ML)\nmodels is increasing, as ML systems have been widely applied in more and more\nreal-world scenarios and any discrimination hidden in them will directly affect\nhuman life. Many techniques have been developed to enhance fairness including\ncommonly-used group fairness measures and several fairness-aware methods\ncombining ensemble learning. However, existing fairness measures can only focus\non one aspect -- either group or individual fairness, and the hard\ncompatibility among them indicates a possibility of remaining biases even if\none of them is satisfied. Moreover, existing mechanisms to boost fairness\nusually present empirical results to show validity, yet few of them discuss\nwhether fairness can be boosted with certain theoretical guarantees. To address\nthese issues, we propose a fairness quality measure named discriminative risk\nto reflect both individual and group fairness aspects. Furthermore, we\ninvestigate the properties of the proposed measure and propose first- and\nsecond-order oracle bounds to show that fairness can be boosted via ensemble\ncombination with theoretical learning guarantees. The analysis is suitable for\nboth binary and multi-class classification. A pruning method is also proposed\nto utilise our proposed measure and comprehensive experiments are conducted to\nevaluate the effectiveness of the proposed methods.",
          "link": "http://arxiv.org/abs/2301.10813",
          "publishedOn": "2023-10-28T00:41:30.608Z",
          "wordCount": 778,
          "title": "Increasing Fairness via Combination with Learning Guarantees. (arXiv:2301.10813v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.10485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minseon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ha_H/0/1/0/all/0/1\">Hyeonjeong Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dong Bok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Despite the success on few-shot learning problems, most meta-learned models\nonly focus on achieving good performance on clean examples and thus easily\nbreak down when given adversarially perturbed samples. While some recent works\nhave shown that a combination of adversarial learning and meta-learning could\nenhance the robustness of a meta-learner against adversarial attacks, they fail\nto achieve generalizable adversarial robustness to unseen domains and tasks,\nwhich is the ultimate goal of meta-learning. To address this challenge, we\npropose a novel meta-adversarial multi-view representation learning framework\nwith dual encoders. Specifically, we introduce the discrepancy across the two\ndifferently augmented samples of the same data instance by first updating the\nencoder parameters with them and further imposing a novel label-free\nadversarial attack to maximize their discrepancy. Then, we maximize the\nconsistency across the views to learn transferable robust representations\nacross domains and tasks. Through experimental validation on multiple\nbenchmarks, we demonstrate the effectiveness of our framework on few-shot\nlearning tasks from unseen domains, achieving over 10\\% robust accuracy\nimprovements against previous adversarial meta-learning baselines.",
          "link": "http://arxiv.org/abs/2210.10485",
          "publishedOn": "2023-10-28T00:41:30.586Z",
          "wordCount": 733,
          "title": "Learning Transferable Adversarial Robust Representations via Multi-view Consistency. (arXiv:2210.10485v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.13534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_T/0/1/0/all/0/1\">Tiancheng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junyan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>",
          "description": "We study the problem of designing adaptive multi-armed bandit algorithms that\nperform optimally in both the stochastic setting and the adversarial setting\nsimultaneously (often known as a best-of-both-world guarantee). A line of\nrecent works shows that when configured and analyzed properly, the\nFollow-the-Regularized-Leader (FTRL) algorithm, originally designed for the\nadversarial setting, can in fact optimally adapt to the stochastic setting as\nwell. Such results, however, critically rely on an assumption that there exists\none unique optimal arm. Recently, Ito (2021) took the first step to remove such\nan undesirable uniqueness assumption for one particular FTRL algorithm with the\n$\\frac{1}{2}$-Tsallis entropy regularizer. In this work, we significantly\nimprove and generalize this result, showing that uniqueness is unnecessary for\nFTRL with a broad family of regularizers and a new learning rate schedule. For\nsome regularizers, our regret bounds also improve upon prior results even when\nuniqueness holds. We further provide an application of our results to the\ndecoupled exploration and exploitation problem, demonstrating that our\ntechniques are broadly applicable.",
          "link": "http://arxiv.org/abs/2302.13534",
          "publishedOn": "2023-10-28T00:41:30.580Z",
          "wordCount": 754,
          "title": "Improved Best-of-Both-Worlds Guarantees for Multi-Armed Bandits: FTRL with General Regularizers and Multiple Optimal Arms. (arXiv:2302.13534v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.03654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shuai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhenfeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhizhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Youru Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yao Zhao</a>",
          "description": "Graph neural networks (GNNs) have shown remarkable performance on homophilic\ngraph data while being far less impressive when handling non-homophilic graph\ndata due to the inherent low-pass filtering property of GNNs. In general, since\nreal-world graphs are often complex mixtures of diverse subgraph patterns,\nlearning a universal spectral filter on the graph from the global perspective\nas in most current works may still suffer from great difficulty in adapting to\nthe variation of local patterns. On the basis of the theoretical analysis of\nlocal patterns, we rethink the existing spectral filtering methods and propose\nthe node-oriented spectral filtering for graph neural network (namely NFGNN).\nBy estimating the node-oriented spectral filter for each node, NFGNN is\nprovided with the capability of precise local node positioning via the\ngeneralized translated operator, thus discriminating the variations of local\nhomophily patterns adaptively. Meanwhile, the utilization of\nre-parameterization brings a good trade-off between global consistency and\nlocal sensibility for learning the node-oriented spectral filters. Furthermore,\nwe theoretically analyze the localization property of NFGNN, demonstrating that\nthe signal after adaptive filtering is still positioned around the\ncorresponding node. Extensive experimental results demonstrate that the\nproposed NFGNN achieves more favorable performance.",
          "link": "http://arxiv.org/abs/2212.03654",
          "publishedOn": "2023-10-28T00:41:30.574Z",
          "wordCount": 761,
          "title": "Node-oriented Spectral Filtering for Graph Neural Networks. (arXiv:2212.03654v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.17218",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Straub_V/0/1/0/all/0/1\">Vincent J. Straub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morgan_D/0/1/0/all/0/1\">Deborah Morgan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bright_J/0/1/0/all/0/1\">Jonathan Bright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Margetts_H/0/1/0/all/0/1\">Helen Margetts</a>",
          "description": "Recent advances in artificial intelligence (AI), especially in generative\nlanguage modelling, hold the promise of transforming government. Given the\nadvanced capabilities of new AI systems, it is critical that these are embedded\nusing standard operational procedures, clear epistemic criteria, and behave in\nalignment with the normative expectations of society. Scholars in multiple\ndomains have subsequently begun to conceptualize the different forms that AI\napplications may take, highlighting both their potential benefits and pitfalls.\nHowever, the literature remains fragmented, with researchers in social science\ndisciplines like public administration and political science, and the\nfast-moving fields of AI, ML, and robotics, all developing concepts in relative\nisolation. Although there are calls to formalize the emerging study of AI in\ngovernment, a balanced account that captures the full depth of theoretical\nperspectives needed to understand the consequences of embedding AI into a\npublic sector context is lacking. Here, we unify efforts across social and\ntechnical disciplines by first conducting an integrative literature review to\nidentify and cluster 69 key terms that frequently co-occur in the\nmultidisciplinary study of AI. We then build on the results of this\nbibliometric analysis to propose three new multifaceted concepts for\nunderstanding and analysing AI-based systems for government (AI-GOV) in a more\nunified way: (1) operational fitness, (2) epistemic alignment, and (3)\nnormative divergence. Finally, we put these concepts to work by using them as\ndimensions in a conceptual typology of AI-GOV and connecting each with emerging\nAI technical measurement standards to encourage operationalization, foster\ncross-disciplinary dialogue, and stimulate debate among those aiming to rethink\ngovernment with AI.",
          "link": "http://arxiv.org/abs/2210.17218",
          "publishedOn": "2023-10-28T00:41:30.542Z",
          "wordCount": 838,
          "title": "Artificial intelligence in government: Concepts, standards, and a unified framework. (arXiv:2210.17218v2 [cs.CY] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.09933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_J/0/1/0/all/0/1\">Jos&#xe9; Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cardoso_L/0/1/0/all/0/1\">Lucas Cardoso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Ra&#xed;ssa Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cirilo_V/0/1/0/all/0/1\">Vitor Cirilo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carneiro_N/0/1/0/all/0/1\">N&#xed;kolas Carneiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alves_R/0/1/0/all/0/1\">Ronnie Alves</a>",
          "description": "In recent years, XAI researchers have been formalizing proposals and\ndeveloping new methods to explain black box models, with no general consensus\nin the community on which method to use to explain these models, with this\nchoice being almost directly linked to the popularity of a specific method.\nMethods such as Ciu, Dalex, Eli5, Lofo, Shap and Skater emerged with the\nproposal to explain black box models through global rankings of feature\nrelevance, which based on different methodologies, generate global explanations\nthat indicate how the model's inputs explain its predictions. In this context,\n41 datasets, 4 tree-ensemble algorithms (Light Gradient Boosting, CatBoost,\nRandom Forest, and Gradient Boosting), and 6 XAI methods were used to support\nthe launch of a new XAI method, called eXirt, based on Item Response Theory -\nIRT and aimed at tree-ensemble black box models that use tabular data referring\nto binary classification problems. In the first set of analyses, the 164 global\nfeature relevance ranks of the eXirt were compared with 984 ranks of the other\nXAI methods present in the literature, seeking to highlight their similarities\nand differences. In a second analysis, exclusive explanations of the eXirt\nbased on Explanation-by-example were presented that help in understanding the\nmodel trust. Thus, it was verified that eXirt is able to generate global\nexplanations of tree-ensemble models and also local explanations of instances\nof models through IRT, showing how this consolidated theory can be used in\nmachine learning in order to obtain explainable and reliable models.",
          "link": "http://arxiv.org/abs/2210.09933",
          "publishedOn": "2023-10-28T00:41:30.535Z",
          "wordCount": 845,
          "title": "Explanations Based on Item Response Theory (eXirt): A Model-Specific Method to Explain Tree-Ensemble Model in Trust Perspective. (arXiv:2210.09933v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.06589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyungeun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1\">Kijung Yoon</a>",
          "description": "Graph neural networks (GNNs) have become compelling models designed to\nperform learning and inference on graph-structured data. However, little work\nhas been done to understand the fundamental limitations of GNNs for scaling to\nlarger graphs and generalizing to out-of-distribution (OOD) inputs. In this\npaper, we use a random graph generator to systematically investigate how the\ngraph size and structural properties affect the predictive performance of GNNs.\nWe present specific evidence that the average node degree is a key feature in\ndetermining whether GNNs can generalize to unseen graphs, and that the use of\nmultiple node update functions can improve the generalization performance of\nGNNs when dealing with graphs of multimodal degree distributions. Accordingly,\nwe propose a multi-module GNN framework that allows the network to adapt\nflexibly to new graphs by generalizing a single canonical nonlinear\ntransformation over aggregated inputs. Our results show that the multi-module\nGNNs improve the OOD generalization on a variety of inference tasks in the\ndirection of diverse structural features.",
          "link": "http://arxiv.org/abs/2209.06589",
          "publishedOn": "2023-10-28T00:41:30.529Z",
          "wordCount": 746,
          "title": "Towards Better Generalization with Flexible Representation of Multi-Module Graph Neural Networks. (arXiv:2209.06589v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.04306",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Belkhouja_T/0/1/0/all/0/1\">Taha Belkhouja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doppa_J/0/1/0/all/0/1\">Janardhan Rao Doppa</a>",
          "description": "Safe deployment of time-series classifiers for real-world applications relies\non the ability to detect the data which is not generated from the same\ndistribution as training data. This task is referred to as out-of-distribution\n(OOD) detection. We consider the novel problem of OOD detection for the\ntime-series domain. We discuss the unique challenges posed by time-series data\nand explain why prior methods from the image domain will perform poorly.\nMotivated by these challenges, this paper proposes a novel {\\em Seasonal Ratio\nScoring (SRS)} approach. SRS consists of three key algorithmic steps. First,\neach input is decomposed into class-wise semantic component and remainder.\nSecond, this decomposition is employed to estimate the class-wise conditional\nlikelihoods of the input and remainder using deep generative models. The\nseasonal ratio score is computed from these estimates. Third, a threshold\ninterval is identified from the in-distribution data to detect OOD examples.\nExperiments on diverse real-world benchmarks demonstrate that the SRS method is\nwell-suited for time-series OOD detection when compared to baseline methods.\nOpen-source code for SRS method is provided at\nhttps://github.com/tahabelkhouja/SRS",
          "link": "http://arxiv.org/abs/2207.04306",
          "publishedOn": "2023-10-28T00:41:30.521Z",
          "wordCount": 754,
          "title": "Out-of-Distribution Detection in Time-Series Domain: A Novel Seasonal Ratio Scoring Approach. (arXiv:2207.04306v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.05869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Lam M. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Trang H. Tran</a>",
          "description": "Stochastic gradient descent (SGD) algorithm is the method of choice in many\nmachine learning tasks thanks to its scalability and efficiency in dealing with\nlarge-scale problems. In this paper, we focus on the shuffling version of SGD\nwhich matches the mainstream practical heuristics. We show the convergence to a\nglobal solution of shuffling SGD for a class of non-convex functions under\nover-parameterized settings. Our analysis employs more relaxed non-convex\nassumptions than previous literature. Nevertheless, we maintain the desired\ncomputational complexity as shuffling SGD has achieved in the general convex\nsetting.",
          "link": "http://arxiv.org/abs/2206.05869",
          "publishedOn": "2023-10-28T00:41:30.515Z",
          "wordCount": 665,
          "title": "On the Convergence to a Global Solution of Shuffling-Type Gradient Algorithms. (arXiv:2206.05869v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2107.11419",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Komiyama_J/0/1/0/all/0/1\">Junpei Komiyama</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fouche_E/0/1/0/all/0/1\">Edouard Fouch&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Honda_J/0/1/0/all/0/1\">Junya Honda</a>",
          "description": "We consider nonstationary multi-armed bandit problems where the model\nparameters of the arms change over time. We introduce the adaptive resetting\nbandit (ADR-bandit), a bandit algorithm class that leverages adaptive windowing\ntechniques from literature on data streams. We first provide new guarantees on\nthe quality of estimators resulting from adaptive windowing techniques, which\nare of independent interest. Furthermore, we conduct a finite-time analysis of\nADR-bandit in two typical environments: an abrupt environment where changes\noccur instantaneously and a gradual environment where changes occur\nprogressively. We demonstrate that ADR-bandit has nearly optimal performance\nwhen abrupt or gradual changes occur in a coordinated manner that we call\nglobal changes. We demonstrate that forced exploration is unnecessary when we\nassume such global changes. Unlike the existing nonstationary bandit\nalgorithms, ADR-bandit has optimal performance in stationary environments as\nwell as nonstationary environments with global changes. Our experiments show\nthat the proposed algorithms outperform the existing approaches in synthetic\nand real-world environments.",
          "link": "http://arxiv.org/abs/2107.11419",
          "publishedOn": "2023-10-28T00:41:30.481Z",
          "wordCount": 699,
          "title": "Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits. (arXiv:2107.11419v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.05794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galanti_T/0/1/0/all/0/1\">Tomer Galanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siegel_Z/0/1/0/all/0/1\">Zachary S. Siegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupte_A/0/1/0/all/0/1\">Aparna Gupte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poggio_T/0/1/0/all/0/1\">Tomaso Poggio</a>",
          "description": "We study the bias of Stochastic Gradient Descent (SGD) to learn low-rank\nweight matrices when training deep neural networks. Our results show that\ntraining neural networks with mini-batch SGD and weight decay causes a bias\ntowards rank minimization over the weight matrices. Specifically, we show, both\ntheoretically and empirically, that this bias is more pronounced when using\nsmaller batch sizes, higher learning rates, or increased weight decay.\nAdditionally, we predict and observe empirically that weight decay is necessary\nto achieve this bias. Unlike previous literature, our analysis does not rely on\nassumptions about the data, convergence, or optimality of the weight matrices\nand applies to a wide range of neural network architectures of any width or\ndepth. Finally, we empirically investigate the connection between this bias and\ngeneralization, finding that it has a marginal effect on generalization.",
          "link": "http://arxiv.org/abs/2206.05794",
          "publishedOn": "2023-10-28T00:41:30.468Z",
          "wordCount": 731,
          "title": "Characterizing the Implicit Bias of Regularized SGD in Rank Minimization. (arXiv:2206.05794v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.17380",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_T/0/1/0/all/0/1\">Tiancheng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junyan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouyer_C/0/1/0/all/0/1\">Chlo&#xe9; Rouyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_W/0/1/0/all/0/1\">William Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chen-Yu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>",
          "description": "Existing online learning algorithms for adversarial Markov Decision Processes\nachieve ${O}(\\sqrt{T})$ regret after $T$ rounds of interactions even if the\nloss functions are chosen arbitrarily by an adversary, with the caveat that the\ntransition function has to be fixed. This is because it has been shown that\nadversarial transition functions make no-regret learning impossible. Despite\nsuch impossibility results, in this work, we develop algorithms that can handle\nboth adversarial losses and adversarial transitions, with regret increasing\nsmoothly in the degree of maliciousness of the adversary. More concretely, we\nfirst propose an algorithm that enjoys $\\widetilde{{O}}(\\sqrt{T} +\nC^{\\textsf{P}})$ regret where $C^{\\textsf{P}}$ measures how adversarial the\ntransition functions are and can be at most ${O}(T)$. While this algorithm\nitself requires knowledge of $C^{\\textsf{P}}$, we further develop a black-box\nreduction approach that removes this requirement. Moreover, we also show that\nfurther refinements of the algorithm not only maintains the same regret bound,\nbut also simultaneously adapts to easier environments (where losses are\ngenerated in a certain stochastically constrained manner as in Jin et al.\n[2021]) and achieves $\\widetilde{{O}}(U + \\sqrt{UC^{\\textsf{L}}} +\nC^{\\textsf{P}})$ regret, where $U$ is some standard gap-dependent coefficient\nand $C^{\\textsf{L}}$ is the amount of corruption on losses.",
          "link": "http://arxiv.org/abs/2305.17380",
          "publishedOn": "2023-10-28T00:41:30.379Z",
          "wordCount": null,
          "title": "No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions. (arXiv:2305.17380v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.15694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Han Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1\">Yuanzhao Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1\">Yu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruifeng Xu</a>",
          "description": "The technique of Reinforcement Learning from Human Feedback (RLHF) is a\ncommonly employed method to improve pre-trained Language Models (LM), enhancing\ntheir ability to conform to human preferences. Nevertheless, the current\nRLHF-based LMs necessitate full retraining each time novel queries or feedback\nare introduced, which becomes a challenging task because human preferences can\nvary between different domains or tasks. Retraining LMs poses practical\ndifficulties in many real-world situations due to the significant time and\ncomputational resources required, along with concerns related to data privacy.\nTo address this limitation, we propose a new method called Continual Optimal\nPolicy Fitting (COPF), in which we estimate a series of optimal policies using\nthe Monte Carlo method, and then continually fit the policy sequence with the\nfunction regularization. COPF involves a single learning phase and doesn't\nnecessitate complex reinforcement learning. Importantly, it shares the\ncapability with RLHF to learn from unlabeled data, making it flexible for\ncontinual preference learning. Our experimental results show that COPF\noutperforms strong Continuous learning (CL) baselines when it comes to\nconsistently aligning with human preferences on different tasks and domains.",
          "link": "http://arxiv.org/abs/2310.15694",
          "publishedOn": "2023-10-28T00:41:30.372Z",
          "wordCount": null,
          "title": "COPF: Continual Learning Human Preference through Optimal Policy Fitting. (arXiv:2310.15694v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raya_G/0/1/0/all/0/1\">Gabriel Raya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ambrogioni_L/0/1/0/all/0/1\">Luca Ambrogioni</a>",
          "description": "Generative diffusion models have recently emerged as a leading approach for\ngenerating high-dimensional data. In this paper, we show that the dynamics of\nthese models exhibit a spontaneous symmetry breaking that divides the\ngenerative dynamics into two distinct phases: 1) A linear steady-state dynamics\naround a central fixed-point and 2) an attractor dynamics directed towards the\ndata manifold. These two \"phases\" are separated by the change in stability of\nthe central fixed-point, with the resulting window of instability being\nresponsible for the diversity of the generated samples. Using both theoretical\nand empirical evidence, we show that an accurate simulation of the early\ndynamics does not significantly contribute to the final generation, since early\nfluctuations are reverted to the central fixed point. To leverage this insight,\nwe propose a Gaussian late initialization scheme, which significantly improves\nmodel performance, achieving up to 3x FID improvements on fast samplers, while\nalso increasing sample diversity (e.g., racial composition of generated CelebA\nimages). Our work offers a new way to understand the generative dynamics of\ndiffusion models that has the potential to bring about higher performance and\nless biased fast-samplers.",
          "link": "http://arxiv.org/abs/2305.19693",
          "publishedOn": "2023-10-28T00:41:30.369Z",
          "wordCount": null,
          "title": "Spontaneous Symmetry Breaking in Generative Diffusion Models. (arXiv:2305.19693v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muennighoff_N/0/1/0/all/0/1\">Niklas Muennighoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barak_B/0/1/0/all/0/1\">Boaz Barak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scao_T/0/1/0/all/0/1\">Teven Le Scao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piktus_A/0/1/0/all/0/1\">Aleksandra Piktus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tazi_N/0/1/0/all/0/1\">Nouamane Tazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyysalo_S/0/1/0/all/0/1\">Sampo Pyysalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_T/0/1/0/all/0/1\">Thomas Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>",
          "description": "The current trend of scaling language models involves increasing both\nparameter count and training dataset size. Extrapolating this trend suggests\nthat training dataset size may soon be limited by the amount of text data\navailable on the internet. Motivated by this limit, we investigate scaling\nlanguage models in data-constrained regimes. Specifically, we run a large set\nof experiments varying the extent of data repetition and compute budget,\nranging up to 900 billion training tokens and 9 billion parameter models. We\nfind that with constrained data for a fixed compute budget, training with up to\n4 epochs of repeated data yields negligible changes to loss compared to having\nunique data. However, with more repetition, the value of adding compute\neventually decays to zero. We propose and empirically validate a scaling law\nfor compute optimality that accounts for the decreasing value of repeated\ntokens and excess parameters. Finally, we experiment with approaches mitigating\ndata scarcity, including augmenting the training dataset with code data or\nremoving commonly used filters. Models and datasets from our 400 training runs\nare freely available at https://github.com/huggingface/datablations.",
          "link": "http://arxiv.org/abs/2305.16264",
          "publishedOn": "2023-10-28T00:41:30.365Z",
          "wordCount": null,
          "title": "Scaling Data-Constrained Language Models. (arXiv:2305.16264v4 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.00990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Golmakani_A/0/1/0/all/0/1\">Ali Golmakani</a> (MULTISPEECH), <a href=\"http://arxiv.org/find/cs/1/au:+Sadeghi_M/0/1/0/all/0/1\">Mostafa Sadeghi</a> (MULTISPEECH), <a href=\"http://arxiv.org/find/cs/1/au:+Alameda_Pineda_X/0/1/0/all/0/1\">Xavier Alameda-Pineda</a> (ROBOTLEARN), <a href=\"http://arxiv.org/find/cs/1/au:+Serizel_R/0/1/0/all/0/1\">Romain Serizel</a> (MULTISPEECH)",
          "description": "We address speech enhancement based on variational autoencoders, which\ninvolves learning a speech prior distribution in the time-frequency (TF)\ndomain. A zero-mean complex-valued Gaussian distribution is usually assumed for\nthe generative model, where the speech information is encoded in the variance\nas a function of a latent variable. In contrast to this commonly used approach,\nwe propose a weighted variance generative model, where the contribution of each\nspectrogram time-frame in parameter learning is weighted. We impose a Gamma\nprior distribution on the weights, which would effectively lead to a Student's\nt-distribution instead of Gaussian for speech generative modeling. We develop\nefficient training and speech enhancement algorithms based on the proposed\ngenerative model. Our experimental results on spectrogram auto-encoding and\nspeech enhancement demonstrate the effectiveness and robustness of the proposed\napproach compared to the standard unweighted variance model.",
          "link": "http://arxiv.org/abs/2211.00990",
          "publishedOn": "2023-10-28T00:41:30.363Z",
          "wordCount": null,
          "title": "A weighted-variance variational autoencoder model for speech enhancement. (arXiv:2211.00990v2 [cs.SD] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.01874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hirose_N/0/1/0/all/0/1\">Noriaki Hirose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Dhruv Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_A/0/1/0/all/0/1\">Ajay Sridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Machine learning provides a powerful tool for building socially compliant\nrobotic systems that go beyond simple predictive models of human behavior. By\nobserving and understanding human interactions from past experiences, learning\ncan enable effective social navigation behaviors directly from data. In this\npaper, our goal is to develop methods for training policies for socially\nunobtrusive navigation, such that robots can navigate among humans in ways that\ndon't disturb human behavior. We introduce a definition for such behavior based\non the counterfactual perturbation of the human: if the robot had not intruded\ninto the space, would the human have acted in the same way? By minimizing this\ncounterfactual perturbation, we can induce robots to behave in ways that do not\nalter the natural behavior of humans in the shared space. Instantiating this\nprinciple requires training policies to minimize their effect on human\nbehavior, and this in turn requires data that allows us to model the behavior\nof humans in the presence of robots. Therefore, our approach is based on two\nkey contributions. First, we collect a large dataset where an indoor mobile\nrobot interacts with human bystanders. Second, we utilize this dataset to train\npolicies that minimize counterfactual perturbation. We provide supplementary\nvideos and make publicly available the largest-of-its-kind visual navigation\ndataset on our project page.",
          "link": "http://arxiv.org/abs/2306.01874",
          "publishedOn": "2023-10-28T00:41:30.359Z",
          "wordCount": null,
          "title": "SACSoN: Scalable Autonomous Control for Social Navigation. (arXiv:2306.01874v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.11113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maragno_D/0/1/0/all/0/1\">Donato Maragno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurtz_J/0/1/0/all/0/1\">Jannis Kurtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rober_T/0/1/0/all/0/1\">Tabea E. R&#xf6;ber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goedhart_R/0/1/0/all/0/1\">Rob Goedhart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birbil_S/0/1/0/all/0/1\">&#x15e;. Ilker Birbil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hertog_D/0/1/0/all/0/1\">Dick den Hertog</a>",
          "description": "Counterfactual explanations play an important role in detecting bias and\nimproving the explainability of data-driven classification models. A\ncounterfactual explanation (CE) is a minimal perturbed data point for which the\ndecision of the model changes. Most of the existing methods can only provide\none CE, which may not be achievable for the user. In this work we derive an\niterative method to calculate robust CEs, i.e. CEs that remain valid even after\nthe features are slightly perturbed. To this end, our method provides a whole\nregion of CEs allowing the user to choose a suitable recourse to obtain a\ndesired outcome. We use algorithmic ideas from robust optimization and prove\nconvergence results for the most common machine learning methods including\nlogistic regression, decision trees, random forests, and neural networks. Our\nexperiments show that our method can efficiently generate globally optimal\nrobust CEs for a variety of common data sets and classification models.",
          "link": "http://arxiv.org/abs/2301.11113",
          "publishedOn": "2023-10-28T00:41:30.355Z",
          "wordCount": null,
          "title": "Finding Regions of Counterfactual Explanations via Robust Optimization. (arXiv:2301.11113v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiatao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qingzhe Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_S/0/1/0/all/0/1\">Shuangfei Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Baoquan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingjie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susskind_J/0/1/0/all/0/1\">Josh Susskind</a>",
          "description": "Diffusion models have recently become the de-facto approach for generative\nmodeling in the 2D domain. However, extending diffusion models to 3D is\nchallenging due to the difficulties in acquiring 3D ground truth data for\ntraining. On the other hand, 3D GANs that integrate implicit 3D representations\ninto GANs have shown remarkable 3D-aware generation when trained only on\nsingle-view image datasets. However, 3D GANs do not provide straightforward\nways to precisely control image synthesis. To address these challenges, We\npresent Control3Diff, a 3D diffusion model that combines the strengths of\ndiffusion models and 3D GANs for versatile, controllable 3D-aware image\nsynthesis for single-view datasets. Control3Diff explicitly models the\nunderlying latent distribution (optionally conditioned on external inputs),\nthus enabling direct control during the diffusion process. Moreover, our\napproach is general and applicable to any type of controlling input, allowing\nus to train it with the same diffusion objective without any auxiliary\nsupervision. We validate the efficacy of Control3Diff on standard image\ngeneration benchmarks, including FFHQ, AFHQ, and ShapeNet, using various\nconditioning inputs such as images, sketches, and text prompts. Please see the\nproject website (\\url{https://jiataogu.me/control3diff}) for video comparisons.",
          "link": "http://arxiv.org/abs/2304.06700",
          "publishedOn": "2023-10-28T00:41:30.354Z",
          "wordCount": null,
          "title": "Control3Diff: Learning Controllable 3D Diffusion Models from Single-view Images. (arXiv:2304.06700v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16638",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kato_M/0/1/0/all/0/1\">Masahiro Kato</a>",
          "description": "Consider a scenario where we have access to train data with both covariates\nand outcomes while test data only contains covariates. In this scenario, our\nprimary aim is to predict the missing outcomes of the test data. With this\nobjective in mind, we train parametric regression models under a covariate\nshift, where covariate distributions are different between the train and test\ndata. For this problem, existing studies have proposed covariate shift\nadaptation via importance weighting using the density ratio. This approach\naverages the train data losses, each weighted by an estimated ratio of the\ncovariate densities between the train and test data, to approximate the\ntest-data risk. Although it allows us to obtain a test-data risk minimizer, its\nperformance heavily relies on the accuracy of the density ratio estimation.\nMoreover, even if the density ratio can be consistently estimated, the\nestimation errors of the density ratio also yield bias in the estimators of the\nregression model's parameters of interest. To mitigate these challenges, we\nintroduce a doubly robust estimator for covariate shift adaptation via\nimportance weighting, which incorporates an additional estimator for the\nregression function. Leveraging double machine learning techniques, our\nestimator reduces the bias arising from the density ratio estimation errors. We\ndemonstrate the asymptotic distribution of the regression parameter estimator.\nNotably, our estimator remains consistent if either the density ratio estimator\nor the regression function is consistent, showcasing its robustness against\npotential errors in density ratio estimation. Finally, we confirm the soundness\nof our proposed method via simulation studies.",
          "link": "http://arxiv.org/abs/2310.16638",
          "publishedOn": "2023-10-28T00:41:30.353Z",
          "wordCount": null,
          "title": "Robust Covariate Shift Adaptation for Density-Ratio Estimation. (arXiv:2310.16638v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.11531",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Liu_J/0/1/0/all/0/1\">Junze Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ghosh_A/0/1/0/all/0/1\">Aishik Ghosh</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Smith_D/0/1/0/all/0/1\">Dylan Smith</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Baldi_P/0/1/0/all/0/1\">Pierre Baldi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Whiteson_D/0/1/0/all/0/1\">Daniel Whiteson</a>",
          "description": "Generation of simulated detector response to collision products is crucial to\ndata analysis in particle physics, but computationally very expensive. One\nsubdetector, the calorimeter, dominates the computational time due to the high\ngranularity of its cells and complexity of the interactions. Generative models\ncan provide more rapid sample production, but currently require significant\neffort to optimize performance for specific detector geometries, often\nrequiring many models to describe the varying cell sizes and arrangements,\nwithout the ability to generalize to other geometries. We develop a\n$\\textit{geometry-aware}$ autoregressive model, which learns how the\ncalorimeter response varies with geometry, and is capable of generating\nsimulated responses to unseen geometries without additional training. The\ngeometry-aware model outperforms a baseline unaware model by over $50\\%$ in\nseveral metrics such as the Wasserstein distance between the generated and the\ntrue distributions of key quantities which summarize the simulated response. A\nsingle geometry-aware model could replace the hundreds of generative models\ncurrently designed for calorimeter simulation by physicists analyzing data\ncollected at the Large Hadron Collider. This proof-of-concept study motivates\nthe design of a foundational model that will be a crucial tool for the study of\nfuture detectors, dramatically reducing the large upfront investment usually\nneeded to develop generative calorimeter models.",
          "link": "http://arxiv.org/abs/2305.11531",
          "publishedOn": "2023-10-28T00:41:30.352Z",
          "wordCount": null,
          "title": "Generalizing to new geometries with Geometry-Aware Autoregressive Models (GAAMs) for fast calorimeter simulation. (arXiv:2305.11531v3 [physics.ins-det] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.12593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Queeney_J/0/1/0/all/0/1\">James Queeney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benosman_M/0/1/0/all/0/1\">Mouhacine Benosman</a>",
          "description": "Many real-world domains require safe decision making in uncertain\nenvironments. In this work, we introduce a deep reinforcement learning\nframework for approaching this important problem. We consider a distribution\nover transition models, and apply a risk-averse perspective towards model\nuncertainty through the use of coherent distortion risk measures. We provide\nrobustness guarantees for this framework by showing it is equivalent to a\nspecific class of distributionally robust safe reinforcement learning problems.\nUnlike existing approaches to robustness in deep reinforcement learning,\nhowever, our formulation does not involve minimax optimization. This leads to\nan efficient, model-free implementation of our approach that only requires\nstandard data collection from a single training environment. In experiments on\ncontinuous control tasks with safety constraints, we demonstrate that our\nframework produces robust performance and safety at deployment time across a\nrange of perturbed test environments.",
          "link": "http://arxiv.org/abs/2301.12593",
          "publishedOn": "2023-10-28T00:41:30.350Z",
          "wordCount": null,
          "title": "Risk-Averse Model Uncertainty for Distributionally Robust Safe Reinforcement Learning. (arXiv:2301.12593v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.00028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jakkala_K/0/1/0/all/0/1\">Kalvik Jakkala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akella_S/0/1/0/all/0/1\">Srinivas Akella</a>",
          "description": "The sensor placement problem is a common problem that arises when monitoring\ncorrelated phenomena, such as temperature, precipitation, and salinity.\nExisting approaches to this problem typically formulate it as the maximization\nof information metrics, such as mutual information~(MI), and use optimization\nmethods such as greedy algorithms in discrete domains, and derivative-free\noptimization methods such as genetic algorithms in continuous domains. However,\ncomputing MI for sensor placement requires discretizing the environment, and\nits computation cost depends on the size of the discretized environment. This\nlimitation restricts these approaches from scaling to large problems. We have\nuncovered a novel connection between the sensor placement problem and sparse\nGaussian processes~(SGP). Our approach leverages SGPs and is gradient-based,\nwhich allows us to efficiently find solution placements in continuous\nenvironments. We generalize our method to also handle discrete environments.\nOur experimental results on four real-world datasets demonstrate that our\napproach generates sensor placements consistently on par with or better than\nthe prior state-of-the-art approaches in terms of both MI and reconstruction\nquality, all while being significantly faster. Our computationally efficient\napproach enables both large-scale sensor placement and fast robotic sensor\nplacement for informative path planning algorithms.",
          "link": "http://arxiv.org/abs/2303.00028",
          "publishedOn": "2023-10-28T00:41:30.350Z",
          "wordCount": null,
          "title": "Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces. (arXiv:2303.00028v6 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.00198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yun-Yun Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1\">Chengzhi Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junfeng Yang</a>",
          "description": "Vision models are often vulnerable to out-of-distribution (OOD) samples\nwithout adapting. While visual prompts offer a lightweight method of\ninput-space adaptation for large-scale vision models, they rely on a\nhigh-dimensional additive vector and labeled data. This leads to overfitting\nwhen adapting models in a self-supervised test-time setting without labels. We\nintroduce convolutional visual prompts (CVP) for label-free test-time\nadaptation for robust visual perception. The structured nature of CVP demands\nfewer trainable parameters, less than 1\\% compared to standard visual prompts,\ncombating overfitting. Extensive experiments and analysis on a wide variety of\nOOD visual perception tasks show that our approach is effective, improving\nrobustness by up to 5.87% over several large-scale models.",
          "link": "http://arxiv.org/abs/2303.00198",
          "publishedOn": "2023-10-28T00:41:30.346Z",
          "wordCount": null,
          "title": "Convolutional Visual Prompt for Robust Visual Perception. (arXiv:2303.00198v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02987",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xufeng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alacaoglu_A/0/1/0/all/0/1\">Ahmet Alacaoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diakonikolas_J/0/1/0/all/0/1\">Jelena Diakonikolas</a>",
          "description": "Machine learning approaches relying on such criteria as adversarial\nrobustness or multi-agent settings have raised the need for solving\ngame-theoretic equilibrium problems. Of particular relevance to these\napplications are methods targeting finite-sum structure, which generically\narises in empirical variants of learning problems in these contexts. Further,\nmethods with computable approximation errors are highly desirable, as they\nprovide verifiable exit criteria. Motivated by these applications, we study\nfinite-sum monotone inclusion problems, which model broad classes of\nequilibrium problems. Our main contributions are variants of the classical\nHalpern iteration that employ variance reduction to obtain improved complexity\nguarantees in which $n$ component operators in the finite sum are ``on\naverage'' either cocoercive or Lipschitz continuous and monotone, with\nparameter $L$. The resulting oracle complexity of our methods, which provide\nguarantees for the last iterate and for a (computable) operator norm residual,\nis $\\widetilde{\\mathcal{O}}( n + \\sqrt{n}L\\varepsilon^{-1})$, which improves\nupon existing methods by a factor up to $\\sqrt{n}$. This constitutes the first\nvariance reduction-type result for general finite-sum monotone inclusions and\nfor more specific problems such as convex-concave optimization when operator\nnorm residual is the optimality measure. We further argue that, up to\npoly-logarithmic factors, this complexity is unimprovable in the monotone\nLipschitz setting; i.e., the provided result is near-optimal.",
          "link": "http://arxiv.org/abs/2310.02987",
          "publishedOn": "2023-10-28T00:41:30.342Z",
          "wordCount": null,
          "title": "Variance Reduced Halpern Iteration for Finite-Sum Monotone Inclusions. (arXiv:2310.02987v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jullien_M/0/1/0/all/0/1\">Ma&#xeb;l Jullien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1\">Marco Valentino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frost_H/0/1/0/all/0/1\">Hannah Frost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ORegan_P/0/1/0/all/0/1\">Paul O&#x27;Regan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1\">Donal Landers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andr&#xe9; Freitas</a>",
          "description": "How can we interpret and retrieve medical evidence to support clinical\ndecisions? Clinical trial reports (CTR) amassed over the years contain\nindispensable information for the development of personalized medicine.\nHowever, it is practically infeasible to manually inspect over 400,000+\nclinical trial reports in order to find the best evidence for experimental\ntreatments. Natural Language Inference (NLI) offers a potential solution to\nthis problem, by allowing the scalable computation of textual entailment.\nHowever, existing NLI models perform poorly on biomedical corpora, and\npreviously published datasets fail to capture the full complexity of inference\nover CTRs. In this work, we present a novel resource to advance research on NLI\nfor reasoning on CTRs. The resource includes two main tasks. Firstly, to\ndetermine the inference relation between a natural language statement, and a\nCTR. Secondly, to retrieve supporting facts to justify the predicted relation.\nWe provide NLI4CT, a corpus of 2400 statements and CTRs, annotated for these\ntasks. Baselines on this corpus expose the limitations of existing NLI models,\nwith 6 state-of-the-art NLI models achieving a maximum F1 score of 0.627. To\nthe best of our knowledge, we are the first to design a task that covers the\ninterpretation of full CTRs. To encourage further work on this challenging\ndataset, we make the corpus, competition leaderboard, website and code to\nreplicate the baseline experiments available at:\nhttps://github.com/ai-systems/nli4ct",
          "link": "http://arxiv.org/abs/2305.03598",
          "publishedOn": "2023-10-28T00:41:30.340Z",
          "wordCount": null,
          "title": "NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial Reports. (arXiv:2305.03598v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Franceschi_J/0/1/0/all/0/1\">Jean-Yves Franceschi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gartrell_M/0/1/0/all/0/1\">Mike Gartrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_L/0/1/0/all/0/1\">Ludovic Dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Issenhuth_T/0/1/0/all/0/1\">Thibaut Issenhuth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1\">Emmanuel de B&#xe9;zenac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Micka&#xeb;l Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakotomamonjy_A/0/1/0/all/0/1\">Alain Rakotomamonjy</a>",
          "description": "Particle-based deep generative models, such as gradient flows and score-based\ndiffusion models, have recently gained traction thanks to their striking\nperformance. Their principle of displacing particle distributions using\ndifferential equations is conventionally seen as opposed to the previously\nwidespread generative adversarial networks (GANs), which involve training a\npushforward generator network. In this paper we challenge this interpretation,\nand propose a novel framework that unifies particle and adversarial generative\nmodels by framing generator training as a generalization of particle models.\nThis suggests that a generator is an optional addition to any such generative\nmodel. Consequently, integrating a generator into a score-based diffusion model\nand training a GAN without a generator naturally emerge from our framework. We\nempirically test the viability of these original models as proofs of concepts\nof potential applications of our framework.",
          "link": "http://arxiv.org/abs/2305.16150",
          "publishedOn": "2023-10-28T00:41:30.340Z",
          "wordCount": null,
          "title": "Unifying GANs and Score-Based Diffusion as Generative Particle Models. (arXiv:2305.16150v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.00270",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bang An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yongjian Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "The problem of urban event ranking aims at predicting the top-k most risky\nlocations of future events such as traffic accidents and crimes. This problem\nis of fundamental importance to public safety and urban administration\nespecially when limited resources are available. The problem is, however,\nchallenging due to complex and dynamic spatio-temporal correlations between\nlocations, uneven distribution of urban events in space, and the difficulty to\ncorrectly rank nearby locations with similar features. Prior works on event\nforecasting mostly aim at accurately predicting the actual risk score or counts\nof events for all the locations. Rankings obtained as such usually have low\nquality due to prediction errors. Learning-to-rank methods directly optimize\nmeasures such as Normalized Discounted Cumulative Gain (NDCG), but cannot\nhandle the spatiotemporal autocorrelation existing among locations. In this\npaper, we bridge the gap by proposing a novel spatial event ranking approach\nnamed SpatialRank. SpatialRank features adaptive graph convolution layers that\ndynamically learn the spatiotemporal dependencies across locations from data.\nIn addition, the model optimizes through surrogates a hybrid NDCG loss with a\nspatial component to better rank neighboring spatial locations. We design an\nimportance-sampling with a spatial filtering algorithm to effectively evaluate\nthe loss during training. Comprehensive experiments on three real-world\ndatasets demonstrate that SpatialRank can effectively identify the top riskiest\nlocations of crimes and traffic accidents and outperform state-of-art methods\nin terms of NDCG by up to 12.7%.",
          "link": "http://arxiv.org/abs/2310.00270",
          "publishedOn": "2023-10-28T00:41:30.339Z",
          "wordCount": null,
          "title": "SpatialRank: Urban Event Ranking with NDCG Optimization on Spatiotemporal Data. (arXiv:2310.00270v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.05683",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gagolewski_M/0/1/0/all/0/1\">Marek Gagolewski</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cena_A/0/1/0/all/0/1\">Anna Cena</a>, <a href=\"http://arxiv.org/find/stat/1/au:+James_S/0/1/0/all/0/1\">Simon James</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beliakov_G/0/1/0/all/0/1\">Gleb Beliakov</a>",
          "description": "Agglomerative hierarchical clustering based on Ordered Weighted Averaging\n(OWA) operators not only generalises the single, complete, and average\nlinkages, but also includes intercluster distances based on a few nearest or\nfarthest neighbours, trimmed and winsorised means of pairwise point\nsimilarities, amongst many others. We explore the relationships between the\nfamous Lance-Williams update formula and the extended OWA-based linkages with\nweights generated via infinite coefficient sequences. Furthermore, we provide\nsome conditions for the weight generators to guarantee the resulting\ndendrograms to be free from unaesthetic inversions.",
          "link": "http://arxiv.org/abs/2303.05683",
          "publishedOn": "2023-10-28T00:41:30.338Z",
          "wordCount": null,
          "title": "Hierarchical clustering with OWA-based linkages, the Lance-Williams formula, and dendrogram inversions. (arXiv:2303.05683v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.17310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiayuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borovykh_A/0/1/0/all/0/1\">Anastasia Borovykh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayou_S/0/1/0/all/0/1\">Soufiane Hayou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokri_R/0/1/0/all/0/1\">Reza Shokri</a>",
          "description": "We introduce a new analytical framework to quantify the changes in a machine\nlearning algorithm's output distribution following the inclusion of a few data\npoints in its training set, a notion we define as leave-one-out\ndistinguishability (LOOD). This problem is key to measuring data\n**memorization** and **information leakage** in machine learning, and the\n**influence** of training data points on model predictions. We illustrate how\nour method broadens and refines existing empirical measures of memorization and\nprivacy risks associated with training data. We use Gaussian processes to model\nthe randomness of machine learning algorithms, and validate LOOD with extensive\nempirical analysis of information leakage using membership inference attacks.\nOur theoretical framework enables us to investigate the causes of information\nleakage and where the leakage is high. For example, we analyze the influence of\nactivation functions, on data memorization. Additionally, our method allows us\nto optimize queries that disclose the most significant information about the\ntraining data in the leave-one-out setting. We illustrate how optimal queries\ncan be used for accurate **reconstruction** of training data.",
          "link": "http://arxiv.org/abs/2309.17310",
          "publishedOn": "2023-10-28T00:41:30.337Z",
          "wordCount": null,
          "title": "Leave-one-out Distinguishability in Machine Learning. (arXiv:2309.17310v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.13633",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Duong_L/0/1/0/all/0/1\">Lyndon R. Duong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Simoncelli_E/0/1/0/all/0/1\">Eero P. Simoncelli</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chklovskii_D/0/1/0/all/0/1\">Dmitri B. Chklovskii</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lipshutz_D/0/1/0/all/0/1\">David Lipshutz</a>",
          "description": "Neurons in early sensory areas rapidly adapt to changing sensory statistics,\nboth by normalizing the variance of their individual responses and by reducing\ncorrelations between their responses. Together, these transformations may be\nviewed as an adaptive form of statistical whitening. Existing mechanistic\nmodels of adaptive whitening exclusively use either synaptic plasticity or gain\nmodulation as the biological substrate for adaptation; however, on their own,\neach of these models has significant limitations. In this work, we unify these\napproaches in a normative multi-timescale mechanistic model that adaptively\nwhitens its responses with complementary computational roles for synaptic\nplasticity and gain modulation. Gains are modified on a fast timescale to adapt\nto the current statistical context, whereas synapses are modified on a slow\ntimescale to match structural properties of the input statistics that are\ninvariant across contexts. Our model is derived from a novel multi-timescale\nwhitening objective that factorizes the inverse whitening matrix into basis\nvectors, which correspond to synaptic weights, and a diagonal matrix, which\ncorresponds to neuronal gains. We test our model on synthetic and natural\ndatasets and find that the synapses learn optimal configurations over long\ntimescales that enable adaptive whitening on short timescales using gain\nmodulation.",
          "link": "http://arxiv.org/abs/2308.13633",
          "publishedOn": "2023-10-28T00:41:30.336Z",
          "wordCount": null,
          "title": "Adaptive whitening with fast gain modulation and slow synaptic plasticity. (arXiv:2308.13633v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.03857",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xilie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kankanhalli_M/0/1/0/all/0/1\">Mohan Kankanhalli</a>",
          "description": "Adversarial contrastive learning (ACL) does not require expensive data\nannotations but outputs a robust representation that withstands adversarial\nattacks and also generalizes to a wide range of downstream tasks. However, ACL\nneeds tremendous running time to generate the adversarial variants of all\ntraining data, which limits its scalability to large datasets. To speed up ACL,\nthis paper proposes a robustness-aware coreset selection (RCS) method. RCS does\nnot require label information and searches for an informative subset that\nminimizes a representational divergence, which is the distance of the\nrepresentation between natural data and their virtual adversarial variants. The\nvanilla solution of RCS via traversing all possible subsets is computationally\nprohibitive. Therefore, we theoretically transform RCS into a surrogate problem\nof submodular maximization, of which the greedy search is an efficient solution\nwith an optimality guarantee for the original problem. Empirically, our\ncomprehensive results corroborate that RCS can speed up ACL by a large margin\nwithout significantly hurting the robustness transferability. Notably, to the\nbest of our knowledge, we are the first to conduct ACL efficiently on the\nlarge-scale ImageNet-1K dataset to obtain an effective robust representation\nvia RCS. Our source code is at\nhttps://github.com/GodXuxilie/Efficient_ACL_via_RCS.",
          "link": "http://arxiv.org/abs/2302.03857",
          "publishedOn": "2023-10-28T00:41:30.335Z",
          "wordCount": null,
          "title": "Efficient Adversarial Contrastive Learning via Robustness-Aware Coreset Selection. (arXiv:2302.03857v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.13923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jianing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1\">Geng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jiangchao Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>",
          "description": "Out-of-distribution (OOD) detection is important for deploying reliable\nmachine learning models on real-world applications. Recent advances in outlier\nexposure have shown promising results on OOD detection via fine-tuning model\nwith informatively sampled auxiliary outliers. However, previous methods assume\nthat the collected outliers can be sufficiently large and representative to\ncover the boundary between ID and OOD data, which might be impractical and\nchallenging. In this work, we propose a novel framework, namely, Diversified\nOutlier Exposure (DivOE), for effective OOD detection via informative\nextrapolation based on the given auxiliary outliers. Specifically, DivOE\nintroduces a new learning objective, which diversifies the auxiliary\ndistribution by explicitly synthesizing more informative outliers for\nextrapolation during training. It leverages a multi-step optimization method to\ngenerate novel outliers beyond the original ones, which is compatible with many\nvariants of outlier exposure. Extensive experiments and analyses have been\nconducted to characterize and demonstrate the effectiveness of the proposed\nDivOE. The code is publicly available at: https://github.com/tmlr-group/DivOE.",
          "link": "http://arxiv.org/abs/2310.13923",
          "publishedOn": "2023-10-28T00:41:30.334Z",
          "wordCount": null,
          "title": "Diversified Outlier Exposure for Out-of-Distribution Detection via Informative Extrapolation. (arXiv:2310.13923v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.07983",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cardoso_G/0/1/0/all/0/1\">Gabriel Cardoso</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Idrissi_Y/0/1/0/all/0/1\">Yazid Janati El Idrissi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Corff_S/0/1/0/all/0/1\">Sylvain Le Corff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1\">Eric Moulines</a>",
          "description": "Ill-posed linear inverse problems arise frequently in various applications,\nfrom computational photography to medical imaging. A recent line of research\nexploits Bayesian inference with informative priors to handle the ill-posedness\nof such problems. Amongst such priors, score-based generative models (SGM) have\nrecently been successfully applied to several different inverse problems. In\nthis study, we exploit the particular structure of the prior defined by the SGM\nto define a sequence of intermediate linear inverse problems. As the noise\nlevel decreases, the posteriors of these inverse problems get closer to the\ntarget posterior of the original inverse problem. To sample from this sequence\nof posteriors, we propose the use of Sequential Monte Carlo (SMC) methods. The\nproposed algorithm, MCGDiff, is shown to be theoretically grounded and we\nprovide numerical simulations showing that it outperforms competing baselines\nwhen dealing with ill-posed inverse problems in a Bayesian setting.",
          "link": "http://arxiv.org/abs/2308.07983",
          "publishedOn": "2023-10-28T00:41:30.328Z",
          "wordCount": null,
          "title": "Monte Carlo guided Diffusion for Bayesian linear inverse problems. (arXiv:2308.07983v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jier Chen</a>",
          "description": "Forecasting vehicular motions in autonomous driving requires a deep\nunderstanding of agent interactions and the preservation of motion equivariance\nunder Euclidean geometric transformations. Traditional models often lack the\nsophistication needed to handle the intricate dynamics inherent to autonomous\nvehicles and the interaction relationships among agents in the scene. As a\nresult, these models have a lower model capacity, which then leads to higher\nprediction errors and lower training efficiency. In our research, we employ\nEqMotion, a leading equivariant particle, and human prediction model that also\naccounts for invariant agent interactions, for the task of multi-agent vehicle\nmotion forecasting. In addition, we use a multi-modal prediction mechanism to\naccount for multiple possible future paths in a probabilistic manner. By\nleveraging EqMotion, our model achieves state-of-the-art (SOTA) performance\nwith fewer parameters (1.2 million) and a significantly reduced training time\n(less than 2 hours).",
          "link": "http://arxiv.org/abs/2310.17540",
          "publishedOn": "2023-10-28T00:41:30.327Z",
          "wordCount": null,
          "title": "EqDrive: Efficient Equivariant Motion Forecasting with Multi-Modality for Autonomous Driving. (arXiv:2310.17540v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gorishniy_Y/0/1/0/all/0/1\">Yury Gorishniy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubachev_I/0/1/0/all/0/1\">Ivan Rubachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1\">Artem Babenko</a>",
          "description": "Recently, Transformer-like deep architectures have shown strong performance\non tabular data problems. Unlike traditional models, e.g., MLP, these\narchitectures map scalar values of numerical features to high-dimensional\nembeddings before mixing them in the main backbone. In this work, we argue that\nembeddings for numerical features are an underexplored degree of freedom in\ntabular DL, which allows constructing more powerful DL models and competing\nwith GBDT on some traditionally GBDT-friendly benchmarks. We start by\ndescribing two conceptually different approaches to building embedding modules:\nthe first one is based on a piecewise linear encoding of scalar values, and the\nsecond one utilizes periodic activations. Then, we empirically demonstrate that\nthese two approaches can lead to significant performance boosts compared to the\nembeddings based on conventional blocks such as linear layers and ReLU\nactivations. Importantly, we also show that embedding numerical features is\nbeneficial for many backbones, not only for Transformers. Specifically, after\nproper embeddings, simple MLP-like models can perform on par with the\nattention-based architectures. Overall, we highlight embeddings for numerical\nfeatures as an important design aspect with good potential for further\nimprovements in tabular DL.",
          "link": "http://arxiv.org/abs/2203.05556",
          "publishedOn": "2023-10-28T00:41:30.326Z",
          "wordCount": null,
          "title": "On Embeddings for Numerical Features in Tabular Deep Learning. (arXiv:2203.05556v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.07420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiling Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Fang-Yi Yu</a>",
          "description": "This paper studies the design of optimal proper scoring rules when the\nprincipal has partial knowledge of an agent's signal distribution. Recent work\ncharacterizes the proper scoring rules that maximize the increase of an agent's\npayoff when the agent chooses to access a costly signal to refine a posterior\nbelief from her prior prediction, under the assumption that the agent's signal\ndistribution is fully known to the principal. In our setting, the principal\nonly knows about a set of distributions where the agent's signal distribution\nbelongs. We formulate the scoring rule design problem as a max-min optimization\nthat maximizes the worst-case increase in payoff across the set of\ndistributions.\n\nWe propose an efficient algorithm to compute an optimal scoring rule when the\nset of distributions is finite, and devise a fully polynomial-time\napproximation scheme that accommodates various infinite sets of distributions.\nWe further remark that widely used scoring rules, such as the quadratic and log\nrules, as well as previously identified optimal scoring rules under full\nknowledge, can be far from optimal in our partial knowledge settings.",
          "link": "http://arxiv.org/abs/2107.07420",
          "publishedOn": "2023-10-28T00:41:30.323Z",
          "wordCount": null,
          "title": "Optimal Scoring Rule Design under Partial Knowledge. (arXiv:2107.07420v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Junfeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhencheng Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yuxuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmermann_R/0/1/0/all/0/1\">Roger Zimmermann</a>",
          "description": "Spatio-temporal graph learning is a fundamental problem in the Web of Things\nera, which enables a plethora of Web applications such as smart cities, human\nmobility and climate analysis. Existing approaches tackle different learning\ntasks independently, tailoring their models to unique task characteristics.\nThese methods, however, fall short of modeling intrinsic uncertainties in the\nspatio-temporal data. Meanwhile, their specialized designs limit their\nuniversality as general spatio-temporal learning solutions. In this paper, we\npropose to model the learning tasks in a unified perspective, viewing them as\npredictions based on conditional information with shared spatio-temporal\npatterns. Based on this proposal, we introduce Unified Spatio-Temporal\nDiffusion Models (USTD) to address the tasks uniformly within the\nuncertainty-aware diffusion framework. USTD is holistically designed,\ncomprising a shared spatio-temporal encoder and attention-based denoising\nnetworks that are task-specific. The shared encoder, optimized by a\npre-training strategy, effectively captures conditional spatio-temporal\npatterns. The denoising networks, utilizing both cross- and self-attention,\nintegrate conditional dependencies and generate predictions. Opting for\nforecasting and kriging as downstream tasks, we design Gated Attention (SGA)\nand Temporal Gated Attention (TGA) for each task, with different emphases on\nthe spatial and temporal dimensions, respectively. By combining the advantages\nof deterministic encoders and probabilistic diffusion models, USTD achieves\nstate-of-the-art performances compared to deterministic and probabilistic\nbaselines in both tasks, while also providing valuable uncertainty estimates.",
          "link": "http://arxiv.org/abs/2310.17360",
          "publishedOn": "2023-10-28T00:41:30.110Z",
          "wordCount": null,
          "title": "Towards Unifying Diffusion Models for Probabilistic Spatio-Temporal Graph Learning. (arXiv:2310.17360v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17550",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1\">Andi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tucker_M/0/1/0/all/0/1\">Mycal Tucker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenny_E/0/1/0/all/0/1\">Eoin Kenny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaslavsky_N/0/1/0/all/0/1\">Noga Zaslavsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Pulkit Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_J/0/1/0/all/0/1\">Julie Shah</a>",
          "description": "Neural networks often learn task-specific latent representations that fail to\ngeneralize to novel settings or tasks. Conversely, humans learn discrete\nrepresentations (i.e., concepts or words) at a variety of abstraction levels\n(e.g., ``bird'' vs. ``sparrow'') and deploy the appropriate abstraction based\non task. Inspired by this, we train neural models to generate a spectrum of\ndiscrete representations, and control the complexity of the representations\n(roughly, how many bits are allocated for encoding inputs) by tuning the\nentropy of the distribution over representations. In finetuning experiments,\nusing only a small number of labeled examples for a new task, we show that (1)\ntuning the representation to a task-appropriate complexity level supports the\nhighest finetuning performance, and (2) in a human-participant study, users\nwere able to identify the appropriate complexity level for a downstream task\nusing visualizations of discrete representations. Our results indicate a\npromising direction for rapid model finetuning by leveraging human insight.",
          "link": "http://arxiv.org/abs/2310.17550",
          "publishedOn": "2023-10-28T00:41:30.110Z",
          "wordCount": null,
          "title": "Human-Guided Complexity-Controlled Abstractions. (arXiv:2310.17550v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shahini_X/0/1/0/all/0/1\">Xhulja Shahini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bubel_D/0/1/0/all/0/1\">Domenic Bubel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metzger_A/0/1/0/all/0/1\">Andreas Metzger</a>",
          "description": "Software quality assurance activities become increasingly difficult as\nsoftware systems become more and more complex and continuously grow in size.\nMoreover, testing becomes even more expensive when dealing with large-scale\nsystems. Thus, to effectively allocate quality assurance resources, researchers\nhave proposed fault prediction (FP) which utilizes machine learning (ML) to\npredict fault-prone code areas. However, ML algorithms typically make use of\nstochastic elements to increase the prediction models' generalizability and\nefficiency of the training process. These stochastic elements, also known as\nnondeterminism-introducing (NI) factors, lead to variance in the training\nprocess and as a result, lead to variance in prediction accuracy and training\ntime. This variance poses a challenge for reproducibility in research. More\nimportantly, while fault prediction models may have shown good performance in\nthe lab (e.g., often-times involving multiple runs and averaging outcomes),\nhigh variance of results can pose the risk that these models show low\nperformance when applied in practice. In this work, we experimentally analyze\nthe variance of a state-of-the-art fault prediction approach. Our experimental\nresults indicate that NI factors can indeed cause considerable variance in the\nfault prediction models' accuracy. We observed a maximum variance of 10.10% in\nterms of the per-class accuracy metric. We thus, also discuss how to deal with\nsuch variance.",
          "link": "http://arxiv.org/abs/2310.17264",
          "publishedOn": "2023-10-28T00:41:30.109Z",
          "wordCount": null,
          "title": "Variance of ML-based software fault predictors: are we really improving fault prediction?. (arXiv:2310.17264v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Racz_D/0/1/0/all/0/1\">D&#xe1;niel R&#xe1;cz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petreczky_M/0/1/0/all/0/1\">Mih&#xe1;ly Petreczky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Csertan_A/0/1/0/all/0/1\">Andr&#xe1;s Csert&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daroczy_B/0/1/0/all/0/1\">B&#xe1;lint Dar&#xf3;czy</a>",
          "description": "Recent advances in deep learning have given us some very promising results on\nthe generalization ability of deep neural networks, however literature still\nlacks a comprehensive theory explaining why heavily over-parametrized models\nare able to generalize well while fitting the training data. In this paper we\npropose a PAC type bound on the generalization error of feedforward ReLU\nnetworks via estimating the Rademacher complexity of the set of networks\navailable from an initial parameter vector via gradient descent. The key idea\nis to bound the sensitivity of the network's gradient to perturbation of the\ninput data along the optimization trajectory. The obtained bound does not\nexplicitly depend on the depth of the network. Our results are experimentally\nverified on the MNIST and CIFAR-10 datasets.",
          "link": "http://arxiv.org/abs/2310.17378",
          "publishedOn": "2023-10-28T00:41:30.109Z",
          "wordCount": null,
          "title": "Optimization dependent generalization bound for ReLU networks based on sensitivity in the tangent bundle. (arXiv:2310.17378v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ronchetti_F/0/1/0/all/0/1\">Franco Ronchetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quiroga_F/0/1/0/all/0/1\">Facundo Manuel Quiroga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Estrebou_C/0/1/0/all/0/1\">C&#xe9;sar Estrebou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lanzarini_L/0/1/0/all/0/1\">Laura Lanzarini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosete_A/0/1/0/all/0/1\">Alejandro Rosete</a>",
          "description": "Automatic sign language recognition (SLR) is an important topic within the\nareas of human-computer interaction and machine learning. On the one hand, it\nposes a complex challenge that requires the intervention of various knowledge\nareas, such as video processing, image processing, intelligent systems and\nlinguistics. On the other hand, robust recognition of sign language could\nassist in the translation process and the integration of hearing-impaired\npeople, as well as the teaching of sign language for the hearing population.\n\nSLR systems usually employ Hidden Markov Models, Dynamic Time Warping or\nsimilar models to recognize signs. Such techniques exploit the sequential\nordering of frames to reduce the number of hypothesis. This paper presents a\ngeneral probabilistic model for sign classification that combines\nsub-classifiers based on different types of features such as position, movement\nand handshape. The model employs a bag-of-words approach in all classification\nsteps, to explore the hypothesis that ordering is not essential for\nrecognition. The proposed model achieved an accuracy rate of 97% on an\nArgentinian Sign Language dataset containing 64 classes of signs and 3200\nsamples, providing some evidence that indeed recognition without ordering is\npossible.",
          "link": "http://arxiv.org/abs/2310.17437",
          "publishedOn": "2023-10-28T00:41:30.109Z",
          "wordCount": null,
          "title": "Sign Languague Recognition without frame-sequencing constraints: A proof of concept on the Argentinian Sign Language. (arXiv:2310.17437v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Terence Jie Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>",
          "description": "The efficient deployment and fine-tuning of foundation models are pivotal in\ncontemporary artificial intelligence. In this study, we present a\ngroundbreaking paradigm integrating Mobile Edge Computing (MEC) with foundation\nmodels, specifically designed to enhance local task performance on user\nequipment (UE). Central to our approach is the innovative Emulator-Adapter\narchitecture, segmenting the foundation model into two cohesive modules. This\ndesign not only conserves computational resources but also ensures adaptability\nand fine-tuning efficiency for downstream tasks. Additionally, we introduce an\nadvanced resource allocation mechanism that is fine-tuned to the needs of the\nEmulator-Adapter structure in decentralized settings. To address the challenges\npresented by this system, we employ a hybrid multi-agent Deep Reinforcement\nLearning (DRL) strategy, adept at handling mixed discrete-continuous action\nspaces, ensuring dynamic and optimal resource allocations. Our comprehensive\nsimulations and validations underscore the practical viability of our approach,\ndemonstrating its robustness, efficiency, and scalability. Collectively, this\nwork offers a fresh perspective on deploying foundation models and balancing\ncomputational efficiency with task proficiency.",
          "link": "http://arxiv.org/abs/2310.17492",
          "publishedOn": "2023-10-28T00:41:30.109Z",
          "wordCount": null,
          "title": "Orchestration of Emulator Assisted Mobile Edge Tuning for AI Foundation Models: A Multi-Agent Deep Reinforcement Learning Approach. (arXiv:2310.17492v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sievers_J/0/1/0/all/0/1\">Jonas Sievers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blank_T/0/1/0/all/0/1\">Thomas Blank</a>",
          "description": "Electricity load forecasting is an essential task within smart grids to\nassist demand and supply balance. While advanced deep learning models require\nlarge amounts of high-resolution data for accurate short-term load predictions,\nfine-grained load profiles can expose users' electricity consumption behaviors,\nwhich raises privacy and security concerns. One solution to improve data\nprivacy is federated learning, where models are trained locally on private\ndata, and only the trained model parameters are merged and updated on a global\nserver. Therefore, this paper presents a novel transformer-based deep learning\napproach with federated learning for short-term electricity load prediction. To\nevaluate our results, we benchmark our federated learning architecture against\ncentral and local learning and compare the performance of our model to long\nshort-term memory models and convolutional neural networks. Our simulations are\nbased on a dataset from a German university campus and show that\ntransformer-based forecasting is a promising alternative to state-of-the-art\nmodels within federated learning.",
          "link": "http://arxiv.org/abs/2310.17477",
          "publishedOn": "2023-10-28T00:41:30.108Z",
          "wordCount": null,
          "title": "Secure short-term load forecasting for smart grids with transformer-based federated learning. (arXiv:2310.17477v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17341",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Buin_A/0/1/0/all/0/1\">Andrei Buin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1\">Hung Yi Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadsden_S/0/1/0/all/0/1\">S. Andrew Gadsden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alderson_F/0/1/0/all/0/1\">Faraz A. Alderson</a>",
          "description": "We present here a combination of two networks, Recurrent Neural Networks\n(RNN) and Temporarily Convolutional Neural Networks (TCN) in de novo reaction\ngeneration using the novel Reaction Smiles-like representation of reactions\n(CGRSmiles) with atom mapping directly incorporated. Recurrent Neural Networks\nare known for their autoregressive properties and are frequently used in\nlanguage modelling with direct application to SMILES generation. The relatively\nnovel TCNs possess similar properties with wide receptive field while obeying\nthe causality required for natural language processing (NLP). The combination\nof both latent representations expressed through TCN and RNN results in an\noverall better performance compared to RNN alone. Additionally, it is shown\nthat different fine-tuning protocols have a profound impact on generative scope\nof the model when applied on a dataset of interest via transfer learning.",
          "link": "http://arxiv.org/abs/2310.17341",
          "publishedOn": "2023-10-28T00:41:30.107Z",
          "wordCount": null,
          "title": "De-novo Chemical Reaction Generation by Means of Temporarily Convolutional Neural Networks. (arXiv:2310.17341v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17394",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Q/0/1/0/all/0/1\">Qingqing Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zeyuan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yiding Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_A/0/1/0/all/0/1\">Anfeng Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuaiqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Dawei Yin</a>",
          "description": "Graph Neural Networks (GNNs) are powerful in learning semantics of graph\ndata. Recently, a new paradigm \"pre-train, prompt\" has shown promising results\nin adapting GNNs to various tasks with less supervised data. The success of\nsuch paradigm can be attributed to the more consistent objectives of\npre-training and task-oriented prompt tuning, where the pre-trained knowledge\ncan be effectively transferred to downstream tasks. However, an overlooked\nissue of existing studies is that the structure information of graph is usually\nexploited during pre-training for learning node representations, while\nneglected in the prompt tuning stage for learning task-specific parameters. To\nbridge this gap, we propose a novel structure-based prompting method for GNNs,\nnamely SAP, which consistently exploits structure information in both\npre-training and prompt tuning stages. In particular, SAP 1) employs a\ndual-view contrastive learning to align the latent semantic spaces of node\nattributes and graph structure, and 2) incorporates structure information in\nprompted graph to elicit more pre-trained knowledge in prompt tuning. We\nconduct extensive experiments on node classification and graph classification\ntasks to show the effectiveness of SAP. Moreover, we show that SAP can lead to\nbetter performance in more challenging few-shot scenarios on both homophilous\nand heterophilous graphs.",
          "link": "http://arxiv.org/abs/2310.17394",
          "publishedOn": "2023-10-28T00:41:30.107Z",
          "wordCount": null,
          "title": "Enhancing Graph Neural Networks with Structure-Based Prompt. (arXiv:2310.17394v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hess_K/0/1/0/all/0/1\">Konstantin Hess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melnychuk_V/0/1/0/all/0/1\">Valentyn Melnychuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frauen_D/0/1/0/all/0/1\">Dennis Frauen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>",
          "description": "Treatment effect estimation in continuous time is crucial for personalized\nmedicine. However, existing methods for this task are limited to point\nestimates of the potential outcomes, whereas uncertainty estimates have been\nignored. Needless to say, uncertainty quantification is crucial for reliable\ndecision-making in medical applications. To fill this gap, we propose a novel\nBayesian neural controlled differential equation (BNCDE) for treatment effect\nestimation in continuous time. In our BNCDE, the time dimension is modeled\nthrough a coupled system of neural controlled differential equations and neural\nstochastic differential equations, where the neural stochastic differential\nequations allow for tractable variational Bayesian inference. Thereby, for an\nassigned sequence of treatments, our BNCDE provides meaningful posterior\npredictive distributions of the potential outcomes. To the best of our\nknowledge, ours is the first tailored neural method to provide uncertainty\nestimates of treatment effects in continuous time. As such, our method is of\ndirect practical value for promoting reliable decision-making in medicine.",
          "link": "http://arxiv.org/abs/2310.17463",
          "publishedOn": "2023-10-28T00:41:30.107Z",
          "wordCount": null,
          "title": "Bayesian Neural Controlled Differential Equations for Treatment Effect Estimation. (arXiv:2310.17463v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scheurer_E/0/1/0/all/0/1\">Erik Scheurer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmalfuss_J/0/1/0/all/0/1\">Jenny Schmalfuss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lis_A/0/1/0/all/0/1\">Alexander Lis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruhn_A/0/1/0/all/0/1\">Andr&#xe9;s Bruhn</a>",
          "description": "Adversarial patches undermine the reliability of optical flow predictions\nwhen placed in arbitrary scene locations. Therefore, they pose a realistic\nthreat to real-world motion detection and its downstream applications.\nPotential remedies are defense strategies that detect and remove adversarial\npatches, but their influence on the underlying motion prediction has not been\ninvestigated. In this paper, we thoroughly examine the currently available\ndetect-and-remove defenses ILP and LGS for a wide selection of state-of-the-art\noptical flow methods, and illuminate their side effects on the quality and\nrobustness of the final flow predictions. In particular, we implement\ndefense-aware attacks to investigate whether current defenses are able to\nwithstand attacks that take the defense mechanism into account. Our experiments\nyield two surprising results: Detect-and-remove defenses do not only lower the\noptical flow quality on benign scenes, in doing so, they also harm the\nrobustness under patch attacks for all tested optical flow methods except\nFlowNetC. As currently employed detect-and-remove defenses fail to deliver the\npromised adversarial robustness for optical flow, they evoke a false sense of\nsecurity. The code is available at\nhttps://github.com/cv-stuttgart/DetectionDefenses.",
          "link": "http://arxiv.org/abs/2310.17403",
          "publishedOn": "2023-10-28T00:41:30.106Z",
          "wordCount": null,
          "title": "Detection Defenses: An Empty Promise against Adversarial Patch Attacks on Optical Flow. (arXiv:2310.17403v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goodier_J/0/1/0/all/0/1\">Joseph Goodier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_N/0/1/0/all/0/1\">Neill D.F. Campbell</a>",
          "description": "Out-of-Distribution detection between dataset pairs has been extensively\nexplored with generative models. We show that likelihood-based\nOut-of-Distribution detection can be extended to diffusion models by leveraging\nthe fact that they, like other likelihood-based generative models, are\ndramatically affected by the input sample complexity. Currently, all\nOut-of-Distribution detection methods with Diffusion Models are\nreconstruction-based. We propose a new likelihood ratio for Out-of-Distribution\ndetection with Deep Denoising Diffusion Models, which we call the Complexity\nCorrected Likelihood Ratio. Our likelihood ratio is constructed using Evidence\nLower-Bound evaluations from an individual model at various noising levels. We\npresent results that are comparable to state-of-the-art Out-of-Distribution\ndetection methods with generative models.",
          "link": "http://arxiv.org/abs/2310.17432",
          "publishedOn": "2023-10-28T00:41:30.106Z",
          "wordCount": null,
          "title": "Likelihood-based Out-of-Distribution Detection with Denoising Diffusion Probabilistic Models. (arXiv:2310.17432v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yang Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yuan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1\">Dezhong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Joey Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Peng Hu</a>",
          "description": "Recently, image-text matching has attracted more and more attention from\nacademia and industry, which is fundamental to understanding the latent\ncorrespondence across visual and textual modalities. However, most existing\nmethods implicitly assume the training pairs are well-aligned while ignoring\nthe ubiquitous annotation noise, a.k.a noisy correspondence (NC), thereby\ninevitably leading to a performance drop. Although some methods attempt to\naddress such noise, they still face two challenging problems: excessive\nmemorizing/overfitting and unreliable correction for NC, especially under high\nnoise. To address the two problems, we propose a generalized Cross-modal Robust\nComplementary Learning framework (CRCL), which benefits from a novel Active\nComplementary Loss (ACL) and an efficient Self-refining Correspondence\nCorrection (SCC) to improve the robustness of existing methods. Specifically,\nACL exploits active and complementary learning losses to reduce the risk of\nproviding erroneous supervision, leading to theoretically and experimentally\ndemonstrated robustness against NC. SCC utilizes multiple self-refining\nprocesses with momentum correction to enlarge the receptive field for\ncorrecting correspondences, thereby alleviating error accumulation and\nachieving accurate and stable corrections. We carry out extensive experiments\non three image-text benchmarks, i.e., Flickr30K, MS-COCO, and CC152K, to verify\nthe superior robustness of our CRCL against synthetic and real-world noisy\ncorrespondences.",
          "link": "http://arxiv.org/abs/2310.17468",
          "publishedOn": "2023-10-28T00:41:30.106Z",
          "wordCount": null,
          "title": "Cross-modal Active Complementary Learning with Self-refining Correspondence. (arXiv:2310.17468v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lorch_L/0/1/0/all/0/1\">Lars Lorch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "We develop a novel approach towards causal inference. Rather than structural\nequations over a causal graph, we learn stochastic differential equations\n(SDEs) whose stationary densities model a system's behavior under\ninterventions. These stationary diffusion models do not require the formalism\nof causal graphs, let alone the common assumption of acyclicity. We show that\nin several cases, they generalize to unseen interventions on their variables,\noften better than classical approaches. Our inference method is based on a new\ntheoretical result that expresses a stationarity condition on the diffusion's\ngenerator in a reproducing kernel Hilbert space. The resulting kernel deviation\nfrom stationarity (KDS) is an objective function of independent interest.",
          "link": "http://arxiv.org/abs/2310.17405",
          "publishedOn": "2023-10-28T00:41:30.105Z",
          "wordCount": null,
          "title": "Causal Modeling with Stationary Diffusions. (arXiv:2310.17405v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kienzle_D/0/1/0/all/0/1\">Daniel Kienzle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenz_J/0/1/0/all/0/1\">Julian Lorenz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludwig_K/0/1/0/all/0/1\">Katja Ludwig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lienhart_R/0/1/0/all/0/1\">Rainer Lienhart</a>",
          "description": "We present a novel method for precise 3D object localization in single images\nfrom a single calibrated camera using only 2D labels. No expensive 3D labels\nare needed. Thus, instead of using 3D labels, our model is trained with\neasy-to-annotate 2D labels along with the physical knowledge of the object's\nmotion. Given this information, the model can infer the latent third dimension,\neven though it has never seen this information during training. Our method is\nevaluated on both synthetic and real-world datasets, and we are able to achieve\na mean distance error of just 6 cm in our experiments on real data. The results\nindicate the method's potential as a step towards learning 3D object location\nestimation, where collecting 3D data for training is not feasible.",
          "link": "http://arxiv.org/abs/2310.17462",
          "publishedOn": "2023-10-28T00:41:30.105Z",
          "wordCount": null,
          "title": "Towards Learning Monocular 3D Object Localization From 2D Labels using the Physical Laws of Motion. (arXiv:2310.17462v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17383",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Czekaj_L/0/1/0/all/0/1\">&#x141;ukasz Czekaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radzinski_L/0/1/0/all/0/1\">&#x141;ukasz Radzinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolimaga_M/0/1/0/all/0/1\">Mateusz Kolimaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Domaszewicz_J/0/1/0/all/0/1\">Jakub Domaszewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitlowski_R/0/1/0/all/0/1\">Robert Kit&#x142;owski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szwoch_M/0/1/0/all/0/1\">Mariusz Szwoch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duch_W/0/1/0/all/0/1\">W&#x142;odzis&#x142;aw Duch</a>",
          "description": "Automated interpretation of signals yields many impressive applications from\nthe area of affective computing and human activity recognition (HAR). In this\npaper we ask the question about possibility of cognitive activity recognition\non the base of particular set of signals. We use recognition of the game played\nby the participant as a playground for exploration of the problem. We build\nclassifier of three different games (Space Invaders, Tetris, Tower Defence) and\ninter-game pause. We validate classifier in the player-independent and\nplayer-dependent scenario. We discuss the improvement in the player-dependent\nscenario in the context of biometric person recognition. On the base of the\nresults obtained in game classification, we consider potential applications in\nsmart surveillance and quantified self.",
          "link": "http://arxiv.org/abs/2310.17383",
          "publishedOn": "2023-10-28T00:41:30.104Z",
          "wordCount": null,
          "title": "On the recognition of the game type based on physiological signals and eye tracking. (arXiv:2310.17383v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17496",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Si_N/0/1/0/all/0/1\">Nian Si</a>",
          "description": "In modern recommendation systems, the standard pipeline involves training\nmachine learning models on historical data to predict user behaviors and\nimprove recommendations continuously. However, these data training loops can\nintroduce interference in A/B tests, where data generated by control and\ntreatment algorithms, potentially with different distributions, are combined.\nTo address these challenges, we introduce a novel approach called weighted\ntraining. This approach entails training a model to predict the probability of\neach data point appearing in either the treatment or control data and\nsubsequently applying weighted losses during model training. We demonstrate\nthat this approach achieves the least variance among all estimators without\ncausing shifts in the training distributions. Through simulation studies, we\ndemonstrate the lower bias and variance of our approach compared to other\nmethods.",
          "link": "http://arxiv.org/abs/2310.17496",
          "publishedOn": "2023-10-28T00:41:30.104Z",
          "wordCount": null,
          "title": "Tackling Interference Induced by Data Training Loops in A/B Tests: A Weighted Training Approach. (arXiv:2310.17496v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17499",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lux_F/0/1/0/all/0/1\">Florian Lux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koch_J/0/1/0/all/0/1\">Julia Koch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meyer_S/0/1/0/all/0/1\">Sarina Meyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bott_T/0/1/0/all/0/1\">Thomas Bott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schauffler_N/0/1/0/all/0/1\">Nadja Schauffler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denisov_P/0/1/0/all/0/1\">Pavel Denisov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schweitzer_A/0/1/0/all/0/1\">Antje Schweitzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1\">Ngoc Thang Vu</a>",
          "description": "For our contribution to the Blizzard Challenge 2023, we improved on the\nsystem we submitted to the Blizzard Challenge 2021. Our approach entails a\nrule-based text-to-phoneme processing system that includes rule-based\ndisambiguation of homographs in the French language. It then transforms the\nphonemes to spectrograms as intermediate representations using a fast and\nefficient non-autoregressive synthesis architecture based on Conformer and\nGlow. A GAN based neural vocoder that combines recent state-of-the-art\napproaches converts the spectrogram to the final wave. We carefully designed\nthe data processing, training, and inference procedures for the challenge data.\nOur system identifier is G. Open source code and demo are available.",
          "link": "http://arxiv.org/abs/2310.17499",
          "publishedOn": "2023-10-28T00:41:30.104Z",
          "wordCount": null,
          "title": "The IMS Toucan System for the Blizzard Challenge 2023. (arXiv:2310.17499v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17427",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ronchetti_F/0/1/0/all/0/1\">Franco Ronchetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quiroga_F/0/1/0/all/0/1\">Facundo Manuel Quiroga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Estrebou_C/0/1/0/all/0/1\">C&#xe9;sar Estrebou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lanzarini_L/0/1/0/all/0/1\">Laura Lanzarini</a>",
          "description": "Automatic sign language recognition is an important topic within the areas of\nhuman-computer interaction and machine learning. On the one hand, it poses a\ncomplex challenge that requires the intervention of various knowledge areas,\nsuch as video processing, image processing, intelligent systems and\nlinguistics. On the other hand, robust recognition of sign language could\nassist in the translation process and the integration of hearing-impaired\npeople.\n\nThis paper offers two main contributions: first, the creation of a database\nof handshapes for the Argentinian Sign Language (LSA), which is a topic that\nhas barely been discussed so far. Secondly, a technique for image processing,\ndescriptor extraction and subsequent handshape classification using a\nsupervised adaptation of self-organizing maps that is called ProbSom. This\ntechnique is compared to others in the state of the art, such as Support Vector\nMachines (SVM), Random Forests, and Neural Networks.\n\nThe database that was built contains 800 images with 16 LSA handshapes, and\nis a first step towards building a comprehensive database of Argentinian signs.\nThe ProbSom-based neural classifier, using the proposed descriptor, achieved an\naccuracy rate above 90%.",
          "link": "http://arxiv.org/abs/2310.17427",
          "publishedOn": "2023-10-28T00:41:30.103Z",
          "wordCount": null,
          "title": "Handshape recognition for Argentinian Sign Language using ProbSom. (arXiv:2310.17427v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fengzhuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1\">Vincent Y. F. Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>",
          "description": "We design and analyze reinforcement learning algorithms for Graphon\nMean-Field Games (GMFGs). In contrast to previous works that require the\nprecise values of the graphons, we aim to learn the Nash Equilibrium (NE) of\nthe regularized GMFGs when the graphons are unknown. Our contributions are\nthreefold. First, we propose the Proximal Policy Optimization for GMFG\n(GMFG-PPO) algorithm and show that it converges at a rate of $O(T^{-1/3})$\nafter $T$ iterations with an estimation oracle, improving on a previous work by\nXie et al. (ICML, 2021). Second, using kernel embedding of distributions, we\ndesign efficient algorithms to estimate the transition kernels, reward\nfunctions, and graphons from sampled agents. Convergence rates are then derived\nwhen the positions of the agents are either known or unknown. Results for the\ncombination of the optimization algorithm GMFG-PPO and the estimation algorithm\nare then provided. These algorithms are the first specifically designed for\nlearning graphons from sampled agents. Finally, the efficacy of the proposed\nalgorithms are corroborated through simulations. These simulations demonstrate\nthat learning the unknown graphons reduces the exploitability effectively.",
          "link": "http://arxiv.org/abs/2310.17531",
          "publishedOn": "2023-10-28T00:41:30.103Z",
          "wordCount": null,
          "title": "Learning Regularized Graphon Mean-Field Games with Unknown Graphons. (arXiv:2310.17531v1 [cs.GT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Alice Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_A/0/1/0/all/0/1\">Adith Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1\">Andrey Kolobov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Ching-An Cheng</a>",
          "description": "The ability to learn and refine behavior after deployment has become ever\nmore important for robots as we design them to operate in unstructured\nenvironments like households. In this work, we design a new learning system\nbased on large language model (LLM), OLAF, that allows everyday users to teach\na robot using verbal corrections when the robot makes mistakes, e.g., by saying\n\"Stop what you're doing. You should move closer to the cup.\" A key feature of\nOLAF is its ability to update the robot's visuomotor neural policy based on the\nverbal feedback to avoid repeating mistakes in the future. This is in contrast\nto existing LLM-based robotic systems, which only follow verbal commands or\ncorrections but not learn from them. We demonstrate the efficacy of our design\nin experiments where a user teaches a robot to perform long-horizon\nmanipulation tasks both in simulation and on physical hardware, achieving on\naverage 20.0% improvement in policy success rate. Videos and more results are\nat https://ut-austin-rpl.github.io/olaf/",
          "link": "http://arxiv.org/abs/2310.17555",
          "publishedOn": "2023-10-28T00:41:30.103Z",
          "wordCount": null,
          "title": "Interactive Robot Learning from Verbal Correction. (arXiv:2310.17555v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quiroga_F/0/1/0/all/0/1\">Facundo Manuel Quiroga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torrents_Barrena_J/0/1/0/all/0/1\">Jordina Torrents-Barrena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lanzarini_L/0/1/0/all/0/1\">Laura Cristina Lanzarini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puig_Valls_D/0/1/0/all/0/1\">Domenec Puig-Valls</a>",
          "description": "Invariances in neural networks are useful and necessary for many tasks.\nHowever, the representation of the invariance of most neural network models has\nnot been characterized. We propose measures to quantify the invariance of\nneural networks in terms of their internal representation. The measures are\nefficient and interpretable, and can be applied to any neural network model.\nThey are also more sensitive to invariance than previously defined measures. We\nvalidate the measures and their properties in the domain of affine\ntransformations and the CIFAR10 and MNIST datasets, including their stability\nand interpretability. Using the measures, we perform a first analysis of CNN\nmodels and show that their internal invariance is remarkably stable to random\nweight initializations, but not to changes in dataset or transformation. We\nbelieve the measures will enable new avenues of research in invariance\nrepresentation.",
          "link": "http://arxiv.org/abs/2310.17404",
          "publishedOn": "2023-10-28T00:41:30.102Z",
          "wordCount": null,
          "title": "Invariance Measures for Neural Networks. (arXiv:2310.17404v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yuchen Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kangwook Lee</a>",
          "description": "Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that\nleverages low-rank adaptation of weight matrices, has emerged as a prevalent\ntechnique for fine-tuning pre-trained models such as large language models and\ndiffusion models. Despite its huge success in practice, the theoretical\nunderpinnings of LoRA have largely remained unexplored. This paper takes the\nfirst step to bridge this gap by theoretically analyzing the expressive power\nof LoRA. We prove that, for fully connected neural networks, LoRA can adapt any\nmodel $f$ to accurately represent any smaller target model $\\overline{f}$ if\nLoRA-rank $\\geq(\\text{width of }f) \\times \\frac{\\text{depth of\n}\\overline{f}}{\\text{depth of }f}$. We also quantify the approximation error\nwhen LoRA-rank is lower than the threshold. For Transformer networks, we show\nany model can be adapted to a target model of the same size with\nrank-$(\\frac{\\text{embedding size}}{2})$ LoRA adapters.",
          "link": "http://arxiv.org/abs/2310.17513",
          "publishedOn": "2023-10-28T00:41:30.102Z",
          "wordCount": null,
          "title": "The Expressive Power of Low-Rank Adaptation. (arXiv:2310.17513v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mak_S/0/1/0/all/0/1\">Stephen Mak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liming Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pearce_T/0/1/0/all/0/1\">Tim Pearce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostroumov_M/0/1/0/all/0/1\">Michael Ostroumov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1\">Alexandra Brintrup</a>",
          "description": "Collaborative Vehicle Routing is where delivery companies cooperate by\nsharing their delivery information and performing delivery requests on behalf\nof each other. This achieves economies of scale and thus reduces cost,\ngreenhouse gas emissions, and road congestion. But which company should partner\nwith whom, and how much should each company be compensated? Traditional game\ntheoretic solution concepts, such as the Shapley value or nucleolus, are\ndifficult to calculate for the real-world problem of Collaborative Vehicle\nRouting due to the characteristic function scaling exponentially with the\nnumber of agents. This would require solving the Vehicle Routing Problem (an\nNP-Hard problem) an exponential number of times. We therefore propose to model\nthis problem as a coalitional bargaining game where - crucially - agents are\nnot given access to the characteristic function. Instead, we implicitly reason\nabout the characteristic function, and thus eliminate the need to evaluate the\nVRP an exponential number of times - we only need to evaluate it once. Our\ncontribution is that our decentralised approach is both scalable and considers\nthe self-interested nature of companies. The agents learn using a modified\nIndependent Proximal Policy Optimisation. Our RL agents outperform a strong\nheuristic bot. The agents correctly identify the optimal coalitions 79% of the\ntime with an average optimality gap of 4.2% and reduction in run-time of 62%.",
          "link": "http://arxiv.org/abs/2310.17458",
          "publishedOn": "2023-10-28T00:41:30.101Z",
          "wordCount": null,
          "title": "Coalitional Bargaining via Reinforcement Learning: An Application to Collaborative Vehicle Routing. (arXiv:2310.17458v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Z/0/1/0/all/0/1\">Zhen Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1\">Zidi Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Backdoor attack is a common threat to deep neural networks. During testing,\nsamples embedded with a backdoor trigger will be misclassified as an\nadversarial target by a backdoored model, while samples without the backdoor\ntrigger will be correctly classified. In this paper, we present the first\ncertified backdoor detector (CBD), which is based on a novel, adjustable\nconformal prediction scheme based on our proposed statistic local dominant\nprobability. For any classifier under inspection, CBD provides 1) a detection\ninference, 2) the condition under which the attacks are guaranteed to be\ndetectable for the same classification domain, and 3) a probabilistic upper\nbound for the false positive rate. Our theoretical results show that attacks\nwith triggers that are more resilient to test-time noise and have smaller\nperturbation magnitudes are more likely to be detected with guarantees.\nMoreover, we conduct extensive experiments on four benchmark datasets\nconsidering various backdoor types, such as BadNet, CB, and Blend. CBD achieves\ncomparable or even higher detection accuracy than state-of-the-art detectors,\nand it in addition provides detection certification. Notably, for backdoor\nattacks with random perturbation triggers bounded by $\\ell_2\\leq0.75$ which\nachieves more than 90\\% attack success rate, CBD achieves 100\\% (98\\%), 100\\%\n(84\\%), 98\\% (98\\%), and 72\\% (40\\%) empirical (certified) detection true\npositive rates on the four benchmark datasets GTSRB, SVHN, CIFAR-10, and\nTinyImageNet, respectively, with low false positive rates.",
          "link": "http://arxiv.org/abs/2310.17498",
          "publishedOn": "2023-10-28T00:41:30.101Z",
          "wordCount": null,
          "title": "CBD: A Certified Backdoor Detector Based on Local Dominant Probability. (arXiv:2310.17498v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tumay_A/0/1/0/all/0/1\">Aysin Tumay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aydin_M/0/1/0/all/0/1\">Mustafa E. Aydin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozat_S/0/1/0/all/0/1\">Suleyman S. Kozat</a>",
          "description": "We study a novel ensemble approach for feature selection based on\nhierarchical stacking in cases of non-stationarity and limited number of\nsamples with large number of features. Our approach exploits the co-dependency\nbetween features using a hierarchical structure. Initially, a machine learning\nmodel is trained using a subset of features, and then the model's output is\nupdated using another algorithm with the remaining features to minimize the\ntarget loss. This hierarchical structure allows for flexible depth and feature\nselection. By exploiting feature co-dependency hierarchically, our proposed\napproach overcomes the limitations of traditional feature selection methods and\nfeature importance scores. The effectiveness of the approach is demonstrated on\nsynthetic and real-life datasets, indicating improved performance with\nscalability and stability compared to the traditional methods and\nstate-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2310.17544",
          "publishedOn": "2023-10-28T00:41:30.101Z",
          "wordCount": null,
          "title": "Hierarchical Ensemble-Based Feature Selection for Time Series Forecasting. (arXiv:2310.17544v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17386",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ivanova_A/0/1/0/all/0/1\">Anastasia Ivanova</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ablin_P/0/1/0/all/0/1\">Pierre Ablin</a>",
          "description": "In many scenarios, one uses a large training set to train a model with the\ngoal of performing well on a smaller testing set with a different distribution.\nLearning a weight for each data point of the training set is an appealing\nsolution, as it ideally allows one to automatically learn the importance of\neach training point for generalization on the testing set. This task is usually\nformalized as a bilevel optimization problem. Classical bilevel solvers are\nbased on a warm-start strategy where both the parameters of the models and the\ndata weights are learned at the same time. We show that this joint dynamic may\nlead to sub-optimal solutions, for which the final data weights are very\nsparse. This finding illustrates the difficulty of data reweighting and offers\na clue as to why this method is rarely used in practice.",
          "link": "http://arxiv.org/abs/2310.17386",
          "publishedOn": "2023-10-28T00:41:30.100Z",
          "wordCount": null,
          "title": "A Challenge in Reweighting Data with Bilevel Optimization. (arXiv:2310.17386v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhiheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xijun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Howard H. Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1\">Chenyuan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Junshen Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Sihui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1\">Tony Q. S. Quek</a>",
          "description": "Future wireless communication networks are in a position to move beyond\ndata-centric, device-oriented connectivity and offer intelligent, immersive\nexperiences based on task-oriented connections, especially in the context of\nthe thriving development of pre-trained foundation models (PFM) and the\nevolving vision of 6G native artificial intelligence (AI). Therefore,\nredefining modes of collaboration between devices and servers and constructing\nnative intelligence libraries become critically important in 6G. In this paper,\nwe analyze the challenges of achieving 6G native AI from the perspectives of\ndata, intelligence, and networks. Then, we propose a 6G native AI framework\nbased on foundation models, provide a customization approach for intent-aware\nPFM, present a construction of a task-oriented AI toolkit, and outline a novel\ncloud-edge-end collaboration paradigm. As a practical use case, we apply this\nframework for orchestration, achieving the maximum sum rate within a wireless\ncommunication system, and presenting preliminary evaluation results. Finally,\nwe outline research directions for achieving native AI in 6G.",
          "link": "http://arxiv.org/abs/2310.17471",
          "publishedOn": "2023-10-28T00:41:30.100Z",
          "wordCount": null,
          "title": "Foundation Model Based Native AI Framework in 6G with Cloud-Edge-End Collaboration. (arXiv:2310.17471v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mak_S/0/1/0/all/0/1\">Stephen Mak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liming Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pearce_T/0/1/0/all/0/1\">Tim Pearce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostroumov_M/0/1/0/all/0/1\">Michael Ostroumov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1\">Alexandra Brintrup</a>",
          "description": "Collaborative vehicle routing occurs when carriers collaborate through\nsharing their transportation requests and performing transportation requests on\nbehalf of each other. This achieves economies of scale, thus reducing cost,\ngreenhouse gas emissions and road congestion. But which carrier should partner\nwith whom, and how much should each carrier be compensated? Traditional game\ntheoretic solution concepts are expensive to calculate as the characteristic\nfunction scales exponentially with the number of agents. This would require\nsolving the vehicle routing problem (NP-hard) an exponential number of times.\nWe therefore propose to model this problem as a coalitional bargaining game\nsolved using deep multi-agent reinforcement learning, where - crucially -\nagents are not given access to the characteristic function. Instead, we\nimplicitly reason about the characteristic function; thus, when deployed in\nproduction, we only need to evaluate the expensive post-collaboration vehicle\nrouting problem once. Our contribution is that we are the first to consider\nboth the route allocation problem and gain sharing problem simultaneously -\nwithout access to the expensive characteristic function. Through decentralised\nmachine learning, our agents bargain with each other and agree to outcomes that\ncorrelate well with the Shapley value - a fair profit allocation mechanism.\nImportantly, we are able to achieve a reduction in run-time of 88%.",
          "link": "http://arxiv.org/abs/2310.17485",
          "publishedOn": "2023-10-28T00:41:30.100Z",
          "wordCount": null,
          "title": "Fair collaborative vehicle routing: A deep multi-agent reinforcement learning approach. (arXiv:2310.17485v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1\">Miao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Beining Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1\">Difan Zou</a>",
          "description": "In this work, we theoretically investigate the generalization properties of\nneural networks (NN) trained by stochastic gradient descent (SGD) algorithm\nwith large learning rates. Under such a training regime, our finding is that,\nthe oscillation of the NN weights caused by the large learning rate SGD\ntraining turns out to be beneficial to the generalization of the NN, which\npotentially improves over the same NN trained by SGD with small learning rates\nthat converges more smoothly. In view of this finding, we call such a\nphenomenon \"benign oscillation\". Our theory towards demystifying such a\nphenomenon builds upon the feature learning perspective of deep learning.\nSpecifically, we consider a feature-noise data generation model that consists\nof (i) weak features which have a small $\\ell_2$-norm and appear in each data\npoint; (ii) strong features which have a larger $\\ell_2$-norm but only appear\nin a certain fraction of all data points; and (iii) noise. We prove that NNs\ntrained by oscillating SGD with a large learning rate can effectively learn the\nweak features in the presence of those strong features. In contrast, NNs\ntrained by SGD with a small learning rate can only learn the strong features\nbut makes little progress in learning the weak features. Consequently, when it\ncomes to the new testing data which consist of only weak features, the NN\ntrained by oscillating SGD with a large learning rate could still make correct\npredictions consistently, while the NN trained by small learning rate SGD\nfails. Our theory sheds light on how large learning rate training benefits the\ngeneralization of NNs. Experimental results demonstrate our finding on \"benign\noscillation\".",
          "link": "http://arxiv.org/abs/2310.17074",
          "publishedOn": "2023-10-28T00:41:30.099Z",
          "wordCount": null,
          "title": "Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates. (arXiv:2310.17074v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17303",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tiapkin_D/0/1/0/all/0/1\">Daniil Tiapkin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Belomestny_D/0/1/0/all/0/1\">Denis Belomestny</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Calandriello_D/0/1/0/all/0/1\">Daniele Calandriello</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1\">Eric Moulines</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Naumov_A/0/1/0/all/0/1\">Alexey Naumov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Perrault_P/0/1/0/all/0/1\">Pierre Perrault</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Menard_P/0/1/0/all/0/1\">Pierre Menard</a>",
          "description": "Incorporating expert demonstrations has empirically helped to improve the\nsample efficiency of reinforcement learning (RL). This paper quantifies\ntheoretically to what extent this extra information reduces RL's sample\ncomplexity. In particular, we study the demonstration-regularized reinforcement\nlearning that leverages the expert demonstrations by KL-regularization for a\npolicy learned by behavior cloning. Our findings reveal that using\n$N^{\\mathrm{E}}$ expert demonstrations enables the identification of an optimal\npolicy at a sample complexity of order\n$\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(S,A,H)/(\\varepsilon^2 N^{\\mathrm{E}}))$\nin finite and $\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(d,H)/(\\varepsilon^2\nN^{\\mathrm{E}}))$ in linear Markov decision processes, where $\\varepsilon$ is\nthe target precision, $H$ the horizon, $A$ the number of action, $S$ the number\nof states in the finite case and $d$ the dimension of the feature space in the\nlinear case. As a by-product, we provide tight convergence guarantees for the\nbehaviour cloning procedure under general assumptions on the policy classes.\nAdditionally, we establish that demonstration-regularized methods are provably\nefficient for reinforcement learning from human feedback (RLHF). In this\nrespect, we provide theoretical evidence showing the benefits of\nKL-regularization for RLHF in tabular and linear MDPs. Interestingly, we avoid\npessimism injection by employing computationally feasible regularization to\nhandle reward estimation uncertainty, thus setting our approach apart from the\nprior works.",
          "link": "http://arxiv.org/abs/2310.17303",
          "publishedOn": "2023-10-28T00:41:30.099Z",
          "wordCount": null,
          "title": "Demonstration-Regularized RL. (arXiv:2310.17303v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hirsch_R/0/1/0/all/0/1\">Roy Hirsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_R/0/1/0/all/0/1\">Regev Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caron_M/0/1/0/all/0/1\">Mathilde Caron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golany_T/0/1/0/all/0/1\">Tomer Golany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freedman_D/0/1/0/all/0/1\">Daniel Freedman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rivlin_E/0/1/0/all/0/1\">Ehud Rivlin</a>",
          "description": "A key element of computer-assisted surgery systems is phase recognition of\nsurgical videos. Existing phase recognition algorithms require frame-wise\nannotation of a large number of videos, which is time and money consuming. In\nthis work we join concepts of graph segmentation with self-supervised learning\nto derive a random-walk solution for per-frame phase prediction. Furthermore,\nwe utilize within our method two forms of weak supervision: sparse timestamps\nor few-shot learning. The proposed algorithm enjoys low complexity and can\noperate in lowdata regimes. We validate our method by running experiments with\nthe public Cholec80 dataset of laparoscopic cholecystectomy videos,\ndemonstrating promising performance in multiple setups.",
          "link": "http://arxiv.org/abs/2310.17209",
          "publishedOn": "2023-10-28T00:41:30.098Z",
          "wordCount": null,
          "title": "Weakly-Supervised Surgical Phase Recognition. (arXiv:2310.17209v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17332",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Godahewa_R/0/1/0/all/0/1\">Rakshitha Godahewa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergmeir_C/0/1/0/all/0/1\">Christoph Bergmeir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baz_Z/0/1/0/all/0/1\">Zeynep Erkin Baz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chengjun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhangdi Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_S/0/1/0/all/0/1\">Salvador Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benavides_D/0/1/0/all/0/1\">Dario Benavides</a>",
          "description": "Forecasts are typically not produced in a vacuum but in a business context,\nwhere forecasts are generated on a regular basis and interact with each other.\nFor decisions, it may be important that forecasts do not change arbitrarily,\nand are stable in some sense. However, this area has received only limited\nattention in the forecasting literature. In this paper, we explore two types of\nforecast stability that we call vertical stability and horizontal stability.\nThe existing works in the literature are only applicable to certain base models\nand extending these frameworks to be compatible with any base model is not\nstraightforward. Furthermore, these frameworks can only stabilise the forecasts\nvertically. To fill this gap, we propose a simple linear-interpolation-based\napproach that is applicable to stabilise the forecasts provided by any base\nmodel vertically and horizontally. The approach can produce both accurate and\nstable forecasts. Using N-BEATS, Pooled Regression and LightGBM as the base\nmodels, in our evaluation on four publicly available datasets, the proposed\nframework is able to achieve significantly higher stability and/or accuracy\ncompared to a set of benchmarks including a state-of-the-art forecast\nstabilisation method across three error metrics and six stability metrics.",
          "link": "http://arxiv.org/abs/2310.17332",
          "publishedOn": "2023-10-28T00:41:30.098Z",
          "wordCount": null,
          "title": "On Forecast Stability. (arXiv:2310.17332v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Buyl_M/0/1/0/all/0/1\">Maarten Buyl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Defrance_M/0/1/0/all/0/1\">MaryBeth Defrance</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bie_T/0/1/0/all/0/1\">Tijl De Bie</a>",
          "description": "Current tools for machine learning fairness only admit a limited range of\nfairness definitions and have seen little integration with automatic\ndifferentiation libraries, despite the central role these libraries play in\nmodern machine learning pipelines.\n\nWe introduce a framework of fairness regularization terms (fairrets) which\nquantify bias as modular objectives that are easily integrated in automatic\ndifferentiation pipelines. By employing a general definition of fairness in\nterms of linear-fractional statistics, a wide class of fairrets can be computed\nefficiently. Experiments show the behavior of their gradients and their utility\nin enforcing fairness with minimal loss of predictive power compared to\nbaselines. Our contribution includes a PyTorch implementation of the fairret\nframework.",
          "link": "http://arxiv.org/abs/2310.17256",
          "publishedOn": "2023-10-28T00:41:30.097Z",
          "wordCount": null,
          "title": "fairret: a Framework for Differentiable Fairness Regularization Terms. (arXiv:2310.17256v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenkai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ehinger_K/0/1/0/all/0/1\">Krista A. Ehinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drummond_T/0/1/0/all/0/1\">Tom Drummond</a>",
          "description": "This paper introduces two key contributions aimed at improving the speed and\nquality of images generated through inverse diffusion processes. The first\ncontribution involves reparameterizing the diffusion process in terms of the\nangle on a quarter-circular arc between the image and noise, specifically\nsetting the conventional $\\displaystyle \\sqrt{\\bar{\\alpha}}=\\cos(\\eta)$. This\nreparameterization eliminates two singularities and allows for the expression\nof diffusion evolution as a well-behaved ordinary differential equation (ODE).\nIn turn, this allows higher order ODE solvers such as Runge-Kutta methods to be\nused effectively. The second contribution is to directly estimate both the\nimage ($\\mathbf{x}_0$) and noise ($\\mathbf{\\epsilon}$) using our network, which\nenables more stable calculations of the update step in the inverse diffusion\nsteps, as accurate estimation of both the image and noise are crucial at\ndifferent stages of the process. Together with these changes, our model\nachieves faster generation, with the ability to converge on high-quality images\nmore quickly, and higher quality of the generated images, as measured by\nmetrics such as Frechet Inception Distance (FID), spatial Frechet Inception\nDistance (sFID), precision, and recall.",
          "link": "http://arxiv.org/abs/2310.17167",
          "publishedOn": "2023-10-28T00:41:30.096Z",
          "wordCount": null,
          "title": "Improving Denoising Diffusion Models via Simultaneous Estimation of Image and Noise. (arXiv:2310.17167v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jiaxin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bang An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yuancheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yifan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>",
          "description": "Representation learning assumes that real-world data is generated by a few\nsemantically meaningful generative factors (i.e., sources of variation) and\naims to discover them in the latent space. These factors are expected to be\ncausally disentangled, meaning that distinct factors are encoded into separate\nlatent variables, and changes in one factor will not affect the values of the\nothers. Compared to statistical independence, causal disentanglement allows\nmore controllable data generation, improved robustness, and better\ngeneralization. However, most existing work assumes unconfoundedness in the\ndiscovery process, that there are no common causes to the generative factors\nand thus obtain only statistical independence. In this paper, we recognize the\nimportance of modeling confounders in discovering causal generative factors.\nUnfortunately, such factors are not identifiable without proper inductive bias.\nWe fill the gap by introducing a framework entitled Confounded-Disentanglement\n(C-Disentanglement), the first framework that explicitly introduces the\ninductive bias of confounder via labels from domain expertise. In addition, we\naccordingly propose an approach to sufficiently identify the causally\ndisentangled factors under any inductive bias of the confounder. We conduct\nextensive experiments on both synthetic and real-world datasets. Our method\ndemonstrates competitive results compared to various SOTA baselines in\nobtaining causally disentangled features and downstream tasks under domain\nshifts.",
          "link": "http://arxiv.org/abs/2310.17325",
          "publishedOn": "2023-10-28T00:41:30.096Z",
          "wordCount": null,
          "title": "C-Disentanglement: Discovering Causally-Independent Generative Factors under an Inductive Bias of Confounder. (arXiv:2310.17325v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seungjae Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_D/0/1/0/all/0/1\">Daesol Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jonghae Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">H. Jin Kim</a>",
          "description": "Recent curriculum Reinforcement Learning (RL) has shown notable progress in\nsolving complex tasks by proposing sequences of surrogate tasks. However, the\nprevious approaches often face challenges when they generate curriculum goals\nin a high-dimensional space. Thus, they usually rely on manually specified goal\nspaces. To alleviate this limitation and improve the scalability of the\ncurriculum, we propose a novel curriculum method that automatically defines the\nsemantic goal space which contains vital information for the curriculum\nprocess, and suggests curriculum goals over it. To define the semantic goal\nspace, our method discretizes continuous observations via vector\nquantized-variational autoencoders (VQ-VAE) and restores the temporal relations\nbetween the discretized observations by a graph. Concurrently, ours suggests\nuncertainty and temporal distance-aware curriculum goals that converges to the\nfinal goals over the automatically composed goal space. We demonstrate that the\nproposed method allows efficient explorations in an uninformed environment with\nraw goal examples only. Also, ours outperforms the state-of-the-art curriculum\nRL methods on data efficiency and performance, in various goal-reaching tasks\neven with ego-centric visual inputs.",
          "link": "http://arxiv.org/abs/2310.17330",
          "publishedOn": "2023-10-28T00:41:30.096Z",
          "wordCount": null,
          "title": "CQM: Curriculum Reinforcement Learning with a Quantized World Model. (arXiv:2310.17330v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17191",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiahai Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>",
          "description": "To correctly use in-context information, language models (LMs) must bind\nentities to their attributes. For example, given a context describing a \"green\nsquare\" and a \"blue circle\", LMs must bind the shapes to their respective\ncolors. We analyze LM representations and identify the binding ID mechanism: a\ngeneral mechanism for solving the binding problem, which we observe in every\nsufficiently large model from the Pythia and LLaMA families. Using causal\ninterventions, we show that LMs' internal activations represent binding\ninformation by attaching binding ID vectors to corresponding entities and\nattributes. We further show that binding ID vectors form a continuous subspace,\nin which distances between binding ID vectors reflect their discernability.\nOverall, our results uncover interpretable strategies in LMs for representing\nsymbolic knowledge in-context, providing a step towards understanding general\nin-context reasoning in large-scale LMs.",
          "link": "http://arxiv.org/abs/2310.17191",
          "publishedOn": "2023-10-28T00:41:30.094Z",
          "wordCount": null,
          "title": "How do Language Models Bind Entities in Context?. (arXiv:2310.17191v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gabardi_M/0/1/0/all/0/1\">Matteo Gabardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saibene_A/0/1/0/all/0/1\">Aurora Saibene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasparini_F/0/1/0/all/0/1\">Francesca Gasparini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizzo_D/0/1/0/all/0/1\">Daniele Rizzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stella_F/0/1/0/all/0/1\">Fabio Antonio Stella</a>",
          "description": "Electroencephalographic (EEG) signals are fundamental to neuroscience\nresearch and clinical applications such as brain-computer interfaces and\nneurological disorder diagnosis. These signals are typically a combination of\nneurological activity and noise, originating from various sources, including\nphysiological artifacts like ocular and muscular movements. Under this setting,\nwe tackle the challenge of distinguishing neurological activity from\nnoise-related sources. We develop a novel EEG denoising model that operates in\nthe frequency domain, leveraging prior knowledge about noise spectral features\nto adaptively compute optimal convolutional filters for noise separation. The\nmodel is trained to learn an empirical relationship connecting the spectral\ncharacteristics of noise and noisy signal to a non-linear transformation which\nallows signal denoising. Performance evaluation on the EEGdenoiseNet dataset\nshows that the proposed model achieves optimal results according to both\ntemporal and spectral metrics. The model is found to remove physiological\nartifacts from input EEG data, thus achieving effective EEG denoising. Indeed,\nthe model performance either matches or outperforms that achieved by benchmark\nmodels, proving to effectively remove both muscle and ocular artifacts without\nthe need to perform any training on the particular type of artifact.",
          "link": "http://arxiv.org/abs/2310.17335",
          "publishedOn": "2023-10-28T00:41:30.094Z",
          "wordCount": null,
          "title": "A multi-artifact EEG denoising by frequency-based deep learning. (arXiv:2310.17335v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.13268",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kaiwen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Cheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianfei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Diffusion probabilistic models (DPMs) have exhibited excellent performance\nfor high-fidelity image generation while suffering from inefficient sampling.\nRecent works accelerate the sampling procedure by proposing fast ODE solvers\nthat leverage the specific ODE form of DPMs. However, they highly rely on\nspecific parameterization during inference (such as noise/data prediction),\nwhich might not be the optimal choice. In this work, we propose a novel\nformulation towards the optimal parameterization during sampling that minimizes\nthe first-order discretization error of the ODE solution. Based on such\nformulation, we propose \\textit{DPM-Solver-v3}, a new fast ODE solver for DPMs\nby introducing several coefficients efficiently computed on the pretrained\nmodel, which we call \\textit{empirical model statistics}. We further\nincorporate multistep methods and a predictor-corrector framework, and propose\nsome techniques for improving sample quality at small numbers of function\nevaluations (NFE) or large guidance scales. Experiments show that DPM-Solver-v3\nachieves consistently better or comparable performance in both unconditional\nand conditional sampling with both pixel-space and latent-space DPMs,\nespecially in 5$\\sim$10 NFEs. We achieve FIDs of 12.21 (5 NFE), 2.51 (10 NFE)\non unconditional CIFAR10, and MSE of 0.55 (5 NFE, 7.5 guidance scale) on Stable\nDiffusion, bringing a speed-up of 15\\%$\\sim$30\\% compared to previous\nstate-of-the-art training-free methods. Code is available at\n\\url{https://github.com/thu-ml/DPM-Solver-v3}.",
          "link": "http://arxiv.org/abs/2310.13268",
          "publishedOn": "2023-10-28T00:41:30.094Z",
          "wordCount": null,
          "title": "DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model Statistics. (arXiv:2310.13268v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17178",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ugadiarov_L/0/1/0/all/0/1\">Leonid Ugadiarov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panov_A/0/1/0/all/0/1\">Aleksandr I. Panov</a>",
          "description": "There have recently been significant advances in the problem of unsupervised\nobject-centric representation learning and its application to downstream tasks.\nThe latest works support the argument that employing disentangled object\nrepresentations in image-based object-centric reinforcement learning tasks\nfacilitates policy learning. We propose a novel object-centric reinforcement\nlearning algorithm combining actor-critic and model-based approaches to utilize\nthese representations effectively. In our approach, we use a transformer\nencoder to extract object representations and graph neural networks to\napproximate the dynamics of an environment. The proposed method fills a\nresearch gap in developing efficient object-centric world models for\nreinforcement learning settings that can be used for environments with discrete\nor continuous action spaces. Our algorithm performs better in a visually\ncomplex 3D robotic environment and a 2D environment with compositional\nstructure than the state-of-the-art model-free actor-critic algorithm built\nupon transformer architecture and the state-of-the-art monolithic model-based\nalgorithm.",
          "link": "http://arxiv.org/abs/2310.17178",
          "publishedOn": "2023-10-28T00:41:30.093Z",
          "wordCount": null,
          "title": "Graphical Object-Centric Actor-Critic. (arXiv:2310.17178v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiao-Hu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xiao-Liang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shi-Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhen-Qiu Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao-Yin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_M/0/1/0/all/0/1\">Mei-Jiang Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1\">Tian-Yu Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">De-Xing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_B/0/1/0/all/0/1\">Bo-Xian Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1\">Zeng-Guang Hou</a>",
          "description": "Offline reinforcement learning (RL) aims to optimize policy using collected\ndata without online interactions. Model-based approaches are particularly\nappealing for addressing offline RL challenges due to their capability to\nmitigate the limitations of offline data through data generation using models.\nPrior research has demonstrated that introducing conservatism into the model or\nQ-function during policy optimization can effectively alleviate the prevalent\ndistribution drift problem in offline RL. However, the investigation into the\nimpacts of conservatism in reward estimation is still lacking. This paper\nproposes a novel model-based offline RL algorithm, Conservative Reward for\nmodel-based Offline Policy optimization (CROP), which conservatively estimates\nthe reward in model training. To achieve a conservative reward estimation, CROP\nsimultaneously minimizes the estimation error and the reward of random actions.\nTheoretical analysis shows that this conservative reward mechanism leads to a\nconservative policy evaluation and helps mitigate distribution drift.\nExperiments on D4RL benchmarks showcase that the performance of CROP is\ncomparable to the state-of-the-art baselines. Notably, CROP establishes an\ninnovative connection between offline and online RL, highlighting that offline\nRL problems can be tackled by adopting online RL techniques to the empirical\nMarkov decision process trained with a conservative reward. The source code is\navailable with https://github.com/G0K0URURI/CROP.git.",
          "link": "http://arxiv.org/abs/2310.17245",
          "publishedOn": "2023-10-28T00:41:30.093Z",
          "wordCount": null,
          "title": "CROP: Conservative Reward for Model-based Offline Policy Optimization. (arXiv:2310.17245v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1\">Jongheon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>",
          "description": "Along with recent diffusion models, randomized smoothing has become one of a\nfew tangible approaches that offers adversarial robustness to models at scale,\ne.g., those of large pre-trained models. Specifically, one can perform\nrandomized smoothing on any classifier via a simple \"denoise-and-classify\"\npipeline, so-called denoised smoothing, given that an accurate denoiser is\navailable - such as diffusion model. In this paper, we present scalable methods\nto address the current trade-off between certified robustness and accuracy in\ndenoised smoothing. Our key idea is to \"selectively\" apply smoothing among\nmultiple noise scales, coined multi-scale smoothing, which can be efficiently\nimplemented with a single diffusion model. This approach also suggests a new\nobjective to compare the collective robustness of multi-scale smoothed\nclassifiers, and questions which representation of diffusion model would\nmaximize the objective. To address this, we propose to further fine-tune\ndiffusion model (a) to perform consistent denoising whenever the original image\nis recoverable, but (b) to generate rather diverse outputs otherwise. Our\nexperiments show that the proposed multi-scale smoothing scheme combined with\ndiffusion fine-tuning enables strong certified robustness available with high\nnoise level while maintaining its accuracy closer to non-smoothed classifiers.",
          "link": "http://arxiv.org/abs/2310.16779",
          "publishedOn": "2023-10-28T00:41:30.093Z",
          "wordCount": null,
          "title": "Multi-scale Diffusion Denoised Smoothing. (arXiv:2310.16779v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Loveland_D/0/1/0/all/0/1\">Donald Loveland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caceres_R/0/1/0/all/0/1\">Rajmonda Caceres</a>",
          "description": "Graph Neural Network (GNN) research has produced strategies to modify a\ngraph's edges using gradients from a trained GNN, with the goal of network\ndesign. However, the factors which govern gradient-based editing are\nunderstudied, obscuring why edges are chosen and if edits are grounded in an\nedge's importance. Thus, we begin by analyzing the gradient computation in\nprevious works, elucidating the factors that influence edits and highlighting\nthe potential over-reliance on structural properties. Specifically, we find\nthat edges can achieve high gradients due to structural biases, rather than\nimportance, leading to erroneous edits when the factors are unrelated to the\ndesign task. To improve editing, we propose ORE, an iterative editing method\nthat (a) edits the highest scoring edges and (b) re-embeds the edited graph to\nrefresh gradients, leading to less biased edge choices. We empirically study\nORE through a set of proposed design tasks, each with an external validation\nmethod, demonstrating that ORE improves upon previous methods by up to 50%.",
          "link": "http://arxiv.org/abs/2310.17100",
          "publishedOn": "2023-10-28T00:41:30.092Z",
          "wordCount": null,
          "title": "Network Design through Graph Neural Networks: Identifying Challenges and Improving Performance. (arXiv:2310.17100v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharjee_R/0/1/0/all/0/1\">Rupsa Bhattacharjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akkaya_Z/0/1/0/all/0/1\">Zehra Akkaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luitjens_J/0/1/0/all/0/1\">Johanna Luitjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_P/0/1/0/all/0/1\">Pan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedoia_V/0/1/0/all/0/1\">Valentina Pedoia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1\">Sharmila Majumdar</a>",
          "description": "In the current study, our purpose is to evaluate the feasibility of applying\ndeep learning (DL) enabled algorithms to quantify bilateral knee biomarkers in\nhealthy controls scanned at 0.55T and compared with 3.0T. The current study\nassesses the performance of standard in-practice bone, and cartilage\nsegmentation algorithms at 0.55T, both qualitatively and quantitatively, in\nterms of comparing segmentation performance, areas of improvement, and\ncompartment-wise cartilage thickness values between 0.55T vs. 3.0T. Initial\nresults demonstrate a usable to good technical feasibility of translating\nexisting quantitative deep-learning-based image segmentation techniques,\ntrained on 3.0T, out of 0.55T for knee MRI, in a multi-vendor acquisition\nenvironment. Especially in terms of segmenting cartilage compartments, the\nmodels perform almost equivalent to 3.0T in terms of Likert ranking. The 0.55T\nlow-field sustainable and easy-to-install MRI, as demonstrated, thus, can be\nutilized for evaluating knee cartilage thickness and bone segmentations aided\nby established DL algorithms trained at higher-field strengths out-of-the-box\ninitially. This could be utilized at the far-spread point-of-care locations\nwith a lack of radiologists available to manually segment low-field images, at\nleast till a decent base of low-field data pool is collated. With further\nfine-tuning with manual labeling of low-field data or utilizing synthesized\nhigher SNR images from low-field images, OA biomarker quantification\nperformance is potentially guaranteed to be further improved.",
          "link": "http://arxiv.org/abs/2310.17152",
          "publishedOn": "2023-10-28T00:41:30.092Z",
          "wordCount": null,
          "title": "Technical Note: Feasibility of translating 3.0T-trained Deep-Learning Segmentation Models Out-of-the-Box on Low-Field MRI 0.55T Knee-MRI of Healthy Controls. (arXiv:2310.17152v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Char_I/0/1/0/all/0/1\">Ian Char</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jeff Schneider</a>",
          "description": "Deep reinforcement learning (RL) has shown immense potential for learning to\ncontrol systems through data alone. However, one challenge deep RL faces is\nthat the full state of the system is often not observable. When this is the\ncase, the policy needs to leverage the history of observations to infer the\ncurrent state. At the same time, differences between the training and testing\nenvironments makes it critical for the policy not to overfit to the sequence of\nobservations it sees at training time. As such, there is an important balancing\nact between having the history encoder be flexible enough to extract relevant\ninformation, yet be robust to changes in the environment. To strike this\nbalance, we look to the PID controller for inspiration. We assert the PID\ncontroller's success shows that only summing and differencing are needed to\naccumulate information over time for many control tasks. Following this\nprinciple, we propose two architectures for encoding history: one that directly\nuses PID features and another that extends these core ideas and can be used in\narbitrary control tasks. When compared with prior approaches, our encoders\nproduce policies that are often more robust and achieve better performance on a\nvariety of tracking tasks. Going beyond tracking tasks, our policies achieve\n1.7x better performance on average over previous state-of-the-art methods on a\nsuite of locomotion control tasks.",
          "link": "http://arxiv.org/abs/2307.05891",
          "publishedOn": "2023-10-28T00:41:30.092Z",
          "wordCount": null,
          "title": "PID-Inspired Inductive Biases for Deep Reinforcement Learning in Partially Observable Control Tasks. (arXiv:2307.05891v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14338",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gorishniy_Y/0/1/0/all/0/1\">Yury Gorishniy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubachev_I/0/1/0/all/0/1\">Ivan Rubachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kartashev_N/0/1/0/all/0/1\">Nikolay Kartashev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shlenskii_D/0/1/0/all/0/1\">Daniil Shlenskii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotelnikov_A/0/1/0/all/0/1\">Akim Kotelnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1\">Artem Babenko</a>",
          "description": "Deep learning (DL) models for tabular data problems (e.g. classification,\nregression) are currently receiving increasingly more attention from\nresearchers. However, despite the recent efforts, the non-DL algorithms based\non gradient-boosted decision trees (GBDT) remain a strong go-to solution for\nthese problems. One of the research directions aimed at improving the position\nof tabular DL involves designing so-called retrieval-augmented models. For a\ntarget object, such models retrieve other objects (e.g. the nearest neighbors)\nfrom the available training data and use their features and labels to make a\nbetter prediction.\n\nIn this work, we present TabR -- essentially, a feed-forward network with a\ncustom k-Nearest-Neighbors-like component in the middle. On a set of public\nbenchmarks with datasets up to several million objects, TabR marks a big step\nforward for tabular DL: it demonstrates the best average performance among\ntabular DL models, becomes the new state-of-the-art on several datasets, and\neven outperforms GBDT models on the recently proposed \"GBDT-friendly\" benchmark\n(see Figure 1). Among the important findings and technical details powering\nTabR, the main ones lie in the attention-like mechanism that is responsible for\nretrieving the nearest neighbors and extracting valuable signal from them. In\naddition to the much higher performance, TabR is simple and significantly more\nefficient compared to prior retrieval-based tabular DL models.",
          "link": "http://arxiv.org/abs/2307.14338",
          "publishedOn": "2023-10-28T00:41:30.092Z",
          "wordCount": null,
          "title": "TabR: Tabular Deep Learning Meets Nearest Neighbors in 2023. (arXiv:2307.14338v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neo_D/0/1/0/all/0/1\">Dexter Neo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tsuhan Chen</a>",
          "description": "We present a novel extension to the family of Soft Actor-Critic (SAC)\nalgorithms. We argue that based on the Maximum Entropy Principle, discrete SAC\ncan be further improved via additional statistical constraints derived from a\nsurrogate critic policy. Furthermore, our findings suggests that these\nconstraints provide an added robustness against potential domain shifts, which\nare essential for safe deployment of reinforcement learning agents in the\nreal-world. We provide theoretical analysis and show empirical results on low\ndata regimes for both in-distribution and out-of-distribution variants of Atari\n2600 games.",
          "link": "http://arxiv.org/abs/2310.17173",
          "publishedOn": "2023-10-28T00:41:30.091Z",
          "wordCount": null,
          "title": "DSAC-C: Constrained Maximum Entropy for Robust Discrete Soft-Actor Critic. (arXiv:2310.17173v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17202",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fradet_N/0/1/0/all/0/1\">Nathan Fradet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briot_J/0/1/0/all/0/1\">Jean-Pierre Briot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhel_F/0/1/0/all/0/1\">Fabien Chhel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seghrouchni_A/0/1/0/all/0/1\">Amal El Fallah Seghrouchni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutowski_N/0/1/0/all/0/1\">Nicolas Gutowski</a>",
          "description": "Recent progress in natural language processing has been adapted to the\nsymbolic music modality. Language models, such as Transformers, have been used\nwith symbolic music for a variety of tasks among which music generation,\nmodeling or transcription, with state-of-the-art performances. These models are\nbeginning to be used in production products. To encode and decode music for the\nbackbone model, they need to rely on tokenizers, whose role is to serialize\nmusic into sequences of distinct elements called tokens. MidiTok is an\nopen-source library allowing to tokenize symbolic music with great flexibility\nand extended features. It features the most popular music tokenizations, under\na unified API. It is made to be easily used and extensible for everyone.",
          "link": "http://arxiv.org/abs/2310.17202",
          "publishedOn": "2023-10-28T00:41:30.091Z",
          "wordCount": null,
          "title": "miditok: A Python package for MIDI file tokenization. (arXiv:2310.17202v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01951",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kothapalli_V/0/1/0/all/0/1\">Vignesh Kothapalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tirer_T/0/1/0/all/0/1\">Tom Tirer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>",
          "description": "Graph neural networks (GNNs) have become increasingly popular for\nclassification tasks on graph-structured data. Yet, the interplay between graph\ntopology and feature evolution in GNNs is not well understood. In this paper,\nwe focus on node-wise classification, illustrated with community detection on\nstochastic block model graphs, and explore the feature evolution through the\nlens of the \"Neural Collapse\" (NC) phenomenon. When training instance-wise deep\nclassifiers (e.g. for image classification) beyond the zero training error\npoint, NC demonstrates a reduction in the deepest features' within-class\nvariability and an increased alignment of their class means to certain\nsymmetric structures. We start with an empirical study that shows that a\ndecrease in within-class variability is also prevalent in the node-wise\nclassification setting, however, not to the extent observed in the\ninstance-wise case. Then, we theoretically study this distinction.\nSpecifically, we show that even an \"optimistic\" mathematical model requires\nthat the graphs obey a strict structural condition in order to possess a\nminimizer with exact collapse. Interestingly, this condition is viable also for\nheterophilic graphs and relates to recent empirical studies on settings with\nimproved GNNs' generalization. Furthermore, by studying the gradient dynamics\nof the theoretical model, we provide reasoning for the partial collapse\nobserved empirically. Finally, we present a study on the evolution of within-\nand between-class feature variability across layers of a well-trained GNN and\ncontrast the behavior with spectral methods.",
          "link": "http://arxiv.org/abs/2307.01951",
          "publishedOn": "2023-10-28T00:41:30.091Z",
          "wordCount": null,
          "title": "A Neural Collapse Perspective on Feature Evolution in Graph Neural Networks. (arXiv:2307.01951v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17078",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naimi_S/0/1/0/all/0/1\">Safwen Naimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouachir_W/0/1/0/all/0/1\">Wassim Bouachir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilodeau_G/0/1/0/all/0/1\">Guillaume-Alexandre Bilodeau</a>",
          "description": "In this paper, we propose a novel deep learning method based on a new Hybrid\nConvNet-Transformer architecture to detect and stage Parkinson's disease (PD)\nfrom gait data. We adopt a two-step approach by dividing the problem into two\nsub-problems. Our Hybrid ConvNet-Transformer model first distinguishes healthy\nversus parkinsonian patients. If the patient is parkinsonian, a multi-class\nHybrid ConvNet-Transformer model determines the Hoehn and Yahr (H&Y) score to\nassess the PD severity stage. Our hybrid architecture exploits the strengths of\nboth Convolutional Neural Networks (ConvNets) and Transformers to accurately\ndetect PD and determine the severity stage. In particular, we take advantage of\nConvNets to capture local patterns and correlations in the data, while we\nexploit Transformers for handling long-term dependencies in the input signal.\nWe show that our hybrid method achieves superior performance when compared to\nother state-of-the-art methods, with a PD detection accuracy of 97% and a\nseverity staging accuracy of 87%. Our source code is available at:\nhttps://github.com/SafwenNaimi",
          "link": "http://arxiv.org/abs/2310.17078",
          "publishedOn": "2023-10-28T00:41:30.090Z",
          "wordCount": null,
          "title": "HCT: Hybrid Convnet-Transformer for Parkinson's disease detection and severity prediction from gait. (arXiv:2310.17078v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.14814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Odonnat_A/0/1/0/all/0/1\">Ambroise Odonnat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feofanov_V/0/1/0/all/0/1\">Vasilii Feofanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Redko_I/0/1/0/all/0/1\">Ievgen Redko</a>",
          "description": "Self-training is a well-known approach for semi-supervised learning. It\nconsists of iteratively assigning pseudo-labels to unlabeled data for which the\nmodel is confident and treating them as labeled examples. For neural networks,\nsoftmax prediction probabilities are often used as a confidence measure,\ndespite the fact that they are known to be overconfident, even for wrong\npredictions. This phenomenon is particularly intensified in the presence of\nsample selection bias, i.e., when data labeling is subject to some constraint.\nTo address this issue, we propose a novel confidence measure, called\n$\\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of\nlinear classifiers. We provide the theoretical analysis of our approach by\nstudying stationary points and describing the relationship between the\ndiversity of the individual members and their performance. We empirically\ndemonstrate the benefit of our confidence measure for three different\npseudo-labeling policies on classification datasets of various data modalities.",
          "link": "http://arxiv.org/abs/2310.14814",
          "publishedOn": "2023-10-28T00:41:30.090Z",
          "wordCount": null,
          "title": "Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias. (arXiv:2310.14814v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhaohui Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Songlin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "Entity and Relation Extraction (ERE) is an important task in information\nextraction. Recent marker-based pipeline models achieve state-of-the-art\nperformance, but still suffer from the error propagation issue. Also, most of\ncurrent ERE models do not take into account higher-order interactions between\nmultiple entities and relations, while higher-order modeling could be\nbeneficial.In this work, we propose HyperGraph neural network for ERE\n($\\hgnn{}$), which is built upon the PL-marker (a state-of-the-art marker-based\npipleline model). To alleviate error propagation,we use a high-recall pruner\nmechanism to transfer the burden of entity identification and labeling from the\nNER module to the joint module of our model. For higher-order modeling, we\nbuild a hypergraph, where nodes are entities (provided by the span pruner) and\nrelations thereof, and hyperedges encode interactions between two different\nrelations or between a relation and its associated subject and object entities.\nWe then run a hypergraph neural network for higher-order inference by applying\nmessage passing over the built hypergraph. Experiments on three widely used\nbenchmarks (\\acef{}, \\ace{} and \\scierc{}) for ERE task show significant\nimprovements over the previous state-of-the-art PL-marker.",
          "link": "http://arxiv.org/abs/2310.17238",
          "publishedOn": "2023-10-28T00:41:30.089Z",
          "wordCount": null,
          "title": "Joint Entity and Relation Extraction with Span Pruning and Hypergraph Neural Networks. (arXiv:2310.17238v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16826",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Pena_Asensio_E/0/1/0/all/0/1\">Eloy Pe&#xf1;a-Asensio</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Trigo_Rodriguez_J/0/1/0/all/0/1\">Josep M. Trigo-Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Grebol_Tomas_P/0/1/0/all/0/1\">Pau Gr&#xe8;bol-Tom&#xe0;s</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Regordosa_Avellana_D/0/1/0/all/0/1\">David Regordosa-Avellana</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Rimola_A/0/1/0/all/0/1\">Albert Rimola</a>",
          "description": "In recent decades, the use of optical detection systems for meteor studies\nhas increased dramatically, resulting in huge amounts of data being analyzed.\nAutomated meteor detection tools are essential for studying the continuous\nmeteoroid incoming flux, recovering fresh meteorites, and achieving a better\nunderstanding of our Solar System. Concerning meteor detection, distinguishing\nfalse positives between meteor and non-meteor images has traditionally been\nperformed by hand, which is significantly time-consuming. To address this\nissue, we developed a fully automated pipeline that uses Convolutional Neural\nNetworks (CNNs) to classify candidate meteor detections. Our new method is able\nto detect meteors even in images that contain static elements such as clouds,\nthe Moon, and buildings. To accurately locate the meteor within each frame, we\nemploy the Gradient-weighted Class Activation Mapping (Grad-CAM) technique.\nThis method facilitates the identification of the region of interest by\nmultiplying the activations from the last convolutional layer with the average\nof the gradients across the feature map of that layer. By combining these\nfindings with the activation map derived from the first convolutional layer, we\neffectively pinpoint the most probable pixel location of the meteor. We trained\nand evaluated our model on a large dataset collected by the Spanish Meteor\nNetwork (SPMN) and achieved a precision of 98\\%. Our new methodology presented\nhere has the potential to reduce the workload of meteor scientists and station\noperators and improve the accuracy of meteor tracking and classification.",
          "link": "http://arxiv.org/abs/2310.16826",
          "publishedOn": "2023-10-28T00:41:30.089Z",
          "wordCount": null,
          "title": "Deep machine learning for meteor monitoring: advances with transfer learning and gradient-weighted class activation mapping. (arXiv:2310.16826v2 [astro-ph.EP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.14534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Li He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yachen Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1\">Zifeng Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Donglin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Huazhe Xu</a>",
          "description": "In this paper, we present \\textbf{C}ont\\textbf{E}xtual \\textbf{I}mitation\n\\textbf{L}earning~(CEIL), a general and broadly applicable algorithm for\nimitation learning (IL). Inspired by the formulation of hindsight information\nmatching, we derive CEIL by explicitly learning a hindsight embedding function\ntogether with a contextual policy using the hindsight embeddings. To achieve\nthe expert matching objective for IL, we advocate for optimizing a contextual\nvariable such that it biases the contextual policy towards mimicking expert\nbehaviors. Beyond the typical learning from demonstrations (LfD) setting, CEIL\nis a generalist that can be effectively applied to multiple settings including:\n1)~learning from observations (LfO), 2)~offline IL, 3)~cross-domain IL\n(mismatched experts), and 4) one-shot IL settings. Empirically, we evaluate\nCEIL on the popular MuJoCo tasks (online) and the D4RL dataset (offline).\nCompared to prior state-of-the-art baselines, we show that CEIL is more\nsample-efficient in most online IL tasks and achieves better or competitive\nperformances in offline tasks.",
          "link": "http://arxiv.org/abs/2306.14534",
          "publishedOn": "2023-10-28T00:41:30.085Z",
          "wordCount": null,
          "title": "CEIL: Generalized Contextual Imitation Learning. (arXiv:2306.14534v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.13632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yifu Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziser_Y/0/1/0/all/0/1\">Yftah Ziser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1\">Edoardo M. Ponti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Shay B. Cohen</a>",
          "description": "Hallucinations pose a significant challenge to the reliability of neural\nmodels for abstractive summarisation. While automatically generated summaries\nmay be fluent, they often lack faithfulness to the original document. This\nissue becomes even more pronounced in low-resource settings, such as\ncross-lingual transfer. With the existing faithful metrics focusing on English,\neven measuring the extent of this phenomenon in cross-lingual settings is hard.\nTo address this, we first develop a novel metric, mFACT, evaluating the\nfaithfulness of non-English summaries, leveraging translation-based transfer\nfrom multiple English faithfulness metrics. We then propose a simple but\neffective method to reduce hallucinations with a cross-lingual transfer, which\nweighs the loss of each training example by its faithfulness score. Through\nextensive experiments in multiple languages, we demonstrate that mFACT is the\nmetric that is most suited to detect hallucinations. Moreover, we find that our\nproposed loss weighting method drastically increases both performance and\nfaithfulness according to both automatic and human evaluation when compared to\nstrong baselines for cross-lingual transfer such as MAD-X. Our code and dataset\nare available at https://github.com/yfqiu-nlp/mfact-summ.",
          "link": "http://arxiv.org/abs/2305.13632",
          "publishedOn": "2023-10-28T00:41:30.084Z",
          "wordCount": null,
          "title": "Detecting and Mitigating Hallucinations in Multilingual Summarisation. (arXiv:2305.13632v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lifan Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yangyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_G/0/1/0/all/0/1\">Ganqu Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Hongcheng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_F/0/1/0/all/0/1\">Fangyuan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xingyi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "This paper reexamines the research on out-of-distribution (OOD) robustness in\nthe field of NLP. We find that the distribution shift settings in previous\nstudies commonly lack adequate challenges, hindering the accurate evaluation of\nOOD robustness. To address these issues, we propose a benchmark construction\nprotocol that ensures clear differentiation and challenging distribution\nshifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution\nrobustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we\nconduct a series of experiments on pre-trained language models for analysis and\nevaluation of OOD robustness. First, for vanilla fine-tuning, we examine the\nrelationship between in-distribution (ID) and OOD performance. We identify\nthree typical types that unveil the inner learning mechanism, which could\npotentially facilitate the forecasting of OOD robustness, correlating with the\nadvancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and\nfind that, despite exhibiting some effectiveness in specific cases, they do not\noffer significant improvement compared to vanilla fine-tuning. Further, we\nevaluate 5 LLMs with various adaptation paradigms and find that when sufficient\nID data is available, fine-tuning domain-specific models outperform LLMs on ID\nexamples significantly. However, in the case of OOD instances, prioritizing\nLLMs with in-context learning yields better results. We identify that both\nfine-tuned small models and LLMs face challenges in effectively addressing\ndownstream tasks. The code is public at\n\\url{https://github.com/lifan-yuan/OOD_NLP}.",
          "link": "http://arxiv.org/abs/2306.04618",
          "publishedOn": "2023-10-28T00:41:30.084Z",
          "wordCount": null,
          "title": "Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations. (arXiv:2306.04618v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Minhak Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_C/0/1/0/all/0/1\">Chulhee Yun</a>",
          "description": "Cohen et al. (2021) empirically study the evolution of the largest eigenvalue\nof the loss Hessian, also known as sharpness, along the gradient descent (GD)\ntrajectory and observe the Edge of Stability (EoS) phenomenon. The sharpness\nincreases at the early phase of training (referred to as progressive\nsharpening), and eventually saturates close to the threshold of $2 /\n\\text{(step size)}$. In this paper, we start by demonstrating through empirical\nstudies that when the EoS phenomenon occurs, different GD trajectories (after a\nproper reparameterization) align on a specific bifurcation diagram independent\nof initialization. We then rigorously prove this trajectory alignment\nphenomenon for a two-layer fully-connected linear network and a single-neuron\nnonlinear network trained with a single data point. Our trajectory alignment\nanalysis establishes both progressive sharpening and EoS phenomena,\nencompassing and extending recent findings in the literature.",
          "link": "http://arxiv.org/abs/2307.04204",
          "publishedOn": "2023-10-28T00:41:30.084Z",
          "wordCount": null,
          "title": "Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory. (arXiv:2307.04204v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.12283",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zhongze Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaocheng Li</a>",
          "description": "In this paper, we consider the uncertainty quantification problem for\nregression models. Specifically, we consider an individual calibration\nobjective for characterizing the quantiles of the prediction model. While such\nan objective is well-motivated from downstream tasks such as newsvendor cost,\nthe existing methods have been largely heuristic and lack of statistical\nguarantee in terms of individual calibration. We show via simple examples that\nthe existing methods focusing on population-level calibration guarantees such\nas average calibration or sharpness can lead to harmful and unexpected results.\nWe propose simple nonparametric calibration methods that are agnostic of the\nunderlying prediction model and enjoy both computational efficiency and\nstatistical consistency. Our approach enables a better understanding of the\npossibility of individual calibration, and we establish matching upper and\nlower bounds for the calibration error of our proposed methods. Technically,\nour analysis combines the nonparametric analysis with a covering number\nargument for parametric analysis, which advances the existing theoretical\nanalyses in the literature of nonparametric density estimation and quantile\nbandit problems. Importantly, the nonparametric perspective sheds new\ntheoretical insights into regression calibration in terms of the curse of\ndimensionality and reconciles the existing results on the impossibility of\nindividual calibration. To our knowledge, we make the first effort to reach\nboth individual calibration and finite-sample guarantee with minimal\nassumptions in terms of conformal prediction. Numerical experiments show the\nadvantage of such a simple approach under various metrics, and also under\ncovariates shift. We hope our work provides a simple benchmark and a starting\npoint of theoretical ground for future research on regression calibration.",
          "link": "http://arxiv.org/abs/2305.12283",
          "publishedOn": "2023-10-28T00:41:30.083Z",
          "wordCount": null,
          "title": "Distribution-Free Model-Agnostic Regression Calibration via Nonparametric Methods. (arXiv:2305.12283v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16427",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seleznova_M/0/1/0/all/0/1\">Mariia Seleznova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weitzner_D/0/1/0/all/0/1\">Dana Weitzner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1\">Raja Giryes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1\">Gitta Kutyniok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_H/0/1/0/all/0/1\">Hung-Hsu Chou</a>",
          "description": "This work bridges two important concepts: the Neural Tangent Kernel (NTK),\nwhich captures the evolution of deep neural networks (DNNs) during training,\nand the Neural Collapse (NC) phenomenon, which refers to the emergence of\nsymmetry and structure in the last-layer features of well-trained\nclassification DNNs. We adopt the natural assumption that the empirical NTK\ndevelops a block structure aligned with the class labels, i.e., samples within\nthe same class have stronger correlations than samples from different classes.\nUnder this assumption, we derive the dynamics of DNNs trained with mean squared\n(MSE) loss and break them into interpretable phases. Moreover, we identify an\ninvariant that captures the essence of the dynamics, and use it to prove the\nemergence of NC in DNNs with block-structured NTK. We provide large-scale\nnumerical experiments on three common DNN architectures and three benchmark\ndatasets to support our theory.",
          "link": "http://arxiv.org/abs/2305.16427",
          "publishedOn": "2023-10-28T00:41:30.083Z",
          "wordCount": null,
          "title": "Neural (Tangent Kernel) Collapse. (arXiv:2305.16427v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07163",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshida_Y/0/1/0/all/0/1\">Yuichi Yoshida</a>",
          "description": "We introduce a transformation framework that can be utilized to develop\nonline algorithms with low $\\epsilon$-approximate regret in the random-order\nmodel from offline approximation algorithms. We first give a general reduction\ntheorem that transforms an offline approximation algorithm with low average\nsensitivity to an online algorithm with low $\\epsilon$-approximate regret. We\nthen demonstrate that offline approximation algorithms can be transformed into\na low-sensitivity version using a coreset construction method. To showcase the\nversatility of our approach, we apply it to various problems, including online\n$(k,z)$-clustering, online matrix approximation, and online regression, and\nsuccessfully achieve polylogarithmic $\\epsilon$-approximate regret for each\nproblem. Moreover, we show that in all three cases, our algorithm also enjoys\nlow inconsistency, which may be desired in some online applications.",
          "link": "http://arxiv.org/abs/2306.07163",
          "publishedOn": "2023-10-28T00:41:30.083Z",
          "wordCount": null,
          "title": "A Batch-to-Online Transformation under Random-Order Model. (arXiv:2306.07163v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.00855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ezugwu_A/0/1/0/all/0/1\">Absalom E. Ezugwu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greeff_J/0/1/0/all/0/1\">Japie Greeff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_Y/0/1/0/all/0/1\">Yuh-Shan Ho</a>",
          "description": "Machine learning (ML) has emerged as a prominent field of research in\ncomputer science and other related fields, thereby driving advancements in\nother domains of interest. As the field continues to evolve, it is crucial to\nunderstand the landscape of highly cited publications to identify key trends,\ninfluential authors, and significant contributions made thus far. In this\npaper, we present a comprehensive bibliometric analysis of highly cited ML\npublications. We collected a dataset consisting of the top-cited papers from\nreputable ML conferences and journals, covering a period of several years from\n1959 to 2022. We employed various bibliometric techniques to analyze the data,\nincluding citation analysis, co-authorship analysis, keyword analysis, and\npublication trends. Our findings reveal the most influential papers, highly\ncited authors, and collaborative networks within the machine learning\ncommunity. We identify popular research themes and uncover emerging topics that\nhave recently gained significant attention. Furthermore, we examine the\ngeographical distribution of highly cited publications, highlighting the\ndominance of certain countries in ML research. By shedding light on the\nlandscape of highly cited ML publications, our study provides valuable insights\nfor researchers, policymakers, and practitioners seeking to understand the key\ndevelopments and trends in this rapidly evolving field.",
          "link": "http://arxiv.org/abs/2308.00855",
          "publishedOn": "2023-10-28T00:41:30.083Z",
          "wordCount": null,
          "title": "A Comprehensive Study of Groundbreaking Machine Learning Research: Analyzing highly cited and impactful publications across six decades. (arXiv:2308.00855v2 [cs.DL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Loveland_D/0/1/0/all/0/1\">Donald Loveland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heimann_M/0/1/0/all/0/1\">Mark Heimann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fish_B/0/1/0/all/0/1\">Benjamin Fish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaub_M/0/1/0/all/0/1\">Michael T. Shaub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koutra_D/0/1/0/all/0/1\">Danai Koutra</a>",
          "description": "Graph Neural Network (GNN) research has highlighted a relationship between\nhigh homophily (i.e., the tendency of nodes of the same class to connect) and\nstrong predictive performance in node classification. However, recent work has\nfound the relationship to be more nuanced, demonstrating that simple GNNs can\nlearn in certain heterophilous settings. To resolve these conflicting findings\nand align closer to real-world datasets, we go beyond the assumption of a\nglobal graph homophily level and study the performance of GNNs when the local\nhomophily level of a node deviates from the global homophily level. Through\ntheoretical and empirical analysis, we systematically demonstrate how shifts in\nlocal homophily can introduce performance degradation, leading to performance\ndiscrepancies across local homophily levels. We ground the practical\nimplications of this work through granular analysis on five real-world datasets\nwith varying global homophily levels, demonstrating that (a) GNNs can fail to\ngeneralize to test nodes that deviate from the global homophily of a graph, and\n(b) high local homophily does not necessarily confer high performance for a\nnode. We further show that GNNs designed for globally heterophilous graphs can\nalleviate performance discrepancy by improving performance across local\nhomophily levels, offering a new perspective on how these GNNs achieve stronger\nglobal performance.",
          "link": "http://arxiv.org/abs/2306.05557",
          "publishedOn": "2023-10-28T00:41:30.082Z",
          "wordCount": null,
          "title": "On Performance Discrepancies Across Local Homophily Levels in Graph Neural Networks. (arXiv:2306.05557v3 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhiyu Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xuli Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1\">Xiangyang Xue</a>",
          "description": "Diffusion models (DMs) have recently gained attention with state-of-the-art\nperformance in text-to-image synthesis. Abiding by the tradition in deep\nlearning, DMs are trained and evaluated on the images with fixed sizes.\nHowever, users are demanding for various images with specific sizes and various\naspect ratio. This paper focuses on adapting text-to-image diffusion models to\nhandle such variety while maintaining visual fidelity. First we observe that,\nduring the synthesis, lower resolution images suffer from incomplete object\nportrayal, while higher resolution images exhibit repetitively disordered\npresentation. Next, we establish a statistical relationship indicating that\nattention entropy changes with token quantity, suggesting that models aggregate\nspatial information in proportion to image resolution. The subsequent\ninterpretation on our observations is that objects are incompletely depicted\ndue to limited spatial information for low resolutions, while repetitively\ndisorganized presentation arises from redundant spatial information for high\nresolutions. From this perspective, we propose a scaling factor to alleviate\nthe change of attention entropy and mitigate the defective pattern observed.\nExtensive experimental results validate the efficacy of the proposed scaling\nfactor, enabling models to achieve better visual effects, image quality, and\ntext alignment. Notably, these improvements are achieved without additional\ntraining or fine-tuning techniques.",
          "link": "http://arxiv.org/abs/2306.08645",
          "publishedOn": "2023-10-28T00:41:30.082Z",
          "wordCount": null,
          "title": "Training-free Diffusion Model Adaptation for Variable-Sized Text-to-Image Synthesis. (arXiv:2306.08645v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thao Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadre_S/0/1/0/all/0/1\">Samir Yitzhak Gadre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilharco_G/0/1/0/all/0/1\">Gabriel Ilharco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Sewoong Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1\">Ludwig Schmidt</a>",
          "description": "Massive web datasets play a key role in the success of large vision-language\nmodels like CLIP and Flamingo. However, the raw web data is noisy, and existing\nfiltering methods to reduce noise often come at the expense of data diversity.\nOur work focuses on caption quality as one major source of noise, and studies\nhow generated captions can increase the utility of web-scraped datapoints with\nnondescript text. Through exploring different mixing strategies for raw and\ngenerated captions, we outperform the best filtering method proposed by the\nDataComp benchmark by 2% on ImageNet and 4% on average across 38 tasks, given a\ncandidate pool of 128M image-text pairs. Our best approach is also 2x better at\nFlickr and MS-COCO retrieval. We then analyze what makes synthetic captions an\neffective source of text supervision. In experimenting with different image\ncaptioning models, we also demonstrate that the performance of a model on\nstandard image captioning benchmarks (e.g., NoCaps CIDEr) is not a reliable\nindicator of the utility of the captions it generates for multimodal training.\nFinally, our experiments with using generated captions at DataComp's large\nscale (1.28B image-text pairs) offer insights into the limitations of synthetic\ntext, as well as the importance of image curation with increasing training data\nquantity. The synthetic captions used in our experiments are now available on\nHuggingFace.",
          "link": "http://arxiv.org/abs/2307.10350",
          "publishedOn": "2023-10-28T00:41:30.082Z",
          "wordCount": null,
          "title": "Improving Multimodal Datasets with Image Captioning. (arXiv:2307.10350v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15807",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chzhen_E/0/1/0/all/0/1\">Evgenii Chzhen</a> (LMO, CELESTE), <a href=\"http://arxiv.org/find/stat/1/au:+Giraud_C/0/1/0/all/0/1\">Christophe Giraud</a> (LMO, CELESTE), <a href=\"http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stoltz_G/0/1/0/all/0/1\">Gilles Stoltz</a> (LMO, CELESTE, HEC Paris)",
          "description": "We consider contextual bandit problems with knapsacks [CBwK], a problem where\nat each round, a scalar reward is obtained and vector-valued costs are\nsuffered. The learner aims to maximize the cumulative rewards while ensuring\nthat the cumulative costs are lower than some predetermined cost constraints.\nWe assume that contexts come from a continuous set, that costs can be signed,\nand that the expected reward and cost functions, while unknown, may be\nuniformly estimated -- a typical assumption in the literature. In this setting,\ntotal cost constraints had so far to be at least of order $T^{3/4}$, where $T$\nis the number of rounds, and were even typically assumed to depend linearly on\n$T$. We are however motivated to use CBwK to impose a fairness constraint of\nequalized average costs between groups: the budget associated with the\ncorresponding cost constraints should be as close as possible to the natural\ndeviations, of order $\\sqrt{T}$. To that end, we introduce a dual strategy\nbased on projected-gradient-descent updates, that is able to deal with\ntotal-cost constraints of the order of $\\sqrt{T}$ up to poly-logarithmic terms.\nThis strategy is more direct and simpler than existing strategies in the\nliterature. It relies on a careful, adaptive, tuning of the step size.",
          "link": "http://arxiv.org/abs/2305.15807",
          "publishedOn": "2023-10-28T00:41:30.081Z",
          "wordCount": null,
          "title": "Small Total-Cost Constraints in Contextual Bandits with Knapsacks, with Application to Fairness. (arXiv:2305.15807v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.05858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1\">Jingliang Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Liming Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jiaxin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shengbo Eben Li</a>",
          "description": "Reinforcement learning (RL) has proven to be highly effective in tackling\ncomplex decision-making and control tasks. However, prevalent model-free RL\nmethods often face severe performance degradation due to the well-known\noverestimation issue. In response to this problem, we recently introduced an\noff-policy RL algorithm, called distributional soft actor-critic (DSAC or\nDSAC-v1), which can effectively improve the value estimation accuracy by\nlearning a continuous Gaussian value distribution. Nonetheless, standard DSAC\nhas its own shortcomings, including occasionally unstable learning processes\nand needs for task-specific reward scaling, which may hinder its overall\nperformance and adaptability in some special tasks. This paper further\nintroduces three important refinements to standard DSAC in order to address\nthese shortcomings. These refinements consist of critic gradient adjusting,\ntwin value distribution learning, and variance-based target return clipping.\nThe modified RL algorithm is named as DSAC with three refinements (DSAC-T or\nDSAC-v2), and its performances are systematically evaluated on a diverse set of\nbenchmark tasks. Without any task-specific hyperparameter tuning, DSAC-T\nsurpasses a lot of mainstream model-free RL algorithms, including SAC, TD3,\nDDPG, TRPO, and PPO, in all tested environments. Additionally, DSAC-T, unlike\nits standard version, ensures a highly stable learning process and delivers\nsimilar performance across varying reward scales.",
          "link": "http://arxiv.org/abs/2310.05858",
          "publishedOn": "2023-10-28T00:41:30.081Z",
          "wordCount": null,
          "title": "DSAC-T: Distributional Soft Actor-Critic with Three Refinements. (arXiv:2310.05858v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Echterhoff_J/0/1/0/all/0/1\">Jessica Echterhoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_A/0/1/0/all/0/1\">An Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kyungtae Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelraouf_A/0/1/0/all/0/1\">Amr Abdelraouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Rohit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>",
          "description": "Concept bottleneck models have been successfully used for explainable machine\nlearning by encoding information within the model with a set of human-defined\nconcepts. In the context of human-assisted or autonomous driving,\nexplainability models can help user acceptance and understanding of decisions\nmade by the autonomous vehicle, which can be used to rationalize and explain\ndriver or vehicle behavior. We propose a new approach using concept bottlenecks\nas visual features for control command predictions and explanations of user and\nvehicle behavior. We learn a human-understandable concept layer that we use to\nexplain sequential driving scenes while learning vehicle control commands. This\napproach can then be used to determine whether a change in a preferred gap or\nsteering commands from a human (or autonomous vehicle) is led by an external\nstimulus or change in preferences. We achieve competitive performance to latent\nvisual features while gaining interpretability within our model setup.",
          "link": "http://arxiv.org/abs/2310.16639",
          "publishedOn": "2023-10-28T00:41:30.081Z",
          "wordCount": null,
          "title": "Driving through the Concept Gridlock: Unraveling Explainability Bottlenecks in Automated Driving. (arXiv:2310.16639v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14077",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Haas_M/0/1/0/all/0/1\">Moritz Haas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holzmuller_D/0/1/0/all/0/1\">David Holzm&#xfc;ller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Luxburg_U/0/1/0/all/0/1\">Ulrike von Luxburg</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steinwart_I/0/1/0/all/0/1\">Ingo Steinwart</a>",
          "description": "The success of over-parameterized neural networks trained to near-zero\ntraining error has caused great interest in the phenomenon of benign\noverfitting, where estimators are statistically consistent even though they\ninterpolate noisy training data. While benign overfitting in fixed dimension\nhas been established for some learning methods, current literature suggests\nthat for regression with typical kernel methods and wide neural networks,\nbenign overfitting requires a high-dimensional setting where the dimension\ngrows with the sample size. In this paper, we show that the smoothness of the\nestimators, and not the dimension, is the key: benign overfitting is possible\nif and only if the estimator's derivatives are large enough. We generalize\nexisting inconsistency results to non-interpolating models and more kernels to\nshow that benign overfitting with moderate derivatives is impossible in fixed\ndimension. Conversely, we show that rate-optimal benign overfitting is possible\nfor regression with a sequence of spiky-smooth kernels with large derivatives.\nUsing neural tangent kernels, we translate our results to wide neural networks.\nWe prove that while infinite-width networks do not overfit benignly with the\nReLU activation, this can be fixed by adding small high-frequency fluctuations\nto the activation function. Our experiments verify that such neural networks,\nwhile overfitting, can indeed generalize well even on low-dimensional data\nsets.",
          "link": "http://arxiv.org/abs/2305.14077",
          "publishedOn": "2023-10-28T00:41:30.080Z",
          "wordCount": null,
          "title": "Mind the spikes: Benign overfitting of kernels and neural networks in fixed dimension. (arXiv:2305.14077v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_M/0/1/0/all/0/1\">Martin Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_N/0/1/0/all/0/1\">Nelson Fernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Thuy Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gherbi_E/0/1/0/all/0/1\">Elies Gherbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajri_H/0/1/0/all/0/1\">Hatem Hajri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masmoudi_N/0/1/0/all/0/1\">Nader Masmoudi</a>",
          "description": "A potent class of generative models known as Diffusion Probabilistic Models\n(DPMs) has become prominent. A forward diffusion process adds gradually noise\nto data, while a model learns to gradually denoise. Sampling from pre-trained\nDPMs is obtained by solving differential equations (DE) defined by the learnt\nmodel, a process which has shown to be prohibitively slow. Numerous efforts on\nspeeding-up this process have consisted on crafting powerful ODE solvers.\nDespite being quick, such solvers do not usually reach the optimal quality\nachieved by available slow SDE solvers. Our goal is to propose SDE solvers that\nreach optimal quality without requiring several hundreds or thousands of NFEs\nto achieve that goal. We propose Stochastic Explicit Exponential\nDerivative-free Solvers (SEEDS), improving and generalizing Exponential\nIntegrator approaches to the stochastic case on several frameworks. After\ncarefully analyzing the formulation of exact solutions of diffusion SDEs, we\ncraft SEEDS to analytically compute the linear part of such solutions. Inspired\nby the Exponential Time-Differencing method, SEEDS use a novel treatment of the\nstochastic components of solutions, enabling the analytical computation of\ntheir variance, and contains high-order terms allowing to reach optimal quality\nsampling $\\sim3$-$5\\times$ faster than previous SDE methods. We validate our\napproach on several image generation benchmarks, showing that SEEDS outperform\nor are competitive with previous SDE solvers. Contrary to the latter, SEEDS are\nderivative and training free, and we fully prove strong convergence guarantees\nfor them.",
          "link": "http://arxiv.org/abs/2305.14267",
          "publishedOn": "2023-10-28T00:41:30.080Z",
          "wordCount": null,
          "title": "SEEDS: Exponential SDE Solvers for Fast High-Quality Sampling from Diffusion Models. (arXiv:2305.14267v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leemann_T/0/1/0/all/0/1\">Tobias Leemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pawelczyk_M/0/1/0/all/0/1\">Martin Pawelczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1\">Gjergji Kasneci</a>",
          "description": "We propose a novel and practical privacy notion called $f$-Membership\nInference Privacy ($f$-MIP), which explicitly considers the capabilities of\nrealistic adversaries under the membership inference attack threat model.\nConsequently, $f$-MIP offers interpretable privacy guarantees and improved\nutility (e.g., better classification accuracy). In particular, we derive a\nparametric family of $f$-MIP guarantees that we refer to as $\\mu$-Gaussian\nMembership Inference Privacy ($\\mu$-GMIP) by theoretically analyzing likelihood\nratio-based membership inference attacks on stochastic gradient descent (SGD).\nOur analysis highlights that models trained with standard SGD already offer an\nelementary level of MIP. Additionally, we show how $f$-MIP can be amplified by\nadding noise to gradient updates. Our analysis further yields an analytical\nmembership inference attack that offers two distinct advantages over previous\napproaches. First, unlike existing state-of-the-art attacks that require\ntraining hundreds of shadow models, our attack does not require any shadow\nmodel. Second, our analytical attack enables straightforward auditing of our\nprivacy notion $f$-MIP. Finally, we quantify how various hyperparameters (e.g.,\nbatch size, number of model parameters) and specific data characteristics\ndetermine an attacker's ability to accurately infer a point's membership in the\ntraining set. We demonstrate the effectiveness of our method on models trained\non vision and tabular datasets.",
          "link": "http://arxiv.org/abs/2306.07273",
          "publishedOn": "2023-10-28T00:41:30.080Z",
          "wordCount": null,
          "title": "Gaussian Membership Inference Privacy. (arXiv:2306.07273v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.15012",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Blancard_B/0/1/0/all/0/1\">Bruno R&#xe9;galdo-Saint Blancard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Eickenberg_M/0/1/0/all/0/1\">Michael Eickenberg</a>",
          "description": "Separating signals from an additive mixture may be an unnecessarily hard\nproblem when one is only interested in specific properties of a given signal.\nIn this work, we tackle simpler \"statistical component separation\" problems\nthat focus on recovering a predefined set of statistical descriptors of a\ntarget signal from a noisy mixture. Assuming access to samples of the noise\nprocess, we investigate a method devised to match the statistics of the\nsolution candidate corrupted by noise samples with those of the observed\nmixture. We first analyze the behavior of this method using simple examples\nwith analytically tractable calculations. Then, we apply it in an image\ndenoising context employing 1) wavelet-based descriptors, 2) ConvNet-based\ndescriptors on astrophysics and ImageNet data. In the case of 1), we show that\nour method better recovers the descriptors of the target data than a standard\ndenoising method in most situations. Additionally, despite not constructed for\nthis purpose, it performs surprisingly well in terms of peak signal-to-noise\nratio on full signal reconstruction. In comparison, representation 2) appears\nless suitable for image denoising. Finally, we extend this method by\nintroducing a diffusive stepwise algorithm which gives a new perspective to the\ninitial method and leads to promising results for image denoising under\nspecific circumstances.",
          "link": "http://arxiv.org/abs/2306.15012",
          "publishedOn": "2023-10-28T00:41:30.079Z",
          "wordCount": null,
          "title": "Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures. (arXiv:2306.15012v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiaoliang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuancheng Zhou</a>",
          "description": "We introduce an adaptive sampling method for the Deep Ritz method aimed at\nsolving partial differential equations (PDEs). Two deep neural networks are\nused. One network is employed to approximate the solution of PDEs, while the\nother one is a deep generative model used to generate new collocation points to\nrefine the training set. The adaptive sampling procedure consists of two main\nsteps. The first step is solving the PDEs using the Deep Ritz method by\nminimizing an associated variational loss discretized by the collocation points\nin the training set. The second step involves generating a new training set,\nwhich is then used in subsequent computations to further improve the accuracy\nof the current approximate solution. We treat the integrand in the variational\nloss as an unnormalized probability density function (PDF) and approximate it\nusing a deep generative model called bounded KRnet. The new samples and their\nassociated PDF values are obtained from the bounded KRnet. With these new\nsamples and their associated PDF values, the variational loss can be\napproximated more accurately by importance sampling. Compared to the original\nDeep Ritz method, the proposed adaptive method improves accuracy, especially\nfor problems characterized by low regularity and high dimensionality. We\ndemonstrate the effectiveness of our new method through a series of numerical\nexperiments.",
          "link": "http://arxiv.org/abs/2310.17185",
          "publishedOn": "2023-10-28T00:41:30.075Z",
          "wordCount": null,
          "title": "Adaptive important sampling for Deep Ritz. (arXiv:2310.17185v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.03284",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avalos_R/0/1/0/all/0/1\">Raphael Avalos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delgrange_F/0/1/0/all/0/1\">Florent Delgrange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowe_A/0/1/0/all/0/1\">Ann Now&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_G/0/1/0/all/0/1\">Guillermo A. P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roijers_D/0/1/0/all/0/1\">Diederik M. Roijers</a>",
          "description": "Partially Observable Markov Decision Processes (POMDPs) are used to model\nenvironments where the full state cannot be perceived by an agent. As such the\nagent needs to reason taking into account the past observations and actions.\nHowever, simply remembering the full history is generally intractable due to\nthe exponential growth in the history space. Maintaining a probability\ndistribution that models the belief over what the true state is can be used as\na sufficient statistic of the history, but its computation requires access to\nthe model of the environment and is often intractable. While SOTA algorithms\nuse Recurrent Neural Networks to compress the observation-action history aiming\nto learn a sufficient statistic, they lack guarantees of success and can lead\nto sub-optimal policies. To overcome this, we propose the Wasserstein Belief\nUpdater, an RL algorithm that learns a latent model of the POMDP and an\napproximation of the belief update. Our approach comes with theoretical\nguarantees on the quality of our approximation ensuring that our outputted\nbeliefs allow for learning the optimal value function.",
          "link": "http://arxiv.org/abs/2303.03284",
          "publishedOn": "2023-10-28T00:41:30.075Z",
          "wordCount": null,
          "title": "The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models. (arXiv:2303.03284v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.01757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhuoqun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marchant_N/0/1/0/all/0/1\">Neil G. Marchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucas_K/0/1/0/all/0/1\">Keane Lucas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_L/0/1/0/all/0/1\">Lujo Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohrimenko_O/0/1/0/all/0/1\">Olga Ohrimenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1\">Benjamin I. P. Rubinstein</a>",
          "description": "Randomized smoothing is a leading approach for constructing classifiers that\nare certifiably robust against adversarial examples. Existing work on\nrandomized smoothing has focused on classifiers with continuous inputs, such as\nimages, where $\\ell_p$-norm bounded adversaries are commonly studied. However,\nthere has been limited work for classifiers with discrete or variable-size\ninputs, such as for source code, which require different threat models and\nsmoothing mechanisms. In this work, we adapt randomized smoothing for discrete\nsequence classifiers to provide certified robustness against edit\ndistance-bounded adversaries. Our proposed smoothing mechanism randomized\ndeletion (RS-Del) applies random deletion edits, which are (perhaps\nsurprisingly) sufficient to confer robustness against adversarial deletion,\ninsertion and substitution edits. Our proof of certification deviates from the\nestablished Neyman-Pearson approach, which is intractable in our setting, and\nis instead organized around longest common subsequences. We present a case\nstudy on malware detection--a binary classification problem on byte sequences\nwhere classifier evasion is a well-established threat model. When applied to\nthe popular MalConv malware detection model, our smoothing mechanism RS-Del\nachieves a certified accuracy of 91% at an edit distance radius of 128 bytes.",
          "link": "http://arxiv.org/abs/2302.01757",
          "publishedOn": "2023-10-28T00:41:30.074Z",
          "wordCount": null,
          "title": "RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion. (arXiv:2302.01757v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.11207",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Hibat_Allah_M/0/1/0/all/0/1\">Mohamed Hibat-Allah</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Melko_R/0/1/0/all/0/1\">Roger G. Melko</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Carrasquilla_J/0/1/0/all/0/1\">Juan Carrasquilla</a>",
          "description": "Recurrent neural networks (RNNs), originally developed for natural language\nprocessing, hold great promise for accurately describing strongly correlated\nquantum many-body systems. Here, we employ 2D RNNs to investigate two\nprototypical quantum many-body Hamiltonians exhibiting topological order.\nSpecifically, we demonstrate that RNN wave functions can effectively capture\nthe topological order of the toric code and a Bose-Hubbard spin liquid on the\nkagome lattice by estimating their topological entanglement entropies. We also\nfind that RNNs favor coherent superpositions of minimally-entangled states over\nminimally-entangled states themselves. Overall, our findings demonstrate that\nRNN wave functions constitute a powerful tool to study phases of matter beyond\nLandau's symmetry-breaking paradigm.",
          "link": "http://arxiv.org/abs/2303.11207",
          "publishedOn": "2023-10-28T00:41:30.074Z",
          "wordCount": null,
          "title": "Investigating Topological Order using Recurrent Neural Networks. (arXiv:2303.11207v3 [cond-mat.str-el] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.11249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alexander_Y/0/1/0/all/0/1\">Yotam Alexander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vega_N/0/1/0/all/0/1\">Nimrod De La Vega</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razin_N/0/1/0/all/0/1\">Noam Razin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1\">Nadav Cohen</a>",
          "description": "The question of what makes a data distribution suitable for deep learning is\na fundamental open problem. Focusing on locally connected neural networks (a\nprevalent family of architectures that includes convolutional and recurrent\nneural networks as well as local self-attention models), we address this\nproblem by adopting theoretical tools from quantum physics. Our main\ntheoretical result states that a certain locally connected neural network is\ncapable of accurate prediction over a data distribution if and only if the data\ndistribution admits low quantum entanglement under certain canonical partitions\nof features. As a practical application of this result, we derive a\npreprocessing method for enhancing the suitability of a data distribution to\nlocally connected neural networks. Experiments with widespread models over\nvarious datasets demonstrate our findings. We hope that our use of quantum\nentanglement will encourage further adoption of tools from physics for formally\nreasoning about the relation between deep learning and real-world data.",
          "link": "http://arxiv.org/abs/2303.11249",
          "publishedOn": "2023-10-28T00:41:30.074Z",
          "wordCount": null,
          "title": "What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement. (arXiv:2303.11249v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.00633",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuxi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiran Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qizhe Xie</a>",
          "description": "Breaking down a problem into intermediate steps has demonstrated impressive\nperformance in Large Language Model (LLM) reasoning. However, the growth of the\nreasoning chain introduces uncertainty and error accumulation, making it\nchallenging to elicit accurate final results. To tackle this challenge of\nuncertainty in multi-step reasoning, we introduce a stepwise self-evaluation\nmechanism to guide and calibrate the reasoning process of LLMs. We propose a\ndecoding algorithm integrating the self-evaluation guidance via stochastic beam\nsearch. The self-evaluation guidance serves as a better-calibrated automatic\ncriterion, facilitating an efficient search in the reasoning space and\nresulting in superior prediction quality. Stochastic beam search balances\nexploitation and exploration of the search space with temperature-controlled\nrandomness. Our approach surpasses the corresponding Codex-backboned baselines\nin few-shot accuracy by $6.34\\%$, $9.56\\%$, and $5.46\\%$ on the GSM8K, AQuA,\nand StrategyQA benchmarks, respectively. Experiment results with Llama-2 on\narithmetic reasoning demonstrate the efficiency of our method in outperforming\nthe baseline methods with comparable computational budgets. Further analysis in\nmulti-step reasoning finds our self-evaluation guidance pinpoints logic\nfailures and leads to higher consistency and robustness. Our code is publicly\navailable at https://guideddecoding.github.io/.",
          "link": "http://arxiv.org/abs/2305.00633",
          "publishedOn": "2023-10-28T00:41:30.074Z",
          "wordCount": null,
          "title": "Self-Evaluation Guided Beam Search for Reasoning. (arXiv:2305.00633v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.01681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naunheim_S/0/1/0/all/0/1\">Stephan Naunheim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhl_Y/0/1/0/all/0/1\">Yannick Kuhl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schug_D/0/1/0/all/0/1\">David Schug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulz_V/0/1/0/all/0/1\">Volkmar Schulz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_F/0/1/0/all/0/1\">Florian Mueller</a>",
          "description": "Artificial intelligence (AI) is entering medical imaging, mainly enhancing\nimage reconstruction. Nevertheless, improvements throughout the entire\nprocessing, from signal detection to computation, potentially offer significant\nbenefits. This work presents a novel and versatile approach to detector\noptimization using machine learning (ML) and residual physics. We apply the\nconcept to positron emission tomography (PET), intending to improve the\ncoincidence time resolution (CTR). PET visualizes metabolic processes in the\nbody by detecting photons with scintillation detectors. Improved CTR\nperformance offers the advantage of reducing radioactive dose exposure for\npatients. Modern PET detectors with sophisticated concepts and read-out\ntopologies represent complex physical and electronic systems requiring\ndedicated calibration techniques. Traditional methods primarily depend on\nanalytical formulations successfully describing the main detector\ncharacteristics. However, when accounting for higher-order effects, additional\ncomplexities arise matching theoretical models to experimental reality. Our\nwork addresses this challenge by combining traditional calibration with AI and\nresidual physics, presenting a highly promising approach. We present a residual\nphysics-based strategy using gradient tree boosting and physics-guided data\ngeneration. The explainable AI framework SHapley Additive exPlanations (SHAP)\nwas used to identify known physical effects with learned patterns. In addition,\nthe models were tested against basic physical laws. We were able to improve the\nCTR significantly (more than 20%) for clinically relevant detectors of 19 mm\nheight, reaching CTRs of 185 ps (450-550 keV).",
          "link": "http://arxiv.org/abs/2302.01681",
          "publishedOn": "2023-10-28T00:41:30.073Z",
          "wordCount": null,
          "title": "Improving the Timing Resolution of Positron Emission Tomography Detectors Using Boosted Learning -- A Residual Physics Approach. (arXiv:2302.01681v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.11685",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jang_K/0/1/0/all/0/1\">Kangwook Jang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1\">Sungnyun Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yun_S/0/1/0/all/0/1\">Se-Young Yun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_H/0/1/0/all/0/1\">Hoirin Kim</a>",
          "description": "Transformer-based speech self-supervised learning (SSL) models, such as\nHuBERT, show surprising performance in various speech processing tasks.\nHowever, huge number of parameters in speech SSL models necessitate the\ncompression to a more compact model for wider usage in academia or small\ncompanies. In this study, we suggest to reuse attention maps across the\nTransformer layers, so as to remove key and query parameters while retaining\nthe number of layers. Furthermore, we propose a novel masking distillation\nstrategy to improve the student model's speech representation quality. We\nextend the distillation loss to utilize both masked and unmasked speech frames\nto fully leverage the teacher model's high-quality representation. Our\nuniversal compression strategy yields the student model that achieves phoneme\nerror rate (PER) of 7.72% and word error rate (WER) of 9.96% on the SUPERB\nbenchmark.",
          "link": "http://arxiv.org/abs/2305.11685",
          "publishedOn": "2023-10-28T00:41:30.072Z",
          "wordCount": null,
          "title": "Recycle-and-Distill: Universal Compression Strategy for Transformer-based Speech SSL Models with Attention Map Reusing and Masking Distillation. (arXiv:2305.11685v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kaiwen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wenger_J/0/1/0/all/0/1\">Jonathan Wenger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_H/0/1/0/all/0/1\">Haydn Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1\">Geoff Pleiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1\">Jacob R. Gardner</a>",
          "description": "Gaussian process (GP) hyperparameter optimization requires repeatedly solving\nlinear systems with $n \\times n$ kernel matrices. To address the prohibitive\n$\\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative\nnumerical methods, like conjugate gradients (CG). However, as datasets increase\nin magnitude, the corresponding kernel matrices become increasingly\nill-conditioned and still require $\\mathcal{O}(n^2)$ space without\npartitioning. Thus, while CG increases the size of datasets GPs can be trained\non, modern datasets reach scales beyond its applicability. In this work, we\npropose an iterative method which only accesses subblocks of the kernel matrix,\neffectively enabling \\emph{mini-batching}. Our algorithm, based on alternating\nprojection, has $\\mathcal{O}(n)$ per-iteration time and space complexity,\nsolving many of the practical challenges of scaling GPs to very large datasets.\nTheoretically, we prove our method enjoys linear convergence and empirically we\ndemonstrate its robustness to ill-conditioning. On large-scale benchmark\ndatasets up to four million datapoints our approach accelerates training by a\nfactor of 2$\\times$ to 27$\\times$ compared to CG.",
          "link": "http://arxiv.org/abs/2310.17137",
          "publishedOn": "2023-10-28T00:41:30.071Z",
          "wordCount": null,
          "title": "Large-Scale Gaussian Processes via Alternating Projection. (arXiv:2310.17137v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zang_H/0/1/0/all/0/1\">Hongyu Zang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Leiji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Baigui Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_R/0/1/0/all/0/1\">Riashat Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Combes_R/0/1/0/all/0/1\">Remi Tachet des Combes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laroche_R/0/1/0/all/0/1\">Romain Laroche</a>",
          "description": "While bisimulation-based approaches hold promise for learning robust state\nrepresentations for Reinforcement Learning (RL) tasks, their efficacy in\noffline RL tasks has not been up to par. In some instances, their performance\nhas even significantly underperformed alternative methods. We aim to understand\nwhy bisimulation methods succeed in online settings, but falter in offline\ntasks. Our analysis reveals that missing transitions in the dataset are\nparticularly harmful to the bisimulation principle, leading to ineffective\nestimation. We also shed light on the critical role of reward scaling in\nbounding the scale of bisimulation measurements and of the value error they\ninduce. Based on these findings, we propose to apply the expectile operator for\nrepresentation learning to our offline RL setting, which helps to prevent\noverfitting to incomplete data. Meanwhile, by introducing an appropriate reward\nscaling strategy, we avoid the risk of feature collapse in representation\nspace. We implement these recommendations on two state-of-the-art\nbisimulation-based algorithms, MICo and SimSR, and demonstrate performance\ngains on two benchmark suites: D4RL and Visual D4RL. Codes are provided at\n\\url{https://github.com/zanghyu/Offline_Bisimulation}.",
          "link": "http://arxiv.org/abs/2310.17139",
          "publishedOn": "2023-10-28T00:41:30.071Z",
          "wordCount": null,
          "title": "Understanding and Addressing the Pitfalls of Bisimulation-based Representations in Offline Reinforcement Learning. (arXiv:2310.17139v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_C/0/1/0/all/0/1\">Chenze Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhengrui Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>",
          "description": "Maximum likelihood estimation (MLE) is a statistical method used to estimate\nthe parameters of a probability distribution that best explain the observed\ndata. In the context of text generation, MLE is often used to train generative\nlanguage models, which can then be used to generate new text. However, we argue\nthat MLE is not always necessary and optimal, especially for closed-ended text\ngeneration tasks like machine translation. In these tasks, the goal of model is\nto generate the most appropriate response, which does not necessarily require\nit to estimate the entire data distribution with MLE. To this end, we propose a\nnovel class of training objectives based on convex functions, which enables\ntext generation models to focus on highly probable outputs without having to\nestimate the entire data distribution. We investigate the theoretical\nproperties of the optimal predicted distribution when applying convex functions\nto the loss, demonstrating that convex functions can sharpen the optimal\ndistribution, thereby enabling the model to better capture outputs with high\nprobabilities. Experiments on various text generation tasks and models show the\neffectiveness of our approach. It enables autoregressive models to bridge the\ngap between greedy and beam search, and facilitates the learning of\nnon-autoregressive models with a maximum improvement of 9+ BLEU points.\nMoreover, our approach also exhibits significant impact on large language\nmodels (LLMs), substantially enhancing their generative capability on various\ntasks. Source code is available at\n\\url{https://github.com/ictnlp/Convex-Learning}.",
          "link": "http://arxiv.org/abs/2310.17217",
          "publishedOn": "2023-10-28T00:41:30.071Z",
          "wordCount": null,
          "title": "Beyond MLE: Convex Learning for Text Generation. (arXiv:2310.17217v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.05321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dang_V/0/1/0/all/0/1\">Vien Ngoc Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cascarano_A/0/1/0/all/0/1\">Anna Cascarano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mulder_R/0/1/0/all/0/1\">Rosa H. Mulder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cecil_C/0/1/0/all/0/1\">Charlotte Cecil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuluaga_M/0/1/0/all/0/1\">Maria A. Zuluaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Gonzalez_J/0/1/0/all/0/1\">Jer&#xf3;nimo Hern&#xe1;ndez-Gonz&#xe1;lez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lekadir_K/0/1/0/all/0/1\">Karim Lekadir</a>",
          "description": "A significant level of stigma and inequality exists in mental healthcare,\nespecially in under-served populations. Inequalities are reflected in the data\ncollected for scientific purposes. When not properly accounted for, machine\nlearning (ML) models leart from data can reinforce these structural\ninequalities or biases. Here, we present a systematic study of bias in ML\nmodels designed to predict depression in four different case studies covering\ndifferent countries and populations. We find that standard ML approaches show\nregularly biased behaviors. We also show that mitigation techniques, both\nstandard and our own post-hoc method, can be effective in reducing the level of\nunfair bias. No single best ML model for depression prediction provides\nequality of outcomes. This emphasizes the importance of analyzing fairness\nduring model selection and transparent reporting about the impact of debiasing\ninterventions. Finally, we provide practical recommendations to develop\nbias-aware ML models for depression risk prediction.",
          "link": "http://arxiv.org/abs/2211.05321",
          "publishedOn": "2023-10-28T00:41:30.071Z",
          "wordCount": null,
          "title": "Fairness and bias correction in machine learning for depression prediction: results from four study populations. (arXiv:2211.05321v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14943",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sharrock_L/0/1/0/all/0/1\">Louis Sharrock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nemeth_C/0/1/0/all/0/1\">Christopher Nemeth</a>",
          "description": "We introduce a suite of new particle-based algorithms for sampling on\nconstrained domains which are entirely learning rate free. Our approach\nleverages coin betting ideas from convex optimisation, and the viewpoint of\nconstrained sampling as a mirrored optimisation problem on the space of\nprobability measures. Based on this viewpoint, we also introduce a unifying\nframework for several existing constrained sampling algorithms, including\nmirrored Langevin dynamics and mirrored Stein variational gradient descent. We\ndemonstrate the performance of our algorithms on a range of numerical examples,\nincluding sampling from targets on the simplex, sampling with fairness\nconstraints, and constrained sampling problems in post-selection inference. Our\nresults indicate that our algorithms achieve competitive performance with\nexisting constrained sampling methods, without the need to tune any\nhyperparameters.",
          "link": "http://arxiv.org/abs/2305.14943",
          "publishedOn": "2023-10-28T00:41:30.071Z",
          "wordCount": null,
          "title": "Learning Rate Free Bayesian Inference in Constrained Domains. (arXiv:2305.14943v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17009",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yao_Y/0/1/0/all/0/1\">Yuling Yao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Blancard_B/0/1/0/all/0/1\">Bruno R&#xe9;galdo-Saint Blancard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Domke_J/0/1/0/all/0/1\">Justin Domke</a>",
          "description": "Simulation-based inference has been popular for amortized Bayesian\ncomputation. It is typical to have more than one posterior approximation, from\ndifferent inference algorithms, different architectures, or simply the\nrandomness of initialization and stochastic gradients. With a provable\nasymptotic guarantee, we present a general stacking framework to make use of\nall available posterior approximations. Our stacking method is able to combine\ndensities, simulation draws, confidence intervals, and moments, and address the\noverall precision, calibration, coverage, and bias at the same time. We\nillustrate our method on several benchmark simulations and a challenging\ncosmological inference task.",
          "link": "http://arxiv.org/abs/2310.17009",
          "publishedOn": "2023-10-28T00:41:30.070Z",
          "wordCount": null,
          "title": "Simulation based stacking. (arXiv:2310.17009v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naimi_S/0/1/0/all/0/1\">Safwen Naimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koubaa_O/0/1/0/all/0/1\">Olfa Koubaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouachir_W/0/1/0/all/0/1\">Wassim Bouachir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilodeau_G/0/1/0/all/0/1\">Guillaume-Alexandre Bilodeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeddore_G/0/1/0/all/0/1\">Gregory Jeddore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baines_P/0/1/0/all/0/1\">Patricia Baines</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Correia_D/0/1/0/all/0/1\">David Correia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arsenault_A/0/1/0/all/0/1\">Andre Arsenault</a>",
          "description": "Lichens are symbiotic organisms composed of fungi, algae, and/or\ncyanobacteria that thrive in a variety of environments. They play important\nroles in carbon and nitrogen cycling, and contribute directly and indirectly to\nbiodiversity. Ecologists typically monitor lichens by using them as indicators\nto assess air quality and habitat conditions. In particular, epiphytic lichens,\nwhich live on trees, are key markers of air quality and environmental health. A\nnew method of monitoring epiphytic lichens involves using time-lapse cameras to\ngather images of lichen populations. These cameras are used by ecologists in\nNewfoundland and Labrador to subsequently analyze and manually segment the\nimages to determine lichen thalli condition and change. These methods are\ntime-consuming and susceptible to observer bias. In this work, we aim to\nautomate the monitoring of lichens over extended periods and to estimate their\nbiomass and condition to facilitate the task of ecologists. To accomplish this,\nour proposed framework uses semantic segmentation with an effective training\napproach to automate monitoring and biomass estimation of epiphytic lichens on\ntime-lapse images. We show that our method has the potential to significantly\nimprove the accuracy and efficiency of lichen population monitoring, making it\na valuable tool for forest ecologists and environmental scientists to evaluate\nthe impact of climate change on Canada's forests. To the best of our knowledge,\nthis is the first time that such an approach has been used to assist ecologists\nin monitoring and analyzing epiphytic lichens.",
          "link": "http://arxiv.org/abs/2310.17080",
          "publishedOn": "2023-10-28T00:41:30.070Z",
          "wordCount": null,
          "title": "Automating lichen monitoring in ecological studies using instance segmentation of time-lapse images. (arXiv:2310.17080v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.04089",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kurtic_E/0/1/0/all/0/1\">Eldar Kurtic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frantar_E/0/1/0/all/0/1\">Elias Frantar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>",
          "description": "The breakthrough performance of large language models (LLMs) comes with major\ncomputational footprints and high deployment costs. In this paper, we progress\ntowards resolving this problem by proposing a novel structured compression\napproach for LLMs, called ZipLM. ZipLM achieves state-of-the-art\naccuracy-vs-speedup, while matching a set of desired target runtime speedups in\nany given inference environment. Specifically, given a model, a dataset, an\ninference environment, as well as a set of speedup targets, ZipLM iteratively\nidentifies and removes components with the worst loss-runtime trade-off. Unlike\nprior methods that specialize in either the post-training/one-shot or the\ngradual compression setting, and only for specific families of models such as\nBERT (encoder) or GPT (decoder), ZipLM produces state-of-the-art compressed\nmodels across all these settings. Furthermore, ZipLM achieves superior results\nfor a fraction of the computational cost relative to prior distillation and\npruning techniques, making it a cost-effective approach for generating an\nentire family of smaller, faster, and highly accurate models, guaranteed to\nmeet the desired inference specifications. In particular, ZipLM outperforms all\nprior BERT-base distillation and pruning techniques, such as CoFi, MiniLM, and\nTinyBERT. Moreover, it matches the performance of the heavily optimized\nMobileBERT model, obtained via extensive architecture search, by simply pruning\nthe baseline BERT-large model. When compressing GPT2, ZipLM outperforms\nDistilGPT2 while being 60% smaller and 30% faster. Our code is available at:\nhttps://github.com/IST-DASLab/ZipLM.",
          "link": "http://arxiv.org/abs/2302.04089",
          "publishedOn": "2023-10-28T00:41:30.070Z",
          "wordCount": null,
          "title": "ZipLM: Inference-Aware Structured Pruning of Language Models. (arXiv:2302.04089v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhenghao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1\">Molei Tao</a>",
          "description": "Large learning rates, when applied to gradient descent for nonconvex\noptimization, yield various implicit biases including the edge of stability\n(Cohen et al., 2021), balancing (Wang et al., 2022), and catapult (Lewkowycz et\nal., 2020). These phenomena cannot be well explained by classical optimization\ntheory. Though significant theoretical progress has been made in understanding\nthese implicit biases, it remains unclear for which objective functions would\nthey occur. This paper provides an initial step in answering this question,\nnamely that these implicit biases are in fact various tips of the same iceberg.\nThey occur when the objective function of optimization has some good\nregularity, which, in combination with a provable preference of large learning\nrate gradient descent for moving toward flatter regions, results in these\nnontrivial dynamical phenomena. To establish this result, we develop a new\nglobal convergence theory under large learning rates, for a family of nonconvex\nfunctions without globally Lipschitz continuous gradient, which was typically\nassumed in existing convergence analysis. A byproduct is the first\nnon-asymptotic convergence rate bound for large-learning-rate gradient descent\noptimization of nonconvex functions. We also validate our theory with\nexperiments on neural networks, where different losses, activation functions,\nand batch normalization all can significantly affect regularity and lead to\nvery different training dynamics.",
          "link": "http://arxiv.org/abs/2310.17087",
          "publishedOn": "2023-10-28T00:41:30.068Z",
          "wordCount": null,
          "title": "Good regularity creates large learning rate implicit biases: edge of stability, balancing, and catapult. (arXiv:2310.17087v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17149",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiabin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1\">Lianghao Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chao Huang</a>",
          "description": "Spatio-temporal graph neural networks (STGNNs) have gained popularity as a\npowerful tool for effectively modeling spatio-temporal dependencies in diverse\nreal-world urban applications, including intelligent transportation and public\nsafety. However, the black-box nature of STGNNs limits their interpretability,\nhindering their application in scenarios related to urban resource allocation\nand policy formulation. To bridge this gap, we propose an Explainable\nSpatio-Temporal Graph Neural Networks (STExplainer) framework that enhances\nSTGNNs with inherent explainability, enabling them to provide accurate\npredictions and faithful explanations simultaneously. Our framework integrates\na unified spatio-temporal graph attention network with a positional information\nfusion layer as the STG encoder and decoder, respectively. Furthermore, we\npropose a structure distillation approach based on the Graph Information\nBottleneck (GIB) principle with an explainable objective, which is instantiated\nby the STG encoder and decoder. Through extensive experiments, we demonstrate\nthat our STExplainer outperforms state-of-the-art baselines in terms of\npredictive accuracy and explainability metrics (i.e., sparsity and fidelity) on\ntraffic and crime prediction tasks. Furthermore, our model exhibits superior\nrepresentation ability in alleviating data missing and sparsity issues. The\nimplementation code is available at: https://github.com/HKUDS/STExplainer.",
          "link": "http://arxiv.org/abs/2310.17149",
          "publishedOn": "2023-10-28T00:41:30.068Z",
          "wordCount": null,
          "title": "Explainable Spatio-Temporal Graph Neural Networks. (arXiv:2310.17149v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saidi_H/0/1/0/all/0/1\">Hassen Saidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Susmit Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahai_T/0/1/0/all/0/1\">Tuhin Sahai</a>",
          "description": "As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n\nWhile prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.",
          "link": "http://arxiv.org/abs/2310.17064",
          "publishedOn": "2023-10-28T00:41:30.067Z",
          "wordCount": null,
          "title": "math-PVS: A Large Language Model Framework to Map Scientific Publications to PVS Theories. (arXiv:2310.17064v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zeyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yijian Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Simin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>",
          "description": "In an era marked by the increasing adoption of Large Language Models (LLMs)\nfor various tasks, there is a growing focus on exploring LLMs' capabilities in\nhandling web data, particularly graph data. Dynamic graphs, which capture\ntemporal network evolution patterns, are ubiquitous in real-world web data.\nEvaluating LLMs' competence in understanding spatial-temporal information on\ndynamic graphs is essential for their adoption in web applications, which\nremains unexplored in the literature. In this paper, we bridge the gap via\nproposing to evaluate LLMs' spatial-temporal understanding abilities on dynamic\ngraphs, to the best of our knowledge, for the first time. Specifically, we\npropose the LLM4DyG benchmark, which includes nine specially designed tasks\nconsidering the capability evaluation of LLMs from both temporal and spatial\ndimensions. Then, we conduct extensive experiments to analyze the impacts of\ndifferent data generators, data statistics, prompting techniques, and LLMs on\nthe model performance. Finally, we propose Disentangled Spatial-Temporal\nThoughts (DST2) for LLMs on dynamic graphs to enhance LLMs' spatial-temporal\nunderstanding abilities. Our main observations are: 1) LLMs have preliminary\nspatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph\ntasks show increasing difficulties for LLMs as the graph size and density\nincrease, while not sensitive to the time span and data generation mechanism,\n3) the proposed DST2 prompting method can help to improve LLMs'\nspatial-temporal understanding abilities on dynamic graphs for most tasks. The\ndata and codes will be open-sourced at publication time.",
          "link": "http://arxiv.org/abs/2310.17110",
          "publishedOn": "2023-10-28T00:41:30.067Z",
          "wordCount": null,
          "title": "LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?. (arXiv:2310.17110v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Longlin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tianyu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cheng Zhang</a>",
          "description": "Semi-implicit variational inference (SIVI) has been introduced to expand the\nanalytical variational families by defining expressive semi-implicit\ndistributions in a hierarchical manner. However, the single-layer architecture\ncommonly used in current SIVI methods can be insufficient when the target\nposterior has complicated structures. In this paper, we propose hierarchical\nsemi-implicit variational inference, called HSIVI, which generalizes SIVI to\nallow more expressive multi-layer construction of semi-implicit distributions.\nBy introducing auxiliary distributions that interpolate between a simple base\ndistribution and the target distribution, the conditional layers can be trained\nby progressively matching these auxiliary distributions one layer after\nanother. Moreover, given pre-trained score networks, HSIVI can be used to\naccelerate the sampling process of diffusion models with the score matching\nobjective. We show that HSIVI significantly enhances the expressiveness of SIVI\non several Bayesian inference problems with complicated target distributions.\nWhen used for diffusion model acceleration, we show that HSIVI can produce high\nquality samples comparable to or better than the existing fast diffusion model\nbased samplers with a small number of function evaluations on various datasets.",
          "link": "http://arxiv.org/abs/2310.17153",
          "publishedOn": "2023-10-28T00:41:30.066Z",
          "wordCount": null,
          "title": "Hierarchical Semi-Implicit Variational Inference with Application to Diffusion Model Acceleration. (arXiv:2310.17153v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zichang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dao_T/0/1/0/all/0/1\">Tri Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1\">Binhang Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1\">Anshumali Shrivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher Re</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Beidi Chen</a>",
          "description": "Large language models (LLMs) with hundreds of billions of parameters have\nsparked a new wave of exciting AI applications. However, they are\ncomputationally expensive at inference time. Sparsity is a natural approach to\nreduce this cost, but existing methods either require costly retraining, have\nto forgo LLM's in-context learning ability, or do not yield wall-clock time\nspeedup on modern hardware. We hypothesize that contextual sparsity, which are\nsmall, input-dependent sets of attention heads and MLP parameters that yield\napproximately the same output as the dense model for a given input, can address\nthese issues. We show that contextual sparsity exists, that it can be\naccurately predicted, and that we can exploit it to speed up LLM inference in\nwall-clock time without compromising LLM's quality or in-context learning\nability. Based on these insights, we propose DejaVu, a system that uses a\nlow-cost algorithm to predict contextual sparsity on the fly given inputs to\neach layer, along with an asynchronous and hardware-aware implementation that\nspeeds up LLM inference. We validate that DejaVu can reduce the inference\nlatency of OPT-175B by over 2X compared to the state-of-the-art\nFasterTransformer, and over 6X compared to the widely used Hugging Face\nimplementation, without compromising model quality. The code is available at\nhttps://github.com/FMInference/DejaVu.",
          "link": "http://arxiv.org/abs/2310.17157",
          "publishedOn": "2023-10-28T00:41:30.066Z",
          "wordCount": null,
          "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time. (arXiv:2310.17157v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1\">Jack Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ONeill_C/0/1/0/all/0/1\">Charles O&#x27;Neill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1\">Thang Bui</a>",
          "description": "In some settings neural networks exhibit a phenomenon known as grokking,\nwhere they achieve perfect or near-perfect accuracy on the validation set long\nafter the same performance has been achieved on the training set. In this\npaper, we discover that grokking is not limited to neural networks but occurs\nin other settings such as Gaussian process (GP) classification, GP regression\nand linear regression. We also uncover a mechanism by which to induce grokking\non algorithmic datasets via the addition of dimensions containing spurious\ninformation. The presence of the phenomenon in non-neural architectures\nprovides evidence that grokking is not specific to SGD or weight norm\nregularisation. Instead, grokking may be possible in any setting where solution\nsearch is guided by complexity and error. Based on this insight and further\ntrends we see in the training trajectories of a Bayesian neural network (BNN)\nand GP regression model, we make progress towards a more general theory of\ngrokking. Specifically, we hypothesise that the phenomenon is governed by the\naccessibility of certain regions in the error and complexity landscapes.",
          "link": "http://arxiv.org/abs/2310.17247",
          "publishedOn": "2023-10-28T00:41:30.066Z",
          "wordCount": null,
          "title": "Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity. (arXiv:2310.17247v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.15543",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Brown_S/0/1/0/all/0/1\">Stephen Brown</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rodi_W/0/1/0/all/0/1\">William L. Rodi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Seracini_M/0/1/0/all/0/1\">Marco Seracini</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gu_C/0/1/0/all/0/1\">Chen Gu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Fehler_M/0/1/0/all/0/1\">Michael Fehler</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Faulds_J/0/1/0/all/0/1\">James Faulds</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Smith_C/0/1/0/all/0/1\">Connor M. Smith</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Treitel_S/0/1/0/all/0/1\">Sven Treitel</a>",
          "description": "We consider the application of machine learning to the evaluation of\ngeothermal resource potential. A supervised learning problem is defined where\nmaps of 10 geological and geophysical features within the state of Nevada, USA\nare used to define geothermal potential across a broad region. We have\navailable a relatively small set of positive training sites (known resources or\nactive power plants) and negative training sites (known drill sites with\nunsuitable geothermal conditions) and use these to constrain and optimize\nartificial neural networks for this classification task. The main objective is\nto predict the geothermal resource potential at unknown sites within a large\ngeographic area where the defining features are known. These predictions could\nbe used to target promising areas for further detailed investigations. We\ndescribe the evolution of our work from defining a specific neural network\narchitecture to training and optimization trials. Upon analysis we expose the\ninevitable problems of model variability and resulting prediction uncertainty.\nFinally, to address these problems we apply the concept of Bayesian neural\nnetworks, a heuristic approach to regularization in network training, and make\nuse of the practical interpretation of the formal uncertainty measures they\nprovide.",
          "link": "http://arxiv.org/abs/2209.15543",
          "publishedOn": "2023-10-28T00:41:30.066Z",
          "wordCount": null,
          "title": "Bayesian Neural Networks for Geothermal Resource Assessment: Prediction with Uncertainty. (arXiv:2209.15543v3 [physics.geo-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1\">Reshmi Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kajal_H/0/1/0/all/0/1\">Harjeet Singh Kajal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamath_S/0/1/0/all/0/1\">Sharanya Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_D/0/1/0/all/0/1\">Dhuri Shrivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1\">Samyadeep Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Hansi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1\">Soundararajan Srinivasan</a>",
          "description": "Breaking down a document or a conversation into multiple contiguous segments\nbased on its semantic structure is an important and challenging problem in NLP,\nwhich can assist many downstream tasks. However, current works on topic\nsegmentation often focus on segmentation of structured texts. In this paper, we\ncomprehensively analyze the generalization capabilities of state-of-the-art\ntopic segmentation models on unstructured texts. We find that: (a) Current\nstrategies of pre-training on a large corpus of structured text such as\nWiki-727K do not help in transferability to unstructured conversational data.\n(b) Training from scratch with only a relatively small-sized dataset of the\ntarget unstructured domain improves the segmentation results by a significant\nmargin. We stress-test our proposed Topic Segmentation approach by\nexperimenting with multiple loss functions, in order to mitigate effects of\nimbalance in unstructured conversational datasets. Our empirical evaluation\nindicates that Focal Loss function is a robust alternative to Cross-Entropy and\nre-weighted Cross-Entropy loss function when segmenting unstructured and\nsemi-structured chats.",
          "link": "http://arxiv.org/abs/2310.17120",
          "publishedOn": "2023-10-28T00:41:30.065Z",
          "wordCount": null,
          "title": "Topic Segmentation of Semi-Structured and Unstructured Conversational Datasets using Language Models. (arXiv:2310.17120v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tamkin_A/0/1/0/all/0/1\">Alex Tamkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taufeeque_M/0/1/0/all/0/1\">Mohammad Taufeeque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>",
          "description": "Understanding neural networks is challenging in part because of the dense,\ncontinuous nature of their hidden states. We explore whether we can train\nneural networks to have hidden states that are sparse, discrete, and more\ninterpretable by quantizing their continuous features into what we call\ncodebook features. Codebook features are produced by finetuning neural networks\nwith vector quantization bottlenecks at each layer, producing a network whose\nhidden features are the sum of a small number of discrete vector codes chosen\nfrom a larger codebook. Surprisingly, we find that neural networks can operate\nunder this extreme bottleneck with only modest degradation in performance. This\nsparse, discrete bottleneck also provides an intuitive way of controlling\nneural network behavior: first, find codes that activate when the desired\nbehavior is present, then activate those same codes during generation to elicit\nthat behavior. We validate our approach by training codebook Transformers on\nseveral different datasets. First, we explore a finite state machine dataset\nwith far more hidden states than neurons. In this setting, our approach\novercomes the superposition problem by assigning states to distinct codes, and\nwe find that we can make the neural network behave as if it is in a different\nstate by activating the code for that state. Second, we train Transformer\nlanguage models with up to 410M parameters on two natural language datasets. We\nidentify codes in these models representing diverse, disentangled concepts\n(ranging from negative emotions to months of the year) and find that we can\nguide the model to generate different topics by activating the appropriate\ncodes during inference. Overall, codebook features appear to be a promising\nunit of analysis and control for neural networks and interpretability. Our\ncodebase and models are open-sourced at\nhttps://github.com/taufeeque9/codebook-features.",
          "link": "http://arxiv.org/abs/2310.17230",
          "publishedOn": "2023-10-28T00:41:30.065Z",
          "wordCount": null,
          "title": "Codebook Features: Sparse and Discrete Interpretability for Neural Networks. (arXiv:2310.17230v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neo_D/0/1/0/all/0/1\">Dexter Neo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winkler_S/0/1/0/all/0/1\">Stefan Winkler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tsuhan Chen</a>",
          "description": "We present a new loss function that addresses the out-of-distribution (OOD)\ncalibration problem. While many objective functions have been proposed to\neffectively calibrate models in-distribution, our findings show that they do\nnot always fare well OOD. Based on the Principle of Maximum Entropy, we\nincorporate helpful statistical constraints observed during training,\ndelivering better model calibration without sacrificing accuracy. We provide\ntheoretical analysis and show empirically that our method works well in\npractice, achieving state-of-the-art calibration on both synthetic and\nreal-world benchmarks.",
          "link": "http://arxiv.org/abs/2310.17159",
          "publishedOn": "2023-10-28T00:41:30.064Z",
          "wordCount": null,
          "title": "MaxEnt Loss: Constrained Maximum Entropy for Calibration under Out-of-Distribution Shift. (arXiv:2310.17159v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16905",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bouchiat_K/0/1/0/all/0/1\">Kouroche Bouchiat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Immer_A/0/1/0/all/0/1\">Alexander Immer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yeche_H/0/1/0/all/0/1\">Hugo Y&#xe8;che</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ratsch_G/0/1/0/all/0/1\">Gunnar R&#xe4;tsch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>",
          "description": "Neural additive models (NAMs) can improve the interpretability of deep neural\nnetworks by handling input features in separate additive sub-networks. However,\nthey lack inherent mechanisms that provide calibrated uncertainties and enable\nselection of relevant features and interactions. Approaching NAMs from a\nBayesian perspective, we enhance them in three primary ways, namely by a)\nproviding credible intervals for the individual additive sub-networks; b)\nestimating the marginal likelihood to perform an implicit selection of features\nvia an empirical Bayes procedure; and c) enabling a ranking of feature pairs as\ncandidates for second-order interaction in fine-tuned models. In particular, we\ndevelop Laplace-approximated NAMs (LA-NAMs), which show improved empirical\nperformance on tabular datasets and challenging real-world medical tasks.",
          "link": "http://arxiv.org/abs/2305.16905",
          "publishedOn": "2023-10-28T00:41:30.064Z",
          "wordCount": null,
          "title": "Improving Neural Additive Models with Bayesian Principles. (arXiv:2305.16905v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1\">Kanchana Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryoo_M/0/1/0/all/0/1\">Michael Ryoo</a>",
          "description": "Recent contrastive language image pre-training has led to learning highly\ntransferable and robust image representations. However, adapting these models\nto video domains with minimal supervision remains an open problem. We explore a\nsimple step in that direction, using language tied self-supervised learning to\nadapt an image CLIP model to the video domain. A backbone modified for temporal\nmodeling is trained under self-distillation settings with train objectives\noperating in an action concept space. Feature vectors of various action\nconcepts extracted from a language encoder using relevant textual prompts\nconstruct this space. We introduce two train objectives, concept distillation\nand concept alignment, that retain generality of original representations while\nenforcing relations between actions and their attributes. Our approach improves\nzero-shot and linear probing performance on three action recognition\nbenchmarks.",
          "link": "http://arxiv.org/abs/2307.10922",
          "publishedOn": "2023-10-28T00:41:30.064Z",
          "wordCount": null,
          "title": "Language-based Action Concept Spaces Improve Video Self-Supervised Learning. (arXiv:2307.10922v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Wenhao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1\">Laixi Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1\">Yuejie Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>",
          "description": "Robustness has been extensively studied in reinforcement learning (RL) to\nhandle various forms of uncertainty such as random perturbations, rare events,\nand malicious attacks. In this work, we consider one critical type of\nrobustness against spurious correlation, where different portions of the state\ndo not have correlations induced by unobserved confounders. These spurious\ncorrelations are ubiquitous in real-world tasks, for instance, a self-driving\ncar usually observes heavy traffic in the daytime and light traffic at night\ndue to unobservable human activity. A model that learns such useless or even\nharmful correlation could catastrophically fail when the confounder in the test\ncase deviates from the training one. Although motivated, enabling robustness\nagainst spurious correlation poses significant challenges since the uncertainty\nset, shaped by the unobserved confounder and causal structure, is difficult to\ncharacterize and identify. Existing robust algorithms that assume simple and\nunstructured uncertainty sets are therefore inadequate to address this\nchallenge. To solve this issue, we propose Robust State-Confounded Markov\nDecision Processes (RSC-MDPs) and theoretically demonstrate its superiority in\navoiding learning spurious correlations compared with other robust RL\ncounterparts. We also design an empirical algorithm to learn the robust optimal\npolicy for RSC-MDPs, which outperforms all baselines in eight realistic\nself-driving and manipulation tasks.",
          "link": "http://arxiv.org/abs/2307.07907",
          "publishedOn": "2023-10-28T00:41:30.063Z",
          "wordCount": null,
          "title": "Seeing is not Believing: Robust Reinforcement Learning against Spurious Correlation. (arXiv:2307.07907v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_H/0/1/0/all/0/1\">Hritik Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1\">Tony Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiacheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit\nimpressive problem-solving skills in many tasks and domains, but their ability\nin mathematical reasoning in visual contexts has not been systematically\nstudied. To bridge this gap, we present MathVista, a benchmark designed to\ncombine challenges from diverse mathematical and visual tasks. It consists of\n6,141 examples, derived from 28 existing multimodal datasets involving\nmathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and\nPaperQA). Completing these tasks requires fine-grained, deep visual\nunderstanding and compositional reasoning, which all state-of-the-art\nfoundation models find challenging. With MathVista, we have conducted a\ncomprehensive, quantitative evaluation of 12 prominent foundation models. The\nbest-performing GPT-4V model achieves an overall accuracy of 49.9%,\nsubstantially outperforming Bard, the second-best performer, by 15.1%. Our\nin-depth analysis reveals that the superiority of GPT-4V is mainly attributed\nto its enhanced visual perception and mathematical reasoning. However, GPT-4V\nstill falls short of human performance by 10.4%, as it often struggles to\nunderstand complex figures and perform rigorous reasoning. This significant gap\nunderscores the critical role that MathVista will play in the development of\ngeneral-purpose AI agents capable of tackling mathematically intensive and\nvisually rich real-world tasks. We further explore the new ability of\nself-verification, the application of self-consistency, and the interactive\nchatbot capabilities of GPT-4V, highlighting its promising potential for future\nresearch. The project is available at https://mathvista.github.io/.",
          "link": "http://arxiv.org/abs/2310.02255",
          "publishedOn": "2023-10-28T00:41:30.063Z",
          "wordCount": null,
          "title": "MathVista: Evaluating Math Reasoning in Visual Contexts with GPT-4V, Bard, and Other Large Multimodal Models. (arXiv:2310.02255v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Peng Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1\">Xianyuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhihao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shoucheng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Han Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Youfang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Li Jiang</a>",
          "description": "Offline reinforcement learning (RL) offers an appealing approach to\nreal-world tasks by learning policies from pre-collected datasets without\ninteracting with the environment. However, the performance of existing offline\nRL algorithms heavily depends on the scale and state-action space coverage of\ndatasets. Real-world data collection is often expensive and uncontrollable,\nleading to small and narrowly covered datasets and posing significant\nchallenges for practical deployments of offline RL. In this paper, we provide a\nnew insight that leveraging the fundamental symmetry of system dynamics can\nsubstantially enhance offline RL performance under small datasets.\nSpecifically, we propose a Time-reversal symmetry (T-symmetry) enforced\nDynamics Model (TDM), which establishes consistency between a pair of forward\nand reverse latent dynamics. TDM provides both well-behaved representations for\nsmall datasets and a new reliability measure for OOD samples based on\ncompliance with the T-symmetry. These can be readily used to construct a new\noffline RL algorithm (TSRL) with less conservative policy constraints and a\nreliable latent space data augmentation procedure. Based on extensive\nexperiments, we find TSRL achieves great performance on small benchmark\ndatasets with as few as 1% of the original samples, which significantly\noutperforms the recent offline RL algorithms in terms of data efficiency and\ngeneralizability.Code is available at: https://github.com/pcheng2/TSRL",
          "link": "http://arxiv.org/abs/2306.04220",
          "publishedOn": "2023-10-28T00:41:30.062Z",
          "wordCount": null,
          "title": "Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL. (arXiv:2306.04220v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.09493",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gagolewski_M/0/1/0/all/0/1\">Marek Gagolewski</a>",
          "description": "The evaluation of clustering algorithms can involve running them on a variety\nof benchmark problems, and comparing their outputs to the reference,\nground-truth groupings provided by experts. Unfortunately, many research papers\nand graduate theses consider only a small number of datasets. Also, the fact\nthat there can be many equally valid ways to cluster a given problem set is\nrarely taken into account. In order to overcome these limitations, we have\ndeveloped a framework whose aim is to introduce a consistent methodology for\ntesting clustering algorithms. Furthermore, we have aggregated, polished, and\nstandardised many clustering benchmark dataset collections referred to across\nthe machine learning and data mining literature, and included new datasets of\ndifferent dimensionalities, sizes, and cluster types. An interactive datasets\nexplorer, the documentation of the Python API, a description of the ways to\ninteract with the framework from other programming languages such as R or\nMATLAB, and other details are all provided at\n<https://clustering-benchmarks.gagolewski.com>.",
          "link": "http://arxiv.org/abs/2209.09493",
          "publishedOn": "2023-10-28T00:41:30.061Z",
          "wordCount": null,
          "title": "A framework for benchmarking clustering algorithms. (arXiv:2209.09493v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.01270",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Denize_J/0/1/0/all/0/1\">Julien Denize</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liashuha_M/0/1/0/all/0/1\">Mykola Liashuha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabarisoa_J/0/1/0/all/0/1\">Jaonary Rabarisoa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orcesi_A/0/1/0/all/0/1\">Astrid Orcesi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herault_R/0/1/0/all/0/1\">Romain H&#xe9;rault</a>",
          "description": "We present COMEDIAN, a novel pipeline to initialize spatiotemporal\ntransformers for action spotting, which involves self-supervised learning and\nknowledge distillation. Action spotting is a timestamp-level temporal action\ndetection task. Our pipeline consists of three steps, with two initialization\nstages. First, we perform self-supervised initialization of a spatial\ntransformer using short videos as input. Additionally, we initialize a temporal\ntransformer that enhances the spatial transformer's outputs with global context\nthrough knowledge distillation from a pre-computed feature bank aligned with\neach short video segment. In the final step, we fine-tune the transformers to\nthe action spotting task. The experiments, conducted on the SoccerNet-v2\ndataset, demonstrate state-of-the-art performance and validate the\neffectiveness of COMEDIAN's pretraining paradigm. Our results highlight several\nadvantages of our pretraining pipeline, including improved performance and\nfaster convergence compared to non-pretrained models.",
          "link": "http://arxiv.org/abs/2309.01270",
          "publishedOn": "2023-10-28T00:41:30.061Z",
          "wordCount": null,
          "title": "COMEDIAN: Self-Supervised Learning and Knowledge Distillation for Action Spotting using Transformers. (arXiv:2309.01270v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cabello_L/0/1/0/all/0/1\">Laura Cabello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bugliarello_E/0/1/0/all/0/1\">Emanuele Bugliarello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brandl_S/0/1/0/all/0/1\">Stephanie Brandl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliott_D/0/1/0/all/0/1\">Desmond Elliott</a>",
          "description": "Pretrained machine learning models are known to perpetuate and even amplify\nexisting biases in data, which can result in unfair outcomes that ultimately\nimpact user experience. Therefore, it is crucial to understand the mechanisms\nbehind those prejudicial biases to ensure that model performance does not\nresult in discriminatory behaviour toward certain groups or populations. In\nthis work, we define gender bias as our case study. We quantify bias\namplification in pretraining and after fine-tuning on three families of\nvision-and-language models. We investigate the connection, if any, between the\ntwo learning stages, and evaluate how bias amplification reflects on model\nperformance. Overall, we find that bias amplification in pretraining and after\nfine-tuning are independent. We then examine the effect of continued\npretraining on gender-neutral data, finding that this reduces group\ndisparities, i.e., promotes fairness, on VQAv2 and retrieval tasks without\nsignificantly compromising task performance.",
          "link": "http://arxiv.org/abs/2310.17530",
          "publishedOn": "2023-10-28T00:41:30.032Z",
          "wordCount": null,
          "title": "Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models. (arXiv:2310.17530v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eisenmann_L/0/1/0/all/0/1\">Lukas Eisenmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monfared_Z/0/1/0/all/0/1\">Zahra Monfared</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goring_N/0/1/0/all/0/1\">Niclas Alexander G&#xf6;ring</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durstewitz_D/0/1/0/all/0/1\">Daniel Durstewitz</a>",
          "description": "Recurrent neural networks (RNNs) are popular machine learning tools for\nmodeling and forecasting sequential data and for inferring dynamical systems\n(DS) from observed time series. Concepts from DS theory (DST) have variously\nbeen used to further our understanding of both, how trained RNNs solve complex\ntasks, and the training process itself. Bifurcations are particularly important\nphenomena in DS, including RNNs, that refer to topological (qualitative)\nchanges in a system's dynamical behavior as one or more of its parameters are\nvaried. Knowing the bifurcation structure of an RNN will thus allow to deduce\nmany of its computational and dynamical properties, like its sensitivity to\nparameter variations or its behavior during training. In particular,\nbifurcations may account for sudden loss jumps observed in RNN training that\ncould severely impede the training process. Here we first mathematically prove\nfor a particular class of ReLU-based RNNs that certain bifurcations are indeed\nassociated with loss gradients tending toward infinity or zero. We then\nintroduce a novel heuristic algorithm for detecting all fixed points and\nk-cycles in ReLU-based RNNs and their existence and stability regions, hence\nbifurcation manifolds in parameter space. In contrast to previous numerical\nalgorithms for finding fixed points and common continuation methods, our\nalgorithm provides exact results and returns fixed points and cycles up to high\norders with surprisingly good scaling behavior. We exemplify the algorithm on\nthe analysis of the training process of RNNs, and find that the recently\nintroduced technique of generalized teacher forcing completely avoids certain\ntypes of bifurcations in training. Thus, besides facilitating the DST analysis\nof trained RNNs, our algorithm provides a powerful instrument for analyzing the\ntraining process itself.",
          "link": "http://arxiv.org/abs/2310.17561",
          "publishedOn": "2023-10-28T00:41:30.032Z",
          "wordCount": null,
          "title": "Bifurcations and loss jumps in RNN training. (arXiv:2310.17561v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.08951",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chengmin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>",
          "description": "When perceiving the world from multiple viewpoints, humans have the ability\nto reason about the complete objects in a compositional manner even when an\nobject is completely occluded from certain viewpoints. Meanwhile, humans are\nable to imagine novel views after observing multiple viewpoints. Recent\nremarkable advances in multi-view object-centric learning still leaves some\nunresolved problems: 1) The shapes of partially or completely occluded objects\ncan not be well reconstructed. 2) The novel viewpoint prediction depends on\nexpensive viewpoint annotations rather than implicit rules in view\nrepresentations. In this paper, we introduce a time-conditioned generative\nmodel for videos. To reconstruct the complete shape of an object accurately, we\nenhance the disentanglement between the latent representations of objects and\nviews, where the latent representations of time-conditioned views are jointly\ninferred with a Transformer and then are input to a sequential extension of\nSlot Attention to learn object-centric representations. In addition, Gaussian\nprocesses are employed as priors of view latent variables for video generation\nand novel-view prediction without viewpoint annotations. Experiments on\nmultiple datasets demonstrate that the proposed model can make object-centric\nvideo decomposition, reconstruct the complete shapes of occluded objects, and\nmake novel-view predictions.",
          "link": "http://arxiv.org/abs/2301.08951",
          "publishedOn": "2023-10-28T00:41:30.032Z",
          "wordCount": null,
          "title": "Time-Conditioned Generative Modeling of Object-Centric Representations for Video Decomposition and Prediction. (arXiv:2301.08951v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.11588",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Inatsu_Y/0/1/0/all/0/1\">Yu Inatsu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeno_S/0/1/0/all/0/1\">Shion Takeno</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanada_H/0/1/0/all/0/1\">Hiroyuki Hanada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iwata_K/0/1/0/all/0/1\">Kazuki Iwata</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1\">Ichiro Takeuchi</a>",
          "description": "In this study, we propose a novel multi-objective Bayesian optimization\n(MOBO) method to efficiently identify the Pareto front (PF) defined by risk\nmeasures for black-box functions under the presence of input uncertainty (IU).\nExisting BO methods for Pareto optimization in the presence of IU are\nrisk-specific or without theoretical guarantees, whereas our proposed method\naddresses general risk measures and has theoretical guarantees. The basic idea\nof the proposed method is to assume a Gaussian process (GP) model for the\nblack-box function and to construct high-probability bounding boxes for the\nrisk measures using the GP model. Furthermore, in order to reduce the\nuncertainty of non-dominated bounding boxes, we propose a method of selecting\nthe next evaluation point using a maximin distance defined by the maximum value\nof a quasi distance based on bounding boxes. As theoretical analysis, we prove\nthat the algorithm can return an arbitrary-accurate solution in a finite number\nof iterations with high probability, for various risk measures such as Bayes\nrisk, worst-case risk, and value-at-risk. We also give a theoretical analysis\nthat takes into account approximation errors because there exist non-negligible\napproximation errors (e.g., finite approximation of PFs and sampling-based\napproximation of bounding boxes) in practice. We confirm that the proposed\nmethod outperforms compared with existing methods not only in the setting with\nIU but also in the setting of ordinary MOBO through numerical experiments.",
          "link": "http://arxiv.org/abs/2301.11588",
          "publishedOn": "2023-10-28T00:41:30.031Z",
          "wordCount": null,
          "title": "Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under Input Uncertainty. (arXiv:2301.11588v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zaman_F/0/1/0/all/0/1\">Fahim Ahmed Zaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaodong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weiyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonka_M/0/1/0/all/0/1\">Milan Sonka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mudumbai_R/0/1/0/all/0/1\">Raghuraman Mudumbai</a>",
          "description": "We describe a method for verifying the output of a deep neural network for\nmedical image segmentation that is robust to several classes of random as well\nas worst-case perturbations i.e. adversarial attacks. This method is based on a\ngeneral approach recently developed by the authors called ``Trust, but Verify\"\nwherein an auxiliary verification network produces predictions about certain\nmasked features in the input image using the segmentation as an input. A\nwell-designed auxiliary network will produce high-quality predictions when the\ninput segmentations are accurate, but will produce low-quality predictions when\nthe segmentations are incorrect. Checking the predictions of such a network\nwith the original image allows us to detect bad segmentations. However, to\nensure the verification method is truly robust, we need a method for checking\nthe quality of the predictions that does not itself rely on a black-box neural\nnetwork. Indeed, we show that previous methods for segmentation evaluation that\ndo use deep neural regression networks are vulnerable to false negatives i.e.\ncan inaccurately label bad segmentations as good. We describe the design of a\nverification network that avoids such vulnerability and present results to\ndemonstrate its robustness compared to previous methods.",
          "link": "http://arxiv.org/abs/2310.16999",
          "publishedOn": "2023-10-28T00:41:29.989Z",
          "wordCount": null,
          "title": "Trust, but Verify: Robust Image Segmentation using Deep Learning. (arXiv:2310.16999v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17467",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ambrogioni_L/0/1/0/all/0/1\">Luca Ambrogioni</a>",
          "description": "Generative diffusion models have achieved spectacular performance in many\nareas of generative modeling. While the fundamental ideas behind these models\ncome from non-equilibrium physics, in this paper we show that many aspects of\nthese models can be understood using the tools of equilibrium statistical\nmechanics. Using this reformulation, we show that generative diffusion models\nundergo second-order phase transitions corresponding to symmetry breaking\nphenomena. We argue that this lead to a form of instability that lies at the\nheart of their generative capabilities and that can be described by a set of\nmean field critical exponents. We conclude by analyzing recent work connecting\ndiffusion models and associative memory networks in view of the thermodynamic\nformulations.",
          "link": "http://arxiv.org/abs/2310.17467",
          "publishedOn": "2023-10-28T00:41:29.989Z",
          "wordCount": null,
          "title": "The statistical thermodynamics of generative diffusion models. (arXiv:2310.17467v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Celis_L/0/1/0/all/0/1\">L. Elisa Celis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Amit Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehrotra_A/0/1/0/all/0/1\">Anay Mehrotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1\">Nisheeth K. Vishnoi</a>",
          "description": "Biases with respect to socially-salient attributes of individuals have been\nwell documented in evaluation processes used in settings such as admissions and\nhiring. We view such an evaluation process as a transformation of a\ndistribution of the true utility of an individual for a task to an observed\ndistribution and model it as a solution to a loss minimization problem subject\nto an information constraint. Our model has two parameters that have been\nidentified as factors leading to biases: the resource-information trade-off\nparameter in the information constraint and the risk-averseness parameter in\nthe loss function. We characterize the distributions that arise from our model\nand study the effect of the parameters on the observed distribution. The\noutputs of our model enrich the class of distributions that can be used to\ncapture variation across groups in the observed evaluations. We empirically\nvalidate our model by fitting real-world datasets and use it to study the\neffect of interventions in a downstream selection task. These results\ncontribute to an understanding of the emergence of bias in evaluation processes\nand provide tools to guide the deployment of interventions to mitigate biases.",
          "link": "http://arxiv.org/abs/2310.17489",
          "publishedOn": "2023-10-28T00:41:29.989Z",
          "wordCount": null,
          "title": "Bias in Evaluation Processes: An Optimization-Based Model. (arXiv:2310.17489v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kearney_L/0/1/0/all/0/1\">Logan Kearney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhowmik_D/0/1/0/all/0/1\">Debsindhu Bhowmik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_Z/0/1/0/all/0/1\">Zachary Fox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naskar_A/0/1/0/all/0/1\">Amit K. Naskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gounley_J/0/1/0/all/0/1\">John Gounley</a>",
          "description": "Transformer-based large language models have remarkable potential to\naccelerate design optimization for applications such as drug development and\nmaterials discovery. Self-supervised pretraining of transformer models requires\nlarge-scale datasets, which are often sparsely populated in topical areas such\nas polymer science. State-of-the-art approaches for polymers conduct data\naugmentation to generate additional samples but unavoidably incurs extra\ncomputational costs. In contrast, large-scale open-source datasets are\navailable for small molecules and provide a potential solution to data scarcity\nthrough transfer learning. In this work, we show that using transformers\npretrained on small molecules and fine-tuned on polymer properties achieve\ncomparable accuracy to those trained on augmented polymer datasets for a series\nof benchmark prediction tasks.",
          "link": "http://arxiv.org/abs/2310.16958",
          "publishedOn": "2023-10-28T00:41:29.988Z",
          "wordCount": null,
          "title": "Transferring a molecular foundation model for polymer property predictions. (arXiv:2310.16958v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yufei Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Felix Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>",
          "description": "Large language models (LLMs) such as GPT-3 have demonstrated a strong\ncapability to generate coherent and contextually relevant text. However, amidst\ntheir successes, a crucial issue persists: their generated outputs still lack\ncommonsense at times. Moreover, fine-tuning the entire LLM towards more\ncommonsensical outputs is computationally expensive if not infeasible. In this\npaper, we present a computation-efficient framework that steers a frozen\nPre-Trained Language Model (PTLM) towards more commonsensical generation (i.e.,\nproducing a plausible output that incorporates a list of concepts in a\nmeaningful way). Specifically, we first construct a reference-free evaluator\nthat assigns a sentence with a commonsensical score by grounding the sentence\nto a dynamic commonsense knowledge base from four different relational aspects.\nWe then use the scorer as the oracle for commonsense knowledge, and extend the\ncontrollable generation method called NADO to train an auxiliary head that\nguides a fixed PTLM to better satisfy the oracle. We test our framework on a\nseries of GPT-2-, Flan-T5-, and Alpaca-based language models (LMs) on two\nconstrained concept-to-sentence benchmarks. Human evaluation results\ndemonstrate that our method consistently leads to the most commonsensical\noutputs.",
          "link": "http://arxiv.org/abs/2310.17054",
          "publishedOn": "2023-10-28T00:41:29.988Z",
          "wordCount": null,
          "title": "BOOST: Harnessing Black-Box Control to Boost Commonsense in LMs' Generation. (arXiv:2310.17054v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17114",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mazumder_R/0/1/0/all/0/1\">Rahul Mazumder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_H/0/1/0/all/0/1\">Haoyue Wang</a>",
          "description": "The decision tree is a flexible machine learning model that finds its success\nin numerous applications. It is usually fitted in a recursively greedy manner\nusing CART. In this paper, we investigate the convergence rate of CART under a\nregression setting. First, we establish an upper bound on the prediction error\nof CART under a sufficient impurity decrease (SID) condition\n\\cite{chi2022asymptotic} -- our result improves upon the known result by\n\\cite{chi2022asymptotic} under a similar assumption. Furthermore, we provide\nexamples that demonstrate the error bound cannot be further improved by more\nthan a constant or a logarithmic factor. Second, we introduce a set of easily\nverifiable sufficient conditions for the SID condition. Specifically, we\ndemonstrate that the SID condition can be satisfied in the case of an additive\nmodel, provided that the component functions adhere to a ``locally reverse\nPoincar{\\'e} inequality\". We discuss several well-known function classes in\nnon-parametric estimation to illustrate the practical utility of this concept.",
          "link": "http://arxiv.org/abs/2310.17114",
          "publishedOn": "2023-10-28T00:41:29.988Z",
          "wordCount": null,
          "title": "On the Convergence of CART under Sufficient Impurity Decrease Condition. (arXiv:2310.17114v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01551",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blanc_G/0/1/0/all/0/1\">Guy Blanc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lange_J/0/1/0/all/0/1\">Jane Lange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pabbaraju_C/0/1/0/all/0/1\">Chirag Pabbaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sullivan_C/0/1/0/all/0/1\">Colin Sullivan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1\">Li-Yang Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_M/0/1/0/all/0/1\">Mo Tiwari</a>",
          "description": "We propose a simple generalization of standard and empirically successful\ndecision tree learning algorithms such as ID3, C4.5, and CART. These\nalgorithms, which have been central to machine learning for decades, are greedy\nin nature: they grow a decision tree by iteratively splitting on the best\nattribute. Our algorithm, Top-$k$, considers the $k$ best attributes as\npossible splits instead of just the single best attribute. We demonstrate,\ntheoretically and empirically, the power of this simple generalization. We\nfirst prove a {\\sl greediness hierarchy theorem} showing that for every $k \\in\n\\mathbb{N}$, Top-$(k+1)$ can be dramatically more powerful than Top-$k$: there\nare data distributions for which the former achieves accuracy $1-\\varepsilon$,\nwhereas the latter only achieves accuracy $\\frac1{2}+\\varepsilon$. We then\nshow, through extensive experiments, that Top-$k$ outperforms the two main\napproaches to decision tree learning: classic greedy algorithms and more recent\n\"optimal decision tree\" algorithms. On one hand, Top-$k$ consistently enjoys\nsignificant accuracy gains over greedy algorithms across a wide range of\nbenchmarks. On the other hand, Top-$k$ is markedly more scalable than optimal\ndecision tree algorithms and is able to handle dataset and feature set sizes\nthat remain far beyond the reach of these algorithms.",
          "link": "http://arxiv.org/abs/2310.01551",
          "publishedOn": "2023-10-28T00:41:29.988Z",
          "wordCount": null,
          "title": "Harnessing the Power of Choices in Decision Tree Learning. (arXiv:2310.01551v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inan_H/0/1/0/all/0/1\">Huseyin A. Inan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backurs_A/0/1/0/all/0/1\">Arturs Backurs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrasekaran_V/0/1/0/all/0/1\">Varun Chandrasekaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1\">Janardhan Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1\">Robert Sim</a>",
          "description": "Positioned between pre-training and user deployment, aligning large language\nmodels (LLMs) through reinforcement learning (RL) has emerged as a prevailing\nstrategy for training instruction following-models such as ChatGPT. In this\nwork, we initiate the study of privacy-preserving alignment of LLMs through\nDifferential Privacy (DP) in conjunction with RL. Following the influential\nwork of Ziegler et al. (2020), we study two dominant paradigms: (i) alignment\nvia RL without human in the loop (e.g., positive review generation) and (ii)\nalignment via RL from human feedback (RLHF) (e.g., summarization in a\nhuman-preferred way). We give a new DP framework to achieve alignment via RL,\nand prove its correctness. Our experimental results validate the effectiveness\nof our approach, offering competitive utility while ensuring strong privacy\nprotections.",
          "link": "http://arxiv.org/abs/2310.16960",
          "publishedOn": "2023-10-28T00:41:29.987Z",
          "wordCount": null,
          "title": "Privately Aligning Language Models with Reinforcement Learning. (arXiv:2310.16960v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zixin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Si Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxin Chen</a>",
          "description": "Active learning is a promising paradigm to reduce the labeling cost by\nstrategically requesting labels to improve model performance. However, existing\nactive learning methods often rely on expensive acquisition function to\ncompute, extensive modeling retraining and multiple rounds of interaction with\nannotators. To address these limitations, we propose a novel approach for\nactive learning, which aims to select batches of unlabeled instances through a\nlearned surrogate model for data acquisition. A key challenge in this approach\nis developing an acquisition function that generalizes well, as the history of\ndata, which forms part of the utility function's input, grows over time. Our\nnovel algorithmic contribution is a bilevel multi-task bilevel optimization\nframework that predicts the relative utility -- measured by the validation\naccuracy -- of different training sets, and ensures the learned acquisition\nfunction generalizes effectively. For cases where validation accuracy is\nexpensive to evaluate, we introduce efficient interpolation-based surrogate\nmodels to estimate the utility function, reducing the evaluation cost. We\ndemonstrate the performance of our approach through extensive experiments on\nstandard active classification benchmarks. By employing our learned utility\nfunction, we show significant improvements over traditional techniques, paving\nthe way for more efficient and effective utility maximization in active\nlearning applications.",
          "link": "http://arxiv.org/abs/2310.17044",
          "publishedOn": "2023-10-28T00:41:29.987Z",
          "wordCount": null,
          "title": "Learning to Rank for Active Learning via Multi-Task Bilevel Optimization. (arXiv:2310.17044v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17056",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mohammadi_M/0/1/0/all/0/1\">Mohammad Mohammadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thornburg_J/0/1/0/all/0/1\">Jesse Thornburg</a>",
          "description": "Exploring the convergence of electric vehicles (EVs), renewable energy, and\nsmart grid technologies in the context of Texas, this study addresses\nchallenges hindering the widespread adoption of EVs. Acknowledging their\nenvironmental benefits, the research focuses on grid stability concerns,\nuncoordinated charging patterns, and the complicated relationship between EVs\nand renewable energy sources. Dynamic time warping (DTW) clustering and k-means\nclustering methodologies categorize days based on total load and net load,\noffering nuanced insights into daily electricity consumption and renewable\nenergy generation patterns. By establishing optimal charging and\nvehicle-to-grid (V2G) windows tailored to specific load characteristics, the\nstudy provides a sophisticated methodology for strategic decision-making in\nenergy consumption and renewable integration. The findings contribute to the\nongoing discourse on achieving a sustainable and resilient energy future\nthrough the seamless integration of EVs into smart grids.",
          "link": "http://arxiv.org/abs/2310.17056",
          "publishedOn": "2023-10-28T00:41:29.987Z",
          "wordCount": null,
          "title": "Strategizing EV Charging and Renewable Integration in Texas. (arXiv:2310.17056v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yonghyeon Lee</a>",
          "description": "The Motion Manifold Primitive (MMP) produces, for a given task, a continuous\nmanifold of trajectories each of which can successfully complete the task. It\nconsists of the decoder function that parametrizes the manifold and the\nprobability density in the latent coordinate space. In this paper, we first\nshow that the MMP performance can significantly degrade due to the geometric\ndistortion in the latent space -- by distortion, we mean that similar motions\nare not located nearby in the latent space. We then propose {\\it Isometric\nMotion Manifold Primitives (IMMP)} whose latent coordinate space preserves the\ngeometry of the manifold. For this purpose, we formulate and use a Riemannian\nmetric for the motion space (i.e., parametric curve space), which we call a\n{\\it CurveGeom Riemannian metric}. Experiments with planar obstacle-avoiding\nmotions and pushing manipulation tasks show that IMMP significantly outperforms\nexisting MMP methods. Code is available at\nhttps://github.com/Gabe-YHLee/IMMP-public.",
          "link": "http://arxiv.org/abs/2310.17072",
          "publishedOn": "2023-10-28T00:41:29.987Z",
          "wordCount": null,
          "title": "Isometric Motion Manifold Primitives. (arXiv:2310.17072v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1\">Deqing Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tian-Qi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharan_V/0/1/0/all/0/1\">Vatsal Sharan</a>",
          "description": "Transformers are remarkably good at in-context learning (ICL) -- learning\nfrom demonstrations without parameter updates -- but how they perform ICL\nremains a mystery. Recent work suggests that Transformers may learn in-context\nby internally running Gradient Descent, a first-order optimization method. In\nthis paper, we instead demonstrate that Transformers learn to implement\nhigher-order optimization methods to perform ICL. Focusing on in-context linear\nregression, we show that Transformers learn to implement an algorithm very\nsimilar to Iterative Newton's Method, a higher-order optimization method,\nrather than Gradient Descent. Empirically, we show that predictions from\nsuccessive Transformer layers closely match different iterations of Newton's\nMethod linearly, with each middle layer roughly computing 3 iterations. In\ncontrast, exponentially more Gradient Descent steps are needed to match an\nadditional Transformers layer; this suggests that Transformers have an\ncomparable rate of convergence with high-order methods such as Iterative\nNewton, which are exponentially faster than Gradient Descent. We also show that\nTransformers can learn in-context on ill-conditioned data, a setting where\nGradient Descent struggles but Iterative Newton succeeds. Finally, we show\ntheoretical results which support our empirical findings and have a close\ncorrespondence with them: we prove that Transformers can implement $k$\niterations of Newton's method with $\\mathcal{O}(k)$ layers.",
          "link": "http://arxiv.org/abs/2310.17086",
          "publishedOn": "2023-10-28T00:41:29.987Z",
          "wordCount": null,
          "title": "Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models. (arXiv:2310.17086v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16975",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Zheyu Oliver Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baptista_R/0/1/0/all/0/1\">Ricardo Baptista</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marzouk_Y/0/1/0/all/0/1\">Youssef Marzouk</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ruthotto_L/0/1/0/all/0/1\">Lars Ruthotto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Verma_D/0/1/0/all/0/1\">Deepanshu Verma</a>",
          "description": "We present two neural network approaches that approximate the solutions of\nstatic and dynamic conditional optimal transport (COT) problems, respectively.\nBoth approaches enable sampling and density estimation of conditional\nprobability distributions, which are core tasks in Bayesian inference. Our\nmethods represent the target conditional distributions as transformations of a\ntractable reference distribution and, therefore, fall into the framework of\nmeasure transport. COT maps are a canonical choice within this framework, with\ndesirable properties such as uniqueness and monotonicity. However, the\nassociated COT problems are computationally challenging, even in moderate\ndimensions. To improve the scalability, our numerical algorithms leverage\nneural networks to parameterize COT maps. Our methods exploit the structure of\nthe static and dynamic formulations of the COT problem. PCP-Map models\nconditional transport maps as the gradient of a partially input convex neural\nnetwork (PICNN) and uses a novel numerical implementation to increase\ncomputational efficiency compared to state-of-the-art alternatives. COT-Flow\nmodels conditional transports via the flow of a regularized neural ODE; it is\nslower to train but offers faster sampling. We demonstrate their effectiveness\nand efficiency by comparing them with state-of-the-art approaches using\nbenchmark datasets and Bayesian inverse problems.",
          "link": "http://arxiv.org/abs/2310.16975",
          "publishedOn": "2023-10-28T00:41:29.986Z",
          "wordCount": null,
          "title": "Efficient Neural Network Approaches for Conditional Optimal Transport with Applications in Bayesian Inference. (arXiv:2310.16975v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hansen_L/0/1/0/all/0/1\">Lasse Hansen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seedat_N/0/1/0/all/0/1\">Nabeel Seedat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrovic_A/0/1/0/all/0/1\">Andrija Petrovic</a>",
          "description": "Synthetic data serves as an alternative in training machine learning models,\nparticularly when real-world data is limited or inaccessible. However, ensuring\nthat synthetic data mirrors the complex nuances of real-world data is a\nchallenging task. This paper addresses this issue by exploring the potential of\nintegrating data-centric AI techniques which profile the data to guide the\nsynthetic data generation process. Moreover, we shed light on the often ignored\nconsequences of neglecting these data profiles during synthetic data generation\n-- despite seemingly high statistical fidelity. Subsequently, we propose a\nnovel framework to evaluate the integration of data profiles to guide the\ncreation of more representative synthetic data. In an empirical study, we\nevaluate the performance of five state-of-the-art models for tabular data\ngeneration on eleven distinct tabular datasets. The findings offer critical\ninsights into the successes and limitations of current synthetic data\ngeneration techniques. Finally, we provide practical recommendations for\nintegrating data-centric insights into the synthetic data generation process,\nwith a specific focus on classification performance, model selection, and\nfeature selection. This study aims to reevaluate conventional approaches to\nsynthetic data generation and promote the application of data-centric AI\ntechniques in improving the quality and effectiveness of synthetic data.",
          "link": "http://arxiv.org/abs/2310.16981",
          "publishedOn": "2023-10-28T00:41:29.986Z",
          "wordCount": null,
          "title": "Reimagining Synthetic Tabular Data Generation through Data-Centric AI: A Comprehensive Benchmark. (arXiv:2310.16981v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zentner_K/0/1/0/all/0/1\">K.R. Zentner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Julian_R/0/1/0/all/0/1\">Ryan Julian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichter_B/0/1/0/all/0/1\">Brian Ichter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1\">Gaurav S. Sukhatme</a>",
          "description": "This paper combines two contributions. First, we introduce an extension of\nthe Meta-World benchmark, which we call \"Language-World,\" which allows a large\nlanguage model to operate in a simulated robotic environment using\nsemi-structured natural language queries and scripted skills described using\nnatural language. By using the same set of tasks as Meta-World, Language-World\nresults can be easily compared to Meta-World results, allowing for a point of\ncomparison between recent methods using Large Language Models (LLMs) and those\nusing Deep Reinforcement Learning. Second, we introduce a method we call Plan\nConditioned Behavioral Cloning (PCBC), that allows finetuning the behavior of\nhigh-level plans using end-to-end demonstrations. Using Language-World, we show\nthat PCBC is able to achieve strong performance in a variety of few-shot\nregimes, often achieving task generalization with as little as a single\ndemonstration. We have made Language-World available as open-source software at\nhttps://github.com/krzentner/language-world/.",
          "link": "http://arxiv.org/abs/2310.17019",
          "publishedOn": "2023-10-28T00:41:29.986Z",
          "wordCount": null,
          "title": "Conditionally Combining Robot Skills using Large Language Models. (arXiv:2310.17019v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1\">Shikai Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shibo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirby_R/0/1/0/all/0/1\">Robert Kirby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhe_S/0/1/0/all/0/1\">Shandian Zhe</a>",
          "description": "Practical tensor data is often along with time information. Most existing\ntemporal decomposition approaches estimate a set of fixed factors for the\nobjects in each tensor mode, and hence cannot capture the temporal evolution of\nthe objects' representation. More important, we lack an effective approach to\ncapture such evolution from streaming data, which is common in real-world\napplications. To address these issues, we propose Streaming Factor Trajectory\nLearning (SFTL) for temporal tensor decomposition. We use Gaussian processes\n(GPs) to model the trajectory of factors so as to flexibly estimate their\ntemporal evolution. To address the computational challenges in handling\nstreaming data, we convert the GPs into a state-space prior by constructing an\nequivalent stochastic differential equation (SDE). We develop an efficient\nonline filtering algorithm to estimate a decoupled running posterior of the\ninvolved factor states upon receiving new data. The decoupled estimation\nenables us to conduct standard Rauch-Tung-Striebel smoothing to compute the\nfull posterior of all the trajectories in parallel, without the need for\nrevisiting any previous data. We have shown the advantage of SFTL in both\nsynthetic tasks and real-world applications.",
          "link": "http://arxiv.org/abs/2310.17021",
          "publishedOn": "2023-10-28T00:41:29.985Z",
          "wordCount": null,
          "title": "Streaming Factor Trajectory Learning for Temporal Tensor Decomposition. (arXiv:2310.17021v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.14251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingbo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mengmeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guanbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Ziyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junfan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Liang Lin</a>",
          "description": "Accurate inference of fine-grained traffic flow from coarse-grained one is an\nemerging yet crucial problem, which can help greatly reduce the number of the\nrequired traffic monitoring sensors for cost savings. In this work, we notice\nthat traffic flow has a high correlation with road network, which was either\ncompletely ignored or simply treated as an external factor in previous works.\nTo facilitate this problem, we propose a novel Road-Aware Traffic Flow\nMagnifier (RATFM) that explicitly exploits the prior knowledge of road networks\nto fully learn the road-aware spatial distribution of fine-grained traffic\nflow. Specifically, a multi-directional 1D convolutional layer is first\nintroduced to extract the semantic feature of the road network. Subsequently,\nwe incorporate the road network feature and coarse-grained flow feature to\nregularize the short-range spatial distribution modeling of road-relative\ntraffic flow. Furthermore, we take the road network feature as a query to\ncapture the long-range spatial distribution of traffic flow with a transformer\narchitecture. Benefiting from the road-aware inference mechanism, our method\ncan generate high-quality fine-grained traffic flow maps. Extensive experiments\non three real-world datasets show that the proposed RATFM outperforms\nstate-of-the-art models under various scenarios. Our code and datasets are\nreleased at {\\url{https://github.com/luimoli/RATFM}}.",
          "link": "http://arxiv.org/abs/2109.14251",
          "publishedOn": "2023-10-28T00:41:29.985Z",
          "wordCount": null,
          "title": "Road Network Guided Fine-Grained Urban Traffic Flow Inference. (arXiv:2109.14251v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19470",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scott_C/0/1/0/all/0/1\">Clayton Scott</a>",
          "description": "Label embedding is a framework for multiclass classification problems where\neach label is represented by a distinct vector of some fixed dimension, and\ntraining involves matching model output to the vector representing the correct\nlabel. While label embedding has been successfully applied in extreme\nclassification and zero-shot learning, and offers both computational and\nstatistical advantages, its theoretical foundations remain poorly understood.\nThis work presents an analysis of label embedding in the context of extreme\nmulticlass classification, where the number of classes $C$ is very large. We\npresent an excess risk bound that reveals a trade-off between computational and\nstatistical efficiency, quantified via the coherence of the embedding matrix.\nWe further show that under the Massart noise condition, the statistical penalty\nfor label embedding vanishes with sufficiently low coherence. Our analysis\nsupports an algorithm that is simple, scalable, and easily parallelizable, and\nexperimental results demonstrate its effectiveness in large-scale applications.",
          "link": "http://arxiv.org/abs/2305.19470",
          "publishedOn": "2023-10-28T00:41:29.985Z",
          "wordCount": null,
          "title": "Label Embedding via Low-Coherence Matrices. (arXiv:2305.19470v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mudgal_S/0/1/0/all/0/1\">Sidharth Mudgal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganapathy_H/0/1/0/all/0/1\">Harish Ganapathy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">YaGuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yanping Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Tze Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collins_M/0/1/0/all/0/1\">Michael Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strohman_T/0/1/0/all/0/1\">Trevor Strohman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1\">Alex Beutel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>",
          "description": "We propose controlled decoding (CD), a novel off-policy reinforcement\nlearning method to control the autoregressive generation from language models\ntowards high reward outcomes. CD solves an off-policy reinforcement learning\nproblem through a value function for the reward, which we call a prefix scorer.\nThe prefix scorer is used at inference time to steer the generation towards\nhigher reward outcomes. We show that the prefix scorer may be trained on\n(possibly) off-policy data to predict the expected reward when decoding is\ncontinued from a partially decoded response. We empirically demonstrate that CD\nis effective as a control mechanism on Reddit conversations corpus. We also\nshow that the modularity of the design of CD makes it possible to control for\nmultiple rewards, effectively solving a multi-objective reinforcement learning\nproblem with no additional complexity. Finally, we show that CD can be applied\nin a novel blockwise fashion at inference-time, again without the need for any\ntraining-time changes, essentially bridging the gap between the popular\nbest-of-$K$ strategy and token-level reinforcement learning. This makes CD a\npromising approach for alignment of language models.",
          "link": "http://arxiv.org/abs/2310.17022",
          "publishedOn": "2023-10-28T00:41:29.984Z",
          "wordCount": null,
          "title": "Controlled Decoding from Language Models. (arXiv:2310.17022v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Gene-Ping Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hao Tang</a>",
          "description": "Learning phone types from phone instances has been a long-standing problem,\nwhile still being open. In this work, we revisit this problem in the context of\nself-supervised learning, and pose it as the problem of matching cluster\ncentroids to phone embeddings. We study two key properties that enable\nmatching, namely, whether cluster centroids of self-supervised representations\nreduce the variability of phone instances and respect the relationship among\nphones. We then use the matching result to produce pseudo-labels and introduce\na new loss function for improving self-supervised representations. Our\nexperiments show that the matching result captures the relationship among\nphones. Training the new loss function jointly with the regular self-supervised\nlosses, such as APC and CPC, significantly improves the downstream phone\nclassification.",
          "link": "http://arxiv.org/abs/2310.17558",
          "publishedOn": "2023-10-28T00:41:29.984Z",
          "wordCount": null,
          "title": "Towards Matching Phones and Speech Representations. (arXiv:2310.17558v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.04824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quenum_J/0/1/0/all/0/1\">Jerome Quenum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zenyuk_I/0/1/0/all/0/1\">Iryna Zenyuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ushizima_D/0/1/0/all/0/1\">Daniela Ushizima</a>",
          "description": "Lithium metal battery (LMB) has the potential to be the next-generation\nbattery system because of its high theoretical energy density. However, defects\nknown as dendrites are formed by heterogeneous lithium (Li) plating, which\nhinders the development and utilization of LMBs. Non-destructive techniques to\nobserve the dendrite morphology often use X-ray computed tomography (XCT) to\nprovide cross-sectional views. To retrieve three-dimensional structures inside\na battery, image segmentation becomes essential to quantitatively analyze XCT\nimages. This work proposes a new semantic segmentation approach using a\ntransformer-based neural network called TransforCNN that is capable of\nsegmenting out dendrites from XCT data. In addition, we compare the performance\nof the proposed TransforCNN with three other algorithms, such as U-Net, Y-Net,\nand E-Net, consisting of an Ensemble Network model for XCT analysis. Our\nresults show the advantages of using TransforCNN when evaluating\nover-segmentation metrics, such as mean Intersection over Union (mIoU) and mean\nDice Similarity Coefficient (mDSC) as well as through several qualitatively\ncomparative visualizations.",
          "link": "http://arxiv.org/abs/2302.04824",
          "publishedOn": "2023-10-28T00:41:29.984Z",
          "wordCount": null,
          "title": "Lithium Metal Battery Quality Control via Transformer-CNN Segmentation. (arXiv:2302.04824v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chamma_A/0/1/0/all/0/1\">Ahmad Chamma</a> (1 and 2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Engemann_D/0/1/0/all/0/1\">Denis A. Engemann</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Thirion_B/0/1/0/all/0/1\">Bertrand Thirion</a> (1 and 2 and 3) ((1) Inria, (2) Universite Paris Saclay, (3) CEA, (4) Roche Pharma Research and Early Development, Neuroscience and Rare Diseases, Roche Innovation Center Basel, F. Hoffmann-La Roche Ltd., Basel, Switzerland)",
          "description": "Variable importance assessment has become a crucial step in machine-learning\napplications when using complex learners, such as deep neural networks, on\nlarge-scale data. Removal-based importance assessment is currently the\nreference approach, particularly when statistical guarantees are sought to\njustify variable inclusion. It is often implemented with variable permutation\nschemes. On the flip side, these approaches risk misidentifying unimportant\nvariables as important in the presence of correlations among covariates. Here\nwe develop a systematic approach for studying Conditional Permutation\nImportance (CPI) that is model agnostic and computationally lean, as well as\nreusable benchmarks of state-of-the-art variable importance estimators. We show\ntheoretically and empirically that $\\textit{CPI}$ overcomes the limitations of\nstandard permutation importance by providing accurate type-I error control.\nWhen used with a deep neural network, $\\textit{CPI}$ consistently showed top\naccuracy across benchmarks. An experiment on real-world data analysis in a\nlarge-scale medical dataset showed that $\\textit{CPI}$ provides a more\nparsimonious selection of statistically significant variables. Our results\nsuggest that $\\textit{CPI}$ can be readily used as drop-in replacement for\npermutation-based methods.",
          "link": "http://arxiv.org/abs/2309.07593",
          "publishedOn": "2023-10-28T00:41:29.984Z",
          "wordCount": null,
          "title": "Statistically Valid Variable Importance Assessment through Conditional Permutations. (arXiv:2309.07593v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adachi_M/0/1/0/all/0/1\">Masaki Adachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Planden_B/0/1/0/all/0/1\">Brady Planden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howey_D/0/1/0/all/0/1\">David A. Howey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maundet_K/0/1/0/all/0/1\">Krikamol Maundet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osborne_M/0/1/0/all/0/1\">Michael A. Osborne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_S/0/1/0/all/0/1\">Siu Lun Chau</a>",
          "description": "Like many optimizers, Bayesian optimization often falls short of gaining user\ntrust due to opacity. While attempts have been made to develop human-centric\noptimizers, they typically assume user knowledge is well-specified and\nerror-free, employing users mainly as supervisors of the optimization process.\nWe relax these assumptions and propose a more balanced human-AI partnership\nwith our Collaborative and Explainable Bayesian Optimization (CoExBO)\nframework. Instead of explicitly requiring a user to provide a knowledge model,\nCoExBO employs preference learning to seamlessly integrate human insights into\nthe optimization, resulting in algorithmic suggestions that resonate with user\npreference. CoExBO explains its candidate selection every iteration to foster\ntrust, empowering users with a clearer grasp of the optimization. Furthermore,\nCoExBO offers a no-harm guarantee, allowing users to make mistakes; even with\nextreme adversarial interventions, the algorithm converges asymptotically to a\nvanilla Bayesian optimization. We validate CoExBO's efficacy through human-AI\nteaming experiments in lithium-ion battery design, highlighting substantial\nimprovements over conventional methods.",
          "link": "http://arxiv.org/abs/2310.17273",
          "publishedOn": "2023-10-28T00:41:29.983Z",
          "wordCount": null,
          "title": "Looping in the Human: Collaborative and Explainable Bayesian Optimization. (arXiv:2310.17273v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Jaedong Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Z/0/1/0/all/0/1\">Zhang-Wei Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Eric Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boopathy_A/0/1/0/all/0/1\">Akhilan Boopathy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Pulkit Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fiete_I/0/1/0/all/0/1\">Ila Fiete</a>",
          "description": "Deep reinforcement learning methods exhibit impressive performance on a range\nof tasks but still struggle on hard exploration tasks in large environments\nwith sparse rewards. To address this, intrinsic rewards can be generated using\nforward model prediction errors that decrease as the environment becomes known,\nand incentivize an agent to explore novel states. While prediction-based\nintrinsic rewards can help agents solve hard exploration tasks, they can suffer\nfrom catastrophic forgetting and actually increase at visited states. We first\nexamine the conditions and causes of catastrophic forgetting in grid world\nenvironments. We then propose a new method FARCuriosity, inspired by how humans\nand animals learn. The method depends on fragmentation and recall: an agent\nfragments an environment based on surprisal, and uses different local curiosity\nmodules (prediction-based intrinsic reward functions) for each fragment so that\nmodules are not trained on the entire environment. At each fragmentation event,\nthe agent stores the current module in long-term memory (LTM) and either\ninitializes a new module or recalls a previously stored module based on its\nmatch with the current state. With fragmentation and recall, FARCuriosity\nachieves less forgetting and better overall performance in games with varied\nand heterogeneous environments in the Atari benchmark suite of tasks. Thus,\nthis work highlights the problem of catastrophic forgetting in prediction-based\ncuriosity methods and proposes a solution.",
          "link": "http://arxiv.org/abs/2310.17537",
          "publishedOn": "2023-10-28T00:41:29.983Z",
          "wordCount": null,
          "title": "Neuro-Inspired Fragmentation and Recall to Overcome Catastrophic Forgetting in Curiosity. (arXiv:2310.17537v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yixiao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Hao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Han Wang</a>",
          "description": "We propose a new algorithm for efficiently solving the damped Fisher matrix\nin large-scale scenarios where the number of parameters significantly exceeds\nthe number of available samples. This problem is fundamental for natural\ngradient descent and stochastic reconfiguration. Our algorithm is based on\nCholesky decomposition and is generally applicable. Benchmark results show that\nthe algorithm is significantly faster than existing methods.",
          "link": "http://arxiv.org/abs/2310.17556",
          "publishedOn": "2023-10-28T00:41:29.983Z",
          "wordCount": null,
          "title": "Efficient Numerical Algorithm for Large-Scale Damped Natural Gradient Descent. (arXiv:2310.17556v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_L/0/1/0/all/0/1\">Ling-Yu Duan</a>",
          "description": "Federated Learning (FL) is an emerging distributed learning paradigm under\nprivacy constraint. Data heterogeneity is one of the main challenges in FL,\nwhich results in slow convergence and degraded performance. Most existing\napproaches only tackle the heterogeneity challenge by restricting the local\nmodel update in client, ignoring the performance drop caused by direct global\nmodel aggregation. Instead, we propose a data-free knowledge distillation\nmethod to fine-tune the global model in the server (FedFTG), which relieves the\nissue of direct model aggregation. Concretely, FedFTG explores the input space\nof local models through a generator, and uses it to transfer the knowledge from\nlocal models to the global model. Besides, we propose a hard sample mining\nscheme to achieve effective knowledge distillation throughout the training. In\naddition, we develop customized label sampling and class-level ensemble to\nderive maximum utilization of knowledge, which implicitly mitigates the\ndistribution discrepancy across clients. Extensive experiments show that our\nFedFTG significantly outperforms the state-of-the-art (SOTA) FL algorithms and\ncan serve as a strong plugin for enhancing FedAvg, FedProx, FedDyn, and\nSCAFFOLD.",
          "link": "http://arxiv.org/abs/2203.09249",
          "publishedOn": "2023-10-28T00:41:29.983Z",
          "wordCount": null,
          "title": "Fine-tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning. (arXiv:2203.09249v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.04449",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yewen Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azaria_A/0/1/0/all/0/1\">Amos Azaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_T/0/1/0/all/0/1\">Tom M. Mitchell</a>",
          "description": "High sample complexity has long been a challenge for RL. On the other hand,\nhumans learn to perform tasks not only from interaction or demonstrations, but\nalso by reading unstructured text documents, e.g., instruction manuals.\nInstruction manuals and wiki pages are among the most abundant data that could\ninform agents of valuable features and policies or task-specific environmental\ndynamics and reward structures. Therefore, we hypothesize that the ability to\nutilize human-written instruction manuals to assist learning policies for\nspecific tasks should lead to a more efficient and better-performing agent. We\npropose the Read and Reward framework. Read and Reward speeds up RL algorithms\non Atari games by reading manuals released by the Atari game developers. Our\nframework consists of a QA Extraction module that extracts and summarizes\nrelevant information from the manual and a Reasoning module that evaluates\nobject-agent interactions based on information from the manual. An auxiliary\nreward is then provided to a standard A2C RL agent, when interaction is\ndetected. Experimentally, various RL algorithms obtain significant improvement\nin performance and training speed when assisted by our design.",
          "link": "http://arxiv.org/abs/2302.04449",
          "publishedOn": "2023-10-28T00:41:29.983Z",
          "wordCount": null,
          "title": "Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals. (arXiv:2302.04449v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suya_F/0/1/0/all/0/1\">Fnu Suya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suri_A/0/1/0/all/0/1\">Anshuman Suri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tingwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Jingtao Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_D/0/1/0/all/0/1\">David Evans</a>",
          "description": "Numerous works study black-box attacks on image classifiers. However, these\nworks make different assumptions on the adversary's knowledge and current\nliterature lacks a cohesive organization centered around the threat model. To\nsystematize knowledge in this area, we propose a taxonomy over the threat space\nspanning the axes of feedback granularity, the access of interactive queries,\nand the quality and quantity of the auxiliary data available to the attacker.\nOur new taxonomy provides three key insights. 1) Despite extensive literature,\nnumerous under-explored threat spaces exist, which cannot be trivially solved\nby adapting techniques from well-explored settings. We demonstrate this by\nestablishing a new state-of-the-art in the less-studied setting of access to\ntop-k confidence scores by adapting techniques from well-explored settings of\naccessing the complete confidence vector, but show how it still falls short of\nthe more restrictive setting that only obtains the prediction label,\nhighlighting the need for more research. 2) Identification the threat model of\ndifferent attacks uncovers stronger baselines that challenge prior\nstate-of-the-art claims. We demonstrate this by enhancing an initially weaker\nbaseline (under interactive query access) via surrogate models, effectively\noverturning claims in the respective paper. 3) Our taxonomy reveals\ninteractions between attacker knowledge that connect well to related areas,\nsuch as model inversion and extraction attacks. We discuss how advances in\nother areas can enable potentially stronger black-box attacks. Finally, we\nemphasize the need for a more realistic assessment of attack success by\nfactoring in local attack runtime. This approach reveals the potential for\ncertain attacks to achieve notably higher success rates and the need to\nevaluate attacks in diverse and harder settings, highlighting the need for\nbetter selection criteria.",
          "link": "http://arxiv.org/abs/2310.17534",
          "publishedOn": "2023-10-28T00:41:29.981Z",
          "wordCount": null,
          "title": "SoK: Pitfalls in Evaluating Black-Box Attacks. (arXiv:2310.17534v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Henry H.H. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiaming Lu</a>",
          "description": "The prevailing principle of \"Optimism in the Face of Uncertainty\" advocates\nfor the incorporation of an exploration bonus, generally assumed to be\nproportional to the inverse square root of the visit count ($1/\\sqrt{n}$),\nwhere $n$ is the number of visits to a particular state-action pair. This\napproach, however, exclusively focuses on \"uncertainty,\" neglecting the\ninherent \"difficulty\" of different options. To address this gap, we introduce a\nnovel modification of standard UCB algorithm in the multi-armed bandit problem,\nproposing an adjusted bonus term of $1/n^\\tau$, where $\\tau > 1/2$, that\naccounts for task difficulty. Our proposed algorithm, denoted as UCB$^\\tau$, is\nsubstantiated through comprehensive regret and risk analyses, confirming its\ntheoretical robustness. Comparative evaluations with standard UCB and Thompson\nSampling algorithms on synthetic datasets demonstrate that UCB$^\\tau$ not only\noutperforms in efficacy but also exhibits lower risk across various\nenvironmental conditions and hyperparameter settings.",
          "link": "http://arxiv.org/abs/2310.17538",
          "publishedOn": "2023-10-28T00:41:29.981Z",
          "wordCount": null,
          "title": "Little Exploration is All You Need. (arXiv:2310.17538v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17502",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lux_F/0/1/0/all/0/1\">Florian Lux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tilli_P/0/1/0/all/0/1\">Pascal Tilli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meyer_S/0/1/0/all/0/1\">Sarina Meyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1\">Ngoc Thang Vu</a>",
          "description": "Customizing voice and speaking style in a speech synthesis system with\nintuitive and fine-grained controls is challenging, given that little data with\nappropriate labels is available. Furthermore, editing an existing human's voice\nalso comes with ethical concerns. In this paper, we propose a method to\ngenerate artificial speaker embeddings that cannot be linked to a real human\nwhile offering intuitive and fine-grained control over the voice and speaking\nstyle of the embeddings, without requiring any labels for speaker or style. The\nartificial and controllable embeddings can be fed to a speech synthesis system,\nconditioned on embeddings of real humans during training, without sacrificing\nprivacy during inference.",
          "link": "http://arxiv.org/abs/2310.17502",
          "publishedOn": "2023-10-28T00:41:29.980Z",
          "wordCount": null,
          "title": "Controllable Generation of Artificial Speaker Embeddings through Discovery of Principal Directions. (arXiv:2310.17502v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.15890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aketi_S/0/1/0/all/0/1\">Sai Aparna Aketi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1\">Kaushik Roy</a>",
          "description": "The current state-of-the-art decentralized learning algorithms mostly assume\nthe data distribution to be Independent and Identically Distributed (IID).\nHowever, in practical scenarios, the distributed datasets can have\nsignificantly heterogeneous data distributions across the agents. In this work,\nwe present a novel approach for decentralized learning on heterogeneous data,\nwhere data-free knowledge distillation through contrastive loss on\ncross-features is utilized to improve performance. Cross-features for a pair of\nneighboring agents are the features (i.e., last hidden layer activations)\nobtained from the data of an agent with respect to the model parameters of the\nother agent. We demonstrate the effectiveness of the proposed technique through\nan exhaustive set of experiments on various Computer Vision datasets (CIFAR-10,\nCIFAR-100, Fashion MNIST, Imagenette, and ImageNet), model architectures, and\nnetwork topologies. Our experiments show that the proposed method achieves\nsuperior performance (0.2-4% improvement in test accuracy) compared to other\nexisting techniques for decentralized learning on heterogeneous data.",
          "link": "http://arxiv.org/abs/2310.15890",
          "publishedOn": "2023-10-28T00:41:29.821Z",
          "wordCount": null,
          "title": "Cross-feature Contrastive Loss for Decentralized Deep Learning on Heterogeneous Data. (arXiv:2310.15890v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.01992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bouniot_Q/0/1/0/all/0/1\">Quentin Bouniot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Redko_I/0/1/0/all/0/1\">Ievgen Redko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Audigier_R/0/1/0/all/0/1\">Romaric Audigier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loesch_A/0/1/0/all/0/1\">Ang&#xe9;lique Loesch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habrard_A/0/1/0/all/0/1\">Amaury Habrard</a>",
          "description": "In this paper, we consider the framework of multi-task representation (MTR)\nlearning where the goal is to use source tasks to learn a representation that\nreduces the sample complexity of solving a target task. We start by reviewing\nrecent advances in MTR theory and show that they can provide novel insights for\npopular meta-learning algorithms when analyzed within this framework. In\nparticular, we highlight a fundamental difference between gradient-based and\nmetric-based algorithms in practice and put forward a theoretical analysis to\nexplain it. Finally, we use the derived insights to improve the performance of\nmeta-learning methods via a new spectral-based regularization term and confirm\nits efficiency through experimental studies on few-shot classification\nbenchmarks. To the best of our knowledge, this is the first contribution that\nputs the most recent learning bounds of MTR theory into practice for the task\nof few-shot classification.",
          "link": "http://arxiv.org/abs/2010.01992",
          "publishedOn": "2023-10-28T00:41:29.821Z",
          "wordCount": null,
          "title": "Improving Few-Shot Learning through Multi-task Representation Learning Theory. (arXiv:2010.01992v3 [cs.LG] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yun_J/0/1/0/all/0/1\">Juyoung Yun</a>",
          "description": "In the rapidly advancing domain of deep learning optimization, this paper\nunveils the StochGradAdam optimizer, a novel adaptation of the well-regarded\nAdam algorithm. Central to StochGradAdam is its gradient sampling technique.\nThis method not only ensures stable convergence but also leverages the\nadvantages of selective gradient consideration, fostering robust training by\npotentially mitigating the effects of noisy or outlier data and enhancing the\nexploration of the loss landscape for more dependable convergence. In both\nimage classification and segmentation tasks, StochGradAdam has demonstrated\nsuperior performance compared to the traditional Adam optimizer. By judiciously\nsampling a subset of gradients at each iteration, the optimizer is optimized\nfor managing intricate models. The paper provides a comprehensive exploration\nof StochGradAdam's methodology, from its mathematical foundations to bias\ncorrection strategies, heralding a promising advancement in deep learning\ntraining techniques.",
          "link": "http://arxiv.org/abs/2310.17042",
          "publishedOn": "2023-10-28T00:41:29.820Z",
          "wordCount": null,
          "title": "StochGradAdam: Accelerating Neural Networks Training with Stochastic Gradient Sampling. (arXiv:2310.17042v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Terence Jie Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1\">Kwok-Yan Lam</a>",
          "description": "The emergence of foundation models, including language and vision models, has\nreshaped AI's landscape, offering capabilities across various applications.\nDeploying and fine-tuning these large models, like GPT-3 and BERT, presents\nchallenges, especially in the current foundation model era. We introduce\nEmulator-Assisted Tuning (EAT) combined with Parameter-Efficient Fine-Tuning\n(PEFT) to form Parameter-Efficient Emulator-Assisted Tuning (PEAT). Further, we\nexpand this into federated learning as Federated PEAT (FedPEAT). FedPEAT uses\nadapters, emulators, and PEFT for federated model tuning, enhancing model\nprivacy and memory efficiency. Adapters adjust pre-trained models, while\nemulators give a compact representation of original models, addressing both\nprivacy and efficiency. Adaptable to various neural networks, our approach also\nuses deep reinforcement learning for hyper-parameter optimization. We tested\nFedPEAT in a unique scenario with a server participating in collaborative\nfederated tuning, showcasing its potential in tackling foundation model\nchallenges.",
          "link": "http://arxiv.org/abs/2310.17491",
          "publishedOn": "2023-10-28T00:41:29.820Z",
          "wordCount": null,
          "title": "FedPEAT: Convergence of Federated Learning, Parameter-Efficient Fine Tuning, and Emulator Assisted Tuning for Artificial Intelligence Foundation Models with Mobile Edge Computing. (arXiv:2310.17491v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoang_A/0/1/0/all/0/1\">Anh T. Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viharos_Z/0/1/0/all/0/1\">Zsolt J. Viharos</a>",
          "description": "Machine learning is a powerful tool for extracting valuable information and\nmaking various predictions from diverse datasets. Traditional algorithms rely\non well-defined input and output variables however, there are scenarios where\nthe distinction between the input and output variables and the underlying,\nassociated (input and output) layers of the model, are unknown. Neural\nArchitecture Search (NAS) and Feature Selection have emerged as promising\nsolutions in such scenarios. This research proposes IDENAS, an Internal\nDependency-based Exploration for Neural Architecture Search, integrating NAS\nwith feature selection. The methodology explores internal dependencies in the\ncomplete parameter space for classification involving 1D sensor and 2D image\ndata as well. IDENAS employs a modified encoder-decoder model and the\nSequential Forward Search (SFS) algorithm, combining input-output configuration\nsearch with embedded feature selection. Experimental results demonstrate\nIDENASs superior performance in comparison to other algorithms, showcasing its\neffectiveness in model development pipelines and automated machine learning. On\naverage, IDENAS achieved significant modelling improvements, underscoring its\nsignificant contribution to advancing the state-of-the-art in neural\narchitecture search and feature selection integration.",
          "link": "http://arxiv.org/abs/2310.17250",
          "publishedOn": "2023-10-28T00:41:29.819Z",
          "wordCount": null,
          "title": "IDENAS: Internal Dependency Exploration for Neural Architecture Search. (arXiv:2310.17250v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mustafa_Y/0/1/0/all/0/1\">Yasmine Mustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1\">Tie Luo</a>",
          "description": "Alzheimer's disease (AD) is a prevalent and debilitating neurodegenerative\ndisorder impacting a large aging population. Detecting AD in all its\npresymptomatic and symptomatic stages is crucial for early intervention and\ntreatment. An active research direction is to explore machine learning methods\nthat harness multimodal data fusion to outperform human inspection of medical\nscans. However, existing multimodal fusion models have limitations, including\nredundant computation, complex architecture, and simplistic handling of missing\ndata. Moreover, the preprocessing pipelines of medical scans remain\ninadequately detailed and are seldom optimized for individual subjects. In this\npaper, we propose an efficient early-late fusion (ELF) approach, which\nleverages a convolutional neural network for automated feature extraction and\nrandom forests for their competitive performance on small datasets.\nAdditionally, we introduce a robust preprocessing pipeline that adapts to the\nunique characteristics of individual subjects and makes use of whole brain\nimages rather than slices or patches. Moreover, to tackle the challenge of\ndetecting subtle changes in brain volume, we transform images into the Jacobian\ndomain (JD) to enhance both accuracy and robustness in our classification.\nUsing MRI and CT images from the OASIS-3 dataset, our experiments demonstrate\nthe effectiveness of the ELF approach in classifying AD into four stages with\nan accuracy of 97.19%.",
          "link": "http://arxiv.org/abs/2310.16936",
          "publishedOn": "2023-10-28T00:41:29.751Z",
          "wordCount": null,
          "title": "Diagnosing Alzheimer's Disease using Early-Late Multimodal Data Fusion with Jacobian Maps. (arXiv:2310.16936v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chao Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_T/0/1/0/all/0/1\">Tianheng Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiele_G/0/1/0/all/0/1\">Gregor Schiele</a>",
          "description": "To process sensor data in the Internet of Things(IoTs), embedded deep\nlearning for 1-dimensional data is an important technique. In the past, CNNs\nwere frequently used because they are simple to optimise for special embedded\nhardware such as FPGAs. This work proposes a novel LSTM cell optimisation aimed\nat energy-efficient inference on end devices. Using the traffic speed\nprediction as a case study, a vanilla LSTM model with the optimised LSTM cell\nachieves 17534 inferences per second while consuming only 3.8 $\\mu$J per\ninference on the FPGA \\textit{XC7S15} from \\textit{Spartan-7} family. It\nachieves at least 5.4$\\times$ faster throughput and 1.37$\\times$ more energy\nefficient than existing approaches.",
          "link": "http://arxiv.org/abs/2310.16842",
          "publishedOn": "2023-10-28T00:41:29.748Z",
          "wordCount": null,
          "title": "Enhancing Energy-efficiency by Solving the Throughput Bottleneck of LSTM Cells for Embedded FPGAs. (arXiv:2310.16842v1 [cs.AR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zixuan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiaqi Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hanqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_D/0/1/0/all/0/1\">David Z. Pan</a>",
          "description": "Transformers have achieved great success in machine learning applications.\nNormalization techniques, such as Layer Normalization (LayerNorm, LN) and Root\nMean Square Normalization (RMSNorm), play a critical role in accelerating and\nstabilizing the training of Transformers. While LayerNorm recenters and\nrescales input vectors, RMSNorm only rescales the vectors by their RMS value.\nDespite being more computationally efficient, RMSNorm may compromise the\nrepresentation ability of Transformers. There is currently no consensus\nregarding the preferred normalization technique, as some models employ\nLayerNorm while others utilize RMSNorm, especially in recent large language\nmodels. It is challenging to convert Transformers with one normalization to the\nother type. While there is an ongoing disagreement between the two\nnormalization types, we propose a solution to unify two mainstream Transformer\narchitectures, Pre-LN and Pre-RMSNorm Transformers. By removing the inherent\nredundant mean information in the main branch of Pre-LN Transformers, we can\nreduce LayerNorm to RMSNorm, achieving higher efficiency. We further propose\nthe Compressed RMSNorm (CRMSNorm) and Pre-CRMSNorm Transformer based on a\nlossless compression of the zero-mean vectors. We formally establish the\nequivalence of Pre-LN, Pre-RMSNorm, and Pre-CRMSNorm Transformer variants in\nboth training and inference. It implies that Pre-LN Transformers can be\nsubstituted with Pre-(C)RMSNorm counterparts at almost no cost, offering the\nsame arithmetic functionality along with free efficiency improvement.\nExperiments demonstrate that we can reduce the training and inference time of\nPre-LN Transformers by 1% - 10%.",
          "link": "http://arxiv.org/abs/2305.14858",
          "publishedOn": "2023-10-28T00:41:29.747Z",
          "wordCount": null,
          "title": "Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient Pre-LN Transformers. (arXiv:2305.14858v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalra_A/0/1/0/all/0/1\">Akansha Kalra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel S. Brown</a>",
          "description": "There is an increasing interest in learning reward functions that model human\npreferences. However, many frameworks use blackbox learning methods that, while\nexpressive, are difficult to interpret. We propose and evaluate a novel\napproach for learning expressive and interpretable reward functions from\npreferences using Differentiable Decision Trees (DDTs). Our experiments across\nseveral domains, including CartPole, Visual Gridworld environments and Atari\ngames, provide evidence that that the tree structure of our learned reward\nfunction is useful in determining the extent to which the reward function is\naligned with human preferences. We provide experimental evidence that reward\nDDTs can achieve competitive performance when compared with larger capacity\ndeep neural network reward functions. We also observe that the choice between\nsoft and hard (argmax) output of reward DDT reveals a tension between wanting\nhighly shaped rewards to ensure good RL performance, while also wanting\nsimpler, more interpretable rewards.",
          "link": "http://arxiv.org/abs/2306.13004",
          "publishedOn": "2023-10-28T00:41:29.747Z",
          "wordCount": null,
          "title": "Can Differentiable Decision Trees Learn Interpretable Reward Functions?. (arXiv:2306.13004v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_lahham_A/0/1/0/all/0/1\">Anas Al-lahham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theeb_O/0/1/0/all/0/1\">Obaidah Theeb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elalem_K/0/1/0/all/0/1\">Khaled Elalem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alshawi_T/0/1/0/all/0/1\">Tariq A. Alshawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alshebeili_S/0/1/0/all/0/1\">Saleh A. Alshebeili</a>",
          "description": "Ahead-of-time forecasting of the output power of power plants is essential\nfor the stability of the electricity grid and ensuring uninterrupted service.\nHowever, forecasting renewable energy sources is difficult due to the chaotic\nbehavior of natural energy sources. This paper presents a new approach to\nestimate short-term solar irradiance from sky images. The~proposed algorithm\nextracts features from sky images and use learning-based techniques to estimate\nthe solar irradiance. The~performance of proposed machine learning (ML)\nalgorithm is evaluated using two publicly available datasets of sky images.\nThe~datasets contain over 350,000 images for an interval of 16 years, from 2004\nto 2020, with the corresponding global horizontal irradiance (GHI) of each\nimage as the ground truth. Compared to the state-of-the-art computationally\nheavy algorithms proposed in the literature, our approach achieves competitive\nresults with much less computational complexity for both nowcasting and\nforecasting up to 4 h ahead of time.",
          "link": "http://arxiv.org/abs/2310.17356",
          "publishedOn": "2023-10-28T00:41:29.745Z",
          "wordCount": null,
          "title": "Sky Imager-Based Forecast of Solar Irradiance Using Machine Learning. (arXiv:2310.17356v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17132",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shuai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhizhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhenfeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yao Zhao</a>",
          "description": "Based on the message-passing paradigm, there has been an amount of research\nproposing diverse and impressive feature propagation mechanisms to improve the\nperformance of GNNs. However, less focus has been put on feature\ntransformation, another major operation of the message-passing framework. In\nthis paper, we first empirically investigate the performance of the feature\ntransformation operation in several typical GNNs. Unexpectedly, we notice that\nGNNs do not completely free up the power of the inherent feature transformation\noperation. By this observation, we propose the Bi-directional Knowledge\nTransfer (BiKT), a plug-and-play approach to unleash the potential of the\nfeature transformation operations without modifying the original architecture.\nTaking the feature transformation operation as a derived representation\nlearning model that shares parameters with the original GNN, the direct\nprediction by this model provides a topological-agnostic knowledge feedback\nthat can further instruct the learning of GNN and the feature transformations\ntherein. On this basis, BiKT not only allows us to acquire knowledge from both\nthe GNN and its derived model but promotes each other by injecting the\nknowledge into the other. In addition, a theoretical analysis is further\nprovided to demonstrate that BiKT improves the generalization bound of the GNNs\nfrom the perspective of domain adaption. An extensive group of experiments on\nup to 7 datasets with 5 typical GNNs demonstrates that BiKT brings up to 0.5% -\n4% performance gain over the original GNN, which means a boosted GNN is\nobtained. Meanwhile, the derived model also shows a powerful performance to\ncompete with or even surpass the original GNN, enabling us to flexibly apply it\nindependently to some other specific downstream tasks.",
          "link": "http://arxiv.org/abs/2310.17132",
          "publishedOn": "2023-10-28T00:41:29.744Z",
          "wordCount": null,
          "title": "Unleashing the potential of GNNs via Bi-directional Knowledge Transfer. (arXiv:2310.17132v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.10482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minseon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ha_H/0/1/0/all/0/1\">Hyeonjeong Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_S/0/1/0/all/0/1\">Sooel Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Recently, unsupervised adversarial training (AT) has been highlighted as a\nmeans of achieving robustness in models without any label information. Previous\nstudies in unsupervised AT have mostly focused on implementing self-supervised\nlearning (SSL) frameworks, which maximize the instance-wise classification loss\nto generate adversarial examples. However, we observe that simply maximizing\nthe self-supervised training loss with an untargeted adversarial attack often\nresults in generating ineffective adversaries that may not help improve the\nrobustness of the trained model, especially for non-contrastive SSL frameworks\nwithout negative examples. To tackle this problem, we propose a novel positive\nmining for targeted adversarial attack to generate effective adversaries for\nadversarial SSL frameworks. Specifically, we introduce an algorithm that\nselects the most confusing yet similar target example for a given instance\nbased on entropy and similarity, and subsequently perturbs the given instance\ntowards the selected target. Our method demonstrates significant enhancements\nin robustness when applied to non-contrastive SSL frameworks, and less but\nconsistent robustness improvements with contrastive SSL frameworks, on the\nbenchmark datasets.",
          "link": "http://arxiv.org/abs/2210.10482",
          "publishedOn": "2023-10-28T00:41:29.744Z",
          "wordCount": null,
          "title": "Effective Targeted Attacks for Adversarial Self-Supervised Learning. (arXiv:2210.10482v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iakovlev_V/0/1/0/all/0/1\">Valerii Iakovlev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinonen_M/0/1/0/all/0/1\">Markus Heinonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahdesmaki_H/0/1/0/all/0/1\">Harri L&#xe4;hdesm&#xe4;ki</a>",
          "description": "We introduce a novel grid-independent model for learning partial differential\nequations (PDEs) from noisy and partial observations on irregular\nspatiotemporal grids. We propose a space-time continuous latent neural PDE\nmodel with an efficient probabilistic framework and a novel encoder design for\nimproved data efficiency and grid independence. The latent state dynamics are\ngoverned by a PDE model that combines the collocation method and the method of\nlines. We employ amortized variational inference for approximate posterior\nestimation and utilize a multiple shooting technique for enhanced training\nspeed and stability. Our model demonstrates state-of-the-art performance on\ncomplex synthetic and real-world datasets, overcoming limitations of previous\napproaches and effectively handling partially-observed data. The proposed model\noutperforms recent methods, showing its potential to advance data-driven PDE\nmodeling and enabling robust, grid-independent modeling of complex\npartially-observed dynamic processes.",
          "link": "http://arxiv.org/abs/2307.04110",
          "publishedOn": "2023-10-28T00:41:29.744Z",
          "wordCount": null,
          "title": "Learning Space-Time Continuous Neural PDEs from Partially Observed States. (arXiv:2307.04110v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andaz_S/0/1/0/all/0/1\">Sohrab Andaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenach_C/0/1/0/all/0/1\">Carson Eisenach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madeka_D/0/1/0/all/0/1\">Dhruv Madeka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torkkola_K/0/1/0/all/0/1\">Kari Torkkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Randy Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1\">Dean Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>",
          "description": "In this paper we address the problem of learning and backtesting inventory\ncontrol policies in the presence of general arrival dynamics -- which we term\nas a quantity-over-time arrivals model (QOT). We also allow for order\nquantities to be modified as a post-processing step to meet vendor constraints\nsuch as order minimum and batch size constraints -- a common practice in real\nsupply chains. To the best of our knowledge this is the first work to handle\neither arbitrary arrival dynamics or an arbitrary downstream post-processing of\norder quantities. Building upon recent work (Madeka et al., 2022) we similarly\nformulate the periodic review inventory control problem as an exogenous\ndecision process, where most of the state is outside the control of the agent.\nMadeka et al. (2022) show how to construct a simulator that replays historic\ndata to solve this class of problem. In our case, we incorporate a deep\ngenerative model for the arrivals process as part of the history replay. By\nformulating the problem as an exogenous decision process, we can apply results\nfrom Madeka et al. (2022) to obtain a reduction to supervised learning.\nFinally, we show via simulation studies that this approach yields statistically\nsignificant improvements in profitability over production baselines. Using data\nfrom an ongoing real-world A/B test, we show that Gen-QOT generalizes well to\noff-policy data.",
          "link": "http://arxiv.org/abs/2310.17168",
          "publishedOn": "2023-10-28T00:41:29.742Z",
          "wordCount": null,
          "title": "Learning an Inventory Control Policy with General Inventory Arrival Dynamics. (arXiv:2310.17168v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.02209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xingyue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orth_M/0/1/0/all/0/1\">Miguel Romero Orth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceylan_I/0/1/0/all/0/1\">&#x130;smail &#x130;lkan Ceylan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barcelo_P/0/1/0/all/0/1\">Pablo Barcel&#xf3;</a>",
          "description": "Graph neural networks are prominent models for representation learning over\ngraph-structured data. While the capabilities and limitations of these models\nare well-understood for simple graphs, our understanding remains incomplete in\nthe context of knowledge graphs. Our goal is to provide a systematic\nunderstanding of the landscape of graph neural networks for knowledge graphs\npertaining to the prominent task of link prediction. Our analysis entails a\nunifying perspective on seemingly unrelated models and unlocks a series of\nother models. The expressive power of various models is characterized via a\ncorresponding relational Weisfeiler-Leman algorithm. This analysis is extended\nto provide a precise logical characterization of the class of functions\ncaptured by a class of graph neural networks. The theoretical findings\npresented in this paper explain the benefits of some widely employed practical\ndesign choices, which are validated empirically.",
          "link": "http://arxiv.org/abs/2302.02209",
          "publishedOn": "2023-10-28T00:41:29.742Z",
          "wordCount": null,
          "title": "A Theory of Link Prediction via Relational Weisfeiler-Leman on Knowledge Graphs. (arXiv:2302.02209v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17355",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kudriavtsev_M/0/1/0/all/0/1\">Mikhail Kudriavtsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezbradica_D/0/1/0/all/0/1\">Dr Marija Bezbradica</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCarren_D/0/1/0/all/0/1\">Dr Andrew McCarren</a>",
          "description": "Association rule mining techniques can generate a large volume of sequential\ndata when implemented on transactional databases. Extracting insights from a\nlarge set of association rules has been found to be a challenging process. When\nexamining a ruleset, the fundamental question is how to summarise and represent\nmeaningful mined knowledge efficiently. Many algorithms and strategies have\nbeen developed to address issue of knowledge extraction; however, the\neffectiveness of this process can be limited by the data structures. A better\ndata structure can sufficiently affect the speed of the knowledge extraction\nprocess. This paper proposes a novel data structure, called the Trie of rules,\nfor storing a ruleset that is generated by association rule mining. The\nresulting data structure is a prefix-tree graph structure made of pre-mined\nrules. This graph stores the rules as paths within the prefix-tree in a way\nthat similar rules overlay each other. Each node in the tree represents a rule\nwhere a consequent is this node, and an antecedent is a path from this node to\nthe root of the tree. The evaluation showed that the proposed representation\ntechnique is promising. It compresses a ruleset with almost no data loss and\nbenefits in terms of time for basic operations such as searching for a specific\nrule and sorting, which is the base for many knowledge discovery methods.\nMoreover, our method demonstrated a significant improvement in traversing time,\nachieving an 8-fold increase compared to traditional data structures.",
          "link": "http://arxiv.org/abs/2310.17355",
          "publishedOn": "2023-10-28T00:41:29.741Z",
          "wordCount": null,
          "title": "Exploring the Trie of Rules: a fast data structure for the representation of association rules. (arXiv:2310.17355v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.00650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marsden_R/0/1/0/all/0/1\">Robert A. Marsden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobler_M/0/1/0/all/0/1\">Mario D&#xf6;bler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>",
          "description": "Since distribution shifts are likely to occur during test-time and can\ndrastically decrease the model's performance, online test-time adaptation (TTA)\ncontinues to update the model after deployment, leveraging the current test\ndata. Clearly, a method proposed for online TTA has to perform well for all\nkinds of environmental conditions. By introducing the variable factors domain\nnon-stationarity and temporal correlation, we first unfold all practically\nrelevant settings and define the entity as universal TTA. We want to highlight\nthat this is the first work that covers such a broad spectrum, which is\nindispensable for the use in practice. To tackle the problem of universal TTA,\nwe identify and highlight several challenges a self-training based method has\nto deal with: 1) model bias and the occurrence of trivial solutions when\nperforming entropy minimization on varying sequence lengths with and without\nmultiple domain shifts, 2) loss of generalization which exacerbates the\nadaptation to multiple domain shifts and the occurrence of catastrophic\nforgetting, and 3) performance degradation due to shifts in class prior. To\nprevent the model from becoming biased, we leverage a dataset and\nmodel-agnostic certainty and diversity weighting. In order to maintain\ngeneralization and prevent catastrophic forgetting, we propose to continually\nweight-average the source and adapted model. To compensate for disparities in\nthe class prior during test-time, we propose an adaptive prior correction\nscheme that reweights the model's predictions. We evaluate our approach, named\nROID, on a wide range of settings, datasets, and models, setting new standards\nin the field of universal TTA. Code is available at:\nhttps://github.com/mariodoebler/test-time-adaptation",
          "link": "http://arxiv.org/abs/2306.00650",
          "publishedOn": "2023-10-28T00:41:29.741Z",
          "wordCount": null,
          "title": "Universal Test-time Adaptation through Weight Ensembling, Diversity Weighting, and Prior Correction. (arXiv:2306.00650v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Leon Liyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiarui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moniz_J/0/1/0/all/0/1\">Joel Ruben Antony Moniz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Aditya Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piraviperumal_D/0/1/0/all/0/1\">Dhivya Piraviperumal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Tien Dung Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzou_N/0/1/0/all/0/1\">Nicholas Tzou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>",
          "description": "In the context of a voice assistant system, steering refers to the phenomenon\nin which a user issues a follow-up command attempting to direct or clarify a\nprevious turn. We propose STEER, a steering detection model that predicts\nwhether a follow-up turn is a user's attempt to steer the previous command.\nConstructing a training dataset for steering use cases poses challenges due to\nthe cold-start problem. To overcome this, we developed heuristic rules to\nsample opt-in usage data, approximating positive and negative samples without\nany annotation. Our experimental results show promising performance in\nidentifying steering intent, with over 95% accuracy on our sampled data.\nMoreover, STEER, in conjunction with our sampling strategy, aligns effectively\nwith real-world steering scenarios, as evidenced by its strong zero-shot\nperformance on a human-graded evaluation set. In addition to relying solely on\nuser transcripts as input, we introduce STEER+, an enhanced version of the\nmodel. STEER+ utilizes a semantic parse tree to provide more context on\nout-of-vocabulary words, such as named entities that often occur at the\nsentence boundary. This further improves model performance, reducing error rate\nin domains where entities frequently appear, such as messaging. Lastly, we\npresent a data analysis that highlights the improvement in user experience when\nvoice assistants support steering use cases.",
          "link": "http://arxiv.org/abs/2310.16990",
          "publishedOn": "2023-10-28T00:41:29.739Z",
          "wordCount": null,
          "title": "STEER: Semantic Turn Extension-Expansion Recognition for Voice Assistants. (arXiv:2310.16990v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhar_M/0/1/0/all/0/1\">Mrinal Kanti Dhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deb_M/0/1/0/all/0/1\">Mou Deb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madhab_D/0/1/0/all/0/1\">D. Madhab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zeyun Yu</a>",
          "description": "Accurate teeth segmentation and orientation are fundamental in modern oral\nhealthcare, enabling precise diagnosis, treatment planning, and dental implant\ndesign. In this study, we present a comprehensive approach to teeth\nsegmentation and orientation from panoramic X-ray images, leveraging deep\nlearning techniques. We build our model based on FUSegNet, a popular model\noriginally developed for wound segmentation, and introduce modifications by\nincorporating grid-based attention gates into the skip connections. We\nintroduce oriented bounding box (OBB) generation through principal component\nanalysis (PCA) for precise tooth orientation estimation. Evaluating our\napproach on the publicly available DNS dataset, comprising 543 panoramic X-ray\nimages, we achieve the highest Intersection-over-Union (IoU) score of 82.43%\nand Dice Similarity Coefficient (DSC) score of 90.37% among compared models in\nteeth instance segmentation. In OBB analysis, we obtain the Rotated IoU (RIoU)\nscore of 82.82%. We also conduct detailed analyses of individual tooth labels\nand categorical performance, shedding light on strengths and weaknesses. The\nproposed model's accuracy and versatility offer promising prospects for\nimproving dental diagnoses, treatment planning, and personalized healthcare in\nthe oral domain. Our generated OBB coordinates and codes are available at\nhttps://github.com/mrinal054/Instance_teeth_segmentation.",
          "link": "http://arxiv.org/abs/2310.17176",
          "publishedOn": "2023-10-28T00:41:29.737Z",
          "wordCount": null,
          "title": "A Deep Learning Approach to Teeth Segmentation and Orientation from Panoramic X-rays. (arXiv:2310.17176v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.18353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tosato_N/0/1/0/all/0/1\">Niccol&#xf2; Tosato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basile_L/0/1/0/all/0/1\">Lorenzo Basile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ballarin_E/0/1/0/all/0/1\">Emanuele Ballarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alteriis_G/0/1/0/all/0/1\">Giuseppe de Alteriis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cazzaniga_A/0/1/0/all/0/1\">Alberto Cazzaniga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ansuini_A/0/1/0/all/0/1\">Alessio Ansuini</a>",
          "description": "The Backpropagation algorithm has often been criticised for its lack of\nbiological realism. In an attempt to find a more biologically plausible\nalternative, the recently introduced Forward-Forward algorithm replaces the\nforward and backward passes of Backpropagation with two forward passes. In this\nwork, we show that the internal representations obtained by the Forward-Forward\nalgorithm can organise into category-specific ensembles exhibiting high\nsparsity - i.e. composed of an extremely low number of active units. This\nsituation is reminiscent of what has been observed in cortical sensory areas,\nwhere neuronal ensembles are suggested to serve as the functional building\nblocks for perception and action. Interestingly, while this sparse pattern does\nnot typically arise in models trained with standard Backpropagation, it can\nemerge in networks trained with Backpropagation on the same objective proposed\nfor the Forward-Forward algorithm. These results suggest that the learning\nprocedure proposed by Forward-Forward may be superior to Backpropagation in\nmodelling learning in the cortex, even when a backward pass is used.",
          "link": "http://arxiv.org/abs/2305.18353",
          "publishedOn": "2023-10-28T00:41:29.737Z",
          "wordCount": null,
          "title": "Emergent representations in networks trained with the Forward-Forward algorithm. (arXiv:2305.18353v2 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.13349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "Motivated by the challenge of nonstationarity in sequential decision making,\nwe study Online Convex Optimization (OCO) under the coupling of two problem\nstructures: the domain is unbounded, and the comparator sequence\n$u_1,\\ldots,u_T$ is arbitrarily time-varying. As no algorithm can guarantee low\nregret simultaneously against all comparator sequences, handling this setting\nrequires moving from minimax optimality to comparator adaptivity. That is,\nsensible regret bounds should depend on certain complexity measures of the\ncomparator relative to one's prior knowledge.\n\nThis paper achieves a new type of these adaptive regret bounds via a sparse\ncoding framework. The complexity of the comparator is measured by its energy\nand its sparsity on a user-specified dictionary, which offers considerable\nversatility. Equipped with a wavelet dictionary for example, our framework\nimproves the state-of-the-art bound (Jacobsen & Cutkosky, 2022) by adapting to\nboth ($i$) the magnitude of the comparator average $||\\bar\nu||=||\\sum_{t=1}^Tu_t/T||$, rather than the maximum $\\max_t||u_t||$; and ($ii$)\nthe comparator variability $\\sum_{t=1}^T||u_t-\\bar u||$, rather than the\nuncentered sum $\\sum_{t=1}^T||u_t||$. Furthermore, our analysis is simpler due\nto decoupling function approximation from regret minimization.",
          "link": "http://arxiv.org/abs/2301.13349",
          "publishedOn": "2023-10-28T00:41:29.731Z",
          "wordCount": null,
          "title": "Unconstrained Dynamic Regret via Sparse Coding. (arXiv:2301.13349v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.08175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yingtai Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_G/0/1/0/all/0/1\">Guanlin He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Danfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kifer_D/0/1/0/all/0/1\">Daniel Kifer</a>",
          "description": "Noisy marginals are a common form of confidentiality-protecting data release\nand are useful for many downstream tasks such as contingency table analysis,\nconstruction of Bayesian networks, and even synthetic data generation. Privacy\nmechanisms that provide unbiased noisy answers to linear queries (such as\nmarginals) are known as matrix mechanisms.\n\nWe propose ResidualPlanner, a matrix mechanism for marginals with Gaussian\nnoise that is both optimal and scalable. ResidualPlanner can optimize for many\nloss functions that can be written as a convex function of marginal variances\n(prior work was restricted to just one predefined objective function).\nResidualPlanner can optimize the accuracy of marginals in large scale settings\nin seconds, even when the previous state of the art (HDMM) runs out of memory.\nIt even runs on datasets with 100 attributes in a couple of minutes.\nFurthermore ResidualPlanner can efficiently compute variance/covariance values\nfor each marginal (prior methods quickly run out of memory, even for relatively\nsmall datasets).",
          "link": "http://arxiv.org/abs/2305.08175",
          "publishedOn": "2023-10-28T00:41:29.731Z",
          "wordCount": null,
          "title": "An Optimal and Scalable Matrix Mechanism for Noisy Marginals under Convex Loss Functions. (arXiv:2305.08175v2 [cs.DB] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.20081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_B/0/1/0/all/0/1\">Bingyi Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1\">Chao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1\">Tianyu Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shuicheng Yan</a>",
          "description": "Offline reinforcement learning (RL) aims to learn optimal policies from\noffline datasets, where the parameterization of policies is crucial but often\noverlooked. Recently, Diffsuion-QL significantly boosts the performance of\noffline RL by representing a policy with a diffusion model, whose success\nrelies on a parametrized Markov Chain with hundreds of steps for sampling.\nHowever, Diffusion-QL suffers from two critical limitations. 1) It is\ncomputationally inefficient to forward and backward through the whole Markov\nchain during training. 2) It is incompatible with maximum likelihood-based RL\nalgorithms (e.g., policy gradient methods) as the likelihood of diffusion\nmodels is intractable. Therefore, we propose efficient diffusion policy (EDP)\nto overcome these two challenges. EDP approximately constructs actions from\ncorrupted ones at training to avoid running the sampling chain. We conduct\nextensive experiments on the D4RL benchmark. The results show that EDP can\nreduce the diffusion policy training time from 5 days to 5 hours on\ngym-locomotion tasks. Moreover, we show that EDP is compatible with various\noffline RL algorithms (TD3, CRR, and IQL) and achieves new state-of-the-art on\nD4RL by large margins over previous methods. Our code is available at\nhttps://github.com/sail-sg/edp.",
          "link": "http://arxiv.org/abs/2305.20081",
          "publishedOn": "2023-10-28T00:41:29.731Z",
          "wordCount": null,
          "title": "Efficient Diffusion Policies for Offline Reinforcement Learning. (arXiv:2305.20081v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17385",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Achddou_J/0/1/0/all/0/1\">Juliette Achddou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1\">Nicol&#xf2; Cesa-Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laforgue_P/0/1/0/all/0/1\">Pierre Laforgue</a>",
          "description": "We study multitask online learning in a setting where agents can only\nexchange information with their neighbors on an arbitrary communication\nnetwork. We introduce $\\texttt{MT-CO}_2\\texttt{OL}$, a decentralized algorithm\nfor this setting whose regret depends on the interplay between the task\nsimilarities and the network structure. Our analysis shows that the regret of\n$\\texttt{MT-CO}_2\\texttt{OL}$ is never worse (up to constants) than the bound\nobtained when agents do not share information. On the other hand, our bounds\nsignificantly improve when neighboring agents operate on similar tasks. In\naddition, we prove that our algorithm can be made differentially private with a\nnegligible impact on the regret when the losses are linear. Finally, we provide\nexperimental support for our theory.",
          "link": "http://arxiv.org/abs/2310.17385",
          "publishedOn": "2023-10-28T00:41:29.730Z",
          "wordCount": null,
          "title": "Multitask Online Learning: Listen to the Neighborhood Buzz. (arXiv:2310.17385v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.13082",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hanzely_S/0/1/0/all/0/1\">Slavom&#xed;r Hanzely</a>",
          "description": "In this paper, we propose the first sketch-and-project Newton method with\nfast $\\mathcal O(k^{-2})$ global convergence rate for self-concordant\nfunctions. Our method, SGN, can be viewed in three ways: i) as a\nsketch-and-project algorithm projecting updates of Newton method, ii) as a\ncubically regularized Newton ethod in sketched subspaces, and iii) as a damped\nNewton method in sketched subspaces. SGN inherits best of all three worlds:\ncheap iteration costs of sketch-and-project methods, state-of-the-art $\\mathcal\nO(k^{-2})$ global convergence rate of full-rank Newton-like methods and the\nalgorithm simplicity of damped Newton methods. Finally, we demonstrate its\ncomparable empirical performance to baseline algorithms.",
          "link": "http://arxiv.org/abs/2305.13082",
          "publishedOn": "2023-10-28T00:41:29.730Z",
          "wordCount": null,
          "title": "Sketch-and-Project Meets Newton Method: Global $\\mathcal O(k^{-2})$ Convergence with Low-Rank Updates. (arXiv:2305.13082v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.12906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Southern_J/0/1/0/all/0/1\">Joshua Southern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wayland_J/0/1/0/all/0/1\">Jeremy Wayland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1\">Bastian Rieck</a>",
          "description": "Graph generative model evaluation necessitates understanding differences\nbetween graphs on the distributional level. This entails being able to harness\nsalient attributes of graphs in an efficient manner. Curvature constitutes one\nsuch property that has recently proved its utility in characterising graphs.\nIts expressive properties, stability, and practical utility in model evaluation\nremain largely unexplored, however. We combine graph curvature descriptors with\nemerging methods from topological data analysis to obtain robust, expressive\ndescriptors for evaluating graph generative models.",
          "link": "http://arxiv.org/abs/2301.12906",
          "publishedOn": "2023-10-28T00:41:29.639Z",
          "wordCount": null,
          "title": "Curvature Filtrations for Graph Generative Model Evaluation. (arXiv:2301.12906v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07063",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jian_Y/0/1/0/all/0/1\">Yiren Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chongyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1\">Soroush Vosoughi</a>",
          "description": "We present a novel methodology aimed at optimizing the application of frozen\nlarge language models (LLMs) for resource-intensive vision-language (VL)\npre-training. The current paradigm uses visual features as prompts to guide\nlanguage models, with a focus on determining the most relevant visual features\nfor corresponding text. Our approach diverges by concentrating on the language\ncomponent, specifically identifying the optimal prompts to align with visual\nfeatures. We introduce the Prompt-Transformer (P-Former), a model that predicts\nthese ideal prompts, which is trained exclusively on linguistic data, bypassing\nthe need for image-text pairings. This strategy subtly bifurcates the\nend-to-end VL training process into an additional, separate stage. Our\nexperiments reveal that our framework significantly enhances the performance of\na robust image-to-text baseline (BLIP-2), and effectively narrows the\nperformance gap between models trained with either 4M or 129M image-text pairs.\nImportantly, our framework is modality-agnostic and flexible in terms of\narchitectural design, as validated by its successful application in a video\nlearning task using varied base modules. The code will be made available at\nhttps://github.com/yiren-jian/BLIText.",
          "link": "http://arxiv.org/abs/2307.07063",
          "publishedOn": "2023-10-28T00:41:29.638Z",
          "wordCount": null,
          "title": "Bootstrapping Vision-Language Learning with Decoupled Language Pre-training. (arXiv:2307.07063v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Shengpu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiens_J/0/1/0/all/0/1\">Jenna Wiens</a>",
          "description": "In applying reinforcement learning (RL) to high-stakes domains, quantitative\nand qualitative evaluation using observational data can help practitioners\nunderstand the generalization performance of new policies. However, this type\nof off-policy evaluation (OPE) is inherently limited since offline data may not\nreflect the distribution shifts resulting from the application of new policies.\nOn the other hand, online evaluation by collecting rollouts according to the\nnew policy is often infeasible, as deploying new policies in these domains can\nbe unsafe. In this work, we propose a semi-offline evaluation framework as an\nintermediate step between offline and online evaluation, where human users\nprovide annotations of unobserved counterfactual trajectories. While tempting\nto simply augment existing data with such annotations, we show that this naive\napproach can lead to biased results. Instead, we design a new family of OPE\nestimators based on importance sampling (IS) and a novel weighting scheme that\nincorporate counterfactual annotations without introducing additional bias. We\nanalyze the theoretical properties of our approach, showing its potential to\nreduce both bias and variance compared to standard IS estimators. Our analyses\nreveal important practical considerations for handling biased, noisy, or\nmissing annotations. In a series of proof-of-concept experiments involving\nbandits and a healthcare-inspired simulator, we demonstrate that our approach\noutperforms purely offline IS estimators and is robust to imperfect\nannotations. Our framework, combined with principled human-centered design of\nannotation solicitation, can enable the application of RL in high-stakes\ndomains.",
          "link": "http://arxiv.org/abs/2310.17146",
          "publishedOn": "2023-10-28T00:41:29.637Z",
          "wordCount": null,
          "title": "Counterfactual-Augmented Importance Sampling for Semi-Offline Policy Evaluation. (arXiv:2310.17146v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.11982",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Tang_M/0/1/0/all/0/1\">Mufeng Tang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Barron_H/0/1/0/all/0/1\">Helen Barron</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bogacz_R/0/1/0/all/0/1\">Rafal Bogacz</a>",
          "description": "Forming accurate memory of sequential stimuli is a fundamental function of\nbiological agents. However, the computational mechanism underlying sequential\nmemory in the brain remains unclear. Inspired by neuroscience theories and\nrecent successes in applying predictive coding (PC) to \\emph{static} memory\ntasks, in this work we propose a novel PC-based model for \\emph{sequential}\nmemory, called \\emph{temporal predictive coding} (tPC). We show that our tPC\nmodels can memorize and retrieve sequential inputs accurately with a\nbiologically plausible neural implementation. Importantly, our analytical study\nreveals that tPC can be viewed as a classical Asymmetric Hopfield Network (AHN)\nwith an implicit statistical whitening process, which leads to more stable\nperformance in sequential memory tasks of structured inputs. Moreover, we find\nthat tPC exhibits properties consistent with behavioral observations and\ntheories in neuroscience, thereby strengthening its biological relevance. Our\nwork establishes a possible computational mechanism underlying sequential\nmemory in the brain that can also be theoretically interpreted using existing\nmemory model frameworks.",
          "link": "http://arxiv.org/abs/2305.11982",
          "publishedOn": "2023-10-28T00:41:29.637Z",
          "wordCount": null,
          "title": "Sequential Memory with Temporal Predictive Coding. (arXiv:2305.11982v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xingyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yaling Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1\">Huaming Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yu Zhao</a>",
          "description": "Federated learning, a decentralized approach to machine learning, faces\nsignificant challenges such as extensive communication overheads, slow\nconvergence, and unstable improvements. These challenges primarily stem from\nthe gradient variance due to heterogeneous client data distributions. To\naddress this, we introduce a novel Networked Control Variates (FedNCV)\nframework for Federated Learning. We adopt the REINFORCE Leave-One-Out (RLOO)\nas a fundamental control variate unit in the FedNCV framework, implemented at\nboth client and server levels. At the client level, the RLOO control variate is\nemployed to optimize local gradient updates, mitigating the variance introduced\nby data samples. Once relayed to the server, the RLOO-based estimator further\nprovides an unbiased and low-variance aggregated gradient, leading to robust\nglobal updates. This dual-side application is formalized as a linear\ncombination of composite control variates. We provide a mathematical expression\ncapturing this integration of double control variates within FedNCV and present\nthree theoretical results with corresponding proofs. This unique dual structure\nequips FedNCV to address data heterogeneity and scalability issues, thus\npotentially paving the way for large-scale applications. Moreover, we tested\nFedNCV on six diverse datasets under a Dirichlet distribution with {\\alpha} =\n0.1, and benchmarked its performance against six SOTA methods, demonstrating\nits superiority.",
          "link": "http://arxiv.org/abs/2310.17200",
          "publishedOn": "2023-10-28T00:41:29.636Z",
          "wordCount": null,
          "title": "Taming Gradient Variance in Federated Learning with Networked Control Variates. (arXiv:2310.17200v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17023",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1\">Jiawen Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mu_W/0/1/0/all/0/1\">Wancen Mu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yun Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_D/0/1/0/all/0/1\">Didong Li</a>",
          "description": "In this paper, we critically examine the prevalent practice of using additive\nmixtures of Mat\\'ern kernels in single-output Gaussian process (GP) models and\nexplore the properties of multiplicative mixtures of Mat\\'ern kernels for\nmulti-output GP models. For the single-output case, we derive a series of\ntheoretical results showing that the smoothness of a mixture of Mat\\'ern\nkernels is determined by the least smooth component and that a GP with such a\nkernel is effectively equivalent to the least smooth kernel component.\nFurthermore, we demonstrate that none of the mixing weights or parameters\nwithin individual kernel components are identifiable. We then turn our\nattention to multi-output GP models and analyze the identifiability of the\ncovariance matrix $A$ in the multiplicative kernel $K(x,y) = AK_0(x,y)$, where\n$K_0$ is a standard single output kernel such as Mat\\'ern. We show that $A$ is\nidentifiable up to a multiplicative constant, suggesting that multiplicative\nmixtures are well suited for multi-output tasks. Our findings are supported by\nextensive simulations and real applications for both single- and multi-output\nsettings. This work provides insight into kernel selection and interpretation\nfor GP models, emphasizing the importance of choosing appropriate kernel\nstructures for different tasks.",
          "link": "http://arxiv.org/abs/2310.17023",
          "publishedOn": "2023-10-28T00:41:29.635Z",
          "wordCount": null,
          "title": "On the Identifiability and Interpretability of Gaussian Process Models. (arXiv:2310.17023v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17032",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Khan_S/0/1/0/all/0/1\">Saad Zafar Khan</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Muzammil_N/0/1/0/all/0/1\">Nazeefa Muzammil</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zaidi_S/0/1/0/all/0/1\">Syed Mohammad Hassan Zaidi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Aljohani_A/0/1/0/all/0/1\">Abdulah Jeza Aljohani</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Khan_H/0/1/0/all/0/1\">Haibat Khan</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ghafoor_S/0/1/0/all/0/1\">Salman Ghafoor</a>",
          "description": "Accurately forecasting solar power generation is crucial in the global\nprogression towards sustainable energy systems. In this study, we conduct a\nmeticulous comparison between Quantum Long Short-Term Memory (QLSTM) and\nclassical Long Short-Term Memory (LSTM) models for solar power production\nforecasting. Our controlled experiments reveal promising advantages of QLSTMs,\nincluding accelerated training convergence and substantially reduced test loss\nwithin the initial epoch compared to classical LSTMs. These empirical findings\ndemonstrate QLSTM's potential to swiftly assimilate complex time series\nrelationships, enabled by quantum phenomena like superposition. However,\nrealizing QLSTM's full capabilities necessitates further research into model\nvalidation across diverse conditions, systematic hyperparameter optimization,\nhardware noise resilience, and applications to correlated renewable forecasting\nproblems. With continued progress, quantum machine learning can offer a\nparadigm shift in renewable energy time series prediction. This pioneering work\nprovides initial evidence substantiating quantum advantages over classical\nLSTM, while acknowledging present limitations. Through rigorous benchmarking\ngrounded in real-world data, our study elucidates a promising trajectory for\nquantum learning in renewable forecasting. Additional research and development\ncan further actualize this potential to achieve unprecedented accuracy and\nreliability in predicting solar power generation worldwide.",
          "link": "http://arxiv.org/abs/2310.17032",
          "publishedOn": "2023-10-28T00:41:29.635Z",
          "wordCount": null,
          "title": "Quantum Long Short-Term Memory (QLSTM) vs Classical LSTM in Time Series Forecasting: A Comparative Study in Solar Power Forecasting. (arXiv:2310.17032v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saadatinia_M/0/1/0/all/0/1\">Mehrshad Saadatinia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salimi_Badr_A/0/1/0/all/0/1\">Armin Salimi-Badr</a>",
          "description": "In this study, we leverage a deep learning-based method for the automatic\ndiagnosis of schizophrenia using EEG brain recordings. This approach utilizes\ngenerative data augmentation, a powerful technique that enhances the accuracy\nof the diagnosis. To enable the utilization of time-frequency features,\nspectrograms were extracted from the raw signals. After exploring several\nneural network architectural setups, a proper convolutional neural network\n(CNN) was used for the initial diagnosis. Subsequently, using Wasserstein GAN\nwith Gradient Penalty (WGAN-GP) and Variational Autoencoder (VAE), two\ndifferent synthetic datasets were generated in order to augment the initial\ndataset and address the over-fitting issue. The augmented dataset using VAE\nachieved a 3.0\\% improvement in accuracy reaching up to 99.0\\% and yielded a\nlower loss value as well as a faster convergence. Finally, we addressed the\nlack of trust in black-box models using the Local Interpretable Model-agnostic\nExplanations (LIME) algorithm to determine the most important superpixels\n(frequencies) in the diagnosis process.",
          "link": "http://arxiv.org/abs/2310.16867",
          "publishedOn": "2023-10-28T00:41:29.559Z",
          "wordCount": null,
          "title": "An Explainable Deep Learning-Based Method For Schizophrenia Diagnosis Using Generative Data-Augmentation. (arXiv:2310.16867v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_S/0/1/0/all/0/1\">S M Atikur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibtisum_S/0/1/0/all/0/1\">Sifat Ibtisum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bazgir_E/0/1/0/all/0/1\">Ehsan Bazgir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barai_T/0/1/0/all/0/1\">Tumpa Barai</a>",
          "description": "The global need for effective disease diagnosis remains substantial, given\nthe complexities of various disease mechanisms and diverse patient symptoms. To\ntackle these challenges, researchers, physicians, and patients are turning to\nmachine learning (ML), an artificial intelligence (AI) discipline, to develop\nsolutions. By leveraging sophisticated ML and AI methods, healthcare\nstakeholders gain enhanced diagnostic and treatment capabilities. However,\nthere is a scarcity of research focused on ML algorithms for enhancing the\naccuracy and computational efficiency. This research investigates the capacity\nof machine learning algorithms to improve the transmission of heart rate data\nin time series healthcare metrics, concentrating particularly on optimizing\naccuracy and efficiency. By exploring various ML algorithms used in healthcare\napplications, the review presents the latest trends and approaches in ML-based\ndisease diagnosis (MLBDD). The factors under consideration include the\nalgorithm utilized, the types of diseases targeted, the data types employed,\nthe applications, and the evaluation metrics. This review aims to shed light on\nthe prospects of ML in healthcare, particularly in disease diagnosis. By\nanalyzing the current literature, the study provides insights into\nstate-of-the-art methodologies and their performance metrics.",
          "link": "http://arxiv.org/abs/2310.16978",
          "publishedOn": "2023-10-28T00:41:29.559Z",
          "wordCount": null,
          "title": "The Significance of Machine Learning in Clinical Disease Diagnosis: A Review. (arXiv:2310.16978v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.14597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahn_N/0/1/0/all/0/1\">Nate Rahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DOro_P/0/1/0/all/0/1\">Pierluca D&#x27;Oro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiltzer_H/0/1/0/all/0/1\">Harley Wiltzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacon_P/0/1/0/all/0/1\">Pierre-Luc Bacon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellemare_M/0/1/0/all/0/1\">Marc G. Bellemare</a>",
          "description": "Deep reinforcement learning agents for continuous control are known to\nexhibit significant instability in their performance over time. In this work,\nwe provide a fresh perspective on these behaviors by studying the return\nlandscape: the mapping between a policy and a return. We find that popular\nalgorithms traverse noisy neighborhoods of this landscape, in which a single\nupdate to the policy parameters leads to a wide range of returns. By taking a\ndistributional view of these returns, we map the landscape, characterizing\nfailure-prone regions of policy space and revealing a hidden dimension of\npolicy quality. We show that the landscape exhibits surprising structure by\nfinding simple paths in parameter space which improve the stability of a\npolicy. To conclude, we develop a distribution-aware procedure which finds such\npaths, navigating away from noisy neighborhoods in order to improve the\nrobustness of a policy. Taken together, our results provide new insight into\nthe optimization, evaluation, and design of agents.",
          "link": "http://arxiv.org/abs/2309.14597",
          "publishedOn": "2023-10-28T00:41:29.558Z",
          "wordCount": null,
          "title": "Policy Optimization in a Noisy Neighborhood: On Return Landscapes in Continuous Control. (arXiv:2309.14597v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.12930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiangyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulte_O/0/1/0/all/0/1\">Oliver Schulte</a>",
          "description": "A fundamental problem of causal discovery is cause-effect inference, learning\nthe correct causal direction between two random variables. Significant progress\nhas been made through modelling the effect as a function of its cause and a\nnoise term, which allows us to leverage assumptions about the generating\nfunction class. The recently introduced heteroscedastic location-scale noise\nfunctional models (LSNMs) combine expressive power with identifiability\nguarantees. LSNM model selection based on maximizing likelihood achieves\nstate-of-the-art accuracy, when the noise distributions are correctly\nspecified. However, through an extensive empirical evaluation, we demonstrate\nthat the accuracy deteriorates sharply when the form of the noise distribution\nis misspecified by the user. Our analysis shows that the failure occurs mainly\nwhen the conditional variance in the anti-causal direction is smaller than that\nin the causal direction. As an alternative, we find that causal model selection\nthrough residual independence testing is much more robust to noise\nmisspecification and misleading conditional variance.",
          "link": "http://arxiv.org/abs/2301.12930",
          "publishedOn": "2023-10-28T00:41:29.557Z",
          "wordCount": null,
          "title": "Cause-Effect Inference in Location-Scale Noise Models: Maximum Likelihood vs. Independence Testing. (arXiv:2301.12930v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.12458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avalos_R/0/1/0/all/0/1\">Rapha&#xeb;l Avalos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reymond_M/0/1/0/all/0/1\">Mathieu Reymond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowe_A/0/1/0/all/0/1\">Ann Now&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roijers_D/0/1/0/all/0/1\">Diederik M. Roijers</a>",
          "description": "Many recent successful off-policy multi-agent reinforcement learning (MARL)\nalgorithms for cooperative partially observable environments focus on finding\nfactorized value functions, leading to convoluted network structures. Building\non the structure of independent Q-learners, our LAN algorithm takes a radically\ndifferent approach, leveraging a dueling architecture to learn for each agent a\ndecentralized best-response policies via individual advantage functions. The\nlearning is stabilized by a centralized critic whose primary objective is to\nreduce the moving target problem of the individual advantages. The critic,\nwhose network's size is independent of the number of agents, is cast aside\nafter learning. Evaluation on the StarCraft II multi-agent challenge benchmark\nshows that LAN reaches state-of-the-art performance and is highly scalable with\nrespect to the number of agents, opening up a promising alternative direction\nfor MARL research.",
          "link": "http://arxiv.org/abs/2112.12458",
          "publishedOn": "2023-10-28T00:41:29.555Z",
          "wordCount": null,
          "title": "Local Advantage Networks for Cooperative Multi-Agent Reinforcement Learning. (arXiv:2112.12458v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lequn Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1\">Akshay Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1\">Aleksandrs Slivkins</a>",
          "description": "We consider offline policy optimization (OPO) in contextual bandits, where\none is given a fixed dataset of logged interactions. While pessimistic\nregularizers are typically used to mitigate distribution shift, prior\nimplementations thereof are either specialized or computationally inefficient.\nWe present the first general oracle-efficient algorithm for pessimistic OPO: it\nreduces to supervised learning, leading to broad applicability. We obtain\nstatistical guarantees analogous to those for prior pessimistic approaches. We\ninstantiate our approach for both discrete and continuous actions and perform\nexperiments in both settings, showing advantage over unregularized OPO across a\nwide range of configurations.",
          "link": "http://arxiv.org/abs/2306.07923",
          "publishedOn": "2023-10-28T00:41:29.315Z",
          "wordCount": null,
          "title": "Oracle-Efficient Pessimism: Offline Policy Optimization in Contextual Bandits. (arXiv:2306.07923v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.17281",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sautier_C/0/1/0/all/0/1\">Corentin Sautier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puy_G/0/1/0/all/0/1\">Gilles Puy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boulch_A/0/1/0/all/0/1\">Alexandre Boulch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marlet_R/0/1/0/all/0/1\">Renaud Marlet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lepetit_V/0/1/0/all/0/1\">Vincent Lepetit</a>",
          "description": "We present a surprisingly simple and efficient method for self-supervision of\n3D backbone on automotive Lidar point clouds. We design a contrastive loss\nbetween features of Lidar scans captured in the same scene. Several such\napproaches have been proposed in the literature from PointConstrast, which uses\na contrast at the level of points, to the state-of-the-art TARL, which uses a\ncontrast at the level of segments, roughly corresponding to objects. While the\nformer enjoys a great simplicity of implementation, it is surpassed by the\nlatter, which however requires a costly pre-processing. In BEVContrast, we\ndefine our contrast at the level of 2D cells in the Bird's Eye View plane.\nResulting cell-level representations offer a good trade-off between the\npoint-level representations exploited in PointContrast and segment-level\nrepresentations exploited in TARL: we retain the simplicity of PointContrast\n(cell representations are cheap to compute) while surpassing the performance of\nTARL in downstream semantic segmentation.",
          "link": "http://arxiv.org/abs/2310.17281",
          "publishedOn": "2023-10-28T00:41:29.313Z",
          "wordCount": null,
          "title": "BEVContrast: Self-Supervision in BEV Space for Automotive Lidar Point Clouds. (arXiv:2310.17281v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16912",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Briden_J/0/1/0/all/0/1\">Julia Briden</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Siew_P/0/1/0/all/0/1\">Peng Mun Siew</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rodriguez_Fernandez_V/0/1/0/all/0/1\">Victor Rodriguez-Fernandez</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Linares_R/0/1/0/all/0/1\">Richard Linares</a>",
          "description": "As the peak of the solar cycle approaches in 2025 and the ability of a single\ngeomagnetic storm to significantly alter the orbit of Resident Space Objects\n(RSOs), techniques for atmospheric density forecasting are vital for space\nsituational awareness. While linear data-driven methods, such as dynamic mode\ndecomposition with control (DMDc), have been used previously for forecasting\natmospheric density, deep learning-based forecasting has the ability to capture\nnonlinearities in data. By learning multiple layer weights from historical\natmospheric density data, long-term dependencies in the dataset are captured in\nthe mapping between the current atmospheric density state and control input to\nthe atmospheric density state at the next timestep. This work improves upon\nprevious linear propagation methods for atmospheric density forecasting, by\ndeveloping a nonlinear transformer-based architecture for atmospheric density\nforecasting. Empirical NRLMSISE-00 and JB2008, as well as physics-based TIEGCM\natmospheric density models are compared for forecasting with DMDc and with the\ntransformer-based propagator.",
          "link": "http://arxiv.org/abs/2310.16912",
          "publishedOn": "2023-10-28T00:41:29.290Z",
          "wordCount": 685,
          "title": "Transformer-based Atmospheric Density Forecasting. (arXiv:2310.16912v1 [physics.ao-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Aradhana Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balashankar_A/0/1/0/all/0/1\">Ananth Balashankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avrahami_T/0/1/0/all/0/1\">Thi Avrahami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1\">Alex Beutel</a>",
          "description": "Real-world natural language processing systems need to be robust to human\nadversaries. Collecting examples of human adversaries for training is an\neffective but expensive solution. On the other hand, training on synthetic\nattacks with small perturbations - such as word-substitution - does not\nactually improve robustness to human adversaries. In this paper, we propose an\nadversarial training framework that uses limited human adversarial examples to\ngenerate more useful adversarial examples at scale. We demonstrate the\nadvantages of this system on the ANLI and hate speech detection benchmark\ndatasets - both collected via an iterative, adversarial\nhuman-and-model-in-the-loop procedure. Compared to training only on observed\nhuman attacks, also training on our synthetic adversarial examples improves\nmodel robustness to future rounds. In ANLI, we see accuracy gains on the\ncurrent set of attacks (44.1%$\\,\\to\\,$50.1%) and on two future unseen rounds of\nhuman generated attacks (32.5%$\\,\\to\\,$43.4%, and 29.4%$\\,\\to\\,$40.2%). In hate\nspeech detection, we see AUC gains on current attacks (0.76 $\\to$ 0.84) and a\nfuture round (0.77 $\\to$ 0.79). Attacks from methods that do not learn the\ndistribution of existing human adversaries, meanwhile, degrade robustness.",
          "link": "http://arxiv.org/abs/2310.16955",
          "publishedOn": "2023-10-28T00:41:29.270Z",
          "wordCount": 723,
          "title": "Break it, Imitate it, Fix it: Robustness by Generating Human-Like Attacks. (arXiv:2310.16955v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16986",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gala_G/0/1/0/all/0/1\">Gennaro Gala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campos_C/0/1/0/all/0/1\">Cassio de Campos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peharz_R/0/1/0/all/0/1\">Robert Peharz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vergari_A/0/1/0/all/0/1\">Antonio Vergari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quaeghebeur_E/0/1/0/all/0/1\">Erik Quaeghebeur</a>",
          "description": "Continuous latent variables (LVs) are a key ingredient of many generative\nmodels, as they allow modelling expressive mixtures with an uncountable number\nof components. In contrast, probabilistic circuits (PCs) are hierarchical\ndiscrete mixtures represented as computational graphs composed of input, sum\nand product units. Unlike continuous LV models, PCs provide tractable inference\nbut are limited to discrete LVs with categorical (i.e. unordered) states. We\nbridge these model classes by introducing probabilistic integral circuits\n(PICs), a new language of computational graphs that extends PCs with integral\nunits representing continuous LVs. In the first place, PICs are symbolic\ncomputational graphs and are fully tractable in simple cases where analytical\nintegration is possible. In practice, we parameterise PICs with light-weight\nneural nets delivering an intractable hierarchical continuous mixture that can\nbe approximated arbitrarily well with large PCs using numerical quadrature. On\nseveral distribution estimation benchmarks, we show that such PIC-approximating\nPCs systematically outperform PCs commonly learned via expectation-maximization\nor SGD.",
          "link": "http://arxiv.org/abs/2310.16986",
          "publishedOn": "2023-10-28T00:41:29.260Z",
          "wordCount": 666,
          "title": "Probabilistic Integral Circuits. (arXiv:2310.16986v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16857",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tan_P/0/1/0/all/0/1\">Peiwen Tan</a>",
          "description": "This research underscores the efficacy of Fourier topological optimization in\nrefining MRI imagery, thereby bolstering the classification precision of\nAlzheimer's Disease through convolutional neural networks. Recognizing that MRI\nscans are indispensable for neurological assessments, but frequently grapple\nwith issues like blurriness and contrast irregularities, the deployment of\nFourier topological optimization offered enhanced delineation of brain\nstructures, ameliorated noise, and superior contrast. The applied techniques\nprioritized boundary enhancement, contrast and brightness adjustments, and\noverall image lucidity. Employing CNN architectures VGG16, ResNet50,\nInceptionV3, and Xception, the post-optimization analysis revealed a marked\nelevation in performance. Conclusively, the amalgamation of Fourier topological\noptimization with CNNs delineates a promising trajectory for the nuanced\nclassification of Alzheimer's Disease, portending a transformative impact on\nits diagnostic paradigms.",
          "link": "http://arxiv.org/abs/2310.16857",
          "publishedOn": "2023-10-28T00:41:29.209Z",
          "wordCount": 659,
          "title": "Improvement in Alzheimer's Disease MRI Images Analysis by Convolutional Neural Networks Via Topological Optimization. (arXiv:2310.16857v1 [eess.IV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.13552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsuchida_R/0/1/0/all/0/1\">Russell Tsuchida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_C/0/1/0/all/0/1\">Cheng Soon Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sejdinovic_D/0/1/0/all/0/1\">Dino Sejdinovic</a>",
          "description": "Flexible models for probability distributions are an essential ingredient in\nmany machine learning tasks. We develop and investigate a new class of\nprobability distributions, which we call a Squared Neural Family (SNEFY),\nformed by squaring the 2-norm of a neural network and normalising it with\nrespect to a base measure. Following the reasoning similar to the well\nestablished connections between infinitely wide neural networks and Gaussian\nprocesses, we show that SNEFYs admit closed form normalising constants in many\ncases of interest, thereby resulting in flexible yet fully tractable density\nmodels. SNEFYs strictly generalise classical exponential families, are closed\nunder conditioning, and have tractable marginal distributions. Their utility is\nillustrated on a variety of density estimation, conditional density estimation,\nand density estimation with missing data tasks.",
          "link": "http://arxiv.org/abs/2305.13552",
          "publishedOn": "2023-10-28T00:41:29.202Z",
          "wordCount": null,
          "title": "Squared Neural Families: A New Class of Tractable Density Models. (arXiv:2305.13552v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kelin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yunhai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Matthew Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Ye Zhao</a>",
          "description": "In robotics and artificial intelligence, the integration of tactile\nprocessing is becoming increasingly pivotal, especially in learning to execute\nintricate tasks like alignment and insertion. However, existing works focusing\non tactile methods for insertion tasks predominantly rely on robot\nteleoperation data and reinforcement learning, which do not utilize the rich\ninsights provided by human's control strategy guided by tactile feedback. For\nutilizing human sensations, methodologies related to learning from humans\npredominantly leverage visual feedback, often overlooking the invaluable\ntactile feedback that humans inherently employ to finish complex manipulations.\nAddressing this gap, we introduce \"MimicTouch\", a novel framework that mimics\nhuman's tactile-guided control strategy. In this framework, we initially\ncollect multi-modal tactile datasets from human demonstrators, incorporating\nhuman tactile-guided control strategies for task completion. The subsequent\nstep involves instructing robots through imitation learning using multi-modal\nsensor data and retargeted human motions. To further mitigate the embodiment\ngap between humans and robots, we employ online residual reinforcement learning\non the physical robot. Through comprehensive experiments, we validate the\nsafety of MimicTouch in transferring a latent policy learned through imitation\nlearning from human to robot. This ongoing work will pave the way for a broader\nspectrum of tactile-guided robotic applications.",
          "link": "http://arxiv.org/abs/2310.16917",
          "publishedOn": "2023-10-28T00:41:29.182Z",
          "wordCount": 730,
          "title": "MimicTouch: Learning Human's Control Strategy with Multi-Modal Tactile Feedback. (arXiv:2310.16917v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tunstall_L/0/1/0/all/0/1\">Lewis Tunstall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beeching_E/0/1/0/all/0/1\">Edward Beeching</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lambert_N/0/1/0/all/0/1\">Nathan Lambert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajani_N/0/1/0/all/0/1\">Nazneen Rajani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasul_K/0/1/0/all/0/1\">Kashif Rasul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belkada_Y/0/1/0/all/0/1\">Younes Belkada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shengyi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werra_L/0/1/0/all/0/1\">Leandro von Werra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fourrier_C/0/1/0/all/0/1\">Cl&#xe9;mentine Fourrier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habib_N/0/1/0/all/0/1\">Nathan Habib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarrazin_N/0/1/0/all/0/1\">Nathan Sarrazin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanseviero_O/0/1/0/all/0/1\">Omar Sanseviero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_T/0/1/0/all/0/1\">Thomas Wolf</a>",
          "description": "We aim to produce a smaller language model that is aligned to user intent.\nPrevious research has shown that applying distilled supervised fine-tuning\n(dSFT) on larger models significantly improves task accuracy; however, these\nmodels are unaligned, i.e. they do not respond well to natural prompts. To\ndistill this property, we experiment with the use of preference data from AI\nFeedback (AIF). Starting from a dataset of outputs ranked by a teacher model,\nwe apply distilled direct preference optimization (dDPO) to learn a chat model\nwith significantly improved intent alignment. The approach requires only a few\nhours of training without any additional sampling during fine-tuning. The final\nresult, Zephyr-7B, sets the state-of-the-art on chat benchmarks for 7B\nparameter models, and requires no human annotation. In particular, results on\nMT-Bench show that Zephyr-7B surpasses Llama2-Chat-70B, the best open-access\nRLHF-based model. Code, models, data, and tutorials for the system are\navailable at https://github.com/huggingface/alignment-handbook.",
          "link": "http://arxiv.org/abs/2310.16944",
          "publishedOn": "2023-10-28T00:41:29.167Z",
          "wordCount": 698,
          "title": "Zephyr: Direct Distillation of LM Alignment. (arXiv:2310.16944v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balashankar_A/0/1/0/all/0/1\">Ananth Balashankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Aradhana Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1\">Alex Beutel</a>",
          "description": "As large language models (LLMs) are widely adopted, new safety issues and\npolicies emerge, to which existing safety classifiers do not generalize well.\nIf we have only observed a few examples of violations of a new safety rule, how\ncan we build a classifier to detect violations? In this paper, we study the\nnovel setting of domain-generalized few-shot learning for LLM-based text safety\nclassifiers. Unlike prior few-shot work, these new safety issues can be hard to\nuncover and we do not get to choose the few examples. We demonstrate that\nexisting few-shot techniques do not perform well in this setting, and rather we\npropose to do parameter-efficient fine-tuning (PEFT) combined with augmenting\ntraining data based on similar examples in prior existing rules. We empirically\nshow that our approach of similarity-based data-augmentation + prompt-tuning\n(DAPT) consistently outperforms baselines that either do not rely on data\naugmentation or on PEFT by 7-17% F1 score in the Social Chemistry moral\njudgement and 9-13% AUC in the Toxicity detection tasks, even when the new rule\nis loosely correlated with existing ones.",
          "link": "http://arxiv.org/abs/2310.16959",
          "publishedOn": "2023-10-28T00:41:29.102Z",
          "wordCount": 721,
          "title": "Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning. (arXiv:2310.16959v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16945",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lan_H/0/1/0/all/0/1\">Hui Lan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Syrgkanis_V/0/1/0/all/0/1\">Vasilis Syrgkanis</a>",
          "description": "Accurate estimation of conditional average treatment effects (CATE) is at the\ncore of personalized decision making. While there is a plethora of models for\nCATE estimation, model selection is a nontrivial task, due to the fundamental\nproblem of causal inference. Recent empirical work provides evidence in favor\nof proxy loss metrics with double robust properties and in favor of model\nensembling. However, theoretical understanding is lacking. Direct application\nof prior theoretical work leads to suboptimal oracle model selection rates due\nto the non-convexity of the model selection problem. We provide regret rates\nfor the major existing CATE ensembling approaches and propose a new CATE model\nensembling approach based on Q-aggregation using the doubly robust loss. Our\nmain result shows that causal Q-aggregation achieves statistically optimal\noracle model selection regret rates of $\\frac{\\log(M)}{n}$ (with $M$ models and\n$n$ samples), with the addition of higher-order estimation error terms related\nto products of errors in the nuisance functions. Crucially, our regret rate\ndoes not require that any of the candidate CATE models be close to the truth.\nWe validate our new method on many semi-synthetic datasets and also provide\nextensions of our work to CATE model selection with instrumental variables and\nunobserved confounding.",
          "link": "http://arxiv.org/abs/2310.16945",
          "publishedOn": "2023-10-28T00:41:29.085Z",
          "wordCount": 732,
          "title": "Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinurat_R/0/1/0/all/0/1\">Ray A. O. Sinurat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daram_A/0/1/0/all/0/1\">Anurag Daram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunawi_H/0/1/0/all/0/1\">Haryadi S. Gunawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_R/0/1/0/all/0/1\">Robert B. Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madireddy_S/0/1/0/all/0/1\">Sandeep Madireddy</a>",
          "description": "Machine learning-based performance models are increasingly being used to\nbuild critical job scheduling and application optimization decisions.\nTraditionally, these models assume that data distribution does not change as\nmore samples are collected over time. However, owing to the complexity and\nheterogeneity of production HPC systems, they are susceptible to hardware\ndegradation, replacement, and/or software patches, which can lead to drift in\nthe data distribution that can adversely affect the performance models. To this\nend, we develop continually learning performance models that account for the\ndistribution drift, alleviate catastrophic forgetting, and improve\ngeneralizability. Our best model was able to retain accuracy, regardless of\nhaving to learn the new distribution of data inflicted by system changes, while\ndemonstrating a 2x improvement in the prediction accuracy of the whole data\nsequence in comparison to the naive approach.",
          "link": "http://arxiv.org/abs/2310.16996",
          "publishedOn": "2023-10-28T00:41:29.070Z",
          "wordCount": 690,
          "title": "Towards Continually Learning Application Performance Models. (arXiv:2310.16996v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mattson_C/0/1/0/all/0/1\">Connor Mattson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1\">Jeremy C. Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel S. Brown</a>",
          "description": "We study the problem of determining the emergent behaviors that are possible\ngiven a functionally heterogeneous swarm of robots with limited capabilities.\nPrior work has considered behavior search for homogeneous swarms and proposed\nthe use of novelty search over either a hand-specified or learned behavior\nspace followed by clustering to return a taxonomy of emergent behaviors to the\nuser. In this paper, we seek to better understand the role of novelty search\nand the efficacy of using clustering to discover novel emergent behaviors.\nThrough a large set of experiments and ablations, we analyze the effect of\nrepresentations, evolutionary search, and various clustering methods in the\nsearch for novel behaviors in a heterogeneous swarm. Our results indicate that\nprior methods fail to discover many interesting behaviors and that an iterative\nhuman-in-the-loop discovery process discovers more behaviors than random\nsearch, swarm chemistry, and automated behavior discovery. The combined\ndiscoveries of our experiments uncover 23 emergent behaviors, 18 of which are\nnovel discoveries. To the best of our knowledge, these are the first known\nemergent behaviors for heterogeneous swarms of computation-free agents. Videos,\ncode, and appendix are available at the project website:\nhttps://sites.google.com/view/heterogeneous-bd-methods",
          "link": "http://arxiv.org/abs/2310.16941",
          "publishedOn": "2023-10-28T00:41:29.029Z",
          "wordCount": 746,
          "title": "Exploring Behavior Discovery Methods for Heterogeneous Swarms of Limited-Capability Robots. (arXiv:2310.16941v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhangyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Cheng Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan Z. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Laurence T. Yang</a>",
          "description": "The pre-training architectures of large language models encompass various\ntypes, including autoencoding models, autoregressive models, and\nencoder-decoder models. We posit that any modality can potentially benefit from\na large language model, as long as it undergoes vector quantization to become\ndiscrete tokens. Inspired by GLM, we propose a General Point Model (GPM) which\nseamlessly integrates autoencoding and autoregressive tasks in point cloud\ntransformer. This model is versatile, allowing fine-tuning for downstream point\ncloud representation tasks, as well as unconditional and conditional generation\ntasks. GPM enhances masked prediction in autoencoding through various forms of\nmask padding tasks, leading to improved performance in point cloud\nunderstanding. Additionally, GPM demonstrates highly competitive results in\nunconditional point cloud generation tasks, even exhibiting the potential for\nconditional generation tasks by modifying the input's conditional information.\nCompared to models like Point-BERT, MaskPoint and PointMAE, our GPM achieves\nsuperior performance in point cloud understanding tasks. Furthermore, the\nintegration of autoregressive and autoencoding within the same transformer\nunderscores its versatility across different downstream tasks.",
          "link": "http://arxiv.org/abs/2310.16861",
          "publishedOn": "2023-10-28T00:41:29.022Z",
          "wordCount": 721,
          "title": "General Point Model with Autoencoding and Autoregressive. (arXiv:2310.16861v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Haizhou Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>",
          "description": "Domain incremental learning aims to adapt to a sequence of domains with\naccess to only a small subset of data (i.e., memory) from previous domains.\nVarious methods have been proposed for this problem, but it is still unclear\nhow they are related and when practitioners should choose one method over\nanother. In response, we propose a unified framework, dubbed Unified Domain\nIncremental Learning (UDIL), for domain incremental learning with memory. Our\nUDIL **unifies** various existing methods, and our theoretical analysis shows\nthat UDIL always achieves a tighter generalization error bound compared to\nthese methods. The key insight is that different existing methods correspond to\nour bound with different **fixed** coefficients; based on insights from this\nunification, our UDIL allows **adaptive** coefficients during training, thereby\nalways achieving the tightest bound. Empirical results show that our UDIL\noutperforms the state-of-the-art domain incremental learning methods on both\nsynthetic and real-world datasets. Code will be available at\nhttps://github.com/Wang-ML-Lab/unified-continual-learning.",
          "link": "http://arxiv.org/abs/2310.12244",
          "publishedOn": "2023-10-21T00:41:44.691Z",
          "wordCount": 682,
          "title": "A Unified Approach to Domain Incremental Learning with Memory: Theory and Algorithm. (arXiv:2310.12244v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balin_M/0/1/0/all/0/1\">Muhammed Fatih Balin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LaSalle_D/0/1/0/all/0/1\">Dominique LaSalle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catalyurek_U/0/1/0/all/0/1\">&#xdc;mit V. &#xc7;ataly&#xfc;rek</a>",
          "description": "Significant computational resources are required to train Graph Neural\nNetworks (GNNs) at a large scale, and the process is highly data-intensive. One\nof the most effective ways to reduce resource requirements is minibatch\ntraining coupled with graph sampling. GNNs have the unique property that items\nin a minibatch have overlapping data. However, the commonly implemented\nIndependent Minibatching approach assigns each Processing Element (PE) its own\nminibatch to process, leading to duplicated computations and input data access\nacross PEs. This amplifies the Neighborhood Explosion Phenomenon (NEP), which\nis the main bottleneck limiting scaling. To reduce the effects of NEP in the\nmulti-PE setting, we propose a new approach called Cooperative Minibatching.\nOur approach capitalizes on the fact that the size of the sampled subgraph is a\nconcave function of the batch size, leading to significant reductions in the\namount of work per seed vertex as batch sizes increase. Hence, it is favorable\nfor processors equipped with a fast interconnect to work on a large minibatch\ntogether as a single larger processor, instead of working on separate smaller\nminibatches, even though global batch size is identical. We also show how to\ntake advantage of the same phenomenon in serial execution by generating\ndependent consecutive minibatches. Our experimental evaluations show up to 4x\nbandwidth savings for fetching vertex embeddings, by simply increasing this\ndependency without harming model convergence. Combining our proposed\napproaches, we achieve up to 64% speedup over Independent Minibatching on\nsingle-node multi-GPU systems.",
          "link": "http://arxiv.org/abs/2310.12403",
          "publishedOn": "2023-10-21T00:41:44.683Z",
          "wordCount": 750,
          "title": "Cooperative Minibatching in Graph Neural Networks. (arXiv:2310.12403v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12442",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_D/0/1/0/all/0/1\">Dhananjay Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hawkins_C/0/1/0/all/0/1\">Cole Hawkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_S/0/1/0/all/0/1\">Sheng Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>",
          "description": "Pretrained transformer models have demonstrated remarkable performance across\nvarious natural language processing tasks. These models leverage the attention\nmechanism to capture long- and short-range dependencies in the sequence.\nHowever, the (full) attention mechanism incurs high computational cost -\nquadratic in the sequence length, which is not affordable in tasks with long\nsequences, e.g., inputs with 8k tokens. Although sparse attention can be used\nto improve computational efficiency, as suggested in existing work, it has\nlimited modeling capacity and often fails to capture complicated dependencies\nin long sequences. To tackle this challenge, we propose MASFormer, an\neasy-to-implement transformer variant with Mixed Attention Spans. Specifically,\nMASFormer is equipped with full attention to capture long-range dependencies,\nbut only at a small number of layers. For the remaining layers, MASformer only\nemploys sparse attention to capture short-range dependencies. Our experiments\non natural language modeling and generation tasks show that a decoder-only\nMASFormer model of 1.3B parameters can achieve competitive performance to\nvanilla transformers with full attention while significantly reducing\ncomputational cost (up to 75%). Additionally, we investigate the effectiveness\nof continual training with long sequence data and how sequence length impacts\ndownstream generation performance, which may be of independent interest.",
          "link": "http://arxiv.org/abs/2310.12442",
          "publishedOn": "2023-10-21T00:41:44.676Z",
          "wordCount": 739,
          "title": "Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer. (arXiv:2310.12442v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giambagli_L/0/1/0/all/0/1\">Lorenzo Giambagli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buffoni_L/0/1/0/all/0/1\">Lorenzo Buffoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chicchi_L/0/1/0/all/0/1\">Lorenzo Chicchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fanelli_D/0/1/0/all/0/1\">Duccio Fanelli</a>",
          "description": "In theoretical ML, the teacher-student paradigm is often employed as an\neffective metaphor for real-life tuition. The above scheme proves particularly\nrelevant when the student network is overparameterized as compared to the\nteacher network. Under these operating conditions, it is tempting to speculate\nthat the student ability to handle the given task could be eventually stored in\na sub-portion of the whole network. This latter should be to some extent\nreminiscent of the frozen teacher structure, according to suitable metrics,\nwhile being approximately invariant across different architectures of the\nstudent candidate network. Unfortunately, state-of-the-art conventional\nlearning techniques could not help in identifying the existence of such an\ninvariant subnetwork, due to the inherent degree of non-convexity that\ncharacterizes the examined problem. In this work, we take a leap forward by\nproposing a radically different optimization scheme which builds on a spectral\nrepresentation of the linear transfer of information between layers. The\ngradient is hence calculated with respect to both eigenvalues and eigenvectors\nwith negligible increase in terms of computational and complexity load, as\ncompared to standard training algorithms. Working in this framework, we could\nisolate a stable student substructure, that mirrors the true complexity of the\nteacher in terms of computing neurons, path distribution and topological\nattributes. When pruning unimportant nodes of the trained student, as follows a\nranking that reflects the optimized eigenvalues, no degradation in the recorded\nperformance is seen above a threshold that corresponds to the effective teacher\nsize. The observed behavior can be pictured as a genuine second-order phase\ntransition that bears universality traits.",
          "link": "http://arxiv.org/abs/2310.12612",
          "publishedOn": "2023-10-21T00:41:44.669Z",
          "wordCount": 805,
          "title": "How a student becomes a teacher: learning and forgetting through Spectral methods. (arXiv:2310.12612v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanno_R/0/1/0/all/0/1\">Ryutaro Tanno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saseendran_A/0/1/0/all/0/1\">Amrutha Saseendran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diethe_T/0/1/0/all/0/1\">Tom Diethe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teare_P/0/1/0/all/0/1\">Philip Teare</a>",
          "description": "Textural Inversion, a prompt learning method, learns a singular embedding for\na new \"word\" to represent image style and appearance, allowing it to be\nintegrated into natural language sentences to generate novel synthesised\nimages. However, identifying and integrating multiple object-level concepts\nwithin one scene poses significant challenges even when embeddings for\nindividual concepts are attainable. This is further confirmed by our empirical\ntests. To address this challenge, we introduce a framework for Multi-Concept\nPrompt Learning (MCPL), where multiple new \"words\" are simultaneously learned\nfrom a single sentence-image pair. To enhance the accuracy of word-concept\ncorrelation, we propose three regularisation techniques: Attention Masking\n(AttnMask) to concentrate learning on relevant areas; Prompts Contrastive Loss\n(PromptCL) to separate the embeddings of different concepts; and Bind adjective\n(Bind adj.) to associate new \"words\" with known words. We evaluate via image\ngeneration, editing, and attention visualisation with diverse images. Extensive\nquantitative comparisons demonstrate that our method can learn more\nsemantically disentangled concepts with enhanced word-concept correlation.\nAdditionally, we introduce a novel dataset and evaluation protocol tailored for\nthis new task of learning object-level concepts.",
          "link": "http://arxiv.org/abs/2310.12274",
          "publishedOn": "2023-10-21T00:41:44.653Z",
          "wordCount": 728,
          "title": "An Image is Worth Multiple Words: Learning Object Level Concepts using Multi-Concept Prompt Learning. (arXiv:2310.12274v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bernasconi_M/0/1/0/all/0/1\">Martino Bernasconi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castiglioni_M/0/1/0/all/0/1\">Matteo Castiglioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celli_A/0/1/0/all/0/1\">Andrea Celli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1\">Federico Fusco</a>",
          "description": "Bilateral trade revolves around the challenge of facilitating transactions\nbetween two strategic agents -- a seller and a buyer -- both of whom have a\nprivate valuations for the item. We study the online version of the problem, in\nwhich at each time step a new seller and buyer arrive. The learner's task is to\nset a price for each agent, without any knowledge about their valuations. The\nsequence of sellers and buyers is chosen by an oblivious adversary. In this\nsetting, known negative results rule out the possibility of designing\nalgorithms with sublinear regret when the learner has to guarantee budget\nbalance for each iteration. In this paper, we introduce the notion of global\nbudget balance, which requires the agent to be budget balance only over the\nentire time horizon. By requiring global budget balance, we provide the first\nno-regret algorithms for bilateral trade with adversarial inputs under various\nfeedback models. First, we show that in the full-feedback model the learner can\nguarantee $\\tilde{O}(\\sqrt{T})$ regret against the best fixed prices in\nhindsight, which is order-wise optimal. Then, in the case of partial feedback\nmodels, we provide an algorithm guaranteeing a $\\tilde{O}(T^{3/4})$ regret\nupper bound with one-bit feedback, which we complement with a nearly-matching\nlower bound. Finally, we investigate how these results vary when measuring\nregret using an alternative benchmark.",
          "link": "http://arxiv.org/abs/2310.12370",
          "publishedOn": "2023-10-21T00:41:44.647Z",
          "wordCount": 731,
          "title": "No-Regret Learning in Bilateral Trade via Global Budget Balance. (arXiv:2310.12370v1 [cs.GT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Md Rashedul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiawei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_I/0/1/0/all/0/1\">Iftekhar Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagheri_H/0/1/0/all/0/1\">Hamid Bagheri</a>",
          "description": "The growing adoption of declarative software specification languages, coupled\nwith their inherent difficulty in debugging, has underscored the need for\neffective and automated repair techniques applicable to such languages.\nResearchers have recently explored various methods to automatically repair\ndeclarative software specifications, such as template-based repair,\nfeedback-driven iterative repair, and bounded exhaustive approaches. The latest\ndevelopments in large language models provide new opportunities for the\nautomatic repair of declarative specifications. In this study, we assess the\neffectiveness of utilizing OpenAI's ChatGPT to repair software specifications\nwritten in the Alloy declarative language. Unlike imperative languages,\nspecifications in Alloy are not executed but rather translated into logical\nformulas and evaluated using backend constraint solvers to identify\nspecification instances and counterexamples to assertions. Our evaluation\nfocuses on ChatGPT's ability to improve the correctness and completeness of\nAlloy declarative specifications through automatic repairs. We analyze the\nresults produced by ChatGPT and compare them with those of leading automatic\nAlloy repair methods. Our study revealed that while ChatGPT falls short in\ncomparison to existing techniques, it was able to successfully repair bugs that\nno other technique could address. Our analysis also identified errors in\nChatGPT's generated repairs, including improper operator usage, type errors,\nhigher-order logic misuse, and relational arity mismatches. Additionally, we\nobserved instances of hallucinations in ChatGPT-generated repairs and\ninconsistency in its results. Our study provides valuable insights for software\npractitioners, researchers, and tool builders considering ChatGPT for\ndeclarative specification repairs.",
          "link": "http://arxiv.org/abs/2310.12425",
          "publishedOn": "2023-10-21T00:41:44.641Z",
          "wordCount": 773,
          "title": "Automated Repair of Declarative Software Specifications in the Era of Large Language Models. (arXiv:2310.12425v1 [cs.SE])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12407",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xianglong Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zengfu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Q/0/1/0/all/0/1\">Quan Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_T/0/1/0/all/0/1\">Tao Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_H/0/1/0/all/0/1\">Hua Lan</a>",
          "description": "We address the challenge of tracking an unknown number of targets in strong\nclutter environments using measurements from a radar sensor. Leveraging the\nrange-Doppler spectra information, we identify the measurement classes, which\nserve as additional information to enhance clutter rejection and data\nassociation, thus bolstering the robustness of target tracking. We first\nintroduce a novel neural enhanced message passing approach, where the beliefs\nobtained by the unified message passing are fed into the neural network as\nadditional information. The output beliefs are then utilized to refine the\noriginal beliefs. Then, we propose a classification-aided robust multiple\ntarget tracking algorithm, employing the neural enhanced message passing\ntechnique. This algorithm is comprised of three modules: a message-passing\nmodule, a neural network module, and a Dempster-Shafer module. The\nmessage-passing module is used to represent the statistical model by the factor\ngraph and infers target kinematic states, visibility states, and data\nassociations based on the spatial measurement information. The neural network\nmodule is employed to extract features from range-Doppler spectra and derive\nbeliefs on whether a measurement is target-generated or clutter-generated. The\nDempster-Shafer module is used to fuse the beliefs obtained from both the\nfactor graph and the neural network. As a result, our proposed algorithm adopts\na model-and-data-driven framework, effectively enhancing clutter suppression\nand data association, leading to significant improvements in multiple target\ntracking performance. We validate the effectiveness of our approach using both\nsimulated and real data scenarios, demonstrating its capability to handle\nchallenging tracking scenarios in practical radar applications.",
          "link": "http://arxiv.org/abs/2310.12407",
          "publishedOn": "2023-10-21T00:41:44.634Z",
          "wordCount": 791,
          "title": "Classification-Aided Robust Multiple Target Tracking Using Neural Enhanced Message Passing. (arXiv:2310.12407v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Josef Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xuehai Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruiyang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jiaming Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xinbo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mickel Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>",
          "description": "With the development of large language models (LLMs), striking a balance\nbetween the performance and safety of AI systems has never been more critical.\nHowever, the inherent tension between the objectives of helpfulness and\nharmlessness presents a significant challenge during LLM training. To address\nthis issue, we propose Safe Reinforcement Learning from Human Feedback (Safe\nRLHF), a novel algorithm for human value alignment. Safe RLHF explicitly\ndecouples human preferences regarding helpfulness and harmlessness, effectively\navoiding the crowdworkers' confusion about the tension and allowing us to train\nseparate reward and cost models. We formalize the safety concern of LLMs as an\noptimization task of maximizing the reward function while satisfying specified\ncost constraints. Leveraging the Lagrangian method to solve this constrained\nproblem, Safe RLHF dynamically adjusts the balance between the two objectives\nduring fine-tuning. Through a three-round fine-tuning using Safe RLHF, we\ndemonstrate a superior ability to mitigate harmful responses while enhancing\nmodel performance compared to existing value-aligned algorithms.\nExperimentally, we fine-tuned the Alpaca-7B using Safe RLHF and aligned it with\ncollected human preferences, significantly improving its helpfulness and\nharmlessness according to human evaluations.",
          "link": "http://arxiv.org/abs/2310.12773",
          "publishedOn": "2023-10-21T00:41:44.627Z",
          "wordCount": 692,
          "title": "Safe RLHF: Safe Reinforcement Learning from Human Feedback. (arXiv:2310.12773v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12209",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Shih_D/0/1/0/all/0/1\">David Shih</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Freytsis_M/0/1/0/all/0/1\">Marat Freytsis</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Taylor_S/0/1/0/all/0/1\">Stephen R. Taylor</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Dror_J/0/1/0/all/0/1\">Jeff A. Dror</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Smyth_N/0/1/0/all/0/1\">Nolan Smyth</a>",
          "description": "Pulsar timing arrays (PTAs) perform Bayesian posterior inference with\nexpensive MCMC methods. Given a dataset of ~10-100 pulsars and O(10^3) timing\nresiduals each, producing a posterior distribution for the stochastic\ngravitational wave background (SGWB) can take days to a week. The computational\nbottleneck arises because the likelihood evaluation required for MCMC is\nextremely costly when considering the dimensionality of the search space.\nFortunately, generating simulated data is fast, so modern simulation-based\ninference techniques can be brought to bear on the problem. In this paper, we\ndemonstrate how conditional normalizing flows trained on simulated data can be\nused for extremely fast and accurate estimation of the SGWB posteriors,\nreducing the sampling time from weeks to a matter of seconds.",
          "link": "http://arxiv.org/abs/2310.12209",
          "publishedOn": "2023-10-21T00:41:44.609Z",
          "wordCount": 670,
          "title": "Fast Parameter Inference on Pulsar Timing Arrays with Normalizing Flows. (arXiv:2310.12209v1 [astro-ph.IM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haitian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Renjie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xiao Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zhenkun Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Minjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1\">David Wipf</a>",
          "description": "Among the many variants of graph neural network (GNN) architectures capable\nof modeling data with cross-instance relations, an important subclass involves\nlayers designed such that the forward pass iteratively reduces a\ngraph-regularized energy function of interest. In this way, node embeddings\nproduced at the output layer dually serve as both predictive features for\nsolving downstream tasks (e.g., node classification) and energy function\nminimizers that inherit desirable inductive biases and interpretability.\nHowever, scaling GNN architectures constructed in this way remains challenging,\nin part because the convergence of the forward pass may involve models with\nconsiderable depth. To tackle this limitation, we propose a sampling-based\nenergy function and scalable GNN layers that iteratively reduce it, guided by\nconvergence guarantees in certain settings. We also instantiate a full GNN\narchitecture based on these designs, and the model achieves competitive\naccuracy and scalability when applied to the largest publicly-available node\nclassification benchmark exceeding 1TB in size.",
          "link": "http://arxiv.org/abs/2310.12457",
          "publishedOn": "2023-10-21T00:41:44.160Z",
          "wordCount": 667,
          "title": "MuseGNN: Interpretable and Convergent Graph Neural Network Layers at Scale. (arXiv:2310.12457v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scarvelis_C/0/1/0/all/0/1\">Christopher Scarvelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borde_H/0/1/0/all/0/1\">Haitz S&#xe1;ez de Oc&#xe1;riz Borde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1\">Justin Solomon</a>",
          "description": "Score-based generative models (SGMs) sample from a target distribution by\niteratively transforming noise using the score function of the perturbed\ntarget. For any finite training set, this score function can be evaluated in\nclosed form, but the resulting SGM memorizes its training data and does not\ngenerate novel samples. In practice, one approximates the score by training a\nneural network via score-matching. The error in this approximation promotes\ngeneralization, but neural SGMs are costly to train and sample, and the\neffective regularization this error provides is not well-understood\ntheoretically. In this work, we instead explicitly smooth the closed-form score\nto obtain an SGM that generates novel samples without training. We analyze our\nmodel and propose an efficient nearest-neighbor-based estimator of its score\nfunction. Using this estimator, our method achieves sampling times competitive\nwith neural SGMs while running on consumer-grade CPUs.",
          "link": "http://arxiv.org/abs/2310.12395",
          "publishedOn": "2023-10-21T00:41:44.146Z",
          "wordCount": 634,
          "title": "Closed-Form Diffusion Models. (arXiv:2310.12395v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khatri_M/0/1/0/all/0/1\">Mann Khatri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yusuf_M/0/1/0/all/0/1\">Mirza Yusuf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_Y/0/1/0/all/0/1\">Yaman Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1\">Ponnurangam Kumaraguru</a>",
          "description": "The burdensome impact of a skewed judges-to-cases ratio on the judicial\nsystem manifests in an overwhelming backlog of pending cases alongside an\nongoing influx of new ones. To tackle this issue and expedite the judicial\nprocess, the proposition of an automated system capable of suggesting case\noutcomes based on factual evidence and precedent from past cases gains\nsignificance. This research paper centres on developing a graph neural\nnetwork-based model to address the Legal Judgment Prediction (LJP) problem,\nrecognizing the intrinsic graph structure of judicial cases and making it a\nbinary node classification problem. We explored various embeddings as model\nfeatures, while nodes such as time nodes and judicial acts were added and\npruned to evaluate the model's performance. The study is done while considering\nthe ethical dimension of fairness in these predictions, considering gender and\nname biases. A link prediction task is also conducted to assess the model's\nproficiency in anticipating connections between two specified nodes. By\nharnessing the capabilities of graph neural networks and incorporating fairness\nanalyses, this research aims to contribute insights towards streamlining the\nadjudication process, enhancing judicial efficiency, and fostering a more\nequitable legal landscape, ultimately alleviating the strain imposed by\nmounting case backlogs. Our best-performing model with XLNet pre-trained\nembeddings as its features gives the macro F1 score of 75% for the LJP task.\nFor link prediction, the same set of features is the best performing giving ROC\nof more than 80%",
          "link": "http://arxiv.org/abs/2310.12800",
          "publishedOn": "2023-10-21T00:41:43.292Z",
          "wordCount": null,
          "title": "Exploring Graph Neural Networks for Indian Legal Judgment Prediction. (arXiv:2310.12800v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.10170",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kaplan_D/0/1/0/all/0/1\">David L. Kaplan</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Buehler_M/0/1/0/all/0/1\">Markus J. Buehler</a>",
          "description": "Spider silks are remarkable materials characterized by superb mechanical\nproperties such as strength, extensibility and lightweightedness. Yet, to date,\nlimited models are available to fully explore sequence-property relationships\nfor analysis and design. Here we propose a custom generative large-language\nmodel to enable design of novel spider silk protein sequences to meet complex\ncombinations of target mechanical properties. The model, pretrained on a large\nset of protein sequences, is fine-tuned on ~1,000 major ampullate spidroin\n(MaSp) sequences for which associated fiber-level mechanical properties exist,\nto yield an end-to-end forward and inverse generative strategy. Performance is\nassessed through: (1), a novelty analysis and protein type classification for\ngenerated spidroin sequences through BLAST searches, (2) property evaluation\nand comparison with similar sequences, (3) comparison of molecular structures,\nas well as, and (4) a detailed sequence motif analyses. We generate silk\nsequences with property combinations that do not exist in nature, and develop a\ndeep understanding the mechanistic roles of sequence patterns in achieving\noverarching key mechanical properties (elastic modulus, strength, toughness,\nfailure strain). The model provides an efficient approach to expand the silkome\ndataset, facilitating further sequence-structure analyses of silks, and\nestablishes a foundation for synthetic silk design and optimization.",
          "link": "http://arxiv.org/abs/2309.10170",
          "publishedOn": "2023-10-21T00:41:43.278Z",
          "wordCount": null,
          "title": "Generative modeling, design and analysis of spider silk protein sequences for enhanced mechanical properties. (arXiv:2309.10170v1 [cond-mat.mtrl-sci] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zilong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birke_R/0/1/0/all/0/1\">Robert Birke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lydia Chen</a>",
          "description": "Given the ubiquitous use of tabular data in industries and the growing\nconcerns in data privacy and security, tabular data synthesis emerges as a\ncritical research area. The recent state-of-the-art methods show that large\nlanguage models (LLMs) can be adopted to generate realistic tabular data. As\nLLMs pre-process tabular data as full text, they have the advantage of avoiding\nthe curse of dimensionality associated with one-hot encoding high-dimensional\ndata. However, their long training time and limited re-usability on new tasks\nprevent them from replacing exiting tabular generative models. In this paper,\nwe propose Tabula, a tabular data synthesizer based on the language model\nstructure. Through Tabula, we demonstrate the inherent limitation of employing\npre-trained language models designed for natural language processing (NLP) in\nthe context of tabular data synthesis. Our investigation delves into the\ndevelopment of a dedicated foundational model tailored specifically for tabular\ndata synthesis. Additionally, we propose a token sequence compression strategy\nto significantly reduce training time while preserving the quality of synthetic\ndata. Extensive experiments on six datasets demonstrate that using a language\nmodel structure without loading the well-trained model weights yields a better\nstarting model for tabular data synthesis. Moreover, the Tabula model,\npreviously trained on other tabular data, serves as an excellent foundation\nmodel for new tabular data synthesis tasks. Additionally, the token sequence\ncompression method substantially reduces the model's training time. Results\nshow that Tabula averagely reduces 46.2% training time per epoch comparing to\ncurrent LLMs-based state-of-the-art algorithm and consistently achieves even\nhigher synthetic data utility.",
          "link": "http://arxiv.org/abs/2310.12746",
          "publishedOn": "2023-10-21T00:41:43.277Z",
          "wordCount": null,
          "title": "TabuLa: Harnessing Language Models for Tabular Data Synthesis. (arXiv:2310.12746v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lazarsfeld_J/0/1/0/all/0/1\">John Lazarsfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>",
          "description": "We study a distributed multi-armed bandit setting among a population of $n$\nmemory-constrained nodes in the gossip model: at each round, every node locally\nadopts one of $m$ arms, observes a reward drawn from the arm's (adversarially\nchosen) distribution, and then communicates with a randomly sampled neighbor,\nexchanging information to determine its policy in the next round. We introduce\nand analyze several families of dynamics for this task that are decentralized:\neach node's decision is entirely local and depends only on its most recently\nobtained reward and that of the neighbor it sampled. We show a connection\nbetween the global evolution of these decentralized dynamics with a certain\nclass of \"zero-sum\" multiplicative weights update algorithms, and we develop a\ngeneral framework for analyzing the population-level regret of these natural\nprotocols. Using this framework, we derive sublinear regret bounds under a wide\nrange of parameter regimes (i.e., the size of the population and number of\narms) for both the stationary reward setting (where the mean of each arm's\ndistribution is fixed over time) and the adversarial reward setting (where\nmeans can vary over time). Further, we show that these protocols can\napproximately optimize convex functions over the simplex when the reward\ndistributions are generated from a stochastic gradient oracle.",
          "link": "http://arxiv.org/abs/2306.08670",
          "publishedOn": "2023-10-21T00:41:43.277Z",
          "wordCount": null,
          "title": "The Power of Populations in Decentralized Learning Dynamics. (arXiv:2306.08670v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shomer_H/0/1/0/all/0/1\">Harry Shomer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Haitao Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanhui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bo Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>",
          "description": "Link prediction is a common task on graph-structured data that has seen\napplications in a variety of domains. Classically, hand-crafted heuristics were\nused for this task. Heuristic measures are chosen such that they correlate well\nwith the underlying factors related to link formation. In recent years, a new\nclass of methods has emerged that combines the advantages of message-passing\nneural networks (MPNN) and heuristics methods. These methods perform\npredictions by using the output of an MPNN in conjunction with a \"pairwise\nencoding\" that captures the relationship between nodes in the candidate link.\nThey have been shown to achieve strong performance on numerous datasets.\nHowever, current pairwise encodings often contain a strong inductive bias,\nusing the same underlying factors to classify all links. This limits the\nability of existing methods to learn how to properly classify a variety of\ndifferent links that may form from different factors. To address this\nlimitation, we propose a new method, LPFormer, which attempts to adaptively\nlearn the pairwise encodings for each link. LPFormer models the link factors\nvia an attention module that learns the pairwise encoding that exists between\nnodes by modeling multiple factors integral to link prediction. Extensive\nexperiments demonstrate that LPFormer can achieve SOTA performance on numerous\ndatasets while maintaining efficiency.",
          "link": "http://arxiv.org/abs/2310.11009",
          "publishedOn": "2023-10-21T00:41:43.277Z",
          "wordCount": null,
          "title": "Adaptive Pairwise Encodings for Link Prediction. (arXiv:2310.11009v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.03659",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hubert_N/0/1/0/all/0/1\">Nicolas Hubert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1\">Heiko Paulheim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monnin_P/0/1/0/all/0/1\">Pierre Monnin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brun_A/0/1/0/all/0/1\">Armelle Brun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monticolo_D/0/1/0/all/0/1\">Davy Monticolo</a>",
          "description": "Knowledge graph embedding models (KGEMs) have gained considerable traction in\nrecent years. These models learn a vector representation of knowledge graph\nentities and relations, a.k.a. knowledge graph embeddings (KGEs). Learning\nversatile KGEs is desirable as it makes them useful for a broad range of tasks.\nHowever, KGEMs are usually trained for a specific task, which makes their\nembeddings task-dependent. In parallel, the widespread assumption that KGEMs\nactually create a semantic representation of the underlying entities and\nrelations (e.g., project similar entities closer than dissimilar ones) has been\nchallenged. In this work, we design heuristics for generating protographs --\nsmall, modified versions of a KG that leverage RDF/S information. The learnt\nprotograph-based embeddings are meant to encapsulate the semantics of a KG, and\ncan be leveraged in learning KGEs that, in turn, also better capture semantics.\nExtensive experiments on various evaluation benchmarks demonstrate the\nsoundness of this approach, which we call Modular and Agnostic SCHema-based\nIntegration of protograph Embeddings (MASCHInE). In particular, MASCHInE helps\nproduce more versatile KGEs that yield substantially better performance for\nentity clustering and node classification tasks. For link prediction, using\nMASCHinE substantially increases the number of semantically valid predictions\nwith equivalent rank-based performance.",
          "link": "http://arxiv.org/abs/2306.03659",
          "publishedOn": "2023-10-21T00:41:43.275Z",
          "wordCount": null,
          "title": "Schema First! Learn Versatile Knowledge Graph Embeddings by Capturing Semantics with MASCHInE. (arXiv:2306.03659v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.12129",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Aigner_R/0/1/0/all/0/1\">Roland Aigner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stockl_A/0/1/0/all/0/1\">Andreas St&#xf6;ckl</a>",
          "description": "Knitted sensors frequently suffer from inconsistencies due to innate effects\nsuch as offset, relaxation, and drift. These properties, in combination, make\nit challenging to reliably map from sensor data to physical actuation. In this\npaper, we demonstrate a method for counteracting this by applying processing\nusing a minimal artificial neural network (ANN) in combination with\nstraightforward pre-processing. We apply a number of exponential smoothing\nfilters on a re-sampled sensor signal, to produce features that preserve\ndifferent levels of historical sensor data and, in combination, represent an\nadequate state of previous sensor actuation. By training a three-layer ANN with\na total of 8 neurons, we manage to significantly improve the mapping between\nsensor reading and actuation force. Our findings also show that our technique\ntranslates to sensors of reasonably different composition in terms of material\nand structure, and it can furthermore be applied to related physical features\nsuch as strain.",
          "link": "http://arxiv.org/abs/2306.12129",
          "publishedOn": "2023-10-21T00:41:43.275Z",
          "wordCount": null,
          "title": "Machine Learning Based Compensation for Inconsistencies in Knitted Force Sensors. (arXiv:2306.12129v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meidani_K/0/1/0/all/0/1\">Kazem Meidani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shojaee_P/0/1/0/all/0/1\">Parshin Shojaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1\">Chandan K. Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1\">Amir Barati Farimani</a>",
          "description": "In an era where symbolic mathematical equations are indispensable for\nmodeling complex natural phenomena, scientific inquiry often involves\ncollecting observations and translating them into mathematical expressions.\nRecently, deep learning has emerged as a powerful tool for extracting insights\nfrom data. However, existing models typically specialize in either numeric or\nsymbolic domains, and are usually trained in a supervised manner tailored to\nspecific tasks. This approach neglects the substantial benefits that could\narise from a task-agnostic unified understanding between symbolic equations and\ntheir numeric counterparts. To bridge the gap, we introduce SNIP, a\nSymbolic-Numeric Integrated Pre-training, which employs joint contrastive\nlearning between symbolic and numeric domains, enhancing their mutual\nsimilarities in the pre-trained embeddings. By performing latent space\nanalysis, we observe that SNIP provides cross-domain insights into the\nrepresentations, revealing that symbolic supervision enhances the embeddings of\nnumeric data and vice versa. We evaluate SNIP across diverse tasks, including\nsymbolic-to-numeric mathematical property prediction and numeric-to-symbolic\nequation discovery, commonly known as symbolic regression. Results show that\nSNIP effectively transfers to various tasks, consistently outperforming fully\nsupervised baselines and competing strongly with established task-specific\nmethods, especially in few-shot learning scenarios where available data is\nlimited.",
          "link": "http://arxiv.org/abs/2310.02227",
          "publishedOn": "2023-10-21T00:41:43.274Z",
          "wordCount": null,
          "title": "SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training. (arXiv:2310.02227v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiaobin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Benben Jiang</a>",
          "description": "Bayesian optimization (BO) is widely used for black-box optimization\nproblems, and have been shown to perform well in various real-world tasks.\nHowever, most of the existing BO methods aim to learn the optimal solution,\nwhich may become infeasible when the parameter space is extremely large or the\nproblem is time-sensitive. In these contexts, switching to a satisficing\nsolution that requires less information can result in better performance. In\nthis work, we focus on time-sensitive black-box optimization problems and\npropose satisficing Thompson sampling-based parallel Bayesian optimization\n(STS-PBO) approaches, including synchronous and asynchronous versions. We shift\nthe target from an optimal solution to a satisficing solution that is easier to\nlearn. The rate-distortion theory is introduced to construct a loss function\nthat balances the amount of information that needs to be learned with\nsub-optimality, and the Blahut-Arimoto algorithm is adopted to compute the\ntarget solution that reaches the minimum information rate under the distortion\nlimit at each step. Both discounted and undiscounted Bayesian cumulative regret\nbounds are theoretically derived for the proposed STS-PBO approaches. The\neffectiveness of the proposed methods is demonstrated on a fast-charging design\nproblem of Lithium-ion batteries. The results are accordant with theoretical\nanalyses, and show that our STS-PBO methods outperform both sequential\ncounterparts and parallel BO with traditional Thompson sampling in both\nsynchronous and asynchronous settings.",
          "link": "http://arxiv.org/abs/2310.12526",
          "publishedOn": "2023-10-21T00:41:43.223Z",
          "wordCount": null,
          "title": "Parallel Bayesian Optimization Using Satisficing Thompson Sampling for Time-Sensitive Black-Box Optimization. (arXiv:2310.12526v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12447",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_A/0/1/0/all/0/1\">Abhisek Chakraborty</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Anirban Bhattacharya</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pati_D/0/1/0/all/0/1\">Debdeep Pati</a>",
          "description": "We commonly encounter the problem of identifying an optimally weight adjusted\nversion of the empirical distribution of observed data, adhering to predefined\nconstraints on the weights. Such constraints often manifest as restrictions on\nthe moments, tail behaviour, shapes, number of modes, etc., of the resulting\nweight adjusted empirical distribution. In this article, we substantially\nenhance the flexibility of such methodology by introducing a nonparametrically\nimbued distributional constraints on the weights, and developing a general\nframework leveraging the maximum entropy principle and tools from optimal\ntransport. The key idea is to ensure that the maximum entropy weight adjusted\nempirical distribution of the observed data is close to a pre-specified\nprobability distribution in terms of the optimal transport metric while\nallowing for subtle departures. The versatility of the framework is\ndemonstrated in the context of three disparate applications where data\nre-weighting is warranted to satisfy side constraints on the optimization\nproblem at the heart of the statistical task: namely, portfolio allocation,\nsemi-parametric inference for complex surveys, and ensuring algorithmic\nfairness in machine learning algorithms.",
          "link": "http://arxiv.org/abs/2310.12447",
          "publishedOn": "2023-10-21T00:41:43.220Z",
          "wordCount": null,
          "title": "Constrained Reweighting of Distributions: an Optimal Transport Approach. (arXiv:2310.12447v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12069",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Tanoglidis_D/0/1/0/all/0/1\">Dimitrios Tanoglidis</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Jain_B/0/1/0/all/0/1\">Bhuvnesh Jain</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Qu_H/0/1/0/all/0/1\">Helen Qu</a> (University of Pennsylvania)",
          "description": "The deep learning architecture associated with ChatGPT and related generative\nAI products is known as transformers. Initially applied to Natural Language\nProcessing, transformers and the self-attention mechanism they exploit have\ngained widespread interest across the natural sciences. The goal of this\npedagogical and informal review is to introduce transformers to scientists. The\nreview includes the mathematics underlying the attention mechanism, a\ndescription of the original transformer architecture, and a section on\napplications to time series and imaging data in astronomy. We include a\nFrequently Asked Questions section for readers who are curious about generative\nAI or interested in getting started with transformers for their research\nproblem.",
          "link": "http://arxiv.org/abs/2310.12069",
          "publishedOn": "2023-10-21T00:41:43.220Z",
          "wordCount": null,
          "title": "Transformers for scientific data: a pedagogical review for astronomers. (arXiv:2310.12069v2 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yufei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Siyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jin Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lirong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_O/0/1/0/all/0/1\">Odin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haitao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jingqi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhangyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1\">Jiangbin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan.ZQ.Li</a>",
          "description": "Protein structure-based property prediction has emerged as a promising\napproach for various biological tasks, such as protein function prediction and\nsub-cellular location estimation. The existing methods highly rely on\nexperimental protein structure data and fail in scenarios where these data are\nunavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were\nutilized as alternatives. However, we observed that current practices, which\nsimply employ accurately predicted structures during inference, suffer from\nnotable degradation in prediction accuracy. While similar phenomena have been\nextensively studied in general fields (e.g., Computer Vision) as model\nrobustness, their impact on protein property prediction remains unexplored. In\nthis paper, we first investigate the reason behind the performance decrease\nwhen utilizing predicted structures, attributing it to the structure embedding\nbias from the perspective of structure representation learning. To study this\nproblem, we identify a Protein 3D Graph Structure Learning Problem for Robust\nProtein Property Prediction (PGSL-RP3), collect benchmark datasets, and present\na protein Structure embedding Alignment Optimization framework (SAO) to\nmitigate the problem of structure embedding bias between the predicted and\nexperimental protein structures. Extensive experiments have shown that our\nframework is model-agnostic and effective in improving the property prediction\nof both predicted structures and experimental structures. The benchmark\ndatasets and codes will be released to benefit the community.",
          "link": "http://arxiv.org/abs/2310.11466",
          "publishedOn": "2023-10-21T00:41:43.213Z",
          "wordCount": null,
          "title": "Protein 3D Graph Structure Learning for Robust Structure-based Protein Property Prediction. (arXiv:2310.11466v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jiyuan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenzhuo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1\">Kwok-Yan Lam</a>",
          "description": "Training a large and state-of-the-art machine learning model typically\nnecessitates the use of large-scale datasets, which, in turn, makes the\ntraining and parameter-tuning process expensive and time-consuming. Some\nresearchers opt to distil information from real-world datasets into tiny and\ncompact synthetic datasets while maintaining their ability to train a\nwell-performing model, hence proposing a data-efficient method known as Dataset\nDistillation (DD). Despite recent progress in this field, existing methods\nstill underperform and cannot effectively replace large datasets. In this\npaper, unlike previous methods that focus solely on improving the efficacy of\nstudent distillation, we are the first to recognize the important interplay\nbetween expert and student. We argue the significant impact of expert\nsmoothness when employing more potent expert trajectories in subsequent dataset\ndistillation. Based on this, we introduce the integration of clipping loss and\ngradient penalty to regulate the rate of parameter changes in expert\ntrajectories. Furthermore, in response to the sensitivity exhibited towards\nrandomly initialized variables during distillation, we propose representative\ninitialization for synthetic dataset and balanced inner-loop loss. Finally, we\npresent two enhancement strategies, namely intermediate matching loss and\nweight perturbation, to mitigate the potential occurrence of cumulative errors.\nWe conduct extensive experiments on datasets of different scales, sizes, and\nresolutions. The results demonstrate that the proposed method significantly\noutperforms prior methods.",
          "link": "http://arxiv.org/abs/2310.10541",
          "publishedOn": "2023-10-21T00:41:43.213Z",
          "wordCount": null,
          "title": "Efficient Dataset Distillation through Alignment with Smooth and High-Quality Expert Trajectories. (arXiv:2310.10541v1 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.10194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+McCarter_C/0/1/0/all/0/1\">Calvin McCarter</a>",
          "description": "Feature preprocessing continues to play a critical role when applying machine\nlearning and statistical methods to tabular data. In this paper, we propose the\nuse of the kernel density integral transformation as a feature preprocessing\nstep. Our approach subsumes the two leading feature preprocessing methods as\nlimiting cases: linear min-max scaling and quantile transformation. We\ndemonstrate that, without hyperparameter tuning, the kernel density integral\ntransformation can be used as a simple drop-in replacement for either method,\noffering protection from the weaknesses of each. Alternatively, with tuning of\na single continuous hyperparameter, we frequently outperform both of these\nmethods. Finally, we show that the kernel density transformation can be\nprofitably applied to statistical data analysis, particularly in correlation\nanalysis and univariate clustering.",
          "link": "http://arxiv.org/abs/2309.10194",
          "publishedOn": "2023-10-21T00:41:43.204Z",
          "wordCount": null,
          "title": "The Kernel Density Integral Transformation. (arXiv:2309.10194v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rouhani_B/0/1/0/all/0/1\">Bita Darvish Rouhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Ritchie Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+More_A/0/1/0/all/0/1\">Ankit More</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_M/0/1/0/all/0/1\">Mathew Hall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khodamoradi_A/0/1/0/all/0/1\">Alireza Khodamoradi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Summer Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_D/0/1/0/all/0/1\">Dhruv Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornea_M/0/1/0/all/0/1\">Marius Cornea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dellinger_E/0/1/0/all/0/1\">Eric Dellinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denolf_K/0/1/0/all/0/1\">Kristof Denolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusan_S/0/1/0/all/0/1\">Stosic Dusan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elango_V/0/1/0/all/0/1\">Venmugil Elango</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golub_M/0/1/0/all/0/1\">Maximilian Golub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinecke_A/0/1/0/all/0/1\">Alexander Heinecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_Roxby_P/0/1/0/all/0/1\">Phil James-Roxby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jani_D/0/1/0/all/0/1\">Dharmesh Jani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolhe_G/0/1/0/all/0/1\">Gaurav Kolhe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langhammer_M/0/1/0/all/0/1\">Martin Langhammer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ada Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melnick_L/0/1/0/all/0/1\">Levi Melnick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mesmakhosroshahi_M/0/1/0/all/0/1\">Maral Mesmakhosroshahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Andres Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulte_M/0/1/0/all/0/1\">Michael Schulte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafipour_R/0/1/0/all/0/1\">Rasoul Shafipour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Lei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siu_M/0/1/0/all/0/1\">Michael Siu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_P/0/1/0/all/0/1\">Pradeep Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micikevicius_P/0/1/0/all/0/1\">Paulius Micikevicius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumov_M/0/1/0/all/0/1\">Maxim Naumov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verrilli_C/0/1/0/all/0/1\">Colin Verrilli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wittig_R/0/1/0/all/0/1\">Ralph Wittig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burger_D/0/1/0/all/0/1\">Doug Burger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_E/0/1/0/all/0/1\">Eric Chung</a>",
          "description": "Narrow bit-width data formats are key to reducing the computational and\nstorage costs of modern deep learning applications. This paper evaluates\nMicroscaling (MX) data formats that combine a per-block scaling factor with\nnarrow floating-point and integer types for individual elements. MX formats\nbalance the competing needs of hardware efficiency, model accuracy, and user\nfriction. Empirical results on over two dozen benchmarks demonstrate\npracticality of MX data formats as a drop-in replacement for baseline FP32 for\nAI inference and training with low user friction. We also show the first\ninstance of training generative language models at sub-8-bit weights,\nactivations, and gradients with minimal accuracy loss and no modifications to\nthe training recipe.",
          "link": "http://arxiv.org/abs/2310.10537",
          "publishedOn": "2023-10-21T00:41:43.204Z",
          "wordCount": null,
          "title": "Microscaling Data Formats for Deep Learning. (arXiv:2310.10537v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yuan Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1\">Wenbin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zhiheng Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haoran Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>",
          "description": "The success of AI assistants based on language models (LLMs) hinges crucially\non Reinforcement Learning from Human Feedback (RLHF), which enables the\ngeneration of responses more aligned with human preferences. As universal AI\nassistants, there's a growing expectation for them to perform consistently\nacross various domains. However, previous work shows that Reinforcement\nLearning (RL) often exploits shortcuts to attain high rewards and overlooks\nchallenging samples. This focus on quick reward gains undermines both the\nstability in training and the model's ability to generalize to new, unseen\ndata. In this work, we propose a novel approach that can learn a consistent\npolicy via RL across various data groups or domains. Given the challenges\nassociated with acquiring group annotations, our method automatically\nclassifies data into different groups, deliberately maximizing performance\nvariance. Then, we optimize the policy to perform well on challenging groups.\nLastly, leveraging the established groups, our approach adaptively adjusts the\nexploration space, allocating more learning capacity to more challenging data\nand preventing the model from over-optimizing on simpler data. Experimental\nresults indicate that our approach significantly enhances training stability\nand model generalization.",
          "link": "http://arxiv.org/abs/2310.11971",
          "publishedOn": "2023-10-21T00:41:43.201Z",
          "wordCount": null,
          "title": "Improving Generalization of Alignment with Human Preferences through Group Invariant Learning. (arXiv:2310.11971v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1\">Harshavardhan Kamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingkai Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Alexander Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1\">B. Aditya Prakash</a>",
          "description": "Probabilistic hierarchical time-series forecasting is an important variant of\ntime-series forecasting, where the goal is to model and forecast multivariate\ntime-series that have underlying hierarchical relations. Most methods focus on\npoint predictions and do not provide well-calibrated probabilistic forecasts\ndistributions. Recent state-of-art probabilistic forecasting methods also\nimpose hierarchical relations on point predictions and samples of distribution\nwhich does not account for coherency of forecast distributions. Previous works\nalso silently assume that datasets are always consistent with given\nhierarchical relations and do not adapt to real-world datasets that show\ndeviation from this assumption. We close both these gap and propose PROFHiT,\nwhich is a fully probabilistic hierarchical forecasting model that jointly\nmodels forecast distribution of entire hierarchy. PROFHiT uses a flexible\nprobabilistic Bayesian approach and introduces a novel Distributional Coherency\nregularization to learn from hierarchical relations for entire forecast\ndistribution that enables robust and calibrated forecasts as well as adapt to\ndatasets of varying hierarchical consistency. On evaluating PROFHiT over wide\nrange of datasets, we observed 41-88% better performance in accuracy and\nsignificantly better calibration. Due to modeling the coherency over full\ndistribution, we observed that PROFHiT can robustly provide reliable forecasts\neven if up to 10% of input time-series data is missing where other methods'\nperformance severely degrade by over 70%.",
          "link": "http://arxiv.org/abs/2310.11569",
          "publishedOn": "2023-10-21T00:41:43.198Z",
          "wordCount": null,
          "title": "When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting. (arXiv:2310.11569v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07587",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Zikai Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zihan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Songshang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hualiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jin Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Joey Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Howard Hao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zuozhu Liu</a>",
          "description": "Data privacy and long-tailed distribution are the norms rather than the\nexception in many real-world tasks. This paper investigates a federated\nlong-tailed learning (Fed-LT) task in which each client holds a locally\nheterogeneous dataset; if the datasets can be globally aggregated, they jointly\nexhibit a long-tailed distribution. Under such a setting, existing federated\noptimization and/or centralized long-tailed learning methods hardly apply due\nto challenges in (a) characterizing the global long-tailed distribution under\nprivacy constraints and (b) adjusting the local learning strategy to cope with\nthe head-tail imbalance. In response, we propose a method termed\n$\\texttt{Fed-GraB}$, comprised of a Self-adjusting Gradient Balancer (SGB)\nmodule that re-weights clients' gradients in a closed-loop manner, based on the\nfeedback of global long-tailed distribution evaluated by a Direct Prior\nAnalyzer (DPA) module. Using $\\texttt{Fed-GraB}$, clients can effectively\nalleviate the distribution drift caused by data heterogeneity during the model\ntraining process and obtain a global model with better performance on the\nminority classes while maintaining the performance of the majority classes.\nExtensive experiments demonstrate that $\\texttt{Fed-GraB}$ achieves\nstate-of-the-art performance on representative datasets such as CIFAR-10-LT,\nCIFAR-100-LT, ImageNet-LT, and iNaturalist.",
          "link": "http://arxiv.org/abs/2310.07587",
          "publishedOn": "2023-10-21T00:41:43.195Z",
          "wordCount": null,
          "title": "Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer. (arXiv:2310.07587v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pourcel_J/0/1/0/all/0/1\">Julien Pourcel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colas_C/0/1/0/all/0/1\">C&#xe9;dric Colas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teodorescu_L/0/1/0/all/0/1\">Laetitia Teodorescu</a>",
          "description": "Finding and selecting new and interesting problems to solve is at the heart\nof curiosity, science and innovation. We here study automated problem\ngeneration in the context of the open-ended space of python programming\npuzzles. Existing generative models often aim at modeling a reference\ndistribution without any explicit diversity optimization. Other methods\nexplicitly optimizing for diversity do so either in limited hand-coded\nrepresentation spaces or in uninterpretable learned embedding spaces that may\nnot align with human perceptions of interesting variations. With ACES\n(Autotelic Code Exploration via Semantic descriptors), we introduce a new\nautotelic generation method that leverages semantic descriptors produced by a\nlarge language model (LLM) to directly optimize for interesting diversity, as\nwell as few-shot-based generation. Each puzzle is labeled along 10 dimensions,\neach capturing a programming skill required to solve it. ACES generates and\npursues novel and feasible goals to explore that abstract semantic space,\nslowly discovering a diversity of solvable programming puzzles in any given\nrun. Across a set of experiments, we show that ACES discovers a richer\ndiversity of puzzles than existing diversity-maximizing algorithms as measured\nacross a range of diversity metrics. We further study whether and in which\nconditions this diversity can translate into the successful training of puzzle\nsolving models.",
          "link": "http://arxiv.org/abs/2310.10692",
          "publishedOn": "2023-10-21T00:41:43.192Z",
          "wordCount": null,
          "title": "ACES: Generating Diverse Programming Puzzles with Autotelic Language Models and Semantic Descriptors. (arXiv:2310.10692v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kirchhof_M/0/1/0/all/0/1\">Michael Kirchhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mucsanyi_B/0/1/0/all/0/1\">B&#xe1;lint Mucs&#xe1;nyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seong Joon Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1\">Enkelejda Kasneci</a>",
          "description": "Representation learning has significantly driven the field to develop\npretrained models that can act as a valuable starting point when transferring\nto new datasets. With the rising demand for reliable machine learning and\nuncertainty quantification, there is a need for pretrained models that not only\nprovide embeddings but also transferable uncertainty estimates. To guide the\ndevelopment of such models, we propose the Uncertainty-aware Representation\nLearning (URL) benchmark. Besides the transferability of the representations,\nit also measures the zero-shot transferability of the uncertainty estimate\nusing a novel metric. We apply URL to evaluate eleven uncertainty quantifiers\nthat are pretrained on ImageNet and transferred to eight downstream datasets.\nWe find that approaches that focus on the uncertainty of the representation\nitself or estimate the prediction risk directly outperform those that are based\non the probabilities of upstream classes. Yet, achieving transferable\nuncertainty quantification remains an open challenge. Our findings indicate\nthat it is not necessarily in conflict with traditional representation learning\ngoals. Code is provided under https://github.com/mkirchhof/url .",
          "link": "http://arxiv.org/abs/2307.03810",
          "publishedOn": "2023-10-21T00:41:43.191Z",
          "wordCount": null,
          "title": "URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates. (arXiv:2307.03810v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khalife_S/0/1/0/all/0/1\">Sammy Khalife</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_A/0/1/0/all/0/1\">Amitabh Basu</a>",
          "description": "In this article we present new results about the expressivity of Graph Neural\nNetworks (GNNs). We prove that for any GNN with piecewise polynomial\nactivations, whose architecture size does not grow with the graph input sizes,\nthere exists a pair of non-isomorphic rooted trees of depth two such that the\nGNN cannot distinguish their root vertex up to an arbitrary number of\niterations. The proof relies on tools from the algebra of symmetric\npolynomials. In contrast, it was already known that unbounded GNNs (those whose\nsize is allowed to change with the graph sizes) with piecewise polynomial\nactivations can distinguish these vertices in only two iterations. Our results\nimply a strict separation between bounded and unbounded size GNNs, answering an\nopen question formulated by [Grohe, 2021]. We next prove that if one allows\nactivations that are not piecewise polynomial, then in two iterations a single\nneuron perceptron can distinguish the root vertices of any pair of\nnonisomorphic trees of depth two (our results hold for activations like the\nsigmoid, hyperbolic tan and others). This shows how the power of graph neural\nnetworks can change drastically if one changes the activation function of the\nneural networks. The proof of this result utilizes the Lindemann-Weierstrauss\ntheorem from transcendental number theory.",
          "link": "http://arxiv.org/abs/2307.04661",
          "publishedOn": "2023-10-21T00:41:43.191Z",
          "wordCount": null,
          "title": "On the power of graph neural networks and the role of the activation function. (arXiv:2307.04661v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Sewon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lomeli_M/0/1/0/all/0/1\">Maria Lomeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Margaret Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_V/0/1/0/all/0/1\">Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_S/0/1/0/all/0/1\">Scott Yih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>",
          "description": "Large language models (LMs) are currently trained to predict tokens given\ndocument prefixes, enabling them to directly perform long-form generation and\nprompting-style tasks which can be reduced to document completion. Existing\npretraining pipelines train LMs by concatenating random sets of short documents\nto create input contexts but the prior documents provide no signal for\npredicting the next document. We instead present In-Context Pretraining, a new\napproach where language models are pretrained on a sequence of related\ndocuments, thereby explicitly encouraging them to read and reason across\ndocument boundaries. We can do In-Context Pretraining by simply changing the\ndocument ordering so that each context contains related documents, and directly\napplying existing pretraining pipelines. However, this document sorting problem\nis challenging. There are billions of documents and we would like the sort to\nmaximize contextual similarity for every document without repeating any data.\nTo do this, we introduce approximate algorithms for finding related documents\nwith efficient nearest neighbor search and constructing coherent input contexts\nwith a graph traversal algorithm. Our experiments show In-Context Pretraining\noffers a simple and scalable approach to significantly enhance LMs'performance:\nwe see notable improvements in tasks that require more complex contextual\nreasoning, including in-context learning (+8%), reading comprehension (+15%),\nfaithfulness to previous contexts (+16%), long-context reasoning (+5%), and\nretrieval augmentation (+9%).",
          "link": "http://arxiv.org/abs/2310.10638",
          "publishedOn": "2023-10-21T00:41:43.190Z",
          "wordCount": null,
          "title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries. (arXiv:2310.10638v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yulan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhirui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1\">Sheng Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1\">Junchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fuzheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>",
          "description": "Generative self-supervised learning (SSL) has exhibited significant potential\nand garnered increasing interest in graph learning. In this study, we aim to\nexplore the problem of generative SSL in the context of heterogeneous graph\nlearning (HGL). The previous SSL approaches for heterogeneous graphs have\nprimarily relied on contrastive learning, necessitating the design of complex\nviews to capture heterogeneity. However, existing generative SSL methods have\nnot fully leveraged the capabilities of generative models to address the\nchallenges of HGL. In this paper, we present HGCVAE, a novel contrastive\nvariational graph auto-encoder that liberates HGL from the burden of intricate\nheterogeneity capturing. Instead of focusing on complicated heterogeneity,\nHGCVAE harnesses the full potential of generative SSL. HGCVAE innovatively\nconsolidates contrastive learning with generative SSL, introducing several key\ninnovations. Firstly, we employ a progressive mechanism to generate\nhigh-quality hard negative samples for contrastive learning, utilizing the\npower of variational inference. Additionally, we present a dynamic mask\nstrategy to ensure effective and stable learning. Moreover, we propose an\nenhanced scaled cosine error as the criterion for better attribute\nreconstruction. As an initial step in combining generative and contrastive SSL,\nHGCVAE achieves remarkable results compared to various state-of-the-art\nbaselines, confirming its superiority.",
          "link": "http://arxiv.org/abs/2310.11102",
          "publishedOn": "2023-10-21T00:41:43.190Z",
          "wordCount": null,
          "title": "HGCVAE: Integrating Generative and Contrastive Learning for Heterogeneous Graph Learning. (arXiv:2310.11102v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Przystupa_M/0/1/0/all/0/1\">Michael Przystupa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haghverd_F/0/1/0/all/0/1\">Faezeh Haghverd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagersand_M/0/1/0/all/0/1\">Martin Jagersand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tosatto_S/0/1/0/all/0/1\">Samuele Tosatto</a>",
          "description": "Movement primitives are trainable parametric models that reproduce robotic\nmovements starting from a limited set of demonstrations. Previous works\nproposed simple linear models that exhibited high sample efficiency and\ngeneralization power by allowing temporal modulation of movements (reproducing\nmovements faster or slower), blending (merging two movements into one),\nvia-point conditioning (constraining a movement to meet some particular\nvia-points) and context conditioning (generation of movements based on an\nobserved variable, e.g., position of an object). Previous works have proposed\nneural network-based motor primitive models, having demonstrated their capacity\nto perform tasks with some forms of input conditioning or time-modulation\nrepresentations. However, there has not been a single unified deep motor\nprimitive's model proposed that is capable of all previous operations, limiting\nneural motor primitive's potential applications. This paper proposes a deep\nmovement primitive architecture that encodes all the operations above and uses\na Bayesian context aggregator that allows a more sound context conditioning and\nblending. Our results demonstrate our approach can scale to reproduce complex\nmotions on a larger variety of input choices compared to baselines while\nmaintaining operations of linear movement primitives provide.",
          "link": "http://arxiv.org/abs/2307.05141",
          "publishedOn": "2023-10-21T00:41:43.174Z",
          "wordCount": null,
          "title": "Deep Probabilistic Movement Primitives with a Bayesian Aggregator. (arXiv:2307.05141v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05270",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1\">Mohsin Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teja_K/0/1/0/all/0/1\">Kandukuri Sai Teja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1\">Neeharika Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patwa_P/0/1/0/all/0/1\">Parth Patwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1\">Anubhab Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1\">Vinija Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>",
          "description": "The mixing of two or more languages is called Code-Mixing (CM). CM is a\nsocial norm in multilingual societies. Neural Language Models (NLMs) like\ntransformers have been effective on many NLP tasks. However, NLM for CM is an\nunder-explored area. Though transformers are capable and powerful, they cannot\nalways encode positional information since they are non-recurrent. Therefore,\nto enrich word information and incorporate positional information, positional\nencoding is defined. We hypothesize that Switching Points (SPs), i.e.,\njunctions in the text where the language switches (L1 -> L2 or L2 -> L1), pose\na challenge for CM Language Models (LMs), and hence give special emphasis to\nSPs in the modeling process. We experiment with several positional encoding\nmechanisms and show that rotatory positional encodings along with switching\npoint information yield the best results.\n\nWe introduce CONFLATOR: a neural language modeling approach for code-mixed\nlanguages. CONFLATOR tries to learn to emphasize switching points using smarter\npositional encoding, both at unigram and bigram levels. CONFLATOR outperforms\nthe state-of-the-art on two tasks based on code-mixed Hindi and English\n(Hinglish): (i) sentiment analysis and (ii) machine translation.",
          "link": "http://arxiv.org/abs/2309.05270",
          "publishedOn": "2023-10-21T00:41:43.150Z",
          "wordCount": null,
          "title": "CONFLATOR: Incorporating Switching Point based Rotatory Positional Encodings for Code-Mixed Language Modeling. (arXiv:2309.05270v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.09983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fluri_L/0/1/0/all/0/1\">Lukas Fluri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paleka_D/0/1/0/all/0/1\">Daniel Paleka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tramer_F/0/1/0/all/0/1\">Florian Tram&#xe8;r</a>",
          "description": "If machine learning models were to achieve superhuman abilities at various\nreasoning or decision-making tasks, how would we go about evaluating such\nmodels, given that humans would necessarily be poor proxies for ground truth?\nIn this paper, we propose a framework for evaluating superhuman models via\nconsistency checks. Our premise is that while the correctness of superhuman\ndecisions may be impossible to evaluate, we can still surface mistakes if the\nmodel's decisions fail to satisfy certain logical, human-interpretable rules.\nWe instantiate our framework on three tasks where correctness of decisions is\nhard to evaluate due to either superhuman model abilities, or to otherwise\nmissing ground truth: evaluating chess positions, forecasting future events,\nand making legal judgments. We show that regardless of a model's (possibly\nsuperhuman) performance on these tasks, we can discover logical inconsistencies\nin decision making. For example: a chess engine assigning opposing valuations\nto semantically identical boards; GPT-4 forecasting that sports records will\nevolve non-monotonically over time; or an AI judge assigning bail to a\ndefendant only after we add a felony to their criminal record.",
          "link": "http://arxiv.org/abs/2306.09983",
          "publishedOn": "2023-10-21T00:41:43.139Z",
          "wordCount": null,
          "title": "Evaluating Superhuman Models with Consistency Checks. (arXiv:2306.09983v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhenmei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Junyi Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingyu Liang</a>",
          "description": "Neural networks have achieved remarkable empirical performance, while the\ncurrent theoretical analysis is not adequate for understanding their success,\ne.g., the Neural Tangent Kernel approach fails to capture their key feature\nlearning ability, while recent analyses on feature learning are typically\nproblem-specific. This work proposes a unified analysis framework for two-layer\nnetworks trained by gradient descent. The framework is centered around the\nprinciple of feature learning from gradients, and its effectiveness is\ndemonstrated by applications in several prototypical problems, such as mixtures\nof Gaussians and parity functions. The framework also sheds light on\ninteresting network learning phenomena such as feature learning beyond kernels\nand the lottery ticket hypothesis.",
          "link": "http://arxiv.org/abs/2310.12408",
          "publishedOn": "2023-10-21T00:41:43.129Z",
          "wordCount": null,
          "title": "Provable Guarantees for Neural Networks via Gradient Feature Learning. (arXiv:2310.12408v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kini_G/0/1/0/all/0/1\">Ganesh Ramachandra Kini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakilian_V/0/1/0/all/0/1\">Vala Vakilian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behnia_T/0/1/0/all/0/1\">Tina Behnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gill_J/0/1/0/all/0/1\">Jaidev Gill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "Supervised contrastive loss (SCL) is a competitive and often superior\nalternative to the cross-entropy loss for classification. While prior studies\nhave demonstrated that both losses yield symmetric training representations\nunder balanced data, this symmetry breaks under class imbalances. This paper\npresents an intriguing discovery: the introduction of a ReLU activation at the\nfinal layer effectively restores the symmetry in SCL-learned representations.\nWe arrive at this finding analytically, by establishing that the global\nminimizers of an unconstrained features model with SCL loss and entry-wise\nnon-negativity constraints form an orthogonal frame. Extensive experiments\nconducted across various datasets, architectures, and imbalance scenarios\ncorroborate our finding. Importantly, our experiments reveal that the inclusion\nof the ReLU activation restores symmetry without compromising test accuracy.\nThis constitutes the first geometry characterization of SCL under imbalances.\nAdditionally, our analysis and experiments underscore the pivotal role of batch\nselection strategies in representation geometry. By proving necessary and\nsufficient conditions for mini-batch choices that ensure invariant symmetric\nrepresentations, we introduce batch-binding as an efficient strategy that\nguarantees these conditions hold.",
          "link": "http://arxiv.org/abs/2306.07960",
          "publishedOn": "2023-10-21T00:41:43.111Z",
          "wordCount": null,
          "title": "Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching. (arXiv:2306.07960v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1\">Reid Pryzant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iter_D/0/1/0/all/0/1\">Dan Iter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yin Tat Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>",
          "description": "Large Language Models (LLMs) have shown impressive performance as general\npurpose agents, but their abilities remain highly dependent on prompts which\nare hand written with onerous trial-and-error effort. We propose a simple and\nnonparametric solution to this problem, Automatic Prompt Optimization (APO),\nwhich is inspired by numerical gradient descent to automatically improve\nprompts, assuming access to training data and an LLM API. The algorithm uses\nminibatches of data to form natural language \"gradients\" that criticize the\ncurrent prompt. The gradients are then \"propagated\" into the prompt by editing\nthe prompt in the opposite semantic direction of the gradient. These gradient\ndescent steps are guided by a beam search and bandit selection procedure which\nsignificantly improves algorithmic efficiency. Preliminary results across three\nbenchmark NLP tasks and the novel problem of LLM jailbreak detection suggest\nthat Automatic Prompt Optimization can outperform prior prompt editing\ntechniques and improve an initial prompt's performance by up to 31%, by using\ndata to rewrite vague task descriptions into more precise annotation\ninstructions.",
          "link": "http://arxiv.org/abs/2305.03495",
          "publishedOn": "2023-10-21T00:41:43.107Z",
          "wordCount": null,
          "title": "Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search. (arXiv:2305.03495v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_Z/0/1/0/all/0/1\">Ziyi Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koulieris_G/0/1/0/all/0/1\">George Alex Koulieris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1\">Hubert P. H. Shum</a>",
          "description": "Diffusion models are generative models, which gradually add and remove noise\nto learn the underlying distribution of training data for data generation. The\ncomponents of diffusion models have gained significant attention with many\ndesign choices proposed. Existing reviews have primarily focused on\nhigher-level solutions, thereby covering less on the design fundamentals of\ncomponents. This study seeks to address this gap by providing a comprehensive\nand coherent review on component-wise design choices in diffusion models.\nSpecifically, we organize this review according to their three key components,\nnamely the forward process, the reverse process, and the sampling procedure.\nThis allows us to provide a fine-grained perspective of diffusion models,\nbenefiting future studies in the analysis of individual components, the\napplicability of design choices, and the implementation of diffusion models.",
          "link": "http://arxiv.org/abs/2306.04542",
          "publishedOn": "2023-10-21T00:41:43.107Z",
          "wordCount": null,
          "title": "On the Design Fundamentals of Diffusion Models: A Survey. (arXiv:2306.04542v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.00477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1\">Baohao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Shaomu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1\">Christof Monz</a>",
          "description": "Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs)\nhas emerged as a highly successful approach, with training only a small number\nof parameters without sacrificing performance and becoming the de-facto\nlearning paradigm with the increasing size of PLMs. However, existing PEFT\nmethods are not memory-efficient, because they still require caching most of\nthe intermediate activations for the gradient calculation, akin to fine-tuning.\nOne effective way to reduce the activation memory is to apply a reversible\nmodel, so the intermediate activations are not necessary to be cached and can\nbe recomputed. Nevertheless, modifying a PLM to its reversible variant is not\nstraightforward, since the reversible model has a distinct architecture from\nthe currently released PLMs. In this paper, we first investigate what is a key\nfactor for the success of existing PEFT methods, and realize that it's\nessential to preserve the PLM's starting point when initializing a PEFT method.\nWith this finding, we propose memory-efficient fine-tuning (MEFT) that inserts\nadapters into a PLM, preserving the PLM's starting point and making it\nreversible without additional pre-training. We evaluate MEFT on the GLUE\nbenchmark and five question-answering tasks with various backbones, BERT,\nRoBERTa, BART and OPT. MEFT significantly reduces the activation memory up to\n84% of full fine-tuning with a negligible amount of trainable parameters.\nMoreover, MEFT achieves the same score on GLUE and a comparable score on the\nquestion-answering tasks as full fine-tuning. A similar finding is also\nobserved for the image classification task.",
          "link": "http://arxiv.org/abs/2306.00477",
          "publishedOn": "2023-10-21T00:41:43.106Z",
          "wordCount": null,
          "title": "Make Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v4 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vodrahalli_K/0/1/0/all/0/1\">Kailas Vodrahalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>",
          "description": "As generative AI becomes more prevalent, it is important to study how human\nusers interact with such models. In this work, we investigate how people use\ntext-to-image models to generate desired target images. To study this\ninteraction, we created ArtWhisperer, an online game where users are given a\ntarget image and are tasked with iteratively finding a prompt that creates a\nsimilar-looking image as the target. Through this game, we recorded over 50,000\nhuman-AI interactions; each interaction corresponds to one text prompt created\nby a user and the corresponding generated image. The majority of these are\nrepeated interactions where a user iterates to find the best prompt for their\ntarget image, making this a unique sequential dataset for studying human-AI\ncollaborations. In an initial analysis of this dataset, we identify several\ncharacteristics of prompt interactions and user strategies. People submit\ndiverse prompts and are able to discover a variety of text descriptions that\ngenerate similar images. Interestingly, prompt diversity does not decrease as\nusers find better prompts. We further propose a new metric to quantify the\nsteerability of AI using our dataset. We define steerability as the expected\nnumber of interactions required to adequately complete a task. We estimate this\nvalue by fitting a Markov chain for each target task and calculating the\nexpected time to reach an adequate score in the Markov chain. We quantify and\ncompare AI steerability across different types of target images and two\ndifferent models, finding that images of cities and natural world images are\nmore steerable than artistic and fantasy images. These findings provide\ninsights into human-AI interaction behavior, present a concrete method of\nassessing AI steerability, and demonstrate the general utility of the\nArtWhisperer dataset.",
          "link": "http://arxiv.org/abs/2306.08141",
          "publishedOn": "2023-10-21T00:41:43.100Z",
          "wordCount": null,
          "title": "ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations. (arXiv:2306.08141v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1\">Evan Unit Lim</a>",
          "description": "The Quasi Manhattan Wasserstein Distance (QMWD) is a metric designed to\nquantify the dissimilarity between two matrices by combining elements of the\nWasserstein Distance with specific transformations. It offers improved time and\nspace complexity compared to the Manhattan Wasserstein Distance (MWD) while\nmaintaining accuracy. QMWD is particularly advantageous for large datasets or\nsituations with limited computational resources. This article provides a\ndetailed explanation of QMWD, its computation, complexity analysis, and\ncomparisons with WD and MWD.",
          "link": "http://arxiv.org/abs/2310.12498",
          "publishedOn": "2023-10-21T00:41:43.093Z",
          "wordCount": null,
          "title": "Quasi Manhattan Wasserstein Distance. (arXiv:2310.12498v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hui_W/0/1/0/all/0/1\">Wendy Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_W/0/1/0/all/0/1\">Wai Kwong Lau</a>",
          "description": "This paper proposes the use of causal modeling to detect and mitigate\nalgorithmic bias. We provide a brief description of causal modeling and a\ngeneral overview of our approach. We then use the Adult dataset, which is\navailable for download from the UC Irvine Machine Learning Repository, to\ndevelop (1) a prediction model, which is treated as a black box, and (2) a\ncausal model for bias mitigation. In this paper, we focus on gender bias and\nthe problem of binary classification. We show that gender bias in the\nprediction model is statistically significant at the 0.05 level. We demonstrate\nthe effectiveness of the causal model in mitigating gender bias by\ncross-validation. Furthermore, we show that the overall classification accuracy\nis improved slightly. Our novel approach is intuitive, easy-to-use, and can be\nimplemented using existing statistical software tools such as \"lavaan\" in R.\nHence, it enhances explainability and promotes trust.",
          "link": "http://arxiv.org/abs/2310.12421",
          "publishedOn": "2023-10-21T00:41:43.092Z",
          "wordCount": null,
          "title": "Detecting and Mitigating Algorithmic Bias in Binary Classification using Causal Modeling. (arXiv:2310.12421v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.10744",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Duksang Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Overman_W/0/1/0/all/0/1\">William Overman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dabeen Lee</a>",
          "description": "This paper studies a long-term resource allocation problem over multiple\nperiods where each period requires a multi-stage decision-making process. We\nformulate the problem as an online allocation problem in an episodic\nfinite-horizon constrained Markov decision process with an unknown\nnon-stationary transition function and stochastic non-stationary reward and\nresource consumption functions. We propose the observe-then-decide regime and\nimprove the existing decide-then-observe regime, while the two settings differ\nin how the observations and feedback about the reward and resource consumption\nfunctions are given to the decision-maker. We develop an online dual mirror\ndescent algorithm that achieves near-optimal regret bounds for both settings.\nFor the observe-then-decide regime, we prove that the expected regret against\nthe dynamic clairvoyant optimal policy is bounded by $\\tilde\nO(\\rho^{-1}{H^{3/2}}S\\sqrt{AT})$ where $\\rho\\in(0,1)$ is the budget parameter,\n$H$ is the length of the horizon, $S$ and $A$ are the numbers of states and\nactions, and $T$ is the number of episodes. For the decide-then-observe regime,\nwe show that the regret against the static optimal policy that has access to\nthe mean reward and mean resource consumption functions is bounded by $\\tilde\nO(\\rho^{-1}{H^{3/2}}S\\sqrt{AT})$ with high probability. We test the numerical\nefficiency of our method for a variant of the resource-constrained inventory\nmanagement problem.",
          "link": "http://arxiv.org/abs/2305.10744",
          "publishedOn": "2023-10-21T00:41:43.092Z",
          "wordCount": null,
          "title": "Online Resource Allocation in Episodic Markov Decision Processes. (arXiv:2305.10744v3 [cs.DS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Doshi_L/0/1/0/all/0/1\">Lyric Doshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_V/0/1/0/all/0/1\">Vincent Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_G/0/1/0/all/0/1\">Gaurav Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcus_R/0/1/0/all/0/1\">Ryan Marcus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haoyu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altinbuken_D/0/1/0/all/0/1\">Deniz Altinb&#xfc;ken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brevdo_E/0/1/0/all/0/1\">Eugene Brevdo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fraser_C/0/1/0/all/0/1\">Campbell Fraser</a>",
          "description": "Most existing parametric query optimization (PQO) techniques rely on\ntraditional query optimizer cost models, which are often inaccurate and result\nin suboptimal query performance. We propose Kepler, an end-to-end\nlearning-based approach to PQO that demonstrates significant speedups in query\nlatency over a traditional query optimizer. Central to our method is Row Count\nEvolution (RCE), a novel plan generation algorithm based on perturbations in\nthe sub-plan cardinality space. While previous approaches require accurate cost\nmodels, we bypass this requirement by evaluating candidate plans via actual\nexecution data and training an ML model to predict the fastest plan given\nparameter binding values. Our models leverage recent advances in neural network\nuncertainty in order to robustly predict faster plans while avoiding\nregressions in query performance. Experimentally, we show that Kepler achieves\nsignificant improvements in query runtime on multiple datasets on PostgreSQL.",
          "link": "http://arxiv.org/abs/2306.06798",
          "publishedOn": "2023-10-21T00:41:43.089Z",
          "wordCount": null,
          "title": "Kepler: Robust Learning for Faster Parametric Query Optimization. (arXiv:2306.06798v2 [cs.DB] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zehan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xize Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haifeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiageng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1\">Li Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_A/0/1/0/all/0/1\">Aoxiong Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhou Zhao</a>",
          "description": "Multi-modal Contrastive Representation learning aims to encode different\nmodalities into a semantically aligned shared space. This paradigm shows\nremarkable generalization ability on numerous downstream tasks across various\nmodalities. However, the reliance on massive high-quality data pairs limits its\nfurther development on more modalities. This paper proposes a novel\ntraining-efficient method for learning MCR without paired data called\nConnecting Multi-modal Contrastive Representations (C-MCR). Specifically, given\ntwo existing MCRs pre-trained on (A, B) and (B, C) modality pairs, we project\nthem to a new space and use the data from the overlapping modality B to\naligning the two MCRs in the new space. Meanwhile, since the modality pairs (A,\nB) and (B, C) are already aligned within each MCR, the connection learned by\noverlapping modality can also be transferred to non-overlapping modality pair\n(A, C). To unleash the potential of C-MCR, we further introduce a\nsemantic-enhanced inter- and intra-MCR connection method. We first enhance the\nsemantic consistency and completion of embeddings across different modalities\nfor more robust alignment. Then we utilize the inter-MCR alignment to establish\nthe connection, and employ the intra-MCR alignment to better maintain the\nconnection for inputs from non-overlapping modalities. To demonstrate the\neffectiveness of C-MCR, we connect CLIP and CLAP via texts to derive\naudio-visual representations, and integrate CLIP and ULIP via images for\n3D-language representations. Remarkably, without using any paired data, C-MCR\nfor audio-visual achieves state-of-the-art performance on audio-image\nretrieval, audio-visual source localization, and counterfactual audio-image\nrecognition tasks. Furthermore, C-MCR for 3D-language also attains advanced\nzero-shot 3D point cloud classification accuracy on ModelNet40.",
          "link": "http://arxiv.org/abs/2305.14381",
          "publishedOn": "2023-10-21T00:41:43.078Z",
          "wordCount": null,
          "title": "Connecting Multi-modal Contrastive Representations. (arXiv:2305.14381v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.05799",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Flynn_A/0/1/0/all/0/1\">Andrew Flynn</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tsachouridis_V/0/1/0/all/0/1\">Vassilios A. Tsachouridis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Amann_A/0/1/0/all/0/1\">Andreas Amann</a>",
          "description": "Multifunctional biological neural networks exploit multistability in order to\nperform multiple tasks without changing any network properties. Enabling\nartificial neural networks (ANNs) to obtain certain multistabilities in order\nto perform several tasks, where each task is related to a particular attractor\nin the network's state space, naturally has many benefits from a machine\nlearning perspective. Given the association to multistability, in this paper we\nexplore how the relationship between different attractors influences the\nability of a reservoir computer (RC), which is a dynamical system in the form\nof an ANN, to achieve multifunctionality. We construct the `seeing double'\nproblem to systematically study how a RC reconstructs a coexistence of\nattractors when there is an overlap between them. As the amount of overlap\nincreases, we discover that for multifunctionality to occur, there is a\ncritical dependence on a suitable choice of the spectral radius for the RC's\ninternal network connections. A bifurcation analysis reveals how\nmultifunctionality emerges and is destroyed as the RC enters a chaotic regime\nthat can lead to chaotic itinerancy.",
          "link": "http://arxiv.org/abs/2305.05799",
          "publishedOn": "2023-10-21T00:41:43.076Z",
          "wordCount": null,
          "title": "Seeing double with a multifunctional reservoir computer. (arXiv:2305.05799v2 [math.DS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.09310",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mozafari_Majd_E/0/1/0/all/0/1\">Emadaldin Mozafari-Majd</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Koivunen_V/0/1/0/all/0/1\">Visa Koivunen</a>",
          "description": "This paper introduces a new regularized version of the robust\n$\\tau$-regression estimator for analyzing high-dimensional datasets subject to\ngross contamination in the response variables and covariates (explanatory\nvariables). The resulting estimator, termed adaptive $\\tau$-Lasso, is robust to\noutliers and high-leverage points. It also incorporates an adaptive\n$\\ell_1$-norm penalty term, which enables the selection of relevant variables\nand reduces the bias associated with large true regression coefficients. More\nspecifically, this adaptive $\\ell_1$-norm penalty term assigns a weight to each\nregression coefficient. For a fixed number of predictors $p$, we show that the\nadaptive $\\tau$-Lasso has the oracle property, ensuring both variable-selection\nconsistency and asymptotic normality. Asymptotic normality applies only to the\nentries of the regression vector corresponding to the true support, assuming\nknowledge of the true regression vector support. We characterize its robustness\nvia the finite-sample breakdown point and the influence function. We carry out\nextensive simulations and observe that the class of $\\tau$-Lasso estimators\nexhibits robustness and reliable performance in both contaminated and\nuncontaminated data settings. We also validate our theoretical findings on\nrobustness properties through simulation experiments. In the face of outliers\nand high-leverage points, the adaptive $\\tau$-Lasso and $\\tau$-Lasso estimators\nachieve the best performance or close-to-best performance in terms of\nprediction and variable selection accuracy compared to other competing\nregularized estimators for all scenarios considered in this study. Therefore,\nthe adaptive $\\tau$-Lasso and $\\tau$-Lasso estimators can be effectively\nemployed for a variety of sparse linear regression problems, particularly in\nhigh-dimensional settings and when the data is contaminated by outliers and\nhigh-leverage points.",
          "link": "http://arxiv.org/abs/2304.09310",
          "publishedOn": "2023-10-21T00:41:43.069Z",
          "wordCount": null,
          "title": "The Adaptive $\\tau$-Lasso: Robustness and Oracle Properties. (arXiv:2304.09310v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12547",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junghyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_G/0/1/0/all/0/1\">Gi-Cheon Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jaein Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Seoyun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_M/0/1/0/all/0/1\">Minjoon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Byoung-Tak Zhang</a>",
          "description": "Language-Conditioned Robotic Grasping (LCRG) aims to develop robots that\nground and grasp objects based on natural language instructions. While robots\ncapable of recognizing personal objects like \"my wallet\" can interact more\nnaturally with non-expert users, current LCRG systems primarily limit robots to\nunderstanding only generic expressions. To this end, we introduce a task\nscenario GraspMine with a novel dataset that aims to locate and grasp personal\nobjects given personal indicators via learning from a single human-robot\ninteraction. To address GraspMine, we propose Personalized Grasping Agent\n(PGA), that learns personal objects by propagating user-given information\nthrough a Reminiscence-a collection of raw images from the user's environment.\nSpecifically, PGA acquires personal object information by a user presenting a\npersonal object with its associated indicator, followed by PGA inspecting the\nobject by rotating it. Based on the acquired information, PGA pseudo-labels\nobjects in the Reminiscence by our proposed label propagation algorithm.\nHarnessing the information acquired from the interactions and the\npseudo-labeled objects in the Reminiscence, PGA adapts the object grounding\nmodel to grasp personal objects. Experiments on GraspMine show that PGA\nsignificantly outperforms baseline methods both in offline and online settings,\nsignifying its effectiveness and personalization applicability on real-world\nscenarios. Finally, qualitative analysis shows the effectiveness of PGA through\na detailed investigation of results in each phase.",
          "link": "http://arxiv.org/abs/2310.12547",
          "publishedOn": "2023-10-21T00:41:43.064Z",
          "wordCount": null,
          "title": "PGA: Personalizing Grasping Agents with Single Human-Robot Interaction. (arXiv:2310.12547v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12667",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Karimi_B/0/1/0/all/0/1\">Belhal Karimi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_J/0/1/0/all/0/1\">Jianwen Xie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>",
          "description": "We propose in this paper, STANLEY, a STochastic gradient ANisotropic LangEvin\ndYnamics, for sampling high dimensional data. With the growing efficacy and\npotential of Energy-Based modeling, also known as non-normalized probabilistic\nmodeling, for modeling a generative process of different natures of high\ndimensional data observations, we present an end-to-end learning algorithm for\nEnergy-Based models (EBM) with the purpose of improving the quality of the\nresulting sampled data points. While the unknown normalizing constant of EBMs\nmakes the training procedure intractable, resorting to Markov Chain Monte Carlo\n(MCMC) is in general a viable option. Realizing what MCMC entails for the EBM\ntraining, we propose in this paper, a novel high dimensional sampling method,\nbased on an anisotropic stepsize and a gradient-informed covariance matrix,\nembedded into a discretized Langevin diffusion. We motivate the necessity for\nan anisotropic update of the negative samples in the Markov Chain by the\nnonlinearity of the backbone of the EBM, here a Convolutional Neural Network.\nOur resulting method, namely STANLEY, is an optimization algorithm for training\nEnergy-Based models via our newly introduced MCMC method. We provide a\ntheoretical understanding of our sampling scheme by proving that the sampler\nleads to a geometrically uniformly ergodic Markov Chain. Several image\ngeneration experiments are provided in our paper to show the effectiveness of\nour method.",
          "link": "http://arxiv.org/abs/2310.12667",
          "publishedOn": "2023-10-21T00:41:43.064Z",
          "wordCount": null,
          "title": "STANLEY: Stochastic Gradient Anisotropic Langevin Dynamics for Learning Energy-Based Models. (arXiv:2310.12667v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.03098",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andrew_G/0/1/0/all/0/1\">Galen Andrew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kairouz_P/0/1/0/all/0/1\">Peter Kairouz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Sewoong Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprea_A/0/1/0/all/0/1\">Alina Oprea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McMahan_H/0/1/0/all/0/1\">H. Brendan McMahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suriyakumar_V/0/1/0/all/0/1\">Vinith Suriyakumar</a>",
          "description": "Privacy estimation techniques for differentially private (DP) algorithms are\nuseful for comparing against analytical bounds, or to empirically measure\nprivacy loss in settings where known analytical bounds are not tight. However,\nexisting privacy auditing techniques usually make strong assumptions on the\nadversary (e.g., knowledge of intermediate model iterates or the training data\ndistribution), are tailored to specific tasks, model architectures, or DP\nalgorithm, and/or require retraining the model many times (typically on the\norder of thousands). These shortcomings make deploying such techniques at scale\ndifficult in practice, especially in federated settings where model training\ncan take days or weeks. In this work, we present a novel ``one-shot'' approach\nthat can systematically address these challenges, allowing efficient auditing\nor estimation of the privacy loss of a model during the same, single training\nrun used to fit model parameters, and without requiring any a priori knowledge\nabout the model architecture, task, or DP training algorithm. We show that our\nmethod provides provably correct estimates for the privacy loss under the\nGaussian mechanism, and we demonstrate its performance on well-established FL\nbenchmark datasets under several adversarial threat models.",
          "link": "http://arxiv.org/abs/2302.03098",
          "publishedOn": "2023-10-21T00:41:43.059Z",
          "wordCount": null,
          "title": "One-shot Empirical Privacy Estimation for Federated Learning. (arXiv:2302.03098v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.06368",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hasan_T/0/1/0/all/0/1\">Tonmoy Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bunescu_R/0/1/0/all/0/1\">Razvan Bunescu</a>",
          "description": "A recommender system that optimizes its recommendations solely to fit a\nuser's history of ratings for consumed items can create a filter bubble,\nwherein the user does not get to experience items from novel, unseen\ncategories. One approach to mitigate this undesired behavior is to recommend\nitems with high potential for serendipity, namely surprising items that are\nlikely to be highly rated. In this paper, we propose a content-based\nformulation of serendipity that is rooted in Bayesian surprise and use it to\nmeasure the serendipity of items after they are consumed and rated by the user.\nWhen coupled with a collaborative-filtering component that identifies similar\nusers, this enables recommending items with high potential for serendipity. To\nfacilitate the evaluation of topic-level models for surprise and serendipity,\nwe introduce a dataset of book reading histories extracted from Goodreads,\ncontaining over 26 thousand users and close to 1.3 million books, where we\nmanually annotate 449 books read by 4 users in terms of their time-dependent,\ntopic-level surprise. Experimental evaluations show that models that use\nBayesian surprise correlate much better with the manual annotations of\ntopic-level surprise than distance-based heuristics, and also obtain better\nserendipitous item recommendation performance.",
          "link": "http://arxiv.org/abs/2308.06368",
          "publishedOn": "2023-10-21T00:41:43.055Z",
          "wordCount": null,
          "title": "Topic-Level Bayesian Surprise and Serendipity for Recommender Systems. (arXiv:2308.06368v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.04934",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Buehler_M/0/1/0/all/0/1\">Markus J. Buehler</a>",
          "description": "We report a flexible language-model based deep learning strategy, applied\nhere to solve complex forward and inverse problems in protein modeling, based\non an attention neural network that integrates transformer and graph\nconvolutional architectures in a causal multi-headed graph mechanism, to\nrealize a generative pretrained model. The model is applied to predict\nsecondary structure content (per-residue level and overall content), protein\nsolubility, and sequencing tasks. Further trained on inverse tasks, the model\nis rendered capable of designing proteins with these properties as target\nfeatures. The model is formulated as a general framework, completely\nprompt-based, and can be adapted for a variety of downstream tasks. We find\nthat adding additional tasks yields emergent synergies that the model exploits\nin improving overall performance, beyond what would be possible by training a\nmodel on each dataset alone. Case studies are presented to validate the method,\nyielding protein designs specifically focused on structural proteins, but also\nexploring the applicability in the design of soluble, antimicrobial\nbiomaterials. While our model is trained to ultimately perform 8 distinct\ntasks, with available datasets it can be extended to solve additional problems.\nIn a broader sense, this work illustrates a form of multiscale modeling that\nrelates a set of ultimate building blocks (here, byte-level utf8 characters\nthat define the nature of the physical system at hand) to complex output. This\nmateriomic scheme captures complex emergent relationships between universal\nbuilding block and resulting properties via a synergizing learning capacity to\nexpress a set of potentialities embedded in the knowledge used in training, via\nthe interplay of universality and diversity.",
          "link": "http://arxiv.org/abs/2305.04934",
          "publishedOn": "2023-10-21T00:41:43.054Z",
          "wordCount": null,
          "title": "Generative Pretrained Autoregressive Transformer Graph Neural Network applied to the Analysis and Discovery of Novel Proteins. (arXiv:2305.04934v2 [q-bio.BM] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rege_A/0/1/0/all/0/1\">Aniket Rege</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1\">Aditya Kusupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_S/0/1/0/all/0/1\">Sharan Ranjit S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1\">Alan Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qingqing Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>",
          "description": "Web-scale search systems learn an encoder to embed a given query which is\nthen hooked into an approximate nearest neighbor search (ANNS) pipeline to\nretrieve similar data points. To accurately capture tail queries and data\npoints, learned representations typically are rigid, high-dimensional vectors\nthat are generally used as-is in the entire ANNS pipeline and can lead to\ncomputationally expensive retrieval. In this paper, we argue that instead of\nrigid representations, different stages of ANNS can leverage adaptive\nrepresentations of varying capacities to achieve significantly better\naccuracy-compute trade-offs, i.e., stages of ANNS that can get away with more\napproximate computation should use a lower-capacity representation of the same\ndata point. To this end, we introduce AdANNS, a novel ANNS design framework\nthat explicitly leverages the flexibility of Matryoshka Representations. We\ndemonstrate state-of-the-art accuracy-compute trade-offs using novel\nAdANNS-based key ANNS building blocks like search data structures (AdANNS-IVF)\nand quantization (AdANNS-OPQ). For example on ImageNet retrieval, AdANNS-IVF is\nup to 1.5% more accurate than the rigid representations-based IVF at the same\ncompute budget; and matches accuracy while being up to 90x faster in wall-clock\ntime. For Natural Questions, 32-byte AdANNS-OPQ matches the accuracy of the\n64-byte OPQ baseline constructed using rigid representations -- same accuracy\nat half the cost! We further show that the gains from AdANNS translate to\nmodern-day composite ANNS indices that combine search structures and\nquantization. Finally, we demonstrate that AdANNS can enable inference-time\nadaptivity for compute-aware search on ANNS indices built non-adaptively on\nmatryoshka representations. Code is open-sourced at\nhttps://github.com/RAIVNLab/AdANNS.",
          "link": "http://arxiv.org/abs/2305.19435",
          "publishedOn": "2023-10-21T00:41:43.051Z",
          "wordCount": null,
          "title": "AdANNS: A Framework for Adaptive Semantic Search. (arXiv:2305.19435v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01225",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gonon_A/0/1/0/all/0/1\">Antoine Gonon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brisebarre_N/0/1/0/all/0/1\">Nicolas Brisebarre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Riccietti_E/0/1/0/all/0/1\">Elisa Riccietti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gribonval_R/0/1/0/all/0/1\">R&#xe9;mi Gribonval</a>",
          "description": "This work introduces the first toolkit around path-norms that is fully able\nto encompass general DAG ReLU networks with biases, skip connections and any\noperation based on the extraction of order statistics: max pooling, GroupSort\netc. This toolkit notably allows us to establish generalization bounds for\nmodern neural networks that are not only the most widely applicable path-norm\nbased ones, but also recover or beat the sharpest known bounds of this type.\nThese extended path-norms further enjoy the usual benefits of path-norms: ease\nof computation, invariance under the symmetries of the network, and improved\nsharpness on feedforward networks compared to the product of operators' norms,\nanother complexity measure most commonly used.\n\nThe versatility of the toolkit and its ease of implementation allow us to\nchallenge the concrete promises of path-norm-based generalization bounds, by\nnumerically evaluating the sharpest known bounds for ResNets on ImageNet.",
          "link": "http://arxiv.org/abs/2310.01225",
          "publishedOn": "2023-10-21T00:41:43.048Z",
          "wordCount": null,
          "title": "A path-norm toolkit for modern networks: consequences, promises and challenges. (arXiv:2310.01225v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.12467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingze Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chao Ma</a>",
          "description": "The training process of ReLU neural networks often exhibits complicated\nnonlinear phenomena. The nonlinearity of models and non-convexity of loss pose\nsignificant challenges for theoretical analysis. Therefore, most previous\ntheoretical works on the optimization dynamics of neural networks focus either\non local analysis (like the end of training) or approximate linear models (like\nNeural Tangent Kernel). In this work, we conduct a complete theoretical\ncharacterization of the training process of a two-layer ReLU network trained by\nGradient Flow on a linearly separable data. In this specific setting, our\nanalysis captures the whole optimization process starting from random\ninitialization to final convergence. Despite the relatively simple model and\ndata that we studied, we reveal four different phases from the whole training\nprocess showing a general simplifying-to-complicating learning trend. Specific\nnonlinear behaviors can also be precisely identified and captured\ntheoretically, such as initial condensation, saddle-to-plateau dynamics,\nplateau escape, changes of activation patterns, learning with increasing\ncomplexity, etc.",
          "link": "http://arxiv.org/abs/2305.12467",
          "publishedOn": "2023-10-21T00:41:43.044Z",
          "wordCount": null,
          "title": "Understanding Multi-phase Optimization Dynamics and Rich Nonlinear Behaviors of ReLU Networks. (arXiv:2305.12467v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.10557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>",
          "description": "The transformer is a neural network component that can be used to learn\nuseful representations of sequences or sets of data-points. The transformer has\ndriven recent advances in natural language processing, computer vision, and\nspatio-temporal modelling. There are many introductions to transformers, but\nmost do not contain precise mathematical descriptions of the architecture and\nthe intuitions behind the design choices are often also missing. Moreover, as\nresearch takes a winding path, the explanations for the components of the\ntransformer can be idiosyncratic. In this note we aim for a mathematically\nprecise, intuitive, and clean description of the transformer architecture. We\nwill not discuss training as this is rather standard. We assume that the reader\nis familiar with fundamental topics in machine learning including multi-layer\nperceptrons, linear transformations, softmax functions and basic probability.",
          "link": "http://arxiv.org/abs/2304.10557",
          "publishedOn": "2023-10-21T00:41:43.036Z",
          "wordCount": null,
          "title": "An Introduction to Transformers. (arXiv:2304.10557v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mingkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Shan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>",
          "description": "Self-supervised Learning (SSL) including the mainstream contrastive learning\nhas achieved great success in learning visual representations without data\nannotations. However, most methods mainly focus on the instance level\ninformation (\\ie, the different augmented images of the same instance should\nhave the same feature or cluster into the same class), but there is a lack of\nattention on the relationships between different instances. In this paper, we\nintroduce a novel SSL paradigm, which we term as relational self-supervised\nlearning (ReSSL) framework that learns representations by modeling the\nrelationship between different instances. Specifically, our proposed method\nemploys sharpened distribution of pairwise similarities among different\ninstances as \\textit{relation} metric, which is thus utilized to match the\nfeature embeddings of different augmentations. To boost the performance, we\nargue that weak augmentations matter to represent a more reliable relation, and\nleverage momentum strategy for practical efficiency. The designed asymmetric\npredictor head and an InfoNCE warm-up strategy enhance the robustness to\nhyper-parameters and benefit the resulting performance. Experimental results\nshow that our proposed ReSSL substantially outperforms the state-of-the-art\nmethods across different network architectures, including various lightweight\nnetworks (\\eg, EfficientNet and MobileNet).",
          "link": "http://arxiv.org/abs/2203.08717",
          "publishedOn": "2023-10-21T00:41:43.035Z",
          "wordCount": null,
          "title": "Relational Self-Supervised Learning. (arXiv:2203.08717v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.12410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brehmer_J/0/1/0/all/0/1\">Johann Brehmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bose_J/0/1/0/all/0/1\">Joey Bose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haan_P/0/1/0/all/0/1\">Pim de Haan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1\">Taco Cohen</a>",
          "description": "Embodied agents operate in a structured world, often solving tasks with\nspatial, temporal, and permutation symmetries. Most algorithms for planning and\nmodel-based reinforcement learning (MBRL) do not take this rich geometric\nstructure into account, leading to sample inefficiency and poor generalization.\nWe introduce the Equivariant Diffuser for Generating Interactions (EDGI), an\nalgorithm for MBRL and planning that is equivariant with respect to the product\nof the spatial symmetry group SE(3), the discrete-time translation group Z, and\nthe object permutation group Sn. EDGI follows the Diffuser framework (Janner et\nal., 2022) in treating both learning a world model and planning in it as a\nconditional generative modeling problem, training a diffusion model on an\noffline trajectory dataset. We introduce a new SE(3)xZxSn-equivariant diffusion\nmodel that supports multiple representations. We integrate this model in a\nplanning loop, where conditioning and classifier guidance let us softly break\nthe symmetry for specific tasks as needed. On object manipulation and\nnavigation tasks, EDGI is substantially more sample efficient and generalizes\nbetter across the symmetry group than non-equivariant models.",
          "link": "http://arxiv.org/abs/2303.12410",
          "publishedOn": "2023-10-21T00:41:43.035Z",
          "wordCount": null,
          "title": "EDGI: Equivariant Diffusion for Planning with Embodied Agents. (arXiv:2303.12410v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zijun Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lingbo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tianhua Xu</a>",
          "description": "Data Augmentation (DA) has emerged as an indispensable strategy in Time\nSeries Classification (TSC), primarily due to its capacity to amplify training\nsamples, thereby bolstering model robustness, diversifying datasets, and\ncurtailing overfitting. However, the current landscape of DA in TSC is plagued\nwith fragmented literature reviews, nebulous methodological taxonomies,\ninadequate evaluative measures, and a dearth of accessible, user-oriented\ntools. In light of these challenges, this study embarks on an exhaustive\ndissection of DA methodologies within the TSC realm. Our initial approach\ninvolved an extensive literature review spanning a decade, revealing that\ncontemporary surveys scarcely capture the breadth of advancements in DA for\nTSC, prompting us to meticulously analyze over 100 scholarly articles to\ndistill more than 60 unique DA techniques. This rigorous analysis precipitated\nthe formulation of a novel taxonomy, purpose-built for the intricacies of DA in\nTSC, categorizing techniques into five principal echelons:\nTransformation-Based, Pattern-Based, Generative, Decomposition-Based, and\nAutomated Data Augmentation. Our taxonomy promises to serve as a robust\nnavigational aid for scholars, offering clarity and direction in method\nselection. Addressing the conspicuous absence of holistic evaluations for\nprevalent DA techniques, we executed an all-encompassing empirical assessment,\nwherein upwards of 15 DA strategies were subjected to scrutiny across 8 UCR\ntime-series datasets, employing ResNet and a multi-faceted evaluation paradigm\nencompassing Accuracy, Method Ranking, and Residual Analysis, yielding a\nbenchmark accuracy of 88.94 +- 11.83%. Our investigation underscored the\ninconsistent efficacies of DA techniques, with...",
          "link": "http://arxiv.org/abs/2310.10060",
          "publishedOn": "2023-10-21T00:41:43.028Z",
          "wordCount": null,
          "title": "Data Augmentation for Time-Series Classification: An Extensive Empirical Study and Comprehensive Survey. (arXiv:2310.10060v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.06348",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Han_W/0/1/0/all/0/1\">William Han</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qiu_J/0/1/0/all/0/1\">Jielin Qiu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhu_J/0/1/0/all/0/1\">Jiacheng Zhu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xu_M/0/1/0/all/0/1\">Mengdi Xu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Weber_D/0/1/0/all/0/1\">Douglas Weber</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>",
          "description": "Brain Signals, such as Electroencephalography (EEG), and human languages have\nbeen widely explored independently for many downstream tasks, however, the\nconnection between them has not been well explored. In this study, we explore\nthe relationship and dependency between EEG and language. To study at the\nrepresentation level, we introduced \\textbf{MTAM}, a \\textbf{M}ultimodal\n\\textbf{T}ransformer \\textbf{A}lignment \\textbf{M}odel, to observe coordinated\nrepresentations between the two modalities. We used various relationship\nalignment-seeking techniques, such as Canonical Correlation Analysis and\nWasserstein Distance, as loss functions to transfigure features. On downstream\napplications, sentiment analysis and relation detection, we achieved new\nstate-of-the-art results on two datasets, ZuCo and K-EmoCon. Our method\nachieved an F1-score improvement of 1.7% on K-EmoCon and 9.3% on Zuco datasets\nfor sentiment analysis, and 7.4% on ZuCo for relation detection. In addition,\nwe provide interpretations of the performance improvement: (1) feature\ndistribution shows the effectiveness of the alignment module for discovering\nand encoding the relationship between EEG and language; (2) alignment weights\nshow the influence of different language semantics as well as EEG frequency\nfeatures; (3) brain topographical maps provide an intuitive demonstration of\nthe connectivity in the brain regions. Our code is available at\n\\url{https://github.com/Jason-Qiu/EEG_Language_Alignment}.",
          "link": "http://arxiv.org/abs/2208.06348",
          "publishedOn": "2023-10-21T00:41:43.027Z",
          "wordCount": null,
          "title": "Can Brain Signals Reveal Inner Alignment with Human Languages?. (arXiv:2208.06348v4 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12806",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gauss_J/0/1/0/all/0/1\">Jana Gauss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scheipl_F/0/1/0/all/0/1\">Fabian Scheipl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Herrmann_M/0/1/0/all/0/1\">Moritz Herrmann</a>",
          "description": "Whether class labels in a given data set correspond to meaningful clusters is\ncrucial for the evaluation of clustering algorithms using real-world data sets.\nThis property can be quantified by separability measures. A review of the\nexisting literature shows that neither classification-based complexity measures\nnor cluster validity indices (CVIs) adequately incorporate the central aspects\nof separability for density-based clustering: between-class separation and\nwithin-class connectedness. A newly developed measure (density cluster\nseparability index, DCSI) aims to quantify these two characteristics and can\nalso be used as a CVI. Extensive experiments on synthetic data indicate that\nDCSI correlates strongly with the performance of DBSCAN measured via the\nadjusted rand index (ARI) but lacks robustness when it comes to multi-class\ndata sets with overlapping classes that are ill-suited for density-based hard\nclustering. Detailed evaluation on frequently used real-world data sets shows\nthat DCSI can correctly identify touching or overlapping classes that do not\nform meaningful clusters.",
          "link": "http://arxiv.org/abs/2310.12806",
          "publishedOn": "2023-10-21T00:41:43.021Z",
          "wordCount": null,
          "title": "DCSI -- An improved measure of cluster separability based on separation and connectedness. (arXiv:2310.12806v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06344",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1\">Ziyuan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rempe_D/0/1/0/all/0/1\">Davis Rempe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxiao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivanovic_B/0/1/0/all/0/1\">Boris Ivanovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yulong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Danfei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1\">Baishakhi Ray</a>",
          "description": "Realistic and controllable traffic simulation is a core capability that is\nnecessary to accelerate autonomous vehicle (AV) development. However, current\napproaches for controlling learning-based traffic models require significant\ndomain expertise and are difficult for practitioners to use. To remedy this, we\npresent CTG++, a scene-level conditional diffusion model that can be guided by\nlanguage instructions. Developing this requires tackling two challenges: the\nneed for a realistic and controllable traffic model backbone, and an effective\nmethod to interface with a traffic model using language. To address these\nchallenges, we first propose a scene-level diffusion model equipped with a\nspatio-temporal transformer backbone, which generates realistic and\ncontrollable traffic. We then harness a large language model (LLM) to convert a\nuser's query into a loss function, guiding the diffusion model towards\nquery-compliant generation. Through comprehensive evaluation, we demonstrate\nthe effectiveness of our proposed method in generating realistic,\nquery-compliant traffic simulations.",
          "link": "http://arxiv.org/abs/2306.06344",
          "publishedOn": "2023-10-21T00:41:43.021Z",
          "wordCount": null,
          "title": "Language-Guided Traffic Simulation via Scene-Level Diffusion. (arXiv:2306.06344v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.15687",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Le_M/0/1/0/all/0/1\">Matthew Le</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vyas_A/0/1/0/all/0/1\">Apoorv Vyas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_B/0/1/0/all/0/1\">Bowen Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karrer_B/0/1/0/all/0/1\">Brian Karrer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sari_L/0/1/0/all/0/1\">Leda Sari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moritz_R/0/1/0/all/0/1\">Rashel Moritz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Williamson_M/0/1/0/all/0/1\">Mary Williamson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Manohar_V/0/1/0/all/0/1\">Vimal Manohar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mahadeokar_J/0/1/0/all/0/1\">Jay Mahadeokar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>",
          "description": "Large-scale generative models such as GPT and DALL-E have revolutionized the\nresearch community. These models not only generate high fidelity outputs, but\nare also generalists which can solve tasks not explicitly taught. In contrast,\nspeech generative models are still primitive in terms of scale and task\ngeneralization. In this paper, we present Voicebox, the most versatile\ntext-guided generative model for speech at scale. Voicebox is a\nnon-autoregressive flow-matching model trained to infill speech, given audio\ncontext and text, trained on over 50K hours of speech that are not filtered or\nenhanced. Similar to GPT, Voicebox can perform many different tasks through\nin-context learning, but is more flexible as it can also condition on future\ncontext. Voicebox can be used for mono or cross-lingual zero-shot\ntext-to-speech synthesis, noise removal, content editing, style conversion, and\ndiverse sample generation. In particular, Voicebox outperforms the\nstate-of-the-art zero-shot TTS model VALL-E on both intelligibility (5.9% vs\n1.9% word error rates) and audio similarity (0.580 vs 0.681) while being up to\n20 times faster. Audio samples can be found in\n\\url{https://voicebox.metademolab.com}.",
          "link": "http://arxiv.org/abs/2306.15687",
          "publishedOn": "2023-10-21T00:41:43.021Z",
          "wordCount": null,
          "title": "Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale. (arXiv:2306.15687v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingcheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haoran Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yuxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hulei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Hongqiao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zheng Tian</a>",
          "description": "Data-driven black-box model-based optimization (MBO) problems arise in a\ngreat number of practical application scenarios, where the goal is to find a\ndesign over the whole space maximizing a black-box target function based on a\nstatic offline dataset. In this work, we consider a more general but\nchallenging MBO setting, named constrained MBO (CoMBO), where only part of the\ndesign space can be optimized while the rest is constrained by the environment.\nA new challenge arising from CoMBO is that most observed designs that satisfy\nthe constraints are mediocre in evaluation. Therefore, we focus on optimizing\nthese mediocre designs in the offline dataset while maintaining the given\nconstraints rather than further boosting the best observed design in the\ntraditional MBO setting. We propose retrieval-enhanced offline model-based\noptimization (ROMO), a new derivable forward approach that retrieves the\noffline dataset and aggregates relevant samples to provide a trusted\nprediction, and use it for gradient-based optimization. ROMO is simple to\nimplement and outperforms state-of-the-art approaches in the CoMBO setting.\nEmpirically, we conduct experiments on a synthetic Hartmann (3D) function\ndataset, an industrial CIO dataset, and a suite of modified tasks in the\nDesign-Bench benchmark. Results show that ROMO performs well in a wide range of\nconstrained optimization tasks.",
          "link": "http://arxiv.org/abs/2310.07560",
          "publishedOn": "2023-10-21T00:41:43.021Z",
          "wordCount": null,
          "title": "ROMO: Retrieval-enhanced Offline Model-based Optimization. (arXiv:2310.07560v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Changhun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyungjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1\">Eunhyeok Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jae-Joon Kim</a>",
          "description": "Binary Neural Networks (BNNs) have emerged as a promising solution for\nreducing the memory footprint and compute costs of deep neural networks, but\nthey suffer from quality degradation due to the lack of freedom as activations\nand weights are constrained to the binary values. To compensate for the\naccuracy drop, we propose a novel BNN design called Binary Neural Network with\nINSTAnce-aware threshold (INSTA-BNN), which controls the quantization threshold\ndynamically in an input-dependent or instance-aware manner. According to our\nobservation, higher-order statistics can be a representative metric to estimate\nthe characteristics of the input distribution. INSTA-BNN is designed to adjust\nthe threshold dynamically considering various information, including\nhigher-order statistics, but it is also optimized judiciously to realize\nminimal overhead on a real device. Our extensive study shows that INSTA-BNN\noutperforms the baseline by 3.0% and 2.8% on the ImageNet classification task\nwith comparable computing cost, achieving 68.5% and 72.2% top-1 accuracy on\nResNet-18 and MobileNetV1 based models, respectively.",
          "link": "http://arxiv.org/abs/2204.07439",
          "publishedOn": "2023-10-21T00:41:43.020Z",
          "wordCount": null,
          "title": "INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold. (arXiv:2204.07439v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuelong Li</a>",
          "description": "Spectral clustering and its extensions usually consist of two steps: (1)\nconstructing a graph and computing the relaxed solution; (2) discretizing\nrelaxed solutions. Although the former has been extensively investigated, the\ndiscretization techniques are mainly heuristic methods, e.g., k-means, spectral\nrotation. Unfortunately, the goal of the existing methods is not to find a\ndiscrete solution that minimizes the original objective. In other words, the\nprimary drawback is the neglect of the original objective when computing the\ndiscrete solution. Inspired by the first-order optimization algorithms, we\npropose to develop a first-order term to bridge the original problem and\ndiscretization algorithm, which is the first non-heuristic to the best of our\nknowledge. Since the non-heuristic method is aware of the original graph cut\nproblem, the final discrete solution is more reliable and achieves the\npreferable loss value. We also theoretically show that the continuous optimum\nis beneficial to discretization algorithms though simply finding its closest\ndiscrete solution is an existing heuristic algorithm which is also unreliable.\nSufficient experiments significantly show the superiority of our method.",
          "link": "http://arxiv.org/abs/2310.12752",
          "publishedOn": "2023-10-21T00:41:43.005Z",
          "wordCount": null,
          "title": "Discretize Relaxed Solution of Spectral Clustering via a Non-Heuristic Algorithm. (arXiv:2310.12752v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Halabi_M/0/1/0/all/0/1\">Marwa El Halabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1\">Federico Fusco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_Fard_A/0/1/0/all/0/1\">Ashkan Norouzi-Fard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tardos_J/0/1/0/all/0/1\">Jakab Tardos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarnawski_J/0/1/0/all/0/1\">Jakub Tarnawski</a>",
          "description": "Streaming submodular maximization is a natural model for the task of\nselecting a representative subset from a large-scale dataset. If datapoints\nhave sensitive attributes such as gender or race, it becomes important to\nenforce fairness to avoid bias and discrimination. This has spurred significant\ninterest in developing fair machine learning algorithms. Recently, such\nalgorithms have been developed for monotone submodular maximization under a\ncardinality constraint.\n\nIn this paper, we study the natural generalization of this problem to a\nmatroid constraint. We give streaming algorithms as well as impossibility\nresults that provide trade-offs between efficiency, quality and fairness. We\nvalidate our findings empirically on a range of well-known real-world\napplications: exemplar-based clustering, movie recommendation, and maximum\ncoverage in social networks.",
          "link": "http://arxiv.org/abs/2305.15118",
          "publishedOn": "2023-10-21T00:41:42.989Z",
          "wordCount": null,
          "title": "Fairness in Streaming Submodular Maximization over a Matroid Constraint. (arXiv:2305.15118v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sabry_M/0/1/0/all/0/1\">Mohammed Sabry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belz_A/0/1/0/all/0/1\">Anya Belz</a>",
          "description": "Recent parameter-efficient finetuning (PEFT) techniques aim to improve over\nthe considerable cost of fully finetuning large pretrained language models\n(PLM). As different PEFT techniques proliferate, it is becoming difficult to\ncompare them, in particular in terms of (i) the structure and functionality\nthey add to the PLM, (ii) the different types and degrees of efficiency\nimprovements achieved, (iii) performance at different downstream tasks, and\n(iv) how differences in structure and functionality relate to efficiency and\ntask performance. To facilitate such comparisons, this paper presents a\nreference architecture which standardises aspects shared by different PEFT\ntechniques, while isolating differences to specific locations and interactions\nwith the standard components. Through this process of standardising and\nisolating differences, a modular view of PEFT techniques emerges, supporting\nnot only direct comparison of different techniques and their efficiency and\ntask performance, but also systematic exploration of reusability and\ncomposability of the different types of finetuned modules. We demonstrate how\nthe reference architecture can be applied to understand properties and relative\nadvantages of PEFT techniques, hence to inform selection of techniques for\nspecific tasks, and design choices for new PEFT techniques.",
          "link": "http://arxiv.org/abs/2304.12410",
          "publishedOn": "2023-10-21T00:41:42.959Z",
          "wordCount": null,
          "title": "PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques. (arXiv:2304.12410v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kujanpaa_K/0/1/0/all/0/1\">Kalle Kujanp&#xe4;&#xe4;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1\">Joni Pajarinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilin_A/0/1/0/all/0/1\">Alexander Ilin</a>",
          "description": "Solving complex planning problems has been a long-standing challenge in\ncomputer science. Learning-based subgoal search methods have shown promise in\ntackling these problems, but they often suffer from a lack of completeness\nguarantees, meaning that they may fail to find a solution even if one exists.\nIn this paper, we propose an efficient approach to augment a subgoal search\nmethod to achieve completeness in discrete action spaces. Specifically, we\naugment the high-level search with low-level actions to execute a multi-level\n(hybrid) search, which we call complete subgoal search. This solution achieves\nthe best of both worlds: the practical efficiency of high-level search and the\ncompleteness of low-level search. We apply the proposed search method to a\nrecently proposed subgoal search algorithm and evaluate the algorithm trained\non offline data on complex planning problems. We demonstrate that our complete\nsubgoal search not only guarantees completeness but can even improve\nperformance in terms of search expansions for instances that the high-level\ncould solve without low-level augmentations. Our approach makes it possible to\napply subgoal-level planning for systems where completeness is a critical\nrequirement.",
          "link": "http://arxiv.org/abs/2310.12819",
          "publishedOn": "2023-10-21T00:41:42.949Z",
          "wordCount": null,
          "title": "Hybrid Search for Efficient Planning with Completeness Guarantees. (arXiv:2310.12819v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.07940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1\">Harshavardhan Kamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingkai Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Alexander Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1\">B. Aditya Prakash</a>",
          "description": "Probabilistic hierarchical time-series forecasting is an important variant of\ntime-series forecasting, where the goal is to model and forecast multivariate\ntime-series that have underlying hierarchical relations. Most methods focus on\npoint predictions and do not provide well-calibrated probabilistic forecasts\ndistributions. Recent state-of-art probabilistic forecasting methods also\nimpose hierarchical relations on point predictions and samples of distribution\nwhich does not account for coherency of forecast distributions. Previous works\nalso silently assume that datasets are always consistent with given\nhierarchical relations and do not adapt to real-world datasets that show\ndeviation from this assumption. We close both these gap and propose PROFHiT,\nwhich is a fully probabilistic hierarchical forecasting model that jointly\nmodels forecast distribution of entire hierarchy. PROFHiT uses a flexible\nprobabilistic Bayesian approach and introduces a novel Distributional Coherency\nregularization to learn from hierarchical relations for entire forecast\ndistribution that enables robust and calibrated forecasts as well as adapt to\ndatasets of varying hierarchical consistency. On evaluating PROFHiT over wide\nrange of datasets, we observed 41-88% better performance in accuracy and\nsignificantly better calibration. Due to modeling the coherency over full\ndistribution, we observed that PROFHiT can robustly provide reliable forecasts\neven if up to 10% of input time-series data is missing where other methods'\nperformance severely degrade by over 70%.",
          "link": "http://arxiv.org/abs/2206.07940",
          "publishedOn": "2023-10-21T00:41:42.943Z",
          "wordCount": null,
          "title": "When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting. (arXiv:2206.07940v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12774",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Han Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>",
          "description": "Prompt-based learning has been an effective paradigm for large pretrained\nlanguage models (LLM), enabling few-shot or even zero-shot learning. Black-box\nprompt search has received growing interest recently for its distinctive\nproperties of gradient-free optimization, proven particularly useful and\npowerful for model-as-a-service usage. However, the discrete nature and the\ncomplexity of combinatorial optimization hinder the efficiency of modern\nblack-box approaches. Despite extensive research on search algorithms, the\ncrucial aspect of search space design and optimization has been largely\noverlooked. In this paper, we first conduct a sensitivity analysis by prompting\nLLM, revealing that only a small number of tokens exert a disproportionate\namount of influence on LLM predictions. Leveraging this insight, we propose the\nClustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple\nblack-box search method that first clusters and prunes the search space to\nfocus exclusively on influential prompt tokens. By employing even simple search\nmethods within the pruned search space, ClaPS achieves state-of-the-art\nperformance across various tasks and LLMs, surpassing the performance of\ncomplex approaches while significantly reducing search costs. Our findings\nunderscore the critical role of search space design and optimization in\nenhancing both the usefulness and the efficiency of black-box prompt-based\nlearning.",
          "link": "http://arxiv.org/abs/2310.12774",
          "publishedOn": "2023-10-21T00:41:42.937Z",
          "wordCount": null,
          "title": "Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning. (arXiv:2310.12774v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12346",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Kerber_S/0/1/0/all/0/1\">Samuel W Kerber</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Duncan_N/0/1/0/all/0/1\">Nicholas A Duncan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+LHer_G/0/1/0/all/0/1\">Guillaume F LHer</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bazilian_M/0/1/0/all/0/1\">Morgan Bazilian</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Elvidge_C/0/1/0/all/0/1\">Chris Elvidge</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Deinert_M/0/1/0/all/0/1\">Mark R Deinert</a>",
          "description": "Urban environments are intricate systems where the breakdown of critical\ninfrastructure can impact both the economic and social well-being of\ncommunities. Electricity systems hold particular significance, as they are\nessential for other infrastructure, and disruptions can trigger widespread\nconsequences. Typically, assessing electricity availability requires\nground-level data, a challenge in conflict zones and regions with limited\naccess. This study shows how satellite imagery, social media, and information\nextraction can monitor blackouts and their perceived causes. Night-time light\ndata (in March 2019 for Caracas, Venezuela) is used to indicate blackout\nregions. Twitter data is used to determine sentiment and topic trends, while\nstatistical analysis and topic modeling delved into public perceptions\nregarding blackout causes. The findings show an inverse relationship between\nnighttime light intensity. Tweets mentioning the Venezuelan President displayed\nheightened negativity and a greater prevalence of blame-related terms,\nsuggesting a perception of government accountability for the outages.",
          "link": "http://arxiv.org/abs/2310.12346",
          "publishedOn": "2023-10-21T00:41:42.931Z",
          "wordCount": null,
          "title": "Tracking electricity losses and their perceived causes using nighttime light and social media. (arXiv:2310.12346v1 [physics.soc-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1\">Amir Feder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wald_Y/0/1/0/all/0/1\">Yoav Wald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Claudia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saria_S/0/1/0/all/0/1\">Suchi Saria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blei_D/0/1/0/all/0/1\">David Blei</a>",
          "description": "The reliance of text classifiers on spurious correlations can lead to poor\ngeneralization at deployment, raising concerns about their use in\nsafety-critical domains such as healthcare. In this work, we propose to use\ncounterfactual data augmentation, guided by knowledge of the causal structure\nof the data, to simulate interventions on spurious features and to learn more\nrobust text classifiers. We show that this strategy is appropriate in\nprediction problems where the label is spuriously correlated with an attribute.\nUnder the assumptions of such problems, we discuss the favorable sample\ncomplexity of counterfactual data augmentation, compared to importance\nre-weighting. Pragmatically, we match examples using auxiliary data, based on\ndiff-in-diff methodology, and use a large language model (LLM) to represent a\nconditional probability of text. Through extensive experimentation on learning\ncaregiver-invariant predictors of clinical diagnoses from medical narratives\nand on semi-synthetic data, we demonstrate that our method for simulating\ninterventions improves out-of-distribution (OOD) accuracy compared to baseline\ninvariant learning algorithms.",
          "link": "http://arxiv.org/abs/2310.12803",
          "publishedOn": "2023-10-21T00:41:42.930Z",
          "wordCount": null,
          "title": "Causal-structure Driven Augmentations for Text OOD Generalization. (arXiv:2310.12803v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paissan_F/0/1/0/all/0/1\">Francesco Paissan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhepei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravanelli_M/0/1/0/all/0/1\">Mirco Ravanelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smaragdis_P/0/1/0/all/0/1\">Paris Smaragdis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subakan_C/0/1/0/all/0/1\">Cem Subakan</a>",
          "description": "In this paper, we explore audio-editing with non-rigid text edits. We show\nthat the proposed editing pipeline is able to create audio edits that remain\nfaithful to the input audio. We explore text prompts that perform addition,\nstyle transfer, and in-painting. We quantitatively and qualitatively show that\nthe edits are able to obtain results which outperform Audio-LDM, a recently\nreleased text-prompted audio generation model. Qualitative inspection of the\nresults points out that the edits given by our approach remain more faithful to\nthe input audio in terms of keeping the original onsets and offsets of the\naudio events.",
          "link": "http://arxiv.org/abs/2310.12858",
          "publishedOn": "2023-10-21T00:41:42.930Z",
          "wordCount": null,
          "title": "Audio Editing with Non-Rigid Text Prompts. (arXiv:2310.12858v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.12321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jang-Hyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Sangdoo Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hyun Oh Song</a>",
          "description": "Diagnosing and cleaning data is a crucial step for building robust machine\nlearning systems. However, identifying problems within large-scale datasets\nwith real-world distributions is challenging due to the presence of complex\nissues such as label errors, under-representation, and outliers. In this paper,\nwe propose a unified approach for identifying the problematic data by utilizing\na largely ignored source of information: a relational structure of data in the\nfeature-embedded space. To this end, we present scalable and effective\nalgorithms for detecting label errors and outlier data based on the relational\ngraph structure of data. We further introduce a visualization tool that\nprovides contextual information of a data point in the feature-embedded space,\nserving as an effective tool for interactively diagnosing data. We evaluate the\nlabel error and outlier/out-of-distribution (OOD) detection performances of our\napproach on the large-scale image, speech, and language domain tasks, including\nImageNet, ESC-50, and SST2. Our approach achieves state-of-the-art detection\nperformance on all tasks considered and demonstrates its effectiveness in\ndebugging large-scale real-world datasets across various domains. We release\ncodes at https://github.com/snu-mllab/Neural-Relation-Graph.",
          "link": "http://arxiv.org/abs/2301.12321",
          "publishedOn": "2023-10-21T00:41:42.929Z",
          "wordCount": null,
          "title": "Neural Relation Graph: A Unified Framework for Identifying Label Noise and Outlier Data. (arXiv:2301.12321v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoshikawa_u/0/1/0/all/0/1\">uya Yoshikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1\">Tomoharu Iwata</a>",
          "description": "The quality of explanations for the predictions of complex machine learning\npredictors is often measured using insertion and deletion metrics, which assess\nthe faithfulness of the explanations, i.e., how correctly the explanations\nreflect the predictor's behavior. To improve the faithfulness, we propose\ninsertion/deletion metric-aware explanation-based optimization (ID-ExpO), which\noptimizes differentiable predictors to improve both insertion and deletion\nscores of the explanations while keeping their predictive accuracy. Since the\noriginal insertion and deletion metrics are indifferentiable with respect to\nthe explanations and directly unavailable for gradient-based optimization, we\nextend the metrics to be differentiable and use them to formalize insertion and\ndeletion metric-based regularizers. The experimental results on image and\ntabular datasets show that the deep neural networks-based predictors fine-tuned\nusing ID-ExpO enable popular post-hoc explainers to produce more faithful and\neasy-to-interpret explanations while keeping high predictive accuracy.",
          "link": "http://arxiv.org/abs/2310.12553",
          "publishedOn": "2023-10-21T00:41:42.923Z",
          "wordCount": null,
          "title": "Explanation-Based Training with Differentiable Insertion/Deletion Metric-Aware Regularizers. (arXiv:2310.12553v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.14276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Volk_T/0/1/0/all/0/1\">Tomer Volk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_David_E/0/1/0/all/0/1\">Eyal Ben-David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amosy_O/0/1/0/all/0/1\">Ohad Amosy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1\">Roi Reichart</a>",
          "description": "As Natural Language Processing (NLP) algorithms continually achieve new\nmilestones, out-of-distribution generalization remains a significant challenge.\nThis paper addresses the issue of multi-source adaptation for unfamiliar\ndomains: We leverage labeled data from multiple source domains to generalize to\nunknown target domains at training. Our innovative framework employs\nexample-based Hypernetwork adaptation: a T5 encoder-decoder initially generates\na unique signature from an input example, embedding it within the source\ndomains' semantic space. This signature is subsequently utilized by a\nHypernetwork to generate the task classifier's weights. We evaluated our method\nacross two tasks - sentiment classification and natural language inference - in\n29 adaptation scenarios, where it outpaced established algorithms. In an\nadvanced version, the signature also enriches the input example's\nrepresentation. We also compare our finetuned architecture to few-shot GPT-3,\ndemonstrating its effectiveness in essential use cases. To our knowledge, this\nmarks the first application of Hypernetworks to the adaptation for unknown\ndomains.",
          "link": "http://arxiv.org/abs/2203.14276",
          "publishedOn": "2023-10-21T00:41:42.923Z",
          "wordCount": null,
          "title": "Example-based Hypernetworks for Out-of-Distribution Generalization. (arXiv:2203.14276v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jiayi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Lei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiaoyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhengzong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhirui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengnan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xue Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xucheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yiqiao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1\">Chao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chengru Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1\">Junchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zijia Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fuzheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Di Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gai_K/0/1/0/all/0/1\">Kun Gai</a>",
          "description": "Recent advancements in large language models (LLMs) have demonstrated\nremarkable abilities in handling a variety of natural language processing (NLP)\ndownstream tasks, even on mathematical tasks requiring multi-step reasoning. In\nthis report, we introduce the KwaiYiiMath which enhances the mathematical\nreasoning abilities of KwaiYiiBase1, by applying Supervised Fine-Tuning (SFT)\nand Reinforced Learning from Human Feedback (RLHF), including on both English\nand Chinese mathematical tasks. Meanwhile, we also constructed a small-scale\nChinese primary school mathematics test set (named KMath), consisting of 188\nexamples to evaluate the correctness of the problem-solving process generated\nby the models. Empirical studies demonstrate that KwaiYiiMath can achieve\nstate-of-the-art (SOTA) performance on GSM8k, CMath, and KMath compared with\nthe similar size models, respectively.",
          "link": "http://arxiv.org/abs/2310.07488",
          "publishedOn": "2023-10-21T00:41:42.920Z",
          "wordCount": null,
          "title": "KwaiYiiMath: Technical Report. (arXiv:2310.07488v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.00617",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Giegrich_M/0/1/0/all/0/1\">Michael Giegrich</a>, <a href=\"http://arxiv.org/find/math/1/au:+Reisinger_C/0/1/0/all/0/1\">Christoph Reisinger</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1\">Yufei Zhang</a>",
          "description": "We study the global linear convergence of policy gradient (PG) methods for\nfinite-horizon continuous-time exploratory linear-quadratic control (LQC)\nproblems. The setting includes stochastic LQC problems with indefinite costs\nand allows additional entropy regularisers in the objective. We consider a\ncontinuous-time Gaussian policy whose mean is linear in the state variable and\nwhose covariance is state-independent. Contrary to discrete-time problems, the\ncost is noncoercive in the policy and not all descent directions lead to\nbounded iterates. We propose geometry-aware gradient descents for the mean and\ncovariance of the policy using the Fisher geometry and the Bures-Wasserstein\ngeometry, respectively. The policy iterates are shown to satisfy an a-priori\nbound, and converge globally to the optimal policy with a linear rate. We\nfurther propose a novel PG method with discrete-time policies. The algorithm\nleverages the continuous-time analysis, and achieves a robust linear\nconvergence across different action frequencies. A numerical experiment\nconfirms the convergence and robustness of the proposed algorithm.",
          "link": "http://arxiv.org/abs/2211.00617",
          "publishedOn": "2023-10-21T00:41:42.909Z",
          "wordCount": null,
          "title": "Convergence of policy gradient methods for finite-horizon stochastic linear-quadratic control problems. (arXiv:2211.00617v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.01328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_D/0/1/0/all/0/1\">David M. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myers_A/0/1/0/all/0/1\">Austin Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vijayanarasimhan_S/0/1/0/all/0/1\">Sudheendra Vijayanarasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_D/0/1/0/all/0/1\">David A. Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canny_J/0/1/0/all/0/1\">John Canny</a>",
          "description": "If you ask a human to describe an image, they might do so in a thousand\ndifferent ways. Traditionally, image captioning models are trained to generate\na single \"best\" (most like a reference) image caption. Unfortunately, doing so\nencourages captions that are \"informationally impoverished,\" and focus on only\na subset of the possible details, while ignoring other potentially useful\ninformation in the scene. In this work, we introduce a simple, yet novel,\nmethod: \"Image Captioning by Committee Consensus\" (IC3), designed to generate a\nsingle caption that captures high-level details from several annotator\nviewpoints. Humans rate captions produced by IC3 at least as helpful as\nbaseline SOTA models more than two thirds of the time, and IC3 can improve the\nperformance of SOTA automated recall systems by up to 84%, outperforming single\nhuman-generated reference captions, and indicating significant improvements\nover SOTA approaches for visual description. Code is available at\nhttps://davidmchan.github.io/caption-by-committee/",
          "link": "http://arxiv.org/abs/2302.01328",
          "publishedOn": "2023-10-21T00:41:42.908Z",
          "wordCount": null,
          "title": "IC3: Image Captioning by Committee Consensus. (arXiv:2302.01328v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.01365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1\">Hong Jun Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "We study the compute-optimal trade-off between model and training data set\nsizes for large neural networks. Our result suggests a linear relation similar\nto that supported by the empirical analysis of chinchilla. While that work\nstudies transformer-based large language models trained on the MassiveText\ncorpus gopher, as a starting point for development of a mathematical theory, we\nfocus on a simpler learning model and data generating process, each based on a\nneural network with a sigmoidal output unit and single hidden layer of ReLU\nactivation units. We introduce general error upper bounds for a class of\nalgorithms which incrementally update a statistic (for example gradient\ndescent). For a particular learning model inspired by barron 1993, we establish\nan upper bound on the minimal information-theoretically achievable expected\nerror as a function of model and data set sizes. We then derive allocations of\ncomputation that minimize this bound. We present empirical results which\nsuggest that this approximation correctly identifies an asymptotic linear\ncompute-optimal scaling. This approximation also generates new insights. Among\nother things, it suggests that, as the input dimension or latent space\ncomplexity grows, as might be the case for example if a longer history of\ntokens is taken as input to a language model, a larger fraction of the compute\nbudget should be allocated to growing the learning model rather than training\ndata.",
          "link": "http://arxiv.org/abs/2212.01365",
          "publishedOn": "2023-10-21T00:41:42.907Z",
          "wordCount": null,
          "title": "An Information-Theoretic Analysis of Compute-Optimal Neural Scaling Laws. (arXiv:2212.01365v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.09730",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maimon_G/0/1/0/all/0/1\">Gallil Maimon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>",
          "description": "We introduce DISSC, a novel, lightweight method that converts the rhythm,\npitch contour and timbre of a recording to a target speaker in a textless\nmanner. Unlike DISSC, most voice conversion (VC) methods focus primarily on\ntimbre, and ignore people's unique speaking style (prosody). The proposed\napproach uses a pretrained, self-supervised model for encoding speech to\ndiscrete units, which makes it simple, effective, and fast to train. All\nconversion modules are only trained on reconstruction like tasks, thus suitable\nfor any-to-many VC with no paired data. We introduce a suite of quantitative\nand qualitative evaluation metrics for this setup, and empirically demonstrate\nthat DISSC significantly outperforms the evaluated baselines. Code and samples\nare available at https://pages.cs.huji.ac.il/adiyoss-lab/dissc/.",
          "link": "http://arxiv.org/abs/2212.09730",
          "publishedOn": "2023-10-21T00:41:42.904Z",
          "wordCount": null,
          "title": "Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units. (arXiv:2212.09730v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shufan Jiang</a> (CRESTIC, ISEP), <a href=\"http://arxiv.org/find/cs/1/au:+Angarita_R/0/1/0/all/0/1\">Rafael Angarita</a> (ISEP), <a href=\"http://arxiv.org/find/cs/1/au:+Cormier_S/0/1/0/all/0/1\">St&#xe9;phane Cormier</a> (CRESTIC), <a href=\"http://arxiv.org/find/cs/1/au:+Rousseaux_F/0/1/0/all/0/1\">Francis Rousseaux</a> (CRESTIC)",
          "description": "An important application scenario of precision agriculture is detecting and\nmeasuring crop health threats using sensors and data analysis techniques.\nHowever, the textual data are still under-explored among the existing solutions\ndue to the lack of labelled data and fine-grained semantic resources. Recent\nresearch suggests that the increasing connectivity of farmers and the emergence\nof online farming communities make social media like Twitter a participatory\nplatform for detecting unfamiliar plant health events if we can extract\nessential information from unstructured textual data. ChouBERT is a French\npre-trained language model that can identify Tweets concerning observations of\nplant health issues with generalizability on unseen natural hazards. This paper\ntackles the lack of labelled data by further studying ChouBERT's know-how on\ntoken-level annotation tasks over small labeled sets.",
          "link": "http://arxiv.org/abs/2310.12522",
          "publishedOn": "2023-10-21T00:41:42.902Z",
          "wordCount": null,
          "title": "Named Entity Recognition for Monitoring Plant Health Threats in Tweets: a ChouBERT Approach. (arXiv:2310.12522v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.13623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Baihan Lin</a>",
          "description": "In recent years, reinforcement learning and bandits have transformed a wide\nrange of real-world applications including healthcare, finance, recommendation\nsystems, robotics, and last but not least, the speech and natural language\nprocessing. While most speech and language applications of reinforcement\nlearning algorithms are centered around improving the training of deep neural\nnetworks with its flexible optimization properties, there are still many\ngrounds to explore to utilize the benefits of reinforcement learning, such as\nits reward-driven adaptability, state representations, temporal structures and\ngeneralizability. In this survey, we present an overview of recent advancements\nof reinforcement learning and bandits, and discuss how they can be effectively\nemployed to solve speech and natural language processing problems with models\nthat are adaptive, interactive and scalable.",
          "link": "http://arxiv.org/abs/2210.13623",
          "publishedOn": "2023-10-21T00:41:42.899Z",
          "wordCount": null,
          "title": "Reinforcement Learning and Bandits for Speech and Language Processing: Tutorial, Review and Outlook. (arXiv:2210.13623v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.13001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dey_J/0/1/0/all/0/1\">Jayanta Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeVine_W/0/1/0/all/0/1\">Will LeVine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoyin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1\">Ashwin De Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomita_T/0/1/0/all/0/1\">Tyler M. Tomita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geisa_A/0/1/0/all/0/1\">Ali Geisa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1\">Tiffany Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desman_J/0/1/0/all/0/1\">Jacob Desman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>",
          "description": "Deep discriminative approaches like random forests and deep neural networks\nhave recently found applications in many important real-world scenarios.\nHowever, deploying these learning algorithms in safety-critical applications\nraises concerns, particularly when it comes to ensuring confidence calibration\nfor both in-distribution and out-of-distribution data points. Many popular\nmethods for in-distribution (ID) calibration, such as isotonic regression and\nPlatt's sigmoidal regression, exhibit excellent ID calibration performance but\noften at the cost of classification accuracy. Moreover, these methods are not\ncalibrated for the entire feature space, leading to overconfidence in the case\nof out-of-distribution (OOD) samples. In this paper, we leveraged the fact that\ndeep models, including both random forests and deep-nets, learn internal\nrepresentations which are unions of polytopes with affine activation functions\nto conceptualize them both as partitioning rules of the feature space. We\nreplace the affine function in each polytope populated by the training data\nwith a Gaussian kernel. We propose sufficient conditions for our proposed\nmethods to be consistent estimators of the corresponding class conditional\ndensities. Moreover, our experiments on both tabular and vision benchmarks show\nthat the proposed approaches obtain well-calibrated posteriors while mostly\npreserving or improving the classification accuracy of the original algorithm\nfor in-distribution region, and extrapolates beyond the training data to handle\nout-of-distribution inputs appropriately.",
          "link": "http://arxiv.org/abs/2201.13001",
          "publishedOn": "2023-10-21T00:41:42.894Z",
          "wordCount": null,
          "title": "Deep Discriminative to Kernel Density Networks for Calibrated Inference. (arXiv:2201.13001v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.10398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tianqi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1\">Ngan Thi Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanjalic_A/0/1/0/all/0/1\">Alan Hanjalic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khosla_M/0/1/0/all/0/1\">Megha Khosla</a>",
          "description": "Graph Neural Networks (GNNs) have shown state-of-the-art improvements in node\nclassification tasks on graphs. While these improvements have been largely\ndemonstrated in a multi-class classification scenario, a more general and\nrealistic scenario in which each node could have multiple labels has so far\nreceived little attention. The first challenge in conducting focused studies on\nmulti-label node classification is the limited number of publicly available\nmulti-label graph datasets. Therefore, as our first contribution, we collect\nand release three real-world biological datasets and develop a multi-label\ngraph generator to generate datasets with tunable properties. While high label\nsimilarity (high homophily) is usually attributed to the success of GNNs, we\nargue that a multi-label scenario does not follow the usual semantics of\nhomophily and heterophily so far defined for a multi-class scenario. As our\nsecond contribution, we define homophily and Cross-Class Neighborhood\nSimilarity for the multi-label scenario and provide a thorough analyses of the\ncollected $9$ multi-label datasets. Finally, we perform a large-scale\ncomparative study with $8$ methods and $9$ datasets and analyse the\nperformances of the methods to assess the progress made by current state of the\nart in the multi-label node classification scenario. We release our benchmark\nat https://github.com/Tianqi-py/MLGNC.",
          "link": "http://arxiv.org/abs/2304.10398",
          "publishedOn": "2023-10-21T00:41:42.894Z",
          "wordCount": null,
          "title": "Multi-label Node Classification On Graph-Structured Data. (arXiv:2304.10398v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Minjie Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hongteng Xu</a>",
          "description": "When learning graph neural networks (GNNs) in node-level prediction tasks,\nmost existing loss functions are applied for each node independently, even if\nnode embeddings and their labels are non-i.i.d. because of their graph\nstructures. To eliminate such inconsistency, in this study we propose a novel\nQuasi-Wasserstein (QW) loss with the help of the optimal transport defined on\ngraphs, leading to new learning and prediction paradigms of GNNs. In\nparticular, we design a \"Quasi-Wasserstein\" distance between the observed\nmulti-dimensional node labels and their estimations, optimizing the label\ntransport defined on graph edges. The estimations are parameterized by a GNN in\nwhich the optimal label transport may determine the graph edge weights\noptionally. By reformulating the strict constraint of the label transport to a\nBregman divergence-based regularizer, we obtain the proposed Quasi-Wasserstein\nloss associated with two efficient solvers learning the GNN together with\noptimal label transport. When predicting node labels, our model combines the\noutput of the GNN with the residual component provided by the optimal label\ntransport, leading to a new transductive prediction paradigm. Experiments show\nthat the proposed QW loss applies to various GNNs and helps to improve their\nperformance in node-level classification and regression tasks.",
          "link": "http://arxiv.org/abs/2310.11762",
          "publishedOn": "2023-10-21T00:41:42.890Z",
          "wordCount": null,
          "title": "A Quasi-Wasserstein Loss for Learning Graph Neural Networks. (arXiv:2310.11762v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12893",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_C/0/1/0/all/0/1\">Changhao Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_B/0/1/0/all/0/1\">Boning Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Amer_O/0/1/0/all/0/1\">Omar Amer</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Shaydulin_R/0/1/0/all/0/1\">Ruslan Shaydulin</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Chakrabarti_S/0/1/0/all/0/1\">Shouvanik Chakrabarti</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_G/0/1/0/all/0/1\">Guoqing Wang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Xu_H/0/1/0/all/0/1\">Haowei Xu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tang_H/0/1/0/all/0/1\">Hao Tang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Schoch_I/0/1/0/all/0/1\">Isidor Schoch</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kumar_N/0/1/0/all/0/1\">Niraj Kumar</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lim_C/0/1/0/all/0/1\">Charles Lim</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_J/0/1/0/all/0/1\">Ju Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cappellaro_P/0/1/0/all/0/1\">Paola Cappellaro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Pistoia_M/0/1/0/all/0/1\">Marco Pistoia</a>",
          "description": "Distributed quantum computing is a promising computational paradigm for\nperforming computations that are beyond the reach of individual quantum\ndevices. Privacy in distributed quantum computing is critical for maintaining\nconfidentiality and protecting the data in the presence of untrusted computing\nnodes. In this work, we introduce novel blind quantum machine learning\nprotocols based on the quantum bipartite correlator algorithm. Our protocols\nhave reduced communication overhead while preserving the privacy of data from\nuntrusted parties. We introduce robust algorithm-specific privacy-preserving\nmechanisms with low computational overhead that do not require complex\ncryptographic techniques. We then validate the effectiveness of the proposed\nprotocols through complexity and privacy analysis. Our findings pave the way\nfor advancements in distributed quantum computing, opening up new possibilities\nfor privacy-aware machine learning applications in the era of quantum\ntechnologies.",
          "link": "http://arxiv.org/abs/2310.12893",
          "publishedOn": "2023-10-21T00:41:42.887Z",
          "wordCount": null,
          "title": "Blind quantum machine learning with quantum bipartite correlator. (arXiv:2310.12893v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yupei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yuqi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_R/0/1/0/all/0/1\">Runpeng Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jinyuan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>",
          "description": "Large Language Models (LLMs) are increasingly deployed as the backend for a\nvariety of real-world applications called LLM-Integrated Applications. Multiple\nrecent works showed that LLM-Integrated Applications are vulnerable to prompt\ninjection attacks, in which an attacker injects malicious instruction/data into\nthe input of those applications such that they produce results as the attacker\ndesires. However, existing works are limited to case studies. As a result, the\nliterature lacks a systematic understanding of prompt injection attacks and\ntheir defenses. We aim to bridge the gap in this work. In particular, we\npropose a general framework to formalize prompt injection attacks. Existing\nattacks, which are discussed in research papers and blog posts, are special\ncases in our framework. Our framework enables us to design a new attack by\ncombining existing attacks. Moreover, we also propose a framework to\nsystematize defenses against prompt injection attacks. Using our frameworks, we\nconduct a systematic evaluation on prompt injection attacks and their defenses\nwith 10 LLMs and 7 tasks. We hope our frameworks can inspire future research in\nthis field. Our code is available at\nhttps://github.com/liu00222/Open-Prompt-Injection.",
          "link": "http://arxiv.org/abs/2310.12815",
          "publishedOn": "2023-10-21T00:41:42.886Z",
          "wordCount": null,
          "title": "Prompt Injection Attacks and Defenses in LLM-Integrated Applications. (arXiv:2310.12815v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12862",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krupnik_O/0/1/0/all/0/1\">Orr Krupnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafer_E/0/1/0/all/0/1\">Elisei Shafer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurgenson_T/0/1/0/all/0/1\">Tom Jurgenson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamar_A/0/1/0/all/0/1\">Aviv Tamar</a>",
          "description": "Adaptable models could greatly benefit robotic agents operating in the real\nworld, allowing them to deal with novel and varying conditions. While\napproaches such as Bayesian inference are well-studied frameworks for adapting\nmodels to evidence, we build on recent advances in deep generative models which\nhave greatly affected many areas of robotics. Harnessing modern GPU\nacceleration, we investigate how to quickly adapt the sample generation of\nneural network models to observations in robotic tasks. We propose a simple and\ngeneral method that is applicable to various deep generative models and robotic\nenvironments. The key idea is to quickly fine-tune the model by fitting it to\ngenerated samples matching the observed evidence, using the cross-entropy\nmethod. We show that our method can be applied to both autoregressive models\nand variational autoencoders, and demonstrate its usability in object shape\ninference from grasping, inverse kinematics calculation, and point cloud\ncompletion.",
          "link": "http://arxiv.org/abs/2310.12862",
          "publishedOn": "2023-10-21T00:41:42.886Z",
          "wordCount": null,
          "title": "Fine-Tuning Generative Models as an Inference Method for Robotic Tasks. (arXiv:2310.12862v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1811.11479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_E/0/1/0/all/0/1\">Eunjeong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seungeun Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyesung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jihong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1\">Mehdi Bennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seong-Lyun Kim</a>",
          "description": "On-device machine learning (ML) enables the training process to exploit a\nmassive amount of user-generated private data samples. To enjoy this benefit,\ninter-device communication overhead should be minimized. With this end, we\npropose federated distillation (FD), a distributed model training algorithm\nwhose communication payload size is much smaller than a benchmark scheme,\nfederated learning (FL), particularly when the model size is large. Moreover,\nuser-generated data samples are likely to become non-IID across devices, which\ncommonly degrades the performance compared to the case with an IID dataset. To\ncope with this, we propose federated augmentation (FAug), where each device\ncollectively trains a generative model, and thereby augments its local data\ntowards yielding an IID dataset. Empirical studies demonstrate that FD with\nFAug yields around 26x less communication overhead while achieving 95-98% test\naccuracy compared to FL.",
          "link": "http://arxiv.org/abs/1811.11479",
          "publishedOn": "2023-10-21T00:41:42.878Z",
          "wordCount": null,
          "title": "Communication-Efficient On-Device Machine Learning: Federated Distillation and Augmentation under Non-IID Private Data. (arXiv:1811.11479v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12842",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wood_D/0/1/0/all/0/1\">Danny Wood</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papamarkou_T/0/1/0/all/0/1\">Theodore Papamarkou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Benatan_M/0/1/0/all/0/1\">Matt Benatan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Allmendinger_R/0/1/0/all/0/1\">Richard Allmendinger</a>",
          "description": "In order to trust the predictions of a machine learning algorithm, it is\nnecessary to understand the factors that contribute to those predictions. In\nthe case of probabilistic and uncertainty-aware models, it is necessary to\nunderstand not only the reasons for the predictions themselves, but also the\nmodel's level of confidence in those predictions. In this paper, we show how\nexisting methods in explainability can be extended to uncertainty-aware models\nand how such extensions can be used to understand the sources of uncertainty in\na model's predictive distribution. In particular, by adapting permutation\nfeature importance, partial dependence plots, and individual conditional\nexpectation plots, we demonstrate that novel insights into model behaviour may\nbe obtained and that these methods can be used to measure the impact of\nfeatures on both the entropy of the predictive distribution and the\nlog-likelihood of the ground truth labels under that distribution. With\nexperiments using both synthetic and real-world data, we demonstrate the\nutility of these approaches in understanding both the sources of uncertainty\nand their impact on model performance.",
          "link": "http://arxiv.org/abs/2310.12842",
          "publishedOn": "2023-10-21T00:41:42.870Z",
          "wordCount": null,
          "title": "Model-agnostic variable importance for predictive uncertainty: an entropy-based approach. (arXiv:2310.12842v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.08117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khalife_S/0/1/0/all/0/1\">Sammy Khalife</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hongyu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_A/0/1/0/all/0/1\">Amitabh Basu</a>",
          "description": "In this article we present new results on neural networks with linear\nthreshold activation functions. We precisely characterize the class of\nfunctions that are representable by such neural networks and show that 2 hidden\nlayers are necessary and sufficient to represent any function representable in\nthe class. This is a surprising result in the light of recent exact\nrepresentability investigations for neural networks using other popular\nactivation functions like rectified linear units (ReLU). We also give precise\nbounds on the sizes of the neural networks required to represent any function\nin the class. Finally, we design an algorithm to solve the empirical risk\nminimization (ERM) problem to global optimality for these neural networks with\na fixed architecture. The algorithm's running time is polynomial in the size of\nthe data sample, if the input dimension and the size of the network\narchitecture are considered fixed constants. The algorithm is unique in the\nsense that it works for any architecture with any number of layers, whereas\nprevious polynomial time globally optimal algorithms work only for very\nrestricted classes of architectures. Using these insights, we propose a new\nclass of neural networks that we call shortcut linear threshold networks. To\nthe best of our knowledge, this way of designing neural networks has not been\nexplored before in the literature. We show that these neural networks have\nseveral desirable theoretical properties.",
          "link": "http://arxiv.org/abs/2111.08117",
          "publishedOn": "2023-10-21T00:41:42.867Z",
          "wordCount": null,
          "title": "Neural networks with linear threshold activations: structure and algorithms. (arXiv:2111.08117v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12822",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Carrizosa_E/0/1/0/all/0/1\">Emilio Carrizosa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramirez_Ayerbe_J/0/1/0/all/0/1\">Jasone Ram&#xed;rez-Ayerbe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Morales_D/0/1/0/all/0/1\">Dolores Romero Morales</a>",
          "description": "Due to the increasing use of Machine Learning models in high stakes decision\nmaking settings, it has become increasingly important to have tools to\nunderstand how models arrive at decisions. Assuming a trained Supervised\nClassification model, explanations can be obtained via counterfactual analysis:\na counterfactual explanation of an instance indicates how this instance should\nbe minimally modified so that the perturbed instance is classified in the\ndesired class by the Machine Learning classification model. Most of the\nCounterfactual Analysis literature focuses on the single-instance\nsingle-counterfactual setting, in which the analysis is done for one single\ninstance to provide one single explanation. Taking a stakeholder's perspective,\nin this paper we introduce the so-called collective counterfactual\nexplanations. By means of novel Mathematical Optimization models, we provide a\ncounterfactual explanation for each instance in a group of interest, so that\nthe total cost of the perturbations is minimized under some linking\nconstraints. Making the process of constructing counterfactuals collective\ninstead of individual enables us to detect the features that are critical to\nthe entire dataset to have the individuals classified in the desired class. Our\nmethodology allows for some instances to be treated individually, performing\nthe collective counterfactual analysis for a fraction of records of the group\nof interest. This way, outliers are identified and handled appropriately. Under\nsome assumptions on the classifier and the space in which counterfactuals are\nsought, finding collective counterfactuals is reduced to solving a convex\nquadratic linearly constrained mixed integer optimization problem, which, for\ndatasets of moderate size, can be solved to optimality using existing solvers.\nThe performance of our approach is illustrated on real-world datasets,\ndemonstrating its usefulness.",
          "link": "http://arxiv.org/abs/2310.12822",
          "publishedOn": "2023-10-21T00:41:42.860Z",
          "wordCount": null,
          "title": "Generating collective counterfactual explanations in score-based classification via mathematical optimization. (arXiv:2310.12822v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sprangers_O/0/1/0/all/0/1\">Olivier Sprangers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadman_W/0/1/0/all/0/1\">Wander Wadman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schelter_S/0/1/0/all/0/1\">Sebastian Schelter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1\">Maarten de Rijke</a>",
          "description": "Existing hierarchical forecasting techniques scale poorly when the number of\ntime series increases. We propose to learn a coherent forecast for millions of\ntime series with a single bottom-level forecast model by using a sparse loss\nfunction that directly optimizes the hierarchical product and/or temporal\nstructure. The benefit of our sparse hierarchical loss function is that it\nprovides practitioners a method of producing bottom-level forecasts that are\ncoherent to any chosen cross-sectional or temporal hierarchy. In addition,\nremoving the need for a post-processing step as required in traditional\nhierarchical forecasting techniques reduces the computational cost of the\nprediction phase in the forecasting pipeline. On the public M5 dataset, our\nsparse hierarchical loss function performs up to 10% (RMSE) better compared to\nthe baseline loss function. We implement our sparse hierarchical loss function\nwithin an existing forecasting model at bol, a large European e-commerce\nplatform, resulting in an improved forecasting performance of 2% at the product\nlevel. Finally, we found an increase in forecasting performance of about 5-10%\nwhen evaluating the forecasting performance across the cross-sectional\nhierarchies that we defined. These results demonstrate the usefulness of our\nsparse hierarchical loss applied to a production forecasting system at a major\ne-commerce platform.",
          "link": "http://arxiv.org/abs/2310.12809",
          "publishedOn": "2023-10-21T00:41:42.859Z",
          "wordCount": null,
          "title": "Hierarchical Forecasting at Scale. (arXiv:2310.12809v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hua Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ninghao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Mengnan Du</a>",
          "description": "While the accuracy-fairness trade-off has been frequently observed in the\nliterature of fair machine learning, rigorous theoretical analyses have been\nscarce. To demystify this long-standing challenge, this work seeks to develop a\ntheoretical framework by characterizing the shape of the accuracy-fairness\ntrade-off Pareto frontier (FairFrontier), determined by a set of all optimal\nPareto classifiers that no other classifiers can dominate. Specifically, we\nfirst demonstrate the existence of the trade-off in real-world scenarios and\nthen propose four potential categories to characterize the important properties\nof the accuracy-fairness Pareto frontier. For each category, we identify the\nnecessary conditions that lead to corresponding trade-offs. Experimental\nresults on synthetic data suggest insightful findings of the proposed\nframework: (1) When sensitive attributes can be fully interpreted by\nnon-sensitive attributes, FairFrontier is mostly continuous. (2) Accuracy can\nsuffer a \\textit{sharp} decline when over-pursuing fairness. (3) Eliminate the\ntrade-off via a two-step streamlined approach. The proposed research enables an\nin-depth understanding of the accuracy-fairness trade-off, pushing current fair\nmachine-learning research to a new frontier.",
          "link": "http://arxiv.org/abs/2310.12785",
          "publishedOn": "2023-10-21T00:41:42.854Z",
          "wordCount": null,
          "title": "A Theoretical Approach to Characterize the Accuracy-Fairness Trade-off Pareto Frontier. (arXiv:2310.12785v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.00608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yuxiang Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Chunqiu Steven Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lingming Zhang</a>",
          "description": "During Automated Program Repair (APR), it can be challenging to synthesize\ncorrect patches for real-world systems in general-purpose programming\nlanguages. Recent Large Language Models (LLMs) have been shown to be helpful\n\"copilots\" in assisting developers with various coding tasks, and have also\nbeen directly applied for patch synthesis. However, most LLMs treat programs as\nsequences of tokens, meaning that they are ignorant of the underlying semantics\nconstraints of the target programming language. This results in plenty of\nstatically invalid generated patches, impeding the practicality of the\ntechnique. Therefore, we propose Repilot, a framework to further copilot the AI\n\"copilots\" (i.e., LLMs) by synthesizing more valid patches during the repair\nprocess. Our key insight is that many LLMs produce outputs autoregressively\n(i.e., token by token), resembling human writing programs, which can be\nsignificantly boosted and guided through a Completion Engine. Repilot\nsynergistically synthesizes a candidate patch through the interaction between\nan LLM and a Completion Engine, which 1) prunes away infeasible tokens\nsuggested by the LLM and 2) proactively completes the token based on the\nsuggestions provided by the Completion Engine. Our evaluation on a subset of\nthe widely-used Defects4j 1.2 and 2.0 datasets shows that Repilot fixes 66 and\n50 bugs, respectively, surpassing the best-performing baseline by 14 and 16\nbugs fixed. More importantly, Repilot is capable of producing more valid and\ncorrect patches than the base LLM when given the same generation budget.",
          "link": "http://arxiv.org/abs/2309.00608",
          "publishedOn": "2023-10-21T00:41:42.853Z",
          "wordCount": null,
          "title": "Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair. (arXiv:2309.00608v2 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04228",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Meles_G/0/1/0/all/0/1\">Giovanni Angelo Meles</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Amaya_M/0/1/0/all/0/1\">Macarena Amaya</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Levy_S/0/1/0/all/0/1\">Shiran Levy</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Marelli_S/0/1/0/all/0/1\">Stefano Marelli</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Linde_N/0/1/0/all/0/1\">Niklas Linde</a>",
          "description": "Implementations of Markov chain Monte Carlo (MCMC) methods need to confront\ntwo fundamental challenges: accurate representation of prior information and\nefficient evaluation of likelihoods. Principal component analysis (PCA) and\nrelated techniques can in some cases facilitate the definition and sampling of\nthe prior distribution, as well as the training of accurate surrogate models,\nusing for instance, polynomial chaos expansion (PCE). However, complex\ngeological priors with sharp contrasts necessitate more complex\ndimensionality-reduction techniques, such as, deep generative models (DGMs). By\nsampling a low-dimensional prior probability distribution defined in the\nlow-dimensional latent space of such a model, it becomes possible to\nefficiently sample the physical domain at the price of a generator that is\ntypically highly non-linear. Training a surrogate that is capable of capturing\nintricate non-linear relationships between latent parameters and outputs of\nforward modeling presents a notable challenge. Indeed, while PCE models provide\nhigh accuracy when the input-output relationship can be effectively\napproximated by relatively low-degree multivariate polynomials, this condition\nis typically not met when employing latent variables derived from DGMs. In this\ncontribution, we present a strategy combining the excellent reconstruction\nperformances of a variational autoencoder (VAE) with the accuracy of PCA-PCE\nsurrogate modeling in the context of Bayesian ground penetrating radar (GPR)\ntraveltime tomography. Within the MCMC process, the parametrization of the VAE\nis leveraged for prior exploration and sample proposals. Concurrently,\nsurrogate modeling is conducted using PCE, which operates on either globally or\nlocally defined principal components of the VAE samples under examination.",
          "link": "http://arxiv.org/abs/2307.04228",
          "publishedOn": "2023-10-21T00:41:42.851Z",
          "wordCount": null,
          "title": "Bayesian tomography using polynomial chaos expansion and deep generative networks. (arXiv:2307.04228v4 [physics.geo-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.05161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Svete_A/0/1/0/all/0/1\">Anej Svete</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Studying language models (LMs) in terms of well-understood formalisms allows\nus to precisely characterize their abilities and limitations. Previous work has\ninvestigated the representational capacity of recurrent neural network (RNN)\nLMs in terms of their capacity to recognize unweighted formal languages.\nHowever, LMs do not describe unweighted formal languages -- rather, they define\nprobability distributions over strings. In this work, we study what classes of\nsuch probability distributions RNN LMs can represent, which allows us to make\nmore direct statements about their capabilities. We show that simple RNNs are\nequivalent to a subclass of probabilistic finite-state automata, and can thus\nmodel a strict subset of probability distributions expressible by finite-state\nmodels. Furthermore, we study the space complexity of representing finite-state\nLMs with RNNs. We show that, to represent an arbitrary deterministic\nfinite-state LM with $N$ states over an alphabet $\\Sigma$, an RNN requires\n$\\Omega\\left(N |\\Sigma|\\right)$ neurons. These results present a first step\ntowards characterizing the classes of distributions RNN LMs can represent and\nthus help us understand their capabilities and limitations.",
          "link": "http://arxiv.org/abs/2310.05161",
          "publishedOn": "2023-10-21T00:41:42.851Z",
          "wordCount": null,
          "title": "Recurrent Neural Language Models as Probabilistic Finite-state Automata. (arXiv:2310.05161v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sehgal_A/0/1/0/all/0/1\">Atharva Sehgal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grayeli_A/0/1/0/all/0/1\">Arya Grayeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1\">Swarat Chaudhuri</a>",
          "description": "We introduce Cosmos, a framework for object-centric world modeling that is\ndesigned for compositional generalization (CG), i.e., high performance on\nunseen input scenes obtained through the composition of known visual \"atoms.\"\nThe central insight behind Cosmos is the use of a novel form of neurosymbolic\ngrounding. Specifically, the framework introduces two new tools: (i)\nneurosymbolic scene encodings, which represent each entity in a scene using a\nreal vector computed using a neural encoder, as well as a vector of composable\nsymbols describing attributes of the entity, and (ii) a neurosymbolic attention\nmechanism that binds these entities to learned rules of interaction. Cosmos is\nend-to-end differentiable; also, unlike traditional neurosymbolic methods that\nrequire representations to be manually mapped to symbols, it computes an\nentity's symbolic attributes using vision-language foundation models. Through\nan evaluation that considers two different forms of CG on an established\nblocks-pushing domain, we show that the framework establishes a new\nstate-of-the-art for CG in world modeling.",
          "link": "http://arxiv.org/abs/2310.12690",
          "publishedOn": "2023-10-21T00:41:42.850Z",
          "wordCount": null,
          "title": "Neurosymbolic Grounding for Compositional World Models. (arXiv:2310.12690v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08854",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1\">Yifan Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1\">Weicong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yiduo Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yuhui Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yukang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Han Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>",
          "description": "Modern detection transformers (DETRs) use a set of object queries to predict\na list of bounding boxes, sort them by their classification confidence scores,\nand select the top-ranked predictions as the final detection results for the\ngiven input image. A highly performant object detector requires accurate\nranking for the bounding box predictions. For DETR-based detectors, the\ntop-ranked bounding boxes suffer from less accurate localization quality due to\nthe misalignment between classification scores and localization accuracy, thus\nimpeding the construction of high-quality detectors. In this work, we introduce\na simple and highly performant DETR-based object detector by proposing a series\nof rank-oriented designs, combinedly called Rank-DETR. Our key contributions\ninclude: (i) a rank-oriented architecture design that can prompt positive\npredictions and suppress the negative ones to ensure lower false positive\nrates, as well as (ii) a rank-oriented loss function and matching cost design\nthat prioritizes predictions of more accurate localization accuracy during\nranking to boost the AP under high IoU thresholds. We apply our method to\nimprove the recent SOTA methods (e.g., H-DETR and DINO-DETR) and report strong\nCOCO object detection results when using different backbones such as\nResNet-$50$, Swin-T, and Swin-L, demonstrating the effectiveness of our\napproach. Code is available at \\url{https://github.com/LeapLabTHU/Rank-DETR}.",
          "link": "http://arxiv.org/abs/2310.08854",
          "publishedOn": "2023-10-21T00:41:42.850Z",
          "wordCount": null,
          "title": "Rank-DETR for High Quality Object Detection. (arXiv:2310.08854v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Holvoet_F/0/1/0/all/0/1\">Freek Holvoet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antonio_K/0/1/0/all/0/1\">Katrien Antonio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henckaerts_R/0/1/0/all/0/1\">Roel Henckaerts</a>",
          "description": "Insurers usually turn to generalized linear models for modelling claim\nfrequency and severity data. Due to their success in other fields, machine\nlearning techniques are gaining popularity within the actuarial toolbox. Our\npaper contributes to the literature on frequency-severity insurance pricing\nwith machine learning via deep learning structures. We present a benchmark\nstudy on four insurance data sets with frequency and severity targets in the\npresence of multiple types of input features. We compare in detail the\nperformance of: a generalized linear model on binned input data, a\ngradient-boosted tree model, a feed-forward neural network (FFNN), and the\ncombined actuarial neural network (CANN). Our CANNs combine a baseline\nprediction established with a GLM and GBM, respectively, with a neural network\ncorrection. We explain the data preprocessing steps with specific focus on the\nmultiple types of input features typically present in tabular insurance data\nsets, such as postal codes, numeric and categorical covariates. Autoencoders\nare used to embed the categorical variables into the neural network and we\nexplore their potential advantages in a frequency-severity setting. Finally, we\nconstruct global surrogate models for the neural nets' frequency and severity\nmodels. These surrogates enable the translation of the essential insights\ncaptured by the FFNNs or CANNs to GLMs. As such, a technical tariff table\nresults that can easily be deployed in practice.",
          "link": "http://arxiv.org/abs/2310.12671",
          "publishedOn": "2023-10-21T00:41:42.845Z",
          "wordCount": null,
          "title": "Neural networks for insurance pricing with frequency and severity data: a benchmark study from data preprocessing to technical tariff. (arXiv:2310.12671v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Wei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Haitao Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haoming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1\">Chen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1\">Hongzhi Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1\">Haoyu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruirui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Monica Xiao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goutam_R/0/1/0/all/0/1\">Rahul Goutam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haiyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subbian_K/0/1/0/all/0/1\">Karthik Subbian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yizhou Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xianfeng Tang</a>",
          "description": "Modeling customer shopping intentions is a crucial task for e-commerce, as it\ndirectly impacts user experience and engagement. Thus, accurately understanding\ncustomer preferences is essential for providing personalized recommendations.\nSession-based recommendation, which utilizes customer session data to predict\ntheir next interaction, has become increasingly popular. However, existing\nsession datasets have limitations in terms of item attributes, user diversity,\nand dataset scale. As a result, they cannot comprehensively capture the\nspectrum of user behaviors and preferences. To bridge this gap, we present the\nAmazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It\nis the first multilingual dataset consisting of millions of user sessions from\nsix different locales, where the major languages of products are English,\nGerman, Japanese, French, Italian, and Spanish. Remarkably, the dataset can\nhelp us enhance personalization and understanding of user preferences, which\ncan benefit various existing tasks as well as enable new tasks. To test the\npotential of the dataset, we introduce three tasks in this work: (1)\nnext-product recommendation, (2) next-product recommendation with domain\nshifts, and (3) next-product title generation. With the above tasks, we\nbenchmark a range of algorithms on our proposed dataset, drawing new insights\nfor further research and practice. In addition, based on the proposed dataset\nand tasks, we hosted a competition in the KDD CUP 2023 and have attracted\nthousands of users and submissions. The winning solutions and the associated\nworkshop can be accessed at our website https://kddcup23.github.io/.",
          "link": "http://arxiv.org/abs/2307.09688",
          "publishedOn": "2023-10-21T00:41:42.836Z",
          "wordCount": null,
          "title": "Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation. (arXiv:2307.09688v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhipeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1\">Nanqing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiahao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knottenbelt_W/0/1/0/all/0/1\">William Knottenbelt</a>",
          "description": "Federated Learning (FL) is a machine learning paradigm, which enables\nmultiple and decentralized clients to collaboratively train a model under the\norchestration of a central aggregator. Traditional FL solutions rely on the\ntrust assumption of the centralized aggregator, which forms cohorts of clients\nin a fair and honest manner. However, a malicious aggregator, in reality, could\nabandon and replace the client's training models, or launch Sybil attacks to\ninsert fake clients. Such malicious behaviors give the aggregator more power to\ncontrol clients in the FL setting and determine the final training results. In\nthis work, we introduce zkFL, which leverages zero-knowledge proofs (ZKPs) to\ntackle the issue of a malicious aggregator during the training model\naggregation process. To guarantee the correct aggregation results, the\naggregator needs to provide a proof per round. The proof can demonstrate to the\nclients that the aggregator executes the intended behavior faithfully. To\nfurther reduce the verification cost of clients, we employ a blockchain to\nhandle the proof in a zero-knowledge way, where miners (i.e., the nodes\nvalidating and maintaining the blockchain data) can verify the proof without\nknowing the clients' local and aggregated models. The theoretical analysis and\nempirical results show that zkFL can achieve better security and privacy than\ntraditional FL, without modifying the underlying FL network structure or\nheavily compromising the training speed.",
          "link": "http://arxiv.org/abs/2310.02554",
          "publishedOn": "2023-10-21T00:41:42.836Z",
          "wordCount": null,
          "title": "zkFL: Zero-Knowledge Proof-based Gradient Aggregation for Federated Learning. (arXiv:2310.02554v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12802",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Arola_Fernandez_L/0/1/0/all/0/1\">Llu&#xed;s Arola-Fern&#xe1;ndez</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lacasa_L/0/1/0/all/0/1\">Lucas Lacasa</a>",
          "description": "Unraveling the emergence of collective learning in systems of coupled\nartificial neural networks is an endeavor with broader implications for\nphysics, machine learning, neuroscience and society. Here we introduce a\nminimal model that condenses several recent decentralized algorithms by\nconsidering a competition between two terms: the local learning dynamics in the\nparameters of each neural network unit, and a diffusive coupling among units\nthat tends to homogenize the parameters of the ensemble. We derive the\ncoarse-grained behavior of our model via an effective theory for linear\nnetworks that we show is analogous to a deformed Ginzburg-Landau model with\nquenched disorder. This framework predicts (depth-dependent)\ndisorder-order-disorder phase transitions in the parameters' solutions that\nreveal the onset of a collective learning phase, along with a depth-induced\ndelay of the critical point and a robust shape of the microscopic learning\npath. We validate our theory in realistic ensembles of coupled nonlinear\nnetworks trained in the MNIST dataset under privacy constraints. Interestingly,\nexperiments confirm that individual networks -- trained only with private data\n-- can fully generalize to unseen data classes when the collective learning\nphase emerges. Our work elucidates the physics of collective learning and\ncontributes to the mechanistic interpretability of deep learning in\ndecentralized settings.",
          "link": "http://arxiv.org/abs/2310.12802",
          "publishedOn": "2023-10-21T00:41:42.825Z",
          "wordCount": null,
          "title": "An effective theory of collective deep learning. (arXiv:2310.12802v1 [physics.soc-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.11586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Egressy_B/0/1/0/all/0/1\">B&#xe9;ni Egressy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niederhausern_L/0/1/0/all/0/1\">Luc von Niederh&#xe4;usern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanusa_J/0/1/0/all/0/1\">Jovan Blanusa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altman_E/0/1/0/all/0/1\">Erik Altman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1\">Roger Wattenhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atasu_K/0/1/0/all/0/1\">Kubilay Atasu</a>",
          "description": "This paper analyses a set of simple adaptations that transform standard\nmessage-passing Graph Neural Networks (GNN) into provably powerful directed\nmultigraph neural networks. The adaptations include multigraph port numbering,\nego IDs, and reverse message passing. We prove that the combination of these\ntheoretically enables the detection of any directed subgraph pattern. To\nvalidate the effectiveness of our proposed adaptations in practice, we conduct\nexperiments on synthetic subgraph detection tasks, which demonstrate\noutstanding performance with almost perfect results. Moreover, we apply our\nproposed adaptations to two financial crime analysis tasks. We observe dramatic\nimprovements in detecting money laundering transactions, improving the\nminority-class F1 score of a standard message-passing GNN by up to 30%, and\nclosely matching or outperforming tree-based and GNN baselines. Similarly\nimpressive results are observed on a real-world phishing detection dataset,\nboosting three standard GNNs' F1 scores by around 15% and outperforming all\nbaselines.",
          "link": "http://arxiv.org/abs/2306.11586",
          "publishedOn": "2023-10-21T00:41:42.789Z",
          "wordCount": null,
          "title": "Provably Powerful Graph Neural Networks for Directed Multigraphs. (arXiv:2306.11586v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12544",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+OLoughlin_L/0/1/0/all/0/1\">Luke O&#x27;Loughlin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maclean_J/0/1/0/all/0/1\">John Maclean</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Black_A/0/1/0/all/0/1\">Andrew Black</a>",
          "description": "Stochastic processes defined on integer valued state spaces are popular\nwithin the physical and biological sciences. These models are necessary for\ncapturing the dynamics of small systems where the individual nature of the\npopulations cannot be ignored and stochastic effects are important. The\ninference of the parameters of such models, from time series data, is difficult\ndue to intractability of the likelihood; current methods, based on simulations\nof the underlying model, can be so computationally expensive as to be\nprohibitive. In this paper we construct a neural likelihood approximation for\ninteger valued time series data using causal convolutions, which allows us to\nevaluate the likelihood of the whole time series in parallel. We demonstrate\nour method by performing inference on a number of ecological and\nepidemiological models, showing that we can accurately approximate the true\nposterior while achieving significant computational speed ups in situations\nwhere current methods struggle.",
          "link": "http://arxiv.org/abs/2310.12544",
          "publishedOn": "2023-10-21T00:41:42.778Z",
          "wordCount": null,
          "title": "Neural Likelihood Approximation for Integer Valued Time Series Data. (arXiv:2310.12544v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12631",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Bachtis_D/0/1/0/all/0/1\">Dimitrios Bachtis</a>",
          "description": "We propose inverse renormalization group transformations to construct\napproximate configurations for lattice volumes that have not yet been accessed\nby supercomputers or large-scale simulations in the study of spin glasses.\nSpecifically, starting from lattices of volume $V=8^{3}$ in the case of the\nthree-dimensional Edwards-Anderson model we employ machine learning algorithms\nto construct rescaled lattices up to $V'=128^{3}$, which we utilize to extract\ntwo critical exponents. We conclude by discussing how to incorporate numerical\nexactness within inverse renormalization group approaches of disordered\nsystems, thus opening up the opportunity to explore a sustainable and\nenergy-efficient generation of exact configurations for increasing lattice\nvolumes without the use of dedicated supercomputers.",
          "link": "http://arxiv.org/abs/2310.12631",
          "publishedOn": "2023-10-21T00:41:42.774Z",
          "wordCount": null,
          "title": "Inverse Renormalization Group of Disordered Systems. (arXiv:2310.12631v1 [cond-mat.stat-mech])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maison_L/0/1/0/all/0/1\">Lucas Maison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bourboux_H/0/1/0/all/0/1\">H&#xe9;lion du Mas des Bourboux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courtat_T/0/1/0/all/0/1\">Thomas Courtat</a>",
          "description": "Compressing neural networks is a key step when deploying models for real-time\nor embedded applications. Factorizing the model's matrices using low-rank\napproximations is a promising method for achieving compression. While it is\npossible to set the rank before training, this approach is neither flexible nor\noptimal. In this work, we propose a post-training rank-selection method called\nRank-Tuning that selects a different rank for each matrix. Used in combination\nwith training adaptations, our method achieves high compression rates with no\nor little performance degradation. Our numerical experiments on signal\nprocessing tasks show that we can compress recurrent neural networks up to 14x\nwith at most 1.4% relative performance reduction.",
          "link": "http://arxiv.org/abs/2310.12688",
          "publishedOn": "2023-10-21T00:41:42.766Z",
          "wordCount": null,
          "title": "Compression of Recurrent Neural Networks using Matrix Factorization. (arXiv:2310.12688v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1\">Syed Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filipovska_M/0/1/0/all/0/1\">Monika Filipovska</a>",
          "description": "Traffic state forecasting is crucial for traffic management and control\nstrategies, as well as user- and system-level decision making in the\ntransportation network. While traffic forecasting has been approached with a\nvariety of techniques over the last couple of decades, most approaches simply\nrely on endogenous traffic variables for state prediction, despite the evidence\nthat exogenous factors can significantly impact traffic conditions. This paper\nproposes a multi-dimensional spatio-temporal graph attention-based traffic\nprediction approach (M-STGAT), which predicts traffic based on past\nobservations of speed, along with lane closure events, temperature, and\nvisibility across the transportation network. The approach is based on a graph\nattention network architecture, which also learns based on the structure of the\ntransportation network on which these variables are observed. Numerical\nexperiments are performed using traffic speed and lane closure data from the\nCalifornia Department of Transportation (Caltrans) Performance Measurement\nSystem (PeMS). The corresponding weather data were downloaded from the National\nOceanic and Atmospheric Administration (NOOA) Automated Surface Observing\nSystems (ASOS). For comparison, the numerical experiments implement three\nalternative models which do not allow for the multi-dimensional input. The\nM-STGAT is shown to outperform the three alternative models, when performing\ntests using our primary data set for prediction with a 30-, 45-, and 60-minute\nprediction horizon, in terms of three error measures: Mean Absolute Error\n(MAE), Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE).\nHowever, the model's transferability can vary for different transfer data sets\nand this aspect may require further investigation.",
          "link": "http://arxiv.org/abs/2310.12353",
          "publishedOn": "2023-10-21T00:41:42.763Z",
          "wordCount": null,
          "title": "Networkwide Traffic State Forecasting Using Exogenous Information: A Multi-Dimensional Graph Attention-Based Approach. (arXiv:2310.12353v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1\">Jungbin Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>",
          "description": "Time is one of the crucial factors in real-world question answering (QA)\nproblems. However, language models have difficulty understanding the\nrelationships between time specifiers, such as 'after' and 'before', and\nnumbers, since existing QA datasets do not include sufficient time expressions.\nTo address this issue, we propose a Time-Context aware Question Answering\n(TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE)\ntask, and build a time-context dependent data generation framework for model\ntraining. Moreover, we present a metric to evaluate the time awareness of the\nQA model using TCSE. The TCSE task consists of a question and four sentence\ncandidates classified as correct or incorrect based on time and context. The\nmodel is trained to extract the answer span from the sentence that is both\ncorrect in time and context. The model trained with TCQA outperforms baseline\nmodels up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code\nare available at https://github.com/sonjbin/TCQA",
          "link": "http://arxiv.org/abs/2310.12585",
          "publishedOn": "2023-10-21T00:41:42.755Z",
          "wordCount": null,
          "title": "Time-Aware Representation Learning for Time-Sensitive Question Answering. (arXiv:2310.12585v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guanzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuqi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yunfan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandlekar_A/0/1/0/all/0/1\">Ajay Mandlekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Linxi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "We introduce Voyager, the first LLM-powered embodied lifelong learning agent\nin Minecraft that continuously explores the world, acquires diverse skills, and\nmakes novel discoveries without human intervention. Voyager consists of three\nkey components: 1) an automatic curriculum that maximizes exploration, 2) an\never-growing skill library of executable code for storing and retrieving\ncomplex behaviors, and 3) a new iterative prompting mechanism that incorporates\nenvironment feedback, execution errors, and self-verification for program\nimprovement. Voyager interacts with GPT-4 via blackbox queries, which bypasses\nthe need for model parameter fine-tuning. The skills developed by Voyager are\ntemporally extended, interpretable, and compositional, which compounds the\nagent's abilities rapidly and alleviates catastrophic forgetting. Empirically,\nVoyager shows strong in-context lifelong learning capability and exhibits\nexceptional proficiency in playing Minecraft. It obtains 3.3x more unique\nitems, travels 2.3x longer distances, and unlocks key tech tree milestones up\nto 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill\nlibrary in a new Minecraft world to solve novel tasks from scratch, while other\ntechniques struggle to generalize. We open-source our full codebase and prompts\nat https://voyager.minedojo.org/.",
          "link": "http://arxiv.org/abs/2305.16291",
          "publishedOn": "2023-10-21T00:41:42.725Z",
          "wordCount": null,
          "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models. (arXiv:2305.16291v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.01319",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ahmed_I/0/1/0/all/0/1\">I. Zakir Ahmed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sadjadpour_H/0/1/0/all/0/1\">Hamid R. Sadjadpour</a>",
          "description": "The Orthogonal-Time-Frequency-Space (OTFS) signaling is known to be resilient\nto doubly-dispersive channels, which impacts high mobility scenarios. On the\nother hand, the Orthogonal-Frequency-Division-Multiplexing (OFDM) waveforms\nenjoy the benefits of the reuse of legacy architectures, simplicity of receiver\ndesign, and low-complexity detection. Several studies that compare the\nperformance of OFDM and OTFS have indicated mixed outcomes due to the plethora\nof system parameters at play beyond high-mobility conditions. In this work, we\nexemplify this observation using simulations and propose a deep neural network\n(DNN)-based adaptation scheme to switch between using either an OTFS or OFDM\nsignal processing chain at the transmitter and receiver for optimal\nmean-squared-error (MSE) performance. The DNN classifier is trained to switch\nbetween the two schemes by observing the channel condition, received SNR, and\nmodulation format. We compare the performance of the OTFS, OFDM, and the\nproposed switched-waveform scheme. The simulations indicate superior\nperformance with the proposed scheme with a well-trained DNN, thus improving\nthe MSE performance of the communication significantly.",
          "link": "http://arxiv.org/abs/2309.01319",
          "publishedOn": "2023-10-21T00:41:42.721Z",
          "wordCount": null,
          "title": "An ML-assisted OTFS vs. OFDM adaptable modem. (arXiv:2309.01319v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Openja_M/0/1/0/all/0/1\">Moses Openja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laberge_G/0/1/0/all/0/1\">Gabriel Laberge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1\">Foutse Khomh</a>",
          "description": "The cause-to-effect analysis can help us decompose all the likely causes of a\nproblem, such as an undesirable business situation or unintended harm to the\nindividual(s). This implies that we can identify how the problems are\ninherited, rank the causes to help prioritize fixes, simplify a complex problem\nand visualize them. In the context of machine learning (ML), one can use\ncause-to-effect analysis to understand the reason for the biased behavior of\nthe system. For example, we can examine the root causes of biases by checking\neach feature for a potential cause of bias in the model. To approach this, one\ncan apply small changes to a given feature or a pair of features in the data,\nfollowing some guidelines and observing how it impacts the decision made by the\nmodel (i.e., model prediction). Therefore, we can use cause-to-effect analysis\nto identify the potential bias-inducing features, even when these features are\noriginally are unknown. This is important since most current methods require a\npre-identification of sensitive features for bias assessment and can actually\nmiss other relevant bias-inducing features, which is why systematic\nidentification of such features is necessary. Moreover, it often occurs that to\nachieve an equitable outcome, one has to take into account sensitive features\nin the model decision. Therefore, it should be up to the domain experts to\ndecide based on their knowledge of the context of a decision whether bias\ninduced by specific features is acceptable or not. In this study, we propose an\napproach for systematically identifying all bias-inducing features of a model\nto help support the decision-making of domain experts. We evaluated our\ntechnique using four well-known datasets to showcase how our contribution can\nhelp spearhead the standard procedure when developing, testing, maintaining,\nand deploying fair/equitable machine learning systems.",
          "link": "http://arxiv.org/abs/2310.12805",
          "publishedOn": "2023-10-21T00:41:42.715Z",
          "wordCount": null,
          "title": "Detection and Evaluation of bias-inducing Features in Machine learning. (arXiv:2310.12805v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takhanov_R/0/1/0/all/0/1\">Rustem Takhanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tezekbayev_M/0/1/0/all/0/1\">Maxat Tezekbayev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pak_A/0/1/0/all/0/1\">Artur Pak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolatov_A/0/1/0/all/0/1\">Arman Bolatov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assylbekov_Z/0/1/0/all/0/1\">Zhenisbek Assylbekov</a>",
          "description": "Classes of target functions containing a large number of approximately\northogonal elements are known to be hard to learn by the Statistical Query\nalgorithms. Recently this classical fact re-emerged in a theory of\ngradient-based optimization of neural networks. In the novel framework, the\nhardness of a class is usually quantified by the variance of the gradient with\nrespect to a random choice of a target function.\n\nA set of functions of the form $x\\to ax \\bmod p$, where $a$ is taken from\n${\\mathbb Z}_p$, has attracted some attention from deep learning theorists and\ncryptographers recently. This class can be understood as a subset of\n$p$-periodic functions on ${\\mathbb Z}$ and is tightly connected with a class\nof high-frequency periodic functions on the real line.\n\nWe present a mathematical analysis of limitations and challenges associated\nwith using gradient-based learning techniques to train a high-frequency\nperiodic function or modular multiplication from examples. We highlight that\nthe variance of the gradient is negligibly small in both cases when either a\nfrequency or the prime base $p$ is large. This in turn prevents such a learning\nalgorithm from being successful.",
          "link": "http://arxiv.org/abs/2310.12660",
          "publishedOn": "2023-10-21T00:41:42.713Z",
          "wordCount": null,
          "title": "Gradient Descent Fails to Learn High-frequency Functions and Modular Arithmetic. (arXiv:2310.12660v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhouxing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_F/0/1/0/all/0/1\">Fan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiangning Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>",
          "description": "The prevalence and strong capability of large language models (LLMs) present\nsignificant safety and ethical risks if exploited by malicious users. To\nprevent the potentially deceptive usage of LLMs, recent works have proposed\nalgorithms to detect LLM-generated text and protect LLMs. In this paper, we\ninvestigate the robustness and reliability of these LLM detectors under\nadversarial attacks. We study two types of attack strategies: 1) replacing\ncertain words in an LLM's output with their synonyms given the context; 2)\nautomatically searching for an instructional prompt to alter the writing style\nof the generation. In both strategies, we leverage an auxiliary LLM to generate\nthe word replacements or the instructional prompt. Different from previous\nworks, we consider a challenging setting where the auxiliary LLM can also be\nprotected by a detector. Experiments reveal that our attacks effectively\ncompromise the performance of all detectors in the study with plausible\ngenerations, underscoring the urgent need to improve the robustness of\nLLM-generated text detection systems.",
          "link": "http://arxiv.org/abs/2305.19713",
          "publishedOn": "2023-10-21T00:41:42.709Z",
          "wordCount": null,
          "title": "Red Teaming Language Model Detectors with Language Models. (arXiv:2305.19713v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.11084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yifei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Juntao Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fengyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabih_R/0/1/0/all/0/1\">Ramin Zabih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Ser-Nam Lim</a>",
          "description": "Advances in the field of vision-language contrastive learning have made it\npossible for many downstream applications to be carried out efficiently and\naccurately by simply taking the dot product between image and text\nrepresentations. One of the most representative approaches proposed recently\nknown as CLIP has garnered widespread adoption due to its effectiveness. CLIP\nis trained with an InfoNCE loss that takes into account both positive and\nnegative samples to help learn a much more robust representation space. This\npaper reveals that the common downstream practice of taking a dot product is\nonly a zeroth-order approximation of the optimization goal, resulting in a loss\nof information during test-time. Intuitively, since the model has been\noptimized based on the InfoNCE loss, test-time procedures should also be in\nalignment. The question lies in how one can retrieve any semblance of negative\nsamples information during inference in a computationally efficient way. To\nthis end, we propose Distribution Normalization (DN), where we approximate the\nmean representation of a batch of test samples and use such a mean to represent\nwhat would be analogous to negative samples in the InfoNCE loss. DN requires no\nretraining or fine-tuning and can be effortlessly applied during inference.\nExtensive experiments on a wide variety of downstream tasks exhibit a clear\nadvantage of DN over the dot product on top of other existing test-time\naugmentation methods.",
          "link": "http://arxiv.org/abs/2302.11084",
          "publishedOn": "2023-10-21T00:41:42.686Z",
          "wordCount": null,
          "title": "Test-Time Distribution Normalization for Contrastively Learned Vision-language Models. (arXiv:2302.11084v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudalairaj_S/0/1/0/all/0/1\">Shivchander Sudalairaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henning_J/0/1/0/all/0/1\">John Henning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenewald_K/0/1/0/all/0/1\">Kristjan Greenewald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1\">Akash Srivastava</a>",
          "description": "Existing private synthetic data generation algorithms are agnostic to\ndownstream tasks. However, end users may have specific requirements that the\nsynthetic data must satisfy. Failure to meet these requirements could\nsignificantly reduce the utility of the data for downstream use. We introduce a\npost-processing technique that improves the utility of the synthetic data with\nrespect to measures selected by the end user, while preserving strong privacy\nguarantees and dataset quality. Our technique involves resampling from the\nsynthetic data to filter out samples that do not meet the selected utility\nmeasures, using an efficient stochastic first-order algorithm to find optimal\nresampling weights. Through comprehensive numerical experiments, we demonstrate\nthat our approach consistently improves the utility of synthetic data across\nmultiple benchmark datasets and state-of-the-art synthetic data generation\nalgorithms.",
          "link": "http://arxiv.org/abs/2305.15538",
          "publishedOn": "2023-10-21T00:41:42.686Z",
          "wordCount": null,
          "title": "Post-processing Private Synthetic Data for Improving Utility on Selected Measures. (arXiv:2305.15538v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.14090",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Dai_Z/0/1/0/all/0/1\">Zhenyu Dai</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Moews_B/0/1/0/all/0/1\">Ben Moews</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Vilalta_R/0/1/0/all/0/1\">Ricardo Vilalta</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Dave_R/0/1/0/all/0/1\">Romeel Dave</a>",
          "description": "Physics-informed neural networks have emerged as a coherent framework for\nbuilding predictive models that combine statistical patterns with domain\nknowledge. The underlying notion is to enrich the optimization loss function\nwith known relationships to constrain the space of possible solutions.\nHydrodynamic simulations are a core constituent of modern cosmology, while the\nrequired computations are both expensive and time-consuming. At the same time,\nthe comparatively fast simulation of dark matter requires fewer resources,\nwhich has led to the emergence of machine learning algorithms for baryon\ninpainting as an active area of research; here, recreating the scatter found in\nhydrodynamic simulations is an ongoing challenge. This paper presents the first\napplication of physics-informed neural networks to baryon inpainting by\ncombining advances in neural network architectures with physical constraints,\ninjecting theory on baryon conversion efficiency into the model loss function.\nWe also introduce a punitive prediction comparison based on the\nKullback-Leibler divergence, which enforces scatter reproduction. By\nsimultaneously extracting the complete set of baryonic properties for the Simba\nsuite of cosmological simulations, our results demonstrate improved accuracy of\nbaryonic predictions based on dark matter halo properties, successful recovery\nof the fundamental metallicity relation, and retrieve scatter that traces the\ntarget simulation's distribution.",
          "link": "http://arxiv.org/abs/2303.14090",
          "publishedOn": "2023-10-21T00:41:42.596Z",
          "wordCount": null,
          "title": "Physics-informed neural networks in the recreation of hydrodynamic simulations from dark matter. (arXiv:2303.14090v2 [astro-ph.CO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hahn_Y/0/1/0/all/0/1\">Yannik Hahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maack_R/0/1/0/all/0/1\">Robert Maack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buchholz_G/0/1/0/all/0/1\">Guido Buchholz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purrio_M/0/1/0/all/0/1\">Marion Purrio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angerhausen_M/0/1/0/all/0/1\">Matthias Angerhausen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tercan_H/0/1/0/all/0/1\">Hasan Tercan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meisen_T/0/1/0/all/0/1\">Tobias Meisen</a>",
          "description": "The digitization of manufacturing processes enables promising applications\nfor machine learning-assisted quality assurance. A widely used manufacturing\nprocess that can strongly benefit from data-driven solutions is \\ac{GMAW}. The\nwelding process is characterized by complex cause-effect relationships between\nmaterial properties, process conditions and weld quality. In non-laboratory\nenvironments with frequently changing process parameters, accurate\ndetermination of weld quality by destructive testing is economically\nunfeasible. Deep learning offers the potential to identify the relationships in\navailable process data and predict the weld quality from process observations.\nIn this paper, we present a concept for a deep learning based predictive\nquality system in \\ac{GMAW}. At its core, the concept involves a pipeline\nconsisting of four major phases: collection and management of multi-sensor data\n(e.g. current and voltage), real-time processing and feature engineering of the\ntime series data by means of autoencoders, training and deployment of suitable\nrecurrent deep learning models for quality predictions, and model evolutions\nunder changing process conditions using continual learning. The concept\nprovides the foundation for future research activities in which we will realize\nan online predictive quality system for running production.",
          "link": "http://arxiv.org/abs/2310.12632",
          "publishedOn": "2023-10-21T00:41:42.587Z",
          "wordCount": null,
          "title": "Towards a Deep Learning-based Online Quality Prediction System for Welding Processes. (arXiv:2310.12632v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jiaming Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Borong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiayi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xuehai Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Weidong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruiyang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_Y/0/1/0/all/0/1\">Yiran Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yifan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Juntao Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>",
          "description": "Artificial intelligence (AI) systems possess significant potential to drive\nsocietal progress. However, their deployment often faces obstacles due to\nsubstantial safety concerns. Safe reinforcement learning (SafeRL) emerges as a\nsolution to optimize policies while simultaneously adhering to multiple\nconstraints, thereby addressing the challenge of integrating reinforcement\nlearning in safety-critical scenarios. In this paper, we present an environment\nsuite called Safety-Gymnasium, which encompasses safety-critical tasks in both\nsingle and multi-agent scenarios, accepting vector and vision-only input.\nAdditionally, we offer a library of algorithms named Safe Policy Optimization\n(SafePO), comprising 16 state-of-the-art SafeRL algorithms. This comprehensive\nlibrary can serve as a validation tool for the research community. By\nintroducing this benchmark, we aim to facilitate the evaluation and comparison\nof safety performance, thus fostering the development of reinforcement learning\nfor safer, more reliable, and responsible real-world applications. The website\nof this project can be accessed at\nhttps://sites.google.com/view/safety-gymnasium.",
          "link": "http://arxiv.org/abs/2310.12567",
          "publishedOn": "2023-10-21T00:41:42.584Z",
          "wordCount": null,
          "title": "Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark. (arXiv:2310.12567v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1\">Wei Ping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAfee_L/0/1/0/all/0/1\">Lawrence McAfee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1\">Mohammad Shoeybi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yi Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuchaiev_O/0/1/0/all/0/1\">Oleksii Kuchaiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>",
          "description": "Large decoder-only language models (LMs) can be largely improved in terms of\nperplexity by retrieval (e.g., RETRO), but its impact on text generation\nquality and downstream task accuracy is unclear. Thus, it is still an open\nquestion: shall we pretrain large autoregressive LMs with retrieval? To answer\nit, we perform a comprehensive study on a scalable pre-trained\nretrieval-augmented LM (i.e., RETRO) compared with standard GPT and\nretrieval-augmented GPT incorporated at fine-tuning or inference stages. We\nfirst provide the recipe to reproduce RETRO up to 9.5B parameters while\nretrieving a text corpus with 330B tokens. Based on that, we have the following\nnovel findings: i) RETRO outperforms GPT on text generation with much less\ndegeneration (i.e., repetition), moderately higher factual accuracy, and\nslightly lower toxicity with a nontoxic retrieval database. ii) On the LM\nEvaluation Harness benchmark, RETRO largely outperforms GPT on\nknowledge-intensive tasks, but is on par with GPT on other tasks. Furthermore,\nwe introduce a simple variant of the model, RETRO++, which largely improves\nopen-domain QA results of original RETRO (e.g., EM score +8.6 on Natural\nQuestion) and significantly outperforms retrieval-augmented GPT in both\nfine-tuning and zero-shot evaluation settings. Our findings highlight the\npromising direction of pretraining autoregressive LMs with retrieval as future\nfoundation models. We release our implementation at:\nhttps://github.com/NVIDIA/Megatron-LM#retro.",
          "link": "http://arxiv.org/abs/2304.06762",
          "publishedOn": "2023-10-21T00:41:42.574Z",
          "wordCount": null,
          "title": "Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study. (arXiv:2304.06762v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hull_M/0/1/0/all/0/1\">Matthew Hull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijie J. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1\">Duen Horng Chau</a>",
          "description": "Deep Learning models, such as those used in an autonomous vehicle are\nvulnerable to adversarial attacks where an attacker could place an adversarial\nobject in the environment, leading to mis-classification. Generating these\nadversarial objects in the digital space has been extensively studied, however\nsuccessfully transferring these attacks from the digital realm to the physical\nrealm has proven challenging when controlling for real-world environmental\nfactors. In response to these limitations, we introduce REVAMP, an easy-to-use\nPython library that is the first-of-its-kind tool for creating attack scenarios\nwith arbitrary objects and simulating realistic environmental factors,\nlighting, reflection, and refraction. REVAMP enables researchers and\npractitioners to swiftly explore various scenarios within the digital realm by\noffering a wide range of configurable options for designing experiments and\nusing differentiable rendering to reproduce physically plausible adversarial\nobjects. We will demonstrate and invite the audience to try REVAMP to produce\nan adversarial texture on a chosen object while having control over various\nscene parameters. The audience will choose a scene, an object to attack, the\ndesired attack class, and the number of camera positions to use. Then, in real\ntime, we show how this altered texture causes the chosen object to be\nmis-classified, showcasing the potential of REVAMP in real-world scenarios.\nREVAMP is open-source and available at https://github.com/poloclub/revamp.",
          "link": "http://arxiv.org/abs/2310.12243",
          "publishedOn": "2023-10-21T00:41:42.570Z",
          "wordCount": null,
          "title": "REVAMP: Automated Simulations of Adversarial Attacks on Arbitrary Objects in Realistic Scenes. (arXiv:2310.12243v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhendong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yifan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Huangjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>",
          "description": "Diffusion models are powerful, but they require a lot of time and data to\ntrain. We propose Patch Diffusion, a generic patch-wise training framework, to\nsignificantly reduce the training time costs while improving data efficiency,\nwhich thus helps democratize diffusion model training to broader users. At the\ncore of our innovations is a new conditional score function at the patch level,\nwhere the patch location in the original image is included as additional\ncoordinate channels, while the patch size is randomized and diversified\nthroughout training to encode the cross-region dependency at multiple scales.\nSampling with our method is as easy as in the original diffusion model. Through\nPatch Diffusion, we could achieve $\\mathbf{\\ge 2\\times}$ faster training, while\nmaintaining comparable or better generation quality. Patch Diffusion meanwhile\nimproves the performance of diffusion models trained on relatively small\ndatasets, $e.g.$, as few as 5,000 images to train from scratch. We achieve\noutstanding FID scores in line with state-of-the-art benchmarks: 1.77 on\nCelebA-64$\\times$64, 1.93 on AFHQv2-Wild-64$\\times$64, and 2.72 on\nImageNet-256$\\times$256. We share our code and pre-trained models at\nhttps://github.com/Zhendong-Wang/Patch-Diffusion.",
          "link": "http://arxiv.org/abs/2304.12526",
          "publishedOn": "2023-10-21T00:41:42.567Z",
          "wordCount": null,
          "title": "Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models. (arXiv:2304.12526v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deora_P/0/1/0/all/0/1\">Puneesh Deora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaderi_R/0/1/0/all/0/1\">Rouzbeh Ghaderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taheri_H/0/1/0/all/0/1\">Hossein Taheri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "The training and generalization dynamics of the Transformer's core mechanism,\nnamely the Attention mechanism, remain under-explored. Besides, existing\nanalyses primarily focus on single-head attention. Inspired by the demonstrated\nbenefits of overparameterization when training fully-connected networks, we\ninvestigate the potential optimization and generalization advantages of using\nmultiple attention heads. Towards this goal, we derive convergence and\ngeneralization guarantees for gradient-descent training of a single-layer\nmulti-head self-attention model, under a suitable realizability condition on\nthe data. We then establish primitive conditions on the initialization that\nensure realizability holds. Finally, we demonstrate that these conditions are\nsatisfied for a simple tokenized-mixture model. We expect the analysis can be\nextended to various data-model and architecture variations.",
          "link": "http://arxiv.org/abs/2310.12680",
          "publishedOn": "2023-10-21T00:41:42.565Z",
          "wordCount": null,
          "title": "On the Optimization and Generalization of Multi-head Attention. (arXiv:2310.12680v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1\">Mateo Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somenzi_F/0/1/0/all/0/1\">Fabio Somenzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Ashutosh Trivedi</a>",
          "description": "Linear temporal logic (LTL) and omega-regular objectives -- a superset of LTL\n-- have seen recent use as a way to express non-Markovian objectives in\nreinforcement learning. We introduce a model-based probably approximately\ncorrect (PAC) learning algorithm for omega-regular objectives in Markov\ndecision processes. Unlike prior approaches, our algorithm learns from sampled\ntrajectories of the system and does not require prior knowledge of the system's\ntopology.",
          "link": "http://arxiv.org/abs/2310.12248",
          "publishedOn": "2023-10-21T00:41:42.557Z",
          "wordCount": null,
          "title": "A PAC Learning Algorithm for LTL and Omega-regular Objectives in MDPs. (arXiv:2310.12248v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_M/0/1/0/all/0/1\">Masahiro Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furuta_S/0/1/0/all/0/1\">Shomu Furuta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fukazawa_Y/0/1/0/all/0/1\">Yusuke Fukazawa</a>",
          "description": "We explain the methodology used to create the data submitted to HuMob\nChallenge, a data analysis competition for human mobility prediction. We\nadopted a personalized model to predict the individual's movement trajectory\nfrom their data, instead of predicting from the overall movement, based on the\nhypothesis that human movement is unique to each person. We devised the\nfeatures such as the date and time, activity time, days of the week, time of\nday, and frequency of visits to POI (Point of Interest). As additional\nfeatures, we incorporated the movement of other individuals with similar\nbehavior patterns through the employment of clustering. The machine learning\nmodel we adopted was the Support Vector Regression (SVR). We performed accuracy\nthrough offline assessment and carried out feature selection and parameter\ntuning. Although overall dataset provided consists of 100,000 users trajectory,\nour method use only 20,000 target users data, and do not need to use other\n80,000 data. Despite the personalized model's traditional feature engineering\napproach, this model yields reasonably good accuracy with lower computational\ncost.",
          "link": "http://arxiv.org/abs/2310.12900",
          "publishedOn": "2023-10-21T00:41:42.532Z",
          "wordCount": null,
          "title": "Personalized human mobility prediction for HuMob challenge. (arXiv:2310.12900v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Junwoo Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryu_H/0/1/0/all/0/1\">Hyunwoo Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jiwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1\">Soochul Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Joohwan Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_N/0/1/0/all/0/1\">Nikhil Prakash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jongeun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horowitz_R/0/1/0/all/0/1\">Roberto Horowitz</a>",
          "description": "Diffusion models have risen as a powerful tool in robotics due to their\nflexibility and multi-modality. While some of these methods effectively address\ncomplex problems, they often depend heavily on inference-time obstacle\ndetection and require additional equipment. Addressing these challenges, we\npresent a method that, during inference time, simultaneously generates only\nreachable goals and plans motions that avoid obstacles, all from a single\nvisual input. Central to our approach is the novel use of a collision-avoiding\ndiffusion kernel for training. Through evaluations against behavior-cloning and\nclassical diffusion models, our framework has proven its robustness. It is\nparticularly effective in multi-modal environments, navigating toward goals and\navoiding unreachable ones blocked by obstacles, while ensuring collision\navoidance.",
          "link": "http://arxiv.org/abs/2310.12609",
          "publishedOn": "2023-10-21T00:41:42.523Z",
          "wordCount": null,
          "title": "Denoising Heat-inspired Diffusion with Insulators for Collision Free Motion Planning. (arXiv:2310.12609v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.13047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Le Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Leilei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bowen Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_W/0/1/0/all/0/1\">Weifeng Lv</a>",
          "description": "We propose DyGFormer, a new Transformer-based architecture for dynamic graph\nlearning. DyGFormer is conceptually simple and only needs to learn from nodes'\nhistorical first-hop interactions by: (1) a neighbor co-occurrence encoding\nscheme that explores the correlations of the source node and destination node\nbased on their historical sequences; (2) a patching technique that divides each\nsequence into multiple patches and feeds them to Transformer, allowing the\nmodel to effectively and efficiently benefit from longer histories. We also\nintroduce DyGLib, a unified library with standard training pipelines,\nextensible coding interfaces, and comprehensive evaluating protocols to promote\nreproducible, scalable, and credible dynamic graph learning research. By\nperforming exhaustive experiments on thirteen datasets for dynamic link\nprediction and dynamic node classification tasks, we find that DyGFormer\nachieves state-of-the-art performance on most of the datasets, demonstrating\nits effectiveness in capturing nodes' correlations and long-term temporal\ndependencies. Moreover, some results of baselines are inconsistent with\nprevious reports, which may be caused by their diverse but less rigorous\nimplementations, showing the importance of DyGLib. All the used resources are\npublicly available at https://github.com/yule-BUAA/DyGLib.",
          "link": "http://arxiv.org/abs/2303.13047",
          "publishedOn": "2023-10-21T00:41:42.520Z",
          "wordCount": null,
          "title": "Towards Better Dynamic Graph Learning: New Architecture and Unified Library. (arXiv:2303.13047v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Notsawo_P/0/1/0/all/0/1\">Pascal Junior Tikeng Notsawo</a>",
          "description": "Despite the recent growth of theoretical studies and empirical successes of\nneural networks, gradient backpropagation is still the most widely used\nalgorithm for training such networks. On the one hand, we have deterministic or\nfull gradient (FG) approaches that have a cost proportional to the amount of\ntraining data used but have a linear convergence rate, and on the other hand,\nstochastic gradient (SG) methods that have a cost independent of the size of\nthe dataset, but have a less optimal convergence rate than the determinist\napproaches. To combine the cost of the stochastic approach with the convergence\nrate of the deterministic approach, a stochastic average gradient (SAG) has\nbeen proposed. SAG is a method for optimizing the sum of a finite number of\nsmooth convex functions. Like SG methods, the SAG method's iteration cost is\nindependent of the number of terms in the sum. In this work, we propose to\ncompare SAG to some standard optimizers used in machine learning. SAG converges\nfaster than other optimizers on simple toy problems and performs better than\nmany other optimizers on simple machine learning problems. We also propose a\ncombination of SAG with the momentum algorithm and Adam. These combinations\nallow empirically higher speed and obtain better performance than the other\nmethods, especially when the landscape of the function to optimize presents\nobstacles or is ill-conditioned.",
          "link": "http://arxiv.org/abs/2310.12771",
          "publishedOn": "2023-10-21T00:41:42.519Z",
          "wordCount": null,
          "title": "Stochastic Average Gradient : A Simple Empirical Investigation. (arXiv:2310.12771v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Barbier__Chebbah_A/0/1/0/all/0/1\">Alex Barbier--Chebbah</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Vestergaard_C/0/1/0/all/0/1\">Christian L. Vestergaard</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Masson_J/0/1/0/all/0/1\">Jean-Baptiste Masson</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Boursier_E/0/1/0/all/0/1\">Etienne Boursier</a> (CELESTE)",
          "description": "Entropy maximization and free energy minimization are general physical\nprinciples for modeling the dynamics of various physical systems. Notable\nexamples include modeling decision-making within the brain using the\nfree-energy principle, optimizing the accuracy-complexity trade-off when\naccessing hidden variables with the information bottleneck principle (Tishby et\nal., 2000), and navigation in random environments using information\nmaximization (Vergassola et al., 2007). Built on this principle, we propose a\nnew class of bandit algorithms that maximize an approximation to the\ninformation of a key variable within the system. To this end, we develop an\napproximated analytical physics-based representation of an entropy to forecast\nthe information gain of each action and greedily choose the one with the\nlargest information gain. This method yields strong performances in classical\nbandit settings. Motivated by its empirical success, we prove its asymptotic\noptimality for the two-armed bandit problem with Gaussian rewards. Owing to its\nability to encompass the system's properties in a global physical functional,\nthis approach can be efficiently adapted to more complex bandit settings,\ncalling for further investigation of information maximization approaches for\nmulti-armed bandit problems.",
          "link": "http://arxiv.org/abs/2310.12563",
          "publishedOn": "2023-10-21T00:41:42.518Z",
          "wordCount": null,
          "title": "Approximate information maximization for bandit games. (arXiv:2310.12563v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fazekas_A/0/1/0/all/0/1\">Attila Fazekas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovacs_G/0/1/0/all/0/1\">Gy&#xf6;rgy Kov&#xe1;cs</a>",
          "description": "Binary classification is a fundamental task in machine learning, with\napplications spanning various scientific domains. Whether scientists are\nconducting fundamental research or refining practical applications, they\ntypically assess and rank classification techniques based on performance\nmetrics such as accuracy, sensitivity, and specificity. However, reported\nperformance scores may not always serve as a reliable basis for research\nranking. This can be attributed to undisclosed or unconventional practices\nrelated to cross-validation, typographical errors, and other factors. In a\ngiven experimental setup, with a specific number of positive and negative test\nitems, most performance scores can assume specific, interrelated values. In\nthis paper, we introduce numerical techniques to assess the consistency of\nreported performance scores and the assumed experimental setup. Importantly,\nthe proposed approach does not rely on statistical inference but uses numerical\nmethods to identify inconsistencies with certainty. Through three different\napplications related to medicine, we demonstrate how the proposed techniques\ncan effectively detect inconsistencies, thereby safeguarding the integrity of\nresearch fields. To benefit the scientific community, we have made the\nconsistency tests available in an open-source Python package.",
          "link": "http://arxiv.org/abs/2310.12527",
          "publishedOn": "2023-10-21T00:41:42.513Z",
          "wordCount": null,
          "title": "Testing the Consistency of Performance Scores Reported for Binary Classification Problems. (arXiv:2310.12527v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.08503",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1\">Xiaoming Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cuie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Liang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linqi Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1\">Kay Chen Tan</a>",
          "description": "Sequential transfer optimization (STO), which aims to improve the\noptimization performance on a task of interest by exploiting the knowledge\ncaptured from several previously-solved optimization tasks stored in a\ndatabase, has been gaining increasing research attention over the years.\nHowever, despite the remarkable advances in algorithm design, the development\nof a systematic benchmark suite for comprehensive comparisons of STO algorithms\nreceived far less attention. Existing test problems are either simply generated\nby assembling other benchmark functions or extended from specific practical\nproblems with limited scalability. The relationships between the optimal\nsolutions of the source and target tasks in these problems are also often\nmanually configured, limiting their ability to model different similarity\nrelationships presented in real-world problems. Consequently, the good\nperformance achieved by an algorithm on these problems might be biased and hard\nto be generalized to other problems. In light of the above, in this study, we\nfirst introduce four concepts for characterizing STO problems and present an\nimportant problem feature, namely similarity distribution, which quantitatively\ndelineates the relationship between the optima of the source and target tasks.\nThen, we present the general design guidelines of STO problems and a particular\nSTO problem generator with good scalability. Specifically, the similarity\ndistribution of a problem can be easily customized, enabling a continuous\nspectrum of representation of the diverse similarity relationships of\nreal-world problems. Lastly, a benchmark suite with 12 STO problems featured by\na variety of customized similarity relationships is developed using the\nproposed generator. The source code of the problem generator is available at\nhttps://github.com/XmingHsueh/STOP-G.",
          "link": "http://arxiv.org/abs/2304.08503",
          "publishedOn": "2023-10-21T00:41:42.512Z",
          "wordCount": null,
          "title": "A Scalable Test Problem Generator for Sequential Transfer Optimization. (arXiv:2304.08503v4 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12768",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_W/0/1/0/all/0/1\">Wensheng Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yan_Y/0/1/0/all/0/1\">Yuna Yan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_L/0/1/0/all/0/1\">Lixin Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_Z/0/1/0/all/0/1\">Zhu Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Matsumoto_T/0/1/0/all/0/1\">Tad Matsumoto</a>",
          "description": "This letter proposes a novel anti-interference technique, semantic\ninterference cancellation (SemantIC), for enhancing information quality towards\nthe sixth-generation (6G) wireless networks. SemantIC only requires the\nreceiver to concatenate the channel decoder with a semantic auto-encoder. This\nconstructs a turbo loop which iteratively and alternately eliminates noise in\nthe signal domain and the semantic domain. From the viewpoint of network\ninformation theory, the neural network of the semantic auto-encoder stores side\ninformation by training, and provides side information in iterative decoding,\nas an implementation of the Wyner-Ziv theorem. Simulation results verify the\nperformance improvement by SemantIC without extra channel resource cost.",
          "link": "http://arxiv.org/abs/2310.12768",
          "publishedOn": "2023-10-21T00:41:42.501Z",
          "wordCount": null,
          "title": "SemantIC: Semantic Interference Cancellation Towards 6G Wireless Communications. (arXiv:2310.12768v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "Although remarkable progress has been achieved in preventing large language\nmodel (LLM) hallucinations using instruction tuning and retrieval augmentation,\nit remains challenging to measure the reliability of LLMs using human-crafted\nevaluation data which is not available for many tasks and domains and could\nsuffer from data leakage. Inspired by adversarial machine learning, this paper\naims to develop a method of automatically generating evaluation data by\nappropriately modifying existing data on which LLMs behave faithfully.\nSpecifically, this paper presents AutoDebug, an LLM-based framework to use\nprompting chaining to generate transferable adversarial attacks in the form of\nquestion-answering examples. We seek to understand the extent to which these\nexamples trigger the hallucination behaviors of LLMs.\n\nWe implement AutoDebug using ChatGPT and evaluate the resulting two variants\nof a popular open-domain question-answering dataset, Natural Questions (NQ), on\na collection of open-source and proprietary LLMs under various prompting\nsettings. Our generated evaluation data is human-readable and, as we show,\nhumans can answer these modified questions well. Nevertheless, we observe\npronounced accuracy drops across multiple LLMs including GPT-4. Our\nexperimental results show that LLMs are likely to hallucinate in two categories\nof question-answering scenarios where (1) there are conflicts between knowledge\ngiven in the prompt and their parametric knowledge, or (2) the knowledge\nexpressed in the prompt is complex. Finally, we find that the adversarial\nexamples generated by our method are transferable across all considered LLMs.\nThe examples generated by a small model can be used to debug a much larger\nmodel, making our approach cost-effective.",
          "link": "http://arxiv.org/abs/2310.12516",
          "publishedOn": "2023-10-21T00:41:42.497Z",
          "wordCount": null,
          "title": "Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks. (arXiv:2310.12516v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoffmann_M/0/1/0/all/0/1\">Marcel Hoffmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galke_L/0/1/0/all/0/1\">Lukas Galke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherp_A/0/1/0/all/0/1\">Ansgar Scherp</a>",
          "description": "We study the problem of lifelong graph learning in an open-world scenario,\nwhere a model needs to deal with new tasks and potentially unknown classes. We\nutilize Out-of-Distribution (OOD) detection methods to recognize new classes\nand adapt existing non-graph OOD detection methods to graph data. Crucially, we\nsuggest performing new class detection by combining OOD detection methods with\ninformation aggregated from the graph neighborhood. Most OOD detection methods\navoid determining a crisp threshold for deciding whether a vertex is OOD. To\ntackle this problem, we propose a Weakly-supervised Relevance Feedback\n(Open-WRF) method, which decreases the sensitivity to thresholds in OOD\ndetection. We evaluate our approach on six benchmark datasets. Our results show\nthat the proposed neighborhood aggregation method for OOD scores outperforms\nexisting methods independent of the underlying graph neural network.\nFurthermore, we demonstrate that our Open-WRF method is more robust to\nthreshold selection and analyze the influence of graph neighborhood on OOD\ndetection. The aggregation and threshold methods are compatible with arbitrary\ngraph neural networks and OOD detection methods, making our approach versatile\nand applicable to many real-world applications.",
          "link": "http://arxiv.org/abs/2310.12565",
          "publishedOn": "2023-10-21T00:41:42.491Z",
          "wordCount": null,
          "title": "Open-World Lifelong Graph Learning. (arXiv:2310.12565v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12309",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mileva_Z/0/1/0/all/0/1\">Zlatina Mileva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bikakis_A/0/1/0/all/0/1\">Antonis Bikakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAsaro_F/0/1/0/all/0/1\">Fabio Aurelio D&#x27;Asaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1\">Mark Law</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russo_A/0/1/0/all/0/1\">Alessandra Russo</a>",
          "description": "Argumentation is a very active research field of Artificial Intelligence\nconcerned with the representation and evaluation of arguments used in dialogues\nbetween humans and/or artificial agents. Acceptability semantics of formal\nargumentation systems define the criteria for the acceptance or rejection of\narguments. Several software systems, known as argumentation solvers, have been\ndeveloped to compute the accepted/rejected arguments using such criteria. These\ninclude systems that learn to identify the accepted arguments using\nnon-interpretable methods. In this paper we present a novel framework, which\nuses an Inductive Logic Programming approach to learn the acceptability\nsemantics for several abstract and structured argumentation frameworks in an\ninterpretable way. Through an empirical evaluation we show that our framework\noutperforms existing argumentation solvers, thus opening up new future research\ndirections in the area of formal argumentation and human-machine dialogues.",
          "link": "http://arxiv.org/abs/2310.12309",
          "publishedOn": "2023-10-21T00:41:42.486Z",
          "wordCount": null,
          "title": "A Unifying Framework for Learning Argumentation Semantics. (arXiv:2310.12309v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12156",
          "author": "<a href=\"http://arxiv.org/find/nlin/1/au:+Tavasoli_A/0/1/0/all/0/1\">Ali Tavasoli</a>, <a href=\"http://arxiv.org/find/nlin/1/au:+Shakeri_H/0/1/0/all/0/1\">Heman Shakeri</a>",
          "description": "This paper examines the use of operator-theoretic approaches to the analysis\nof chaotic systems through the lens of their unstable periodic orbits (UPOs).\nOur approach involves three data-driven steps for detecting, identifying, and\nstabilizing UPOs. We demonstrate the use of kernel integral operators within\ndelay coordinates as an innovative method for UPO detection. For identifying\nthe dynamic behavior associated with each individual UPO, we utilize the\nKoopman operator to present the dynamics as linear equations in the space of\nKoopman eigenfunctions. This allows for characterizing the chaotic attractor by\ninvestigating its principal dynamical modes across varying UPOs. We extend this\nmethodology into an interpretable machine learning framework aimed at\nstabilizing strange attractors on their UPOs. To illustrate the efficacy of our\napproach, we apply it to the Lorenz attractor as a case study.",
          "link": "http://arxiv.org/abs/2310.12156",
          "publishedOn": "2023-10-21T00:41:42.470Z",
          "wordCount": null,
          "title": "Operator-Based Detecting, Learning, and Stabilizing Unstable Periodic Orbits of Chaotic Attractors. (arXiv:2310.12156v1 [nlin.AO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.07162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yumeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1\">Ning Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1\">Hanna Ziesche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1\">Gerhard Neumann</a>",
          "description": "We present a novel meta-learning approach for 6D pose estimation on unknown\nobjects. In contrast to ``instance-level\" and ``category-level\" pose estimation\nmethods, our algorithm learns object representation in a category-agnostic way,\nwhich endows it with strong generalization capabilities across object\ncategories. Specifically, we employ a neural process-based meta-learning\napproach to train an encoder to capture texture and geometry of an object in a\nlatent representation, based on very few RGB-D images and ground-truth\nkeypoints. The latent representation is then used by a simultaneously\nmeta-trained decoder to predict the 6D pose of the object in new images.\nFurthermore, we propose a novel geometry-aware decoder for the keypoint\nprediction using a Graph Neural Network (GNN), which explicitly takes geometric\nconstraints specific to each object into consideration. To evaluate our\nalgorithm, extensive experiments are conducted on the \\linemod dataset, and on\nour new fully-annotated synthetic datasets generated from Multiple Categories\nin Multiple Scenes (MCMS). Experimental results demonstrate that our model\nperforms well on unseen objects with very different shapes and appearances.\nRemarkably, our model also shows robust performance on occluded scenes although\ntrained fully on data without occlusion. To our knowledge, this is the first\nwork exploring \\textbf{cross-category level} 6D pose estimation.",
          "link": "http://arxiv.org/abs/2206.07162",
          "publishedOn": "2023-10-21T00:41:42.456Z",
          "wordCount": null,
          "title": "Category-Agnostic 6D Pose Estimation with Conditional Neural Processes. (arXiv:2206.07162v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamdan_S/0/1/0/all/0/1\">Sami Hamdan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+More_S/0/1/0/all/0/1\">Shammi More</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasse_L/0/1/0/all/0/1\">Leonard Sasse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komeyer_V/0/1/0/all/0/1\">Vera Komeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_K/0/1/0/all/0/1\">Kaustubh R. Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raimondo_F/0/1/0/all/0/1\">Federico Raimondo</a> (for the Alzheimer&#x27;s Disease Neuroimaging Initiative)",
          "description": "The fast-paced development of machine learning (ML) methods coupled with its\nincreasing adoption in research poses challenges for researchers without\nextensive training in ML. In neuroscience, for example, ML can help understand\nbrain-behavior relationships, diagnose diseases, and develop biomarkers using\nvarious data sources like magnetic resonance imaging and\nelectroencephalography. The primary objective of ML is to build models that can\nmake accurate predictions on unseen data. Researchers aim to prove the\nexistence of such generalizable models by evaluating performance using\ntechniques such as cross-validation (CV), which uses systematic subsampling to\nestimate the generalization performance. Choosing a CV scheme and evaluating an\nML pipeline can be challenging and, if used improperly, can lead to\noverestimated results and incorrect interpretations.\n\nWe created julearn, an open-source Python library, that allow researchers to\ndesign and evaluate complex ML pipelines without encountering in common\npitfalls. In this manuscript, we present the rationale behind julearn's design,\nits core features, and showcase three examples of previously-published research\nprojects that can be easily implemented using this novel library. Julearn aims\nto simplify the entry into the ML world by providing an easy-to-use environment\nwith built in guards against some of the most common ML pitfalls. With its\ndesign, unique features and simple interface, it poses as a useful Python-based\nlibrary for research projects.",
          "link": "http://arxiv.org/abs/2310.12568",
          "publishedOn": "2023-10-21T00:41:42.444Z",
          "wordCount": null,
          "title": "Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models. (arXiv:2310.12568v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12804",
          "author": "<a href=\"http://arxiv.org/find/hep-ex/1/au:+Smith_R/0/1/0/all/0/1\">Rachel E. C. Smith</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Ochoa_I/0/1/0/all/0/1\">In&#xea;s Ochoa</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Inacio_R/0/1/0/all/0/1\">R&#xfa;ben In&#xe1;cio</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Shoemaker_J/0/1/0/all/0/1\">Jonathan Shoemaker</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Kagan_M/0/1/0/all/0/1\">Michael Kagan</a>",
          "description": "We propose a differentiable vertex fitting algorithm that can be used for\nsecondary vertex fitting, and that can be seamlessly integrated into neural\nnetworks for jet flavour tagging. Vertex fitting is formulated as an\noptimization problem where gradients of the optimized solution vertex are\ndefined through implicit differentiation and can be passed to upstream or\ndownstream neural network components for network training. More broadly, this\nis an application of differentiable programming to integrate physics knowledge\ninto neural network models in high energy physics. We demonstrate how\ndifferentiable secondary vertex fitting can be integrated into larger\ntransformer-based models for flavour tagging and improve heavy flavour jet\nclassification.",
          "link": "http://arxiv.org/abs/2310.12804",
          "publishedOn": "2023-10-21T00:41:42.440Z",
          "wordCount": null,
          "title": "Differentiable Vertex Fitting for Jet Flavour Tagging. (arXiv:2310.12804v1 [hep-ex])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.07469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahn_K/0/1/0/all/0/1\">Kwangjun Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bubeck_S/0/1/0/all/0/1\">S&#xe9;bastien Bubeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chewi_S/0/1/0/all/0/1\">Sinho Chewi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yin Tat Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suarez_F/0/1/0/all/0/1\">Felipe Suarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>",
          "description": "Existing analyses of neural network training often operate under the\nunrealistic assumption of an extremely small learning rate. This lies in stark\ncontrast to practical wisdom and empirical studies, such as the work of J.\nCohen et al. (ICLR 2021), which exhibit startling new phenomena (the \"edge of\nstability\" or \"unstable convergence\") and potential benefits for generalization\nin the large learning rate regime. Despite a flurry of recent works on this\ntopic, however, the latter effect is still poorly understood. In this paper, we\ntake a step towards understanding genuinely non-convex training dynamics with\nlarge learning rates by performing a detailed analysis of gradient descent for\nsimplified models of two-layer neural networks. For these models, we provably\nestablish the edge of stability phenomenon and discover a sharp phase\ntransition for the step size below which the neural network fails to learn\n\"threshold-like\" neurons (i.e., neurons with a non-zero first-layer bias). This\nelucidates one possible mechanism by which the edge of stability can in fact\nlead to better generalization, as threshold neurons are basic building blocks\nwith useful inductive bias for many tasks.",
          "link": "http://arxiv.org/abs/2212.07469",
          "publishedOn": "2023-10-21T00:41:42.439Z",
          "wordCount": null,
          "title": "Learning threshold neurons via the \"edge of stability\". (arXiv:2212.07469v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12570",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sun_G/0/1/0/all/0/1\">Guanqun Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_Y/0/1/0/all/0/1\">Yizhi Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kong_W/0/1/0/all/0/1\">Weikun Kong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Z/0/1/0/all/0/1\">Zichang Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_J/0/1/0/all/0/1\">Jianhua Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Racharak_T/0/1/0/all/0/1\">Teeradaj Racharak</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nguyen_L/0/1/0/all/0/1\">Le-Minh Nguyen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xin_J/0/1/0/all/0/1\">Junyi Xin</a>",
          "description": "Great progress has been made in automatic medical image segmentation due to\npowerful deep representation learning. The influence of transformer has led to\nresearch into its variants, and large-scale replacement of traditional CNN\nmodules. However, such trend often overlooks the intrinsic feature extraction\ncapabilities of the transformer and potential refinements to both the model and\nthe transformer module through minor adjustments. This study proposes a novel\ndeep medical image segmentation framework, called DA-TransUNet, aiming to\nintroduce the Transformer and dual attention block into the encoder and decoder\nof the traditional U-shaped architecture. Unlike prior transformer-based\nsolutions, our DA-TransUNet utilizes attention mechanism of transformer and\nmultifaceted feature extraction of DA-Block, which can efficiently combine\nglobal, local, and multi-scale features to enhance medical image segmentation.\nMeanwhile, experimental results show that a dual attention block is added\nbefore the Transformer layer to facilitate feature extraction in the U-net\nstructure. Furthermore, incorporating dual attention blocks in skip connections\ncan enhance feature transfer to the decoder, thereby improving image\nsegmentation performance. Experimental results across various benchmark of\nmedical image segmentation reveal that DA-TransUNet significantly outperforms\nthe state-of-the-art methods. The codes and parameters of our model will be\npublicly available at https://github.com/SUN-1024/DA-TransUnet.",
          "link": "http://arxiv.org/abs/2310.12570",
          "publishedOn": "2023-10-21T00:41:42.438Z",
          "wordCount": null,
          "title": "DA-TransUNet: Integrating Spatial and Channel Dual Attention with Transformer U-Net for Medical Image Segmentation. (arXiv:2310.12570v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12743",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Flouris_K/0/1/0/all/0/1\">Kyriakos Flouris</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Konukoglu_E/0/1/0/all/0/1\">Ender Konukoglu</a>",
          "description": "Manifold learning flows are a class of generative modelling techniques that\nassume a low-dimensional manifold description of the data. The embedding of\nsuch manifold into the high-dimensional space of the data is achieved via\nlearnable invertible transformations. Therefore, once the manifold is properly\naligned via a reconstruction loss, the probability density is tractable on the\nmanifold and maximum likelihood can be used optimize the network parameters.\nNaturally, the lower-dimensional representation of the data requires an\ninjective-mapping. Recent approaches were able to enforce that density aligns\nwith the modelled manifold, while efficiently calculating the density\nvolume-change term when embedding to the higher-dimensional space. However,\nunless the injective-mapping is analytically predefined, the learned manifold\nis not necessarily an efficient representation of the data. Namely, the latent\ndimensions of such models frequently learn an entangled intrinsic basis with\ndegenerate information being stored in each dimension. Alternatively, if a\nlocally orthogonal and/or sparse basis is to be learned, here coined canonical\nintrinsic basis, it can serve in learning a more compact latent space\nrepresentation. Towards this end, we propose a canonical manifold learning flow\nmethod, where a novel optimization objective enforces the transformation matrix\nto have few prominent and orthogonal basis functions. Canonical manifold flow\nyields a more efficient use of the latent space, automatically generating fewer\nprominent and distinct dimensions to represent data, and consequently a better\napproximation of target distributions than other manifold flow methods in most\nexperiments we conducted, resulting in lower FID scores.",
          "link": "http://arxiv.org/abs/2310.12743",
          "publishedOn": "2023-10-21T00:41:42.438Z",
          "wordCount": null,
          "title": "Canonical normalizing flows for manifold learning. (arXiv:2310.12743v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arimond_A/0/1/0/all/0/1\">Alexander Arimond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molteni_M/0/1/0/all/0/1\">Mauro Molteni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jany_D/0/1/0/all/0/1\">Dominik Jany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manolova_Z/0/1/0/all/0/1\">Zornitsa Manolova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1\">Damian Borth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoepner_A/0/1/0/all/0/1\">Andreas G.F. Hoepner</a>",
          "description": "We propose the application of Transformer-based language models for\nclassifying entity legal forms from raw legal entity names. Specifically, we\nemploy various BERT variants and compare their performance against multiple\ntraditional baselines. Our evaluation encompasses a substantial subset of\nfreely available Legal Entity Identifier (LEI) data, comprising over 1.1\nmillion legal entities from 30 different legal jurisdictions. The ground truth\nlabels for classification per jurisdiction are taken from the Entity Legal Form\n(ELF) code standard (ISO 20275). Our findings demonstrate that pre-trained BERT\nvariants outperform traditional text classification approaches in terms of F1\nscore, while also performing comparably well in the Macro F1 Score. Moreover,\nthe validity of our proposal is supported by the outcome of third-party expert\nreviews conducted in ten selected jurisdictions. This study highlights the\nsignificant potential of Transformer-based models in advancing data\nstandardization and data integration. The presented approaches can greatly\nbenefit financial institutions, corporations, governments and other\norganizations in assessing business relationships, understanding risk exposure,\nand promoting effective governance.",
          "link": "http://arxiv.org/abs/2310.12766",
          "publishedOn": "2023-10-21T00:41:42.438Z",
          "wordCount": null,
          "title": "Transformer-based Entity Legal Form Classification. (arXiv:2310.12766v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rosaler_J/0/1/0/all/0/1\">Joshua Rosaler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Desai_D/0/1/0/all/0/1\">Dhruv Desai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sarmah_B/0/1/0/all/0/1\">Bhaskarjit Sarmah</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vamvourellis_D/0/1/0/all/0/1\">Dimitrios Vamvourellis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Onay_D/0/1/0/all/0/1\">Deran Onay</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mehta_D/0/1/0/all/0/1\">Dhagash Mehta</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pasquali_S/0/1/0/all/0/1\">Stefano Pasquali</a>",
          "description": "We initiate a novel approach to explain the out of sample performance of\nrandom forest (RF) models by exploiting the fact that any RF can be formulated\nas an adaptive weighted K nearest-neighbors model. Specifically, we use the\nproximity between points in the feature space learned by the RF to re-write\nrandom forest predictions exactly as a weighted average of the target labels of\ntraining data points. This linearity facilitates a local notion of\nexplainability of RF predictions that generates attributions for any model\nprediction across observations in the training set, and thereby complements\nestablished methods like SHAP, which instead generates attributions for a model\nprediction across dimensions of the feature space. We demonstrate this approach\nin the context of a bond pricing model trained on US corporate bond trades, and\ncompare our approach to various existing approaches to model explainability.",
          "link": "http://arxiv.org/abs/2310.12428",
          "publishedOn": "2023-10-21T00:41:42.435Z",
          "wordCount": null,
          "title": "Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarker_I/0/1/0/all/0/1\">Iqbal H. Sarker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janicke_H/0/1/0/all/0/1\">Helge Janicke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_N/0/1/0/all/0/1\">Nazeeruddin Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watters_P/0/1/0/all/0/1\">Paul Watters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nepal_S/0/1/0/all/0/1\">Surya Nepal</a>",
          "description": "This position paper explores the broad landscape of AI potentiality in the\ncontext of cybersecurity, with a particular emphasis on its possible risk\nfactors with awareness, which can be managed by incorporating human experts in\nthe loop, i.e., \"Human-AI\" teaming. As artificial intelligence (AI)\ntechnologies advance, they will provide unparalleled opportunities for attack\nidentification, incident response, and recovery. However, the successful\ndeployment of AI into cybersecurity measures necessitates an in-depth\nunderstanding of its capabilities, challenges, and ethical and legal\nimplications to handle associated risk factors in real-world application areas.\nTowards this, we emphasize the importance of a balanced approach that\nincorporates AI's computational power with human expertise. AI systems may\nproactively discover vulnerabilities and detect anomalies through pattern\nrecognition, and predictive modeling, significantly enhancing speed and\naccuracy. Human experts can explain AI-generated decisions to stakeholders,\nregulators, and end-users in critical situations, ensuring responsibility and\naccountability, which helps establish trust in AI-driven security solutions.\nTherefore, in this position paper, we argue that human-AI teaming is worthwhile\nin cybersecurity, in which human expertise such as intuition, critical\nthinking, or contextual understanding is combined with AI's computational power\nto improve overall cyber defenses.",
          "link": "http://arxiv.org/abs/2310.12162",
          "publishedOn": "2023-10-21T00:41:42.434Z",
          "wordCount": null,
          "title": "AI Potentiality and Awareness: A Position Paper from the Perspective of Human-AI Teaming in Cybersecurity. (arXiv:2310.12162v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16546",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_D/0/1/0/all/0/1\">Davi Guimar&#xe3;es da Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meneses_A/0/1/0/all/0/1\">Anderson Alvarenga de Moura Meneses</a>",
          "description": "Electric consumption prediction methods are investigated for many reasons\nsuch as decision-making related to energy efficiency as well as for\nanticipating demand in the energy market dynamics. The objective of the present\nwork is the comparison between two Deep Learning models, namely the Long\nShort-Term Memory (LSTM) and Bi-directional LSTM (BLSTM) for univariate\nelectric consumption Time Series (TS) short-term forecast. The Data Sets (DSs)\nwere selected for their different contexts and scales, aiming the assessment of\nthe models' robustness. Four DSs were used, related to the power consumption\nof: (a) a household in France; (b) a university building in Santar\\'em, Brazil;\n(c) the T\\'etouan city zones, in Morocco; and (c) the Singapore aggregated\nelectric demand. The metrics RMSE, MAE, MAPE and R2 were calculated in a TS\ncross-validation scheme. The Friedman's test was applied to normalized RMSE\n(NRMSE) results, showing that BLSTM outperforms LSTM with statistically\nsignificant difference (p = 0.0455), corroborating the fact that bidirectional\nweight updating improves significantly the LSTM performance concerning\ndifferent scales of electric power consumption.",
          "link": "http://arxiv.org/abs/2305.16546",
          "publishedOn": "2023-10-21T00:41:42.433Z",
          "wordCount": null,
          "title": "Preliminary studies: Comparing LSTM and BLSTM Deep Neural Networks for Power Consumption Prediction. (arXiv:2305.16546v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maezawa_A/0/1/0/all/0/1\">Akira Maezawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1\">Gus Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamamoto_K/0/1/0/all/0/1\">Kazuhiko Yamamoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixon_S/0/1/0/all/0/1\">Simon Dixon</a>",
          "description": "Creating music is iterative, requiring varied methods at each stage. However,\nexisting AI music systems fall short in orchestrating multiple subsystems for\ndiverse needs. To address this gap, we introduce Loop Copilot, a novel system\nthat enables users to generate and iteratively refine music through an\ninteractive, multi-round dialogue interface. The system uses a large language\nmodel to interpret user intentions and select appropriate AI models for task\nexecution. Each backend model is specialized for a specific task, and their\noutputs are aggregated to meet the user's requirements. To ensure musical\ncoherence, essential attributes are maintained in a centralized table. We\nevaluate the effectiveness of the proposed system through semi-structured\ninterviews and questionnaires, highlighting its utility not only in\nfacilitating music creation but also its potential for broader applications.",
          "link": "http://arxiv.org/abs/2310.12404",
          "publishedOn": "2023-10-21T00:41:42.428Z",
          "wordCount": null,
          "title": "Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative Editing. (arXiv:2310.12404v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Davies_C/0/1/0/all/0/1\">Cai Davies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vilamala_M/0/1/0/all/0/1\">Marc Roig Vilamala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preece_A/0/1/0/all/0/1\">Alun D. Preece</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cerutti_F/0/1/0/all/0/1\">Federico Cerutti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaplan_L/0/1/0/all/0/1\">Lance M. Kaplan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Supriyo Chakraborty</a>",
          "description": "This work reveals an evidential signal that emerges from the uncertainty\nvalue in Evidential Deep Learning (EDL). EDL is one example of a class of\nuncertainty-aware deep learning approaches designed to provide confidence (or\nepistemic uncertainty) about the current test sample. In particular for\ncomputer vision and bidirectional encoder large language models, the\n`evidential signal' arising from the Dirichlet strength in EDL can, in some\ncases, discriminate between classes, which is particularly strong when using\nlarge language models. We hypothesise that the KL regularisation term causes\nEDL to couple aleatoric and epistemic uncertainty. In this paper, we\nempirically investigate the correlations between misclassification and\nevaluated uncertainty, and show that EDL's `evidential signal' is due to\nmisclassification bias. We critically evaluate EDL with other Dirichlet-based\napproaches, namely Generative Evidential Neural Networks (EDL-GEN) and Prior\nNetworks, and show theoretically and empirically the differences between these\nloss functions. We conclude that EDL's coupling of uncertainty arises from\nthese differences due to the use (or lack) of out-of-distribution samples\nduring training.",
          "link": "http://arxiv.org/abs/2310.12663",
          "publishedOn": "2023-10-21T00:41:42.382Z",
          "wordCount": null,
          "title": "Knowledge from Uncertainty in Evidential Deep Learning. (arXiv:2310.12663v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.07063",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>",
          "description": "Reasoning on knowledge graphs is a challenging task because it utilizes\nobserved information to predict the missing one. Particularly, answering\ncomplex queries based on first-order logic is one of the crucial tasks to\nverify learning to reason abilities for generalization and composition.\nRecently, the prevailing method is query embedding which learns the embedding\nof a set of entities and treats logic operations as set operations and has\nshown great empirical success. Though there has been much research following\nthe same formulation, many of its claims lack a formal and systematic\ninspection. In this paper, we rethink this formulation and justify many of the\nprevious claims by characterizing the scope of queries investigated previously\nand precisely identifying the gap between its formulation and its goal, as well\nas providing complexity analysis for the currently investigated queries.\nMoreover, we develop a new dataset containing ten new types of queries with\nfeatures that have never been considered and therefore can provide a thorough\ninvestigation of complex queries. Finally, we propose a new neural-symbolic\nmethod, Fuzzy Inference with Truth value (FIT), where we equip the neural link\npredictors with fuzzy logic theory to support end-to-end learning using complex\nqueries with provable reasoning capability. Empirical results show that our\nmethod outperforms previous methods significantly in the new dataset and also\nsurpasses previous methods in the existing dataset at the same time.",
          "link": "http://arxiv.org/abs/2304.07063",
          "publishedOn": "2023-10-21T00:41:42.364Z",
          "wordCount": null,
          "title": "Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors. (arXiv:2304.07063v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng-Kun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min-Hung Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yung-Yu Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yen-Yu Lin</a>",
          "description": "We present a Multimodal Interlaced Transformer (MIT) that jointly considers\n2D and 3D data for weakly supervised point cloud segmentation. Research studies\nhave shown that 2D and 3D features are complementary for point cloud\nsegmentation. However, existing methods require extra 2D annotations to achieve\n2D-3D information fusion. Considering the high annotation cost of point clouds,\neffective 2D and 3D feature fusion based on weakly supervised learning is in\ngreat demand. To this end, we propose a transformer model with two encoders and\none decoder for weakly supervised point cloud segmentation using only\nscene-level class tags. Specifically, the two encoders compute the\nself-attended features for 3D point clouds and 2D multi-view images,\nrespectively. The decoder implements interlaced 2D-3D cross-attention and\ncarries out implicit 2D and 3D feature fusion. We alternately switch the roles\nof queries and key-value pairs in the decoder layers. It turns out that the 2D\nand 3D features are iteratively enriched by each other. Experiments show that\nit performs favorably against existing weakly supervised point cloud\nsegmentation methods by a large margin on the S3DIS and ScanNet benchmarks. The\nproject page will be available at https://jimmy15923.github.io/mit_web/.",
          "link": "http://arxiv.org/abs/2310.12817",
          "publishedOn": "2023-10-21T00:41:42.295Z",
          "wordCount": null,
          "title": "2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision. (arXiv:2310.12817v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daheim_N/0/1/0/all/0/1\">Nico Daheim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mollenhoff_T/0/1/0/all/0/1\">Thomas M&#xf6;llenhoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1\">Edoardo Maria Ponti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>",
          "description": "Models trained on different datasets can be merged by a weighted-averaging of\ntheir parameters, but why does it work and when can it fail? Here, we connect\nthe inaccuracy of weighted-averaging to mismatches in the gradients and propose\na new uncertainty-based scheme to improve the performance by reducing the\nmismatch. The connection also reveals implicit assumptions in other schemes\nsuch as averaging, task arithmetic, and Fisher-weighted averaging. Our new\nmethod gives consistent improvements for large language models and vision\ntransformers, both in terms of performance and robustness to hyperparameters.",
          "link": "http://arxiv.org/abs/2310.12808",
          "publishedOn": "2023-10-21T00:41:42.265Z",
          "wordCount": null,
          "title": "Model Merging by Uncertainty-Based Gradient Matching. (arXiv:2310.12808v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jinheon Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1\">Soyeong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Minki Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jong C. Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Recent Language Models (LMs) have shown impressive capabilities in generating\ntexts with the knowledge internalized in parameters. Yet, LMs often generate\nthe factually incorrect responses to the given queries, since their knowledge\nmay be inaccurate, incomplete, and outdated. To address this problem, previous\nworks propose to augment LMs with the knowledge retrieved from an external\nknowledge source. However, such approaches often show suboptimal text\ngeneration performance due to two reasons: 1) the model may fail to retrieve\nthe knowledge relevant to the given query, or 2) the model may not faithfully\nreflect the retrieved knowledge in the generated text. To overcome these, we\npropose to verify the output and the knowledge of the knowledge-augmented LMs\nwith a separate verifier, which is a small LM that is trained to detect those\ntwo types of errors through instruction-finetuning. Then, when the verifier\nrecognizes an error, we can rectify it by either retrieving new knowledge or\ngenerating new text. Further, we use an ensemble of the outputs from different\ninstructions with a single verifier to enhance the reliability of the\nverification processes. We validate the effectiveness of the proposed\nverification steps on multiple question answering benchmarks, whose results\nshow that the proposed verifier effectively identifies retrieval and generation\nerrors, allowing LMs to provide more factually correct outputs. Our code is\navailable at https://github.com/JinheonBaek/KALMV.",
          "link": "http://arxiv.org/abs/2310.12836",
          "publishedOn": "2023-10-21T00:41:42.264Z",
          "wordCount": null,
          "title": "Knowledge-Augmented Language Model Verification. (arXiv:2310.12836v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Aohan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mingdao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Rui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuxiao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Open large language models (LLMs) with great performance in various tasks\nhave significantly advanced the development of LLMs. However, they are far\ninferior to commercial models such as ChatGPT and GPT-4 when acting as agents\nto tackle complex tasks in the real world. These agent tasks employ LLMs as the\ncentral controller responsible for planning, memorization, and tool\nutilization, necessitating both fine-grained prompting methods and robust LLMs\nto achieve satisfactory performance. Though many prompting methods have been\nproposed to complete particular agent tasks, there is lack of research focusing\non improving the agent capabilities of LLMs themselves without compromising\ntheir general abilities. In this work, we present AgentTuning, a simple and\ngeneral method to enhance the agent abilities of LLMs while maintaining their\ngeneral LLM capabilities. We construct AgentInstruct, a lightweight\ninstruction-tuning dataset containing high-quality interaction trajectories. We\nemploy a hybrid instruction-tuning strategy by combining AgentInstruct with\nopen-source instructions from general domains. AgentTuning is used to\ninstruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show\nthat AgentTuning enables LLMs' agent capabilities without compromising general\nabilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent\ntasks, demonstrating generalized agent capabilities. We open source the\nAgentInstruct and AgentLM-7B, 13B, and 70B models at\nhttps://github.com/THUDM/AgentTuning , serving open and powerful alternatives\nto commercial LLMs for agent tasks.",
          "link": "http://arxiv.org/abs/2310.12823",
          "publishedOn": "2023-10-21T00:41:42.245Z",
          "wordCount": null,
          "title": "AgentTuning: Enabling Generalized Agent Abilities for LLMs. (arXiv:2310.12823v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yaohua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jiaxin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_X/0/1/0/all/0/1\">Xianghao Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Risheng Liu</a>",
          "description": "In light of the vulnerability of deep learning models to adversarial samples\nand the ensuing security issues, a range of methods, including Adversarial\nTraining (AT) as a prominent representative, aimed at enhancing model\nrobustness against various adversarial attacks, have seen rapid development.\nHowever, existing methods essentially assist the current state of target model\nto defend against parameter-oriented adversarial attacks with explicit or\nimplicit computation burdens, which also suffers from unstable convergence\nbehavior due to inconsistency of optimization trajectories. Diverging from\nprevious work, this paper reconsiders the update rule of target model and\ncorresponding deficiency to defend based on its current state. By introducing\nthe historical state of the target model as a proxy, which is endowed with much\nprior information for defense, we formulate a two-stage update rule, resulting\nin a general adversarial defense framework, which we refer to as `LAST' ({\\bf\nL}earn from the P{\\bf ast}). Besides, we devise a Self Distillation (SD) based\ndefense objective to constrain the update process of the proxy model without\nthe introduction of larger teacher models. Experimentally, we demonstrate\nconsistent and significant performance enhancements by refining a series of\nsingle-step and multi-step AT methods (e.g., up to $\\bf 9.2\\%$ and $\\bf 20.5\\%$\nimprovement of Robust Accuracy (RA) on CIFAR10 and CIFAR100 datasets,\nrespectively) across various datasets, backbones and attack modalities, and\nvalidate its ability to enhance training stability and ameliorate catastrophic\noverfitting issues meanwhile.",
          "link": "http://arxiv.org/abs/2310.12713",
          "publishedOn": "2023-10-21T00:41:42.244Z",
          "wordCount": null,
          "title": "Learn from the Past: A Proxy based Adversarial Defense Framework to Boost Robustness. (arXiv:2310.12713v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yida Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_D/0/1/0/all/0/1\">Daxiong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guozhou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>",
          "description": "Ocean science, which delves into the oceans that are reservoirs of life and\nbiodiversity, is of great significance given that oceans cover over 70% of our\nplanet's surface. Recently, advances in Large Language Models (LLMs) have\ntransformed the paradigm in science. Despite the success in other domains,\ncurrent LLMs often fall short in catering to the needs of domain experts like\noceanographers, and the potential of LLMs for ocean science is under-explored.\nThe intrinsic reason may be the immense and intricate nature of ocean data as\nwell as the necessity for higher granularity and richness in knowledge. To\nalleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean\ndomain, which is expert in various ocean science tasks. We propose DoInstruct,\na novel framework to automatically obtain a large volume of ocean domain\ninstruction data, which generates instructions based on multi-agent\ncollaboration. Additionally, we construct the first oceanography benchmark,\nOceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though\ncomprehensive experiments, OceanGPT not only shows a higher level of knowledge\nexpertise for oceans science tasks but also gains preliminary embodied\nintelligence capabilities in ocean technology. Codes, data and checkpoints will\nsoon be available at https://github.com/zjunlp/KnowLM.",
          "link": "http://arxiv.org/abs/2310.02031",
          "publishedOn": "2023-10-21T00:41:42.238Z",
          "wordCount": null,
          "title": "OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12595",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wharrie_S/0/1/0/all/0/1\">Sophie Wharrie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "The key challenge underlying machine learning is generalisation to new data.\nThis work studies generalisation for datasets consisting of related tasks that\nmay differ in causal mechanisms. For example, observational medical data for\ncomplex diseases suffers from heterogeneity in causal mechanisms of disease\nacross patients, creating challenges for machine learning algorithms that need\nto generalise to new patients outside of the training dataset. Common\napproaches for learning supervised models with heterogeneous datasets include\nlearning a global model for the entire dataset, learning local models for each\ntasks' data, or utilising hierarchical, meta-learning and multi-task learning\napproaches to learn how to generalise from data pooled across multiple tasks.\nIn this paper we propose causal similarity-based hierarchical Bayesian models\nto improve generalisation to new tasks by learning how to pool data from\ntraining tasks with similar causal mechanisms. We apply this general modelling\nprinciple to Bayesian neural networks and compare a variety of methods for\nestimating causal task similarity (for both known and unknown causal models).\nWe demonstrate the benefits of our approach and applicability to real world\nproblems through a range of experiments on simulated and real data.",
          "link": "http://arxiv.org/abs/2310.12595",
          "publishedOn": "2023-10-21T00:41:42.183Z",
          "wordCount": null,
          "title": "Causal Similarity-Based Hierarchical Bayesian Models. (arXiv:2310.12595v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yichuan Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shenghao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chiwun Yang</a>",
          "description": "In the realm of deep learning, transformers have emerged as a dominant\narchitecture, particularly in natural language processing tasks. However, with\ntheir widespread adoption, concerns regarding the security and privacy of the\ndata processed by these models have arisen. In this paper, we address a pivotal\nquestion: Can the data fed into transformers be recovered using their attention\nweights and outputs? We introduce a theoretical framework to tackle this\nproblem. Specifically, we present an algorithm that aims to recover the input\ndata $X \\in \\mathbb{R}^{d \\times n}$ from given attention weights $W = QK^\\top\n\\in \\mathbb{R}^{d \\times d}$ and output $B \\in \\mathbb{R}^{n \\times n}$ by\nminimizing the loss function $L(X)$. This loss function captures the\ndiscrepancy between the expected output and the actual output of the\ntransformer. Our findings have significant implications for the Localized\nLayer-wise Mechanism (LLM), suggesting potential vulnerabilities in the model's\ndesign from a security and privacy perspective. This work underscores the\nimportance of understanding and safeguarding the internal workings of\ntransformers to ensure the confidentiality of processed data.",
          "link": "http://arxiv.org/abs/2310.12462",
          "publishedOn": "2023-10-21T00:41:42.085Z",
          "wordCount": null,
          "title": "Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights. (arXiv:2310.12462v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12781",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xiong_X/0/1/0/all/0/1\">Xiaofei Xiong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ju_N/0/1/0/all/0/1\">Nianqiao P. Ju</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Sanguo Zhang</a>",
          "description": "Many modern statistical analysis and machine learning applications require\ntraining models on sensitive user data. Differential privacy provides a formal\nguarantee that individual-level information about users does not leak. In this\nframework, randomized algorithms inject calibrated noise into the confidential\ndata, resulting in privacy-protected datasets or queries. However, restricting\naccess to only the privatized data during statistical analysis makes it\ncomputationally challenging to perform valid inferences on parameters\nunderlying the confidential data. In this work, we propose simulation-based\ninference methods from privacy-protected datasets. Specifically, we use neural\nconditional density estimators as a flexible family of distributions to\napproximate the posterior distribution of model parameters given the observed\nprivate query results. We illustrate our methods on discrete time-series data\nunder an infectious disease model and on ordinary linear regression models.\nIllustrating the privacy-utility trade-off, our experiments and analysis\ndemonstrate the necessity and feasibility of designing valid statistical\ninference procedures to correct for biases introduced by the privacy-protection\nmechanisms.",
          "link": "http://arxiv.org/abs/2310.12781",
          "publishedOn": "2023-10-21T00:41:41.920Z",
          "wordCount": null,
          "title": "Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weize Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaoyue Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Ruobing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Parameter-shared pre-trained language models (PLMs) have emerged as a\nsuccessful approach in resource-constrained environments, enabling substantial\nreductions in model storage and memory costs without significant performance\ncompromise. However, it is important to note that parameter sharing does not\nalleviate computational burdens associated with inference, thus impeding its\npracticality in situations characterized by limited stringent latency\nrequirements or computational resources. Building upon neural ordinary\ndifferential equations (ODEs), we introduce a straightforward technique to\nenhance the inference efficiency of parameter-shared PLMs. Additionally, we\npropose a simple pre-training technique that leads to fully or partially shared\nmodels capable of achieving even greater inference acceleration. The\nexperimental results demonstrate the effectiveness of our methods on both\nautoregressive and autoencoding PLMs, providing novel insights into more\nefficient utilization of parameter-shared models in resource-constrained\nsettings.",
          "link": "http://arxiv.org/abs/2310.12818",
          "publishedOn": "2023-10-21T00:41:41.918Z",
          "wordCount": null,
          "title": "Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models. (arXiv:2310.12818v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Ruizhe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Huimin Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jianhong Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1\">Tianxiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jin Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Joey Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zuozhu Liu</a>",
          "description": "Recent discoveries have revealed that deep neural networks might behave in a\nbiased manner in many real-world scenarios. For instance, deep networks trained\non a large-scale face recognition dataset CelebA tend to predict blonde hair\nfor females and black hair for males. Such biases not only jeopardize the\nrobustness of models but also perpetuate and amplify social biases, which is\nespecially concerning for automated decision-making processes in healthcare,\nrecruitment, etc., as they could exacerbate unfair economic and social\ninequalities among different groups. Existing debiasing methods suffer from\nhigh costs in bias labeling or model re-training, while also exhibiting a\ndeficiency in terms of elucidating the origins of biases within the model. To\nthis respect, we propose a fast model debiasing framework (FMD) which offers an\nefficient approach to identify, evaluate and remove biases inherent in trained\nmodels. The FMD identifies biased attributes through an explicit counterfactual\nconcept and quantifies the influence of data samples with influence functions.\nMoreover, we design a machine unlearning-based strategy to efficiently and\neffectively remove the bias in a trained model with a small counterfactual\ndataset. Experiments on the Colored MNIST, CelebA, and Adult Income datasets\nalong with experiments with large language models demonstrate that our method\nachieves superior or competing accuracies compared with state-of-the-art\nmethods while attaining significantly fewer biases and requiring much less\ndebiasing cost. Notably, our method requires only a small external dataset and\nupdating a minimal amount of model parameters, without the requirement of\naccess to training data that may be too large or unavailable in practice.",
          "link": "http://arxiv.org/abs/2310.12560",
          "publishedOn": "2023-10-21T00:41:41.739Z",
          "wordCount": null,
          "title": "Fast Model Debias with Machine Unlearning. (arXiv:2310.12560v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mitsuboshi_R/0/1/0/all/0/1\">Ryotaro Mitsuboshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hatano_K/0/1/0/all/0/1\">Kohei Hatano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takimoto_E/0/1/0/all/0/1\">Eiji Takimoto</a>",
          "description": "Metarounding is an approach to convert an approximation algorithm for linear\noptimization over some combinatorial classes to an online linear optimization\nalgorithm for the same class. We propose a new metarounding algorithm under a\nnatural assumption that a relax-based approximation algorithm exists for the\ncombinatorial class. Our algorithm is much more efficient in both theoretical\nand practical aspects.",
          "link": "http://arxiv.org/abs/2310.12629",
          "publishedOn": "2023-10-21T00:41:41.733Z",
          "wordCount": null,
          "title": "An Improved Metarounding Algorithm via Frank-Wolfe. (arXiv:2310.12629v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thaminkaew_T/0/1/0/all/0/1\">Thanakorn Thaminkaew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lertvittayakumjorn_P/0/1/0/all/0/1\">Piyawat Lertvittayakumjorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vateekul_P/0/1/0/all/0/1\">Peerapon Vateekul</a>",
          "description": "Prompt-based learning has shown its effectiveness in few-shot text\nclassification. One important factor in its success is a verbalizer, which\ntranslates output from a language model into a predicted class. Notably, the\nsimplest and widely acknowledged verbalizer employs manual labels to represent\nthe classes. However, manual selection does not guarantee the optimality of the\nselected words when conditioned on the chosen language model. Therefore, we\npropose Label-Aware Automatic Verbalizer (LAAV), effectively augmenting the\nmanual labels to achieve better few-shot classification results. Specifically,\nwe use the manual labels along with the conjunction \"and\" to induce the model\nto generate more effective words for the verbalizer. The experimental results\non five datasets across five languages demonstrate that LAAV significantly\noutperforms existing verbalizers. Furthermore, our analysis reveals that LAAV\nsuggests more relevant words compared to similar approaches, especially in\nmid-to-low resource languages.",
          "link": "http://arxiv.org/abs/2310.12778",
          "publishedOn": "2023-10-21T00:41:41.717Z",
          "wordCount": null,
          "title": "Label-Aware Automatic Verbalizer for Few-Shot Text Classification. (arXiv:2310.12778v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huayu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carreon_Rascon_A/0/1/0/all/0/1\">Ana S. Carreon-Rascon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiwen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1\">Geng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ao Li</a>",
          "description": "Medical time series data are indispensable in healthcare, providing critical\ninsights for disease diagnosis, treatment planning, and patient management. The\nexponential growth in data complexity, driven by advanced sensor technologies,\nhas presented challenges related to data labeling. Self-supervised learning\n(SSL) has emerged as a transformative approach to address these challenges,\neliminating the need for extensive human annotation. In this study, we\nintroduce a novel framework for Medical Time Series Representation Learning,\nknown as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and\nMasked Autoencoder (MAE) methods, offering a unique approach to representation\nlearning for medical time series data. By combining these techniques, MTS-LOF\nenhances the potential of healthcare applications by providing more\nsophisticated, context-rich representations. Additionally, MTS-LOF employs a\nmulti-masking strategy to facilitate occlusion-invariant feature learning. This\napproach allows the model to create multiple views of the data by masking\nportions of it. By minimizing the discrepancy between the representations of\nthese masked patches and the fully visible patches, MTS-LOF learns to capture\nrich contextual information within medical time series datasets. The results of\nexperiments conducted on diverse medical time series datasets demonstrate the\nsuperiority of MTS-LOF over other methods. These findings hold promise for\nsignificantly enhancing healthcare applications by improving representation\nlearning. Furthermore, our work delves into the integration of joint-embedding\nSSL and MAE techniques, shedding light on the intricate interplay between\ntemporal and structural dependencies in healthcare data. This understanding is\ncrucial, as it allows us to grasp the complexities of healthcare data analysis.",
          "link": "http://arxiv.org/abs/2310.12451",
          "publishedOn": "2023-10-21T00:41:41.697Z",
          "wordCount": null,
          "title": "MTS-LOF: Medical Time-Series Representation Learning via Occlusion-Invariant Features. (arXiv:2310.12451v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Zipeng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1\">Zhongkai Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bokai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhijie Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>",
          "description": "Neural operators, as an efficient surrogate model for learning the solutions\nof PDEs, have received extensive attention in the field of scientific machine\nlearning. Among them, attention-based neural operators have become one of the\nmainstreams in related research. However, existing approaches overfit the\nlimited training data due to the considerable number of parameters in the\nattention mechanism. To address this, we develop an orthogonal attention based\non the eigendecomposition of the kernel integral operator and the neural\napproximation of eigenfunctions. The orthogonalization naturally poses a proper\nregularization effect on the resulting neural operator, which aids in resisting\noverfitting and boosting generalization. Experiments on six standard neural\noperator benchmark datasets comprising both regular and irregular geometries\nshow that our method can outperform competing baselines with decent margins.",
          "link": "http://arxiv.org/abs/2310.12487",
          "publishedOn": "2023-10-21T00:41:41.694Z",
          "wordCount": null,
          "title": "Improved Operator Learning by Orthogonal Attention. (arXiv:2310.12487v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1\">Boyi Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>",
          "description": "Large language models (LLMs) are susceptible to red teaming attacks, which\ncan induce LLMs to generate harmful content. Previous research constructs\nattack prompts via manual or automatic methods, which have their own\nlimitations on construction cost and quality. To address these issues, we\npropose an integrated approach that combines manual and automatic methods to\neconomically generate high-quality attack prompts. Specifically, considering\nthe impressive capabilities of newly emerged LLMs, we propose an attack\nframework to instruct LLMs to mimic human-generated prompts through in-context\nlearning. Furthermore, we propose a defense framework that fine-tunes victim\nLLMs through iterative interactions with the attack framework to enhance their\nsafety against red teaming attacks. Extensive experiments on different LLMs\nvalidate the effectiveness of our proposed attack and defense frameworks.\nAdditionally, we release a series of attack prompts datasets named SAP with\nvarying sizes, facilitating the safety evaluation and enhancement of more LLMs.\nOur code and dataset is available on https://github.com/Aatrox103/SAP .",
          "link": "http://arxiv.org/abs/2310.12505",
          "publishedOn": "2023-10-21T00:41:41.580Z",
          "wordCount": null,
          "title": "Attack Prompt Generation for Red Teaming and Defending Large Language Models. (arXiv:2310.12505v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08724",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Goan_E/0/1/0/all/0/1\">Ethan Goan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Perrin_D/0/1/0/all/0/1\">Dimitri Perrin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mengersen_K/0/1/0/all/0/1\">Kerrie Mengersen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fookes_C/0/1/0/all/0/1\">Clinton Fookes</a>",
          "description": "Inference on modern Bayesian Neural Networks (BNNs) often relies on a\nvariational inference treatment, imposing violated assumptions of independence\nand the form of the posterior. Traditional MCMC approaches avoid these\nassumptions at the cost of increased computation due to its incompatibility to\nsubsampling of the likelihood. New Piecewise Deterministic Markov Process\n(PDMP) samplers permit subsampling, though introduce a model specific\ninhomogenous Poisson Process (IPPs) which is difficult to sample from. This\nwork introduces a new generic and adaptive thinning scheme for sampling from\nthese IPPs, and demonstrates how this approach can accelerate the application\nof PDMPs for inference in BNNs. Experimentation illustrates how inference with\nthese methods is computationally feasible, can improve predictive accuracy,\nMCMC mixing performance, and provide informative uncertainty measurements when\ncompared against other approximate inference schemes.",
          "link": "http://arxiv.org/abs/2302.08724",
          "publishedOn": "2023-10-21T00:41:41.548Z",
          "wordCount": null,
          "title": "Piecewise Deterministic Markov Processes for Bayesian Neural Networks. (arXiv:2302.08724v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.06949",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saligkaras_D/0/1/0/all/0/1\">Dimitrios Saligkaras</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papageorgiou_V/0/1/0/all/0/1\">Vasileios E. Papageorgiou</a>",
          "description": "Clustering is an unsupervised machine learning methodology where unlabeled\nelements/objects are grouped together aiming to the construction of\nwell-established clusters that their elements are classified according to their\nsimilarity. The goal of this process is to provide a useful aid to the\nresearcher that will help her/him to identify patterns among the data. Dealing\nwith large databases, such patterns may not be easily detectable without the\ncontribution of a clustering algorithm. This article provides a deep\ndescription of the most widely used clustering methodologies accompanied by\nuseful presentations concerning suitable parameter selection and\ninitializations. Simultaneously, this article not only represents a review\nhighlighting the major elements of examined clustering techniques but\nemphasizes the comparison of these algorithms' clustering efficiency based on 3\ndatasets, revealing their existing weaknesses and capabilities through accuracy\nand complexity, during the confrontation of discrete and continuous\nobservations. The produced results help us extract valuable conclusions about\nthe appropriateness of the examined clustering techniques in accordance with\nthe dataset's size.",
          "link": "http://arxiv.org/abs/2207.06949",
          "publishedOn": "2023-10-21T00:41:41.410Z",
          "wordCount": null,
          "title": "Seeking the Truth Beyond the Data. An Unsupervised Machine Learning Approach. (arXiv:2207.06949v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12793",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitawarin_C/0/1/0/all/0/1\">Chawin Sitawarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spratling_M/0/1/0/all/0/1\">Michael Spratling</a>",
          "description": "Existing works have made great progress in improving adversarial robustness,\nbut typically test their method only on data from the same distribution as the\ntraining data, i.e. in-distribution (ID) testing. As a result, it is unclear\nhow such robustness generalizes under input distribution shifts, i.e.\nout-of-distribution (OOD) testing. This is a concerning omission as such\ndistribution shifts are unavoidable when methods are deployed in the wild. To\naddress this issue we propose a benchmark named OODRobustBench to\ncomprehensively assess OOD adversarial robustness using 23 dataset-wise shifts\n(i.e. naturalistic shifts in input distribution) and 6 threat-wise shifts\n(i.e., unforeseen adversarial threat models). OODRobustBench is used to assess\n706 robust models using 60.7K adversarial evaluations. This large-scale\nanalysis shows that: 1) adversarial robustness suffers from a severe OOD\ngeneralization issue; 2) ID robustness correlates strongly with OOD robustness,\nin a positive linear way, under many distribution shifts. The latter enables\nthe prediction of OOD robustness from ID robustness. Based on this, we are able\nto predict the upper limit of OOD robustness for existing robust training\nschemes. The results suggest that achieving OOD robustness requires designing\nnovel methods beyond the conventional ones. Last, we discover that extra data,\ndata augmentation, advanced model architectures and particular regularization\napproaches can improve OOD robustness. Noticeably, the discovered training\nschemes, compared to the baseline, exhibit dramatically higher robustness under\nthreat shift while keeping high ID robustness, demonstrating new promising\nsolutions for robustness against both multi-attack and unforeseen attacks.",
          "link": "http://arxiv.org/abs/2310.12793",
          "publishedOn": "2023-10-21T00:41:41.222Z",
          "wordCount": null,
          "title": "OODRobustBench: benchmarking and analyzing adversarial robustness under distribution shift. (arXiv:2310.12793v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wanli Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zehai Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ragni_A/0/1/0/all/0/1\">Anton Ragni</a>",
          "description": "Recently there has been a lot of interest in non-autoregressive (non-AR)\nmodels for speech synthesis, such as FastSpeech 2 and diffusion models. Unlike\nAR models, these models do not have autoregressive dependencies among outputs\nwhich makes inference efficient. This paper expands the range of available\nnon-AR models with another member called energy-based models (EBMs). The paper\ndescribes how noise contrastive estimation, which relies on the comparison\nbetween positive and negative samples, can be used to train EBMs. It proposes a\nnumber of strategies for generating effective negative samples, including using\nhigh-performing AR models. It also describes how sampling from EBMs can be\nperformed using Langevin Markov Chain Monte-Carlo (MCMC). The use of Langevin\nMCMC enables to draw connections between EBMs and currently popular diffusion\nmodels. Experiments on LJSpeech dataset show that the proposed approach offers\nimprovements over Tacotron 2.",
          "link": "http://arxiv.org/abs/2310.12765",
          "publishedOn": "2023-10-21T00:41:41.049Z",
          "wordCount": null,
          "title": "Energy-Based Models For Speech Synthesis. (arXiv:2310.12765v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12528",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Huppenkothen_D/0/1/0/all/0/1\">D. Huppenkothen</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ntampaka_M/0/1/0/all/0/1\">M. Ntampaka</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ho_M/0/1/0/all/0/1\">M. Ho</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Fouesneau_M/0/1/0/all/0/1\">M. Fouesneau</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Nord_B/0/1/0/all/0/1\">B. Nord</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Peek_J/0/1/0/all/0/1\">J. E. G. Peek</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Walmsley_M/0/1/0/all/0/1\">M. Walmsley</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wu_J/0/1/0/all/0/1\">J. F. Wu</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Avestruz_C/0/1/0/all/0/1\">C. Avestruz</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Buck_T/0/1/0/all/0/1\">T. Buck</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Brescia_M/0/1/0/all/0/1\">M. Brescia</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Finkbeiner_D/0/1/0/all/0/1\">D. P. Finkbeiner</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Goulding_A/0/1/0/all/0/1\">A. D. Goulding</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kacprzak_T/0/1/0/all/0/1\">T. Kacprzak</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Melchior_P/0/1/0/all/0/1\">P. Melchior</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Pasquato_M/0/1/0/all/0/1\">M. Pasquato</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ramachandra_N/0/1/0/all/0/1\">N. Ramachandra</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ting_Y/0/1/0/all/0/1\">Y.-S. Ting</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ven_G/0/1/0/all/0/1\">G. van de Ven</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Villar_S/0/1/0/all/0/1\">S. Villar</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Villar_V/0/1/0/all/0/1\">V.A. Villar</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Zinger_E/0/1/0/all/0/1\">E. Zinger</a>",
          "description": "Machine learning has rapidly become a tool of choice for the astronomical\ncommunity. It is being applied across a wide range of wavelengths and problems,\nfrom the classification of transients to neural network emulators of\ncosmological simulations, and is shifting paradigms about how we generate and\nreport scientific results. At the same time, this class of method comes with\nits own set of best practices, challenges, and drawbacks, which, at present,\nare often reported on incompletely in the astrophysical literature. With this\npaper, we aim to provide a primer to the astronomical community, including\nauthors, reviewers, and editors, on how to implement machine learning models\nand report their results in a way that ensures the accuracy of the results,\nreproducibility of the findings, and usefulness of the method.",
          "link": "http://arxiv.org/abs/2310.12528",
          "publishedOn": "2023-10-21T00:41:40.859Z",
          "wordCount": null,
          "title": "Constructing Impactful Machine Learning Research for Astronomy: Best Practices for Researchers and Reviewers. (arXiv:2310.12528v1 [astro-ph.IM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petrick_F/0/1/0/all/0/1\">Frithjof Petrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herold_C/0/1/0/all/0/1\">Christian Herold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrushkov_P/0/1/0/all/0/1\">Pavel Petrushkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_S/0/1/0/all/0/1\">Shahram Khadivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Despite the known limitations, most machine translation systems today still\noperate on the sentence-level. One reason for this is, that most parallel\ntraining data is only sentence-level aligned, without document-level meta\ninformation available. In this work, we set out to build context-aware\ntranslation systems utilizing document-level monolingual data instead. This can\nbe achieved by combining any existing sentence-level translation model with a\ndocument-level language model. We improve existing approaches by leveraging\nrecent advancements in model combination. Additionally, we propose novel\nweighting techniques that make the system combination more flexible and\nsignificantly reduce computational overhead. In a comprehensive evaluation on\nfour diverse translation tasks, we show that our extensions improve\ndocument-targeted scores substantially and are also computationally more\nefficient. However, we also find that in most scenarios, back-translation gives\neven better results, at the cost of having to re-train the translation system.\nFinally, we explore language model fusion in the light of recent advancements\nin large language models. Our findings suggest that there might be strong\npotential in utilizing large language models via model combination.",
          "link": "http://arxiv.org/abs/2310.12303",
          "publishedOn": "2023-10-21T00:41:40.338Z",
          "wordCount": 696,
          "title": "Document-Level Language Models for Machine Translation. (arXiv:2310.12303v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yazdanpanah_I/0/1/0/all/0/1\">Iman Yazdanpanah</a>",
          "description": "SCGAN adds a similarity constraint between generated images and conditions as\na regularization term on generative adversarial networks. Similarity constraint\nworks as a tutor to instruct the generator network to comprehend the difference\nof representations based on conditions. We understand how SCGAN works on a\ndeeper level. This understanding makes us realize that the similarity\nconstraint functions like the contrastive loss function. We believe that a\nmodel with high understanding and intelligence measures the similarity between\nimages based on their structure and high level features, just like humans do.\nTwo major changes we applied to SCGAN in order to make a modified model are\nusing SSIM to measure similarity between images and applying contrastive loss\nprinciples to the similarity constraint. The modified model performs better\nusing FID and FactorVAE metrics. The modified model also has better\ngeneralisability compared to other models. Keywords Generative Adversarial\nNets, Unsupervised Learning, Disentangled Representation Learning, Contrastive\nDisentanglement, SSIM",
          "link": "http://arxiv.org/abs/2310.12262",
          "publishedOn": "2023-10-21T00:41:40.331Z",
          "wordCount": 661,
          "title": "Improving SCGAN's Similarity Constraint and Learning a Better Disentangled Representation. (arXiv:2310.12262v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12500",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Shen_Y/0/1/0/all/0/1\">Yanhui Shen</a>",
          "description": "Options, serving as a crucial financial instrument, are used by investors to\nmanage and mitigate their investment risks within the securities market.\nPrecisely predicting the present price of an option enables investors to make\ninformed and efficient decisions. In this paper, we propose a machine learning\nmethod for forecasting the prices of SPY (ETF) option based on gated recurrent\nunit (GRU) and self-attention mechanism. We first partitioned the raw dataset\ninto 15 subsets according to moneyness and days to maturity criteria. For each\nsubset, we matched the corresponding U.S. government bond rates and Implied\nVolatility Indices. This segmentation allows for a more insightful exploration\nof the impacts of risk-free rates and underlying volatility on option pricing.\nNext, we built four different machine learning models, including multilayer\nperceptron (MLP), long short-term memory (LSTM), self-attention LSTM, and\nself-attention GRU in comparison to the traditional binomial model. The\nempirical result shows that self-attention GRU with historical data outperforms\nother models due to its ability to capture complex temporal dependencies and\nleverage the contextual information embedded in the historical data. Finally,\nin order to unveil the \"black box\" of artificial intelligence, we employed the\nSHapley Additive exPlanations (SHAP) method to interpret and analyze the\nprediction results of the self-attention GRU model with historical data. This\nprovides insights into the significance and contributions of different input\nfeatures on the pricing of American-style options.",
          "link": "http://arxiv.org/abs/2310.12500",
          "publishedOn": "2023-10-21T00:41:40.322Z",
          "wordCount": 729,
          "title": "American Option Pricing using Self-Attention GRU and Shapley Value Interpretation. (arXiv:2310.12500v1 [q-fin.PR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12324",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Musabirov_I/0/1/0/all/0/1\">Ilya Musabirov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zavaleta_Bernuy_A/0/1/0/all/0/1\">Angela Zavaleta-Bernuy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liut_M/0/1/0/all/0/1\">Michael Liut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1\">Joseph Jay Williams</a>",
          "description": "Randomized experimental comparisons of alternative pedagogical strategies\ncould provide useful empirical evidence in instructors' decision-making.\nHowever, traditional experiments do not have a clear and simple pathway to\nusing data rapidly to try to increase the chances that students in an\nexperiment get the best conditions. Drawing inspiration from the use of machine\nlearning and experimentation in product development at leading technology\ncompanies, we explore how adaptive experimentation might help in continuous\ncourse improvement. In adaptive experiments, as different arms/conditions are\ndeployed to students, data is analyzed and used to change the experience for\nfuture students. This can be done using machine learning algorithms to identify\nwhich actions are more promising for improving student experience or outcomes.\nThis algorithm can then dynamically deploy the most effective conditions to\nfuture students, resulting in better support for students' needs. We illustrate\nthe approach with a case study providing a side-by-side comparison of\ntraditional and adaptive experimentation of self-explanation prompts in online\nhomework problems in a CS1 course. This provides a first step in exploring the\nfuture of how this methodology can be useful in bridging research and practice\nin doing continuous improvement.",
          "link": "http://arxiv.org/abs/2310.12324",
          "publishedOn": "2023-10-21T00:41:40.291Z",
          "wordCount": 721,
          "title": "Opportunities for Adaptive Experiments to Enable Continuous Improvement that Trades-off Instructor and Researcher Incentives. (arXiv:2310.12324v1 [cs.HC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sone_S/0/1/0/all/0/1\">Shusaku Sone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jiaxin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_A/0/1/0/all/0/1\">Atsushi Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiba_N/0/1/0/all/0/1\">Naoya Chiba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ushiku_Y/0/1/0/all/0/1\">Yoshitaka Ushiku</a>",
          "description": "Matching, a task to optimally assign limited resources under constraints, is\na fundamental technology for society. The task potentially has various\nobjectives, conditions, and constraints; however, the efficient neural network\narchitecture for matching is underexplored. This paper proposes a novel graph\nneural network (GNN), \\textit{WeaveNet}, designed for bipartite graphs. Since a\nbipartite graph is generally dense, general GNN architectures lose node-wise\ninformation by over-smoothing when deeply stacked. Such a phenomenon is\nundesirable for solving matching problems. WeaveNet avoids it by preserving\nedge-wise information while passing messages densely to reach a better\nsolution. To evaluate the model, we approximated one of the \\textit{strongly\nNP-hard} problems, \\textit{fair stable matching}. Despite its inherent\ndifficulties and the network's general purpose design, our model reached a\ncomparative performance with state-of-the-art algorithms specially designed for\nstable matching for small numbers of agents.",
          "link": "http://arxiv.org/abs/2310.12515",
          "publishedOn": "2023-10-21T00:41:40.283Z",
          "wordCount": 633,
          "title": "WeaveNet for Approximating Two-sided Matching Problems. (arXiv:2310.12515v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Said_A/0/1/0/all/0/1\">Anwar Said</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shabbir_M/0/1/0/all/0/1\">Mudassir Shabbir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Derr_T/0/1/0/all/0/1\">Tyler Derr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbas_W/0/1/0/all/0/1\">Waseem Abbas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koutsoukos_X/0/1/0/all/0/1\">Xenofon Koutsoukos</a>",
          "description": "Graph Neural Networks (GNNs) have shown remarkable merit in performing\nvarious learning-based tasks in complex networks. The superior performance of\nGNNs often correlates with the availability and quality of node-level features\nin the input networks. However, for many network applications, such node-level\ninformation may be missing or unreliable, thereby limiting the applicability\nand efficacy of GNNs. To address this limitation, we present a novel approach\ndenoted as Ego-centric Spectral subGraph Embedding Augmentation (ESGEA), which\naims to enhance and design node features, particularly in scenarios where\ninformation is lacking. Our method leverages the topological structure of the\nlocal subgraph to create topology-aware node features. The subgraph features\nare generated using an efficient spectral graph embedding technique, and they\nserve as node features that capture the local topological organization of the\nnetwork. The explicit node features, if present, are then enhanced with the\nsubgraph embeddings in order to improve the overall performance. ESGEA is\ncompatible with any GNN-based architecture and is effective even in the absence\nof node features. We evaluate the proposed method in a social network graph\nclassification task where node attributes are unavailable, as well as in a node\nclassification task where node features are corrupted or even absent. The\nevaluation results on seven datasets and eight baseline models indicate up to a\n10% improvement in AUC and a 7% improvement in accuracy for graph and node\nclassification tasks, respectively.",
          "link": "http://arxiv.org/abs/2310.12169",
          "publishedOn": "2023-10-21T00:41:40.271Z",
          "wordCount": 755,
          "title": "Enhanced Graph Neural Networks with Ego-Centric Spectral Subgraph Embeddings Augmentation. (arXiv:2310.12169v1 [cs.SI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_N/0/1/0/all/0/1\">Nan Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiuling Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wendy Hui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_V/0/1/0/all/0/1\">Violet Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Y/0/1/0/all/0/1\">Yue Ning</a>",
          "description": "Graph Neural Networks (GNNs) have been widely used for various types of graph\ndata processing and analytical tasks in different domains. Training GNNs over\ncentralized graph data can be infeasible due to privacy concerns and regulatory\nrestrictions. Thus, federated learning (FL) becomes a trending solution to\naddress this challenge in a distributed learning paradigm. However, as GNNs may\ninherit historical bias from training data and lead to discriminatory\npredictions, the bias of local models can be easily propagated to the global\nmodel in distributed settings. This poses a new challenge in mitigating bias in\nfederated GNNs. To address this challenge, we propose $\\text{F}^2$GNN, a Fair\nFederated Graph Neural Network, that enhances group fairness of federated GNNs.\nAs bias can be sourced from both data and learning algorithms, $\\text{F}^2$GNN\naims to mitigate both types of bias under federated settings. First, we provide\ntheoretical insights on the connection between data bias in a training graph\nand statistical fairness metrics of the trained GNN models. Based on the\ntheoretical analysis, we design $\\text{F}^2$GNN which contains two key\ncomponents: a fairness-aware local model update scheme that enhances group\nfairness of the local models on the client side, and a fairness-weighted global\nmodel update scheme that takes both data bias and fairness metrics of local\nmodels into consideration in the aggregation process. We evaluate\n$\\text{F}^2$GNN empirically versus a number of baseline methods, and\ndemonstrate that $\\text{F}^2$GNN outperforms these baselines in terms of both\nfairness and model accuracy.",
          "link": "http://arxiv.org/abs/2310.12350",
          "publishedOn": "2023-10-21T00:41:40.264Z",
          "wordCount": 752,
          "title": "Equipping Federated Graph Neural Networks with Structure-aware Group Fairness. (arXiv:2310.12350v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vosylius_V/0/1/0/all/0/1\">Vitalis Vosylius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1\">Edward Johns</a>",
          "description": "Consider the following problem: given a few demonstrations of a task across a\nfew different objects, how can a robot learn to perform that same task on new,\npreviously unseen objects? This is challenging because the large variety of\nobjects within a class makes it difficult to infer the task-relevant\nrelationship between the new objects and the objects in the demonstrations. We\naddress this by formulating imitation learning as a conditional alignment\nproblem between graph representations of objects. Consequently, we show that\nthis conditioning allows for in-context learning, where a robot can perform a\ntask on a set of new objects immediately after the demonstrations, without any\nprior knowledge about the object class or any further training. In our\nexperiments, we explore and validate our design choices, and we show that our\nmethod is highly effective for few-shot learning of several real-world,\neveryday tasks, whilst outperforming baselines. Videos are available on our\nproject webpage at https://www.robot-learning.uk/implicit-graph-alignment.",
          "link": "http://arxiv.org/abs/2310.12238",
          "publishedOn": "2023-10-21T00:41:40.246Z",
          "wordCount": 669,
          "title": "Few-Shot In-Context Imitation Learning via Implicit Graph Alignment. (arXiv:2310.12238v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hakim_G/0/1/0/all/0/1\">Gustavo A. Vargas Hakim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osowiechi_D/0/1/0/all/0/1\">David Osowiechi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noori_M/0/1/0/all/0/1\">Mehrdad Noori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheraghalikhani_M/0/1/0/all/0/1\">Milad Cheraghalikhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ismail Ben Ayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desrosiers_C/0/1/0/all/0/1\">Christian Desrosiers</a>",
          "description": "Deep Learning models have shown remarkable performance in a broad range of\nvision tasks. However, they are often vulnerable against domain shifts at\ntest-time. Test-time training (TTT) methods have been developed in an attempt\nto mitigate these vulnerabilities, where a secondary task is solved at training\ntime simultaneously with the main task, to be later used as an self-supervised\nproxy task at test-time. In this work, we propose a novel unsupervised TTT\ntechnique based on the maximization of Mutual Information between multi-scale\nfeature maps and a discrete latent representation, which can be integrated to\nthe standard training as an auxiliary clustering task. Experimental results\ndemonstrate competitive classification performance on different popular\ntest-time adaptation benchmarks.",
          "link": "http://arxiv.org/abs/2310.12345",
          "publishedOn": "2023-10-21T00:41:40.238Z",
          "wordCount": 647,
          "title": "ClusT3: Information Invariant Test-Time Training. (arXiv:2310.12345v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_V/0/1/0/all/0/1\">Victoria Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hui Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bryce Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_J/0/1/0/all/0/1\">Jochen Schmidt</a>",
          "description": "The optimal placement of sensors for environmental monitoring and disaster\nmanagement is a challenging problem due to its NP-hard nature. Traditional\nmethods for sensor placement involve exact, approximation, or heuristic\napproaches, with the latter being the most widely used. However, heuristic\nmethods are limited by expert intuition and experience. Deep learning (DL) has\nemerged as a promising approach for generating heuristic algorithms\nautomatically. In this paper, we introduce a novel sensor placement approach\nfocused on learning improvement heuristics using deep reinforcement learning\n(RL) methods. Our approach leverages an RL formulation for learning improvement\nheuristics, driven by an actor-critic algorithm for training the policy\nnetwork. We compare our method with several state-of-the-art approaches by\nconducting comprehensive experiments, demonstrating the effectiveness and\nsuperiority of our proposed approach in producing high-quality solutions. Our\nwork presents a promising direction for applying advanced DL and RL techniques\nto challenging climate sensor placement problems.",
          "link": "http://arxiv.org/abs/2310.12387",
          "publishedOn": "2023-10-21T00:41:40.173Z",
          "wordCount": 669,
          "title": "Learning to Solve Climate Sensor Placement Problems with a Transformer. (arXiv:2310.12387v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12281",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farokhi_S/0/1/0/all/0/1\">Soheila Farokhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yaramala_A/0/1/0/all/0/1\">Aswani Yaramala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiangtao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Muhammad F. A. Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiaojun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karimi_H/0/1/0/all/0/1\">Hamid Karimi</a>",
          "description": "In recent years, Massive Open Online Courses (MOOCs) have gained significant\ntraction as a rapidly growing phenomenon in online learning. Unlike traditional\nclassrooms, MOOCs offer a unique opportunity to cater to a diverse audience\nfrom different backgrounds and geographical locations. Renowned universities\nand MOOC-specific providers, such as Coursera, offer MOOC courses on various\nsubjects. Automated assessment tasks like grade and early dropout predictions\nare necessary due to the high enrollment and limited direct interaction between\nteachers and learners. However, current automated assessment approaches\noverlook the structural links between different entities involved in the\ndownstream tasks, such as the students and courses. Our hypothesis suggests\nthat these structural relationships, manifested through an interaction graph,\ncontain valuable information that can enhance the performance of the task at\nhand. To validate this, we construct a unique knowledge graph for a large MOOC\ndataset, which will be publicly available to the research community.\nFurthermore, we utilize graph embedding techniques to extract latent structural\ninformation encoded in the interactions between entities in the dataset. These\ntechniques do not require ground truth labels and can be utilized for various\ntasks. Finally, by combining entity-specific features, behavioral features, and\nextracted structural features, we enhance the performance of predictive machine\nlearning models in student assignment grade prediction. Our experiments\ndemonstrate that structural features can significantly improve the predictive\nperformance of downstream assessment tasks. The code and data are available in\n\\url{https://github.com/DSAatUSU/MOOPer_grade_prediction}",
          "link": "http://arxiv.org/abs/2310.12281",
          "publishedOn": "2023-10-21T00:41:40.166Z",
          "wordCount": 768,
          "title": "Enhancing the Performance of Automated Grade Prediction in MOOC using Graph Representation Learning. (arXiv:2310.12281v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12359",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quinones_Grueiro_M/0/1/0/all/0/1\">Marcos Quinones-Grueiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanbing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barbour_W/0/1/0/all/0/1\">William Barbour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biswas_G/0/1/0/all/0/1\">Gautam Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Work_D/0/1/0/all/0/1\">Daniel Work</a>",
          "description": "Variable speed limit (VSL) control is a promising traffic management strategy\nfor enhancing safety and mobility. This work introduces MARVEL, a multi-agent\nreinforcement learning (MARL) framework for implementing large-scale VSL\ncontrol on freeway corridors using only commonly available data. The agents\nlearn through a reward structure that incorporates adaptability to traffic\nconditions, safety, and mobility; enabling coordination among the agents. The\nproposed framework scales to cover corridors with many gantries thanks to a\nparameter sharing among all VSL agents. The agents are trained in a\nmicrosimulation environment based on a short freeway stretch with 8 gantries\nspanning 7 miles and tested with 34 gantries spanning 17 miles of I-24 near\nNashville, TN. MARVEL improves traffic safety by 63.4% compared to the no\ncontrol scenario and enhances traffic mobility by 14.6% compared to a\nstate-of-the-practice algorithm that has been deployed on I-24. An\nexplainability analysis is undertaken to explore the learned policy under\ndifferent traffic conditions and the results provide insights into the\ndecision-making process of agents. Finally, we test the policy learned from the\nsimulation-based experiments on real input data from I-24 to illustrate the\npotential deployment capability of the learned policy.",
          "link": "http://arxiv.org/abs/2310.12359",
          "publishedOn": "2023-10-21T00:41:40.108Z",
          "wordCount": 699,
          "title": "MARVEL: Multi-Agent Reinforcement-Learning for Large-Scale Variable Speed Limits. (arXiv:2310.12359v1 [cs.MA])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yingjie Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianlei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Ao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_T/0/1/0/all/0/1\">Tong Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1\">Chunming Hu</a>",
          "description": "Graph neural networks (GNNs) have gained significant popularity due to the\npowerful capability to extract useful representations from graph data. As the\nneed for efficient GNN computation intensifies, a variety of programming\nabstractions designed for optimizing GNN Aggregation have emerged to facilitate\nacceleration. However, there is no comprehensive evaluation and analysis upon\nexisting abstractions, thus no clear consensus on which approach is better. In\nthis letter, we classify existing programming abstractions for GNN Aggregation\nby the dimension of data organization and propagation method. By constructing\nthese abstractions on a state-of-the-art GNN library, we perform a thorough and\ndetailed characterization study to compare their performance and efficiency,\nand provide several insights on future GNN acceleration based on our analysis.",
          "link": "http://arxiv.org/abs/2310.12184",
          "publishedOn": "2023-10-21T00:41:40.089Z",
          "wordCount": 640,
          "title": "Architectural Implications of GNN Aggregation Programming Abstractions. (arXiv:2310.12184v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Youngkyu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jongho Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chang-Ock Lee</a>",
          "description": "The performance of neural networks has been significantly improved by\nincreasing the number of channels in convolutional layers. However, this\nincrease in performance comes with a higher computational cost, resulting in\nnumerous studies focused on reducing it. One promising approach to address this\nissue is group convolution, which effectively reduces the computational cost by\ngrouping channels. However, to the best of our knowledge, there has been no\ntheoretical analysis on how well the group convolution approximates the\nstandard convolution. In this paper, we mathematically analyze the\napproximation of the group convolution to the standard convolution with respect\nto the number of groups. Furthermore, we propose a novel variant of the group\nconvolution called balanced group convolution, which shows a higher\napproximation with a small additional computational cost. We provide\nexperimental results that validate our theoretical findings and demonstrate the\nsuperior performance of the balanced group convolution over other variants of\ngroup convolution.",
          "link": "http://arxiv.org/abs/2310.12461",
          "publishedOn": "2023-10-21T00:41:39.955Z",
          "wordCount": 679,
          "title": "Balanced Group Convolution: An Improved Group Convolution Based on Approximability Estimates. (arXiv:2310.12461v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yutian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jiaqi Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zuohui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xuan_Q/0/1/0/all/0/1\">Qi Xuan</a>",
          "description": "Recently, the field of machine learning has undergone a transition from\nmodel-centric to data-centric. The advancements in diverse learning tasks have\nbeen propelled by the accumulation of more extensive datasets, subsequently\nfacilitating the training of larger models on these datasets. However, these\ndatasets remain relatively under-explored. To this end, we introduce a\npioneering approach known as RK-core, to empower gaining a deeper understanding\nof the intricate hierarchical structure within datasets. Across several\nbenchmark datasets, we find that samples with low coreness values appear less\nrepresentative of their respective categories, and conversely, those with high\ncoreness values exhibit greater representativeness. Correspondingly, samples\nwith high coreness values make a more substantial contribution to the\nperformance in comparison to those with low coreness values. Building upon\nthis, we further employ RK-core to analyze the hierarchical structure of\nsamples with different coreset selection methods. Remarkably, we find that a\nhigh-quality coreset should exhibit hierarchical diversity instead of solely\nopting for representative samples. The code is available at\nhttps://github.com/yaolu-zjut/Kcore.",
          "link": "http://arxiv.org/abs/2310.12168",
          "publishedOn": "2023-10-21T00:41:39.878Z",
          "wordCount": 696,
          "title": "RK-core: An Established Methodology for Exploring the Hierarchical Structure within Datasets. (arXiv:2310.12168v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12294",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_T/0/1/0/all/0/1\">Thomas Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_T/0/1/0/all/0/1\">Thi Kieu Khanh Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armanfard_N/0/1/0/all/0/1\">Narges Armanfard</a>",
          "description": "Numerous methods for time series anomaly detection (TSAD) methods have\nemerged in recent years. Most existing methods are unsupervised and assume the\navailability of normal training samples only, while few supervised methods have\nshown superior performance by incorporating labeled anomalous samples in the\ntraining phase. However, certain anomaly types are inherently challenging for\nunsupervised methods to differentiate from normal data, while supervised\nmethods are constrained to detecting anomalies resembling those present during\ntraining, failing to generalize to unseen anomaly classes. This paper is the\nfirst attempt in providing a novel approach for the open-set TSAD problem, in\nwhich a small number of labeled anomalies from a limited class of anomalies are\nvisible in the training phase, with the objective of detecting both seen and\nunseen anomaly classes in the test phase. The proposed method, called\nMultivariate Open-Set timeseries Anomaly Detection (MOSAD) consists of three\nprimary modules: a Feature Extractor to extract meaningful time-series\nfeatures; a Multi-head Network consisting of Generative-, Deviation-, and\nContrastive heads for capturing both seen and unseen anomaly classes; and an\nAnomaly Scoring module leveraging the insights of the three heads to detect\nanomalies. Extensive experiments on three real-world datasets consistently show\nthat our approach surpasses existing methods under various experimental\nsettings, thus establishing a new state-of-the-art performance in the TSAD\nfield.",
          "link": "http://arxiv.org/abs/2310.12294",
          "publishedOn": "2023-10-21T00:41:39.811Z",
          "wordCount": 717,
          "title": "Open-Set Multivariate Time-Series Anomaly Detection. (arXiv:2310.12294v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12304",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Park_R/0/1/0/all/0/1\">Ryan Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Theisen_R/0/1/0/all/0/1\">Ryan Theisen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sahni_N/0/1/0/all/0/1\">Navriti Sahni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Patek_M/0/1/0/all/0/1\">Marcel Patek</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cichonska_A/0/1/0/all/0/1\">Anna Cicho&#x144;ska</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rahman_R/0/1/0/all/0/1\">Rayees Rahman</a>",
          "description": "Molecular language modeling is an effective approach to generating novel\nchemical structures. However, these models do not \\emph{a priori} encode\ncertain preferences a chemist may desire. We investigate the use of fine-tuning\nusing Direct Preference Optimization to better align generated molecules with\nchemist preferences. Our findings suggest that this approach is simple,\nefficient, and highly effective.",
          "link": "http://arxiv.org/abs/2310.12304",
          "publishedOn": "2023-10-21T00:41:39.804Z",
          "wordCount": 557,
          "title": "Preference Optimization for Molecular Language Models. (arXiv:2310.12304v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chongyu Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiancheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yihua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Dennis Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1\">Eric Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>",
          "description": "With evolving data regulations, machine unlearning (MU) has become an\nimportant tool for fostering trust and safety in today's AI models. However,\nexisting MU methods focusing on data and/or weight perspectives often grapple\nwith limitations in unlearning accuracy, stability, and cross-domain\napplicability. To address these challenges, we introduce the concept of 'weight\nsaliency' in MU, drawing parallels with input saliency in model explanation.\nThis innovation directs MU's attention toward specific model weights rather\nthan the entire model, improving effectiveness and efficiency. The resultant\nmethod that we call saliency unlearning (SalUn) narrows the performance gap\nwith 'exact' unlearning (model retraining from scratch after removing the\nforgetting dataset). To the best of our knowledge, SalUn is the first\nprincipled MU approach adaptable enough to effectively erase the influence of\nforgetting data, classes, or concepts in both image classification and\ngeneration. For example, SalUn yields a stability advantage in high-variance\nrandom data forgetting, e.g., with a 0.2% gap compared to exact unlearning on\nthe CIFAR-10 dataset. Moreover, in preventing conditional diffusion models from\ngenerating harmful images, SalUn achieves nearly 100% unlearning accuracy,\noutperforming current state-of-the-art baselines like Erased Stable Diffusion\nand Forget-Me-Not.",
          "link": "http://arxiv.org/abs/2310.12508",
          "publishedOn": "2023-10-21T00:41:39.790Z",
          "wordCount": 726,
          "title": "SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation. (arXiv:2310.12508v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klu_E/0/1/0/all/0/1\">Emmanuel Klu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethi_S/0/1/0/all/0/1\">Sameer Sethi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passey_D/0/1/0/all/0/1\">DJ Passey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_D/0/1/0/all/0/1\">Donald Martin Jr</a>",
          "description": "Understanding the long-term impact of algorithmic interventions on society is\nvital to achieving responsible AI. Traditional evaluation strategies often fall\nshort due to the complex, adaptive and dynamic nature of society. While\nreinforcement learning (RL) can be a powerful approach for optimizing decisions\nin dynamic settings, the difficulty of realistic environment design remains a\nbarrier to building robust agents that perform well in practical settings. To\naddress this issue we tap into the field of system dynamics (SD) as a\ncomplementary method that incorporates collaborative simulation model\nspecification practices. We introduce SDGym, a low-code library built on the\nOpenAI Gym framework which enables the generation of custom RL environments\nbased on SD simulation models. Through a feasibility study we validate that\nwell specified, rich RL environments can be generated from preexisting SD\nmodels and a few lines of configuration code. We demonstrate the capabilities\nof the SDGym environment using an SD model of the electric vehicle adoption\nproblem. We compare two SD simulators, PySD and BPTK-Py for parity, and train a\nD4PG agent using the Acme framework to showcase learning and environment\ninteraction. Our preliminary findings underscore the dual potential of SD to\nimprove RL environment design and for RL to improve dynamic policy discovery\nwithin SD models. By open-sourcing SDGym, the intent is to galvanize further\nresearch and promote adoption across the SD and RL communities, thereby\ncatalyzing collaboration in this emerging interdisciplinary space.",
          "link": "http://arxiv.org/abs/2310.12494",
          "publishedOn": "2023-10-21T00:41:39.767Z",
          "wordCount": 745,
          "title": "SDGym: Low-Code Reinforcement Learning Environments using System Dynamics Models. (arXiv:2310.12494v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Siddharth Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sating_Z/0/1/0/all/0/1\">Zachary Sating</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatele_A/0/1/0/all/0/1\">Abhinav Bhatele</a>",
          "description": "Despite their better convergence properties compared to first-order\noptimizers, second-order optimizers for deep learning have been less popular\ndue to their significant computational costs. The primary efficiency bottleneck\nin such optimizers is matrix inverse calculations in the preconditioning step,\nwhich are expensive to compute on GPUs. In this paper, we introduce Jorge, a\nsecond-order optimizer that promises the best of both worlds -- rapid\nconvergence benefits of second-order methods, and high computational efficiency\ntypical of first-order methods. We address the primary computational bottleneck\nof computing matrix inverses by completely eliminating them using an\napproximation of the preconditioner computation. This makes Jorge extremely\nefficient on GPUs in terms of wall-clock time. Further, we describe an approach\nto determine Jorge's hyperparameters directly from a well-tuned SGD baseline,\nthereby significantly minimizing tuning efforts. Our empirical evaluations\ndemonstrate the distinct advantages of using Jorge, outperforming\nstate-of-the-art optimizers such as SGD, AdamW, and Shampoo across multiple\ndeep learning models, both in terms of sample efficiency and wall-clock time.",
          "link": "http://arxiv.org/abs/2310.12298",
          "publishedOn": "2023-10-21T00:41:39.761Z",
          "wordCount": 673,
          "title": "Jorge: Approximate Preconditioning for GPU-efficient Second-order Optimization. (arXiv:2310.12298v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhenghao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Quanyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bolei Zhou</a>",
          "description": "Driving safety is a top priority for autonomous vehicles. Orthogonal to prior\nwork handling accident-prone traffic events by algorithm designs at the policy\nlevel, we investigate a Closed-loop Adversarial Training (CAT) framework for\nsafe end-to-end driving in this paper through the lens of environment\naugmentation. CAT aims to continuously improve the safety of driving agents by\ntraining the agent on safety-critical scenarios that are dynamically generated\nover time. A novel resampling technique is developed to turn log-replay\nreal-world driving scenarios into safety-critical ones via probabilistic\nfactorization, where the adversarial traffic generation is modeled as the\nmultiplication of standard motion prediction sub-problems. Consequently, CAT\ncan launch more efficient physical attacks compared to existing safety-critical\nscenario generation methods and yields a significantly less computational cost\nin the iterative learning pipeline. We incorporate CAT into the MetaDrive\nsimulator and validate our approach on hundreds of driving scenarios imported\nfrom real-world driving datasets. Experimental results demonstrate that CAT can\neffectively generate adversarial scenarios countering the agent being trained.\nAfter training, the agent can achieve superior driving safety in both\nlog-replay and safety-critical traffic scenarios on the held-out test set. Code\nand data are available at https://metadriverse.github.io/cat.",
          "link": "http://arxiv.org/abs/2310.12432",
          "publishedOn": "2023-10-21T00:41:39.752Z",
          "wordCount": 715,
          "title": "CAT: Closed-loop Adversarial Training for Safe End-to-End Driving. (arXiv:2310.12432v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.06763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pei_Q/0/1/0/all/0/1\">Qizhi Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_K/0/1/0/all/0/1\">Kaiyuan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lijun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jinhua Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingce Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shufang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1\">Kun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>",
          "description": "Modeling the interaction between proteins and ligands and accurately\npredicting their binding structures is a critical yet challenging task in drug\ndiscovery. Recent advancements in deep learning have shown promise in\naddressing this challenge, with sampling-based and regression-based methods\nemerging as two prominent approaches. However, these methods have notable\nlimitations. Sampling-based methods often suffer from low efficiency due to the\nneed for generating multiple candidate structures for selection. On the other\nhand, regression-based methods offer fast predictions but may experience\ndecreased accuracy. Additionally, the variation in protein sizes often requires\nexternal modules for selecting suitable binding pockets, further impacting\nefficiency. In this work, we propose $\\mathbf{FABind}$, an end-to-end model\nthat combines pocket prediction and docking to achieve accurate and fast\nprotein-ligand binding. $\\mathbf{FABind}$ incorporates a unique ligand-informed\npocket prediction module, which is also leveraged for docking pose estimation.\nThe model further enhances the docking process by incrementally integrating the\npredicted pocket to optimize protein-ligand binding, reducing discrepancies\nbetween training and inference. Through extensive experiments on benchmark\ndatasets, our proposed $\\mathbf{FABind}$ demonstrates strong advantages in\nterms of effectiveness and efficiency compared to existing methods. Our code is\navailable at $\\href{https://github.com/QizhiPei/FABind}{Github}$.",
          "link": "http://arxiv.org/abs/2310.06763",
          "publishedOn": "2023-10-14T00:41:50.946Z",
          "wordCount": 730,
          "title": "FABind: Fast and Accurate Protein-Ligand Binding. (arXiv:2310.06763v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08150",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Steland_A/0/1/0/all/0/1\">Ansgar Steland</a>",
          "description": "Maximum-type statistics of certain functions of the sample covariance matrix\nof high-dimensional vector time series are studied to statistically confirm or\nreject the null hypothesis that a data set has been collected under normal\nconditions. The approach generalizes the case of the maximal deviation of the\nsample autocovariances function from its assumed values. Within a linear time\nseries framework it is shown that Gumbel-type extreme value asymptotics holds\ntrue. As applications we discuss long-only mimimal-variance portfolio\noptimization and subportfolio analysis with respect to idiosyncratic risks, ETF\nindex tracking by sparse tracking portfolios, convolutional deep learners for\nimage analysis and the analysis of array-of-sensors data.",
          "link": "http://arxiv.org/abs/2310.08150",
          "publishedOn": "2023-10-14T00:41:50.938Z",
          "wordCount": 634,
          "title": "On Extreme Value Asymptotics of Projected Sample Covariances in High Dimensions with Applications in Finance and Convolutional Networks. (arXiv:2310.08150v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miller_Z/0/1/0/all/0/1\">Zohair Shafi. Benjamin A. Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1\">Ayan Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1\">Tina Eliassi-Rad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caceres_R/0/1/0/all/0/1\">Rajmonda S. Caceres</a>",
          "description": "Recent advances in machine learning (ML) have shown promise in aiding and\naccelerating classical combinatorial optimization algorithms. ML-based speed\nups that aim to learn in an end to end manner (i.e., directly output the\nsolution) tend to trade off run time with solution quality. Therefore,\nsolutions that are able to accelerate existing solvers while maintaining their\nperformance guarantees, are of great interest. We consider an APX-hard problem,\nwhere an adversary aims to attack shortest paths in a graph by removing the\nminimum number of edges. We propose the GRASP algorithm: Graph Attention\nAccelerated Shortest Path Attack, an ML aided optimization algorithm that\nachieves run times up to 10x faster, while maintaining the quality of solution\ngenerated. GRASP uses a graph attention network to identify a smaller subgraph\ncontaining the combinatorial solution, thus effectively reducing the input\nproblem size. Additionally, we demonstrate how careful representation of the\ninput graph, including node features that correlate well with the optimization\ntask, can highlight important structure in the optimization solution.",
          "link": "http://arxiv.org/abs/2310.07980",
          "publishedOn": "2023-10-14T00:41:50.934Z",
          "wordCount": 676,
          "title": "GRASP: Accelerating Shortest Path Attacks via Graph Attention. (arXiv:2310.07980v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07793",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1\">Ruotong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xu Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yunpu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>",
          "description": "The rapid advancements in large language models (LLMs) have ignited interest\nin the temporal knowledge graph (tKG) domain, where conventional carefully\ndesigned embedding-based and rule-based models dominate. The question remains\nopen of whether pre-trained LLMs can understand structured temporal relational\ndata and replace them as the foundation model for temporal relational\nforecasting. Therefore, we bring temporal knowledge forecasting into the\ngenerative setting. However, challenges occur in the huge chasms between\ncomplex temporal graph data structure and sequential natural expressions LLMs\ncan handle, and between the enormous data sizes of tKGs and heavy computation\ncosts of finetuning LLMs. To address these challenges, we propose a novel\nretrieval augmented generation framework that performs generative forecasting\non tKGs named GenTKG, which combines a temporal logical rule-based retrieval\nstrategy and lightweight parameter-efficient instruction tuning. Extensive\nexperiments have shown that GenTKG outperforms conventional methods of temporal\nrelational forecasting under low computation resources. GenTKG also highlights\nremarkable transferability with exceeding performance on unseen datasets\nwithout re-training. Our work reveals the huge potential of LLMs in the tKG\ndomain and opens a new frontier for generative forecasting on tKGs.",
          "link": "http://arxiv.org/abs/2310.07793",
          "publishedOn": "2023-10-14T00:41:46.981Z",
          "wordCount": 685,
          "title": "GenTKG: Generative Forecasting on Temporal Knowledge Graph. (arXiv:2310.07793v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1\">Fu Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingfu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenkun Wang</a>",
          "description": "Neural combinatorial optimization (NCO) is a promising learning-based\napproach for solving challenging combinatorial optimization problems without\nspecialized algorithm design by experts. However, most constructive NCO methods\ncannot solve problems with large-scale instance sizes, which significantly\ndiminishes their usefulness for real-world applications. In this work, we\npropose a novel Light Encoder and Heavy Decoder (LEHD) model with a strong\ngeneralization ability to address this critical issue. The LEHD model can learn\nto dynamically capture the relationships between all available nodes of varying\nsizes, which is beneficial for model generalization to problems of various\nscales. Moreover, we develop a data-efficient training scheme and a flexible\nsolution construction mechanism for the proposed LEHD model. By training on\nsmall-scale problem instances, the LEHD model can generate nearly optimal\nsolutions for the Travelling Salesman Problem (TSP) and the Capacitated Vehicle\nRouting Problem (CVRP) with up to 1000 nodes, and also generalizes well to\nsolve real-world TSPLib and CVRPLib problems. These results confirm our\nproposed LEHD model can significantly improve the state-of-the-art performance\nfor constructive NCO. The code is available at\nhttps://github.com/CIAM-Group/NCO_code/tree/main/single_objective/LEHD.",
          "link": "http://arxiv.org/abs/2310.07985",
          "publishedOn": "2023-10-14T00:41:46.976Z",
          "wordCount": 707,
          "title": "Neural Combinatorial Optimization with Heavy Decoder: Toward Large Scale Generalization. (arXiv:2310.07985v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.04234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tengfei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dachuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_P/0/1/0/all/0/1\">Peng Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>",
          "description": "Neural operators as novel neural architectures for fast approximating\nsolution operators of partial differential equations (PDEs), have shown\nconsiderable promise for future scientific computing. However, the mainstream\nof training neural operators is still data-driven, which needs an expensive\nground-truth dataset from various sources (e.g., solving PDEs' samples with the\nconventional solvers, real-world experiments) in addition to training stage\ncosts. From a computational perspective, marrying operator learning and\nspecific domain knowledge to solve PDEs is an essential step in reducing\ndataset costs and label-free learning. We propose a novel paradigm that\nprovides a unified framework of training neural operators and solving PDEs with\nthe variational form, which we refer to as the variational operator learning\n(VOL). Ritz and Galerkin approach with finite element discretization are\ndeveloped for VOL to achieve matrix-free approximation of system functional and\nresidual, then direct minimization and iterative update are proposed as two\noptimization strategies for VOL. Various types of experiments based on\nreasonable benchmarks about variable heat source, Darcy flow, and variable\nstiffness elasticity are conducted to demonstrate the effectiveness of VOL.\nWith a label-free training set and a 5-label-only shift set, VOL learns\nsolution operators with its test errors decreasing in a power law with respect\nto the amount of unlabeled data. To the best of the authors' knowledge, this is\nthe first study that integrates the perspectives of the weak form and efficient\niterative methods for solving sparse linear systems into the end-to-end\noperator learning task.",
          "link": "http://arxiv.org/abs/2304.04234",
          "publishedOn": "2023-10-14T00:41:35.486Z",
          "wordCount": 805,
          "title": "Variational operator learning: A unified paradigm marrying training neural operators and solving partial differential equations. (arXiv:2304.04234v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.12233",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Kim_S/0/1/0/all/0/1\">Seonghwan Kim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Woo_J/0/1/0/all/0/1\">Jeheon Woo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kim_W/0/1/0/all/0/1\">Woo Youn Kim</a>",
          "description": "The exploration of transition state (TS) geometries is crucial for\nelucidating chemical reaction mechanisms and modeling their kinetics. Recently,\nmachine learning (ML) models have shown remarkable performance for prediction\nof TS geometries. However, they require 3D conformations of reactants and\nproducts often with their appropriate orientations as input, which demands\nsubstantial efforts and computational cost. Here, we propose a generative\napproach based on the stochastic diffusion method, namely TSDiff, for\nprediction of TS geometries just from 2D molecular graphs. TSDiff outperformed\nthe existing ML models with 3D geometries in terms of both accuracy and\nefficiency. Moreover, it enables to sample various TS conformations, because it\nlearned the distribution of TS geometries for diverse reactions in training.\nThus, TSDiff was able to find more favorable reaction pathways with lower\nbarrier heights than those in the reference database. These results demonstrate\nthat TSDiff shows promising potential for an efficient and reliable TS\nexploration.",
          "link": "http://arxiv.org/abs/2304.12233",
          "publishedOn": "2023-10-14T00:41:35.462Z",
          "wordCount": 691,
          "title": "Diffusion-based Generative AI for Exploring Transition States from 2D Molecular Graphs. (arXiv:2304.12233v3 [physics.chem-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.00457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Puchert_P/0/1/0/all/0/1\">Patrik Puchert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poonam_P/0/1/0/all/0/1\">Poonam Poonam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onzenoodt_C/0/1/0/all/0/1\">Christian van Onzenoodt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1\">Timo Ropinski</a>",
          "description": "Large Language Models (LLMs) have revolutionized natural language processing\nand demonstrated impressive capabilities in various tasks. Unfortunately, they\nare prone to hallucinations, where the model exposes incorrect or false\ninformation in its responses, which renders diligent evaluation approaches\nmandatory. While LLM performance in specific knowledge fields is often\nevaluated based on question and answer (Q&A) datasets, such evaluations usually\nreport only a single accuracy number for the dataset, which often covers an\nentire field. This field-based evaluation, is problematic with respect to\ntransparency and model improvement. A stratified evaluation could instead\nreveal subfields, where hallucinations are more likely to occur and thus help\nto better assess LLMs' risks and guide their further development. To support\nsuch stratified evaluations, we propose LLMMaps as a novel visualization\ntechnique that enables users to evaluate LLMs' performance with respect to Q&A\ndatasets. LLMMaps provide detailed insights into LLMs' knowledge capabilities\nin different subfields, by transforming Q&A datasets as well as LLM responses\ninto an internal knowledge structure. An extension for comparative\nvisualization furthermore, allows for the detailed comparison of multiple LLMs.\nTo assess LLMMaps we use them to conduct a comparative analysis of several\nstate-of-the-art LLMs, such as BLOOM, GPT-2, GPT-3, ChatGPT and LLaMa-13B, as\nwell as two qualitative user evaluations. All necessary source code and data\nfor generating LLMMaps to be used in scientific publications and elsewhere is\navailable on GitHub: https://github.com/viscom-ulm/LLMMaps",
          "link": "http://arxiv.org/abs/2304.00457",
          "publishedOn": "2023-10-14T00:41:35.454Z",
          "wordCount": 780,
          "title": "LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models. (arXiv:2304.00457v3 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.14219",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sousa_M/0/1/0/all/0/1\">Martim Sousa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tome_A/0/1/0/all/0/1\">Ana Maria Tom&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moreira_J/0/1/0/all/0/1\">Jos&#xe9; Moreira</a>",
          "description": "This paper introduces a novel model-agnostic algorithm called adaptive\nensemble batch multi-input multi-output conformalized quantile regression\n(AEnbMIMOCQR} that enables forecasters to generate multi-step ahead prediction\nintervals for a fixed pre-specified miscoverage rate in a distribution-free\nmanner. Our method is grounded on conformal prediction principles, however, it\ndoes not require data splitting and provides close to exact coverage even when\nthe data is not exchangeable. Moreover, the resulting prediction intervals,\nbesides being empirically valid along the forecast horizon, do not neglect\nheteroscedasticity. AEnbMIMOCQR is designed to be robust to distribution\nshifts, which means that its prediction intervals remain reliable over an\nunlimited period of time, without entailing retraining or imposing unrealistic\nstrict assumptions on the data-generating process. Through methodically\nexperimentation, we demonstrate that our approach outperforms other competitive\nmethods on both real-world and synthetic datasets. The code used in the\nexperimental part and a tutorial on how to use AEnbMIMOCQR can be found at the\nfollowing GitHub repository: https://github.com/Quilograma/AEnbMIMOCQR.",
          "link": "http://arxiv.org/abs/2207.14219",
          "publishedOn": "2023-10-14T00:41:35.155Z",
          "wordCount": 757,
          "title": "A general framework for multi-step ahead adaptive conformal heteroscedastic time series forecasting. (arXiv:2207.14219v9 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14133",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dunion_M/0/1/0/all/0/1\">Mhairi Dunion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McInroe_T/0/1/0/all/0/1\">Trevor McInroe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luck_K/0/1/0/all/0/1\">Kevin Sebastian Luck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanna_J/0/1/0/all/0/1\">Josiah P. Hanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>",
          "description": "Reinforcement Learning (RL) environments can produce training data with\nspurious correlations between features due to the amount of training data or\nits limited feature coverage. This can lead to RL agents encoding these\nmisleading correlations in their latent representation, preventing the agent\nfrom generalising if the correlation changes within the environment or when\ndeployed in the real world. Disentangled representations can improve\nrobustness, but existing disentanglement techniques that minimise mutual\ninformation between features require independent features, thus they cannot\ndisentangle correlated features. We propose an auxiliary task for RL algorithms\nthat learns a disentangled representation of high-dimensional observations with\ncorrelated features by minimising the conditional mutual information between\nfeatures in the representation. We demonstrate experimentally, using continuous\ncontrol tasks, that our approach improves generalisation under correlation\nshifts, as well as improving the training performance of RL algorithms in the\npresence of correlated features.",
          "link": "http://arxiv.org/abs/2305.14133",
          "publishedOn": "2023-10-14T00:41:35.128Z",
          "wordCount": 681,
          "title": "Conditional Mutual Information for Disentangled Representations in Reinforcement Learning. (arXiv:2305.14133v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.00848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1\">Nazmus Sakib Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noor_S/0/1/0/all/0/1\">Saad Sakib Noor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikder_A/0/1/0/all/0/1\">Ashraful Islam Shanto Sikder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1\">Abhijit Paul</a>",
          "description": "This paper focuses on enhancing Bengali Document Layout Analysis (DLA) using\nthe YOLOv8 model and innovative post-processing techniques. We tackle\nchallenges unique to the complex Bengali script by employing data augmentation\nfor model robustness. After meticulous validation set evaluation, we fine-tune\nour approach on the complete dataset, leading to a two-stage prediction\nstrategy for accurate element segmentation. Our ensemble model, combined with\npost-processing, outperforms individual base architectures, addressing issues\nidentified in the BaDLAD dataset. By leveraging this approach, we aim to\nadvance Bengali document analysis, contributing to improved OCR and document\ncomprehension and BaDLAD serves as a foundational resource for this endeavor,\naiding future research in the field. Furthermore, our experiments provided key\ninsights to incorporate new strategies into the established solution.",
          "link": "http://arxiv.org/abs/2309.00848",
          "publishedOn": "2023-10-14T00:41:35.116Z",
          "wordCount": null,
          "title": "Bengali Document Layout Analysis -- A YOLOV8 Based Ensembling Approach. (arXiv:2309.00848v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.06970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathys_J/0/1/0/all/0/1\">Jo&#xeb;l Mathys</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grotschla_F/0/1/0/all/0/1\">Florian Gr&#xf6;tschla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadimpalli_K/0/1/0/all/0/1\">Kalyan Varma Nadimpalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1\">Roger Wattenhofer</a>",
          "description": "Graph Neural Networks are a natural fit for learning algorithms. They can\ndirectly represent tasks through an abstract but versatile graph structure and\nhandle inputs of different sizes. This opens up the possibility for scaling and\nextrapolation to larger graphs, one of the most important advantages of an\nalgorithm. However, this raises two core questions i) How can we enable nodes\nto gather the required information in a given graph ($\\textit{information\nexchange}$), even if is far away and ii) How can we design an execution\nframework which enables this information exchange for extrapolation to larger\ngraph sizes ($\\textit{algorithmic alignment for extrapolation}$). We propose a\nnew execution framework that is inspired by the design principles of\ndistributed algorithms: Flood and Echo Net. It propagates messages through the\nentire graph in a wave like activation pattern, which naturally generalizes to\nlarger instances. Through its sparse but parallel activations it is provably\nmore efficient in terms of message complexity. We study the proposed model and\nprovide both empirical evidence and theoretical insights in terms of its\nexpressiveness, efficiency, information exchange and ability to extrapolate.",
          "link": "http://arxiv.org/abs/2310.06970",
          "publishedOn": "2023-10-14T00:41:35.098Z",
          "wordCount": null,
          "title": "Flood and Echo: Algorithmic Alignment of GNNs with Distributed Computing. (arXiv:2310.06970v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Letafati_M/0/1/0/all/0/1\">Mehdi Letafati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1\">Samad Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latva_aho_M/0/1/0/all/0/1\">Matti Latva-aho</a>",
          "description": "Innovative foundation models, such as GPT-3 and stable diffusion models, have\nmade a paradigm shift in the realm of artificial intelligence (AI) towards\ngenerative AI-based systems. In unison, from data communication and networking\nperspective, AI and machine learning (AI/ML) algorithms are envisioned to be\npervasively incorporated into the future generations of wireless communications\nsystems, highlighting the need for novel AI-native solutions for the emergent\ncommunication scenarios. In this article, we outline the applications of\ngenerative AI in wireless communication systems to lay the foundations for\nresearch in this field. Diffusion-based generative models, as the new\nstate-of-the-art paradigm of generative models, are introduced, and their\napplications in wireless communication systems are discussed. Two case studies\nare also presented to showcase how diffusion models can be exploited for the\ndevelopment of resilient AI-native communication systems. Specifically, we\npropose denoising diffusion probabilistic models (DDPM) for a wireless\ncommunication scheme with non-ideal transceivers, where 30% improvement is\nachieved in terms of bit error rate. As the second application, DDPMs are\nemployed at the transmitter to shape the constellation symbols, highlighting a\nrobust out-of-distribution performance. Finally, future directions and open\nissues for the development of generative AI-based wireless systems are\ndiscussed to promote future research endeavors towards wireless generative AI\n(WiGenAI).",
          "link": "http://arxiv.org/abs/2310.07312",
          "publishedOn": "2023-10-14T00:41:35.097Z",
          "wordCount": null,
          "title": "WiGenAI: The Symphony of Wireless and Generative AI via Diffusion Models. (arXiv:2310.07312v2 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19443",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maldonado_S/0/1/0/all/0/1\">Sebasti&#xe1;n Maldonado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vairetti_C/0/1/0/all/0/1\">Carla Vairetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jara_K/0/1/0/all/0/1\">Katherine Jara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carrasco_M/0/1/0/all/0/1\">Miguel Carrasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_J/0/1/0/all/0/1\">Julio L&#xf3;pez</a>",
          "description": "In this paper, we propose a fuzzy adaptive loss function for enhancing deep\nlearning performance in classification tasks. Specifically, we redefine the\ncross-entropy loss to effectively address class-level noise conditions,\nincluding the challenging problem of class imbalance. Our approach introduces\naggregation operators, leveraging the power of fuzzy logic to improve\nclassification accuracy. The rationale behind our proposed method lies in the\niterative up-weighting of class-level components within the loss function,\nfocusing on those with larger errors. To achieve this, we employ the ordered\nweighted average (OWA) operator and combine it with an adaptive scheme for\ngradient-based learning. Through extensive experimentation, our method\noutperforms other commonly used loss functions, such as the standard\ncross-entropy or focal loss, across various binary and multiclass\nclassification tasks. Furthermore, we explore the influence of hyperparameters\nassociated with the OWA operators and present a default configuration that\nperforms well across different experimental settings.",
          "link": "http://arxiv.org/abs/2305.19443",
          "publishedOn": "2023-10-14T00:41:35.090Z",
          "wordCount": 711,
          "title": "OWAdapt: An adaptive loss function for deep learning using OWA operators. (arXiv:2305.19443v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.00767",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Orlichenko_A/0/1/0/all/0/1\">Anton Orlichenko</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Daly_G/0/1/0/all/0/1\">Grant Daly</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhou_Z/0/1/0/all/0/1\">Ziyu Zhou</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_A/0/1/0/all/0/1\">Anqi Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Shen_H/0/1/0/all/0/1\">Hui Shen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deng_H/0/1/0/all/0/1\">Hong-Wen Deng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Ping Wang</a>",
          "description": "Most packages for the analysis of fMRI-based functional connectivity (FC) and\ngenomic data are used with a programming language interface, lacking an\neasy-to-navigate GUI frontend. This exacerbates two problems found in these\ntypes of data: demographic confounds and quality control in the face of high\ndimensionality of features. The reason is that it is too slow and cumbersome to\nuse a programming interface to create all the necessary visualizations required\nto identify all correlations, confounding effects, or quality control problems\nin a dataset. To remedy this situation, we have developed ImageNomer, a data\nvisualization and analysis tool that allows inspection of both subject-level\nand cohort-level demographic, genomic, and imaging features. The software is\nPython-based, runs in a self-contained Docker image, and contains a\nbrowser-based GUI frontend. We demonstrate the usefulness of ImageNomer by\nidentifying an unexpected race confound when predicting achievement scores in\nthe Philadelphia Neurodevelopmental Cohort (PNC) dataset. In the past, many\nstudies have attempted to use FC to identify achievement-related features in\nfMRI. Using ImageNomer, we find a clear potential for confounding effects of\nrace. Using correlation analysis in the ImageNomer software, we show that FCs\ncorrelated with Wide Range Achievement Test (WRAT) score are in fact more\nhighly correlated with race. Investigating further, we find that whereas both\nFC and SNP (genomic) features can account for 10-15\\% of WRAT score variation,\nthis predictive ability disappears when controlling for race. In this work, we\ndemonstrate the advantage of our ImageNomer GUI tool in data exploration and\nconfound detection. Additionally, this work identifies race as a strong\nconfound in FC data and casts doubt on the possibility of finding unbiased\nachievement-related features in fMRI and SNP data of healthy adolescents.",
          "link": "http://arxiv.org/abs/2302.00767",
          "publishedOn": "2023-10-14T00:41:35.084Z",
          "wordCount": null,
          "title": "ImageNomer: description of a functional connectivity and omics analysis tool and case study identifying a race confound. (arXiv:2302.00767v2 [q-bio.PE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.04610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuaiwen Leon Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruft_B/0/1/0/all/0/1\">Bonnie Kruft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Minjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Conglong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shiyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chengming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_M/0/1/0/all/0/1\">Masahiro Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaoxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasley_J/0/1/0/all/0/1\">Jeff Rasley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awan_A/0/1/0/all/0/1\">Ammar Ahmad Awan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmes_C/0/1/0/all/0/1\">Connor Holmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1\">Martin Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_A/0/1/0/all/0/1\">Adam Ghanem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhongzhu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuxiong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luferenko_P/0/1/0/all/0/1\">Pete Luferenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_D/0/1/0/all/0/1\">Divya Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weyn_J/0/1/0/all/0/1\">Jonathan Weyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruixiong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klocek_S/0/1/0/all/0/1\">Sylwester Klocek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vragov_V/0/1/0/all/0/1\">Volodymyr Vragov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AlQuraishi_M/0/1/0/all/0/1\">Mohammed AlQuraishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahdritz_G/0/1/0/all/0/1\">Gustaf Ahdritz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Floristean_C/0/1/0/all/0/1\">Christina Floristean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negri_C/0/1/0/all/0/1\">Cristina Negri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotamarthi_R/0/1/0/all/0/1\">Rao Kotamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishwanath_V/0/1/0/all/0/1\">Venkatram Vishwanath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanathan_A/0/1/0/all/0/1\">Arvind Ramanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foreman_S/0/1/0/all/0/1\">Sam Foreman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hippe_K/0/1/0/all/0/1\">Kyle Hippe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcomano_T/0/1/0/all/0/1\">Troy Arcomano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maulik_R/0/1/0/all/0/1\">Romit Maulik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zvyagin_M/0/1/0/all/0/1\">Maxim Zvyagin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brace_A/0/1/0/all/0/1\">Alexander Brace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohorquez_C/0/1/0/all/0/1\">Cindy Orozco Bohorquez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clyde_A/0/1/0/all/0/1\">Austin Clyde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kale_B/0/1/0/all/0/1\">Bharat Kale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Rivera_D/0/1/0/all/0/1\">Danilo Perez-Rivera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Heng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mann_C/0/1/0/all/0/1\">Carla M. Mann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irvin_M/0/1/0/all/0/1\">Michael Irvin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauloski_J/0/1/0/all/0/1\">J. Gregory Pauloski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ward_L/0/1/0/all/0/1\">Logan Ward</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayot_V/0/1/0/all/0/1\">Valerie Hayot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emani_M/0/1/0/all/0/1\">Murali Emani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Diangen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukla_M/0/1/0/all/0/1\">Maulik Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1\">Ian Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">James J. Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papka_M/0/1/0/all/0/1\">Michael E. Papka</a>, et al. (40 additional authors not shown)",
          "description": "In the upcoming decade, deep learning may revolutionize the natural sciences,\nenhancing our capacity to model and predict natural occurrences. This could\nherald a new era of scientific exploration, bringing significant advancements\nacross sectors from drug development to renewable energy. To answer this call,\nwe present DeepSpeed4Science initiative (deepspeed4science.ai) which aims to\nbuild unique capabilities through AI system technology innovations to help\ndomain experts to unlock today's biggest science mysteries. By leveraging\nDeepSpeed's current technology pillars (training, inference and compression) as\nbase technology enablers, DeepSpeed4Science will create a new set of AI system\ntechnologies tailored for accelerating scientific discoveries by addressing\ntheir unique complexity beyond the common technical approaches used for\naccelerating generic large language models (LLMs). In this paper, we showcase\nthe early progress we made with DeepSpeed4Science in addressing two of the\ncritical system challenges in structural biology research.",
          "link": "http://arxiv.org/abs/2310.04610",
          "publishedOn": "2023-10-14T00:41:35.083Z",
          "wordCount": null,
          "title": "DeepSpeed4Science Initiative: Enabling Large-Scale Scientific Discovery through Sophisticated AI System Technologies. (arXiv:2310.04610v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.05421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1\">Shujian Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_H/0/1/0/all/0/1\">Hao Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpruch_L/0/1/0/all/0/1\">Lukasz Szpruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiese_M/0/1/0/all/0/1\">Magnus Wiese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabate_Vidales_M/0/1/0/all/0/1\">Marc Sabate-Vidales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Baoren Xiao</a>",
          "description": "Generative adversarial networks (GANs) have been extremely successful in\ngenerating samples, from seemingly high dimensional probability measures.\nHowever, these methods struggle to capture the temporal dependence of joint\nprobability distributions induced by time-series data. Furthermore, long\ntime-series data streams hugely increase the dimension of the target space,\nwhich may render generative modelling infeasible. To overcome these challenges,\nmotivated by the autoregressive models in econometric, we are interested in the\nconditional distribution of future time series given the past information. We\npropose the generic conditional Sig-WGAN framework by integrating\nWasserstein-GANs (WGANs) with mathematically principled and efficient path\nfeature extraction called the signature of a path. The signature of a path is a\ngraded sequence of statistics that provides a universal description for a\nstream of data, and its expected value characterises the law of the time-series\nmodel. In particular, we develop the conditional Sig-$W_1$ metric, that\ncaptures the conditional joint law of time series models, and use it as a\ndiscriminator. The signature feature space enables the explicit representation\nof the proposed discriminators which alleviates the need for expensive\ntraining. We validate our method on both synthetic and empirical dataset and\nobserve that our method consistently and significantly outperforms\nstate-of-the-art benchmarks with respect to measures of similarity and\npredictive ability.",
          "link": "http://arxiv.org/abs/2006.05421",
          "publishedOn": "2023-10-14T00:41:35.077Z",
          "wordCount": 761,
          "title": "Conditional Sig-Wasserstein GANs for Time Series Generation. (arXiv:2006.05421v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.14041",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenyuan Liu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Parys_B/0/1/0/all/0/1\">Bart P. G. Van Parys</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lam_H/0/1/0/all/0/1\">Henry Lam</a>",
          "description": "In data-driven optimization, sample average approximation (SAA) is known to\nsuffer from the so-called optimizer's curse that causes an over-optimistic\nevaluation of the solution performance. We argue that a special type of\ndistributionallly robust optimization (DRO) formulation offers theoretical\nadvantages in correcting for this optimizer's curse compared to simple\n``margin'' adjustments to SAA and other DRO approaches: It attains a\nstatistical bound on the out-of-sample performance, for a wide class of\nobjective functions and distributions, that is nearly tightest in terms of\nexponential decay rate. This DRO uses an ambiguity set based on a Kullback\nLeibler (KL) divergence smoothed by the Wasserstein or L\\'evy-Prokhorov (LP)\ndistance via a suitable distance optimization. Computationally, we also show\nthat such a DRO, and its generalized versions using smoothed $f$-divergence,\nare not harder than DRO problems based on $f$-divergence or Wasserstein\ndistances, rendering our DRO formulations both statistically optimal and\ncomputationally viable.",
          "link": "http://arxiv.org/abs/2306.14041",
          "publishedOn": "2023-10-14T00:41:35.072Z",
          "wordCount": 678,
          "title": "Smoothed $f$-Divergence Distributionally Robust Optimization. (arXiv:2306.14041v2 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Ivan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>",
          "description": "What is the relationship between model architecture and the ability to\nperform in-context learning? In this empirical study, we take the first steps\ntowards answering this question. In particular, we evaluate fifteen model\narchitectures across a suite of synthetic in-context learning tasks. The\nselected architectures represent a broad range of paradigms, including\nrecurrent and convolution-based neural networks, transformers, and emerging\nattention alternatives. We discover that all considered architectures can\nperform in-context learning under certain conditions. However, contemporary\narchitectures are found to be the best performing, especially as task\ncomplexity grows. Additionally, our follow-up experiments delve into various\nfactors that influence in-context learning. We observe varied sensitivities\namong architectures with respect to hyperparameter settings. Our study of\ntraining dynamics reveals that certain architectures exhibit a smooth,\nprogressive learning trajectory, while others demonstrate periods of stagnation\nfollowed by abrupt mastery of the task. Finally, and somewhat surprisingly, we\nfind that several emerging attention alternatives are more robust in-context\nlearners than transformers; since such approaches have constant-sized memory\nfootprints at inference time, this result opens the future possibility of\nscaling up in-context learning to vastly larger numbers of in-context examples.",
          "link": "http://arxiv.org/abs/2310.08049",
          "publishedOn": "2023-10-14T00:41:35.066Z",
          "wordCount": null,
          "title": "Exploring the Relationship Between Model Architecture and In-Context Learning Ability. (arXiv:2310.08049v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.04263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cagatan_O/0/1/0/all/0/1\">Omer Veysel Cagatan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akgun_B/0/1/0/all/0/1\">Baris Akgun</a>",
          "description": "This paper introduces BarlowRL, a data-efficient reinforcement learning agent\nthat combines the Barlow Twins self-supervised learning framework with DER\n(Data-Efficient Rainbow) algorithm. BarlowRL outperforms both DER and its\ncontrastive counterpart CURL on the Atari 100k benchmark. BarlowRL avoids\ndimensional collapse by enforcing information spread to the whole space. This\nhelps RL algorithms to utilize uniformly spread state representation that\neventually results in a remarkable performance. The integration of Barlow Twins\nwith DER enhances data efficiency and achieves superior performance in the RL\ntasks. BarlowRL demonstrates the potential of incorporating self-supervised\nlearning techniques to improve RL algorithms.",
          "link": "http://arxiv.org/abs/2308.04263",
          "publishedOn": "2023-10-14T00:41:35.066Z",
          "wordCount": null,
          "title": "BarlowRL: Barlow Twins for Data-Efficient Reinforcement Learning. (arXiv:2308.04263v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.11355",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Agarwal_A/0/1/0/all/0/1\">Anish Agarwal</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Cen_S/0/1/0/all/0/1\">Sarah H. Cen</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Yu_C/0/1/0/all/0/1\">Christina Lee Yu</a>",
          "description": "We propose a generalization of the synthetic controls and synthetic\ninterventions methodology to incorporate network interference. We consider the\nestimation of unit-specific potential outcomes from panel data in the presence\nof spillover across units and unobserved confounding. Key to our approach is a\nnovel latent factor model that takes into account network interference and\ngeneralizes the factor models typically used in panel data settings. We propose\nan estimator, Network Synthetic Interventions (NSI), and show that it\nconsistently estimates the mean outcomes for a unit under an arbitrary set of\ncounterfactual treatments for the network. We further establish that the\nestimator is asymptotically normal. We furnish two validity tests for whether\nthe NSI estimator reliably generalizes to produce accurate counterfactual\nestimates. We provide a novel graph-based experiment design that guarantees the\nNSI estimator produces accurate counterfactual estimates, and also analyze the\nsample complexity of the proposed design. We conclude with simulations that\ncorroborate our theoretical findings.",
          "link": "http://arxiv.org/abs/2210.11355",
          "publishedOn": "2023-10-14T00:41:35.063Z",
          "wordCount": null,
          "title": "Network Synthetic Interventions: A Causal Framework for Panel Data Under Network Interference. (arXiv:2210.11355v2 [econ.EM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.15889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenguan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>",
          "description": "Neural-symbolic computing (NeSy), which pursues the integration of the\nsymbolic and statistical paradigms of cognition, has been an active research\narea of Artificial Intelligence (AI) for many years. As NeSy shows promise of\nreconciling the advantages of reasoning and interpretability of symbolic\nrepresentation and robust learning in neural networks, it may serve as a\ncatalyst for the next generation of AI. In the present paper, we provide a\nsystematic overview of the recent developments and important contributions of\nNeSy research. Firstly, we introduce study history of this area, covering early\nwork and foundations. We further discuss background concepts and identify key\ndriving factors behind the development of NeSy. Afterward, we categorize recent\nlandmark approaches along several main characteristics that underline this\nresearch paradigm, including neural-symbolic integration, knowledge\nrepresentation, knowledge embedding, and functionality. Next, we briefly\ndiscuss the successful application of modern NeSy approaches in several\ndomains. Then, we benchmark several NeSy methods on three representative\napplication tasks. Finally, we identify the open problems together with\npotential future research directions. This survey is expected to help new\nresearchers enter this rapidly evolving field and accelerate the progress\ntowards data-and knowledge-driven AI.",
          "link": "http://arxiv.org/abs/2210.15889",
          "publishedOn": "2023-10-14T00:41:35.063Z",
          "wordCount": 740,
          "title": "Towards Data-and Knowledge-Driven Artificial Intelligence: A Survey on Neuro-Symbolic Computing. (arXiv:2210.15889v4 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelsalam_M/0/1/0/all/0/1\">Mohamed Ashraf Abdelsalam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangrej_S/0/1/0/all/0/1\">Samrudhdhi B. Rangrej</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadji_I/0/1/0/all/0/1\">Isma Hadji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dvornik_N/0/1/0/all/0/1\">Nikita Dvornik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Derpanis_K/0/1/0/all/0/1\">Konstantinos G. Derpanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazly_A/0/1/0/all/0/1\">Afsaneh Fazly</a>",
          "description": "We study the problem of future step anticipation in procedural videos. Given\na video of an ongoing procedural activity, we predict a plausible next\nprocedure step described in rich natural language. While most previous work\nfocus on the problem of data scarcity in procedural video datasets, another\ncore challenge of future anticipation is how to account for multiple plausible\nfuture realizations in natural settings. This problem has been largely\noverlooked in previous work. To address this challenge, we frame future step\nprediction as modelling the distribution of all possible candidates for the\nnext step. Specifically, we design a generative model that takes a series of\nvideo clips as input, and generates multiple plausible and diverse candidates\n(in natural language) for the next step. Following previous work, we side-step\nthe video annotation scarcity by pretraining our model on a large text-based\ncorpus of procedural activities, and then transfer the model to the video\ndomain. Our experiments, both in textual and video domains, show that our model\ncaptures diversity in the next step prediction and generates multiple plausible\nfuture predictions. Moreover, our model establishes new state-of-the-art\nresults on YouCookII, where it outperforms existing baselines on the next step\nanticipation. Finally, we also show that our model can successfully transfer\nfrom text to the video domain zero-shot, ie, without fine-tuning or adaptation,\nand produces good-quality future step predictions from video.",
          "link": "http://arxiv.org/abs/2310.08312",
          "publishedOn": "2023-10-14T00:41:35.056Z",
          "wordCount": null,
          "title": "GePSAn: Generative Procedure Step Anticipation in Cooking Videos. (arXiv:2310.08312v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaoke Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Haizhou Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenshuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siliang Tang</a>",
          "description": "Graph-structured data is ubiquitous in the world which models complex\nrelationships between objects, enabling various Web applications. Daily\ninfluxes of unlabeled graph data on the Web offer immense potential for these\napplications. Graph self-supervised algorithms have achieved significant\nsuccess in acquiring generic knowledge from abundant unlabeled graph data.\nThese pre-trained models can be applied to various downstream Web applications,\nsaving training time and improving downstream (target) performance. However,\ndifferent graphs, even across seemingly similar domains, can differ\nsignificantly in terms of attribute semantics, posing difficulties, if not\ninfeasibility, for transferring the pre-trained models to downstream tasks.\nConcretely speaking, for example, the additional task-specific node information\nin downstream tasks (specificity) is usually deliberately omitted so that the\npre-trained representation (transferability) can be leveraged. The trade-off as\nsuch is termed as \"transferability-specificity dilemma\" in this work. To\naddress this challenge, we introduce an innovative deployment module coined as\nGraphControl, motivated by ControlNet, to realize better graph domain transfer\nlearning. Specifically, by leveraging universal structural pre-trained models\nand GraphControl, we align the input space across various graphs and\nincorporate unique characteristics of target data as conditional inputs. These\nconditions will be progressively integrated into the model during fine-tuning\nor prompt tuning through ControlNet, facilitating personalized deployment.\nExtensive experiments show that our method significantly enhances the\nadaptability of pre-trained models on target attributed datasets, achieving\n1.4-3x performance gain. Furthermore, it outperforms training-from-scratch\nmethods on target data with a comparable margin and exhibits faster\nconvergence.",
          "link": "http://arxiv.org/abs/2310.07365",
          "publishedOn": "2023-10-14T00:41:35.050Z",
          "wordCount": null,
          "title": "GraphControl: Adding Conditional Control to Universal Graph Pre-trained Models for Graph Domain Transfer Learning. (arXiv:2310.07365v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuanlin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yunhao Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhuowen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>",
          "description": "Large vision-language models have achieved outstanding performance, but their\nsize and computational requirements make their deployment on\nresource-constrained devices and time-sensitive tasks impractical. Model\ndistillation, the process of creating smaller, faster models that maintain the\nperformance of larger models, is a promising direction towards the solution.\nThis paper investigates the distillation of visual representations in large\nteacher vision-language models into lightweight student models using a small-\nor mid-scale dataset. Notably, this study focuses on open-vocabulary\nout-of-distribution (OOD) generalization, a challenging problem that has been\noverlooked in previous model distillation literature. We propose two principles\nfrom vision and language modality perspectives to enhance student's OOD\ngeneralization: (1) by better imitating teacher's visual representation space,\nand carefully promoting better coherence in vision-language alignment with the\nteacher; (2) by enriching the teacher's language representations with\ninformative and finegrained semantic attributes to effectively distinguish\nbetween different labels. We propose several metrics and conduct extensive\nexperiments to investigate their techniques. The results demonstrate\nsignificant improvements in zero-shot and few-shot student performance on\nopen-vocabulary out-of-distribution classification, highlighting the\neffectiveness of our proposed approaches. Poster:\nhttps://xuanlinli17.github.io/pdfs/iccv23_large_vlm_distillation_poster.pdf\nCode: https://github.com/xuanlinli17/large_vlm_distillation_ood",
          "link": "http://arxiv.org/abs/2307.03135",
          "publishedOn": "2023-10-14T00:41:35.049Z",
          "wordCount": 738,
          "title": "Distilling Large Vision-Language Model with Out-of-Distribution Generalizability. (arXiv:2307.03135v3 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1\">Weijun Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yingdong Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1\">Chuan Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhao-Heng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "Humans often acquire new skills through observation and imitation. For\nrobotic agents, learning from the plethora of unlabeled video demonstration\ndata available on the Internet necessitates imitating the expert without access\nto its action, presenting a challenge known as Imitation Learning from\nObservations (ILfO). A common approach to tackle ILfO problems is to convert\nthem into inverse reinforcement learning problems, utilizing a proxy reward\ncomputed from the agent's and the expert's observations. Nonetheless, we\nidentify that tasks characterized by a progress dependency property pose\nsignificant challenges for such approaches; in these tasks, the agent needs to\ninitially learn the expert's preceding behaviors before mastering the\nsubsequent ones. Our investigation reveals that the main cause is that the\nreward signals assigned to later steps hinder the learning of initial\nbehaviors. To address this challenge, we present a novel ILfO framework that\nenables the agent to master earlier behaviors before advancing to later ones.\nWe introduce an Automatic Discount Scheduling (ADS) mechanism that adaptively\nalters the discount factor in reinforcement learning during the training phase,\nprioritizing earlier rewards initially and gradually engaging later rewards\nonly when the earlier behaviors have been mastered. Our experiments, conducted\non nine Meta-World tasks, demonstrate that our method significantly outperforms\nstate-of-the-art methods across all tasks, including those that are unsolvable\nby them.",
          "link": "http://arxiv.org/abs/2310.07433",
          "publishedOn": "2023-10-14T00:41:35.044Z",
          "wordCount": null,
          "title": "Imitation Learning from Observation with Automatic Discount Scheduling. (arXiv:2310.07433v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.02285",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Leng_Y/0/1/0/all/0/1\">Yichong Leng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_Z/0/1/0/all/0/1\">Zhifang Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_K/0/1/0/all/0/1\">Kai Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ju_Z/0/1/0/all/0/1\">Zeqian Ju</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yanqing Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yufei Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_D/0/1/0/all/0/1\">Dongchao Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1\">Leying Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_K/0/1/0/all/0/1\">Kaitao Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_L/0/1/0/all/0/1\">Lei He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xiang-Yang Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_S/0/1/0/all/0/1\">Sheng Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>",
          "description": "Speech conveys more information than text, as the same word can be uttered in\nvarious voices to convey diverse information. Compared to traditional\ntext-to-speech (TTS) methods relying on speech prompts (reference speech) for\nvoice variability, using text prompts (descriptions) is more user-friendly\nsince speech prompts can be hard to find or may not exist at all. TTS\napproaches based on the text prompt face two main challenges: 1) the\none-to-many problem, where not all details about voice variability can be\ndescribed in the text prompt, and 2) the limited availability of text prompt\ndatasets, where vendors and large cost of data labeling are required to write\ntext prompts for speech. In this work, we introduce PromptTTS 2 to address\nthese challenges with a variation network to provide variability information of\nvoice not captured by text prompts, and a prompt generation pipeline to utilize\nthe large language models (LLM) to compose high quality text prompts.\nSpecifically, the variation network predicts the representation extracted from\nthe reference speech (which contains full information about voice variability)\nbased on the text prompt representation. For the prompt generation pipeline, it\ngenerates text prompts for speech with a speech language understanding model to\nrecognize voice attributes (e.g., gender, speed) from speech and a large\nlanguage model to formulate text prompts based on the recognition results.\nExperiments on a large-scale (44K hours) speech dataset demonstrate that\ncompared to the previous works, PromptTTS 2 generates voices more consistent\nwith text prompts and supports the sampling of diverse voice variability,\nthereby offering users more choices on voice generation. Additionally, the\nprompt generation pipeline produces high-quality text prompts, eliminating the\nlarge labeling cost. The demo page of PromptTTS 2 is available online.",
          "link": "http://arxiv.org/abs/2309.02285",
          "publishedOn": "2023-10-14T00:41:35.041Z",
          "wordCount": null,
          "title": "PromptTTS 2: Describing and Generating Voices with Text Prompt. (arXiv:2309.02285v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.00177",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Lan_K/0/1/0/all/0/1\">Kai Weixian Lan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gueidon_E/0/1/0/all/0/1\">Elias Gueidon</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kaneda_A/0/1/0/all/0/1\">Ayano Kaneda</a>, <a href=\"http://arxiv.org/find/math/1/au:+Panetta_J/0/1/0/all/0/1\">Julian Panetta</a>, <a href=\"http://arxiv.org/find/math/1/au:+Teran_J/0/1/0/all/0/1\">Joseph Teran</a>",
          "description": "We introduce a neural-preconditioned iterative solver for Poisson equations\nwith mixed boundary conditions. The Poisson equation is ubiquitous in\nscientific computing: it governs a wide array of physical phenomena, arises as\na subproblem in many numerical algorithms, and serves as a model problem for\nthe broader class of elliptic PDEs. The most popular Poisson discretizations\nyield large sparse linear systems. At high resolution, and for\nperformance-critical applications, iterative solvers can be advantageous for\nthese -- but only when paired with powerful preconditioners. The core of our\nsolver is a neural network trained to approximate the inverse of a discrete\nstructured-grid Laplace operator for a domain of arbitrary shape and with mixed\nboundary conditions. The structure of this problem motivates a novel network\narchitecture that we demonstrate is highly effective as a preconditioner even\nfor boundary conditions outside the training set. We show that on challenging\ntest cases arising from an incompressible fluid simulation, our method\noutperforms state-of-the-art solvers like algebraic multigrid as well as some\nrecent neural preconditioners.",
          "link": "http://arxiv.org/abs/2310.00177",
          "publishedOn": "2023-10-14T00:41:35.040Z",
          "wordCount": null,
          "title": "A Neural-preconditioned Poisson Solver for Mixed Dirichlet and Neumann Boundary Conditions. (arXiv:2310.00177v3 [math.NA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.04948",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1\">Furong Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1\">Sercan O Arik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yixiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wen Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "The past decade has witnessed significant advances in time series modeling\nwith deep learning. While achieving state-of-the-art results, the\nbest-performing architectures vary highly across applications and domains.\nMeanwhile, for natural language processing, the Generative Pre-trained\nTransformer (GPT) has demonstrated impressive performance via training one\ngeneral-purpose model across various textual datasets. It is intriguing to\nexplore whether GPT-type architectures can be effective for time series,\ncapturing the intrinsic dynamic attributes and leading to significant accuracy\nimprovements. In this paper, we propose a novel framework, TEMPO, that can\neffectively learn time series representations. We focus on utilizing two\nessential inductive biases of the time series task for pre-trained models: (i)\ndecomposition of the complex interaction between trend, seasonal and residual\ncomponents; and (ii) introducing the selection-based prompts to facilitate\ndistribution adaptation in non-stationary time series. TEMPO expands the\ncapability for dynamically modeling real-world temporal phenomena from data\nwithin diverse domains. Our experiments demonstrate the superior performance of\nTEMPO over state-of-the-art methods on a number of time series benchmark\ndatasets. This performance gain is observed not only in standard supervised\nlearning settings but also in scenarios involving previously unseen datasets as\nwell as in scenarios with multi-modal inputs. This compelling finding\nhighlights TEMPO's potential to constitute a foundational model-building\nframework.",
          "link": "http://arxiv.org/abs/2310.04948",
          "publishedOn": "2023-10-14T00:41:35.040Z",
          "wordCount": null,
          "title": "TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting. (arXiv:2310.04948v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.02286",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zambon_L/0/1/0/all/0/1\">Lorenzo Zambon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Azzimonti_D/0/1/0/all/0/1\">Dario Azzimonti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Corani_G/0/1/0/all/0/1\">Giorgio Corani</a>",
          "description": "Hierarchical time series are common in several applied fields. The forecasts\nfor these time series are required to be coherent, that is, to satisfy the\nconstraints given by the hierarchy. The most popular technique to enforce\ncoherence is called reconciliation, which adjusts the base forecasts computed\nfor each time series. However, recent works on probabilistic reconciliation\npresent several limitations. In this paper, we propose a new approach based on\nconditioning to reconcile any type of forecast distribution. We then introduce\na new algorithm, called Bottom-Up Importance Sampling, to efficiently sample\nfrom the reconciled distribution. It can be used for any base forecast\ndistribution: discrete, continuous, or in the form of samples, providing a\nmajor speedup compared to the current methods. Experiments on several temporal\nhierarchies show a significant improvement over base probabilistic forecasts.",
          "link": "http://arxiv.org/abs/2210.02286",
          "publishedOn": "2023-10-14T00:41:35.038Z",
          "wordCount": 677,
          "title": "Efficient probabilistic reconciliation of forecasts for real-valued and count time series. (arXiv:2210.02286v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.05898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lizhang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kaizhao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>",
          "description": "Lion (Evolved Sign Momentum), a new optimizer discovered through program\nsearch, has shown promising results in training large AI models. It performs\ncomparably or favorably to AdamW but with greater memory efficiency. As we can\nexpect from the results of a random search program, Lion incorporates elements\nfrom several existing algorithms, including signed momentum, decoupled weight\ndecay, Polak, and Nesterov momentum, but does not fit into any existing\ncategory of theoretically grounded optimizers. Thus, even though Lion appears\nto perform well as a general-purpose optimizer for a wide range of tasks, its\ntheoretical basis remains uncertain. This lack of theoretical clarity limits\nopportunities to further enhance and expand Lion's efficacy.\n\nThis work aims to demystify Lion. Based on both continuous-time and\ndiscrete-time analysis, we demonstrate that Lion is a theoretically novel and\nprincipled approach for minimizing a general loss function $f(x)$ while\nenforcing a bound constraint $\\|x\\|_\\infty \\leq 1/\\lambda$. Lion achieves this\nthrough the incorporation of decoupled weight decay, where $\\lambda$ represents\nthe weight decay coefficient. Our analysis is made possible by the development\nof a new Lyapunov function for the Lion updates. It applies to a broader family\nof Lion-$\\kappa$ algorithms, where the $\\text{sign}(\\cdot)$ operator in Lion is\nreplaced by the subgradient of a convex function $\\kappa$, leading to the\nsolution of a general composite optimization problem of $\\min_x f(x) +\n\\kappa^*(x)$. Our findings provide valuable insights into the dynamics of Lion\nand pave the way for further improvements and extensions of Lion-related\nalgorithms.",
          "link": "http://arxiv.org/abs/2310.05898",
          "publishedOn": "2023-10-14T00:41:35.029Z",
          "wordCount": null,
          "title": "Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts. (arXiv:2310.05898v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.05288",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Clark_K/0/1/0/all/0/1\">Katharine M. Clark</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McNicholas_P/0/1/0/all/0/1\">Paul D. McNicholas</a>",
          "description": "Matrix-variate distributions are a recent addition to the model-based\nclustering field, thereby making it possible to analyze data in matrix form\nwith complex structure such as images and time series. Due to its recent\nappearance, there is limited literature on matrix-variate data, with even less\non dealing with outliers in these models. An approach for clustering\nmatrix-variate normal data with outliers is discussed. The approach, which uses\nthe distribution of subset log-likelihoods, extends the OCLUST algorithm to\nmatrix-variate normal data and uses an iterative approach to detect and trim\noutliers.",
          "link": "http://arxiv.org/abs/2310.05288",
          "publishedOn": "2023-10-14T00:41:35.027Z",
          "wordCount": null,
          "title": "Clustering Three-Way Data with Outliers. (arXiv:2310.05288v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zheshun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1\">Dun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>",
          "description": "Federated Learning (FL) has surged in prominence due to its capability of\ncollaborative model training without direct data sharing. However, the vast\ndisparity in local data distributions among clients, often termed the\nnon-Independent Identically Distributed (non-IID) challenge, poses a\nsignificant hurdle to FL's generalization efficacy. The scenario becomes even\nmore complex when not all clients participate in the training process, a common\noccurrence due to unstable network connections or limited computational\ncapacities. This can greatly complicate the assessment of the trained models'\ngeneralization abilities. While a plethora of recent studies has centered on\nthe generalization gap pertaining to unseen data from participating clients\nwith diverse distributions, the divergence between the training distributions\nof participating clients and the testing distributions of non-participating\nones has been largely overlooked. In response, our paper unveils an\ninformation-theoretic generalization framework for FL. Specifically, it\nquantifies generalization errors by evaluating the information entropy of local\ndistributions and discerning discrepancies across these distributions. Inspired\nby our deduced generalization bounds, we introduce a weighted aggregation\napproach and a duo of client selection strategies. These innovations aim to\nbolster FL's generalization prowess by encompassing a more varied set of client\ndata distributions. Our extensive empirical evaluations reaffirm the potency of\nour proposed methods, aligning seamlessly with our theoretical construct.",
          "link": "http://arxiv.org/abs/2310.07171",
          "publishedOn": "2023-10-14T00:41:35.026Z",
          "wordCount": null,
          "title": "Federated Generalization via Information-Theoretic Distribution Diversification. (arXiv:2310.07171v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.06488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianlong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wenhao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1\">Changze Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jianhan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cenyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Muling Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiaoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>",
          "description": "Spiking neural networks (SNNs) have demonstrated the capability to achieve\ncomparable performance to deep neural networks (DNNs) in both visual and\nlinguistic domains while offering the advantages of improved energy efficiency\nand adherence to biological plausibility. However, the extension of such\nsingle-modality SNNs into the realm of multimodal scenarios remains an\nunexplored territory. Drawing inspiration from the concept of contrastive\nlanguage-image pre-training (CLIP), we introduce a novel framework, named\nSpikeCLIP, to address the gap between two modalities within the context of\nspike-based computing through a two-step recipe involving ``Alignment\nPre-training + Dual-Loss Fine-tuning\". Extensive experiments demonstrate that\nSNNs achieve comparable results to their DNN counterparts while significantly\nreducing energy consumption across a variety of datasets commonly used for\nmultimodal model evaluation. Furthermore, SpikeCLIP maintains robust\nperformance in image classification tasks that involve class labels not\npredefined within specific categories.",
          "link": "http://arxiv.org/abs/2310.06488",
          "publishedOn": "2023-10-14T00:41:35.025Z",
          "wordCount": null,
          "title": "SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network. (arXiv:2310.06488v2 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.10404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Konrad_A/0/1/0/all/0/1\">Anna Konrad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_J/0/1/0/all/0/1\">John McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villing_R/0/1/0/all/0/1\">Rudi Villing</a>",
          "description": "We present the Grasp Proposal Network (GP-net), a Convolutional Neural\nNetwork model which can generate 6-DoF grasps from flexible viewpoints, e.g. as\nexperienced by mobile manipulators. To train GP-net, we synthetically generate\na dataset containing depth-images and ground-truth grasp information. In\nreal-world experiments, we use the EGAD evaluation benchmark to evaluate GP-net\nagainst two commonly used algorithms, the Volumetric Grasping Network (VGN) and\nthe Grasp Pose Detection package (GPD), on a PAL TIAGo mobile manipulator. In\ncontrast to the state-of-the-art methods in robotic grasping, GP-net can be\nused for grasping objects from flexible, unknown viewpoints without the need to\ndefine the workspace and achieves a grasp success of 54.4% compared to 51.6%\nfor VGN and 44.2% for GPD. We provide a ROS package along with our code and\npre-trained models at https://aucoroboticsmu.github.io/GP-net/.",
          "link": "http://arxiv.org/abs/2209.10404",
          "publishedOn": "2023-10-14T00:41:35.024Z",
          "wordCount": null,
          "title": "GP-net: Flexible Viewpoint Grasp Proposal. (arXiv:2209.10404v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07807",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kiyamousavi_E/0/1/0/all/0/1\">Ensiye Kiyamousavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraychev_B/0/1/0/all/0/1\">Boris Kraychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koychev_I/0/1/0/all/0/1\">Ivan Koychev</a>",
          "description": "Federated learning (FL) is a decentralized machine learning approach where\nindependent learners process data privately. Its goal is to create a robust and\naccurate model by aggregating and retraining local models over multiple rounds.\nHowever, FL faces challenges regarding data heterogeneity and model aggregation\neffectiveness. In order to simulate real-world data, researchers use methods\nfor data partitioning that transform a dataset designated for centralized\nlearning into a group of sub-datasets suitable for distributed machine learning\nwith different data heterogeneity. In this paper, we study the currently\npopular data partitioning techniques and visualize their main disadvantages:\nthe lack of precision in the data diversity, which leads to unreliable\nheterogeneity indexes, and the inability to incrementally challenge the FL\nalgorithms. To resolve this problem, we propose a method that leverages entropy\nand symmetry to construct 'the most challenging' and controllable data\ndistributions with gradual difficulty. We introduce a metric to measure data\nheterogeneity among the learning agents and a transformation technique that\ndivides any dataset into splits with precise data diversity. Through a\ncomparative study, we demonstrate the superiority of our method over existing\nFL data partitioning approaches, showcasing its potential to challenge model\naggregation algorithms. Experimental results indicate that our approach\ngradually challenges the FL strategies, and the models trained on FedSym\ndistributions are more distinct.",
          "link": "http://arxiv.org/abs/2310.07807",
          "publishedOn": "2023-10-14T00:41:35.022Z",
          "wordCount": null,
          "title": "FedSym: Unleashing the Power of Entropy for Benchmarking the Algorithms for Federated Learning. (arXiv:2310.07807v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.06225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_B/0/1/0/all/0/1\">Bruno Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nunes_L/0/1/0/all/0/1\">Leonardo Nunes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Estevao_R/0/1/0/all/0/1\">Roberto Estev&#xe3;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aski_V/0/1/0/all/0/1\">Vijay Aski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1\">Ranveer Chandra</a>",
          "description": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding across various domains, including healthcare and\nfinance. For some tasks, LLMs achieve similar or better performance than\ntrained human beings, therefore it is reasonable to employ human exams (e.g.,\ncertification tests) to assess the performance of LLMs. We present a\ncomprehensive evaluation of popular LLMs, such as Llama 2 and GPT, on their\nability to answer agriculture-related questions. In our evaluation, we also\nemploy RAG (Retrieval-Augmented Generation) and ER (Ensemble Refinement)\ntechniques, which combine information retrieval, generation capabilities, and\nprompting strategies to improve the LLMs' performance. To demonstrate the\ncapabilities of LLMs, we selected agriculture exams and benchmark datasets from\nthree of the largest agriculture producer countries: Brazil, India, and the\nUSA. Our analysis highlights GPT-4's ability to achieve a passing score on\nexams to earn credits for renewing agronomist certifications, answering 93% of\nthe questions correctly and outperforming earlier general-purpose models, which\nachieved 88% accuracy. On one of our experiments, GPT-4 obtained the highest\nperformance when compared to human subjects. This performance suggests that\nGPT-4 could potentially pass on major graduate education admission tests or\neven earn credits for renewing agronomy certificates. We also explore the\nmodels' capacity to address general agriculture-related questions and generate\ncrop management guidelines for Brazilian and Indian farmers, utilizing robust\ndatasets from the Brazilian Agency of Agriculture (Embrapa) and graduate\nprogram exams from India. The results suggest that GPT-4, ER, and RAG can\ncontribute meaningfully to agricultural education, assessment, and crop\nmanagement practice, offering valuable insights to farmers and agricultural\nprofessionals.",
          "link": "http://arxiv.org/abs/2310.06225",
          "publishedOn": "2023-10-14T00:41:35.020Z",
          "wordCount": null,
          "title": "GPT-4 as an Agronomist Assistant? Answering Agriculture Exams Using Large Language Models. (arXiv:2310.06225v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.06823",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ammar_M/0/1/0/all/0/1\">Mou&#xef;n Ben Ammar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Belkhir_N/0/1/0/all/0/1\">Nacim Belkhir</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Popescu_S/0/1/0/all/0/1\">Sebastian Popescu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Manzanera_A/0/1/0/all/0/1\">Antoine Manzanera</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Franchi_G/0/1/0/all/0/1\">Gianni Franchi</a>",
          "description": "Detecting out-of-distribution (OOD) data is a critical challenge in machine\nlearning due to model overconfidence, often without awareness of their\nepistemological limits. We hypothesize that ``neural collapse'', a phenomenon\naffecting in-distribution data for models trained beyond loss convergence, also\ninfluences OOD data. To benefit from this interplay, we introduce NECO, a novel\npost-hoc method for OOD detection, which leverages the geometric properties of\n``neural collapse'' and of principal component spaces to identify OOD data. Our\nextensive experiments demonstrate that NECO achieves state-of-the-art results\non both small and large-scale OOD detection tasks while exhibiting strong\ngeneralization capabilities across different network architectures.\nFurthermore, we provide a theoretical explanation for the effectiveness of our\nmethod in OOD detection. We plan to release the code after the anonymity\nperiod.",
          "link": "http://arxiv.org/abs/2310.06823",
          "publishedOn": "2023-10-14T00:41:35.019Z",
          "wordCount": null,
          "title": "NECO: NEural Collapse Based Out-of-distribution detection. (arXiv:2310.06823v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.05624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Doyup Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chiheon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1\">Minsu Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wook-Shin Han</a>",
          "description": "Generalizable implicit neural representation (INR) enables a single\ncontinuous function, i.e., a coordinate-based neural network, to represent\nmultiple data instances by modulating its weights or intermediate features\nusing latent codes. However, the expressive power of the state-of-the-art\nmodulation is limited due to its inability to localize and capture fine-grained\ndetails of data entities such as specific pixels and rays. To address this\nissue, we propose a novel framework for generalizable INR that combines a\ntransformer encoder with a locality-aware INR decoder. The transformer encoder\npredicts a set of latent tokens from a data instance to encode local\ninformation into each latent token. The locality-aware INR decoder extracts a\nmodulation vector by selectively aggregating the latent tokens via\ncross-attention for a coordinate input and then predicts the output by\nprogressively decoding with coarse-to-fine modulation through multiple\nfrequency bandwidths. The selective token aggregation and the multi-band\nfeature modulation enable us to learn locality-aware representation in spatial\nand spectral aspects, respectively. Our framework significantly outperforms\nprevious generalizable INRs and validates the usefulness of the locality-aware\nlatents for downstream tasks such as image generation.",
          "link": "http://arxiv.org/abs/2310.05624",
          "publishedOn": "2023-10-14T00:41:35.017Z",
          "wordCount": null,
          "title": "Locality-Aware Generalizable Implicit Neural Representation. (arXiv:2310.05624v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hintersdorf_D/0/1/0/all/0/1\">Dominik Hintersdorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Struppek_L/0/1/0/all/0/1\">Lukas Struppek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neider_D/0/1/0/all/0/1\">Daniel Neider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>",
          "description": "The proliferation of large AI models trained on uncurated, often sensitive\nweb-scraped data has raised significant privacy concerns. One of the concerns\nis that adversaries can extract information about the training data using\nprivacy attacks. Unfortunately, the task of removing specific information from\nthe models without sacrificing performance is not straightforward and has\nproven to be challenging. We propose a rather easy yet effective defense based\non backdoor attacks to remove private information such as names of individuals\nfrom models, and focus in this work on text encoders. Specifically, through\nstrategic insertion of backdoors, we align the embeddings of sensitive phrases\nwith those of neutral terms-\"a person\" instead of the person's name. Our\nempirical results demonstrate the effectiveness of our backdoor-based defense\non CLIP by assessing its performance using a specialized privacy attack for\nzero-shot classifiers. Our approach provides not only a new \"dual-use\"\nperspective on backdoor attacks, but also presents a promising avenue to\nenhance the privacy of individuals within models trained on uncurated\nweb-scraped data.",
          "link": "http://arxiv.org/abs/2310.08320",
          "publishedOn": "2023-10-14T00:41:35.015Z",
          "wordCount": null,
          "title": "Defending Our Privacy With Backdoors. (arXiv:2310.08320v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kai Liu</a>",
          "description": "Sparse logistic regression is for classification and feature selection\nsimultaneously. Although many studies have been done to solve\n$\\ell_1$-regularized logistic regression, there is no equivalently abundant\nwork on solving sparse logistic regression with nonconvex regularization term.\nIn this paper, we propose a unified framework to solve $\\ell_1$-regularized\nlogistic regression, which can be naturally extended to nonconvex\nregularization term, as long as certain requirement is satisfied. In addition,\nwe also utilize a different line search criteria to guarantee monotone\nconvergence for various regularization terms. Empirical experiments on binary\nclassification tasks with real-world datasets demonstrate our proposed\nalgorithms are capable of performing classification and feature selection\neffectively at a lower computational cost.",
          "link": "http://arxiv.org/abs/2309.05925",
          "publishedOn": "2023-10-14T00:41:35.012Z",
          "wordCount": null,
          "title": "On Regularized Sparse Logistic Regression. (arXiv:2309.05925v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08069",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haochen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>",
          "description": "Recently, contrastive learning has become a key component in fine-tuning code\nsearch models for software development efficiency and effectiveness. It pulls\ntogether positive code snippets while pushing negative samples away given\nsearch queries. Among contrastive learning, InfoNCE is the most widely used\nloss function due to its better performance. However, the following problems in\nnegative samples of InfoNCE may deteriorate its representation learning: 1) The\nexistence of false negative samples in large code corpora due to duplications.\n2). The failure to explicitly differentiate between the potential relevance of\nnegative samples. As an example, a bubble sorting algorithm example is less\n``negative'' than a file saving function for the quick sorting algorithm query.\nIn this paper, we tackle the above problems by proposing a simple yet effective\nSoft-InfoNCE loss that inserts weight terms into InfoNCE. In our proposed loss\nfunction, we apply three methods to estimate the weights of negative pairs and\nshow that the vanilla InfoNCE loss is a special case of Soft-InfoNCE.\nTheoretically, we analyze the effects of Soft-InfoNCE on controlling the\ndistribution of learnt code representations and on deducing a more precise\nmutual information estimation. We furthermore discuss the superiority of\nproposed loss functions with other design alternatives. Extensive experiments\ndemonstrate the effectiveness of Soft-InfoNCE and weights estimation methods\nunder state-of-the-art code search models on a large-scale public dataset\nconsisting of six programming languages. Source code is available at\n\\url{https://github.com/Alex-HaochenLi/Soft-InfoNCE}.",
          "link": "http://arxiv.org/abs/2310.08069",
          "publishedOn": "2023-10-14T00:41:35.009Z",
          "wordCount": null,
          "title": "Rethinking Negative Pairs in Code Search. (arXiv:2310.08069v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galliera_R/0/1/0/all/0/1\">Raffaele Galliera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venable_K/0/1/0/all/0/1\">Kristen Brent Venable</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bassani_M/0/1/0/all/0/1\">Matteo Bassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suri_N/0/1/0/all/0/1\">Niranjan Suri</a>",
          "description": "In modern communication systems, efficient and reliable information\ndissemination is crucial for supporting critical operations across domains like\ndisaster response, autonomous vehicles, and sensor networks. This paper\nintroduces a Multi-Agent Reinforcement Learning (MARL) approach as a\nsignificant step forward in achieving more decentralized, efficient, and\ncollaborative solutions. We propose a Partially Observable Stochastic Game\n(POSG) formulation for information dissemination empowering each agent to\ndecide on message forwarding independently, based on their one-hop\nneighborhood. This constitutes a significant paradigm shift from traditional\nheuristics based on Multi-Point Relay (MPR) selection. Our approach harnesses\nGraph Convolutional Reinforcement Learning, employing Graph Attention Networks\n(GAT) with dynamic attention to capture essential network features. We propose\ntwo approaches, L-DGN and HL-DGN, which differ in the information that is\nexchanged among agents. We evaluate the performance of our decentralized\napproaches, by comparing them with a widely-used MPR heuristic, and we show\nthat our trained policies are able to efficiently cover the network while\nbypassing the MPR set selection process. Our approach is a first step toward\nsupporting the resilience of real-world broadcast communication infrastructures\nvia learned, collaborative information dissemination.",
          "link": "http://arxiv.org/abs/2308.16198",
          "publishedOn": "2023-10-14T00:41:35.006Z",
          "wordCount": null,
          "title": "Learning Collaborative Information Dissemination with Graph-based Multi-Agent Reinforcement Learning. (arXiv:2308.16198v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.03807",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fan_X/0/1/0/all/0/1\">Xiaohong Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1\">Yin Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_K/0/1/0/all/0/1\">Ke Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feng_Y/0/1/0/all/0/1\">Yujie Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1\">Jianping Zhang</a>",
          "description": "Proximal gradient-based optimization is one of the most common strategies to\nsolve inverse problem of images, and it is easy to implement. However, these\ntechniques often generate heavy artifacts in image reconstruction. One of the\nmost popular refinement methods is to fine-tune the regularization parameter to\nalleviate such artifacts, but it may not always be sufficient or applicable due\nto increased computational costs. In this work, we propose a deep geometric\nincremental learning framework based on the second Nesterov proximal gradient\noptimization. The proposed end-to-end network not only has the powerful\nlearning ability for high-/low-frequency image features, but also can\ntheoretically guarantee that geometric texture details will be reconstructed\nfrom preliminary linear reconstruction. Furthermore, it can avoid the risk of\nintermediate reconstruction results falling outside the geometric decomposition\ndomains and achieve fast convergence. Our reconstruction framework is\ndecomposed into four modules including general linear reconstruction, cascade\ngeometric incremental restoration, Nesterov acceleration, and post-processing.\nIn the image restoration step, a cascade geometric incremental learning module\nis designed to compensate for missing texture information from different\ngeometric spectral decomposition domains. Inspired by the overlap-tile\nstrategy, we also develop a post-processing module to remove the block effect\nin patch-wise-based natural image reconstruction. All parameters in the\nproposed model are learnable, an adaptive initialization technique of physical\nparameters is also employed to make model flexibility and ensure converging\nsmoothly. We compare the reconstruction performance of the proposed method with\nexisting state-of-the-art methods to demonstrate its superiority. Our source\ncodes are available at https://github.com/fanxiaohong/Nest-DGIL.",
          "link": "http://arxiv.org/abs/2308.03807",
          "publishedOn": "2023-10-14T00:41:34.996Z",
          "wordCount": null,
          "title": "Nest-DGIL: Nesterov-optimized Deep Geometric Incremental Learning for CS Image Reconstruction. (arXiv:2308.03807v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08165",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Morani_K/0/1/0/all/0/1\">Kenan Morani</a>",
          "description": "The accurate and efficient diagnosis of COVID-19 is of paramount importance,\nparticularly in the context of large-scale medical imaging datasets. In this\npreprint paper, we propose a novel approach for COVID-19 diagnosis using CT\nimages that leverages the power of Swin Transformer models, state-of-the-art\nsolutions in computer vision tasks. Our method includes a systematic approach\nfor patient-level predictions, where individual CT slices are classified as\nCOVID-19 or non-COVID, and the patient's overall diagnosis is determined\nthrough majority voting. The application of the Swin Transformer in this\ncontext results in patient-level predictions that demonstrate exceptional\ndiagnostic accuracy. In terms of evaluation metrics, our approach consistently\noutperforms the baseline, as well as numerous competing methods, showcasing its\neffectiveness in COVID-19 diagnosis. The macro F1 score achieved by our model\nexceeds the baseline and offers a robust solution for accurate diagnosis.",
          "link": "http://arxiv.org/abs/2310.08165",
          "publishedOn": "2023-10-14T00:41:34.989Z",
          "wordCount": null,
          "title": "COVID-19 Detection Using Swin Transformer Approach from Computed Tomography Images. (arXiv:2310.08165v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hongling Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_A/0/1/0/all/0/1\">Anke Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Han Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Foundation models (FM) have demonstrated remarkable performance across a wide\nrange of tasks (especially in the fields of natural language processing and\ncomputer vision), primarily attributed to their ability to comprehend\ninstructions and access extensive, high-quality data. This not only showcases\ntheir current effectiveness but also sets a promising trajectory towards the\ndevelopment of artificial general intelligence. Unfortunately, due to multiple\nconstraints, the raw data of the model used for large model training are often\ninaccessible, so the use of end-to-end models for downstream tasks has become a\nnew research trend, which we call Learn From Model (LFM) in this article. LFM\nfocuses on the research, modification, and design of FM based on the model\ninterface, so as to better understand the model structure and weights (in a\nblack box environment), and to generalize the model to downstream tasks. The\nstudy of LFM techniques can be broadly categorized into five major areas: model\ntuning, model distillation, model reuse, meta learning and model editing. Each\ncategory encompasses a repertoire of methods and strategies that aim to enhance\nthe capabilities and performance of FM. This paper gives a comprehensive review\nof the current methods based on FM from the perspective of LFM, in order to\nhelp readers better understand the current research status and ideas. To\nconclude, we summarize the survey by highlighting several critical areas for\nfuture exploration and addressing open issues that require further attention\nfrom the research community. The relevant papers we investigated in this\narticle can be accessed at\n<https://github.com/ruthless-man/Awesome-Learn-from-Model>.",
          "link": "http://arxiv.org/abs/2310.08184",
          "publishedOn": "2023-10-14T00:41:34.986Z",
          "wordCount": null,
          "title": "Learn From Model Beyond Fine-Tuning: A Survey. (arXiv:2310.08184v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08224",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sbailo_L/0/1/0/all/0/1\">Luigi Sbail&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghiringhelli_L/0/1/0/all/0/1\">Luca Ghiringhelli</a>",
          "description": "We observe the emergence of binary encoding within the latent space of\ndeep-neural-network classifiers. Such binary encoding is induced by introducing\na linear penultimate layer, which is equipped during training with a loss\nfunction that grows as $\\exp(\\vec{x}^2)$, where $\\vec{x}$ are the coordinates\nin the latent space. The phenomenon we describe represents a specific instance\nof a well-documented occurrence known as \\textit{neural collapse}, which arises\nin the terminal phase of training and entails the collapse of latent class\nmeans to the vertices of a simplex equiangular tight frame (ETF). We show that\nbinary encoding accelerates convergence toward the simplex ETF and enhances\nclassification accuracy.",
          "link": "http://arxiv.org/abs/2310.08224",
          "publishedOn": "2023-10-14T00:41:34.971Z",
          "wordCount": null,
          "title": "Emergence of Latent Binary Encoding in Deep Neural Network Classifiers. (arXiv:2310.08224v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1\">KaiChieh Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Daniel Huang</a>",
          "description": "We refer to the setting where the (partial) derivatives of a neural network's\n(NN's) predictions with respect to its inputs are used as additional training\nsignal as a derivative-constrained (DC) NN. This situation is common in\nphysics-informed settings in the natural sciences. We propose an integrated\nRELU (IReLU) activation function to improve training of DC NNs. We also\ninvestigate denormalization and label rescaling to help stabilize DC training.\nWe evaluate our methods on physics-informed settings including quantum\nchemistry and Scientific Machine Learning (SciML) tasks. We demonstrate that\nexisting architectures with IReLU activations combined with denormalization and\nlabel rescaling better incorporate training signal provided by derivative\nconstraints.",
          "link": "http://arxiv.org/abs/2310.01649",
          "publishedOn": "2023-10-14T00:41:34.953Z",
          "wordCount": null,
          "title": "On Training Derivative-Constrained Neural Networks. (arXiv:2310.01649v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.06648",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Marion_P/0/1/0/all/0/1\">Pierre Marion</a>",
          "description": "Neural ordinary differential equations (neural ODEs) are a popular family of\ncontinuous-depth deep learning models. In this work, we consider a large family\nof parameterized ODEs with continuous-in-time parameters, which include\ntime-dependent neural ODEs. We derive a generalization bound for this class by\na Lipschitz-based argument. By leveraging the analogy between neural ODEs and\ndeep residual networks, our approach yields in particular a generalization\nbound for a class of deep residual networks. The bound involves the magnitude\nof the difference between successive weight matrices. We illustrate numerically\nhow this quantity affects the generalization capability of neural networks.",
          "link": "http://arxiv.org/abs/2305.06648",
          "publishedOn": "2023-10-14T00:41:34.947Z",
          "wordCount": 616,
          "title": "Generalization bounds for neural ordinary differential equations and deep residual networks. (arXiv:2305.06648v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.04102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jason Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahrzad_H/0/1/0/all/0/1\">Hormoz Shahrzad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1\">Risto Miikkulainen</a>",
          "description": "Many evolutionary algorithms (EAs) take advantage of parallel evaluation of\ncandidates. However, if evaluation times vary significantly, many worker nodes\n(i.e.,\\ compute clients) are idle much of the time, waiting for the next\ngeneration to be created. Evolutionary neural architecture search (ENAS), a\nclass of EAs that optimizes the architecture and hyperparameters of deep neural\nnetworks, is particularly vulnerable to this issue. This paper proposes a\ngeneric asynchronous evaluation strategy (AES) that is then adapted to work\nwith ENAS. AES increases throughput by maintaining a queue of up to $K$\nindividuals ready to be sent to the workers for evaluation and proceeding to\nthe next generation as soon as $M<<K$ individuals have been evaluated. A\nsuitable value for $M$ is determined experimentally, balancing diversity and\nefficiency. To showcase the generality and power of AES, it was first evaluated\nin eight-line sorting network design (a single-population optimization task\nwith limited evaluation-time variability), achieving an over two-fold speedup.\nNext, it was evaluated in 11-bit multiplexer design (a single-population\ndiscovery task with extended variability), where a 14-fold speedup was\nobserved. It was then scaled up to ENAS for image captioning (a\nmulti-population open-ended-optimization task), resulting in an over two-fold\nspeedup. In all problems, a multifold performance improvement was observed,\nsuggesting that AES is a promising method for parallelizing the evolution of\ncomplex systems with long and variable evaluation times, such as those in ENAS.",
          "link": "http://arxiv.org/abs/2308.04102",
          "publishedOn": "2023-10-14T00:41:34.931Z",
          "wordCount": null,
          "title": "Asynchronous Evolution of Deep Neural Network Architectures. (arXiv:2308.04102v2 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_M/0/1/0/all/0/1\">Mingyang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1\">Lucas Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benton_J/0/1/0/all/0/1\">Joe Benton</a>",
          "description": "Recent works have proposed that activations in language models can be\nmodelled as sparse linear combinations of vectors corresponding to features of\ninput text. Under this assumption, these works aimed to reconstruct feature\ndirections using sparse coding. We develop metrics to assess the success of\nthese sparse coding techniques and test the validity of the linearity and\nsparsity assumptions. We show our metrics can predict the level of sparsity on\nsynthetic sparse linear activations, and can distinguish between sparse linear\ndata and several other distributions. We use our metrics to measure levels of\nsparsity in several language models. We find evidence that language model\nactivations can be accurately modelled by sparse linear combinations of\nfeatures, significantly more so than control datasets. We also show that model\nactivations appear to be sparsest in the first and final layers.",
          "link": "http://arxiv.org/abs/2310.07837",
          "publishedOn": "2023-10-14T00:41:34.930Z",
          "wordCount": null,
          "title": "Measuring Feature Sparsity in Language Models. (arXiv:2310.07837v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhengxiang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipani_A/0/1/0/all/0/1\">Aldo Lipani</a>",
          "description": "Prompt tuning (PT), where a small amount of trainable soft (continuous)\nprompt vectors is affixed to the input of language models (LM), has shown\npromising results across various tasks and models for parameter-efficient\nfine-tuning (PEFT). PT stands out from other PEFT approaches because it\nmaintains competitive performance with fewer trainable parameters and does not\ndrastically scale up its parameters as the model size expands. However, PT\nintroduces additional soft prompt tokens, leading to longer input sequences,\nwhich significantly impacts training and inference time and memory usage due to\nthe Transformer's quadratic complexity. Particularly concerning for Large\nLanguage Models (LLMs) that face heavy daily querying. To address this issue,\nwe propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt\ninto a shorter soft prompt and a pair of low-rank matrices that are then\noptimised with two different learning rates. This allows DePT to achieve better\nperformance while saving over 20% memory and time costs compared to vanilla PT\nand its variants, without changing trainable parameter sizes. Through extensive\nexperiments on 23 natural language processing (NLP) and vision-language (VL)\ntasks, we demonstrate that DePT outperforms state-of-the-art PEFT approaches,\nincluding the full fine-tuning baseline in some scenarios. Additionally, we\nempirically show that DEPT grows more efficient as the model size increases.\nOur further study reveals that DePT integrates seamlessly with\nparameter-efficient transfer learning in the few-shot learning setting and\nhighlights its adaptability to various model architectures and sizes.",
          "link": "http://arxiv.org/abs/2309.05173",
          "publishedOn": "2023-10-14T00:41:34.930Z",
          "wordCount": null,
          "title": "DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning. (arXiv:2309.05173v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.00327",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dirksen_S/0/1/0/all/0/1\">Sjoerd Dirksen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Finke_P/0/1/0/all/0/1\">Patrick Finke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Genzel_M/0/1/0/all/0/1\">Martin Genzel</a>",
          "description": "In practice, deep neural networks are often able to easily interpolate their\ntraining data. To understand this phenomenon, many works have aimed to quantify\nthe memorization capacity of a neural network architecture: the largest number\nof points such that the architecture can interpolate any placement of these\npoints with any assignment of labels. For real-world data, however, one\nintuitively expects the presence of a benign structure so that interpolation\nalready occurs at a smaller network size than suggested by memorization\ncapacity. In this paper, we investigate interpolation by adopting an\ninstance-specific viewpoint. We introduce a simple randomized algorithm that,\ngiven a fixed finite dataset with two classes, with high probability constructs\nan interpolating three-layer neural network in polynomial time. The required\nnumber of parameters is linked to geometric properties of the two classes and\ntheir mutual arrangement. As a result, we obtain guarantees that are\nindependent of the number of samples and hence move beyond worst-case\nmemorization capacity bounds. We illustrate the effectiveness of the algorithm\nin non-pathological situations with extensive numerical experiments and link\nthe insights back to the theoretical results.",
          "link": "http://arxiv.org/abs/2310.00327",
          "publishedOn": "2023-10-14T00:41:34.924Z",
          "wordCount": null,
          "title": "Memorization with neural nets: going beyond the worst case. (arXiv:2310.00327v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Ze Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1\">Lei Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yinghuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "A recent empirical observation (Li et al., 2022b) of activation sparsity in\nMLP blocks offers an opportunity to drastically reduce computation costs for\nfree. Although having attributed it to training dynamics, existing theoretical\nexplanations of activation sparsity are restricted to shallow networks, small\ntraining steps and special training, despite its emergence in deep models\nstandardly trained for a large number of steps. To fill these gaps, we propose\nthe notion of gradient sparsity as one source of activation sparsity and a\ntheoretical explanation based on it that sees sparsity a necessary step to\nadversarial robustness w.r.t. hidden features and parameters, which is\napproximately the flatness of minima for well-learned models. The theory\napplies to standardly trained LayerNorm-ed MLPs, and further to Transformers or\nother architectures trained with weight noises. Eliminating other sources of\nflatness except for sparsity, we discover the phenomenon that the ratio between\nthe largest and smallest non-zero singular values of weight matrices is small.\nWhen discussing the emergence of this spectral concentration, we use random\nmatrix theory (RMT) as a powerful tool to analyze stochastic gradient noises.\nValidational experiments are conducted to verify our gradient-sparsity-based\nexplanation. We propose two plug-and-play modules for both training and\nfinetuning for sparsity. Experiments on ImageNet-1k and C4 demonstrate their\n50% sparsity improvements, indicating further potential cost reduction in both\ntraining and inference.",
          "link": "http://arxiv.org/abs/2309.03004",
          "publishedOn": "2023-10-14T00:41:34.918Z",
          "wordCount": null,
          "title": "A Theoretical Explanation of Activation Sparsity through Flat Minima and Adversarial Robustness. (arXiv:2309.03004v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07987",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wensheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yuna Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lixin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_T/0/1/0/all/0/1\">Tad Matsumoto</a>",
          "description": "This letter proposes a novel relaying framework, semantic-forward (SF), for\ncooperative communications towards the sixth-generation (6G) wireless networks.\nThe SF relay extracts and transmits the semantic features, which reduces\nforwarding payload, and also improves the network robustness against intra-link\nerrors. Based on the theoretical basis for cooperative communications with side\ninformation and the turbo principle, we design a joint source-channel coding\nalgorithm to iteratively exchange the extrinsic information for enhancing the\ndecoding gains at the destination. Surprisingly, simulation results indicate\nthat even in bad channel conditions, SF relaying can still effectively improve\nthe recovered information quality.",
          "link": "http://arxiv.org/abs/2310.07987",
          "publishedOn": "2023-10-14T00:41:34.917Z",
          "wordCount": null,
          "title": "Semantic-Forward Relaying: A Novel Framework Towards 6G Cooperative Communications. (arXiv:2310.07987v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.15363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xutan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jingfeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevenson_M/0/1/0/all/0/1\">Mark Stevenson</a>",
          "description": "Although it has been demonstrated that Natural Language Processing (NLP)\nalgorithms are vulnerable to deliberate attacks, the question of whether such\nweaknesses can lead to software security threats is under-explored. To bridge\nthis gap, we conducted vulnerability tests on Text-to-SQL systems that are\ncommonly used to create natural language interfaces to databases. We showed\nthat the Text-to-SQL modules within six commercial applications can be\nmanipulated to produce malicious code, potentially leading to data breaches and\nDenial of Service attacks. This is the first demonstration that NLP models can\nbe exploited as attack vectors in the wild. In addition, experiments using four\nopen-source language models verified that straightforward backdoor attacks on\nText-to-SQL systems achieve a 100% success rate without affecting their\nperformance. The aim of this work is to draw the community's attention to\npotential software security issues associated with NLP algorithms and encourage\nexploration of methods to mitigate against them.",
          "link": "http://arxiv.org/abs/2211.15363",
          "publishedOn": "2023-10-14T00:41:34.914Z",
          "wordCount": null,
          "title": "On the Security Vulnerabilities of Text-to-SQL Models. (arXiv:2211.15363v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingyun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>",
          "description": "Literature-Based Discovery (LBD) aims to discover new scientific knowledge by\nmining papers and generating hypotheses. Standard LBD is limited to predicting\npairwise relations between discrete concepts (e.g., drug-disease links), and\nignores critical contexts like experimental settings (e.g., a specific patient\npopulation where a drug is evaluated) and background motivations (e.g., to find\ndrugs without specific side effects). We address these limitations with a novel\nformulation of contextualized-LBD (C-LBD): generating scientific hypotheses in\nnatural language, while grounding them in a context that controls the\nhypothesis search space. We present a modeling framework using retrieval of\n``inspirations'' from past scientific papers. Our evaluations reveal that GPT-4\ntends to generate ideas with overall low technical depth and novelty, while our\ninspiration prompting approaches partially mitigate this issue. Our work\nrepresents a first step toward building language models that generate new ideas\nderived from scientific literature.",
          "link": "http://arxiv.org/abs/2305.14259",
          "publishedOn": "2023-10-14T00:41:34.913Z",
          "wordCount": 693,
          "title": "Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery. (arXiv:2305.14259v3 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frati_L/0/1/0/all/0/1\">Lapo Frati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Traft_N/0/1/0/all/0/1\">Neil Traft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1\">Jeff Clune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheney_N/0/1/0/all/0/1\">Nick Cheney</a>",
          "description": "This work identifies a simple pre-training mechanism that leads to\nrepresentations exhibiting better continual and transfer learning. This\nmechanism -- the repeated resetting of weights in the last layer, which we\nnickname \"zapping\" -- was originally designed for a meta-continual-learning\nprocedure, yet we show it is surprisingly applicable in many settings beyond\nboth meta-learning and continual learning. In our experiments, we wish to\ntransfer a pre-trained image classifier to a new set of classes, in a few\nshots. We show that our zapping procedure results in improved transfer accuracy\nand/or more rapid adaptation in both standard fine-tuning and continual\nlearning settings, while being simple to implement and computationally\nefficient. In many cases, we achieve performance on par with state of the art\nmeta-learning without needing the expensive higher-order gradients, by using a\ncombination of zapping and sequential learning. An intuitive explanation for\nthe effectiveness of this zapping procedure is that representations trained\nwith repeated zapping learn features that are capable of rapidly adapting to\nnewly initialized classifiers. Such an approach may be considered a\ncomputationally cheaper type of, or alternative to, meta-learning rapidly\nadaptable features with higher-order gradients. This adds to recent work on the\nusefulness of resetting neural network parameters during training, and invites\nfurther investigation of this mechanism.",
          "link": "http://arxiv.org/abs/2310.07996",
          "publishedOn": "2023-10-14T00:41:34.903Z",
          "wordCount": null,
          "title": "Reset It and Forget It: Relearning Last-Layer Weights Improves Continual and Transfer Learning. (arXiv:2310.07996v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mentzer_F/0/1/0/all/0/1\">Fabian Mentzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minnen_D/0/1/0/all/0/1\">David Minnen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agustsson_E/0/1/0/all/0/1\">Eirikur Agustsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tschannen_M/0/1/0/all/0/1\">Michael Tschannen</a>",
          "description": "We propose to replace vector quantization (VQ) in the latent representation\nof VQ-VAEs with a simple scheme termed finite scalar quantization (FSQ), where\nwe project the VAE representation down to a few dimensions (typically less than\n10). Each dimension is quantized to a small set of fixed values, leading to an\n(implicit) codebook given by the product of these sets. By appropriately\nchoosing the number of dimensions and values each dimension can take, we obtain\nthe same codebook size as in VQ. On top of such discrete representations, we\ncan train the same models that have been trained on VQ-VAE representations. For\nexample, autoregressive and masked transformer models for image generation,\nmultimodal generation, and dense prediction computer vision tasks. Concretely,\nwe employ FSQ with MaskGIT for image generation, and with UViM for depth\nestimation, colorization, and panoptic segmentation. Despite the much simpler\ndesign of FSQ, we obtain competitive performance in all these tasks. We\nemphasize that FSQ does not suffer from codebook collapse and does not need the\ncomplex machinery employed in VQ (commitment losses, codebook reseeding, code\nsplitting, entropy penalties, etc.) to learn expressive discrete\nrepresentations.",
          "link": "http://arxiv.org/abs/2309.15505",
          "publishedOn": "2023-10-14T00:41:34.902Z",
          "wordCount": null,
          "title": "Finite Scalar Quantization: VQ-VAE Made Simple. (arXiv:2309.15505v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08337",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bartosh_G/0/1/0/all/0/1\">Grigory Bartosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naesseth_C/0/1/0/all/0/1\">Christian A. Naesseth</a>",
          "description": "Diffusion models have shown remarkable performance on many generative tasks.\nDespite recent success, most diffusion models are restricted in that they only\nallow linear transformation of the data distribution. In contrast, broader\nfamily of transformations can potentially help train generative distributions\nmore efficiently, simplifying the reverse process and closing the gap between\nthe true negative log-likelihood and the variational approximation. In this\npaper, we present Neural Diffusion Models (NDMs), a generalization of\nconventional diffusion models that enables defining and learning time-dependent\nnon-linear transformations of data. We show how to optimise NDMs using a\nvariational bound in a simulation-free setting. Moreover, we derive a\ntime-continuous formulation of NDMs, which allows fast and reliable inference\nusing off-the-shelf numerical ODE and SDE solvers. Finally, we demonstrate the\nutility of NDMs with learnable transformations through experiments on standard\nimage generation benchmarks, including CIFAR-10, downsampled versions of\nImageNet and CelebA-HQ. NDMs outperform conventional diffusion models in terms\nof likelihood and produce high-quality samples.",
          "link": "http://arxiv.org/abs/2310.08337",
          "publishedOn": "2023-10-14T00:41:34.899Z",
          "wordCount": null,
          "title": "Neural Diffusion Models. (arXiv:2310.08337v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Ju Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_T/0/1/0/all/0/1\">Ting Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hei_F/0/1/0/all/0/1\">Falun Hei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zhemei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yunfeng Luo</a>",
          "description": "Counterfactual Regret Minimization (CFR) and its variants are the best\nalgorithms so far for solving large-scale incomplete information games.\nHowever, we believe that there are two problems with CFR: First, matrix\nmultiplication is required in CFR iteration, and the time complexity of one\niteration is too high; Secondly, the game characteristics in the real world are\ndifferent. Just using one CFR algorithm will not be perfectly suitable for all\ngame problems.\n\nFor these two problems, this paper proposes a new algorithm called Pure CFR\n(PCFR) based on CFR. PCFR can be seen as a combination of CFR and Fictitious\nPlay (FP), inheriting the concept of counterfactual regret (value) from CFR,\nand using the best response strategy instead of the regret matching strategy\nfor the next iteration. This algorithm has three advantages. First, PCFR can be\ncombined with any CFR variant. The resulting Pure MCCFR (PMCCFR) can\nsignificantly reduce the time and space complexity of one iteration. Secondly,\nour experiments show that the convergence speed of the PMCCFR is 2$\\sim$3 times\nthat of the MCCFR. Finally, there is a type of game that is very suitable for\nPCFR, we call this type of game clear-game, which is characterized by a high\nproportion of dominated strategies. Experiments show that in clear-game, the\nconvergence rate of PMCCFR is two orders of magnitude higher than that of\nMCCFR.",
          "link": "http://arxiv.org/abs/2309.03084",
          "publishedOn": "2023-10-14T00:41:34.897Z",
          "wordCount": null,
          "title": "Pure Monte Carlo Counterfactual Regret Minimization. (arXiv:2309.03084v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08087",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Barbieri_L/0/1/0/all/0/1\">Luca Barbieri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Savazzi_S/0/1/0/all/0/1\">Stefano Savazzi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kianoush_S/0/1/0/all/0/1\">Sanaz Kianoush</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nicoli_M/0/1/0/all/0/1\">Monica Nicoli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Serio_L/0/1/0/all/0/1\">Luigi Serio</a>",
          "description": "Federated Learning (FL) methods adopt efficient communication technologies to\ndistribute machine learning tasks across edge devices, reducing the overhead in\nterms of data storage and computational complexity compared to centralized\nsolutions. Rather than moving large data volumes from producers (sensors,\nmachines) to energy-hungry data centers, raising environmental concerns due to\nresource demands, FL provides an alternative solution to mitigate the energy\ndemands of several learning tasks while enabling new Artificial Intelligence of\nThings (AIoT) applications. This paper proposes a framework for real-time\nmonitoring of the energy and carbon footprint impacts of FL systems. The carbon\ntracking tool is evaluated for consensus (fully decentralized) and classical FL\npolicies. For the first time, we present a quantitative evaluation of different\ncomputationally and communication efficient FL methods from the perspectives of\nenergy consumption and carbon equivalent emissions, suggesting also general\nguidelines for energy-efficient design. Results indicate that consensus-driven\nFL implementations should be preferred for limiting carbon emissions when the\nenergy efficiency of the communication is low (i.e., < 25 Kbit/Joule). Besides,\nquantization and sparsification operations are shown to strike a balance\nbetween learning performances and energy consumption, leading to sustainable FL\ndesigns.",
          "link": "http://arxiv.org/abs/2310.08087",
          "publishedOn": "2023-10-14T00:41:34.881Z",
          "wordCount": null,
          "title": "A Carbon Tracking Model for Federated Learning: Impact of Quantization and Sparsification. (arXiv:2310.08087v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Palmer_G/0/1/0/all/0/1\">Gregory Palmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parry_C/0/1/0/all/0/1\">Chris Parry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harrold_D/0/1/0/all/0/1\">Daniel J.B. Harrold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willis_C/0/1/0/all/0/1\">Chris Willis</a>",
          "description": "The rapid increase in the number of cyber-attacks in recent years raises the\nneed for principled methods for defending networks against malicious actors.\nDeep reinforcement learning (DRL) has emerged as a promising approach for\nmitigating these attacks. However, while DRL has shown much potential for\ncyber-defence, numerous challenges must be overcome before DRL can be applied\nto autonomous cyber-operations (ACO) at scale. Principled methods are required\nfor environments that confront learners with very high-dimensional state\nspaces, large multi-discrete action spaces, and adversarial learning. Recent\nworks have reported success in solving these problems individually. There have\nalso been impressive engineering efforts towards solving all three for\nreal-time strategy games. However, applying DRL to the full ACO problem remains\nan open challenge. Here, we survey the relevant DRL literature and\nconceptualize an idealised ACO-DRL agent. We provide: i.) A summary of the\ndomain properties that define the ACO problem; ii.) A comprehensive evaluation\nof the extent to which domains used for benchmarking DRL approaches are\ncomparable to ACO; iii.) An overview of state-of-the-art approaches for scaling\nDRL to domains that confront learners with the curse of dimensionality, and;\niv.) A survey and critique of current methods for limiting the exploitability\nof agents within adversarial settings from the perspective of ACO. We conclude\nwith open research questions that we hope will motivate future directions for\nresearchers and practitioners working on ACO.",
          "link": "http://arxiv.org/abs/2310.07745",
          "publishedOn": "2023-10-14T00:41:34.879Z",
          "wordCount": null,
          "title": "Deep Reinforcement Learning for Autonomous Cyber Operations: A Survey. (arXiv:2310.07745v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qingyue Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Banghua Zhu</a>",
          "description": "We characterize the statistical efficiency of knowledge transfer through $n$\nsamples from a teacher to a probabilistic student classifier with input space\n$\\mathcal S$ over labels $\\mathcal A$. We show that privileged information at\nthree progressive levels accelerates the transfer. At the first level, only\nsamples with hard labels are known, via which the maximum likelihood estimator\nattains the minimax rate $\\sqrt{{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. The\nsecond level has the teacher probabilities of sampled labels available in\naddition, which turns out to boost the convergence rate lower bound to\n${{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. However, under this second data\nacquisition protocol, minimizing a naive adaptation of the cross-entropy loss\nresults in an asymptotically biased student. We overcome this limitation and\nachieve the fundamental limit by using a novel empirical variant of the squared\nerror logit loss. The third level further equips the student with the soft\nlabels (complete logits) on ${\\mathcal A}$ given every sampled input, thereby\nprovably enables the student to enjoy a rate ${|{\\mathcal S}|}/{n}$ free of\n$|{\\mathcal A}|$. We find any Kullback-Leibler divergence minimizer to be\noptimal in the last case. Numerical simulations distinguish the four learners\nand corroborate our theory.",
          "link": "http://arxiv.org/abs/2310.07838",
          "publishedOn": "2023-10-14T00:41:34.876Z",
          "wordCount": null,
          "title": "Towards the Fundamental Limits of Knowledge Transfer over Finite Domains. (arXiv:2310.07838v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03486",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Seungyong Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeom_J/0/1/0/all/0/1\">Junyoung Yeom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1\">Bumsoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hyun Oh Song</a>",
          "description": "Discovering achievements with a hierarchical structure in procedurally\ngenerated environments presents a significant challenge. This requires an agent\nto possess a broad range of abilities, including generalization and long-term\nreasoning. Many prior methods have been built upon model-based or hierarchical\napproaches, with the belief that an explicit module for long-term planning\nwould be advantageous for learning hierarchical dependencies. However, these\nmethods demand an excessive number of environment interactions or large model\nsizes, limiting their practicality. In this work, we demonstrate that proximal\npolicy optimization (PPO), a simple yet versatile model-free algorithm,\noutperforms previous methods when optimized with recent implementation\npractices. Moreover, we find that the PPO agent can predict the next\nachievement to be unlocked to some extent, albeit with limited confidence.\nBased on this observation, we introduce a novel contrastive learning method,\ncalled achievement distillation, which strengthens the agent's ability to\npredict the next achievement. Our method exhibits a strong capacity for\ndiscovering hierarchical achievements and shows state-of-the-art performance on\nthe challenging Crafter environment in a sample-efficient manner while\nutilizing fewer model parameters.",
          "link": "http://arxiv.org/abs/2307.03486",
          "publishedOn": "2023-10-14T00:41:34.876Z",
          "wordCount": null,
          "title": "Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning. (arXiv:2307.03486v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08209",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cholaquidis_A/0/1/0/all/0/1\">Alejandro Cholaquidis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gamboa_F/0/1/0/all/0/1\">Fabrice Gamboa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moreno_L/0/1/0/all/0/1\">Leonardo Moreno</a>",
          "description": "Regression on manifolds, and, more broadly, statistics on manifolds, has\ngarnered significant importance in recent years due to the vast number of\napplications for this type of data. Circular data is a classic example, but so\nis data in the space of covariance matrices, data on the Grassmannian manifold\nobtained as a result of principal component analysis, among many others. In\nthis work we investigate prediction sets for regression scenarios when the\nresponse variable, denoted by $Y$, resides in a manifold, and the covariable,\ndenoted by X, lies in Euclidean space. This extends the concepts delineated in\n[Lei and Wasserman, 2014] to this novel context. Aligning with traditional\nprinciples in conformal inference, these prediction sets are distribution-free,\nindicating that no specific assumptions are imposed on the joint distribution\nof $(X, Y)$, and they maintain a non-parametric character. We prove the\nasymptotic almost sure convergence of the empirical version of these regions on\nthe manifold to their population counterparts. The efficiency of this method is\nshown through a comprehensive simulation study and an analysis involving\nreal-world data.",
          "link": "http://arxiv.org/abs/2310.08209",
          "publishedOn": "2023-10-14T00:41:34.874Z",
          "wordCount": null,
          "title": "Conformal inference for regression on Riemannian Manifolds. (arXiv:2310.08209v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.04413",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_Z/0/1/0/all/0/1\">Zhang-Wei Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Aviral Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnik_S/0/1/0/all/0/1\">Sathwik Karnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhandwaldar_A/0/1/0/all/0/1\">Abhishek Bhandwaldar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1\">Akash Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1\">Joni Pajarinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laroche_R/0/1/0/all/0/1\">Romain Laroche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhishek Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Pulkit Agrawal</a>",
          "description": "Offline policy learning is aimed at learning decision-making policies using\nexisting datasets of trajectories without collecting additional data. The\nprimary motivation for using reinforcement learning (RL) instead of supervised\nlearning techniques such as behavior cloning is to find a policy that achieves\na higher average return than the trajectories constituting the dataset.\nHowever, we empirically find that when a dataset is dominated by suboptimal\ntrajectories, state-of-the-art offline RL algorithms do not substantially\nimprove over the average return of trajectories in the dataset. We argue this\nis due to an assumption made by current offline RL algorithms of staying close\nto the trajectories in the dataset. If the dataset primarily consists of\nsub-optimal trajectories, this assumption forces the policy to mimic the\nsuboptimal actions. We overcome this issue by proposing a sampling strategy\nthat enables the policy to only be constrained to ``good data\" rather than all\nactions in the dataset (i.e., uniform sampling). We present a realization of\nthe sampling strategy and an algorithm that can be used as a plug-and-play\nmodule in standard offline RL algorithms. Our evaluation demonstrates\nsignificant performance gains in 72 imbalanced datasets, D4RL dataset, and\nacross three different offline RL algorithms. Code is available at\nhttps://github.com/Improbable-AI/dw-offline-rl.",
          "link": "http://arxiv.org/abs/2310.04413",
          "publishedOn": "2023-10-14T00:41:34.867Z",
          "wordCount": null,
          "title": "Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets. (arXiv:2310.04413v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.03770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hanlin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy Zhang</a>",
          "description": "Goal-conditioned reinforcement learning (GCRL) refers to learning\ngeneral-purpose skills that aim to reach diverse goals. In particular, offline\nGCRL only requires purely pre-collected datasets to perform training tasks\nwithout additional interactions with the environment. Although offline GCRL has\nbecome increasingly prevalent and many previous works have demonstrated its\nempirical success, the theoretical understanding of efficient offline GCRL\nalgorithms is not well established, especially when the state space is huge and\nthe offline dataset only covers the policy we aim to learn. In this paper, we\nprovide a rigorous theoretical analysis of an existing empirically successful\noffline GCRL algorithm. We prove that under slight modification, this algorithm\nenjoys an $\\widetilde{O}(\\text{poly}(1/\\epsilon))$ sample complexity (where\n$\\epsilon$ is the desired suboptimality of the learned policy) with general\nfunction approximation thanks to the property of (semi-)strong convexity of the\nobjective functions. We only require nearly minimal assumptions on the dataset\n(single-policy concentrability) and the function class (realizability).\nMoreover, this algorithm consists of two uninterleaved optimization steps,\nwhich we refer to as $V$-learning and policy learning, and is computationally\nstable since it does not involve minimax optimization. We also empirically\nvalidate our theory by showing that the modified algorithm outperforms the\nprevious algorithm in various real-world environments. To the best of our\nknowledge, this is the first algorithm that is both provably efficient with\ngeneral function approximation and single-policy concentrability, and\nempirically successful without requiring solving minimax optimization problems.",
          "link": "http://arxiv.org/abs/2302.03770",
          "publishedOn": "2023-10-14T00:41:34.866Z",
          "wordCount": 778,
          "title": "Provably Efficient Offline Goal-Conditioned Reinforcement Learning with General Function Approximation and Single-Policy Concentrability. (arXiv:2302.03770v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.12461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamparth_M/0/1/0/all/0/1\">Max Lamparth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reuel_A/0/1/0/all/0/1\">Anka Reuel</a>",
          "description": "Poisoning of data sets is a potential security threat to large language\nmodels that can lead to backdoored models. A description of the internal\nmechanisms of backdoored language models and how they process trigger inputs,\ne.g., when switching to toxic language, has yet to be found. In this work, we\nstudy the internal representations of transformer-based backdoored language\nmodels and determine early-layer MLP modules as most important for the backdoor\nmechanism in combination with the initial embedding projection. We use this\nknowledge to remove, insert, and modify backdoor mechanisms with engineered\nreplacements that reduce the MLP module outputs to essentials for the backdoor\nmechanism. To this end, we introduce PCP ablation, where we replace transformer\nmodules with low-rank matrices based on the principal components of their\nactivations. We demonstrate our results on backdoored toy, backdoored large,\nand non-backdoored open-source models. We show that we can improve the backdoor\nrobustness of large language models by locally constraining individual modules\nduring fine-tuning on potentially poisonous data sets.\n\nTrigger warning: Offensive language.",
          "link": "http://arxiv.org/abs/2302.12461",
          "publishedOn": "2023-10-14T00:41:34.858Z",
          "wordCount": null,
          "title": "Analyzing And Editing Inner Mechanisms Of Backdoored Language Models. (arXiv:2302.12461v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07427",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhengmeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hai Lin</a>",
          "description": "We propose a time series forecasting method named Quantum Gramian Angular\nField (QGAF). This approach merges the advantages of quantum computing\ntechnology with deep learning, aiming to enhance the precision of time series\nclassification and forecasting. We successfully transformed stock return time\nseries data into two-dimensional images suitable for Convolutional Neural\nNetwork (CNN) training by designing specific quantum circuits. Distinct from\nthe classical Gramian Angular Field (GAF) approach, QGAF's uniqueness lies in\neliminating the need for data normalization and inverse cosine calculations,\nsimplifying the transformation process from time series data to two-dimensional\nimages. To validate the effectiveness of this method, we conducted experiments\non datasets from three major stock markets: the China A-share market, the Hong\nKong stock market, and the US stock market. Experimental results revealed that\ncompared to the classical GAF method, the QGAF approach significantly improved\ntime series prediction accuracy, reducing prediction errors by an average of\n25% for Mean Absolute Error (MAE) and 48% for Mean Squared Error (MSE). This\nresearch confirms the potential and promising prospects of integrating quantum\ncomputing with deep learning techniques in financial time series forecasting.",
          "link": "http://arxiv.org/abs/2310.07427",
          "publishedOn": "2023-10-14T00:41:34.853Z",
          "wordCount": null,
          "title": "Quantum-Enhanced Forecasting: Leveraging Quantum Gramian Angular Field and CNNs for Stock Return Predictions. (arXiv:2310.07427v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deuschel_J/0/1/0/all/0/1\">Jannik Deuschel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellington_C/0/1/0/all/0/1\">Caleb N. Ellington</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lengerich_B/0/1/0/all/0/1\">Benjamin J. Lengerich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yingtao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friederich_P/0/1/0/all/0/1\">Pascal Friederich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>",
          "description": "Interpretable policy learning seeks to estimate intelligible decision\npolicies from observed actions; however, existing models fall short by forcing\na tradeoff between accuracy and interpretability. This tradeoff limits\ndata-driven interpretations of human decision-making process. e.g. to audit\nmedical decisions for biases and suboptimal practices, we require models of\ndecision processes which provide concise descriptions of complex behaviors.\nFundamentally, existing approaches are burdened by this tradeoff because they\nrepresent the underlying decision process as a universal policy, when in fact\nhuman decisions are dynamic and can change drastically with contextual\ninformation. Thus, we propose Contextualized Policy Recovery (CPR), which\nre-frames the problem of modeling complex decision processes as a multi-task\nlearning problem in which complex decision policies are comprised of\ncontext-specific policies. CPR models each context-specific policy as a linear\nobservation-to-action mapping, and generates new decision models\n$\\textit{on-demand}$ as contexts are updated with new observations. CPR is\ncompatible with fully offline and partially observable decision environments,\nand can be tailored to incorporate any recurrent black-box model or\ninterpretable decision model. We assess CPR through studies on simulated and\nreal data, achieving state-of-the-art performance on the canonical tasks of\npredicting antibiotic prescription in intensive care units ($+22\\%$ AUROC vs.\nprevious SOTA) and predicting MRI prescription for Alzheimer's patients\n($+7.7\\%$ AUROC vs. previous SOTA). With this improvement in predictive\nperformance, CPR closes the accuracy gap between interpretable and black-box\nmethods for policy learning, allowing high-resolution exploration and analysis\nof context-specific decision models.",
          "link": "http://arxiv.org/abs/2310.07918",
          "publishedOn": "2023-10-14T00:41:34.845Z",
          "wordCount": null,
          "title": "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning. (arXiv:2310.07918v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07402",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenguo Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xumeng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_W/0/1/0/all/0/1\">Wei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Congrui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Stephen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhirong Wu</a>",
          "description": "Recent research on time-series self-supervised models shows great promise in\nlearning semantic representations. However, it has been limited to small-scale\ndatasets, e.g., thousands of temporal sequences. In this work, we make key\ntechnical contributions that are tailored to the numerical properties of\ntime-series data and allow the model to scale to large datasets, e.g., millions\nof temporal sequences. We adopt the Transformer architecture by first\npartitioning the input into non-overlapping windows. Each window is then\ncharacterized by its normalized shape and two scalar values denoting the mean\nand standard deviation within each window. To embed scalar values that may\npossess arbitrary numerical scales to high-dimensional vectors, we propose a\nnumerically multi-scaled embedding module enumerating all possible scales for\nthe scalar values. The model undergoes pretraining using the proposed\nnumerically multi-scaled embedding with a simple contrastive objective on a\nlarge-scale dataset containing over a million sequences. We study its transfer\nperformance on a number of univariate and multivariate classification\nbenchmarks. Our method exhibits remarkable improvement against previous\nrepresentation learning approaches and establishes the new state of the art,\neven compared with domain-specific non-learning-based methods.",
          "link": "http://arxiv.org/abs/2310.07402",
          "publishedOn": "2023-10-14T00:41:34.831Z",
          "wordCount": null,
          "title": "NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series Pretraining. (arXiv:2310.07402v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.09222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Ziqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuntao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianguo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1\">Junliang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1\">Shwetak Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuanchun Shi</a>",
          "description": "Multimodal sensors provide complementary information to develop accurate\nmachine-learning methods for human activity recognition (HAR), but introduce\nsignificantly higher computational load, which reduces efficiency. This paper\nproposes an efficient multimodal neural architecture for HAR using an RGB\ncamera and inertial measurement units (IMUs) called Multimodal Temporal Segment\nAttention Network (MMTSA). MMTSA first transforms IMU sensor data into a\ntemporal and structure-preserving gray-scale image using the Gramian Angular\nField (GAF), representing the inherent properties of human activities. MMTSA\nthen applies a multimodal sparse sampling method to reduce data redundancy.\nLastly, MMTSA adopts an inter-segment attention module for efficient multimodal\nfusion. Using three well-established public datasets, we evaluated MMTSA's\neffectiveness and efficiency in HAR. Results show that our method achieves\nsuperior performance improvements 11.13% of cross-subject F1-score on the MMAct\ndataset than the previous state-of-the-art (SOTA) methods. The ablation study\nand analysis suggest that MMTSA's effectiveness in fusing multimodal data for\naccurate HAR. The efficiency evaluation on an edge device showed that MMTSA\nachieved significantly better accuracy, lower computational load, and lower\ninference latency than SOTA methods.",
          "link": "http://arxiv.org/abs/2210.09222",
          "publishedOn": "2023-10-14T00:41:34.795Z",
          "wordCount": 713,
          "title": "MMTSA: Multimodal Temporal Segment Attention Network for Efficient Human Activity Recognition. (arXiv:2210.09222v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuang_W/0/1/0/all/0/1\">Weijie Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_H/0/1/0/all/0/1\">Hann Woei Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Ye Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suandi_S/0/1/0/all/0/1\">Shahrel Azmin Suandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ismail_F/0/1/0/all/0/1\">Farzad Ismail</a>",
          "description": "Unmanned Aerial Vehicles (UAVs) are considered cutting-edge technology with\nhighly cost-effective and flexible usage scenarios. Although many papers have\nreviewed the application of UAVs in agriculture, the review of the application\nfor tree detection is still insufficient. This paper focuses on tree detection\nmethods applied to UAV data collected by UAVs. There are two kinds of data, the\npoint cloud and the images, which are acquired by the Light Detection and\nRanging (LiDAR) sensor and camera, respectively. Among the detection methods\nusing point-cloud data, this paper mainly classifies these methods according to\nLiDAR and Digital Aerial Photography (DAP). For the detection methods using\nimages directly, this paper reviews these methods by whether or not to use the\nDeep Learning (DL) method. Our review concludes and analyses the comparison and\ncombination between the application of LiDAR-based and DAP-based point cloud\ndata. The performance, relative merits, and application fields of the methods\nare also introduced. Meanwhile, this review counts the number of tree detection\nstudies using different methods in recent years. From our statics, the\ndetection task using DL methods on the image has become a mainstream trend as\nthe number of DL-based detection researches increases to 45% of the total\nnumber of tree detection studies up to 2022. As a result, this review could\nhelp and guide researchers who want to carry out tree detection on specific\nforests and for farmers to use UAVs in managing agriculture production.",
          "link": "http://arxiv.org/abs/2309.16375",
          "publishedOn": "2023-10-14T00:41:34.696Z",
          "wordCount": null,
          "title": "A Comprehensive Review on Tree Detection Methods Using Point Cloud and Aerial Imagery from Unmanned Aerial Vehicles. (arXiv:2309.16375v2 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahabadi_S/0/1/0/all/0/1\">Sepideh Mahabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trajanovski_S/0/1/0/all/0/1\">Stojan Trajanovski</a>",
          "description": "We study core-set construction algorithms for the task of Diversity\nMaximization under fairness/partition constraint. Given a set of points $P$ in\na metric space partitioned into $m$ groups, and given $k_1,\\ldots,k_m$, the\ngoal of this problem is to pick $k_i$ points from each group $i$ such that the\noverall diversity of the $k=\\sum_i k_i$ picked points is maximized. We consider\ntwo natural diversity measures: sum-of-pairwise distances and\nsum-of-nearest-neighbor distances, and show improved core-set construction\nalgorithms with respect to these measures. More precisely, we show the first\nconstant factor core-set w.r.t. sum-of-pairwise distances whose size is\nindependent of the size of the dataset and the aspect ratio. Second, we show\nthe first core-set w.r.t. the sum-of-nearest-neighbor distances. Finally, we\nrun several experiments showing the effectiveness of our core-set approach. In\nparticular, we apply constrained diversity maximization to summarize a set of\ntimed messages that takes into account the messages' recency. Specifically, the\nsummary should include more recent messages compared to older ones. This is a\nreal task in one of the largest communication platforms, affecting the\nexperience of hundreds of millions daily active users. By utilizing our\ncore-set method for this task, we achieve a 100x speed-up while losing the\ndiversity by only a few percent. Moreover, our approach allows us to improve\nthe space usage of the algorithm in the streaming setting.",
          "link": "http://arxiv.org/abs/2310.08122",
          "publishedOn": "2023-10-14T00:41:34.453Z",
          "wordCount": null,
          "title": "Core-sets for Fair and Diverse Data Summarization. (arXiv:2310.08122v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zeyuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hongshu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiacheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenrui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_G/0/1/0/all/0/1\">Guojun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yue-Jiao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yining Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Zhiguang Cao</a>",
          "description": "Recently, Meta-Black-Box Optimization with Reinforcement Learning\n(MetaBBO-RL) has showcased the power of leveraging RL at the meta-level to\nmitigate manual fine-tuning of low-level black-box optimizers. However, this\nfield is hindered by the lack of a unified benchmark. To fill this gap, we\nintroduce MetaBox, the first benchmark platform expressly tailored for\ndeveloping and evaluating MetaBBO-RL methods. MetaBox offers a flexible\nalgorithmic template that allows users to effortlessly implement their unique\ndesigns within the platform. Moreover, it provides a broad spectrum of over 300\nproblem instances, collected from synthetic to realistic scenarios, and an\nextensive library of 19 baseline methods, including both traditional black-box\noptimizers and recent MetaBBO-RL methods. Besides, MetaBox introduces three\nstandardized performance metrics, enabling a more thorough assessment of the\nmethods. In a bid to illustrate the utility of MetaBox for facilitating\nrigorous evaluation and in-depth analysis, we carry out a wide-ranging\nbenchmarking study on existing MetaBBO-RL methods. Our MetaBox is open-source\nand accessible at: https://github.com/GMC-DRL/MetaBox.",
          "link": "http://arxiv.org/abs/2310.08252",
          "publishedOn": "2023-10-14T00:41:34.444Z",
          "wordCount": null,
          "title": "MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning. (arXiv:2310.08252v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.09663",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Botvinick_Greenhouse_J/0/1/0/all/0/1\">Jonah Botvinick-Greenhouse</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1\">Yunan Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maulik_R/0/1/0/all/0/1\">Romit Maulik</a>",
          "description": "Motivated by the computational difficulties incurred by popular deep learning\nalgorithms for the generative modeling of temporal densities, we propose a\ncheap alternative which requires minimal hyperparameter tuning and scales\nfavorably to high dimensional problems. In particular, we use a\nprojection-based optimal transport solver [Meng et al., 2019] to join\nsuccessive samples and subsequently use transport splines [Chewi et al., 2020]\nto interpolate the evolving density. When the sampling frequency is\nsufficiently high, the optimal maps are close to the identity and are thus\ncomputationally efficient to compute. Moreover, the training process is highly\nparallelizable as all optimal maps are independent and can thus be learned\nsimultaneously. Finally, the approach is based solely on numerical linear\nalgebra rather than minimizing a nonconvex objective function, allowing us to\neasily analyze and control the algorithm. We present several numerical\nexperiments on both synthetic and real-world datasets to demonstrate the\nefficiency of our method. In particular, these experiments show that the\nproposed approach is highly competitive compared with state-of-the-art\nnormalizing flows conditioned on time across a wide range of dimensionalities.",
          "link": "http://arxiv.org/abs/2304.09663",
          "publishedOn": "2023-10-14T00:41:34.434Z",
          "wordCount": null,
          "title": "Generative modeling of time-dependent densities via optimal transport and projection pursuit. (arXiv:2304.09663v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.17823",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Okuno_A/0/1/0/all/0/1\">Akifumi Okuno</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Harada_K/0/1/0/all/0/1\">Kazuharu Harada</a>",
          "description": "This study proposes an interpretable neural network-based non-proportional\nodds model (N$^3$POM) for ordinal regression. N$^3$POM is different from\nconventional approaches to ordinal regression with non-proportional models in\nseveral ways: (1) N$^3$POM is designed to directly handle continuous responses,\nwhereas standard methods typically treat de facto ordered continuous variables\nas discrete, (2) instead of estimating response-dependent finite coefficients\nof linear models from discrete responses as is done in conventional approaches,\nwe train a non-linear neural network to serve as a coefficient function. Thanks\nto the neural network, N$^3$POM offers flexibility while preserving the\ninterpretability of conventional ordinal regression. We establish a sufficient\ncondition under which the predicted conditional cumulative probability locally\nsatisfies the monotonicity constraint over a user-specified region in the\ncovariate space. Additionally, we provide a monotonicity-preserving stochastic\n(MPS) algorithm for effectively training the neural network. We apply N$^3$POM\nto several real-world datasets.",
          "link": "http://arxiv.org/abs/2303.17823",
          "publishedOn": "2023-10-14T00:41:34.433Z",
          "wordCount": null,
          "title": "An interpretable neural network-based non-proportional odds model for ordinal regression. (arXiv:2303.17823v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.02931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Setlur_A/0/1/0/all/0/1\">Amrith Setlur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_D/0/1/0/all/0/1\">Don Dennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1\">Benjamin Eysenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghunathan_A/0/1/0/all/0/1\">Aditi Raghunathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1\">Virginia Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Training machine learning models robust to distribution shifts is critical\nfor real-world applications. Some robust training algorithms (e.g., Group DRO)\nspecialize to group shifts and require group information on all training\npoints. Other methods (e.g., CVaR DRO) that do not need group annotations can\nbe overly conservative, since they naively upweight high loss points which may\nform a contrived set that does not correspond to any meaningful group in the\nreal world (e.g., when the high loss points are randomly mislabeled training\npoints). In this work, we address limitations in prior approaches by assuming a\nmore nuanced form of group shift: conditioned on the label, we assume that the\ntrue group function (indicator over group) is simple. For example, we may\nexpect that group shifts occur along low bitrate features (e.g., image\nbackground, lighting). Thus, we aim to learn a model that maintains high\naccuracy on simple group functions realized by these low bitrate features, that\nneed not spend valuable model capacity achieving high accuracy on contrived\ngroups of examples. Based on this, we consider the two-player game formulation\nof DRO where the adversary's capacity is bitrate-constrained. Our resulting\npractical algorithm, Bitrate-Constrained DRO (BR-DRO), does not require group\ninformation on training samples yet matches the performance of Group DRO on\ndatasets that have training group annotations and that of CVaR DRO on\nlong-tailed distributions. Our theoretical analysis reveals that in some\nsettings BR-DRO objective can provably yield statistically efficient and less\nconservative solutions than unconstrained CVaR DRO.",
          "link": "http://arxiv.org/abs/2302.02931",
          "publishedOn": "2023-10-14T00:41:34.432Z",
          "wordCount": null,
          "title": "Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts. (arXiv:2302.02931v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nikpour_B/0/1/0/all/0/1\">Bahareh Nikpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armanfard_N/0/1/0/all/0/1\">Narges Armanfard</a>",
          "description": "Attention mechanisms have exhibited promising potential in enhancing learning\nmodels by identifying salient portions of input data. This is particularly\nvaluable in scenarios where limited training samples are accessible due to\nchallenges in data collection and labeling. Drawing inspiration from human\nrecognition processes, we posit that an AI baseline's performance could be more\naccurate and dependable if it is exposed to essential segments of raw data\nrather than the entire input dataset, akin to human perception. However, the\ntask of selecting these informative data segments, referred to as hard\nattention finding, presents a formidable challenge. In situations with few\ntraining samples, existing studies struggle to locate such informative regions\ndue to the large number of training parameters that cannot be effectively\nlearned from the available limited samples. In this study, we introduce a novel\nand practical framework for achieving explainable hard attention finding,\nspecifically tailored for few-shot learning scenarios, called FewXAT. Our\napproach employs deep reinforcement learning to implement the concept of hard\nattention, directly impacting raw input data and thus rendering the process\ninterpretable for human understanding. Through extensive experimentation across\nvarious benchmark datasets, we demonstrate the efficacy of our proposed method.",
          "link": "http://arxiv.org/abs/2310.07800",
          "publishedOn": "2023-10-14T00:41:34.426Z",
          "wordCount": null,
          "title": "Explainable Attention for Few-shot Learning and Beyond. (arXiv:2310.07800v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwajong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seong-Woo Kim</a>",
          "description": "A flow control system is a critical concept for increasing the production\ncapacity of manufacturing systems. To solve the scheduling optimization problem\nrelated to the flow control with the aim of improving productivity, existing\nmethods depend on a heuristic design by domain human experts. Therefore, the\nmethods require correction, monitoring, and verification by using real\nequipment. As system designs increase in complexity, the monitoring time\nincreases, which decreases the probability of arriving at the optimal design.\nAs an alternative approach to the heuristic design of flow control systems, the\nuse of deep reinforcement learning to solve the scheduling optimization problem\nhas been considered. Although the existing research on reinforcement learning\nhas yielded excellent performance in some areas, the applicability of the\nresults to actual FAB such as display and semiconductor manufacturing processes\nis not evident so far. To this end, we propose a method to implement a physical\nsimulation environment and devise a feasible flow control system design using a\ntransfer robot in display manufacturing through reinforcement learning. We\npresent a model and parameter setting to build a virtual environment for\ndifferent display transfer robots, and training methods of reinforcement\nlearning on the environment to obtain an optimal scheduling of glass flow\ncontrol systems. Its feasibility was verified by using different types of\nrobots used in the actual process.",
          "link": "http://arxiv.org/abs/2310.07981",
          "publishedOn": "2023-10-14T00:41:34.422Z",
          "wordCount": null,
          "title": "Reinforcement Learning of Display Transfer Robots in Glass Flow Control Systems: A Physical Simulation-Based Approach. (arXiv:2310.07981v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.10010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pouplin_A/0/1/0/all/0/1\">Alison Pouplin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eklund_D/0/1/0/all/0/1\">David Eklund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ek_C/0/1/0/all/0/1\">Carl Henrik Ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>",
          "description": "Riemannian geometry provides us with powerful tools to explore the latent\nspace of generative models while preserving the underlying structure of the\ndata. The latent space can be equipped it with a Riemannian metric, pulled back\nfrom the data manifold. With this metric, we can systematically navigate the\nspace relying on geodesics defined as the shortest curves between two points.\nGenerative models are often stochastic, causing the data space, the Riemannian\nmetric, and the geodesics, to be stochastic as well. Stochastic objects are at\nbest impractical, and at worst impossible, to manipulate. A common solution is\nto approximate the stochastic pullback metric by its expectation. But the\ngeodesics derived from this expected Riemannian metric do not correspond to the\nexpected length-minimising curves. In this work, we propose another metric\nwhose geodesics explicitly minimise the expected length of the pullback metric.\nWe show this metric defines a Finsler metric, and we compare it with the\nexpected Riemannian metric. In high dimensions, we prove that both metrics\nconverge to each other at a rate of $O\\left(\\frac{1}{D}\\right)$. This\nconvergence implies that the established expected Riemannian metric is an\naccurate approximation of the theoretically more grounded Finsler metric. This\nprovides justification for using the expected Riemannian metric for practical\nimplementations.",
          "link": "http://arxiv.org/abs/2212.10010",
          "publishedOn": "2023-10-14T00:41:34.419Z",
          "wordCount": null,
          "title": "Identifying latent distances with Finslerian geometry. (arXiv:2212.10010v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1\">Ming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingbin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shroff_N/0/1/0/all/0/1\">Ness Shroff</a>",
          "description": "Partially observable Markov decision processes (POMDPs) have been widely\napplied to capture many real-world applications. However, existing theoretical\nresults have shown that learning in general POMDPs could be intractable, where\nthe main challenge lies in the lack of latent state information. A key\nfundamental question here is how much online state information (OSI) is\nsufficient to achieve tractability. In this paper, we establish a lower bound\nthat reveals a surprising hardness result: unless we have full OSI, we need an\nexponentially scaling sample complexity to obtain an $\\epsilon$-optimal policy\nsolution for POMDPs. Nonetheless, inspired by the key insights in our lower\nbound design, we find that there exist important tractable classes of POMDPs\neven with only partial OSI. In particular, for two novel classes of POMDPs with\npartial OSI, we provide new algorithms that are proved to be near-optimal by\nestablishing new regret upper and lower bounds.",
          "link": "http://arxiv.org/abs/2306.08762",
          "publishedOn": "2023-10-14T00:41:34.411Z",
          "wordCount": null,
          "title": "Theoretical Hardness and Tractability of POMDPs in RL with Partial Online State Information. (arXiv:2306.08762v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cobanoglu_Y/0/1/0/all/0/1\">Yunus Cobanoglu</a>",
          "description": "This work analyzes Graph Neural Networks, a generalization of Fully-Connected\nDeep Neural Nets on Graph structured data, when their width, that is the number\nof nodes in each fullyconnected layer is increasing to infinity. Infinite Width\nNeural Networks are connecting Deep Learning to Gaussian Processes and Kernels,\nboth Machine Learning Frameworks with long traditions and extensive theoretical\nfoundations. Gaussian Processes and Kernels have much less hyperparameters then\nNeural Networks and can be used for uncertainty estimation, making them more\nuser friendly for applications. This works extends the increasing amount of\nresearch connecting Gaussian Processes and Kernels to Neural Networks. The\nKernel and Gaussian Process closed forms are derived for a variety of\narchitectures, namely the standard Graph Neural Network, the Graph Neural\nNetwork with Skip-Concatenate Connections and the Graph Attention Neural\nNetwork. All architectures are evaluated on a variety of datasets on the task\nof transductive Node Regression and Classification. Additionally, a Spectral\nSparsification method known as Effective Resistance is used to improve runtime\nand memory requirements. Extending the setting to inductive graph learning\ntasks (Graph Regression/ Classification) is straightforward and is briefly\ndiscussed in 3.5.",
          "link": "http://arxiv.org/abs/2310.08176",
          "publishedOn": "2023-10-14T00:41:34.409Z",
          "wordCount": null,
          "title": "Infinite Width Graph Neural Networks for Node Regression/ Classification. (arXiv:2310.08176v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1\">Xin Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tal_A/0/1/0/all/0/1\">Avishay Tal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hongxun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junzhao Yang</a>",
          "description": "In his breakthrough paper, Raz showed that any parity learning algorithm\nrequires either quadratic memory or an exponential number of samples [FOCS'16,\nJACM'19]. A line of work that followed extended this result to a large class of\nlearning problems. Until recently, all these results considered learning in the\nstreaming model, where each sample is drawn independently, and the learner is\nallowed a single pass over the stream of samples. Garg, Raz, and Tal [CCC'19]\nconsidered a stronger model, allowing multiple passes over the stream. In the\n$2$-pass model, they showed that learning parities of size $n$ requires either\na memory of size $n^{1.5}$ or at least $2^{\\sqrt{n}}$ samples. (Their result\nalso generalizes to other learning problems.)\n\nIn this work, for any constant $q$, we prove tight memory-sample lower bounds\nfor any parity learning algorithm that makes $q$ passes over the stream of\nsamples. We show that such a learner requires either $\\Omega(n^{2})$ memory\nsize or at least $2^{\\Omega(n)}$ samples. Beyond establishing a tight lower\nbound, this is the first non-trivial lower bound for $q$-pass learning for any\n$q\\ge 3$. Similar to prior work, our results extend to any learning problem\nwith many nearly-orthogonal concepts.\n\nWe complement the lower bound with an upper bound, showing that parity\nlearning with $q$ passes can be done efficiently with $O(n^2/\\log q)$ memory.",
          "link": "http://arxiv.org/abs/2310.08070",
          "publishedOn": "2023-10-14T00:41:34.408Z",
          "wordCount": null,
          "title": "Tight Time-Space Lower Bounds for Constant-Pass Learning. (arXiv:2310.08070v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ao_W/0/1/0/all/0/1\">Wei Ao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boddeti_V/0/1/0/all/0/1\">Vishnu Naresh Boddeti</a>",
          "description": "Secure inference of deep convolutional neural networks (CNNs) under RNS-CKKS\ninvolves polynomial approximation of unsupported non-linear activation\nfunctions. However, existing approaches have three main limitations: 1)\nInflexibility: The polynomial approximation and associated homomorphic\nevaluation architecture are customized manually for each CNN architecture and\ndo not generalize to other networks. 2) Suboptimal Approximation: Each\nactivation function is approximated instead of the function represented by the\nCNN. 3) Restricted Design: Either high-degree or low-degree polynomial\napproximations are used. The former retains high accuracy but slows down\ninference due to bootstrapping operations, while the latter accelerates\nciphertext inference but compromises accuracy. To address these limitations, we\npresent AutoFHE, which automatically adapts standard CNNs for secure inference\nunder RNS-CKKS. The key idea is to adopt layerwise mixed-degree polynomial\nactivation functions, which are optimized jointly with the homomorphic\nevaluation architecture in terms of the placement of bootstrapping operations.\nThe problem is modeled within a multi-objective optimization framework to\nmaximize accuracy and minimize the number of bootstrapping operations. AutoFHE\ncan be applied flexibly on any CNN architecture, and it provides diverse\nsolutions that span the trade-off between accuracy and latency. Experimental\nevaluation over RNS-CKKS encrypted CIFAR datasets shows that AutoFHE\naccelerates secure inference by $1.32\\times$ to $1.8\\times$ compared to methods\nemploying high-degree polynomials. It also improves accuracy by up to 2.56%\ncompared to methods using low-degree polynomials. Lastly, AutoFHE accelerates\ninference and improves accuracy by $103\\times$ and 3.46%, respectively,\ncompared to CNNs under TFHE.",
          "link": "http://arxiv.org/abs/2310.08012",
          "publishedOn": "2023-10-14T00:41:34.407Z",
          "wordCount": null,
          "title": "AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE. (arXiv:2310.08012v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08331",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zangirolami_V/0/1/0/all/0/1\">Valentina Zangirolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Borrotti_M/0/1/0/all/0/1\">Matteo Borrotti</a>",
          "description": "Incomplete knowledge of the environment leads an agent to make decisions\nunder uncertainty. One of the major dilemmas in Reinforcement Learning (RL)\nwhere an autonomous agent has to balance two contrasting needs in making its\ndecisions is: exploiting the current knowledge of the environment to maximize\nthe cumulative reward as well as exploring actions that allow improving the\nknowledge of the environment, hopefully leading to higher reward values\n(exploration-exploitation trade-off). Concurrently, another relevant issue\nregards the full observability of the states, which may not be assumed in all\napplications. Such as when only 2D images are considered as input in a RL\napproach used for finding the optimal action within a 3D simulation\nenvironment. In this work, we address these issues by deploying and testing\nseveral techniques to balance exploration and exploitation trade-off on\npartially observable systems for predicting steering wheels in autonomous\ndriving scenario. More precisely, the final aim is to investigate the effects\nof using both stochastic and deterministic multi-armed bandit strategies\ncoupled with a Deep Recurrent Q-Network. Additionally, we adapted and evaluated\nthe impact of an innovative method to improve the learning phase of the\nunderlying Convolutional Recurrent Neural Network. We aim to show that adaptive\nstochastic methods for exploration better approximate the trade-off between\nexploration and exploitation as, in general, Softmax and Max-Boltzmann\nstrategies are able to outperform epsilon-greedy techniques.",
          "link": "http://arxiv.org/abs/2310.08331",
          "publishedOn": "2023-10-14T00:41:34.407Z",
          "wordCount": null,
          "title": "Impact of multi-armed bandit strategies on deep recurrent reinforcement learning. (arXiv:2310.08331v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianfei Ma</a>",
          "description": "Future sequence represents the outcome after executing the action into the\nenvironment. When driven by the information-theoretic concept of mutual\ninformation, it seeks maximally informative consequences. Explicit outcomes may\nvary across state, return, or trajectory serving different purposes such as\ncredit assignment or imitation learning. However, the inherent nature of\nincorporating intrinsic motivation with reward maximization is often neglected.\nIn this work, we propose a variational approach to jointly learn the necessary\nquantity for estimating the mutual information and the dynamics model,\nproviding a general framework for incorporating different forms of outcomes of\ninterest. Integrated into a policy iteration scheme, our approach guarantees\nconvergence to the optimal policy. While we mainly focus on theoretical\nanalysis, our approach opens the possibilities of leveraging intrinsic control\nwith model learning to enhance sample efficiency and incorporate uncertainty of\nthe environment into decision-making.",
          "link": "http://arxiv.org/abs/2310.08100",
          "publishedOn": "2023-10-14T00:41:34.403Z",
          "wordCount": null,
          "title": "Generative Intrinsic Optimization: Intrisic Control with Model Learning. (arXiv:2310.08100v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_K/0/1/0/all/0/1\">Kushagra Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudolph_M/0/1/0/all/0/1\">Maja Rudolph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Diffusion models suffer from slow sample generation at inference time.\nTherefore, developing a principled framework for fast deterministic/stochastic\nsampling for a broader class of diffusion models is a promising direction. We\npropose two complementary frameworks for accelerating sample generation in\npre-trained models: Conjugate Integrators and Splitting Integrators. Conjugate\nintegrators generalize DDIM, mapping the reverse diffusion dynamics to a more\namenable space for sampling. In contrast, splitting-based integrators, commonly\nused in molecular dynamics, reduce the numerical simulation error by cleverly\nalternating between numerical updates involving the data and auxiliary\nvariables. After extensively studying these methods empirically and\ntheoretically, we present a hybrid method that leads to the best-reported\nperformance for diffusion models in augmented spaces. Applied to Phase Space\nLangevin Diffusion [Pandey & Mandt, 2023] on CIFAR-10, our deterministic and\nstochastic samplers achieve FID scores of 2.11 and 2.36 in only 100 network\nfunction evaluations (NFE) as compared to 2.57 and 2.63 for the best-performing\nbaselines, respectively. Our code and model checkpoints will be made publicly\navailable at \\url{https://github.com/mandt-lab/PSLD}.",
          "link": "http://arxiv.org/abs/2310.07894",
          "publishedOn": "2023-10-14T00:41:34.397Z",
          "wordCount": null,
          "title": "Efficient Integrators for Diffusion Generative Models. (arXiv:2310.07894v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Decker_T/0/1/0/all/0/1\">Thomas Decker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gross_R/0/1/0/all/0/1\">Ralf Gross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koebler_A/0/1/0/all/0/1\">Alexander Koebler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lebacher_M/0/1/0/all/0/1\">Michael Lebacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schnitzer_R/0/1/0/all/0/1\">Ronald Schnitzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_S/0/1/0/all/0/1\">Stefan H. Weber</a>",
          "description": "In this paper, we investigate the practical relevance of explainable\nartificial intelligence (XAI) with a special focus on the producing industries\nand relate them to the current state of academic XAI research. Our findings are\nbased on an extensive series of interviews regarding the role and applicability\nof XAI along the Machine Learning (ML) lifecycle in current industrial practice\nand its expected relevance in the future. The interviews were conducted among a\ngreat variety of roles and key stakeholders from different industry sectors. On\ntop of that, we outline the state of XAI research by providing a concise review\nof the relevant literature. This enables us to provide an encompassing overview\ncovering the opinions of the surveyed persons as well as the current state of\nacademic research. By comparing our interview results with the current research\napproaches we reveal several discrepancies. While a multitude of different XAI\napproaches exists, most of them are centered around the model evaluation phase\nand data scientists. Their versatile capabilities for other stages are\ncurrently either not sufficiently explored or not popular among practitioners.\nIn line with existing work, our findings also confirm that more efforts are\nneeded to enable also non-expert users' interpretation and understanding of\nopaque AI models with existing methods and frameworks.",
          "link": "http://arxiv.org/abs/2310.07882",
          "publishedOn": "2023-10-14T00:41:34.393Z",
          "wordCount": null,
          "title": "The Thousand Faces of Explainable AI Along the Machine Learning Life Cycle: Industrial Reality and Current State of Research. (arXiv:2310.07882v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.04370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DeFazio_D/0/1/0/all/0/1\">David DeFazio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirota_E/0/1/0/all/0/1\">Eisuke Hirota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiqi Zhang</a>",
          "description": "Seeing-eye robots are very useful tools for guiding visually impaired people,\npotentially producing a huge societal impact given the low availability and\nhigh cost of real guide dogs. Although a few seeing-eye robot systems have\nalready been demonstrated, none considered external tugs from humans, which\nfrequently occur in a real guide dog setting. In this paper, we simultaneously\ntrain a locomotion controller that is robust to external tugging forces via\nReinforcement Learning (RL), and an external force estimator via supervised\nlearning. The controller ensures stable walking, and the force estimator\nenables the robot to respond to the external forces from the human. These\nforces are used to guide the robot to the global goal, which is unknown to the\nrobot, while the robot guides the human around nearby obstacles via a local\nplanner. Experimental results in simulation and on hardware show that our\ncontroller is robust to external forces, and our seeing-eye system can\naccurately detect force direction. We demonstrate our full seeing-eye robot\nsystem on a real quadruped robot with a blindfolded human. The video can be\nseen at our project page: https://bu-air-lab.github.io/guide_dog/",
          "link": "http://arxiv.org/abs/2309.04370",
          "publishedOn": "2023-10-14T00:41:34.363Z",
          "wordCount": null,
          "title": "Seeing-Eye Quadruped Navigation with Force Responsive Locomotion Control. (arXiv:2309.04370v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.08469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Ching Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wen-Chih Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tien-Fu Chen</a>",
          "description": "In this work, we leverage pre-trained Large Language Models (LLMs) to enhance\ntime-series forecasting. Mirroring the growing interest in unifying models for\nNatural Language Processing and Computer Vision, we envision creating an\nanalogous model for long-term time-series forecasting. Due to limited\nlarge-scale time-series data for building robust foundation models, our\napproach LLM4TS focuses on leveraging the strengths of pre-trained LLMs. By\ncombining time-series patching with temporal encoding, we have enhanced the\ncapability of LLMs to handle time-series data effectively. Inspired by the\nsupervised fine-tuning in chatbot domains, we prioritize a two-stage\nfine-tuning process: first conducting supervised fine-tuning to orient the LLM\ntowards time-series data, followed by task-specific downstream fine-tuning.\nFurthermore, to unlock the flexibility of pre-trained LLMs without extensive\nparameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT)\ntechniques. Drawing on these innovations, LLM4TS has yielded state-of-the-art\nresults in long-term forecasting. Our model has also shown exceptional\ncapabilities as both a robust representation learner and an effective few-shot\nlearner, thanks to the knowledge transferred from the pre-trained LLM.",
          "link": "http://arxiv.org/abs/2308.08469",
          "publishedOn": "2023-10-14T00:41:34.362Z",
          "wordCount": null,
          "title": "LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs. (arXiv:2308.08469v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hotegni_S/0/1/0/all/0/1\">S. S. Hotegni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peitz_S/0/1/0/all/0/1\">S. Peitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berkemeier_M/0/1/0/all/0/1\">M. Berkemeier</a>",
          "description": "Different conflicting optimization criteria arise naturally in various Deep\nLearning scenarios. These can address different main tasks (i.e., in the\nsetting of Multi-Task Learning), but also main and secondary tasks such as loss\nminimization versus sparsity. The usual approach is a simple weighting of the\ncriteria, which formally only works in the convex setting. In this paper, we\npresent a Multi-Objective Optimization algorithm using a modified Weighted\nChebyshev scalarization for training Deep Neural Networks (DNNs) with respect\nto several tasks. By employing this scalarization technique, the algorithm can\nidentify all optimal solutions of the original problem while reducing its\ncomplexity to a sequence of single-objective problems. The simplified problems\nare then solved using an Augmented Lagrangian method, enabling the use of\npopular optimization techniques such as Adam and Stochastic Gradient Descent,\nwhile efficaciously handling constraints. Our work aims to address the\n(economical and also ecological) sustainability issue of DNN models, with a\nparticular focus on Deep Multi-Task models, which are typically designed with a\nvery large number of weights to perform equally well on multiple tasks. Through\nexperiments conducted on two Machine Learning datasets, we demonstrate the\npossibility of adaptively sparsifying the model during training without\nsignificantly impacting its performance, if we are willing to apply\ntask-specific adaptations to the network weights. Code is available at\nhttps://github.com/salomonhotegni/MDMTN.",
          "link": "http://arxiv.org/abs/2308.12243",
          "publishedOn": "2023-10-14T00:41:34.359Z",
          "wordCount": null,
          "title": "Multi-Objective Optimization for Sparse Deep Neural Network Training. (arXiv:2308.12243v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zihao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xuan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yufei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingsong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xian Wei</a>",
          "description": "In continual learning, the learner learns multiple tasks in sequence, with\ndata being acquired only once for each task. Catastrophic forgetting is a major\nchallenge to continual learning. To reduce forgetting, some existing\nrehearsal-based methods use episodic memory to replay samples of previous\ntasks. However, in the process of knowledge integration when learning a new\ntask, this strategy also suffers from catastrophic forgetting due to an\nimbalance between old and new knowledge. To address this problem, we propose a\nnovel replay strategy called Manifold Expansion Replay (MaER). We argue that\nexpanding the implicit manifold of the knowledge representation in the episodic\nmemory helps to improve the robustness and expressiveness of the model. To this\nend, we propose a greedy strategy to keep increasing the diameter of the\nimplicit manifold represented by the knowledge in the buffer during memory\nmanagement. In addition, we introduce Wasserstein distance instead of cross\nentropy as distillation loss to preserve previous knowledge. With extensive\nexperimental validation on MNIST, CIFAR10, CIFAR100, and TinyImageNet, we show\nthat the proposed method significantly improves the accuracy in continual\nlearning setup, outperforming the state of the arts.",
          "link": "http://arxiv.org/abs/2310.08038",
          "publishedOn": "2023-10-14T00:41:34.336Z",
          "wordCount": null,
          "title": "Continual Learning via Manifold Expansion Replay. (arXiv:2310.08038v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.10691",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiateng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yangyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lifan Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>",
          "description": "To solve complex tasks, large language models (LLMs) often require multiple\nrounds of interactions with the user, sometimes assisted by external tools.\nHowever, current evaluation protocols often emphasize benchmark performance\nwith single-turn exchanges, neglecting the nuanced interactions among the user,\nLLMs, and external tools, while also underestimating the importance of natural\nlanguage feedback from users. These oversights contribute to discrepancies\nbetween research benchmark evaluations and real-world use cases. We introduce\nMINT, a benchmark that evaluates LLMs' ability to solve tasks with multi-turn\ninteractions by (1) using tools and (2) leveraging natural language feedback.\nTo ensure reproducibility, we provide an evaluation framework where LLMs can\naccess tools by executing Python code and receive users' natural language\nfeedback simulated by GPT-4. We repurpose a diverse set of established\nevaluation datasets focusing on reasoning, coding, and decision-making and\ncarefully curate them into a compact subset for efficient evaluation. Our\nanalysis of 20 open- and closed-source LLMs offers intriguing findings. (a)\nLLMs generally benefit from tools and language feedback, with performance gains\n(absolute, same below) of 1-8% for each turn of tool use and 2-17% with natural\nlanguage feedback. (b) Better single-turn performance does not guarantee better\nmulti-turn performance. (c) Surprisingly, on the LLMs evaluated, supervised\ninstruction-finetuning (SIFT) and reinforcement learning from human feedback\n(RLHF) generally hurt multi-turn capabilities. We expect MINT can help measure\nprogress and incentivize research in improving LLMs' capabilities in multi-turn\ninteractions, especially for open-source communities where multi-turn human\nevaluation can be less accessible compared to commercial LLMs with a larger\nuser base.",
          "link": "http://arxiv.org/abs/2309.10691",
          "publishedOn": "2023-10-14T00:41:34.326Z",
          "wordCount": null,
          "title": "MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback. (arXiv:2309.10691v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maesumi_A/0/1/0/all/0/1\">Arman Maesumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerrero_P/0/1/0/all/0/1\">Paul Guerrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_V/0/1/0/all/0/1\">Vladimir G. Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisher_M/0/1/0/all/0/1\">Matthew Fisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1\">Siddhartha Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aigerman_N/0/1/0/all/0/1\">Noam Aigerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritchie_D/0/1/0/all/0/1\">Daniel Ritchie</a>",
          "description": "Exploring variations of 3D shapes is a time-consuming process in traditional\n3D modeling tools. Deep generative models of 3D shapes often feature continuous\nlatent spaces that can, in principle, be used to explore potential variations\nstarting from a set of input shapes. In practice, doing so can be problematic:\nlatent spaces are high dimensional and hard to visualize, contain shapes that\nare not relevant to the input shapes, and linear paths through them often lead\nto sub-optimal shape transitions. Furthermore, one would ideally be able to\nexplore variations in the original high-quality meshes used to train the\ngenerative model, not its lower-quality output geometry. In this paper, we\npresent a method to explore variations among a given set of landmark shapes by\nconstructing a mapping from an easily-navigable 2D exploration space to a\nsubspace of a pre-trained generative model. We first describe how to find a\nmapping that spans the set of input landmark shapes and exhibits smooth\nvariations between them. We then show how to turn the variations in this\nsubspace into deformation fields, to transfer those variations to high-quality\nmeshes for the landmark shapes. Our results show that our method can produce\nvisually-pleasing and easily-navigable 2D exploration spaces for several\ndifferent shape categories, especially as compared to prior work on learning\ndeformation spaces for 3D shapes.",
          "link": "http://arxiv.org/abs/2310.07814",
          "publishedOn": "2023-10-14T00:41:34.303Z",
          "wordCount": null,
          "title": "Explorable Mesh Deformation Subspaces from Unstructured Generative Models. (arXiv:2310.07814v1 [cs.GR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07747",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huyuk_A/0/1/0/all/0/1\">Alihan H&#xfc;y&#xfc;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarrett_D/0/1/0/all/0/1\">Daniel Jarrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Learning transparent, interpretable controllers with offline data in\ndecision-making systems is an essential area of research due to its potential\nto reduce the risk of applications in real-world systems. However, in\nresponsibility-sensitive settings such as healthcare, decision accountability\nis of paramount importance, yet has not been adequately addressed by the\nliterature. This paper introduces the Accountable Offline Controller (AOC) that\nemploys the offline dataset as the Decision Corpus and performs accountable\ncontrol based on a tailored selection of examples, referred to as the Corpus\nSubset. ABC operates effectively in low-data scenarios, can be extended to the\nstrictly offline imitation setting, and displays qualities of both conservation\nand adaptability. We assess ABC's performance in both simulated and real-world\nhealthcare scenarios, emphasizing its capability to manage offline control\ntasks with high levels of performance while maintaining accountability.\n\nKeywords: Interpretable Reinforcement Learning, Explainable Reinforcement\nLearning, Reinforcement Learning Transparency, Offline Reinforcement Learning,\nBatched Control.",
          "link": "http://arxiv.org/abs/2310.07747",
          "publishedOn": "2023-10-14T00:41:34.300Z",
          "wordCount": null,
          "title": "Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples. (arXiv:2310.07747v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.01748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_K/0/1/0/all/0/1\">Kushagra Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Score-based Generative Models (SGMs) have demonstrated exceptional synthesis\noutcomes across various tasks. However, the current design landscape of the\nforward diffusion process remains largely untapped and often relies on physical\nheuristics or simplifying assumptions. Utilizing insights from the development\nof scalable Bayesian posterior samplers, we present a complete recipe for\nformulating forward processes in SGMs, ensuring convergence to the desired\ntarget distribution. Our approach reveals that several existing SGMs can be\nseen as specific manifestations of our framework. Building upon this method, we\nintroduce Phase Space Langevin Diffusion (PSLD), which relies on score-based\nmodeling within an augmented space enriched by auxiliary variables akin to\nphysical phase space. Empirical results exhibit the superior sample quality and\nimproved speed-quality trade-off of PSLD compared to various competing\napproaches on established image synthesis benchmarks. Remarkably, PSLD achieves\nsample quality akin to state-of-the-art SGMs (FID: 2.10 for unconditional\nCIFAR-10 generation). Lastly, we demonstrate the applicability of PSLD in\nconditional synthesis using pre-trained score networks, offering an appealing\nalternative as an SGM backbone for future advancements. Code and model\ncheckpoints can be accessed at \\url{https://github.com/mandt-lab/PSLD}.",
          "link": "http://arxiv.org/abs/2303.01748",
          "publishedOn": "2023-10-14T00:41:34.278Z",
          "wordCount": null,
          "title": "A Complete Recipe for Diffusion Generative Models. (arXiv:2303.01748v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marks_L/0/1/0/all/0/1\">Luke Marks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdullah_A/0/1/0/all/0/1\">Amir Abdullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendez_L/0/1/0/all/0/1\">Luna Mendez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arike_R/0/1/0/all/0/1\">Rauno Arike</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barez_F/0/1/0/all/0/1\">Fazl Barez</a>",
          "description": "Large language models (LLMs) aligned to human preferences via reinforcement\nlearning from human feedback (RLHF) underpin many commercial applications.\nHowever, how RLHF impacts LLM internals remains opaque. We propose a novel\nmethod to interpret learned reward functions in RLHF-tuned LLMs using sparse\nautoencoders. Our approach trains autoencoder sets on activations from a base\nLLM and its RLHF-tuned version. By comparing autoencoder hidden spaces, we\nidentify unique features that reflect the accuracy of the learned reward model.\nTo quantify this, we construct a scenario where the tuned LLM learns\ntoken-reward mappings to maximize reward. This is the first application of\nsparse autoencoders for interpreting learned rewards and broadly inspecting\nreward learning in LLMs. Our method provides an abstract approximation of\nreward integrity. This presents a promising technique for ensuring alignment\nbetween specified objectives and model behaviors.",
          "link": "http://arxiv.org/abs/2310.08164",
          "publishedOn": "2023-10-14T00:41:34.277Z",
          "wordCount": null,
          "title": "Interpreting Reward Models in RLHF-Tuned Language Models Using Sparse Autoencoders. (arXiv:2310.08164v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huayu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Cheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Recent developments in offline reinforcement learning have uncovered the\nimmense potential of diffusion modeling, which excels at representing\nheterogeneous behavior policies. However, sampling from diffusion policies is\nconsiderably slow because it necessitates tens to hundreds of iterative\ninference steps for one action. To address this issue, we propose to extract an\nefficient deterministic inference policy from critic models and pretrained\ndiffusion behavior models, leveraging the latter to directly regularize the\npolicy gradient with the behavior distribution's score function during\noptimization. Our method enjoys powerful generative capabilities of diffusion\nmodeling while completely circumventing the computationally intensive and\ntime-consuming diffusion sampling scheme, both during training and evaluation.\nExtensive results on D4RL tasks show that our method boosts action sampling\nspeed by more than 25 times compared with various leading diffusion-based\nmethods in locomotion tasks, while still maintaining state-of-the-art\nperformance.",
          "link": "http://arxiv.org/abs/2310.07297",
          "publishedOn": "2023-10-14T00:41:34.273Z",
          "wordCount": null,
          "title": "Score Regularized Policy Optimization through Diffusion Behavior. (arXiv:2310.07297v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.09033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Aadirupa Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>",
          "description": "Most bandit algorithms assume that the reward variances or their upper bounds\nare known, and that they are the same for all arms. This naturally leads to\nsuboptimal performance and higher regret due to variance overestimation. On the\nother hand, underestimated reward variances may lead to linear regret due to\ncommitting early to a suboptimal arm. This motivated prior works on\nvariance-adaptive frequentist algorithms, which have strong instance-dependent\nregret bounds but cannot incorporate prior knowledge on reward variances. We\nlay foundations for the Bayesian setting, which incorporates prior knowledge.\nThis results in lower regret in practice, due to using the prior in the\nalgorithm design, and also improved regret guarantees. Specifically, we study\nGaussian bandits with {unknown heterogeneous reward variances}, and develop a\nThompson sampling algorithm with prior-dependent Bayes regret bounds. We\nachieve lower regret with lower reward variances and more informative priors on\nthem, which is precisely why we pay only for what is uncertain. This is the\nfirst result of its kind. Finally, we corroborate our theory with extensive\nexperiments, which show the superiority of our variance-adaptive Bayesian\nalgorithm over prior frequentist approaches. We also show that our approach is\nrobust to model misspecification and can be applied with estimated priors.",
          "link": "http://arxiv.org/abs/2303.09033",
          "publishedOn": "2023-10-14T00:41:34.262Z",
          "wordCount": null,
          "title": "Only Pay for What Is Uncertain: Variance-Adaptive Thompson Sampling. (arXiv:2303.09033v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malik_G/0/1/0/all/0/1\">Girik Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowder_D/0/1/0/all/0/1\">Dakarai Crowder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mingolla_E/0/1/0/all/0/1\">Ennio Mingolla</a>",
          "description": "Adversarial attacks can affect the object recognition capabilities of\nmachines in wild. These can often result from spurious correlations between\ninput and class labels, and are prone to memorization in large networks. While\nnetworks are expected to do automated feature selection, it is not effective at\nthe scale of the object. Humans, however, are able to select the minimum set of\nfeatures required to form a robust representation of an object. In this work,\nwe show that finetuning any pretrained off-the-shelf network with Extreme Image\nTransformations (EIT) not only helps in learning a robust latent\nrepresentation, it also improves the performance of these networks against\ncommon adversarial attacks of various intensities. Our EIT trained networks\nshow strong activations in the object regions even when tested with more\nintense noise, showing promising generalizations across different kinds of\nadversarial attacks.",
          "link": "http://arxiv.org/abs/2310.07725",
          "publishedOn": "2023-10-14T00:41:34.261Z",
          "wordCount": null,
          "title": "Extreme Image Transformations Facilitate Robust Latent Object Representations. (arXiv:2310.07725v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.11014",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Hoidn_O/0/1/0/all/0/1\">Oliver Hoidn</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mishra_A/0/1/0/all/0/1\">Aashwin Ananda Mishra</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mehta_A/0/1/0/all/0/1\">Apurva Mehta</a>",
          "description": "By circumventing the resolution limitations of optics, coherent diffractive\nimaging (CDI) and ptychography are making their way into scientific fields\nranging from X-ray imaging to astronomy. Yet, the need for time consuming\niterative phase recovery hampers real-time imaging. While supervised deep\nlearning strategies have increased reconstruction speed, they sacrifice image\nquality. Furthermore, these methods' demand for extensive labeled training data\nis experimentally burdensome. Here, we propose an unsupervised physics-informed\nneural network reconstruction method, PtychoPINN, that retains the factor of\n100-to-1000 speedup of deep learning-based reconstruction while improving\nreconstruction quality by combining the diffraction forward map with real-space\nconstraints from overlapping measurements. In particular, PtychoPINN\nsignificantly advances generalizability, accuracy (with a typical 10 dB PSNR\nincrease), and linear resolution (2- to 6-fold gain). This blend of performance\nand speed offers exciting prospects for high-resolution real-time imaging in\nhigh-throughput environments such as X-ray free electron lasers (XFELs) and\ndiffraction-limited light sources.",
          "link": "http://arxiv.org/abs/2306.11014",
          "publishedOn": "2023-10-14T00:41:34.261Z",
          "wordCount": null,
          "title": "Physics Constrained Unsupervised Deep Learning for Rapid, High Resolution Scanning Coherent Diffraction Reconstruction. (arXiv:2306.11014v2 [physics.comp-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pawelczyk_M/0/1/0/all/0/1\">Martin Pawelczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neel_S/0/1/0/all/0/1\">Seth Neel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>",
          "description": "Machine unlearning, the study of efficiently removing the impact of specific\ntraining points on the trained model, has garnered increased attention of late,\ndriven by the need to comply with privacy regulations like the Right to be\nForgotten. Although unlearning is particularly relevant for LLMs in light of\nthe copyright issues they raise, achieving precise unlearning is\ncomputationally infeasible for very large models. To this end, recent work has\nproposed several algorithms which approximate the removal of training data\nwithout retraining the model. These algorithms crucially rely on access to the\nmodel parameters in order to update them, an assumption that may not hold in\npractice due to computational constraints or when the LLM is accessed via API.\nIn this work, we propose a new class of unlearning methods for LLMs we call\n''In-Context Unlearning'', providing inputs in context and without having to\nupdate model parameters. To unlearn a particular training instance, we provide\nthe instance alongside a flipped label and additional correctly labelled\ninstances which are prepended as inputs to the LLM at inference time. Our\nexperimental results demonstrate that these contexts effectively remove\nspecific information from the training set while maintaining performance levels\nthat are competitive with (or in some cases exceed) state-of-the-art unlearning\nmethods that require access to the LLM parameters.",
          "link": "http://arxiv.org/abs/2310.07579",
          "publishedOn": "2023-10-14T00:41:34.259Z",
          "wordCount": null,
          "title": "In-Context Unlearning: Language Models as Few Shot Unlearners. (arXiv:2310.07579v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jaewoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaehong Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Wonjae Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yunji Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "We present a lifelong audio-video masked autoencoder that continually learns\nthe multimodal representations from a video stream containing audio-video\npairs, while its distribution continually shifts over time. Specifically, we\npropose two novel ideas to tackle the problem: (1) Localized Alignment: We\nintroduce a small trainable multimodal encoder that predicts the audio and\nvideo tokens that are well-aligned with each other. This allows the model to\nlearn only the highly correlated audiovisual patches with accurate multimodal\nrelationships. (2) Forget-robust multimodal patch selection: We compare the\nrelative importance of each audio-video patch between the current and past data\npair to mitigate unintended drift of the previously learned audio-video\nrepresentations. Our proposed method, FLAVA (Forget-robust Localized\nAudio-Video Alignment), therefore, captures the complex relationships between\nthe audio and video modalities during training on a sequence of pre-training\ntasks while alleviating the forgetting of learned audiovisual correlations. Our\nexperiments validate that FLAVA outperforms the state-of-the-art continual\nlearning methods on several benchmark datasets under continual audio-video\nrepresentation learning scenarios.",
          "link": "http://arxiv.org/abs/2310.08204",
          "publishedOn": "2023-10-14T00:41:34.250Z",
          "wordCount": null,
          "title": "Lifelong Audio-video Masked Autoencoder with Forget-robust Localized Alignments. (arXiv:2310.08204v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_C/0/1/0/all/0/1\">Cheongwoong Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaesik Choi</a>",
          "description": "Large language models (LLMs) often make factually incorrect responses despite\ntheir success in various applications. In this paper, we hypothesize that\nrelying heavily on simple co-occurrence statistics of the pre-training corpora\nis one of the main factors that cause factual errors. Our results reveal that\nLLMs are vulnerable to the co-occurrence bias, defined as preferring frequently\nco-occurred words over the correct answer. Consequently, LLMs struggle to\nrecall facts whose subject and object rarely co-occur in the pre-training\ndataset although they are seen during finetuning. We show that co-occurrence\nbias remains despite scaling up model sizes or finetuning. Therefore, we\nsuggest finetuning on a debiased dataset to mitigate the bias by filtering out\nbiased samples whose subject-object co-occurrence count is high. Although\ndebiased finetuning allows LLMs to memorize rare facts in the training set, it\nis not effective in recalling rare facts unseen during finetuning. Further\nresearch in mitigation will help build reliable language models by preventing\npotential errors. The code is available at\n\\url{https://github.com/CheongWoong/impact_of_cooccurrence}.",
          "link": "http://arxiv.org/abs/2310.08256",
          "publishedOn": "2023-10-14T00:41:34.236Z",
          "wordCount": null,
          "title": "Impact of Co-occurrence on Factual Knowledge of Large Language Models. (arXiv:2310.08256v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cong_T/0/1/0/all/0/1\">Tianji Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hulsebos_M/0/1/0/all/0/1\">Madelon Hulsebos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhenjie Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groth_P/0/1/0/all/0/1\">Paul Groth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagadish_H/0/1/0/all/0/1\">H. V. Jagadish</a>",
          "description": "Language models and specialized table embedding models have recently\ndemonstrated strong performance on many tasks over tabular data. Researchers\nand practitioners are keen to leverage these models in many new application\ncontexts; but limited understanding of the strengths and weaknesses of these\nmodels, and the table representations they generate, makes the process of\nfinding a suitable model for a given task reliant on trial and error. There is\nan urgent need to gain a comprehensive understanding of these models to\nminimize inefficiency and failures in downstream usage.\n\nTo address this need, we propose Observatory, a formal framework to\nsystematically analyze embedding representations of relational tables.\nMotivated both by invariants of the relational data model and by statistical\nconsiderations regarding data distributions, we define eight primitive\nproperties, and corresponding measures to quantitatively characterize table\nembeddings for these properties. Based on these properties, we define an\nextensible framework to evaluate language and table embedding models. We\ncollect and synthesize a suite of datasets and use Observatory to analyze seven\nsuch models. Our analysis provides insights into the strengths and weaknesses\nof learned representations over tables. We find, for example, that some models\nare sensitive to table structure such as column order, that functional\ndependencies are rarely reflected in embeddings, and that specialized table\nembedding models have relatively lower sample fidelity. Such insights help\nresearchers and practitioners better anticipate model behaviors and select\nappropriate models for their downstream tasks, while guiding researchers in the\ndevelopment of new models.",
          "link": "http://arxiv.org/abs/2310.07736",
          "publishedOn": "2023-10-14T00:41:34.211Z",
          "wordCount": null,
          "title": "Observatory: Characterizing Embeddings of Relational Tables. (arXiv:2310.07736v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.12345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldwaser_A/0/1/0/all/0/1\">Adrian Goldwaser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1\">Hong Ge</a>",
          "description": "Larger and deeper networks generalise well despite their increased capacity\nto overfit. Understanding why this happens is theoretically and practically\nimportant. One recent approach looks at the infinitely wide limits of such\nnetworks and their corresponding kernels. However, these theoretical tools\ncannot fully explain finite networks as the empirical kernel changes\nsignificantly during gradient-descent-based training in contrast to infinite\nnetworks. In this work, we derive an iterative linearised training method as a\nnovel empirical tool to further investigate this distinction, allowing us to\ncontrol for sparse (i.e. infrequent) feature updates and quantify the frequency\nof feature learning needed to achieve comparable performance. We justify\niterative linearisation as an interpolation between a finite analog of the\ninfinite width regime, which does not learn features, and standard gradient\ndescent training, which does. Informally, we also show that it is analogous to\na damped version of the Gauss-Newton algorithm -- a second-order method. We\nshow that in a variety of cases, iterative linearised training surprisingly\nperforms on par with standard training, noting in particular how much less\nfrequent feature learning is required to achieve comparable performance. We\nalso show that feature learning is essential for good performance. Since such\nfeature learning inevitably causes changes in the NTK kernel, we provide direct\nnegative evidence for the NTK theory, which states the NTK kernel remains\nconstant during training.",
          "link": "http://arxiv.org/abs/2211.12345",
          "publishedOn": "2023-10-14T00:41:34.188Z",
          "wordCount": null,
          "title": "Understanding Sparse Feature Updates in Deep Networks using Iterative Linearisation. (arXiv:2211.12345v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08088",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozanec_J/0/1/0/all/0/1\">Jo&#x17e;e M. Ro&#x17e;anec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petelin_G/0/1/0/all/0/1\">Ga&#x161;per Petelin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_J/0/1/0/all/0/1\">Jo&#xe3;o Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertalanic_B/0/1/0/all/0/1\">Bla&#x17e; Bertalani&#x10d;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cerar_G/0/1/0/all/0/1\">Gregor Cerar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gucek_M/0/1/0/all/0/1\">Marko Gu&#x10d;ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papa_G/0/1/0/all/0/1\">Gregor Papa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mladenic_D/0/1/0/all/0/1\">Dunja Mladeni&#x107;</a>",
          "description": "In many cases, a machine learning model must learn to correctly predict a few\ndata points with particular values of interest in a broader range of data where\nmany target values are zero. Zero-inflated data can be found in diverse\nscenarios, such as lumpy and intermittent demands, power consumption for home\nappliances being turned on and off, impurities measurement in distillation\nprocesses, and even airport shuttle demand prediction. The presence of zeroes\naffects the models' learning and may result in poor performance. Furthermore,\nzeroes also distort the metrics used to compute the model's prediction quality.\nThis paper showcases two real-world use cases (home appliances classification\nand airport shuttle demand prediction) where a hierarchical model applied in\nthe context of zero-inflated data leads to excellent results. In particular,\nfor home appliances classification, the weighted average of Precision, Recall,\nF1, and AUC ROC was increased by 27%, 34%, 49%, and 27%, respectively.\nFurthermore, it is estimated that the proposed approach is also four times more\nenergy efficient than the SOTA approach against which it was compared to.\nTwo-fold models performed best in all cases when predicting airport shuttle\ndemand, and the difference against other models has been proven to be\nstatistically significant.",
          "link": "http://arxiv.org/abs/2310.08088",
          "publishedOn": "2023-10-14T00:41:34.153Z",
          "wordCount": 729,
          "title": "Dealing with zero-inflated data: achieving SOTA with a two-fold machine learning approach. (arXiv:2310.08088v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1\">Mauro Conti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farronato_N/0/1/0/all/0/1\">Nicola Farronato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koffas_S/0/1/0/all/0/1\">Stefanos Koffas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajola_L/0/1/0/all/0/1\">Luca Pajola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Picek_S/0/1/0/all/0/1\">Stjepan Picek</a>",
          "description": "Optical Character Recognition (OCR) is a widely used tool to extract text\nfrom scanned documents. Today, the state-of-the-art is achieved by exploiting\ndeep neural networks. However, the cost of this performance is paid at the\nprice of system vulnerability. For instance, in backdoor attacks, attackers\ncompromise the training phase by inserting a backdoor in the victim's model\nthat will be activated at testing time by specific patterns while leaving the\noverall model performance intact. This work proposes a backdoor attack for OCR\nresulting in the injection of non-readable characters from malicious input\nimages. This simple but effective attack exposes the state-of-the-art OCR\nweakness, making the extracted text correct to human eyes but simultaneously\nunusable for the NLP application that uses OCR as a preprocessing step.\nExperimental results show that the attacked models successfully output\nnon-readable characters for around 90% of the poisoned instances without\nharming their performance for the remaining instances.",
          "link": "http://arxiv.org/abs/2310.08259",
          "publishedOn": "2023-10-14T00:41:34.147Z",
          "wordCount": null,
          "title": "Invisible Threats: Backdoor Attack in OCR Systems. (arXiv:2310.08259v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.14432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yun Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yongchao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_S/0/1/0/all/0/1\">Suo Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Minghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1\">Chunyang Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Huanjun Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_L/0/1/0/all/0/1\">Lihong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinjie Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yixiang Mu</a>",
          "description": "We develop a novel framework that adds the regularizers of the sparse group\nlasso to a family of adaptive optimizers in deep learning, such as Momentum,\nAdagrad, Adam, AMSGrad, AdaHessian, and create a new class of optimizers, which\nare named Group Momentum, Group Adagrad, Group Adam, Group AMSGrad and Group\nAdaHessian, etc., accordingly. We establish theoretically proven convergence\nguarantees in the stochastic convex settings, based on primal-dual methods. We\nevaluate the regularized effect of our new optimizers on three large-scale\nreal-world ad click datasets with state-of-the-art deep learning models. The\nexperimental results reveal that compared with the original optimizers with the\npost-processing procedure which uses the magnitude pruning method, the\nperformance of the models can be significantly improved on the same sparsity\nlevel. Furthermore, in comparison to the cases without magnitude pruning, our\nmethods can achieve extremely high sparsity with significantly better or highly\ncompetitive performance. The code is available at\nhttps://github.com/intelligent-machine-learning/dlrover/blob/master/tfplus.",
          "link": "http://arxiv.org/abs/2107.14432",
          "publishedOn": "2023-10-14T00:41:34.132Z",
          "wordCount": 796,
          "title": "Adaptive Optimizers with Sparse Group Lasso for Neural Networks in CTR Prediction. (arXiv:2107.14432v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.11670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Everaert_D/0/1/0/all/0/1\">Dante Everaert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>",
          "description": "It is often advantageous to train models on a subset of the available train\nexamples, because the examples are of variable quality or because one would\nlike to train with fewer examples, without sacrificing performance. We present\nGradient Information Optimization (GIO), a scalable, task-agnostic approach to\nthis data selection problem that requires only a small set of (unlabeled)\nexamples representing a target distribution. GIO begins from a natural,\ninformation-theoretic objective that is intractable in practice. Our\ncontribution is in showing that it can be made highly scalable through a simple\nrelaxation of the objective and a highly efficient implementation. In\nexperiments with machine translation, spelling correction, and image\nrecognition, we show that GIO delivers outstanding results with very small\ntrain sets. These findings are robust to different representation models and\nhyperparameters for GIO itself. GIO is task- and domain-agnostic and can be\napplied out-of-the-box to new datasets and domains.",
          "link": "http://arxiv.org/abs/2306.11670",
          "publishedOn": "2023-10-14T00:41:34.120Z",
          "wordCount": null,
          "title": "GIO: Gradient Information Optimization for Training Dataset Selection. (arXiv:2306.11670v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07891",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Moniri_B/0/1/0/all/0/1\">Behrad Moniri</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_D/0/1/0/all/0/1\">Donghwan Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>",
          "description": "Feature learning is thought to be one of the fundamental reasons for the\nsuccess of deep neural networks. It is rigorously known that in two-layer\nfully-connected neural networks under certain conditions, one step of gradient\ndescent on the first layer followed by ridge regression on the second layer can\nlead to feature learning; characterized by the appearance of a separated\nrank-one component -- spike -- in the spectrum of the feature matrix. However,\nwith a constant gradient descent step size, this spike only carries information\nfrom the linear component of the target function and therefore learning\nnon-linear components is impossible. We show that with a learning rate that\ngrows with the sample size, such training in fact introduces multiple rank-one\ncomponents, each corresponding to a specific polynomial feature. We further\nprove that the limiting large-dimensional and large sample training and test\nerrors of the updated neural networks are fully characterized by these spikes.\nBy precisely analyzing the improvement in the loss, we demonstrate that these\nnon-linear features can enhance learning.",
          "link": "http://arxiv.org/abs/2310.07891",
          "publishedOn": "2023-10-14T00:41:34.119Z",
          "wordCount": null,
          "title": "A Theory of Non-Linear Feature Learning with One Gradient Step in Two-Layer Neural Networks. (arXiv:2310.07891v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08041",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ruihao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiuying Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zhiwei Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jianfei Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1\">Bohan Zhuang</a>",
          "description": "Large Language Models (LLMs) excel in NLP, but their demands hinder their\nwidespread deployment. While Quantization-Aware Training (QAT) offers a\nsolution, its extensive training costs make Post-Training Quantization (PTQ) a\nmore practical approach for LLMs. In existing studies, activation outliers in\nparticular channels are identified as the bottleneck to PTQ accuracy. They\npropose to transform the magnitudes from activations to weights, which however\noffers limited alleviation or suffers from unstable gradients, resulting in a\nsevere performance drop at low-bitwidth. In this paper, we propose QLLM, an\naccurate and efficient low-bitwidth PTQ method designed for LLMs. QLLM\nintroduces an adaptive channel reassembly technique that reallocates the\nmagnitude of outliers to other channels, thereby mitigating their impact on the\nquantization range. This is achieved by channel disassembly and channel\nassembly, which first breaks down the outlier channels into several\nsub-channels to ensure a more balanced distribution of activation magnitudes.\nThen similar channels are merged to maintain the original channel number for\nefficiency. Additionally, an adaptive strategy is designed to autonomously\ndetermine the optimal number of sub-channels for channel disassembly. To\nfurther compensate for the performance loss caused by quantization, we propose\nan efficient tuning method that only learns a small number of low-rank weights\nwhile freezing the pre-trained quantized model. After training, these low-rank\nparameters can be fused into the frozen weights without affecting inference.\nExtensive experiments on LLaMA-1 and LLaMA-2 show that QLLM can obtain accurate\nquantized models efficiently. For example, QLLM quantizes the 4-bit LLaMA-2-70B\nwithin 10 hours on a single A100-80G GPU, outperforming the previous\nstate-of-the-art method by 7.89% on the average accuracy across five zero-shot\ntasks.",
          "link": "http://arxiv.org/abs/2310.08041",
          "publishedOn": "2023-10-14T00:41:34.110Z",
          "wordCount": 782,
          "title": "QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models. (arXiv:2310.08041v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vijayan_P/0/1/0/all/0/1\">Preetha Vijayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_P/0/1/0/all/0/1\">Prashant Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1\">Elahe Arani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1\">Bahram Zonooz</a>",
          "description": "Continual learning (CL) has remained a persistent challenge for deep neural\nnetworks due to catastrophic forgetting (CF) of previously learned tasks.\nSeveral techniques such as weight regularization, experience rehearsal, and\nparameter isolation have been proposed to alleviate CF. Despite their relative\nsuccess, these research directions have predominantly remained orthogonal and\nsuffer from several shortcomings, while missing out on the advantages of\ncompeting strategies. On the contrary, the brain continually learns,\naccommodates, and transfers knowledge across tasks by simultaneously leveraging\nseveral neurophysiological processes, including neurogenesis, active\nforgetting, neuromodulation, metaplasticity, experience rehearsal, and\ncontext-dependent gating, rarely resulting in CF. Inspired by how the brain\nexploits multiple mechanisms concurrently, we propose TriRE, a novel CL\nparadigm that encompasses retaining the most prominent neurons for each task,\nrevising and solidifying the extracted knowledge of current and past tasks, and\nactively promoting less active neurons for subsequent tasks through rewinding\nand relearning. Across CL settings, TriRE significantly reduces task\ninterference and surpasses different CL approaches considered in isolation.",
          "link": "http://arxiv.org/abs/2310.08217",
          "publishedOn": "2023-10-14T00:41:34.084Z",
          "wordCount": 690,
          "title": "TriRE: A Multi-Mechanism Learning Paradigm for Continual Knowledge Retention and Promotion. (arXiv:2310.08217v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Floris_G/0/1/0/all/0/1\">Giuseppe Floris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mura_R/0/1/0/all/0/1\">Raffaele Mura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scionis_L/0/1/0/all/0/1\">Luca Scionis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piras_G/0/1/0/all/0/1\">Giorgio Piras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1\">Maura Pintor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demontis_A/0/1/0/all/0/1\">Ambra Demontis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1\">Battista Biggio</a>",
          "description": "Evaluating the adversarial robustness of machine learning models using\ngradient-based attacks is challenging. In this work, we show that\nhyperparameter optimization can improve fast minimum-norm attacks by automating\nthe selection of the loss function, the optimizer and the step-size scheduler,\nalong with the corresponding hyperparameters. Our extensive evaluation\ninvolving several robust models demonstrates the improved efficacy of fast\nminimum-norm attacks when hyper-up with hyperparameter optimization. We release\nour open-source code at https://github.com/pralab/HO-FMN.",
          "link": "http://arxiv.org/abs/2310.08177",
          "publishedOn": "2023-10-14T00:41:34.048Z",
          "wordCount": 599,
          "title": "Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization. (arXiv:2310.08177v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.10108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inae_E/0/1/0/all/0/1\">Eric Inae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiaxin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1\">Tengfei Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>",
          "description": "Graph property prediction tasks are important and numerous. While each task\noffers a small size of labeled examples, unlabeled graphs have been collected\nfrom various sources and at a large scale. A conventional approach is training\na model with the unlabeled graphs on self-supervised tasks and then fine-tuning\nthe model on the prediction tasks. However, the self-supervised task knowledge\ncould not be aligned or sometimes conflicted with what the predictions needed.\nIn this paper, we propose to extract the knowledge underlying the large set of\nunlabeled graphs as a specific set of useful data points to augment each\nproperty prediction model. We use a diffusion model to fully utilize the\nunlabeled graphs and design two new objectives to guide the model's denoising\nprocess with each task's labeled data to generate task-specific graph examples\nand their labels. Experiments demonstrate that our data-centric approach\nperforms significantly better than fifteen existing various methods on fifteen\ntasks. The performance improvement brought by unlabeled data is visible as the\ngenerated labeled examples unlike the self-supervised learning.",
          "link": "http://arxiv.org/abs/2303.10108",
          "publishedOn": "2023-10-14T00:41:34.042Z",
          "wordCount": 698,
          "title": "Data-Centric Learning from Unlabeled Graphs with Diffusion Model. (arXiv:2303.10108v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1908.04628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xindi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varol_O/0/1/0/all/0/1\">Onur Varol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1\">Tina Eliassi-Rad</a>",
          "description": "Many real-world prediction tasks have outcome variables that have\ncharacteristic heavy-tail distributions. Examples include copies of books sold,\nauction prices of art pieces, demand for commodities in warehouses, etc. By\nlearning heavy-tailed distributions, \"big and rare\" instances (e.g., the\nbest-sellers) will have accurate predictions. Most existing approaches are not\ndedicated to learning heavy-tailed distribution; thus, they heavily\nunder-predict such instances. To tackle this problem, we introduce Learning to\nPlace (L2P), which exploits the pairwise relationships between instances for\nlearning. In its training phase, L2P learns a pairwise preference classifier:\nis instance A > instance B? In its placing phase, L2P obtains a prediction by\nplacing the new instance among the known instances. Based on its placement, the\nnew instance is then assigned a value for its outcome variable. Experiments on\nreal data show that L2P outperforms competing approaches in terms of accuracy\nand ability to reproduce heavy-tailed outcome distribution. In addition, L2P\nprovides an interpretable model by placing each predicted instance in relation\nto its comparable neighbors. Interpretable models are highly desirable when\nlives and treasure are at stake.",
          "link": "http://arxiv.org/abs/1908.04628",
          "publishedOn": "2023-10-14T00:41:34.034Z",
          "wordCount": null,
          "title": "L2P: Learning to Place for Estimating Heavy-Tailed Distributed Outcomes. (arXiv:1908.04628v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08061",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Yi_Y/0/1/0/all/0/1\">Yiqiang Yi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wan_X/0/1/0/all/0/1\">Xu Wan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bian_Y/0/1/0/all/0/1\">Yatao Bian</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ou_Yang_L/0/1/0/all/0/1\">Le Ou-Yang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_P/0/1/0/all/0/1\">Peilin Zhao</a>",
          "description": "Predicting the docking between proteins and ligands is a crucial and\nchallenging task for drug discovery. However, traditional docking methods\nmainly rely on scoring functions, and deep learning-based docking approaches\nusually neglect the 3D spatial information of proteins and ligands, as well as\nthe graph-level features of ligands, which limits their performance. To address\nthese limitations, we propose an equivariant transformer neural network for\nprotein-ligand docking pose prediction. Our approach involves the fusion of\nligand graph-level features by feature processing, followed by the learning of\nligand and protein representations using our proposed TAMformer module.\nAdditionally, we employ an iterative optimization approach based on the\npredicted distance matrix to generate refined ligand poses. The experimental\nresults on real datasets show that our model can achieve state-of-the-art\nperformance.",
          "link": "http://arxiv.org/abs/2310.08061",
          "publishedOn": "2023-10-14T00:41:34.027Z",
          "wordCount": 625,
          "title": "ETDock: A Novel Equivariant Transformer for Protein-Ligand Docking. (arXiv:2310.08061v1 [q-bio.BM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rasul_K/0/1/0/all/0/1\">Kashif Rasul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashok_A/0/1/0/all/0/1\">Arjun Ashok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Andrew Robert Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khorasani_A/0/1/0/all/0/1\">Arian Khorasani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adamopoulos_G/0/1/0/all/0/1\">George Adamopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagwatkar_R/0/1/0/all/0/1\">Rishika Bhagwatkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilos_M/0/1/0/all/0/1\">Marin Bilo&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghonia_H/0/1/0/all/0/1\">Hena Ghonia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassen_N/0/1/0/all/0/1\">Nadhir Vincent Hassen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_A/0/1/0/all/0/1\">Anderson Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Sahil Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drouin_A/0/1/0/all/0/1\">Alexandre Drouin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapados_N/0/1/0/all/0/1\">Nicolas Chapados</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nevmyvaka_Y/0/1/0/all/0/1\">Yuriy Nevmyvaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>",
          "description": "Aiming to build foundation models for time-series forecasting and study their\nscaling behavior, we present here our work-in-progress on Lag-Llama, a\ngeneral-purpose univariate probabilistic time-series forecasting model trained\non a large collection of time-series data. The model shows good zero-shot\nprediction capabilities on unseen \"out-of-distribution\" time-series datasets,\noutperforming supervised baselines. We use smoothly broken power-laws to fit\nand predict model scaling behavior. The open source code is made available at\nhttps://github.com/kashif/pytorch-transformer-ts.",
          "link": "http://arxiv.org/abs/2310.08278",
          "publishedOn": "2023-10-14T00:41:34.021Z",
          "wordCount": null,
          "title": "Lag-Llama: Towards Foundation Models for Time Series Forecasting. (arXiv:2310.08278v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08039",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jinbo Song</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ruoran Huang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyang Wang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qian Yu</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingming Chen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yafei Yao</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chaosheng Fan</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1\">Changping Peng</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhangang Lin</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jinghe Hu</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1\">Jingping Shao</a> (1) ((1) Marketing and Commercialization Center, JD.com)",
          "description": "Industrial systems such as recommender systems and online advertising, have\nbeen widely equipped with multi-stage architectures, which are divided into\nseveral cascaded modules, including matching, pre-ranking, ranking and\nre-ranking. As a critical bridge between matching and ranking, existing\npre-ranking approaches mainly endure sample selection bias (SSB) problem owing\nto ignoring the entire-chain data dependence, resulting in sub-optimal\nperformances. In this paper, we rethink pre-ranking system from the perspective\nof the entire sample space, and propose Entire-chain Cross-domain Models (ECM),\nwhich leverage samples from the whole cascaded stages to effectively alleviate\nSSB problem. Besides, we design a fine-grained neural structure named ECMM to\nfurther improve the pre-ranking accuracy. Specifically, we propose a\ncross-domain multi-tower neural network to comprehensively predict for each\nstage result, and introduce the sub-networking routing strategy with $L0$\nregularization to reduce computational costs. Evaluations on real-world\nlarge-scale traffic logs demonstrate that our pre-ranking models outperform\nSOTA methods while time consumption is maintained within an acceptable level,\nwhich achieves better trade-off between efficiency and effectiveness.",
          "link": "http://arxiv.org/abs/2310.08039",
          "publishedOn": "2023-10-14T00:41:33.997Z",
          "wordCount": null,
          "title": "Rethinking Large-scale Pre-ranking System: Entire-chain Cross-domain Models. (arXiv:2310.08039v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08348",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Niu_Y/0/1/0/all/0/1\">Yazhe Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1\">Yuan Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhenjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xueyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jiyuan Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shuai Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu Liu</a>",
          "description": "Building agents based on tree-search planning capabilities with learned\nmodels has achieved remarkable success in classic decision-making problems,\nsuch as Go and Atari. However, it has been deemed challenging or even\ninfeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse\nreal-world applications, especially when these environments involve complex\naction spaces and significant simulation costs, or inherent stochasticity. In\nthis work, we introduce LightZero, the first unified benchmark for deploying\nMCTS/MuZero in general sequential decision scenarios. Specificially, we\nsummarize the most critical challenges in designing a general MCTS-style\ndecision-making solver, then decompose the tightly-coupled algorithm and system\ndesign of tree-search RL methods into distinct sub-modules. By incorporating\nmore appropriate exploration and optimization strategies, we can significantly\nenhance these sub-modules and construct powerful LightZero agents to tackle\ntasks across a wide range of domains, such as board games, Atari, MuJoCo,\nMiniGrid and GoBigger. Detailed benchmark results reveal the significant\npotential of such methods in building scalable and efficient decision\nintelligence. The code is available as part of OpenDILab at\nhttps://github.com/opendilab/LightZero.",
          "link": "http://arxiv.org/abs/2310.08348",
          "publishedOn": "2023-10-14T00:41:33.996Z",
          "wordCount": 711,
          "title": "LightZero: A Unified Benchmark for Monte Carlo Tree Search in General Sequential Decision Scenarios. (arXiv:2310.08348v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jihye Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tople_S/0/1/0/all/0/1\">Shruti Tople</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrasekaran_V/0/1/0/all/0/1\">Varun Chandrasekaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Somesh Jha</a>",
          "description": "Membership Inference Attacks (MIAs) aim to identify specific data samples\nwithin the private training dataset of machine learning models, leading to\nserious privacy violations and other sophisticated threats. Many practical\nblack-box MIAs require query access to the data distribution (the same\ndistribution where the private data is drawn) to train shadow models. By doing\nso, the adversary obtains models trained \"with\" or \"without\" samples drawn from\nthe distribution, and analyzes the characteristics of the samples under\nconsideration. The adversary is often required to train more than hundreds of\nshadow models to extract the signals needed for MIAs; this becomes the\ncomputational overhead of MIAs. In this paper, we propose that by strategically\nchoosing the samples, MI adversaries can maximize their attack success while\nminimizing the number of shadow models. First, our motivational experiments\nsuggest memorization as the key property explaining disparate sample\nvulnerability to MIAs. We formalize this through a theoretical bound that\nconnects MI advantage with memorization. Second, we show sample complexity\nbounds that connect the number of shadow models needed for MIAs with\nmemorization. Lastly, we confirm our theoretical arguments with comprehensive\nexperiments; by utilizing samples with high memorization scores, the adversary\ncan (a) significantly improve its efficacy regardless of the MIA used, and (b)\nreduce the number of shadow models by nearly two orders of magnitude compared\nto state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2310.08015",
          "publishedOn": "2023-10-14T00:41:33.989Z",
          "wordCount": 738,
          "title": "Why Train More? Effective and Efficient Membership Inference via Memorization. (arXiv:2310.08015v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaopeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_Z/0/1/0/all/0/1\">Zhenlin An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Q/0/1/0/all/0/1\">Qingrui Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lei Yang</a>",
          "description": "Although Maxwell discovered the physical laws of electromagnetic waves 160\nyears ago, how to precisely model the propagation of an RF signal in an\nelectrically large and complex environment remains a long-standing problem. The\ndifficulty is in the complex interactions between the RF signal and the\nobstacles (e.g., reflection, diffraction, etc.). Inspired by the great success\nof using a neural network to describe the optical field in computer vision, we\npropose a neural radio-frequency radiance field, NeRF$^\\textbf{2}$, which\nrepresents a continuous volumetric scene function that makes sense of an RF\nsignal's propagation. Particularly, after training with a few signal\nmeasurements, NeRF$^\\textbf{2}$ can tell how/what signal is received at any\nposition when it knows the position of a transmitter. As a physical-layer\nneural network, NeRF$^\\textbf{2}$ can take advantage of the learned statistic\nmodel plus the physical model of ray tracing to generate a synthetic dataset\nthat meets the training demands of application-layer artificial neural networks\n(ANNs). Thus, we can boost the performance of ANNs by the proposed\nturbo-learning, which mixes the true and synthetic datasets to intensify the\ntraining. Our experiment results show that turbo-learning can enhance\nperformance with an approximate 50% increase. We also demonstrate the power of\nNeRF$^\\textbf{2}$ in the field of indoor localization and 5G MIMO.",
          "link": "http://arxiv.org/abs/2305.06118",
          "publishedOn": "2023-10-14T00:41:33.989Z",
          "wordCount": null,
          "title": "NeRF2: Neural Radio-Frequency Radiance Fields. (arXiv:2305.06118v2 [cs.NI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.07481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brekelmans_R/0/1/0/all/0/1\">Rob Brekelmans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1\">Frank Nielsen</a>",
          "description": "Markov Chain Monte Carlo methods for sampling from complex distributions and\nestimating normalization constants often simulate samples from a sequence of\nintermediate distributions along an annealing path, which bridges between a\ntractable initial distribution and a target density of interest. Prior work has\nconstructed annealing paths using quasi-arithmetic means, and interpreted the\nresulting intermediate densities as minimizing an expected divergence to the\nendpoints. We provide a comprehensive analysis of this 'centroid' property\nusing Bregman divergences under a monotonic embedding of the density function,\nthereby associating common divergences such as Amari's and Renyi's\n${\\alpha}$-divergences, ${(\\alpha,\\beta)}$-divergences, and the Jensen-Shannon\ndivergence with intermediate densities along an annealing path. Our analysis\nhighlights the interplay between parametric families, quasi-arithmetic means,\nand divergence functions using the rho-tau Bregman divergence framework of\nZhang 2004,2013.",
          "link": "http://arxiv.org/abs/2209.07481",
          "publishedOn": "2023-10-14T00:41:33.978Z",
          "wordCount": null,
          "title": "Quasi-Arithmetic Mixtures, Divergence Minimization, and Bregman Information. (arXiv:2209.07481v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.12389",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalluri_T/0/1/0/all/0/1\">Tarun Kalluri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Astuti Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandraker_M/0/1/0/all/0/1\">Manmohan Chandraker</a>",
          "description": "Practical real world datasets with plentiful categories introduce new\nchallenges for unsupervised domain adaptation like small inter-class\ndiscriminability, that existing approaches relying on domain invariance alone\ncannot handle sufficiently well. In this work we propose MemSAC, which exploits\nsample level similarity across source and target domains to achieve\ndiscriminative transfer, along with architectures that scale to a large number\nof categories. For this purpose, we first introduce a memory augmented approach\nto efficiently extract pairwise similarity relations between labeled source and\nunlabeled target domain instances, suited to handle an arbitrary number of\nclasses. Next, we propose and theoretically justify a novel variant of the\ncontrastive loss to promote local consistency among within-class cross domain\nsamples while enforcing separation between classes, thus preserving\ndiscriminative transfer from source to target. We validate the advantages of\nMemSAC with significant improvements over previous state-of-the-art on multiple\nchallenging transfer tasks designed for large-scale adaptation, such as\nDomainNet with 345 classes and fine-grained adaptation on Caltech-UCSD birds\ndataset with 200 classes. We also provide in-depth analysis and insights into\nthe effectiveness of MemSAC.",
          "link": "http://arxiv.org/abs/2207.12389",
          "publishedOn": "2023-10-14T00:41:33.948Z",
          "wordCount": null,
          "title": "MemSAC: Memory Augmented Sample Consistency for Large Scale Unsupervised Domain Adaptation. (arXiv:2207.12389v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1\">Jiali Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Tian Han</a>",
          "description": "This paper studies the fundamental problem of learning multi-layer generator\nmodels. The multi-layer generator model builds multiple layers of latent\nvariables as a prior model on top of the generator, which benefits learning\ncomplex data distribution and hierarchical representations. However, such a\nprior model usually focuses on modeling inter-layer relations between latent\nvariables by assuming non-informative (conditional) Gaussian distributions,\nwhich can be limited in model expressivity. To tackle this issue and learn more\nexpressive prior models, we propose an energy-based model (EBM) on the joint\nlatent space over all layers of latent variables with the multi-layer generator\nas its backbone. Such joint latent space EBM prior model captures the\nintra-layer contextual relations at each layer through layer-wise energy terms,\nand latent variables across different layers are jointly corrected. We develop\na joint training scheme via maximum likelihood estimation (MLE), which involves\nMarkov Chain Monte Carlo (MCMC) sampling for both prior and posterior\ndistributions of the latent variables from different layers. To ensure\nefficient inference and learning, we further propose a variational training\nscheme where an inference model is used to amortize the costly posterior MCMC\nsampling. Our experiments demonstrate that the learned model can be expressive\nin generating high-quality images and capturing hierarchical features for\nbetter outlier detection.",
          "link": "http://arxiv.org/abs/2306.06323",
          "publishedOn": "2023-10-14T00:41:33.934Z",
          "wordCount": 737,
          "title": "Learning Joint Latent Space EBM Prior Model for Multi-layer Generator. (arXiv:2306.06323v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Werner_J/0/1/0/all/0/1\">Julia Werner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerum_C/0/1/0/all/0/1\">Christoph Gerum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reiber_M/0/1/0/all/0/1\">Moritz Reiber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nick_J/0/1/0/all/0/1\">J&#xf6;rg Nick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bringmann_O/0/1/0/all/0/1\">Oliver Bringmann</a>",
          "description": "This paper presents a method to efficiently classify the gastroenterologic\nsection of images derived from Video Capsule Endoscopy (VCE) studies by\nexploring the combination of a Convolutional Neural Network (CNN) for\nclassification with the time-series analysis properties of a Hidden Markov\nModel (HMM). It is demonstrated that successive time-series analysis identifies\nand corrects errors in the CNN output. Our approach achieves an accuracy of\n$98.04\\%$ on the Rhode Island (RI) Gastroenterology dataset. This allows for\nprecise localization within the gastrointestinal (GI) tract while requiring\nonly approximately 1M parameters and thus, provides a method suitable for low\npower devices",
          "link": "http://arxiv.org/abs/2310.07895",
          "publishedOn": "2023-10-14T00:41:33.907Z",
          "wordCount": 639,
          "title": "Precise localization within the GI tract by combining classification of CNNs and time-series analysis of HMMs. (arXiv:2310.07895v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.03874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joren_H/0/1/0/all/0/1\">Hailey Joren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1\">Chirag Nagpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_K/0/1/0/all/0/1\">Katherine Heller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ustun_B/0/1/0/all/0/1\">Berk Ustun</a>",
          "description": "Machine learning models are often personalized with information that is\nprotected, sensitive, self-reported, or costly to acquire. These models use\ninformation about people but do not facilitate nor inform their consent.\nIndividuals cannot opt out of reporting personal information to a model, nor\ntell if they benefit from personalization in the first place. We introduce a\nfamily of classification models, called participatory systems, that let\nindividuals opt into personalization at prediction time. We present a\nmodel-agnostic algorithm to learn participatory systems for personalization\nwith categorical group attributes. We conduct a comprehensive empirical study\nof participatory systems in clinical prediction tasks, benchmarking them with\ncommon approaches for personalization and imputation. Our results demonstrate\nthat participatory systems can facilitate and inform consent while improving\nperformance and data use across all groups who report personal data.",
          "link": "http://arxiv.org/abs/2302.03874",
          "publishedOn": "2023-10-14T00:41:33.783Z",
          "wordCount": null,
          "title": "Participatory Personalization in Classification. (arXiv:2302.03874v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.10902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhanglu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shida Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Kaiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_W/0/1/0/all/0/1\">Weng-Fai Wong</a>",
          "description": "Hyperdimensional computing (HDC) is a method to perform classification that\nuses binary vectors with high dimensions and the majority rule. This approach\nhas the potential to be energy-efficient and hence deemed suitable for\nresource-limited platforms due to its simplicity and massive parallelism.\nHowever, in order to achieve high accuracy, HDC sometimes uses hypervectors\nwith tens of thousands of dimensions. This potentially negates its efficiency\nadvantage. In this paper, we examine the necessity of such high dimensions and\nconduct a detailed theoretical analysis of the relationship between hypervector\ndimensions and accuracy. Our results demonstrate that as the dimension of the\nhypervectors increases, the worst-case/average-case HDC prediction accuracy\nwith the majority rule decreases. Building on this insight, we develop HDC\nmodels that use binary hypervectors with dimensions orders of magnitude lower\nthan those of state-of-the-art HDC models while maintaining equivalent or even\nimproved accuracy and efficiency. For instance, on the MNIST dataset, we\nachieve 91.12% HDC accuracy in image classification with a dimension of only\n64. Our methods perform operations that are only 0.35% of other HDC models with\ndimensions of 10,000. Furthermore, we evaluate our methods on ISOLET, UCI-HAR,\nand Fashion-MNIST datasets and investigate the limits of HDC computing.",
          "link": "http://arxiv.org/abs/2301.10902",
          "publishedOn": "2023-10-14T00:41:33.736Z",
          "wordCount": 732,
          "title": "Efficient Hyperdimensional Computing. (arXiv:2301.10902v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gholami_S/0/1/0/all/0/1\">Sia Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omar_M/0/1/0/all/0/1\">Marwan Omar</a>",
          "description": "Natural Language Processing (NLP) has undergone transformative changes with\nthe advent of deep learning methodologies. One challenge persistently\nconfronting researchers is the scarcity of high-quality, annotated datasets\nthat drive these models. This paper explores the nuances of synthetic data\ngeneration in NLP, with a focal point on template-based question generation. By\nassessing its advantages, including data augmentation potential and the\nintroduction of structured variety, we juxtapose these benefits against\ninherent limitations, such as the risk of overfitting and the constraints posed\nby pre-defined templates. Drawing from empirical evaluations, we demonstrate\nthe impact of template-based synthetic data on the performance of modern\ntransformer models. We conclude by emphasizing the delicate balance required\nbetween synthetic and real-world data, and the future trajectories of\nintegrating synthetic data in model training pipelines. The findings aim to\nguide NLP practitioners in harnessing synthetic data's potential, ensuring\noptimal model performance in diverse applications.",
          "link": "http://arxiv.org/abs/2310.07830",
          "publishedOn": "2023-10-14T00:41:33.731Z",
          "wordCount": 649,
          "title": "Does Synthetic Data Make Large Language Models More Efficient?. (arXiv:2310.07830v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07740",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Baumstark_M/0/1/0/all/0/1\">Matthew J. Baumstark</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Vinci_G/0/1/0/all/0/1\">Giuseppe Vinci</a>",
          "description": "The classification of galaxy morphologies is an important step in the\ninvestigation of theories of hierarchical structure formation. While human\nexpert visual classification remains quite effective and accurate, it cannot\nkeep up with the massive influx of data from emerging sky surveys. A variety of\napproaches have been proposed to classify large numbers of galaxies; these\napproaches include crowdsourced visual classification, and automated and\ncomputational methods, such as machine learning methods based on designed\nmorphology statistics and deep learning. In this work, we develop two novel\ngalaxy morphology statistics, descent average and descent variance, which can\nbe efficiently extracted from telescope galaxy images. We further propose\nsimplified versions of the existing image statistics concentration, asymmetry,\nand clumpiness, which have been widely used in the literature of galaxy\nmorphologies. We utilize the galaxy image data from the Sloan Digital Sky\nSurvey to demonstrate the effective performance of our proposed image\nstatistics at accurately detecting spiral and elliptical galaxies when used as\nfeatures of a random forest classifier.",
          "link": "http://arxiv.org/abs/2310.07740",
          "publishedOn": "2023-10-14T00:41:33.667Z",
          "wordCount": 696,
          "title": "Spiral-Elliptical automated galaxy morphology classification from telescope images. (arXiv:2310.07740v1 [astro-ph.IM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weng_E/0/1/0/all/0/1\">Erica Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoshino_H/0/1/0/all/0/1\">Hana Hoshino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1\">Deva Ramanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1\">Kris Kitani</a>",
          "description": "Multi-modal trajectory forecasting methods commonly evaluate using\nsingle-agent metrics (marginal metrics), such as minimum Average Displacement\nError (ADE) and Final Displacement Error (FDE), which fail to capture joint\nperformance of multiple interacting agents. Only focusing on marginal metrics\ncan lead to unnatural predictions, such as colliding trajectories or diverging\ntrajectories for people who are clearly walking together as a group.\nConsequently, methods optimized for marginal metrics lead to overly-optimistic\nestimations of performance, which is detrimental to progress in trajectory\nforecasting research. In response to the limitations of marginal metrics, we\npresent the first comprehensive evaluation of state-of-the-art (SOTA)\ntrajectory forecasting methods with respect to multi-agent metrics (joint\nmetrics): JADE, JFDE, and collision rate. We demonstrate the importance of\njoint metrics as opposed to marginal metrics with quantitative evidence and\nqualitative examples drawn from the ETH / UCY and Stanford Drone datasets. We\nintroduce a new loss function incorporating joint metrics that, when applied to\na SOTA trajectory forecasting method, achieves a 7\\% improvement in JADE / JFDE\non the ETH / UCY datasets with respect to the previous SOTA. Our results also\nindicate that optimizing for joint metrics naturally leads to an improvement in\ninteraction modeling, as evidenced by a 16\\% decrease in mean collision rate on\nthe ETH / UCY datasets with respect to the previous SOTA. Code is available at\n\\texttt{\\hyperlink{https://github.com/ericaweng/joint-metrics-matter}{github.com/ericaweng/joint-metrics-matter}}.",
          "link": "http://arxiv.org/abs/2305.06292",
          "publishedOn": "2023-10-14T00:41:33.655Z",
          "wordCount": 752,
          "title": "Joint Metrics Matter: A Better Standard for Trajectory Forecasting. (arXiv:2305.06292v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alkassab_N/0/1/0/all/0/1\">Nawras Alkassab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chin-Tser Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Botran_T/0/1/0/all/0/1\">Tania Lorido Botran</a>",
          "description": "Content Delivery Networks carry the majority of Internet traffic, and the\nincreasing demand for video content as a major IP traffic across the Internet\nhighlights the importance of caching and prefetching optimization algorithms.\nPrefetching aims to make data available in the cache before the requester\nplaces its request to reduce access time and improve the Quality of Experience\non the user side. Prefetching is well investigated in operating systems,\ncompiler instructions, in-memory cache, local storage systems, high-speed\nnetworks, and cloud systems. Traditional prefetching techniques are well\nadapted to a particular access pattern, but fail to adapt to sudden variations\nor randomization in workloads. This paper explores the use of reinforcement\nlearning to tackle the changes in user access patterns and automatically adapt\nover time. To this end, we propose, DeePref, a Deep Reinforcement Learning\nagent for online video content prefetching in Content Delivery Networks.\nDeePref is a prefetcher implemented on edge networks and is agnostic to\nhardware design, operating systems, and applications. Our results show that\nDeePref DRQN, using a real-world dataset, achieves a 17% increase in\nprefetching accuracy and a 28% increase in prefetching coverage on average\ncompared to baseline approaches that use video content popularity as a building\nblock to statically or dynamically make prefetching decisions. We also study\nthe possibility of transfer learning of statistical models from one edge\nnetwork into another, where unseen user requests from unknown distribution are\nobserved. In terms of transfer learning, the increase in prefetching accuracy\nand prefetching coverage are [$30%$, $10%$], respectively. Our source code will\nbe available on Github.",
          "link": "http://arxiv.org/abs/2310.07881",
          "publishedOn": "2023-10-14T00:41:33.650Z",
          "wordCount": 774,
          "title": "DeePref: Deep Reinforcement Learning For Video Prefetching In Content Delivery Networks. (arXiv:2310.07881v1 [cs.NI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zheqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yueyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_X/0/1/0/all/0/1\">Xu Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Real-world applications of contextual bandits often exhibit non-stationarity\ndue to seasonality, serendipity, and evolving social trends. While a number of\nnon-stationary contextual bandit learning algorithms have been proposed in the\nliterature, they excessively explore due to a lack of prioritization for\ninformation of enduring value, or are designed in ways that do not scale in\nmodern applications with high-dimensional user-specific features and large\naction set, or both. In this paper, we introduce a novel non-stationary\ncontextual bandit algorithm that addresses these concerns. It combines a\nscalable, deep-neural-network-based architecture with a carefully designed\nexploration mechanism that strategically prioritizes collecting information\nwith the most lasting value in a non-stationary environment. Through empirical\nevaluations on two real-world recommendation datasets, which exhibit pronounced\nnon-stationarity, we demonstrate that our approach significantly outperforms\nthe state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2310.07786",
          "publishedOn": "2023-10-14T00:41:33.646Z",
          "wordCount": 639,
          "title": "Non-Stationary Contextual Bandit Learning via Neural Predictive Ensemble Sampling. (arXiv:2310.07786v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08138",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haiyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chunjiang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Detian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qing Li</a>",
          "description": "Traffic flow prediction is one of the most fundamental tasks of intelligent\ntransportation systems. The complex and dynamic spatial-temporal dependencies\nmake the traffic flow prediction quite challenging. Although existing\nspatial-temporal graph neural networks hold prominent, they often encounter\nchallenges such as (1) ignoring the fixed graph that limits the predictive\nperformance of the model, (2) insufficiently capturing complex spatial-temporal\ndependencies simultaneously, and (3) lacking attention to spatial-temporal\ninformation at different time lengths. In this paper, we propose a Multi-Scale\nSpatial-Temporal Recurrent Network for traffic flow prediction, namely MSSTRN,\nwhich consists of two different recurrent neural networks: the single-step gate\nrecurrent unit and the multi-step gate recurrent unit to fully capture the\ncomplex spatial-temporal information in the traffic data under different time\nwindows. Moreover, we propose a spatial-temporal synchronous attention\nmechanism that integrates adaptive position graph convolutions into the\nself-attention mechanism to achieve synchronous capture of spatial-temporal\ndependencies. We conducted extensive experiments on four real traffic datasets\nand demonstrated that our model achieves the best prediction accuracy with\nnon-trivial margins compared to all the twenty baseline methods.",
          "link": "http://arxiv.org/abs/2310.08138",
          "publishedOn": "2023-10-14T00:41:33.615Z",
          "wordCount": 682,
          "title": "Multi-Scale Spatial-Temporal Recurrent Networks for Traffic Flow Prediction. (arXiv:2310.08138v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_N/0/1/0/all/0/1\">Namiko Matsumoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>",
          "description": "In 1-bit compressed sensing, the aim is to estimate a $k$-sparse unit vector\n$x\\in S^{n-1}$ within an $\\epsilon$ error (in $\\ell_2$) from minimal number of\nlinear measurements that are quantized to just their signs, i.e., from\nmeasurements of the form $y = \\mathrm{Sign}(\\langle a, x\\rangle).$ In this\npaper, we study a noisy version where a fraction of the measurements can be\nflipped, potentially by an adversary. In particular, we analyze the Binary\nIterative Hard Thresholding (BIHT) algorithm, a proximal gradient descent on a\nproperly defined loss function used for 1-bit compressed sensing, in this noisy\nsetting. It is known from recent results that, with\n$\\tilde{O}(\\frac{k}{\\epsilon})$ noiseless measurements, BIHT provides an\nestimate within $\\epsilon$ error. This result is optimal and universal, meaning\none set of measurements work for all sparse vectors. In this paper, we show\nthat BIHT also provides better results than all known methods for the noisy\nsetting. We show that when up to $\\tau$-fraction of the sign measurements are\nincorrect (adversarial error), with the same number of measurements as before,\nBIHT agnostically provides an estimate of $x$ within an\n$\\tilde{O}(\\epsilon+\\tau)$ error, maintaining the universality of measurements.\nThis establishes stability of iterative hard thresholding in the presence of\nmeasurement error. To obtain the result, we use the restricted approximate\ninvertibility of Gaussian matrices, as well as a tight analysis of the\nhigh-dimensional geometry of the adversarially corrupted measurements.",
          "link": "http://arxiv.org/abs/2310.08019",
          "publishedOn": "2023-10-14T00:41:33.573Z",
          "wordCount": 753,
          "title": "Robust 1-bit Compressed Sensing with Iterative Hard Thresholding. (arXiv:2310.08019v1 [cs.IT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.19838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bardou_A/0/1/0/all/0/1\">Anthony Bardou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiran_P/0/1/0/all/0/1\">Patrick Thiran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Begin_T/0/1/0/all/0/1\">Thomas Begin</a>",
          "description": "Bayesian Optimization (BO) is typically used to optimize an unknown function\n$f$ that is noisy and costly to evaluate, by exploiting an acquisition function\nthat must be maximized at each optimization step. Even if provably\nasymptotically optimal BO algorithms are efficient at optimizing\nlow-dimensional functions, scaling them to high-dimensional spaces remains an\nopen problem, often tackled by assuming an additive structure for $f$. By doing\nso, BO algorithms typically introduce additional restrictive assumptions on the\nadditive structure that reduce their applicability domain. This paper contains\ntwo main contributions: (i) we relax the restrictive assumptions on the\nadditive structure of $f$, at the expense of weakening the maximization\nguarantees of the acquisition function, and (ii) we address the\nover-exploration problem for decentralized BO algorithms. To these ends, we\npropose DumBO, an asymptotically optimal decentralized BO algorithm that\nachieves very competitive performance against state-of-the-art BO algorithms,\nespecially when the additive structure of $f$ comprises high-dimensional\nfactors.",
          "link": "http://arxiv.org/abs/2305.19838",
          "publishedOn": "2023-10-14T00:41:33.558Z",
          "wordCount": 680,
          "title": "Relaxing the Additivity Constraints in Decentralized No-Regret High-Dimensional Bayesian Optimization. (arXiv:2305.19838v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhendong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miliou_I/0/1/0/all/0/1\">Ioanna Miliou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samsten_I/0/1/0/all/0/1\">Isak Samsten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papapetrou_P/0/1/0/all/0/1\">Panagiotis Papapetrou</a>",
          "description": "Among recent developments in time series forecasting methods, deep\nforecasting models have gained popularity as they can utilize hidden feature\npatterns in time series to improve forecasting performance. Nevertheless, the\nmajority of current deep forecasting models are opaque, hence making it\nchallenging to interpret the results. While counterfactual explanations have\nbeen extensively employed as a post-hoc approach for explaining classification\nmodels, their application to forecasting models still remains underexplored. In\nthis paper, we formulate the novel problem of counterfactual generation for\ntime series forecasting, and propose an algorithm, called ForecastCF, that\nsolves the problem by applying gradient-based perturbations to the original\ntime series. ForecastCF guides the perturbations by applying constraints to the\nforecasted values to obtain desired prediction outcomes. We experimentally\nevaluate ForecastCF using four state-of-the-art deep model architectures and\ncompare to two baselines. Our results show that ForecastCF outperforms the\nbaseline in terms of counterfactual validity and data manifold closeness.\nOverall, our findings suggest that ForecastCF can generate meaningful and\nrelevant counterfactual explanations for various forecasting tasks.",
          "link": "http://arxiv.org/abs/2310.08137",
          "publishedOn": "2023-10-14T00:41:33.550Z",
          "wordCount": 671,
          "title": "Counterfactual Explanations for Time Series Forecasting. (arXiv:2310.08137v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1\">Bowen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Hansi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiusi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1\">Tianxin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruirui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xianfeng Tang</a>",
          "description": "Semantic identifier (ID) is an important concept in information retrieval\nthat aims to preserve the semantics of objects such as documents and items\ninside their IDs. Previous studies typically adopt a two-stage pipeline to\nlearn semantic IDs by first procuring embeddings using off-the-shelf text\nencoders and then deriving IDs based on the embeddings. However, each step\nintroduces potential information loss and there is usually an inherent mismatch\nbetween the distribution of embeddings within the latent space produced by text\nencoders and the anticipated distribution required for semantic indexing.\nNevertheless, it is non-trivial to design a method that can learn the\ndocument's semantic representations and its hierarchical structure\nsimultaneously, given that semantic IDs are discrete and sequentially\nstructured, and the semantic supervision is deficient. In this paper, we\nintroduce LMINDEXER, a self-supervised framework to learn semantic IDs with a\ngenerative language model. We tackle the challenge of sequential discrete ID by\nintroducing a semantic indexer capable of generating neural sequential discrete\nrepresentations with progressive training and contrastive learning. In response\nto the semantic supervision deficiency, we propose to train the model with a\nself-supervised document reconstruction objective. The learned semantic indexer\ncan facilitate various downstream tasks, such as recommendation and retrieval.\nWe conduct experiments on three tasks including recommendation, product search,\nand document retrieval on five datasets from various domains, where LMINDEXER\noutperforms competitive baselines significantly and consistently.",
          "link": "http://arxiv.org/abs/2310.07815",
          "publishedOn": "2023-10-14T00:41:33.265Z",
          "wordCount": null,
          "title": "Language Models As Semantic Indexers. (arXiv:2310.07815v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamp_M/0/1/0/all/0/1\">Michael Kamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_J/0/1/0/all/0/1\">Jonas Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vreeken_J/0/1/0/all/0/1\">Jilles Vreeken</a>",
          "description": "Federated learning allows multiple parties to collaboratively train a joint\nmodel without sharing local data. This enables applications of machine learning\nin settings of inherently distributed, undisclosable data such as in the\nmedical domain. In practice, joint training is usually achieved by aggregating\nlocal models, for which local training objectives have to be in expectation\nsimilar to the joint (global) objective. Often, however, local datasets are so\nsmall that local objectives differ greatly from the global objective, resulting\nin federated learning to fail. We propose a novel approach that intertwines\nmodel aggregations with permutations of local models. The permutations expose\neach local model to a daisy chain of local datasets resulting in more efficient\ntraining in data-sparse domains. This enables training on extremely small local\ndatasets, such as patient data across hospitals, while retaining the training\nefficiency and privacy benefits of federated learning.",
          "link": "http://arxiv.org/abs/2110.03469",
          "publishedOn": "2023-10-14T00:41:33.205Z",
          "wordCount": null,
          "title": "Federated Learning from Small Datasets. (arXiv:2110.03469v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1\">Xianghao Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_O/0/1/0/all/0/1\">Ollie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Han Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yogatama_D/0/1/0/all/0/1\">Dani Yogatama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1\">Greg Ver Steeg</a>",
          "description": "Denoising diffusion models enable conditional generation and density modeling\nof complex relationships like images and text. However, the nature of the\nlearned relationships is opaque making it difficult to understand precisely\nwhat relationships between words and parts of an image are captured, or to\npredict the effect of an intervention. We illuminate the fine-grained\nrelationships learned by diffusion models by noticing a precise relationship\nbetween diffusion and information decomposition. Exact expressions for mutual\ninformation and conditional mutual information can be written in terms of the\ndenoising model. Furthermore, pointwise estimates can be easily estimated as\nwell, allowing us to ask questions about the relationships between specific\nimages and captions. Decomposing information even further to understand which\nvariables in a high-dimensional space carry information is a long-standing\nproblem. For diffusion models, we show that a natural non-negative\ndecomposition of mutual information emerges, allowing us to quantify\ninformative relationships between words and pixels in an image. We exploit\nthese new relations to measure the compositional understanding of diffusion\nmodels, to do unsupervised localization of objects in images, and to measure\neffects when selectively editing images through prompt interventions.",
          "link": "http://arxiv.org/abs/2310.07972",
          "publishedOn": "2023-10-14T00:41:33.203Z",
          "wordCount": null,
          "title": "Interpretable Diffusion via Information Decomposition. (arXiv:2310.07972v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schimanski_T/0/1/0/all/0/1\">Tobias Schimanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bingler_J/0/1/0/all/0/1\">Julia Bingler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hyslop_C/0/1/0/all/0/1\">Camilla Hyslop</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraus_M/0/1/0/all/0/1\">Mathias Kraus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leippold_M/0/1/0/all/0/1\">Markus Leippold</a>",
          "description": "Public and private actors struggle to assess the vast amounts of information\nabout sustainability commitments made by various institutions. To address this\nproblem, we create a novel tool for automatically detecting corporate,\nnational, and regional net zero and reduction targets in three steps. First, we\nintroduce an expert-annotated data set with 3.5K text samples. Second, we train\nand release ClimateBERT-NetZero, a natural language classifier to detect\nwhether a text contains a net zero or reduction target. Third, we showcase its\nanalysis potential with two use cases: We first demonstrate how\nClimateBERT-NetZero can be combined with conventional question-answering (Q&A)\nmodels to analyze the ambitions displayed in net zero and reduction targets.\nFurthermore, we employ the ClimateBERT-NetZero model on quarterly earning call\ntranscripts and outline how communication patterns evolve over time. Our\nexperiments demonstrate promising pathways for extracting and analyzing net\nzero and emission reduction targets at scale.",
          "link": "http://arxiv.org/abs/2310.08096",
          "publishedOn": "2023-10-14T00:41:33.038Z",
          "wordCount": null,
          "title": "ClimateBERT-NetZero: Detecting and Assessing Net Zero and Reduction Targets. (arXiv:2310.08096v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Binghui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gysel_P/0/1/0/all/0/1\">Philipp Gysel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Divakaran_D/0/1/0/all/0/1\">Dinil Mon Divakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurusamy_M/0/1/0/all/0/1\">Mohan Gurusamy</a>",
          "description": "Recent research works have proposed machine learning models for classifying\nIoT devices connected to a network. However, there is still a practical\nchallenge of not having all devices (and hence their traffic) available during\nthe training of a model. This essentially means, during the operational phase,\nwe need to classify new devices not seen during the training phase. To address\nthis challenge, we propose ZEST -- a ZSL (zero-shot learning) framework based\non self-attention for classifying both seen and unseen devices. ZEST consists\nof i) a self-attention based network feature extractor, termed SANE, for\nextracting latent space representations of IoT traffic, ii) a generative model\nthat trains a decoder using latent features to generate pseudo data, and iii) a\nsupervised model that is trained on the generated pseudo data for classifying\ndevices. We carry out extensive experiments on real IoT traffic data; our\nexperiments demonstrate i) ZEST achieves significant improvement (in terms of\naccuracy) over the baselines; ii) ZEST is able to better extract meaningful\nrepresentations than LSTM which has been commonly used for modeling network\ntraffic.",
          "link": "http://arxiv.org/abs/2310.08036",
          "publishedOn": "2023-10-14T00:41:32.980Z",
          "wordCount": 696,
          "title": "ZEST: Attention-based Zero-Shot Learning for Unseen IoT Device Classification. (arXiv:2310.08036v1 [cs.NI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lebailly_T/0/1/0/all/0/1\">Tim Lebailly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stegmuller_T/0/1/0/all/0/1\">Thomas Stegm&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bozorgtabar_B/0/1/0/all/0/1\">Behzad Bozorgtabar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiran_J/0/1/0/all/0/1\">Jean-Philippe Thiran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuytelaars_T/0/1/0/all/0/1\">Tinne Tuytelaars</a>",
          "description": "Leveraging nearest neighbor retrieval for self-supervised representation\nlearning has proven beneficial with object-centric images. However, this\napproach faces limitations when applied to scene-centric datasets, where\nmultiple objects within an image are only implicitly captured in the global\nrepresentation. Such global bootstrapping can lead to undesirable entanglement\nof object representations. Furthermore, even object-centric datasets stand to\nbenefit from a finer-grained bootstrapping approach. In response to these\nchallenges, we introduce a novel Cross-Image Object-Level Bootstrapping method\ntailored to enhance dense visual representation learning. By employing\nobject-level nearest neighbor bootstrapping throughout the training, CrIBo\nemerges as a notably strong and adequate candidate for in-context learning,\nleveraging nearest neighbor retrieval at test time. CrIBo shows\nstate-of-the-art performance on the latter task while being highly competitive\nin more standard downstream segmentation tasks. Our code and pretrained models\nwill be publicly available upon acceptance.",
          "link": "http://arxiv.org/abs/2310.07855",
          "publishedOn": "2023-10-14T00:41:32.974Z",
          "wordCount": 638,
          "title": "CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping. (arXiv:2310.07855v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hayajneh_A/0/1/0/all/0/1\">Abdullah Hayajneh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serpedin_E/0/1/0/all/0/1\">Erchin Serpedin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaqfeh_M/0/1/0/all/0/1\">Mohammad Shaqfeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_G/0/1/0/all/0/1\">Graeme Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stotland_M/0/1/0/all/0/1\">Mitchell A. Stotland</a>",
          "description": "A major obstacle when attempting to train a machine learning system to\nevaluate facial clefts is the scarcity of large datasets of high-quality,\nethics board-approved patient images. In response, we have built a deep\nlearning-based cleft lip generator designed to produce an almost unlimited\nnumber of artificial images exhibiting high-fidelity facsimiles of cleft lip\nwith wide variation. We undertook a transfer learning protocol testing\ndifferent versions of StyleGAN-ADA (a generative adversarial network image\ngenerator incorporating adaptive data augmentation (ADA)) as the base model.\nTraining images depicting a variety of cleft deformities were pre-processed to\nadjust for rotation, scaling, color adjustment and background blurring. The ADA\nmodification of the primary algorithm permitted construction of our new\ngenerative model while requiring input of a relatively small number of training\nimages. Adversarial training was carried out using 514 unique frontal\nphotographs of cleft-affected faces to adapt a pre-trained model based on\n70,000 normal faces. The Frechet Inception Distance (FID) was used to measure\nthe similarity of the newly generated facial images to the cleft training\ndataset, while Perceptual Path Length (PPL) and the novel Divergence Index of\nSeverity Histograms (DISH) measures were also used to assess the performance of\nthe image generator that we dub CleftGAN. We found that StyleGAN3 with\ntranslation invariance (StyleGAN3-t) performed optimally as a base model.\nGenerated images achieved a low FID reflecting a close similarity to our\ntraining input dataset of genuine cleft images. Low PPL and DISH measures\nreflected a smooth and semantically valid interpolation of images through the\ntransfer learning process and a similar distribution of severity in the\ntraining and generated images, respectively.",
          "link": "http://arxiv.org/abs/2310.07969",
          "publishedOn": "2023-10-14T00:41:32.939Z",
          "wordCount": 815,
          "title": "CleftGAN: Adapting A Style-Based Generative Adversarial Network To Create Images Depicting Cleft Lip Deformity. (arXiv:2310.07969v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Budan_G/0/1/0/all/0/1\">Gokhan Budan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damiani_F/0/1/0/all/0/1\">Francesca Damiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurtulus_C/0/1/0/all/0/1\">Can Kurtulus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ure_N/0/1/0/all/0/1\">N. Kemal Ure</a>",
          "description": "Model identification of battery dynamics is a central problem in energy\nresearch; many energy management systems and design processes rely on accurate\nbattery models for efficiency optimization. The standard methodology for\nbattery modelling is traditional design of experiments (DoE), where the battery\ndynamics are excited with many different current profiles and the measured\noutputs are used to estimate the system dynamics. However, although it is\npossible to obtain useful models with the traditional approach, the process is\ntime consuming and expensive because of the need to sweep many different\ncurrent-profile configurations. In the present work, a novel DoE approach is\ndeveloped based on deep reinforcement learning, which alters the configuration\nof the experiments on the fly based on the statistics of past experiments.\nInstead of sticking to a library of predefined current profiles, the proposed\napproach modifies the current profiles dynamically by updating the output space\ncovered by past measurements, hence only the current profiles that are\ninformative for future experiments are applied. Simulations and real\nexperiments are used to show that the proposed approach gives models that are\nas accurate as those obtained with traditional DoE but by using 85\\% less\nresources.",
          "link": "http://arxiv.org/abs/2310.08198",
          "publishedOn": "2023-10-14T00:41:32.922Z",
          "wordCount": 727,
          "title": "Beyond Traditional DoE: Deep Reinforcement Learning for Optimizing Experiments in Model Identification of Battery Dynamics. (arXiv:2310.08198v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1\">Ravit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romaszkan_W/0/1/0/all/0/1\">Wojciech Romaszkan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Feiqian Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Puneet Gupta</a>",
          "description": "Researchers have long touted a vision of the future enabled by a\nproliferation of internet-of-things devices, including smart sensors, homes,\nand cities. Increasingly, embedding intelligence in such devices involves the\nuse of deep neural networks. However, their storage and processing requirements\nmake them prohibitive for cheap, off-the-shelf platforms. Overcoming those\nrequirements is necessary for enabling widely-applicable smart devices. While\nmany ways of making models smaller and more efficient have been developed,\nthere is a lack of understanding of which ones are best suited for particular\nscenarios. More importantly for edge platforms, those choices cannot be\nanalyzed in isolation from cost and user experience. In this work, we\nholistically explore how quantization, model scaling, and multi-modality\ninteract with system components such as memory, sensors, and processors. We\nperform this hardware/software co-design from the cost, latency, and\nuser-experience perspective, and develop a set of guidelines for optimal system\ndesign and model deployment for the most cost-constrained platforms. We\ndemonstrate our approach using an end-to-end, on-device, biometric user\nauthentication system using a $20 ESP-EYE board.",
          "link": "http://arxiv.org/abs/2310.07940",
          "publishedOn": "2023-10-14T00:41:32.888Z",
          "wordCount": 668,
          "title": "Cost-Driven Hardware-Software Co-Optimization of Machine Learning Pipelines. (arXiv:2310.07940v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1\">Arpit Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jhaveri_H/0/1/0/all/0/1\">Harshil Jhaveri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallick_S/0/1/0/all/0/1\">Swapnil Mallick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ajmera_A/0/1/0/all/0/1\">Abhishek Ajmera</a>",
          "description": "Few-shot object classification is the task of classifying objects in an image\nwith limited number of examples as supervision. We propose a one-shot/few-shot\nclassification model that can classify an object of any unseen class into a\nrelatively general category in an hierarchically based classification. Our\nmodel uses a three-level hierarchical contrastive loss based ResNet152\nclassifier for classifying an object based on its features extracted from Image\nembedding, not used during the training phase. For our experimentation, we have\nused a subset of the ImageNet (ILSVRC-12) dataset that contains only the animal\nclasses for training our model and created our own dataset of unseen classes\nfor evaluating our trained model. Our model provides satisfactory results in\nclassifying the unknown objects into a generic category which has been later\ndiscussed in greater detail.",
          "link": "http://arxiv.org/abs/2310.08304",
          "publishedOn": "2023-10-14T00:41:32.883Z",
          "wordCount": 624,
          "title": "CHIP: Contrastive Hierarchical Image Pretraining. (arXiv:2310.08304v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07852",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Roy_S/0/1/0/all/0/1\">Saptarshi Roy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1\">Ambuj Tewari</a>",
          "description": "We consider the problem of model selection in a high-dimensional sparse\nlinear regression model under the differential privacy framework. In\nparticular, we consider the problem of differentially private best subset\nselection and study its utility guarantee. We adopt the well-known exponential\nmechanism for selecting the best model, and under a certain margin condition,\nwe establish its strong model recovery property. However, the exponential\nsearch space of the exponential mechanism poses a serious computational\nbottleneck. To overcome this challenge, we propose a Metropolis-Hastings\nalgorithm for the sampling step and establish its polynomial mixing time to its\nstationary distribution in the problem parameters $n,p$, and $s$. Furthermore,\nwe also establish approximate differential privacy for the final estimates of\nthe Metropolis-Hastings random walk using its mixing property. Finally, we also\nperform some illustrative simulations that echo the theoretical findings of our\nmain results.",
          "link": "http://arxiv.org/abs/2310.07852",
          "publishedOn": "2023-10-14T00:41:32.873Z",
          "wordCount": 663,
          "title": "On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1\">William Merrill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>",
          "description": "Recent theoretical work has identified surprisingly simple reasoning\nproblems, such as checking if two nodes in a graph are connected or simulating\nfinite-state machines, that are provably unsolvable by standard transformers\nthat answer immediately after reading their input. However, in practice,\ntransformers' reasoning can be improved by allowing them to use a \"chain of\nthought\" or \"scratchpad\", i.e., generate and condition on a sequence of\nintermediate tokens before answering. Motivated by this, we ask: Does such\nintermediate generation fundamentally extend the computational power of a\ndecoder-only transformer? We show that the answer is yes, but the amount of\nincrease depends crucially on the amount of intermediate generation. For\ninstance, we find that transformer decoders with a logarithmic number of\ndecoding steps (w.r.t. the input length) push the limits of standard\ntransformers only slightly, while a linear number of decoding steps adds a\nclear new ability (under standard complexity conjectures): recognizing all\nregular languages. Our results also imply that linear steps keep transformer\ndecoders within context-sensitive languages, and polynomial steps make them\nrecognize exactly the class of polynomial-time solvable problems -- the first\nexact characterization of a type of transformers in terms of standard\ncomplexity classes. Together, our results provide a nuanced framework for\nunderstanding how the length of a transformer's chain of thought or scratchpad\nimpacts its reasoning power.",
          "link": "http://arxiv.org/abs/2310.07923",
          "publishedOn": "2023-10-14T00:41:32.852Z",
          "wordCount": 737,
          "title": "The Expresssive Power of Transformers with Chain of Thought. (arXiv:2310.07923v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.16335",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schar_S/0/1/0/all/0/1\">Styfen Sch&#xe4;r</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marelli_S/0/1/0/all/0/1\">Stefano Marelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sudret_B/0/1/0/all/0/1\">Bruno Sudret</a>",
          "description": "We propose a novel surrogate modelling approach to efficiently and accurately\napproximate the response of complex dynamical systems driven by time-varying\nexogenous excitations over extended time periods. Our approach, namely manifold\nnonlinear autoregressive modelling with exogenous input (mNARX), involves\nconstructing a problem-specific exogenous input manifold that is optimal for\nconstructing autoregressive surrogates. The manifold, which forms the core of\nmNARX, is constructed incrementally by incorporating the physics of the system,\nas well as prior expert- and domain- knowledge. Because mNARX decomposes the\nfull problem into a series of smaller sub-problems, each with a lower\ncomplexity than the original, it scales well with the complexity of the\nproblem, both in terms of training and evaluation costs of the final surrogate.\nFurthermore, mNARX synergizes well with traditional dimensionality reduction\ntechniques, making it highly suitable for modelling dynamical systems with\nhigh-dimensional exogenous inputs, a class of problems that is typically\nchallenging to solve. Since domain knowledge is particularly abundant in\nphysical systems, such as those found in civil and mechanical engineering,\nmNARX is well suited for these applications. We demonstrate that mNARX\noutperforms traditional autoregressive surrogates in predicting the response of\na classical coupled spring-mass system excited by a one-dimensional random\nexcitation. Additionally, we show that mNARX is well suited for emulating very\nhigh-dimensional time- and state-dependent systems, even when affected by\nactive controllers, by surrogating the dynamics of a realistic\naero-servo-elastic onshore wind turbine simulator. In general, our results\ndemonstrate that mNARX offers promising prospects for modelling complex\ndynamical systems, in terms of accuracy and efficiency.",
          "link": "http://arxiv.org/abs/2306.16335",
          "publishedOn": "2023-10-14T00:41:32.840Z",
          "wordCount": 791,
          "title": "Emulating the dynamics of complex systems using autoregressive models on manifolds (mNARX). (arXiv:2306.16335v2 [stat.CO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1\">Chenzhong Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Mingxi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xiongye Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinghe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nazarian_S/0/1/0/all/0/1\">Shahin Nazarian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irimia_A/0/1/0/all/0/1\">Andrei Irimia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogdan_P/0/1/0/all/0/1\">Paul Bogdan</a>",
          "description": "The collective behavior of a network with heterogeneous, resource-limited\ninformation processing units (e.g., group of fish, flock of birds, or network\nof neurons) demonstrates high self-organization and complexity. These emergent\nproperties arise from simple interaction rules where certain individuals can\nexhibit leadership-like behavior and influence the collective activity of the\ngroup. Motivated by the intricacy of these collectives, we propose a neural\nnetwork (NN) architecture inspired by the rules observed in nature's collective\nensembles. This NN structure contains workers that encompass one or more\ninformation processing units (e.g., neurons, filters, layers, or blocks of\nlayers). Workers are either leaders or followers, and we train a\nleader-follower neural network (LFNN) by leveraging local error signals and\noptionally incorporating backpropagation (BP) and global loss. We investigate\nworker behavior and evaluate LFNNs through extensive experimentation. Our LFNNs\ntrained with local error signals achieve significantly lower error rates than\nprevious BP-free algorithms on MNIST and CIFAR-10 and even surpass BP-enabled\nbaselines. In the case of ImageNet, our LFNN-l demonstrates superior\nscalability and outperforms previous BP-free algorithms by a significant\nmargin.",
          "link": "http://arxiv.org/abs/2310.07885",
          "publishedOn": "2023-10-14T00:41:32.834Z",
          "wordCount": 698,
          "title": "Leader-Follower Neural Networks with Local Error Signals Inspired by Complex Collectives. (arXiv:2310.07885v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Md Mahbubur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceka_I/0/1/0/all/0/1\">Ira Ceka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1\">Chengzhi Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Saikat Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1\">Baishakhi Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_W/0/1/0/all/0/1\">Wei Le</a>",
          "description": "Deep learning vulnerability detection has shown promising results in recent\nyears. However, an important challenge that still blocks it from being very\nuseful in practice is that the model is not robust under perturbation and it\ncannot generalize well over the out-of-distribution (OOD) data, e.g., applying\na trained model to unseen projects in real world. We hypothesize that this is\nbecause the model learned non-robust features, e.g., variable names, that have\nspurious correlations with labels. When the perturbed and OOD datasets no\nlonger have the same spurious features, the model prediction fails. To address\nthe challenge, in this paper, we introduced causality into deep learning\nvulnerability detection. Our approach CausalVul consists of two phases. First,\nwe designed novel perturbations to discover spurious features that the model\nmay use to make predictions. Second, we applied the causal learning algorithms,\nspecifically, do-calculus, on top of existing deep learning models to\nsystematically remove the use of spurious features and thus promote causal\nbased prediction. Our results show that CausalVul consistently improved the\nmodel accuracy, robustness and OOD performance for all the state-of-the-art\nmodels and datasets we experimented. To the best of our knowledge, this is the\nfirst work that introduces do calculus based causal learning to software\nengineering models and shows it's indeed useful for improving the model\naccuracy, robustness and generalization. Our replication package is located at\nhttps://figshare.com/s/0ffda320dcb96c249ef2.",
          "link": "http://arxiv.org/abs/2310.07958",
          "publishedOn": "2023-10-14T00:41:32.829Z",
          "wordCount": 745,
          "title": "Towards Causal Deep Learning for Vulnerability Detection. (arXiv:2310.07958v1 [cs.SE])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maharana_A/0/1/0/all/0/1\">Adyasha Maharana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1\">Prateek Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Analytical theories suggest that higher-quality data can lead to lower test\nerrors in models trained on a fixed data budget. Moreover, a model can be\ntrained on a lower compute budget without compromising performance if a dataset\ncan be stripped of its redundancies. Coreset selection (or data pruning) seeks\nto select a subset of the training data so as to maximize the performance of\nmodels trained on this subset, also referred to as coreset. There are two\ndominant approaches: (1) geometry-based data selection for maximizing data\ndiversity in the coreset, and (2) functions that assign difficulty scores to\nsamples based on training dynamics. Optimizing for data diversity leads to a\ncoreset that is biased towards easier samples, whereas, selection by difficulty\nranking omits easy samples that are necessary for the training of deep learning\nmodels. This demonstrates that data diversity and importance scores are two\ncomplementary factors that need to be jointly considered during coreset\nselection. We represent a dataset as an undirected graph and propose a novel\npruning algorithm, D2 Pruning, that uses forward and reverse message passing\nover this dataset graph for coreset selection. D2 Pruning updates the\ndifficulty scores of each example by incorporating the difficulty of its\nneighboring examples in the dataset graph. Then, these updated difficulty\nscores direct a graph-based sampling method to select a coreset that\nencapsulates both diverse and difficult regions of the dataset space. We\nevaluate supervised and self-supervised versions of our method on various\nvision and language datasets. Results show that D2 Pruning improves coreset\nselection over previous state-of-the-art methods for up to 70% pruning rates.\nAdditionally, we find that using D2 Pruning for filtering large multimodal\ndatasets leads to increased diversity in the dataset and improved\ngeneralization of pretrained models.",
          "link": "http://arxiv.org/abs/2310.07931",
          "publishedOn": "2023-10-14T00:41:32.816Z",
          "wordCount": 833,
          "title": "D2 Pruning: Message Passing for Balancing Diversity and Difficulty in Data Pruning. (arXiv:2310.07931v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07780",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linbo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1\">Trong Nghia Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Lam M. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_T/0/1/0/all/0/1\">Tsui-Wei Weng</a>",
          "description": "Randomized smoothing has recently attracted attentions in the field of\nadversarial robustness to provide provable robustness guarantees on smoothed\nneural network classifiers. However, existing works show that vanilla\nrandomized smoothing usually does not provide good robustness performance and\noften requires (re)training techniques on the base classifier in order to boost\nthe robustness of the resulting smoothed classifier. In this work, we propose\ntwo cost-effective approaches to boost the robustness of randomized smoothing\nwhile preserving its clean performance. The first approach introduces a new\nrobust training method AdvMacerwhich combines adversarial training and\nrobustness certification maximization for randomized smoothing. We show that\nAdvMacer can improve the robustness performance of randomized smoothing\nclassifiers compared to SOTA baselines, while being 3x faster to train than\nMACER baseline. The second approach introduces a post-processing method EsbRS\nwhich greatly improves the robustness certificate based on building model\nensembles. We explore different aspects of model ensembles that has not been\nstudied by prior works and propose a novel design methodology to further\nimprove robustness of the ensemble based on our theoretical analysis.",
          "link": "http://arxiv.org/abs/2310.07780",
          "publishedOn": "2023-10-14T00:41:32.758Z",
          "wordCount": 679,
          "title": "Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches. (arXiv:2310.07780v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07925",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Rostami_M/0/1/0/all/0/1\">M. Rostami</a>, <a href=\"http://arxiv.org/find/math/1/au:+Moradian_H/0/1/0/all/0/1\">H. Moradian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kia_S/0/1/0/all/0/1\">S. S. Kia</a>",
          "description": "This paper proposes a set of novel optimization algorithms for solving a\nclass of convex optimization problems with time-varying streaming cost\nfunction. We develop an approach to track the optimal solution with a bounded\nerror. Unlike the existing results, our algorithm is executed only by using the\nfirst-order derivatives of the cost function which makes it computationally\nefficient for optimization with time-varying cost function. We compare our\nalgorithms to the gradient descent algorithm and show why gradient descent is\nnot an effective solution for optimization problems with time-varying cost.\nSeveral examples including solving a model predictive control problem cast as a\nconvex optimization problem with a streaming time-varying cost function\ndemonstrate our results.",
          "link": "http://arxiv.org/abs/2310.07925",
          "publishedOn": "2023-10-14T00:41:32.750Z",
          "wordCount": 608,
          "title": "First-Order Dynamic Optimization for Streaming Convex Costs. (arXiv:2310.07925v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luca_A/0/1/0/all/0/1\">Artur Back de Luca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fountoulakis_K/0/1/0/all/0/1\">Kimon Fountoulakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shenghao Yang</a>",
          "description": "The growing interest in machine learning problems over graphs with additional\nnode information such as texts, images, or labels has popularized methods that\nrequire the costly operation of processing the entire graph. Yet, little effort\nhas been made to the development of fast local methods (i.e. without accessing\nthe entire graph) that extract useful information from such data. To that end,\nwe propose a study of local graph clustering using noisy node labels as a proxy\nfor additional node information. In this setting, nodes receive initial binary\nlabels based on cluster affiliation: 1 if they belong to the target cluster and\n0 otherwise. Subsequently, a fraction of these labels is flipped. We\ninvestigate the benefits of incorporating noisy labels for local graph\nclustering. By constructing a weighted graph with such labels, we study the\nperformance of graph diffusion-based local clustering method on both the\noriginal and the weighted graphs. From a theoretical perspective, we consider\nrecovering an unknown target cluster with a single seed node in a random graph\nwith independent noisy node labels. We provide sufficient conditions on the\nlabel noise under which, with high probability, using diffusion in the weighted\ngraph yields a more accurate recovery of the target cluster. This approach\nproves more effective than using the given labels alone or using diffusion in\nthe label-free original graph. Empirically, we show that reliable node labels\ncan be obtained with just a few samples from an attributed graph. Moreover,\nutilizing these labels via diffusion in the weighted graph leads to\nsignificantly better local clustering performance across several real-world\ndatasets, improving F1 scores by up to 13%.",
          "link": "http://arxiv.org/abs/2310.08031",
          "publishedOn": "2023-10-14T00:41:32.723Z",
          "wordCount": 784,
          "title": "Local Graph Clustering with Noisy Labels. (arXiv:2310.08031v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.13326",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nie_G/0/1/0/all/0/1\">Guanyu Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadew_Y/0/1/0/all/0/1\">Yididiya Y Nadew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanhui Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1\">Vaneet Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quinn_C/0/1/0/all/0/1\">Christopher John Quinn</a>",
          "description": "We investigate the problem of stochastic, combinatorial multi-armed bandits\nwhere the learner only has access to bandit feedback and the reward function\ncan be non-linear. We provide a general framework for adapting discrete offline\napproximation algorithms into sublinear $\\alpha$-regret methods that only\nrequire bandit feedback, achieving\n$\\mathcal{O}\\left(T^\\frac{2}{3}\\log(T)^\\frac{1}{3}\\right)$ expected cumulative\n$\\alpha$-regret dependence on the horizon $T$. The framework only requires the\noffline algorithms to be robust to small errors in function evaluation. The\nadaptation procedure does not even require explicit knowledge of the offline\napproximation algorithm -- the offline algorithm can be used as a black box\nsubroutine. To demonstrate the utility of the proposed framework, the proposed\nframework is applied to diverse applications in submodular maximization. The\nnew CMAB algorithms for submodular maximization with knapsack constraints\noutperform a full-bandit method developed for the adversarial setting in\nexperiments with real-world data.",
          "link": "http://arxiv.org/abs/2301.13326",
          "publishedOn": "2023-10-14T00:41:32.708Z",
          "wordCount": 755,
          "title": "A Framework for Adapting Offline Algorithms to Solve Combinatorial Multi-Armed Bandit Problems with Bandit Feedback. (arXiv:2301.13326v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.03410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jacob_J/0/1/0/all/0/1\">Jayadeep Jacob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bandyopadhyay_T/0/1/0/all/0/1\">Tirthankar Bandyopadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1\">Jason Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borges_P/0/1/0/all/0/1\">Paulo Borges</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1\">Fabio Ramos</a>",
          "description": "We propose to use a simulation driven inverse inference approach to model the\ndynamics of tree branches under manipulation. Learning branch dynamics and\ngaining the ability to manipulate deformable vegetation can help with\nocclusion-prone tasks, such as fruit picking in dense foliage, as well as\nmoving overhanging vines and branches for navigation in dense vegetation. The\nunderlying deformable tree geometry is encapsulated as coarse spring\nabstractions executed on parallel, non-differentiable simulators. The implicit\nstatistical model defined by the simulator, reference trajectories obtained by\nactively probing the ground truth, and the Bayesian formalism, together guide\nthe spring parameter posterior density estimation. Our non-parametric inference\nalgorithm, based on Stein Variational Gradient Descent, incorporates\nbiologically motivated assumptions into the inference process as neural network\ndriven learnt joint priors; moreover, it leverages the finite difference scheme\nfor gradient approximations. Real and simulated experiments confirm that our\nmodel can predict deformation trajectories, quantify the estimation\nuncertainty, and it can perform better when base-lined against other inference\nalgorithms, particularly from the Monte Carlo family. The model displays strong\nrobustness properties in the presence of heteroscedastic sensor noise;\nfurthermore, it can generalise to unseen grasp locations.",
          "link": "http://arxiv.org/abs/2306.03410",
          "publishedOn": "2023-10-14T00:41:32.703Z",
          "wordCount": 704,
          "title": "Learning to Simulate Tree-Branch Dynamics for Manipulation. (arXiv:2306.03410v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhongji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuhang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yinghao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianlong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaohe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasha Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Liantao Ma</a>",
          "description": "Due to the limited information about emerging diseases, symptoms are hard to\nbe noticed and recognized, so that the window for clinical intervention could\nbe ignored. An effective prognostic model is expected to assist doctors in\nmaking right diagnosis and designing personalized treatment plan, so to\npromptly prevent unfavorable outcomes. However, in the early stage of a\ndisease, limited data collection and clinical experiences, plus the concern out\nof privacy and ethics, may result in restricted data availability for\nreference, to the extent that even data labels are difficult to mark correctly.\nIn addition, Electronic Medical Record (EMR) data of different diseases or of\ndifferent sources of the same disease can prove to be having serious\ncross-dataset feature misalignment problems, greatly mutilating the efficiency\nof deep learning models. This article introduces a transfer learning method to\nbuild a transition model from source dataset to target dataset. By way of\nconstraining the distribution shift of features generated in disparate domains,\ndomain-invariant features that are exclusively relative to downstream tasks are\ncaptured, so to cultivate a unified domain-invariant encoder across various\ntask domains to achieve better feature representation. Experimental results of\nseveral target tasks demonstrate that our proposed model outperforms competing\nbaseline methods and has higher rate of training convergence, especially in\ndealing with limited data amount. A multitude of experiences have proven the\nefficacy of our method to provide more accurate predictions concerning newly\nemergent pandemics and other diseases.",
          "link": "http://arxiv.org/abs/2310.07799",
          "publishedOn": "2023-10-14T00:41:32.698Z",
          "wordCount": 772,
          "title": "A Transfer-Learning-Based Prognosis Prediction Paradigm that Bridges Data Distribution Shift across EMR Datasets. (arXiv:2310.07799v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.02484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yueh-Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamaya_M/0/1/0/all/0/1\">Masashi Hamaya</a>",
          "description": "This paper introduces Elastic Decision Transformer (EDT), a significant\nadvancement over the existing Decision Transformer (DT) and its variants.\nAlthough DT purports to generate an optimal trajectory, empirical evidence\nsuggests it struggles with trajectory stitching, a process involving the\ngeneration of an optimal or near-optimal trajectory from the best parts of a\nset of sub-optimal trajectories. The proposed EDT differentiates itself by\nfacilitating trajectory stitching during action inference at test time,\nachieved by adjusting the history length maintained in DT. Further, the EDT\noptimizes the trajectory by retaining a longer history when the previous\ntrajectory is optimal and a shorter one when it is sub-optimal, enabling it to\n\"stitch\" with a more optimal trajectory. Extensive experimentation demonstrates\nEDT's ability to bridge the performance gap between DT-based and Q\nLearning-based approaches. In particular, the EDT outperforms Q Learning-based\nmethods in a multi-task regime on the D4RL locomotion benchmark and Atari\ngames. Videos are available at: https://kristery.github.io/edt/",
          "link": "http://arxiv.org/abs/2307.02484",
          "publishedOn": "2023-10-14T00:41:32.661Z",
          "wordCount": 689,
          "title": "Elastic Decision Transformer. (arXiv:2307.02484v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.00152",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hanneke_S/0/1/0/all/0/1\">Steve Hanneke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mahdaviyeh_Y/0/1/0/all/0/1\">Yasaman Mahdaviyeh</a>",
          "description": "Theoretical studies on transfer learning or domain adaptation have so far\nfocused on situations with a known hypothesis class or model; however in\npractice, some amount of model selection is usually involved, often appearing\nunder the umbrella term of hyperparameter-tuning: for example, one may think of\nthe problem of tuning for the right neural network architecture towards a\ntarget task, while leveraging data from a related source task.\n\nNow, in addition to the usual tradeoffs on approximation vs estimation errors\ninvolved in model selection, this problem brings in a new complexity term,\nnamely, the transfer distance between source and target distributions, which is\nknown to vary with the choice of hypothesis class.\n\nWe present a first study of this problem, focusing on classification; in\nparticular, the analysis reveals some remarkable phenomena: adaptive rates,\ni.e., those achievable with no distributional information, can be arbitrarily\nslower than oracle rates, i.e., when given knowledge on distances.",
          "link": "http://arxiv.org/abs/2305.00152",
          "publishedOn": "2023-10-14T00:41:32.648Z",
          "wordCount": 693,
          "title": "Limits of Model Selection under Transfer Learning. (arXiv:2305.00152v4 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_S/0/1/0/all/0/1\">Shaofei Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bowei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Anji Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yitao Liang</a>",
          "description": "We study the problem of building a controller that can follow open-ended\ninstructions in open-world environments. We propose to follow reference videos\nas instructions, which offer expressive goal specifications while eliminating\nthe need for expensive text-gameplay annotations. A new learning framework is\nderived to allow learning such instruction-following controllers from gameplay\nvideos while producing a video instruction encoder that induces a structured\ngoal space. We implement our agent GROOT in a simple yet effective\nencoder-decoder architecture based on causal transformers. We evaluate GROOT\nagainst open-world counterparts and human players on a proposed Minecraft\nSkillForge benchmark. The Elo ratings clearly show that GROOT is closing the\nhuman-machine gap as well as exhibiting a 70% winning rate over the best\ngeneralist agent baseline. Qualitative analysis of the induced goal space\nfurther demonstrates some interesting emergent properties, including the goal\ncomposition and complex gameplay behavior synthesis. Code and video can be\nfound on the website https://craftjarvis-groot.github.io.",
          "link": "http://arxiv.org/abs/2310.08235",
          "publishedOn": "2023-10-14T00:41:32.567Z",
          "wordCount": 659,
          "title": "GROOT: Learning to Follow Instructions by Watching Gameplay Videos. (arXiv:2310.08235v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1\">Shengzhao Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamnoedboon_P/0/1/0/all/0/1\">Porawit Kamnoedboon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">WeiWei Li</a>",
          "description": "The lack of standardized robustness metrics and the widespread reliance on\nnumerous unrelated benchmark datasets for testing have created a gap between\nacademically validated robust models and their often problematic practical\nadoption. To address this, we introduce XIMAGENET-12, an explainable benchmark\ndataset with over 200K images and 15,600 manual semantic annotations. Covering\n12 categories from ImageNet to represent objects commonly encountered in\npractical life and simulating six diverse scenarios, including overexposure,\nblurring, color changing, etc., we further propose a novel robustness criterion\nthat extends beyond model generation ability assessment. This benchmark\ndataset, along with related code, is available at\nhttps://sites.google.com/view/ximagenet-12/home. Researchers and practitioners\ncan leverage this resource to evaluate the robustness of their visual models\nunder challenging conditions and ultimately benefit from the demands of\npractical computer vision systems.",
          "link": "http://arxiv.org/abs/2310.08182",
          "publishedOn": "2023-10-14T00:41:32.502Z",
          "wordCount": 649,
          "title": "XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation. (arXiv:2310.08182v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Piras_G/0/1/0/all/0/1\">Giorgio Piras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1\">Maura Pintor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demontis_A/0/1/0/all/0/1\">Ambra Demontis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1\">Battista Biggio</a>",
          "description": "Neural network pruning has shown to be an effective technique for reducing\nthe network size, trading desirable properties like generalization and\nrobustness to adversarial attacks for higher sparsity. Recent work has claimed\nthat adversarial pruning methods can produce sparse networks while also\npreserving robustness to adversarial examples. In this work, we first\nre-evaluate three state-of-the-art adversarial pruning methods, showing that\ntheir robustness was indeed overestimated. We then compare pruned and dense\nversions of the same models, discovering that samples on thin ice, i.e., closer\nto the unpruned model's decision boundary, are typically misclassified after\npruning. We conclude by discussing how this intuition may lead to designing\nmore effective adversarial pruning methods in future work.",
          "link": "http://arxiv.org/abs/2310.08073",
          "publishedOn": "2023-10-14T00:41:32.451Z",
          "wordCount": 629,
          "title": "Samples on Thin Ice: Re-Evaluating Adversarial Pruning of Neural Networks. (arXiv:2310.08073v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08282",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ruyi Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_N/0/1/0/all/0/1\">Ningning Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yizhuang You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiang Zhang</a>",
          "description": "Multiscale modeling of complex systems is crucial for understanding their\nintricacies. Data-driven multiscale modeling has emerged as a promising\napproach to tackle challenges associated with complex systems. On the other\nhand, self-similarity is prevalent in complex systems, hinting that large-scale\ncomplex systems can be modeled at a reduced cost. In this paper, we introduce a\nmultiscale neural network framework that incorporates self-similarity as prior\nknowledge, facilitating the modeling of self-similar dynamical systems. For\ndeterministic dynamics, our framework can discern whether the dynamics are\nself-similar. For uncertain dynamics, it can compare and determine which\nparameter set is closer to self-similarity. The framework allows us to extract\nscale-invariant kernels from the dynamics for modeling at any scale. Moreover,\nour method can identify the power law exponents in self-similar systems.\nPreliminary tests on the Ising model yielded critical exponents consistent with\ntheoretical expectations, providing valuable insights for addressing critical\nphase transitions in non-equilibrium systems.",
          "link": "http://arxiv.org/abs/2310.08282",
          "publishedOn": "2023-10-14T00:41:32.442Z",
          "wordCount": 655,
          "title": "Data driven modeling of self-similar dynamics. (arXiv:2310.08282v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08078",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Md Mushfiqur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakib_F/0/1/0/all/0/1\">Fardin Ahsan Sakib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faisal_F/0/1/0/all/0/1\">Fahim Faisal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>",
          "description": "Choosing an appropriate tokenization scheme is often a bottleneck in\nlow-resource cross-lingual transfer. To understand the downstream implications\nof text representation choices, we perform a comparative analysis on language\nmodels having diverse text representation modalities including 2\nsegmentation-based models (\\texttt{BERT}, \\texttt{mBERT}), 1 image-based model\n(\\texttt{PIXEL}), and 1 character-level model (\\texttt{CANINE}). First, we\npropose a scoring Language Quotient (LQ) metric capable of providing a weighted\nrepresentation of both zero-shot and few-shot evaluation combined. Utilizing\nthis metric, we perform experiments comprising 19 source languages and 133\ntarget languages on three tasks (POS tagging, Dependency parsing, and NER). Our\nanalysis reveals that image-based models excel in cross-lingual transfer when\nlanguages are closely related and share visually similar scripts. However, for\ntasks biased toward word meaning (POS, NER), segmentation-based models prove to\nbe superior. Furthermore, in dependency parsing tasks where word relationships\nplay a crucial role, models with their character-level focus, outperform\nothers. Finally, we propose a recommendation scheme based on our findings to\nguide model selection according to task and language requirements.",
          "link": "http://arxiv.org/abs/2310.08078",
          "publishedOn": "2023-10-14T00:41:32.353Z",
          "wordCount": 710,
          "title": "To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer. (arXiv:2310.08078v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Havaldar_S/0/1/0/all/0/1\">Shreyas Havaldar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_N/0/1/0/all/0/1\">Navodita Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sareen_S/0/1/0/all/0/1\">Shubhi Sareen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghuveer_A/0/1/0/all/0/1\">Aravindan Raghuveer</a>",
          "description": "Learning from Label Proportions (LLP) is a learning problem where only\naggregate level labels are available for groups of instances, called bags,\nduring training, and the aim is to get the best performance at the\ninstance-level on the test data. This setting arises in domains like\nadvertising and medicine due to privacy considerations. We propose a novel\nalgorithmic framework for this problem that iteratively performs two main\nsteps. For the first step (Pseudo Labeling) in every iteration, we define a\nGibbs distribution over binary instance labels that incorporates a) covariate\ninformation through the constraint that instances with similar covariates\nshould have similar labels and b) the bag level aggregated label. We then use\nBelief Propagation (BP) to marginalize the Gibbs distribution to obtain pseudo\nlabels. In the second step (Embedding Refinement), we use the pseudo labels to\nprovide supervision for a learner that yields a better embedding. Further, we\niterate on the two steps again by using the second step's embeddings as new\ncovariates for the next iteration. In the final iteration, a classifier is\ntrained using the pseudo labels. Our algorithm displays strong gains against\nseveral SOTA baselines (up to 15%) for the LLP Binary Classification problem on\nvarious dataset types - tabular and Image. We achieve these improvements with\nminimal computational overhead above standard supervised learning due to Belief\nPropagation, for large bag sizes, even for a million samples.",
          "link": "http://arxiv.org/abs/2310.08056",
          "publishedOn": "2023-10-14T00:41:32.276Z",
          "wordCount": 745,
          "title": "Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation. (arXiv:2310.08056v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08109",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Schuster_G/0/1/0/all/0/1\">Gerard T. Schuster</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Feng_S/0/1/0/all/0/1\">Shihang Feng</a>",
          "description": "We review four types of algorithms for physics-informed machine learning\n(PIML) inversion of geophysical data. The unifying equation is given by the\njoint objective function $\\epsilon$:\n\n\\begin{eqnarray} \\epsilon^{||-PIML}&=&\\lambda_1 \\overbrace{||{\\bf\nW}^{ML}({\\bf H}_{{\\bf w}} {\\bf d}^{obs}-{\\bf m})||^2}^{NN} + \\lambda_2\n\\overbrace{{||{\\bf W}^{FWI}({\\bf L} {\\bf m}-{\\bf d}^{obs})||^2}}^{FWI} ~+\n\\nonumber\\\\ \\nonumber\\\\ && + ~~Regularizer, \\label{PIML.eq120}\n\\end{eqnarray}where the optimal model ${\\bf m}^*$ and weights $\\bf w^*$\nminimize $\\epsilon$. Here, The matrix weights are given by the boldface symbol\n$\\bf W$, and full waveform inversion (FWI) is typically computed using a\nfinite-difference solution of the wave equation, where $\\bf L$ represents the\nforward modeling operation of the wave equation as a function of the model $\\bf\nm$. Also, a fully-connected neural network (NN) is used to compute the model\n${\\bf H_w}{\\bf d}^{obs} \\approx \\bf m$ from the observed input data ${\\bf\nd}^{obs}$. The selection of weights $\\lambda_i$ and the NN operations determine\none of four different PIML algorithms.\n\nPIML offers potential advantages over standard FWI through its enhanced\nability to avoid local minima and the option to locally train the inversion\noperator, minimizing the requirement for extensive training data for global\napplicability. However, the effectiveness of PIML relies on the similarity\nbetween the test and trained data. Nevertheless, a possible strategy to\novercome this limitation involves initial pretraining of a PIML architecture\nwith data from a broader region, followed by fine-tuning for specific data-a\nmethod reminiscent of the way large language models are pretrained and adapted\nfor various tasks.",
          "link": "http://arxiv.org/abs/2310.08109",
          "publishedOn": "2023-10-14T00:41:32.269Z",
          "wordCount": 742,
          "title": "Overview of Physics-Informed Machine Learning Inversion of Geophysical Data. (arXiv:2310.08109v1 [physics.geo-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianchao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuzhe Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1\">Jiaqi Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1\">Quan Z. Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xi Zheng</a>",
          "description": "Brain-Computer Interfaces (BCIs) are a groundbreaking technology for\ninteracting with external devices using brain signals. Despite advancements,\nelectroencephalogram (EEG)-based Motor Imagery (MI) tasks face challenges like\namplitude and phase variability, and complex spatial correlations, with a need\nfor smaller model size and faster inference. This study introduces the LGL-BCI\nframework, employing a Geometric Deep Learning Framework for EEG processing in\nnon-Euclidean metric spaces, particularly the Symmetric Positive Definite (SPD)\nManifold space. LGL-BCI offers robust EEG data representation and captures\nspatial correlations. We propose an EEG channel selection solution via a\nfeature decomposition algorithm to reduce SPD matrix dimensionality, with a\nlossless transformation boosting inference speed. Extensive experiments show\nLGL-BCI's superior accuracy and efficiency compared to current solutions,\nhighlighting geometric deep learning's potential in MI-BCI applications. The\nefficiency, assessed on two public EEG datasets and two real-world EEG devices,\nsignificantly outperforms the state-of-the-art solution in accuracy ($82.54\\%$\nversus $62.22\\%$) with fewer parameters (64.9M compared to 183.7M).",
          "link": "http://arxiv.org/abs/2310.08051",
          "publishedOn": "2023-10-14T00:41:32.182Z",
          "wordCount": 674,
          "title": "LGL-BCI: A Lightweight Geometric Learning Framework for Motor Imagery-Based Brain-Computer Interfaces. (arXiv:2310.08051v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1\">Minseok Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gwak_C/0/1/0/all/0/1\">Chaeheon Gwak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Si Hyeong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jaegul Choo</a>",
          "description": "Keyphrase generation (KG) aims to generate a set of summarizing words or\nphrases given a source document, while keyphrase extraction (KE) aims to\nidentify them from the text. Because the search space is much smaller in KE, it\nis often combined with KG to predict keyphrases that may or may not exist in\nthe corresponding document. However, current unified approaches adopt sequence\nlabeling and maximization-based generation that primarily operate at a token\nlevel, falling short in observing and scoring keyphrases as a whole. In this\nwork, we propose SimCKP, a simple contrastive learning framework that consists\nof two stages: 1) An extractor-generator that extracts keyphrases by learning\ncontext-aware phrase-level representations in a contrastive manner while also\ngenerating keyphrases that do not appear in the document; 2) A reranker that\nadapts scores for each generated phrase by likewise aligning their\nrepresentations with the corresponding document. Experimental results on\nmultiple benchmark datasets demonstrate the effectiveness of our proposed\napproach, which outperforms the state-of-the-art models by a significant\nmargin.",
          "link": "http://arxiv.org/abs/2310.08221",
          "publishedOn": "2023-10-14T00:41:32.038Z",
          "wordCount": 674,
          "title": "SimCKP: Simple Contrastive Learning of Keyphrase Representations. (arXiv:2310.08221v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.13660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Ying Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apruzzese_G/0/1/0/all/0/1\">Giovanni Apruzzese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1\">Mauro Conti</a>",
          "description": "Existing literature on adversarial Machine Learning (ML) focuses either on\nshowing attacks that break every ML model, or defenses that withstand most\nattacks. Unfortunately, little consideration is given to the actual feasibility\nof the attack or the defense. Moreover, adversarial samples are often crafted\nin the \"feature-space\", making the corresponding evaluations of questionable\nvalue. Simply put, the current situation does not allow to estimate the actual\nthreat posed by adversarial attacks, leading to a lack of secure ML systems.\n\nWe aim to clarify such confusion in this paper. By considering the\napplication of ML for Phishing Website Detection (PWD), we formalize the\n\"evasion-space\" in which an adversarial perturbation can be introduced to fool\na ML-PWD -- demonstrating that even perturbations in the \"feature-space\" are\nuseful. Then, we propose a realistic threat model describing evasion attacks\nagainst ML-PWD that are cheap to stage, and hence intrinsically more attractive\nfor real phishers. After that, we perform the first statistically validated\nassessment of state-of-the-art ML-PWD against 12 evasion attacks. Our\nevaluation shows (i) the true efficacy of evasion attempts that are more likely\nto occur; and (ii) the impact of perturbations crafted in different\nevasion-spaces. Our realistic evasion attempts induce a statistically\nsignificant degradation (3-10% at p<0.05), and their cheap cost makes them a\nsubtle threat. Notably, however, some ML-PWD are immune to our most realistic\nattacks (p=0.22).\n\nFinally, as an additional contribution of this journal publication, we are\nthe first to consider the intriguing case wherein an attacker introduces\nperturbations in multiple evasion-spaces at the same time. These new results\nshow that simultaneously applying perturbations in the problem- and\nfeature-space can cause a drop in the detection rate from 0.95 to 0.",
          "link": "http://arxiv.org/abs/2210.13660",
          "publishedOn": "2023-10-14T00:41:31.829Z",
          "wordCount": 845,
          "title": "Multi-SpacePhish: Extending the Evasion-space of Adversarial Attacks against Phishing Website Detectors using Machine Learning. (arXiv:2210.13660v3 [cs.CR] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.13869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1\">Minseok Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1\">Hyesu Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jaegul Choo</a>",
          "description": "Document-level relation extraction (DocRE) aims to extract relations of all\nentity pairs in a document. A key challenge in DocRE is the cost of annotating\nsuch data which requires intensive human effort. Thus, we investigate the case\nof DocRE in a low-resource setting, and we find that existing models trained on\nlow data overestimate the NA (\"no relation\") label, causing limited\nperformance. In this work, we approach the problem from a calibration\nperspective and propose PRiSM, which learns to adapt logits based on relation\nsemantic information. We evaluate our method on three DocRE datasets and\ndemonstrate that integrating existing models with PRiSM improves performance by\nas much as 26.38 F1 score, while the calibration error drops as much as 36\ntimes when trained with about 3% of data. The code is publicly available at\nhttps://github.com/brightjade/PRiSM.",
          "link": "http://arxiv.org/abs/2309.13869",
          "publishedOn": "2023-10-14T00:41:31.680Z",
          "wordCount": 652,
          "title": "PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration. (arXiv:2309.13869v1 [cs.CL] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.15395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zihan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Honghao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_L/0/1/0/all/0/1\">Lei Ying</a>",
          "description": "This paper considers the best policy identification (BPI) problem in online\nConstrained Markov Decision Processes (CMDPs). We are interested in algorithms\nthat are model-free, have low regret, and identify an optimal policy with a\nhigh probability. Existing model-free algorithms for online CMDPs with\nsublinear regret and constraint violation do not provide any convergence\nguarantee to an optimal policy and provide only average performance guarantees\nwhen a policy is uniformly sampled at random from all previously used policies.\nIn this paper, we develop a new algorithm, named\nPruning-Refinement-Identification (PRI), based on a fundamental structural\nproperty of CMDPs we discover, called limited stochasticity. The property says\nfor a CMDP with $N$ constraints, there exists an optimal policy with at most\n$N$ stochastic decisions.\n\nThe proposed algorithm first identifies at which step and in which state a\nstochastic decision has to be taken and then fine-tunes the distributions of\nthese stochastic decisions. PRI achieves trio objectives: (i) PRI is a\nmodel-free algorithm; and (ii) it outputs a near-optimal policy with a high\nprobability at the end of learning; and (iii) in the tabular setting, PRI\nguarantees $\\tilde{\\mathcal{O}}(\\sqrt{K})$ regret and constraint violation,\nwhich significantly improves the best existing regret bound\n$\\tilde{\\mathcal{O}}(K^{\\frac{4}{5}})$ under a model-free algorithm, where $K$\nis the total number of episodes.",
          "link": "http://arxiv.org/abs/2309.15395",
          "publishedOn": "2023-10-14T00:41:31.621Z",
          "wordCount": 727,
          "title": "Model-Free, Regret-Optimal Best Policy Identification in Online CMDPs. (arXiv:2309.15395v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chaoqi Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_W/0/1/0/all/0/1\">Weiqiang Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_L/0/1/0/all/0/1\">Lifeng Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yuchen Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jianle Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_P/0/1/0/all/0/1\">Peng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hongliang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinzhu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1\">Wangmeng Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanli Ouyang</a>",
          "description": "With the success of large-scale pretraining in NLP, there is an increasing\ntrend of applying it to the domain of life sciences. In particular, pretraining\nmethods based on DNA sequences have garnered growing attention due to their\npotential to capture generic information about genes. However, existing\npretraining methods for DNA sequences largely rely on direct adoptions of BERT\npretraining from NLP, lacking a comprehensive understanding and a specifically\ntailored approach. To address this research gap, we first conducted a series of\nexploratory experiments and gained several insightful observations: 1) In the\nfine-tuning phase of downstream tasks, when using K-mer overlapping\ntokenization instead of K-mer non-overlapping tokenization, both overlapping\nand non-overlapping pretraining weights show consistent performance\nimprovement.2) During the pre-training process, using K-mer overlapping\ntokenization quickly produces clear K-mer embeddings and reduces the loss to a\nvery low level, while using K-mer non-overlapping tokenization results in less\ndistinct embeddings and continuously decreases the loss. 3) Using overlapping\ntokenization causes the self-attention in the intermediate layers of\npre-trained models to tend to overly focus on certain tokens, reflecting that\nthese layers are not adequately optimized. In summary, overlapping tokenization\ncan benefit the fine-tuning of downstream tasks but leads to inadequate\npretraining with fast convergence. To unleash the pretraining potential, we\nintroduce a novel approach called RandomMask, which gradually increases the\ntask difficulty of BERT-like pretraining by continuously expanding its mask\nboundary, forcing the model to learn more knowledge. RandomMask is simple but\neffective, achieving top-tier performance across 26 datasets of 28 datasets\nspanning 7 downstream tasks.",
          "link": "http://arxiv.org/abs/2310.07644",
          "publishedOn": "2023-10-14T00:41:31.613Z",
          "wordCount": 781,
          "title": "Rethinking the BERT-like Pretraining for DNA Sequences. (arXiv:2310.07644v2 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.02010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahdavi_S/0/1/0/all/0/1\">Sadegh Mahdavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1\">Renjie Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "Transformers have become the go-to architecture for language and vision\ntasks, yet their theoretical properties, especially memorization capacity,\nremain elusive. This paper investigates the memorization abilities of\nmulti-head attention mechanisms, examining how many example sequences they can\nmemorize, as a function of the number of heads and sequence length. Motivated\nby experimental findings on vision transformers, we introduce novel assumptions\nabout the linear independence of input data, distinct from the commonly used\ngeneral-position assumption. Under these assumptions, we demonstrate that an\nattention layer with $H$ heads, dimension $d$, and context size $n < d$,\nfeaturing $\\Theta(Hd^2)$ parameters, can memorize $\\Omega(Hn)$ examples. Our\nanalysis sheds light on how different attention heads handle various example\nsequences, aided by the softmax operator's saturation property. We validate our\nfindings through experiments on synthetic data.",
          "link": "http://arxiv.org/abs/2306.02010",
          "publishedOn": "2023-10-14T00:41:31.582Z",
          "wordCount": 642,
          "title": "Memorization Capacity of Multi-Head Attention in Transformers. (arXiv:2306.02010v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changhe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pourkeshavarz_M/0/1/0/all/0/1\">Mozhgan Pourkeshavarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasouli_A/0/1/0/all/0/1\">Amir Rasouli</a>",
          "description": "Benchmarking is a common method for evaluating trajectory prediction models\nfor autonomous driving. Existing benchmarks rely on datasets, which are biased\ntowards more common scenarios, such as cruising, and distance-based metrics\nthat are computed by averaging over all scenarios. Following such a regiment\nprovides a little insight into the properties of the models both in terms of\nhow well they can handle different scenarios and how admissible and diverse\ntheir outputs are. There exist a number of complementary metrics designed to\nmeasure the admissibility and diversity of trajectories, however, they suffer\nfrom biases, such as length of trajectories.\n\nIn this paper, we propose a new benChmarking paRadIgm for evaluaTing\ntrajEctoRy predIction Approaches (CRITERIA). Particularly, we propose 1) a\nmethod for extracting driving scenarios at varying levels of specificity\naccording to the structure of the roads, models' performance, and data\nproperties for fine-grained ranking of prediction models; 2) A set of new\nbias-free metrics for measuring diversity, by incorporating the characteristics\nof a given scenario, and admissibility, by considering the structure of roads\nand kinematic compliancy, motivated by real-world driving constraints. 3) Using\nthe proposed benchmark, we conduct extensive experimentation on a\nrepresentative set of the prediction models using the large scale Argoverse\ndataset. We show that the proposed benchmark can produce a more accurate\nranking of the models and serve as a means of characterizing their behavior. We\nfurther present ablation studies to highlight contributions of different\nelements that are used to compute the proposed metrics.",
          "link": "http://arxiv.org/abs/2310.07794",
          "publishedOn": "2023-10-14T00:41:31.458Z",
          "wordCount": 771,
          "title": "CRITERIA: a New Benchmarking Paradigm for Evaluating Trajectory Prediction Models for Autonomous Driving. (arXiv:2310.07794v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1910.09143",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_Y/0/1/0/all/0/1\">Yijia Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Poloczek_M/0/1/0/all/0/1\">Matthias Poloczek</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jiang_D/0/1/0/all/0/1\">Daniel R. Jiang</a>",
          "description": "Reinforcement learning in sparse-reward navigation environments with\nexpensive and limited interactions is challenging and poses a need for\neffective exploration. Motivated by complex navigation tasks that require\nreal-world training (when cheap simulators are not available), we consider an\nagent that faces an unknown distribution of environments and must decide on an\nexploration strategy. It may leverage a series of training environments to\nimprove its policy before it is evaluated in a test environment drawn from the\nsame environment distribution. Most existing approaches focus on fixed\nexploration strategies, while the few that view exploration as a\nmeta-optimization problem tend to ignore the need for cost-efficient\nexploration. We propose a cost-aware Bayesian optimization approach that\nefficiently searches over a class of dynamic subgoal-based exploration\nstrategies. The algorithm adjusts a variety of levers -- the locations of the\nsubgoals, the length of each episode, and the number of replications per trial\n-- in order to overcome the challenges of sparse rewards, expensive\ninteractions, and noise. An experimental evaluation demonstrates that the new\napproach outperforms existing baselines across a number of problem domains. We\nalso provide a theoretical foundation and prove that the method asymptotically\nidentifies a near-optimal subgoal design.",
          "link": "http://arxiv.org/abs/1910.09143",
          "publishedOn": "2023-10-14T00:41:31.451Z",
          "wordCount": 740,
          "title": "Dynamic Subgoal-based Exploration via Bayesian Optimization. (arXiv:1910.09143v5 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.10886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1\">Mingqi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>",
          "description": "We present AIRS: Automatic Intrinsic Reward Shaping that intelligently and\nadaptively provides high-quality intrinsic rewards to enhance exploration in\nreinforcement learning (RL). More specifically, AIRS selects shaping function\nfrom a predefined set based on the estimated task return in real-time,\nproviding reliable exploration incentives and alleviating the biased objective\nproblem. Moreover, we develop an intrinsic reward toolkit to provide efficient\nand reliable implementations of diverse intrinsic reward approaches. We test\nAIRS on various tasks of MiniGrid, Procgen, and DeepMind Control Suite.\nExtensive simulation demonstrates that AIRS can outperform the benchmarking\nschemes and achieve superior performance with simple architecture.",
          "link": "http://arxiv.org/abs/2301.10886",
          "publishedOn": "2023-10-14T00:41:31.424Z",
          "wordCount": 672,
          "title": "Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning. (arXiv:2301.10886v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boutsikas_C/0/1/0/all/0/1\">Christos Boutsikas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drineas_P/0/1/0/all/0/1\">Petros Drineas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mertzanidis_M/0/1/0/all/0/1\">Marios Mertzanidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Psomas_A/0/1/0/all/0/1\">Alexandros Psomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_P/0/1/0/all/0/1\">Paritosh Verma</a>",
          "description": "We consider the problem of a revenue-maximizing seller with a large number of\nitems $m$ for sale to $n$ strategic bidders, whose valuations are drawn\nindependently from high-dimensional, unknown prior distributions. It is\nwell-known that optimal and even approximately-optimal mechanisms for this\nsetting are notoriously difficult to characterize or compute, and, even when\nthey can be found, are often rife with various counter-intuitive properties. In\nthis paper, following a model introduced recently by Cai and\nDaskalakis~\\cite{cai2022recommender}, we consider the case that bidders' prior\ndistributions can be well-approximated by a topic model. We design an active\nlearning component, responsible for interacting with the bidders and outputting\nlow-dimensional approximations of their types, and a mechanism design\ncomponent, responsible for robustifying mechanisms for the low-dimensional\nmodel to work for the approximate types of the former component. On the active\nlearning front, we cast our problem in the framework of Randomized Linear\nAlgebra (RLA) for regression problems, allowing us to import several\nbreakthrough results from that line of research, and adapt them to our setting.\nOn the mechanism design front, we remove many restrictive assumptions of prior\nwork on the type of access needed to the underlying distributions and the\nassociated mechanisms. To the best of our knowledge, our work is the first to\nformulate connections between mechanism design, and RLA for active learning of\nregression problems, opening the door for further applications of randomized\nlinear algebra primitives to mechanism design.",
          "link": "http://arxiv.org/abs/2310.07874",
          "publishedOn": "2023-10-14T00:41:31.418Z",
          "wordCount": 769,
          "title": "Refined Mechanism Design for Approximately Structured Priors via Active Regression. (arXiv:2310.07874v1 [cs.GT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiaoyang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wenbo Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nouiehed_M/0/1/0/all/0/1\">Maher Nouiehed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kontar_R/0/1/0/all/0/1\">Raed Al Kontar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Judy Jin</a>",
          "description": "Current techniques for Out-of-Distribution (OoD) detection predominantly rely\non quantifying predictive uncertainty and incorporating model regularization\nduring the training phase, using either real or synthetic OoD samples. However,\nmethods that utilize real OoD samples lack exploration and are prone to overfit\nthe OoD samples at hand. Whereas synthetic samples are often generated based on\nfeatures extracted from training data, rendering them less effective when the\ntraining and OoD data are highly overlapped in the feature space. In this work,\nwe propose a Wasserstein-score-based generative adversarial training scheme to\nenhance OoD detection accuracy, which, for the first time, performs data\naugmentation and exploration simultaneously under the supervision of limited\nOoD samples. Specifically, the generator explores OoD spaces and generates\nsynthetic OoD samples using feedback from the discriminator, while the\ndiscriminator exploits both the observed and synthesized samples for OoD\ndetection using a predefined Wasserstein score. We provide theoretical\nguarantees that the optimal solutions of our generative scheme are\nstatistically achievable through adversarial training in empirical settings. We\nthen demonstrate that the proposed method outperforms state-of-the-art\ntechniques on various computer vision datasets and exhibits superior\ngeneralizability to unseen OoD data.",
          "link": "http://arxiv.org/abs/2310.08040",
          "publishedOn": "2023-10-14T00:41:31.413Z",
          "wordCount": 687,
          "title": "SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection. (arXiv:2310.08040v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gan_J/0/1/0/all/0/1\">Jingru Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xinzhe Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qingming Huang</a>",
          "description": "Given an image and an associated textual question, the purpose of\nKnowledge-Based Visual Question Answering (KB-VQA) is to provide a correct\nanswer to the question with the aid of external knowledge bases. Prior KB-VQA\nmodels are usually formulated as a retriever-classifier framework, where a\npre-trained retriever extracts textual or visual information from knowledge\ngraphs and then makes a prediction among the candidates. Despite promising\nprogress, there are two drawbacks with existing models. Firstly, modeling\nquestion-answering as multi-class classification limits the answer space to a\npreset corpus and lacks the ability of flexible reasoning. Secondly, the\nclassifier merely consider \"what is the answer\" without \"how to get the\nanswer\", which cannot ground the answer to explicit reasoning paths. In this\npaper, we confront the challenge of \\emph{explainable open-set} KB-VQA, where\nthe system is required to answer questions with entities at wild and retain an\nexplainable reasoning path. To resolve the aforementioned issues, we propose a\nnew retriever-ranker paradigm of KB-VQA, Graph pATH rankER (GATHER for\nbrevity). Specifically, it contains graph constructing, pruning, and path-level\nranking, which not only retrieves accurate answers but also provides inference\npaths that explain the reasoning process. To comprehensively evaluate our\nmodel, we reformulate the benchmark dataset OK-VQA with manually corrected\nentity-level annotations and release it as ConceptVQA. Extensive experiments on\nreal-world questions demonstrate that our framework is not only able to perform\nopen-set question answering across the whole knowledge base but provide\nexplicit reasoning path.",
          "link": "http://arxiv.org/abs/2310.08148",
          "publishedOn": "2023-10-14T00:41:31.408Z",
          "wordCount": 741,
          "title": "Open-Set Knowledge-Based Visual Question Answering with Inference Paths. (arXiv:2310.08148v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.06599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>",
          "description": "Existing regression models tend to fall short in both accuracy and\nuncertainty estimation when the label distribution is imbalanced. In this\npaper, we propose a probabilistic deep learning model, dubbed variational\nimbalanced regression (VIR), which not only performs well in imbalanced\nregression but naturally produces reasonable uncertainty estimation as a\nbyproduct. Different from typical variational autoencoders assuming I.I.D.\nrepresentations (a data point's representation is not directly affected by\nother data points), our VIR borrows data with similar regression labels to\ncompute the latent representation's variational distribution; furthermore,\ndifferent from deterministic regression models producing point estimates, VIR\npredicts the entire normal-inverse-gamma distributions and modulates the\nassociated conjugate distributions to impose probabilistic reweighting on the\nimbalanced data, thereby providing better uncertainty estimation. Experiments\nin several real-world datasets show that our VIR can outperform\nstate-of-the-art imbalanced regression models in terms of both accuracy and\nuncertainty estimation. Code will soon be available at\n\\url{https://github.com/Wang-ML-Lab/variational-imbalanced-regression}.",
          "link": "http://arxiv.org/abs/2306.06599",
          "publishedOn": "2023-10-14T00:41:31.391Z",
          "wordCount": 713,
          "title": "Variational Imbalanced Regression: Fair Uncertainty Quantification via Probabilistic Smoothing. (arXiv:2306.06599v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08339",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guillou_E/0/1/0/all/0/1\">Eve Le Guillou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Will_M/0/1/0/all/0/1\">Michael Will</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guillou_P/0/1/0/all/0/1\">Pierre Guillou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasczyk_J/0/1/0/all/0/1\">Jonas Lukasczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fortin_P/0/1/0/all/0/1\">Pierre Fortin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garth_C/0/1/0/all/0/1\">Christoph Garth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tierny_J/0/1/0/all/0/1\">Julien Tierny</a>",
          "description": "This system paper presents a software framework for the support of\ntopological analysis pipelines in a distributed-memory model. While several\nrecent papers introduced topology-based approaches for distributed-memory\nenvironments, these were reporting experiments obtained with tailored,\nmono-algorithm implementations. In contrast, we describe in this paper a\ngeneral-purpose, generic framework for topological analysis pipelines, i.e. a\nsequence of topological algorithms interacting together, possibly on distinct\nnumbers of processes. Specifically, we instantiated our framework with the MPI\nmodel, within the Topology ToolKit (TTK). While developing this framework, we\nfaced several algorithmic and software engineering challenges, which we\ndocument in this paper. We provide a taxonomy for the distributed-memory\ntopological algorithms supported by TTK, depending on their communication needs\nand provide examples of hybrid MPI+thread parallelizations. Detailed\nperformance analyses show that parallel efficiencies range from $20\\%$ to\n$80\\%$ (depending on the algorithms), and that the MPI-specific preconditioning\nintroduced by our framework induces a negligible computation time overhead. We\nillustrate the new distributed-memory capabilities of TTK with an example of\nadvanced analysis pipeline, combining multiple algorithms, run on the largest\npublicly available dataset we have found (120 billion vertices) on a standard\ncluster with 64 nodes (for a total of 1,536 cores). Finally, we provide a\nroadmap for the completion of TTK's MPI extension, along with generic\nrecommendations for each algorithm communication category.",
          "link": "http://arxiv.org/abs/2310.08339",
          "publishedOn": "2023-10-14T00:41:31.381Z",
          "wordCount": 754,
          "title": "A Generic Software Framework for Distributed Topological Analysis Pipelines. (arXiv:2310.08339v1 [cs.DC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mucsanyi_B/0/1/0/all/0/1\">B&#xe1;lint Mucs&#xe1;nyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchhof_M/0/1/0/all/0/1\">Michael Kirchhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_E/0/1/0/all/0/1\">Elisa Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_A/0/1/0/all/0/1\">Alexander Rubinstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seong Joon Oh</a>",
          "description": "As machine learning technology gets applied to actual products and solutions,\nnew challenges have emerged. Models unexpectedly fail to generalize to small\nchanges in the distribution, tend to be confident on novel data they have never\nseen, or cannot communicate the rationale behind their decisions effectively\nwith the end users. Collectively, we face a trustworthiness issue with the\ncurrent machine learning technology. This textbook on Trustworthy Machine\nLearning (TML) covers a theoretical and technical background of four key topics\nin TML: Out-of-Distribution Generalization, Explainability, Uncertainty\nQuantification, and Evaluation of Trustworthiness. We discuss important\nclassical and contemporary research papers of the aforementioned fields and\nuncover and connect their underlying intuitions. The book evolved from the\nhomonymous course at the University of T\\\"ubingen, first offered in the Winter\nSemester of 2022/23. It is meant to be a stand-alone product accompanied by\ncode snippets and various pointers to further sources on topics of TML. The\ndedicated website of the book is https://trustworthyml.io/.",
          "link": "http://arxiv.org/abs/2310.08215",
          "publishedOn": "2023-10-14T00:41:31.376Z",
          "wordCount": 678,
          "title": "Trustworthy Machine Learning. (arXiv:2310.08215v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08237",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_X/0/1/0/all/0/1\">Xingdong Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_X/0/1/0/all/0/1\">Xin He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1\">Caixing Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1\">Chao Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jingnan Zhang</a>",
          "description": "Covariate shift occurs prevalently in practice, where the input distributions\nof the source and target data are substantially different. Despite its\npractical importance in various learning problems, most of the existing methods\nonly focus on some specific learning tasks and are not well validated\ntheoretically and numerically. To tackle this problem, we propose a unified\nanalysis of general nonparametric methods in a reproducing kernel Hilbert space\n(RKHS) under covariate shift. Our theoretical results are established for a\ngeneral loss belonging to a rich loss function family, which includes many\ncommonly used methods as special cases, such as mean regression, quantile\nregression, likelihood-based classification, and margin-based classification.\nTwo types of covariate shift problems are the focus of this paper and the sharp\nconvergence rates are established for a general loss function to provide a\nunified theoretical analysis, which concurs with the optimal results in\nliterature where the squared loss is used. Extensive numerical studies on\nsynthetic and real examples confirm our theoretical findings and further\nillustrate the effectiveness of our proposed method.",
          "link": "http://arxiv.org/abs/2310.08237",
          "publishedOn": "2023-10-14T00:41:31.362Z",
          "wordCount": 697,
          "title": "Towards a Unified Analysis of Kernel-based Methods Under Covariate Shift. (arXiv:2310.08237v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07990",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_C/0/1/0/all/0/1\">Chen Zhao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Su_K/0/1/0/all/0/1\">Kuan-Jui Su</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_C/0/1/0/all/0/1\">Chong Wu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cao_X/0/1/0/all/0/1\">Xuewei Cao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sha_Q/0/1/0/all/0/1\">Qiuying Sha</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_W/0/1/0/all/0/1\">Wu Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Luo_Z/0/1/0/all/0/1\">Zhe Luo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qin_T/0/1/0/all/0/1\">Tian Qin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qiu_C/0/1/0/all/0/1\">Chuan Qiu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_L/0/1/0/all/0/1\">Lan Juan Zhao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_A/0/1/0/all/0/1\">Anqi Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jiang_L/0/1/0/all/0/1\">Lindong Jiang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Shen_H/0/1/0/all/0/1\">Hui Shen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhou_W/0/1/0/all/0/1\">Weihua Zhou</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deng_H/0/1/0/all/0/1\">Hong-Wen Deng</a>",
          "description": "Background: Missing data is a common challenge in mass spectrometry-based\nmetabolomics, which can lead to biased and incomplete analyses. The integration\nof whole-genome sequencing (WGS) data with metabolomics data has emerged as a\npromising approach to enhance the accuracy of data imputation in metabolomics\nstudies. Method: In this study, we propose a novel method that leverages the\ninformation from WGS data and reference metabolites to impute unknown\nmetabolites. Our approach utilizes a multi-view variational autoencoder to\njointly model the burden score, polygenetic risk score (PGS), and linkage\ndisequilibrium (LD) pruned single nucleotide polymorphisms (SNPs) for feature\nextraction and missing metabolomics data imputation. By learning the latent\nrepresentations of both omics data, our method can effectively impute missing\nmetabolomics values based on genomic information. Results: We evaluate the\nperformance of our method on empirical metabolomics datasets with missing\nvalues and demonstrate its superiority compared to conventional imputation\ntechniques. Using 35 template metabolites derived burden scores, PGS and\nLD-pruned SNPs, the proposed methods achieved r2-scores > 0.01 for 71.55% of\nmetabolites. Conclusion: The integration of WGS data in metabolomics imputation\nnot only improves data completeness but also enhances downstream analyses,\npaving the way for more comprehensive and accurate investigations of metabolic\npathways and disease associations. Our findings offer valuable insights into\nthe potential benefits of utilizing WGS data for metabolomics data imputation\nand underscore the importance of leveraging multi-modal data integration in\nprecision medicine research.",
          "link": "http://arxiv.org/abs/2310.07990",
          "publishedOn": "2023-10-14T00:41:31.272Z",
          "wordCount": 773,
          "title": "Multi-View Variational Autoencoder for Missing Value Imputation in Untargeted Metabolomics. (arXiv:2310.07990v1 [q-bio.GN])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianrong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiatao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinh_L/0/1/0/all/0/1\">Laurent Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1\">Evangelos A. Theodorou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susskind_J/0/1/0/all/0/1\">Josh Susskind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_S/0/1/0/all/0/1\">Shuangfei Zhai</a>",
          "description": "Diffusion models (DMs) represent state-of-the-art generative models for\ncontinuous inputs. DMs work by constructing a Stochastic Differential Equation\n(SDE) in the input space (ie, position space), and using a neural network to\nreverse it. In this work, we introduce a novel generative modeling framework\ngrounded in \\textbf{phase space dynamics}, where a phase space is defined as\n{an augmented space encompassing both position and velocity.} Leveraging\ninsights from Stochastic Optimal Control, we construct a path measure in the\nphase space that enables efficient sampling. {In contrast to DMs, our framework\ndemonstrates the capability to generate realistic data points at an early stage\nof dynamics propagation.} This early prediction sets the stage for efficient\ndata generation by leveraging additional velocity information along the\ntrajectory. On standard image generation benchmarks, our model yields favorable\nperformance over baselines in the regime of small Number of Function\nEvaluations (NFEs). Furthermore, our approach rivals the performance of\ndiffusion models equipped with efficient sampling techniques, underscoring its\npotential as a new tool generative modeling.",
          "link": "http://arxiv.org/abs/2310.07805",
          "publishedOn": "2023-10-14T00:41:31.195Z",
          "wordCount": 670,
          "title": "Generative Modeling with Phase Stochastic Bridges. (arXiv:2310.07805v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.07189",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dorosti_T/0/1/0/all/0/1\">Tina Dorosti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schultheiss_M/0/1/0/all/0/1\">Manuel Schultheiss</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hofmann_F/0/1/0/all/0/1\">Felix Hofmann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thalhammer_J/0/1/0/all/0/1\">Johannes Thalhammer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kirchner_L/0/1/0/all/0/1\">Luisa Kirchner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Urban_T/0/1/0/all/0/1\">Theresa Urban</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pfeiffer_F/0/1/0/all/0/1\">Franz Pfeiffer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schaff_F/0/1/0/all/0/1\">Florian Schaff</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lasser_T/0/1/0/all/0/1\">Tobias Lasser</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pfeiffer_D/0/1/0/all/0/1\">Daniela Pfeiffer</a>",
          "description": "We aim to optimize the binary detection of Chronic Obstructive Pulmonary\nDisease (COPD) based on emphysema presence in the lung with convolutional\nneural networks (CNN) by exploring manually adjusted versus automated\nwindow-setting optimization (WSO) on computed tomography (CT) images. 7,194 CT\nimages (3,597 with COPD; 3,597 healthy controls) from 78 subjects (43 with\nCOPD; 35 healthy controls) were selected retrospectively (10.2018-12.2019) and\npreprocessed. For each image, intensity values were manually clipped to the\nemphysema window setting and a baseline 'full-range' window setting.\nClass-balanced train, validation, and test sets contained 3,392, 1,114, and\n2,688 images. The network backbone was optimized by comparing various CNN\narchitectures. Furthermore, automated WSO was implemented by adding a\ncustomized layer to the model. The image-level area under the Receiver\nOperating Characteristics curve (AUC) [lower, upper limit 95% confidence] was\nutilized to compare model variations. Repeated inference (n=7) on the test set\nshowed that the DenseNet was the most efficient backbone and achieved a mean\nAUC of 0.80 [0.76, 0.85] without WSO. Comparably, with input images manually\nadjusted to the emphysema window, the DenseNet model predicted COPD with a mean\nAUC of 0.86 [0.82, 0.89]. By adding a customized WSO layer to the DenseNet, an\noptimal window in the proximity of the emphysema window setting was learned\nautomatically, and a mean AUC of 0.82 [0.78, 0.86] was achieved. Detection of\nCOPD with DenseNet models was improved by WSO of CT data to the emphysema\nwindow setting range.",
          "link": "http://arxiv.org/abs/2303.07189",
          "publishedOn": "2023-10-14T00:41:31.187Z",
          "wordCount": 818,
          "title": "Optimizing Convolutional Neural Networks for Chronic Obstructive Pulmonary Disease Detection in Clinical Computed Tomography Imaging. (arXiv:2303.07189v3 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.02621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jonnarth_A/0/1/0/all/0/1\">Arvi Jonnarth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yushan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Felsberg_M/0/1/0/all/0/1\">Michael Felsberg</a>",
          "description": "Image-level weakly-supervised semantic segmentation (WSSS) reduces the\nusually vast data annotation cost by surrogate segmentation masks during\ntraining. The typical approach involves training an image classification\nnetwork using global average pooling (GAP) on convolutional feature maps. This\nenables the estimation of object locations based on class activation maps\n(CAMs), which identify the importance of image regions. The CAMs are then used\nto generate pseudo-labels, in the form of segmentation masks, to supervise a\nsegmentation model in the absence of pixel-level ground truth. Our work is\nbased on two techniques for improving CAMs; importance sampling, which is a\nsubstitute for GAP, and the feature similarity loss, which utilizes a heuristic\nthat object contours almost always align with color edges in images. However,\nboth are based on the multinomial posterior with softmax, and implicitly assume\nthat classes are mutually exclusive, which turns out suboptimal in our\nexperiments. Thus, we reformulate both techniques based on binomial posteriors\nof multiple independent binary problems. This has two benefits; their\nperformance is improved and they become more general, resulting in an add-on\nmethod that can boost virtually any WSSS method. This is demonstrated on a wide\nvariety of baselines on the PASCAL VOC dataset, improving the region similarity\nand contour quality of all implemented state-of-the-art methods. Experiments on\nthe MS COCO dataset show that our proposed add-on is well-suited for\nlarge-scale settings. Our code is available at https://github.com/arvijj/hfpl.",
          "link": "http://arxiv.org/abs/2304.02621",
          "publishedOn": "2023-10-14T00:41:31.180Z",
          "wordCount": 751,
          "title": "High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation. (arXiv:2304.02621v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15394",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vos_D/0/1/0/all/0/1\">Dani&#xeb;l Vos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vos_J/0/1/0/all/0/1\">Jelle Vos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erkin_Z/0/1/0/all/0/1\">Zekeriya Erkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verwer_S/0/1/0/all/0/1\">Sicco Verwer</a>",
          "description": "Decision trees are interpretable models that are well-suited to non-linear\nlearning problems. Much work has been done on extending decision tree learning\nalgorithms with differential privacy, a system that guarantees the privacy of\nsamples within the training data. However, current state-of-the-art algorithms\nfor this purpose sacrifice much utility for a small privacy benefit. These\nsolutions create random decision nodes that reduce decision tree accuracy or\nspend an excessive share of the privacy budget on labeling leaves. Moreover,\nmany works do not support continuous features or leak information about them.\nWe propose a new method called PrivaTree based on private histograms that\nchooses good splits while consuming a small privacy budget. The resulting trees\nprovide a significantly better privacy-utility trade-off and accept mixed\nnumerical and categorical data without leaking information about numerical\nfeatures. Finally, while it is notoriously hard to give robustness guarantees\nagainst data poisoning attacks, we demonstrate bounds for the expected accuracy\nand success rates of backdoor attacks against differentially-private learners.\nBy leveraging the better privacy-utility trade-off of PrivaTree we are able to\ntrain decision trees with significantly better robustness against backdoor\nattacks compared to regular decision trees and with meaningful theoretical\nguarantees.",
          "link": "http://arxiv.org/abs/2305.15394",
          "publishedOn": "2023-10-14T00:41:31.154Z",
          "wordCount": 723,
          "title": "Differentially-Private Decision Trees and Provable Robustness to Data Poisoning. (arXiv:2305.15394v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08287",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Laurent_O/0/1/0/all/0/1\">Olivier Laurent</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aldea_E/0/1/0/all/0/1\">Emanuel Aldea</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Franchi_G/0/1/0/all/0/1\">Gianni Franchi</a>",
          "description": "The distribution of the weights of modern deep neural networks (DNNs) -\ncrucial for uncertainty quantification and robustness - is an eminently complex\nobject due to its extremely high dimensionality. This paper proposes one of the\nfirst large-scale explorations of the posterior distribution of deep Bayesian\nNeural Networks (BNNs), expanding its study to real-world vision tasks and\narchitectures. Specifically, we investigate the optimal approach for\napproximating the posterior, analyze the connection between posterior quality\nand uncertainty quantification, delve into the impact of modes on the\nposterior, and explore methods for visualizing the posterior. Moreover, we\nuncover weight-space symmetries as a critical aspect for understanding the\nposterior. To this extent, we develop an in-depth assessment of the impact of\nboth permutation and scaling symmetries that tend to obfuscate the Bayesian\nposterior. While the first type of transformation is known for duplicating\nmodes, we explore the relationship between the latter and L2 regularization,\nchallenging previous misconceptions. Finally, to help the community improve our\nunderstanding of the Bayesian posterior, we will shortly release the first\nlarge-scale checkpoint dataset, including thousands of real-world models and\nour codes.",
          "link": "http://arxiv.org/abs/2310.08287",
          "publishedOn": "2023-10-14T00:41:30.728Z",
          "wordCount": null,
          "title": "A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors. (arXiv:2310.08287v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08071",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinhong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Changsheng Xu</a>",
          "description": "Despite the great progress of unsupervised domain adaptation (UDA) with the\ndeep neural networks, current UDA models are opaque and cannot provide\npromising explanations, limiting their applications in the scenarios that\nrequire safe and controllable model decisions. At present, a surge of work\nfocuses on designing deep interpretable methods with adequate data annotations\nand only a few methods consider the distributional shift problem. Most existing\ninterpretable UDA methods are post-hoc ones, which cannot facilitate the model\nlearning process for performance enhancement. In this paper, we propose an\ninherently interpretable method, named Transferable Conceptual Prototype\nLearning (TCPL), which could simultaneously interpret and improve the processes\nof knowledge transfer and decision-making in UDA. To achieve this goal, we\ndesign a hierarchically prototypical module that transfers categorical basic\nconcepts from the source domain to the target domain and learns domain-shared\nprototypes for explaining the underlying reasoning process. With the learned\ntransferable prototypes, a self-predictive consistent pseudo-label strategy\nthat fuses confidence, predictions, and prototype information, is designed for\nselecting suitable target samples for pseudo annotations and gradually\nnarrowing down the domain gap. Comprehensive experiments show that the proposed\nmethod can not only provide effective and intuitive explanations but also\noutperform previous state-of-the-arts.",
          "link": "http://arxiv.org/abs/2310.08071",
          "publishedOn": "2023-10-14T00:41:30.523Z",
          "wordCount": 712,
          "title": "Learning Transferable Conceptual Prototypes for Interpretable Unsupervised Domain Adaptation. (arXiv:2310.08071v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shafi_Z/0/1/0/all/0/1\">Zohair Shafi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_B/0/1/0/all/0/1\">Benjamin A. Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1\">Tina Eliassi-Rad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caceres_R/0/1/0/all/0/1\">Rajmonda S. Caceres</a>",
          "description": "Machine learning (ML) approaches are increasingly being used to accelerate\ncombinatorial optimization (CO) problems. We look specifically at the Set Cover\nProblem (SCP) and propose Graph-SCP, a graph neural network method that can\naugment existing optimization solvers by learning to identify a much smaller\nsub-problem that contains the solution space. We evaluate the performance of\nGraph-SCP on synthetic weighted and unweighted SCP instances with diverse\nproblem characteristics and complexities, and on instances from the OR Library,\na canonical benchmark for SCP. We show that Graph-SCP reduces the problem size\nby 30-70% and achieves run time speedups up to~25x when compared to commercial\nsolvers (Gurobi). Given a desired optimality threshold, Graph-SCP will improve\nupon it or even achieve 100% optimality. This is in contrast to fast greedy\nsolutions that significantly compromise solution quality to achieve guaranteed\npolynomial run time. Graph-SCP can generalize to larger problem sizes and can\nbe used with other conventional or ML-augmented CO solvers to lead to potential\nadditional run time improvement.",
          "link": "http://arxiv.org/abs/2310.07979",
          "publishedOn": "2023-10-14T00:41:30.499Z",
          "wordCount": 674,
          "title": "Graph-SCP: Accelerating Set Cover Problems with Graph Neural Networks. (arXiv:2310.07979v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nezami_N/0/1/0/all/0/1\">Nazanin Nezami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anahideh_H/0/1/0/all/0/1\">Hadis Anahideh</a>",
          "description": "Surrogate Optimization (SO) algorithms have shown promise for optimizing\nexpensive black-box functions. However, their performance is heavily influenced\nby hyperparameters related to sampling and surrogate fitting, which poses a\nchallenge to their widespread adoption. We investigate the impact of\nhyperparameters on various SO algorithms and propose a Hyperparameter Adaptive\nSearch for SO (HASSO) approach. HASSO is not a hyperparameter tuning algorithm,\nbut a generic self-adjusting SO algorithm that dynamically tunes its own\nhyperparameters while concurrently optimizing the primary objective function,\nwithout requiring additional evaluations. The aim is to improve the\naccessibility, effectiveness, and convergence speed of SO algorithms for\npractitioners. Our approach identifies and modifies the most influential\nhyperparameters specific to each problem and SO approach, reducing the need for\nmanual tuning without significantly increasing the computational burden.\nExperimental results demonstrate the effectiveness of HASSO in enhancing the\nperformance of various SO algorithms across different global optimization test\nproblems.",
          "link": "http://arxiv.org/abs/2310.07970",
          "publishedOn": "2023-10-14T00:41:30.476Z",
          "wordCount": 667,
          "title": "Hyperparameter Adaptive Search for Surrogate Optimization: A Self-Adjusting Approach. (arXiv:2310.07970v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianfei Ma</a>",
          "description": "Temporal difference learning (TD) is a foundational concept in reinforcement\nlearning (RL), aimed at efficiently assessing a policy's value function.\nTD($\\lambda$), a potent variant, incorporates a memory trace to distribute the\nprediction error into the historical context. However, this approach often\nneglects the significance of historical states and the relative importance of\npropagating the TD error, influenced by challenges such as visitation imbalance\nor outcome noise. To address this, we propose a novel TD algorithm named\ndiscerning TD learning (DTD), which allows flexible emphasis\nfunctions$-$predetermined or adapted during training$-$to allocate efforts\neffectively across states. We establish the convergence properties of our\nmethod within a specific class of emphasis functions and showcase its promising\npotential for adaptation to deep RL contexts. Empirical results underscore that\nemploying a judicious emphasis function not only improves value estimation but\nalso expedites learning across diverse scenarios.",
          "link": "http://arxiv.org/abs/2310.08091",
          "publishedOn": "2023-10-14T00:41:30.297Z",
          "wordCount": 617,
          "title": "Discerning Temporal Difference Learning. (arXiv:2310.08091v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaquier_N/0/1/0/all/0/1\">No&#xe9;mie Jaquier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rozo_L/0/1/0/all/0/1\">Leonel Rozo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asfour_T/0/1/0/all/0/1\">Tamim Asfour</a>",
          "description": "In the realm of robotics, numerous downstream robotics tasks leverage machine\nlearning methods for processing, modeling, or synthesizing data. Often, this\ndata comprises variables that inherently carry geometric constraints, such as\nthe unit-norm condition of quaternions representing rigid-body orientations or\nthe positive definiteness of stiffness and manipulability ellipsoids. Handling\nsuch geometric constraints effectively requires the incorporation of tools from\ndifferential geometry into the formulation of machine learning methods. In this\ncontext, Riemannian manifolds emerge as a powerful mathematical framework to\nhandle such geometric constraints. Nevertheless, their recent adoption in robot\nlearning has been largely characterized by a mathematically-flawed\nsimplification, hereinafter referred to as the ``single tangent space fallacy\".\nThis approach involves merely projecting the data of interest onto a single\ntangent (Euclidean) space, over which an off-the-shelf learning algorithm is\napplied. This paper provides a theoretical elucidation of various\nmisconceptions surrounding this approach and offers experimental evidence of\nits shortcomings. Finally, it presents valuable insights to promote best\npractices when employing Riemannian geometry within robot learning\napplications.",
          "link": "http://arxiv.org/abs/2310.07902",
          "publishedOn": "2023-10-14T00:41:30.277Z",
          "wordCount": 704,
          "title": "Unraveling the Single Tangent Space Fallacy: An Analysis and Clarification for Applying Riemannian Geometry in Robot Learning. (arXiv:2310.07902v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yite Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jiahao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanlin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Cong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jianbo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haibin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruoyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Scaling of deep neural networks, especially Transformers, is pivotal for\ntheir surging performance and has further led to the emergence of sophisticated\nreasoning capabilities in foundation models. Such scaling generally requires\ntraining large models from scratch with random initialization, failing to\nleverage the knowledge acquired by their smaller counterparts, which are\nalready resource-intensive to obtain. To tackle this inefficiency, we present\n$\\textbf{L}$ossl$\\textbf{E}$ss $\\textbf{MO}$del Expansio$\\textbf{N}$ (LEMON), a\nrecipe to initialize scaled models using the weights of their smaller but\npre-trained counterparts. This is followed by model training with an optimized\nlearning rate scheduler tailored explicitly for the scaled models,\nsubstantially reducing the training time compared to training from scratch.\nNotably, LEMON is versatile, ensuring compatibility with various network\nstructures, including models like Vision Transformers and BERT. Our empirical\nresults demonstrate that LEMON reduces computational costs by 56.7% for Vision\nTransformers and 33.2% for BERT when compared to training from scratch.",
          "link": "http://arxiv.org/abs/2310.07999",
          "publishedOn": "2023-10-14T00:41:30.270Z",
          "wordCount": 652,
          "title": "LEMON: Lossless model expansion. (arXiv:2310.07999v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eggert_G/0/1/0/all/0/1\">Gus Eggert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_K/0/1/0/all/0/1\">Kevin Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biven_M/0/1/0/all/0/1\">Mike Biven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waugh_J/0/1/0/all/0/1\">Justin Waugh</a>",
          "description": "It is well-established that large, diverse datasets play a pivotal role in\nthe performance of modern AI systems for text and image modalities. However,\nthere are no datasets for tabular data of comparable size and diversity to\nthose available for text and images. Thus we present \"TabLib'', a compilation\nof 627 million tables totaling 69 TiB, along with 867B tokens of context.\nTabLib was extracted from numerous file formats, including CSV, HTML, SQLite,\nPDF, Excel, and others, sourced from GitHub and Common Crawl. The size and\ndiversity of TabLib offer considerable promise in the table modality,\nreminiscent of the original promise of foundational datasets for text and\nimages, such as The Pile and LAION.",
          "link": "http://arxiv.org/abs/2310.07875",
          "publishedOn": "2023-10-14T00:41:30.262Z",
          "wordCount": 621,
          "title": "TabLib: A Dataset of 627M Tables with Context. (arXiv:2310.07875v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07927",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Zou_Z/0/1/0/all/0/1\">Ziyue Zou</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Tiwary_P/0/1/0/all/0/1\">Pratyush Tiwary</a>",
          "description": "In this study, we present a graph neural network-based learning approach\nusing an autoencoder setup to derive low-dimensional variables from features\nobserved in experimental crystal structures. These variables are then biased in\nenhanced sampling to observe state-to-state transitions and reliable\nthermodynamic weights. Our approach uses simple convolution and pooling\nmethods. To verify the effectiveness of our protocol, we examined the\nnucleation of various allotropes and polymorphs of iron and glycine from their\nmolten states. Our graph latent variables when biased in well-tempered\nmetadynamics consistently show transitions between states and achieve accurate\nfree energy calculations in agreement with experiments, both of which are\nindicators of dependable sampling. This underscores the strength and promise of\nour graph neural net variables for improved sampling. The protocol shown here\nshould be applicable for other systems and with other sampling methods.",
          "link": "http://arxiv.org/abs/2310.07927",
          "publishedOn": "2023-10-14T00:41:30.257Z",
          "wordCount": 647,
          "title": "Enhanced sampling of Crystal Nucleation with Graph Representation Learnt Variables. (arXiv:2310.07927v1 [cond-mat.stat-mech])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weisz_G/0/1/0/all/0/1\">Gell&#xe9;rt Weisz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andr&#xe1;s Gy&#xf6;rgy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesv&#xe1;ri</a>",
          "description": "We consider online reinforcement learning (RL) in episodic Markov decision\nprocesses (MDPs) under the linear $q^\\pi$-realizability assumption, where it is\nassumed that the action-values of all policies can be expressed as linear\nfunctions of state-action features. This class is known to be more general than\nlinear MDPs, where the transition kernel and the reward function are assumed to\nbe linear functions of the feature vectors. As our first contribution, we show\nthat the difference between the two classes is the presence of states in\nlinearly $q^\\pi$-realizable MDPs where for any policy, all the actions have\napproximately equal values, and skipping over these states by following an\narbitrarily fixed policy in those states transforms the problem to a linear\nMDP. Based on this observation, we derive a novel (computationally inefficient)\nlearning algorithm for linearly $q^\\pi$-realizable MDPs that simultaneously\nlearns what states should be skipped over and runs another learning algorithm\non the linear MDP hidden in the problem. The method returns an\n$\\epsilon$-optimal policy after $\\text{polylog}(H, d)/\\epsilon^2$ interactions\nwith the MDP, where $H$ is the time horizon and $d$ is the dimension of the\nfeature vectors, giving the first polynomial-sample-complexity online RL\nalgorithm for this setting. The results are proved for the misspecified case,\nwhere the sample complexity is shown to degrade gracefully with the\nmisspecification error.",
          "link": "http://arxiv.org/abs/2310.07811",
          "publishedOn": "2023-10-14T00:41:30.237Z",
          "wordCount": 769,
          "title": "Online RL in Linearly $q^\\pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore. (arXiv:2310.07811v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gruver_N/0/1/0/all/0/1\">Nate Gruver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finzi_M/0/1/0/all/0/1\">Marc Finzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1\">Shikai Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>",
          "description": "By encoding time series as a string of numerical digits, we can frame time\nseries forecasting as next-token prediction in text. Developing this approach,\nwe find that large language models (LLMs) such as GPT-3 and LLaMA-2 can\nsurprisingly zero-shot extrapolate time series at a level comparable to or\nexceeding the performance of purpose-built time series models trained on the\ndownstream tasks. To facilitate this performance, we propose procedures for\neffectively tokenizing time series data and converting discrete distributions\nover tokens into highly flexible densities over continuous values. We argue the\nsuccess of LLMs for time series stems from their ability to naturally represent\nmultimodal distributions, in conjunction with biases for simplicity, and\nrepetition, which align with the salient features in many time series, such as\nrepeated seasonal trends. We also show how LLMs can naturally handle missing\ndata without imputation through non-numerical text, accommodate textual side\ninformation, and answer questions to help explain predictions. While we find\nthat increasing model size generally improves performance on time series, we\nshow GPT-4 can perform worse than GPT-3 because of how it tokenizes numbers,\nand poor uncertainty calibration, which is likely the result of alignment\ninterventions such as RLHF.",
          "link": "http://arxiv.org/abs/2310.07820",
          "publishedOn": "2023-10-14T00:41:30.231Z",
          "wordCount": 708,
          "title": "Large Language Models Are Zero-Shot Time Series Forecasters. (arXiv:2310.07820v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07892",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chavez_Galaviz_J/0/1/0/all/0/1\">Jalil Chavez-Galaviz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianwen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1\">Ajinkya Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmoudian_N/0/1/0/all/0/1\">Nina Mahmoudian</a>",
          "description": "Station keeping is an essential maneuver for Autonomous Surface Vehicles\n(ASVs), mainly when used in confined spaces, to carry out surveys that require\nthe ASV to keep its position or in collaboration with other vehicles where the\nrelative position has an impact over the mission. However, this maneuver can\nbecome challenging for classic feedback controllers due to the need for an\naccurate model of the ASV dynamics and the environmental disturbances. This\nwork proposes a Model Predictive Controller using Neural Network Simulation\nError Minimization (NNSEM-MPC) to accurately predict the dynamics of the ASV\nunder wind disturbances. The performance of the proposed scheme under wind\ndisturbances is tested and compared against other controllers in simulation,\nusing the Robotics Operating System (ROS) and the multipurpose simulation\nenvironment Gazebo. A set of six tests were conducted by combining two wind\nspeeds (3 m/s and 6 m/s) and three wind directions (0$^\\circ$, 90$^\\circ$, and\n180$^\\circ$). The simulation results clearly show the advantage of the\nNNSEM-MPC over the following methods: backstepping controller, sliding mode\ncontroller, simplified dynamics MPC (SD-MPC), neural ordinary differential\nequation MPC (NODE-MPC), and knowledge-based NODE MPC (KNODE-MPC). The proposed\nNNSEM-MPC approach performs better than the rest in 4 out of the 6 test\nconditions, and it is the second best in the 2 remaining test cases, reducing\nthe mean position and heading error by at least 31\\% and 46\\% respectively\nacross all the test cases. In terms of execution speed, the proposed NNSEM-MPC\nis at least 36\\% faster than the rest of the MPC controllers. The field\nexperiments on two different ASV platforms showed that ASVs can effectively\nkeep the station utilizing the proposed method, with a position error as low as\n$1.68$ m and a heading error as low as $6.14^{\\circ}$ within time windows of at\nleast $150$s.",
          "link": "http://arxiv.org/abs/2310.07892",
          "publishedOn": "2023-10-14T00:41:30.166Z",
          "wordCount": 821,
          "title": "ASV Station Keeping under Wind Disturbances using Neural Network Simulation Error Minimization Model Predictive Control. (arXiv:2310.07892v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07896",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_A/0/1/0/all/0/1\">Ajay Sridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Dhruv Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glossop_C/0/1/0/all/0/1\">Catherine Glossop</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Robotic learning for navigation in unfamiliar environments needs to provide\npolicies for both task-oriented navigation (i.e., reaching a goal that the\nrobot has located), and task-agnostic exploration (i.e., searching for a goal\nin a novel setting). Typically, these roles are handled by separate models, for\nexample by using subgoal proposals, planning, or separate navigation\nstrategies. In this paper, we describe how we can train a single unified\ndiffusion policy to handle both goal-directed navigation and goal-agnostic\nexploration, with the latter providing the ability to search novel\nenvironments, and the former providing the ability to reach a user-specified\ngoal once it has been located. We show that this unified policy results in\nbetter overall performance when navigating to visually indicated goals in novel\nenvironments, as compared to approaches that use subgoal proposals from\ngenerative models, or prior methods based on latent variable models. We\ninstantiate our method by using a large-scale Transformer-based policy trained\non data from multiple ground robots, with a diffusion model decoder to flexibly\nhandle both goal-conditioned and goal-agnostic navigation. Our experiments,\nconducted on a real-world mobile robot platform, show effective navigation in\nunseen environments in comparison with five alternative methods, and\ndemonstrate significant improvements in performance and lower collision rates,\ndespite utilizing smaller models than state-of-the-art approaches. For more\nvideos, code, and pre-trained model checkpoints, see\nhttps://general-navigation-models.github.io/nomad/",
          "link": "http://arxiv.org/abs/2310.07896",
          "publishedOn": "2023-10-14T00:41:30.150Z",
          "wordCount": 733,
          "title": "NoMaD: Goal Masked Diffusion Policies for Navigation and Exploration. (arXiv:2310.07896v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Luyao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alghunaim_S/0/1/0/all/0/1\">Sulaiman A. Alghunaim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1\">Kun Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Condat_L/0/1/0/all/0/1\">Laurent Condat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jinde Cao</a>",
          "description": "Distributed optimization methods with random communication skips are gaining\nincreasing attention due to their proven benefits in accelerating communication\ncomplexity. Nevertheless, existing research mainly focuses on centralized\ncommunication protocols for strongly convex deterministic settings. In this\nwork, we provide a decentralized optimization method called RandCom, which\nincorporates probabilistic local updates. We analyze the performance of RandCom\nin stochastic non-convex, convex, and strongly convex settings and demonstrate\nits ability to asymptotically reduce communication overhead by the probability\nof communication. Additionally, we prove that RandCom achieves linear speedup\nas the number of nodes increases. In stochastic strongly convex settings, we\nfurther prove that RandCom can achieve linear speedup with network-independent\nstepsizes. Moreover, we apply RandCom to federated learning and provide\npositive results concerning the potential for achieving linear speedup and the\nsuitability of the probabilistic local update approach for non-convex settings.",
          "link": "http://arxiv.org/abs/2310.07983",
          "publishedOn": "2023-10-14T00:41:30.143Z",
          "wordCount": 677,
          "title": "RandCom: Random Communication Skipping Method for Decentralized Stochastic Optimization. (arXiv:2310.07983v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jafarigol_E/0/1/0/all/0/1\">Elaheh Jafarigol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trafalis_T/0/1/0/all/0/1\">Theodore Trafalis</a>",
          "description": "For over two decades, detecting rare events has been a challenging task among\nresearchers in the data mining and machine learning domain. Real-life problems\ninspire researchers to navigate and further improve data processing and\nalgorithmic approaches to achieve effective and computationally efficient\nmethods for imbalanced learning. In this paper, we have collected and reviewed\n258 peer-reviewed papers from archival journals and conference papers in an\nattempt to provide an in-depth review of various approaches in imbalanced\nlearning from technical and application perspectives. This work aims to provide\na structured review of methods used to address the problem of imbalanced data\nin various domains and create a general guideline for researchers in academia\nor industry who want to dive into the broad field of machine learning using\nlarge-scale imbalanced data.",
          "link": "http://arxiv.org/abs/2310.07917",
          "publishedOn": "2023-10-14T00:41:30.091Z",
          "wordCount": 644,
          "title": "A Review of Machine Learning Techniques in Imbalanced Data and Future Trends. (arXiv:2310.07917v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07858",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Kulshrestha_A/0/1/0/all/0/1\">Ankit Kulshrestha</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lykov_D/0/1/0/all/0/1\">Danylo Lykov</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Safro_I/0/1/0/all/0/1\">Ilya Safro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Alexeev_Y/0/1/0/all/0/1\">Yuri Alexeev</a>",
          "description": "The current era of quantum computing has yielded several algorithms that\npromise high computational efficiency. While the algorithms are sound in theory\nand can provide potentially exponential speedup, there is little guidance on\nhow to design proper quantum circuits to realize the appropriate unitary\ntransformation to be applied to the input quantum state. In this paper, we\npresent \\texttt{QArchSearch}, an AI based quantum architecture search package\nwith the \\texttt{QTensor} library as a backend that provides a principled and\nautomated approach to finding the best model given a task and input quantum\nstate. We show that the search package is able to efficiently scale the search\nto large quantum circuits and enables the exploration of more complex models\nfor different quantum applications. \\texttt{QArchSearch} runs at scale and high\nefficiency on high-performance computing systems using a two-level\nparallelization scheme on both CPUs and GPUs, which has been demonstrated on\nthe Polaris supercomputer.",
          "link": "http://arxiv.org/abs/2310.07858",
          "publishedOn": "2023-10-14T00:41:30.076Z",
          "wordCount": 660,
          "title": "QArchSearch: A Scalable Quantum Architecture Search Package. (arXiv:2310.07858v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Defazio_A/0/1/0/all/0/1\">Aaron Defazio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_H/0/1/0/all/0/1\">Harsh Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>",
          "description": "Learning rate schedules used in practice bear little resemblance to those\nrecommended by theory. We close much of this theory/practice gap, and as a\nconsequence are able to derive new problem-adaptive learning rate schedules.\nOur key technical contribution is a refined analysis of learning rate schedules\nfor a wide class of optimization algorithms (including SGD). In contrast to\nmost prior works that study the convergence of the average iterate, we study\nthe last iterate, which is what most people use in practice. When considering\nonly worst-case analysis, our theory predicts that the best choice is the\nlinear decay schedule: a popular choice in practice that sets the stepsize\nproportionally to $1 - t/T$, where $t$ is the current iteration and $T$ is the\ntotal number of steps. To go beyond this worst-case analysis, we use the\nobserved gradient norms to derive schedules refined for any particular task.\nThese refined schedules exhibit learning rate warm-up and rapid learning rate\nannealing near the end of training. Ours is the first systematic approach to\nautomatically yield both of these properties. We perform the most comprehensive\nevaluation of learning rate schedules to date, evaluating across 10 diverse\ndeep learning problems, a series of LLMs, and a suite of logistic regression\nproblems. We validate that overall, the linear-decay schedule matches or\noutperforms all commonly used default schedules including cosine annealing, and\nthat our schedule refinement method gives further improvements.",
          "link": "http://arxiv.org/abs/2310.07831",
          "publishedOn": "2023-10-14T00:41:30.045Z",
          "wordCount": 765,
          "title": "When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement. (arXiv:2310.07831v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Day_H/0/1/0/all/0/1\">Hannah Day</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahn_Y/0/1/0/all/0/1\">Yonatan Kahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_D/0/1/0/all/0/1\">Daniel A. Roberts</a>",
          "description": "Fully-connected deep neural networks with weights initialized from\nindependent Gaussian distributions can be tuned to criticality, which prevents\nthe exponential growth or decay of signals propagating through the network.\nHowever, such networks still exhibit fluctuations that grow linearly with the\ndepth of the network, which may impair the training of networks with width\ncomparable to depth. We show analytically that rectangular networks with tanh\nactivations and weights initialized from the ensemble of orthogonal matrices\nhave corresponding preactivation fluctuations which are independent of depth,\nto leading order in inverse width. Moreover, we demonstrate numerically that,\nat initialization, all correlators involving the neural tangent kernel (NTK)\nand its descendants at leading order in inverse width -- which govern the\nevolution of observables during training -- saturate at a depth of $\\sim 20$,\nrather than growing without bound as in the case of Gaussian initializations.\nWe speculate that this structure preserves finite-width feature learning while\nreducing overall noise, thus improving both generalization and training speed.\nWe provide some experimental justification by relating empirical measurements\nof the NTK to the superior performance of deep nonlinear orthogonal networks\ntrained under full-batch gradient descent on the MNIST and CIFAR-10\nclassification tasks.",
          "link": "http://arxiv.org/abs/2310.07765",
          "publishedOn": "2023-10-14T00:41:30.033Z",
          "wordCount": 734,
          "title": "Feature Learning and Generalization in Deep Networks with Orthogonal Weights. (arXiv:2310.07765v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madsen_A/0/1/0/all/0/1\">Andreas Madsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>",
          "description": "A common approach to explain NLP models, is to use importance measures that\nexpress which tokens are important for a prediction. Unfortunately, such\nexplanations are often wrong despite being persuasive. Therefore, it is\nessential to measure their faithfulness. One such metric is if tokens are truly\nimportant, then masking them should result in worse model performance. However,\ntoken masking introduces out-of-distribution issues and existing solutions are\ncomputationally expensive and employ proxy-models. Furthermore, other metrics\nare very limited in scope. In this work, we propose an inherently faithfulness\nmeasurable model that addresses these challenges. This is achieved by using a\nnovel fine-tuning method that incorporates masking, such that masking tokens\nbecome in-distribution by design. This differs from existing approaches, which\nare completely model-agnostic but are inapplicable in practice. We demonstrate\nthe generality of our approach by applying it to various tasks and validate it\nusing statistical in-distribution tests. Additionally, because masking is\nin-distribution, importance measures which themselves use masking become more\nfaithful, thus our model becomes more explainable.",
          "link": "http://arxiv.org/abs/2310.07819",
          "publishedOn": "2023-10-14T00:41:29.999Z",
          "wordCount": 651,
          "title": "Faithfulness Measurable Masked Language Models. (arXiv:2310.07819v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_P/0/1/0/all/0/1\">Philip Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thant_P/0/1/0/all/0/1\">Phue Thant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1\">Pratiksha Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antaliya_R/0/1/0/all/0/1\">Ruta Antaliya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1\">Jongwook Woo</a>",
          "description": "This paper discusses predictive performance and processes undertaken on\nflight pricing data utilizing r2(r-square) and RMSE that leverages a large\ndataset, originally from Expedia.com, consisting of approximately 20 million\nrecords or 4.68 gigabytes. The project aims to determine the best models usable\nin the real world to predict airline ticket fares for non-stop flights across\nthe US. Therefore, good generalization capability and optimized processing\ntimes are important measures for the model.\n\nWe will discover key business insights utilizing feature importance and\ndiscuss the process and tools used for our analysis. Four regression machine\nlearning algorithms were utilized: Random Forest, Gradient Boost Tree, Decision\nTree, and Factorization Machines utilizing Cross Validator and Training\nValidator functions for assessing performance and generalization capability.",
          "link": "http://arxiv.org/abs/2310.07787",
          "publishedOn": "2023-10-14T00:41:29.960Z",
          "wordCount": 662,
          "title": "Using Spark Machine Learning Models to Perform Predictive Analysis on Flight Ticket Pricing Data. (arXiv:2310.07787v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1\">Yi Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongzi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cresswell_J/0/1/0/all/0/1\">Jesse C. Cresswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Ga Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stein_G/0/1/0/all/0/1\">George Stein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiao Shi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaochen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Volkovs_M/0/1/0/all/0/1\">Maksims Volkovs</a>",
          "description": "Self-supervised representation learning~(SSRL) has advanced considerably by\nexploiting the transformation invariance assumption under artificially designed\ndata augmentations. While augmentation-based SSRL algorithms push the\nboundaries of performance in computer vision and natural language processing,\nthey are often not directly applicable to other data modalities, and can\nconflict with application-specific data augmentation constraints. This paper\npresents an SSRL approach that can be applied to any data modality and network\narchitecture because it does not rely on augmentations or masking.\nSpecifically, we show that high-quality data representations can be learned by\nreconstructing random data projections. We evaluate the proposed approach on a\nwide range of representation learning tasks that span diverse modalities and\nreal-world applications. We show that it outperforms multiple state-of-the-art\nSSRL baselines. Due to its wide applicability and strong empirical results, we\nargue that learning from randomness is a fruitful research direction worthy of\nattention and further study.",
          "link": "http://arxiv.org/abs/2310.07756",
          "publishedOn": "2023-10-14T00:41:29.946Z",
          "wordCount": 653,
          "title": "Self-supervised Representation Learning From Random Data Projectors. (arXiv:2310.07756v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mastromichalakis_S/0/1/0/all/0/1\">Stamatis Mastromichalakis</a>",
          "description": "Activation functions (AFs) are crucial components of deep neural networks\n(DNNs), having a significant impact on their performance. An activation\nfunction in a DNN is typically a smooth, nonlinear function that transforms an\ninput signal into an output signal for the subsequent layer. In this paper, we\npropose the Parametric Leaky Tanh (PLTanh), a novel hybrid activation function\ndesigned to combine the strengths of both the Tanh and Leaky ReLU (LReLU)\nactivation functions. PLTanh is differentiable at all points and addresses the\n'dying ReLU' problem by ensuring a non-zero gradient for negative inputs,\nconsistent with the behavior of LReLU. By integrating the unique advantages of\nthese two diverse activation functions, PLTanh facilitates the learning of more\nintricate nonlinear relationships within the network. This paper presents an\nempirical evaluation of PLTanh against established activation functions, namely\nReLU, LReLU, and ALReLU utilizing five diverse datasets.",
          "link": "http://arxiv.org/abs/2310.07720",
          "publishedOn": "2023-10-14T00:41:29.941Z",
          "wordCount": 661,
          "title": "Parametric Leaky Tanh: A New Hybrid Activation Function for Deep Learning. (arXiv:2310.07720v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hsuan-Kung Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_T/0/1/0/all/0/1\">Tsung-Chih Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting-Ru Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chun-Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jou-Min Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chun-Yi Lee</a>",
          "description": "The challenge of navigation in environments with dynamic objects continues to\nbe a central issue in the study of autonomous agents. While predictive methods\nhold promise, their reliance on precise state information makes them less\npractical for real-world implementation. This study presents visual forecasting\nas an innovative alternative. By introducing intuitive visual cues, this\napproach projects the future trajectories of dynamic objects to improve agent\nperception and enable anticipatory actions. Our research explores two distinct\nstrategies for conveying predictive information through visual forecasting: (1)\nsequences of bounding boxes, and (2) augmented paths. To validate the proposed\nvisual forecasting strategies, we initiate evaluations in simulated\nenvironments using the Unity engine and then extend these evaluations to\nreal-world scenarios to assess both practicality and effectiveness. The results\nconfirm the viability of visual forecasting as a promising solution for\nnavigation and obstacle avoidance in dynamic environments.",
          "link": "http://arxiv.org/abs/2310.07724",
          "publishedOn": "2023-10-14T00:41:29.893Z",
          "wordCount": 686,
          "title": "Visual Forecasting as a Mid-level Representation for Avoidance. (arXiv:2310.07724v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        }
      ]
    },
    {
      "title": "stat.ML updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/stat.ML",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2311.02043",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feldman_J/0/1/0/all/0/1\">Joseph Feldman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kowal_D/0/1/0/all/0/1\">Daniel Kowal</a>",
          "description": "Quantile regression is a powerful tool for inferring how covariates affect\nspecific percentiles of the response distribution. Existing methods either\nestimate conditional quantiles separately for each quantile of interest or\nestimate the entire conditional distribution using semi- or non-parametric\nmodels. The former often produce inadequate models for real data and do not\nshare information across quantiles, while the latter are characterized by\ncomplex and constrained models that can be difficult to interpret and\ncomputationally inefficient. Further, neither approach is well-suited for\nquantile-specific subset selection. Instead, we pose the fundamental problems\nof linear quantile estimation, uncertainty quantification, and subset selection\nfrom a Bayesian decision analysis perspective. For any Bayesian regression\nmodel, we derive optimal and interpretable linear estimates and uncertainty\nquantification for each model-based conditional quantile. Our approach\nintroduces a quantile-focused squared error loss, which enables efficient,\nclosed-form computing and maintains a close relationship with Wasserstein-based\ndensity estimation. In an extensive simulation study, our methods demonstrate\nsubstantial gains in quantile estimation accuracy, variable selection, and\ninference over frequentist and Bayesian competitors. We apply these tools to\nidentify the quantile-specific impacts of social and environmental stressors on\neducational outcomes for a large cohort of children in North Carolina.",
          "link": "http://arxiv.org/abs/2311.02043",
          "publishedOn": "2023-11-07T00:44:08.184Z",
          "wordCount": null,
          "title": "Bayesian Quantile Regression with Subset Selection: A Posterior Summarization Perspective. (arXiv:2311.02043v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.11657",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Alaluusua_K/0/1/0/all/0/1\">Kalle Alaluusua</a>, <a href=\"http://arxiv.org/find/math/1/au:+Avrachenkov_K/0/1/0/all/0/1\">Konstantin Avrachenkov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kumar_B/0/1/0/all/0/1\">B. R. Vinay Kumar</a>, <a href=\"http://arxiv.org/find/math/1/au:+Leskela_L/0/1/0/all/0/1\">Lasse Leskel&#xe4;</a>",
          "description": "We consider the community recovery problem on a multilayer variant of the\nhypergraph stochastic block model (HSBM). Each layer is associated with an\nindependent realization of a d-uniform HSBM on N vertices. Given the similarity\nmatrix containing the aggregated number of hyperedges incident to each pair of\nvertices, the goal is to obtain a partition of the N vertices into disjoint\ncommunities. In this work, we investigate a semidefinite programming (SDP)\napproach and obtain information-theoretic conditions on the model parameters\nthat guarantee exact recovery both in the assortative and the disassortative\ncases.",
          "link": "http://arxiv.org/abs/2301.11657",
          "publishedOn": "2023-11-07T00:44:08.073Z",
          "wordCount": null,
          "title": "Multilayer hypergraph clustering using the aggregate similarity matrix. (arXiv:2301.11657v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03609",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kang_T/0/1/0/all/0/1\">Taegyu Kang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1\">Sehwan Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sohn_J/0/1/0/all/0/1\">Jinwon Sohn</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Awan_J/0/1/0/all/0/1\">Jordan Awan</a>",
          "description": "This paper is the first to attempt differentially private (DP) topological\ndata analysis (TDA), producing near-optimal private persistence diagrams. We\nanalyze the sensitivity of persistence diagrams in terms of the bottleneck\ndistance, and we show that the commonly used \\v{C}ech complex has sensitivity\nthat does not decrease as the sample size $n$ increases. This makes it\nchallenging for the persistence diagrams of \\v{C}ech complexes to be\nprivatized. As an alternative, we show that the persistence diagram obtained by\nthe $L^1$-distance to measure (DTM) has sensitivity $O(1/n)$. Based on the\nsensitivity analysis, we propose using the exponential mechanism whose utility\nfunction is defined in terms of the bottleneck distance of the $L^1$-DTM\npersistence diagrams. We also derive upper and lower bounds of the accuracy of\nour privacy mechanism; the obtained bounds indicate that the privacy error of\nour mechanism is near-optimal. We demonstrate the performance of our privatized\npersistence diagrams through simulations as well as on a real dataset tracking\nhuman movement.",
          "link": "http://arxiv.org/abs/2305.03609",
          "publishedOn": "2023-11-07T00:44:08.072Z",
          "wordCount": null,
          "title": "Differentially Private Topological Data Analysis. (arXiv:2305.03609v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.00265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Banghua Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Mingyu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobson_P/0/1/0/all/0/1\">Philip Jacobson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Ming Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1\">Wei Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jiantao Jiao</a>",
          "description": "Self-training is an important technique for solving semi-supervised learning\nproblems. It leverages unlabeled data by generating pseudo-labels and combining\nthem with a limited labeled dataset for training. The effectiveness of\nself-training heavily relies on the accuracy of these pseudo-labels. In this\npaper, we introduce doubly robust self-training, a novel semi-supervised\nalgorithm that provably balances between two extremes. When the pseudo-labels\nare entirely incorrect, our method reduces to a training process solely using\nlabeled data. Conversely, when the pseudo-labels are completely accurate, our\nmethod transforms into a training process utilizing all pseudo-labeled data and\nlabeled data, thus increasing the effective sample size. Through empirical\nevaluations on both the ImageNet dataset for image classification and the\nnuScenes autonomous driving dataset for 3D object detection, we demonstrate the\nsuperiority of the doubly robust loss over the standard self-training baseline.",
          "link": "http://arxiv.org/abs/2306.00265",
          "publishedOn": "2023-11-07T00:44:08.071Z",
          "wordCount": null,
          "title": "Doubly Robust Self-Training. (arXiv:2306.00265v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.00424",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kone_C/0/1/0/all/0/1\">Cyrille Kone</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaufmann_E/0/1/0/all/0/1\">Emilie Kaufmann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Richert_L/0/1/0/all/0/1\">Laura Richert</a>",
          "description": "In this paper we revisit the fixed-confidence identification of the Pareto\noptimal set in a multi-objective multi-armed bandit model. As the sample\ncomplexity to identify the exact Pareto set can be very large, a relaxation\nallowing to output some additional near-optimal arms has been studied. In this\nwork we also tackle alternative relaxations that allow instead to identify a\nrelevant subset of the Pareto set. Notably, we propose a single sampling\nstrategy, called Adaptive Pareto Exploration, that can be used in conjunction\nwith different stopping rules to take into account different relaxations of the\nPareto Set Identification problem. We analyze the sample complexity of these\ndifferent combinations, quantifying in particular the reduction in sample\ncomplexity that occurs when one seeks to identify at most $k$ Pareto optimal\narms. We showcase the good practical performance of Adaptive Pareto Exploration\non a real-world scenario, in which we adaptively explore several vaccination\nstrategies against Covid-19 in order to find the optimal ones when multiple\nimmunogenicity criteria are taken into account.",
          "link": "http://arxiv.org/abs/2307.00424",
          "publishedOn": "2023-11-07T00:44:08.070Z",
          "wordCount": null,
          "title": "Adaptive Algorithms for Relaxed Pareto Set Identification. (arXiv:2307.00424v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04532",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chaudhry_H/0/1/0/all/0/1\">Hamza Tahir Chaudhry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zavatone_Veth_J/0/1/0/all/0/1\">Jacob A. Zavatone-Veth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krotov_D/0/1/0/all/0/1\">Dmitry Krotov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "Sequence memory is an essential attribute of natural and artificial\nintelligence that enables agents to encode, store, and retrieve complex\nsequences of stimuli and actions. Computational models of sequence memory have\nbeen proposed where recurrent Hopfield-like neural networks are trained with\ntemporally asymmetric Hebbian rules. However, these networks suffer from\nlimited sequence capacity (maximal length of the stored sequence) due to\ninterference between the memories. Inspired by recent work on Dense Associative\nMemories, we expand the sequence capacity of these models by introducing a\nnonlinear interaction term, enhancing separation between the patterns. We\nderive novel scaling laws for sequence capacity with respect to network size,\nsignificantly outperforming existing scaling laws for models based on\ntraditional Hopfield networks, and verify these theoretical results with\nnumerical simulation. Moreover, we introduce a generalized pseudoinverse rule\nto recall sequences of highly correlated patterns. Finally, we extend this\nmodel to store sequences with variable timing between states' transitions and\ndescribe a biologically-plausible implementation, with connections to motor\nneuroscience.",
          "link": "http://arxiv.org/abs/2306.04532",
          "publishedOn": "2023-11-07T00:44:08.070Z",
          "wordCount": null,
          "title": "Long Sequence Hopfield Memory. (arXiv:2306.04532v2 [cs.NE] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.04750",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_A/0/1/0/all/0/1\">Aditya Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rauber_P/0/1/0/all/0/1\">Paulo Rauber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conserva_M/0/1/0/all/0/1\">Michelangelo Conserva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>",
          "description": "An agent in a nonstationary contextual bandit problem should balance between\nexploration and the exploitation of (periodic or structured) patterns present\nin its previous experiences. Handcrafting an appropriate historical context is\nan attractive alternative to transform a nonstationary problem into a\nstationary problem that can be solved efficiently. However, even a carefully\ndesigned historical context may introduce spurious relationships or lack a\nconvenient representation of crucial information. In order to address these\nissues, we propose an approach that learns to represent the relevant context\nfor a decision based solely on the raw history of interactions between the\nagent and the environment. This approach relies on a combination of features\nextracted by recurrent neural networks with a contextual linear bandit\nalgorithm based on posterior sampling. Our experiments on a diverse selection\nof contextual and noncontextual nonstationary problems show that our recurrent\napproach consistently outperforms its feedforward counterpart, which requires\nhandcrafted historical contexts, while being more widely applicable than\nconventional nonstationary bandit algorithms. Although it is very difficult to\nprovide theoretical performance guarantees for our new approach, we also prove\na novel regret bound for linear posterior sampling with measurement error that\nmay serve as a foundation for future theoretical work.",
          "link": "http://arxiv.org/abs/2007.04750",
          "publishedOn": "2023-11-07T00:44:08.057Z",
          "wordCount": null,
          "title": "Recurrent Neural-Linear Posterior Sampling for Nonstationary Contextual Bandits. (arXiv:2007.04750v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.05062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lindner_D/0/1/0/all/0/1\">David Lindner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kramar_J/0/1/0/all/0/1\">J&#xe1;nos Kram&#xe1;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1\">Sebastian Farquhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahtz_M/0/1/0/all/0/1\">Matthew Rahtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McGrath_T/0/1/0/all/0/1\">Thomas McGrath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikulik_V/0/1/0/all/0/1\">Vladimir Mikulik</a>",
          "description": "We show how to \"compile\" human-readable programs into standard decoder-only\ntransformer models. Our compiler, Tracr, generates models with known structure.\nThis structure can be used to design experiments. For example, we use it to\nstudy \"superposition\" in transformers that execute multi-step algorithms.\nAdditionally, the known structure of Tracr-compiled models can serve as\nground-truth for evaluating interpretability methods. Commonly, because the\n\"programs\" learned by transformers are unknown it is unclear whether an\ninterpretation succeeded. We demonstrate our approach by implementing and\nexamining programs including computing token frequencies, sorting, and\nparenthesis checking. We provide an open-source implementation of Tracr at\nhttps://github.com/google-deepmind/tracr.",
          "link": "http://arxiv.org/abs/2301.05062",
          "publishedOn": "2023-11-07T00:44:08.051Z",
          "wordCount": null,
          "title": "Tracr: Compiled Transformers as a Laboratory for Interpretability. (arXiv:2301.05062v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01968",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lee_D/0/1/0/all/0/1\">Daesoo Lee</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ovanger_O/0/1/0/all/0/1\">Oscar Ovanger</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Eidsvik_J/0/1/0/all/0/1\">Jo Eidsvik</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Aune_E/0/1/0/all/0/1\">Erlend Aune</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Skauvold_J/0/1/0/all/0/1\">Jacob Skauvold</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hauge_R/0/1/0/all/0/1\">Ragnar Hauge</a>",
          "description": "Creating accurate and geologically realistic reservoir facies based on\nlimited measurements is crucial for field development and reservoir management,\nespecially in the oil and gas sector. Traditional two-point geostatistics,\nwhile foundational, often struggle to capture complex geological patterns.\nMulti-point statistics offers more flexibility, but comes with its own\nchallenges. With the rise of Generative Adversarial Networks (GANs) and their\nsuccess in various fields, there has been a shift towards using them for facies\ngeneration. However, recent advances in the computer vision domain have shown\nthe superiority of diffusion models over GANs. Motivated by this, a novel\nLatent Diffusion Model is proposed, which is specifically designed for\nconditional generation of reservoir facies. The proposed model produces\nhigh-fidelity facies realizations that rigorously preserve conditioning data.\nIt significantly outperforms a GAN-based alternative.",
          "link": "http://arxiv.org/abs/2311.01968",
          "publishedOn": "2023-11-07T00:44:08.037Z",
          "wordCount": null,
          "title": "Latent Diffusion Model for Conditional Reservoir Facies Generation. (arXiv:2311.01968v1 [physics.geo-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.01264",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_H/0/1/0/all/0/1\">Haochuan Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Qian_J/0/1/0/all/0/1\">Jian Qian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tian_Y/0/1/0/all/0/1\">Yi Tian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rakhlin_A/0/1/0/all/0/1\">Alexander Rakhlin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jadbabaie_A/0/1/0/all/0/1\">Ali Jadbabaie</a>",
          "description": "Classical analysis of convex and non-convex optimization methods often\nrequires the Lipshitzness of the gradient, which limits the analysis to\nfunctions bounded by quadratics. Recent work relaxed this requirement to a\nnon-uniform smoothness condition with the Hessian norm bounded by an affine\nfunction of the gradient norm, and proved convergence in the non-convex setting\nvia gradient clipping, assuming bounded noise. In this paper, we further\ngeneralize this non-uniform smoothness condition and develop a simple, yet\npowerful analysis technique that bounds the gradients along the trajectory,\nthereby leading to stronger results for both convex and non-convex optimization\nproblems. In particular, we obtain the classical convergence rates for\n(stochastic) gradient descent and Nesterov's accelerated gradient method in the\nconvex and/or non-convex setting under this general smoothness condition. The\nnew analysis approach does not require gradient clipping and allows\nheavy-tailed noise with bounded variance in the stochastic setting.",
          "link": "http://arxiv.org/abs/2306.01264",
          "publishedOn": "2023-11-07T00:44:08.037Z",
          "wordCount": null,
          "title": "Convex and Non-convex Optimization Under Generalized Smoothness. (arXiv:2306.01264v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.02899",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jiang_Y/0/1/0/all/0/1\">Yibo Jiang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aragam_B/0/1/0/all/0/1\">Bryon Aragam</a>",
          "description": "We establish conditions under which latent causal graphs are\nnonparametrically identifiable and can be reconstructed from unknown\ninterventions in the latent space. Our primary focus is the identification of\nthe latent structure in measurement models without parametric assumptions such\nas linearity or Gaussianity. Moreover, we do not assume the number of hidden\nvariables is known, and we show that at most one unknown intervention per\nhidden variable is needed. This extends a recent line of work on learning\ncausal representations from observations and interventions. The proofs are\nconstructive and introduce two new graphical concepts -- imaginary subsets and\nisolated edges -- that may be useful in their own right. As a matter of\nindependent interest, the proofs also involve a novel characterization of the\nlimits of edge orientations within the equivalence class of DAGs induced by\nunknown interventions. These are the first results to characterize the\nconditions under which causal representations are identifiable without making\nany parametric assumptions in a general setting with unknown interventions and\nwithout faithfulness.",
          "link": "http://arxiv.org/abs/2306.02899",
          "publishedOn": "2023-11-07T00:44:08.037Z",
          "wordCount": null,
          "title": "Learning nonparametric latent causal graphs with unknown interventions. (arXiv:2306.02899v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lopardo_G/0/1/0/all/0/1\">Gianluigi Lopardo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precioso_F/0/1/0/all/0/1\">Frederic Precioso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garreau_D/0/1/0/all/0/1\">Damien Garreau</a>",
          "description": "Interpretability is essential for machine learning models to be trusted and\ndeployed in critical domains. However, existing methods for interpreting text\nmodels are often complex, lack solid mathematical foundations, and their\nperformance is not guaranteed. In this paper, we propose FRED (Faithful and\nRobust Explainer for textual Documents), a novel method for interpreting\npredictions over text. FRED identifies key words in a document that\nsignificantly impact the prediction when removed. We establish the reliability\nof FRED through formal definitions and theoretical analyses on interpretable\nclassifiers. Additionally, our empirical evaluation against state-of-the-art\nmethods demonstrates the effectiveness of FRED in providing insights into text\nmodels.",
          "link": "http://arxiv.org/abs/2311.01605",
          "publishedOn": "2023-11-07T00:44:08.035Z",
          "wordCount": null,
          "title": "Faithful and Robust Local Interpretability for Textual Predictions. (arXiv:2311.01605v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.02108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_R/0/1/0/all/0/1\">Ruohan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1\">Emma Brunskill</a>",
          "description": "In many applications, e.g. in healthcare and e-commerce, the goal of a\ncontextual bandit may be to learn an optimal treatment assignment policy at the\nend of the experiment. That is, to minimize simple regret. However, this\nobjective remains understudied. We propose a new family of computationally\nefficient bandit algorithms for the stochastic contextual bandit setting, where\na tuning parameter determines the weight placed on cumulative regret\nminimization (where we establish near-optimal minimax guarantees) versus simple\nregret minimization (where we establish state-of-the-art guarantees). Our\nalgorithms work with any function class, are robust to model misspecification,\nand can be used in continuous arm settings. This flexibility comes from\nconstructing and relying on \"conformal arm sets\" (CASs). CASs provide a set of\narms for every context, encompassing the context-specific optimal arm with a\ncertain probability across the context distribution. Our positive results on\nsimple and cumulative regret guarantees are contrasted with a negative result,\nwhich shows that no algorithm can achieve instance-dependent simple regret\nguarantees while simultaneously achieving minimax optimal cumulative regret\nguarantees.",
          "link": "http://arxiv.org/abs/2307.02108",
          "publishedOn": "2023-11-07T00:44:08.035Z",
          "wordCount": null,
          "title": "Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization. (arXiv:2307.02108v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01537",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mitsuzawa_K/0/1/0/all/0/1\">Kensuke Mitsuzawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanagawa_M/0/1/0/all/0/1\">Motonobu Kanagawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bortoli_S/0/1/0/all/0/1\">Stefano Bortoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Grossi_M/0/1/0/all/0/1\">Margherita Grossi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papotti_P/0/1/0/all/0/1\">Paolo Papotti</a>",
          "description": "Two-sample testing decides whether two datasets are generated from the same\ndistribution. This paper studies variable selection for two-sample testing, the\ntask being to identify the variables (or dimensions) responsible for the\ndiscrepancies between the two distributions. This task is relevant to many\nproblems of pattern analysis and machine learning, such as dataset shift\nadaptation, causal inference and model validation. Our approach is based on a\ntwo-sample test based on the Maximum Mean Discrepancy (MMD). We optimise the\nAutomatic Relevance Detection (ARD) weights defined for individual variables to\nmaximise the power of the MMD-based test. For this optimisation, we introduce\nsparse regularisation and propose two methods for dealing with the issue of\nselecting an appropriate regularisation parameter. One method determines the\nregularisation parameter in a data-driven way, and the other aggregates the\nresults of different regularisation parameters. We confirm the validity of the\nproposed methods by systematic comparisons with baseline methods, and\ndemonstrate their usefulness in exploratory analysis of high-dimensional\ntraffic simulation data. Preliminary theoretical analyses are also provided,\nincluding a rigorous definition of variable selection for two-sample testing.",
          "link": "http://arxiv.org/abs/2311.01537",
          "publishedOn": "2023-11-07T00:44:08.033Z",
          "wordCount": null,
          "title": "Variable Selection in Maximum Mean Discrepancy for Interpretable Distribution Comparison. (arXiv:2311.01537v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01050",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nusken_N/0/1/0/all/0/1\">Nikolas N&#xfc;sken</a>",
          "description": "This paper explores the connections between optimal transport and variational\ninference, with a focus on forward and reverse time stochastic differential\nequations and Girsanov transformations.We present a principled and systematic\nframework for sampling and generative modelling centred around divergences on\npath space. Our work culminates in the development of a novel score-based\nannealed flow technique (with connections to Jarzynski and Crooks identities\nfrom statistical physics) and a regularised iterative proportional fitting\n(IPF)-type objective, departing from the sequential nature of standard IPF.\nThrough a series of generative modelling examples and a double-well-based rare\nevent task, we showcase the potential of the proposed methods.",
          "link": "http://arxiv.org/abs/2307.01050",
          "publishedOn": "2023-11-07T00:44:08.032Z",
          "wordCount": null,
          "title": "Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\\\"odinger Bridges. (arXiv:2307.01050v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.08627",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhu_Q/0/1/0/all/0/1\">Qiuyun Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Atchade_Y/0/1/0/all/0/1\">Yves Atchade</a>",
          "description": "Canonical correlation analysis (CCA) is a popular statistical technique for\nexploring relationships between datasets. In recent years, the estimation of\nsparse canonical vectors has emerged as an important but challenging variant of\nthe CCA problem, with widespread applications. Unfortunately, existing\nrate-optimal estimators for sparse canonical vectors have high computational\ncost. We propose a quasi-Bayesian estimation procedure that not only achieves\nthe minimax estimation rate, but also is easy to compute by Markov Chain Monte\nCarlo (MCMC). The method builds on Tan et al. (2018) and uses a re-scaled\nRayleigh quotient function as the quasi-log-likelihood. However, unlike Tan et\nal. (2018), we adopt a Bayesian framework that combines this\nquasi-log-likelihood with a spike-and-slab prior to regularize the inference\nand promote sparsity. We investigate the empirical behavior of the proposed\nmethod on both continuous and truncated data, and we demonstrate that it\noutperforms several state-of-the-art methods. As an application, we use the\nproposed methodology to maximally correlate clinical variables and proteomic\ndata for better understanding the Covid-19 disease.",
          "link": "http://arxiv.org/abs/2010.08627",
          "publishedOn": "2023-11-07T00:44:07.801Z",
          "wordCount": null,
          "title": "Minimax Quasi-Bayesian estimation in sparse canonical correlation analysis via a Rayleigh quotient function. (arXiv:2010.08627v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.16578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Ningyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenhao Li</a>",
          "description": "We consider a decision maker allocating one unit of renewable and divisible\nresource in each period on a number of arms. The arms have unknown and random\nrewards whose means are proportional to the allocated resource and whose\nvariances are proportional to an order $b$ of the allocated resource. In\nparticular, if the decision maker allocates resource $A_i$ to arm $i$ in a\nperiod, then the reward $Y_i$ is$Y_i(A_i)=A_i \\mu_i+A_i^b \\xi_{i}$, where\n$\\mu_i$ is the unknown mean and the noise $\\xi_{i}$ is independent and\nsub-Gaussian. When the order $b$ ranges from 0 to 1, the framework smoothly\nbridges the standard stochastic multi-armed bandit and online learning with\nfull feedback. We design two algorithms that attain the optimal gap-dependent\nand gap-independent regret bounds for $b\\in [0,1]$, and demonstrate a phase\ntransition at $b=1/2$. The theoretical results hinge on a novel concentration\ninequality we have developed that bounds a linear combination of sub-Gaussian\nrandom variables whose weights are fractional, adapted to the filtration, and\nmonotonic.",
          "link": "http://arxiv.org/abs/2306.16578",
          "publishedOn": "2023-11-07T00:44:07.748Z",
          "wordCount": null,
          "title": "Allocating Divisible Resources on Arms with Unknown and Random Rewards. (arXiv:2306.16578v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.03374",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadrtdinov_I/0/1/0/all/0/1\">Ildus Sadrtdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pozdeev_D/0/1/0/all/0/1\">Dmitrii Pozdeev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lobacheva_E/0/1/0/all/0/1\">Ekaterina Lobacheva</a>",
          "description": "Transfer learning and ensembling are two popular techniques for improving the\nperformance and robustness of neural networks. Due to the high cost of\npre-training, ensembles of models fine-tuned from a single pre-trained\ncheckpoint are often used in practice. Such models end up in the same basin of\nthe loss landscape, which we call the pre-train basin, and thus have limited\ndiversity. In this work, we show that ensembles trained from a single\npre-trained checkpoint may be improved by better exploring the pre-train basin,\nhowever, leaving the basin results in losing the benefits of transfer learning\nand in degradation of the ensemble quality. Based on the analysis of existing\nexploration methods, we propose a more effective modification of the Snapshot\nEnsembles (SSE) for transfer learning setup, StarSSE, which results in stronger\nensembles and uniform model soups.",
          "link": "http://arxiv.org/abs/2303.03374",
          "publishedOn": "2023-11-07T00:44:07.746Z",
          "wordCount": null,
          "title": "To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning. (arXiv:2303.03374v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.05812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shumaylov_Z/0/1/0/all/0/1\">Zakhar Shumaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budd_J/0/1/0/all/0/1\">Jeremy Budd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhadip Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola-Bibiane Sch&#xf6;nlieb</a>",
          "description": "An emerging new paradigm for solving inverse problems is via the use of deep\nlearning to learn a regularizer from data. This leads to high-quality results,\nbut often at the cost of provable guarantees. In this work, we show how\nwell-posedness and convergent regularization arises within the convex-nonconvex\n(CNC) framework for inverse problems. We introduce a novel input weakly convex\nneural network (IWCNN) construction to adapt the method of learned adversarial\nregularization to the CNC framework. Empirically we show that our method\novercomes numerical issues of previous adversarial methods.",
          "link": "http://arxiv.org/abs/2310.05812",
          "publishedOn": "2023-11-07T00:44:07.745Z",
          "wordCount": null,
          "title": "Provably Convergent Data-Driven Convex-Nonconvex Regularization. (arXiv:2310.05812v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.08473",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bonavita_M/0/1/0/all/0/1\">Massimo Bonavita</a>",
          "description": "As in many other areas of engineering and applied science, Machine Learning\n(ML) is having a profound impact in the domain of Weather and Climate\nPrediction. A very recent development in this area has been the emergence of\nfully data-driven ML prediction models which routinely claim superior\nperformance to that of traditional physics-based models. In this work, we\nexamine some aspects of the forecasts produced by an exemplar of the current\ngeneration of ML models, Pangu-Weather, with a focus on the fidelity and\nphysical consistency of those forecasts and how these characteristics relate to\nperceived forecast performance. The main conclusion is that Pangu-Weather\nforecasts, and possibly those of similar ML models, do not have the fidelity\nand physical consistency of physics-based models and their advantage in\naccuracy on traditional deterministic metrics of forecast skill can be at least\npartly attributed to these peculiarities. Balancing forecast skill and physical\nconsistency of ML-driven predictions will be an important consideration for\nfuture ML models. However, and similarly to other modern post-processing\ntechnologies, the current ML models appear to be already able to add value to\nstandard NWP output for specific forecast applications and combined with their\nextremely low computational cost during deployment, are set to provide an\nadditional, useful source of forecast information. .",
          "link": "http://arxiv.org/abs/2309.08473",
          "publishedOn": "2023-11-07T00:44:07.744Z",
          "wordCount": null,
          "title": "On some limitations of data-driven weather forecasting models. (arXiv:2309.08473v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.11024",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yifan Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daniel Zhengyu Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_J/0/1/0/all/0/1\">Jiaoyang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reich_S/0/1/0/all/0/1\">Sebastian Reich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew M. Stuart</a>",
          "description": "Sampling a probability distribution with an unknown normalization constant is\na fundamental problem in computational science and engineering. This task may\nbe cast as an optimization problem over all probability measures, and an\ninitial distribution can be evolved to the desired minimizer dynamically via\ngradient flows. Mean-field models, whose law is governed by the gradient flow\nin the space of probability measures, may also be identified; particle\napproximations of these mean-field models form the basis of algorithms. The\ngradient flow approach is also the basis of algorithms for variational\ninference, in which the optimization is performed over a parameterized family\nof probability distributions such as Gaussians, and the underlying gradient\nflow is restricted to the parameterized family.\n\nBy choosing different energy functionals and metrics for the gradient flow,\ndifferent algorithms with different convergence properties arise. In this\npaper, we concentrate on the Kullback-Leibler divergence after showing that, up\nto scaling, it has the unique property that the gradient flows resulting from\nthis choice of energy do not depend on the normalization constant. For the\nmetrics, we focus on variants of the Fisher-Rao, Wasserstein, and Stein\nmetrics; we introduce the affine invariance property for gradient flows, and\ntheir corresponding mean-field models, determine whether a given metric leads\nto affine invariance, and modify it to make it affine invariant if it does not.\nWe study the resulting gradient flows in both probability density space and\nGaussian space. The flow in the Gaussian space may be understood as a Gaussian\napproximation of the flow. We demonstrate that the Gaussian approximation based\non the metric and through moment closure coincide, establish connections\nbetween them, and study their long-time convergence properties showing the\nadvantages of affine invariance.",
          "link": "http://arxiv.org/abs/2302.11024",
          "publishedOn": "2023-11-07T00:44:07.743Z",
          "wordCount": null,
          "title": "Gradient Flows for Sampling: Mean-Field Models, Gaussian Approximations and Affine Invariance. (arXiv:2302.11024v6 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.18860",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tew_S/0/1/0/all/0/1\">Shu Yu Tew</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Boley_M/0/1/0/all/0/1\">Mario Boley</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schmidt_D/0/1/0/all/0/1\">Daniel F. Schmidt</a>",
          "description": "We present a novel method for tuning the regularization hyper-parameter,\n$\\lambda$, of a ridge regression that is faster to compute than leave-one-out\ncross-validation (LOOCV) while yielding estimates of the regression parameters\nof equal, or particularly in the setting of sparse covariates, superior quality\nto those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from\nmultiple and bad local minima for finite $n$ and thus requires the\nspecification of a set of candidate $\\lambda$, which can fail to provide good\nsolutions. In contrast, we show that the proposed method is guaranteed to find\na unique optimal solution for large enough $n$, under relatively mild\nconditions, without requiring the specification of any difficult to determine\nhyper-parameters. This is based on a Bayesian formulation of ridge regression\nthat we prove to have a unimodal posterior for large enough $n$, allowing for\nboth the optimal $\\lambda$ and the regression coefficients to be jointly\nlearned within an iterative expectation maximization (EM) procedure.\nImportantly, we show that by utilizing an appropriate preprocessing step, a\nsingle iteration of the main EM loop can be implemented in $O(\\min(n, p))$\noperations, for input data with $n$ rows and $p$ columns. In contrast,\nevaluating a single value of $\\lambda$ using fast LOOCV costs $O(n \\min(n, p))$\noperations when using the same preprocessing. This advantage amounts to an\nasymptotic improvement of a factor of $l$ for $l$ candidate values for\n$\\lambda$ (in the regime $q, p \\in O(\\sqrt{n})$ where $q$ is the number of\nregression targets).",
          "link": "http://arxiv.org/abs/2310.18860",
          "publishedOn": "2023-11-07T00:44:07.742Z",
          "wordCount": null,
          "title": "Bayes beats Cross Validation: Efficient and Accurate Ridge Regression via Expectation Maximization. (arXiv:2310.18860v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.03028",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sevilla_Salcedo_C/0/1/0/all/0/1\">Carlos Sevilla-Salcedo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gallardo_Antolin_A/0/1/0/all/0/1\">Ascensi&#xf3;n Gallardo-Antol&#xed;n</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gomez_Verdejo_V/0/1/0/all/0/1\">Vanessa G&#xf3;mez-Verdejo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Parrado_Hernandez_E/0/1/0/all/0/1\">Emilio Parrado-Hern&#xe1;ndez</a>",
          "description": "This paper introduces a novel approach for multi-task regression that\nconnects Kernel Machines (KMs) and Extreme Learning Machines (ELMs) through the\nexploitation of the Random Fourier Features (RFFs) approximation of the RBF\nkernel. In this sense, one of the contributions of this paper shows that for\nthe proposed models, the KM and the ELM formulations can be regarded as two\nsides of the same coin. These proposed models, termed RFF-BLR, stand on a\nBayesian framework that simultaneously addresses two main design goals. On the\none hand, it fits multitask regressors based on KMs endowed with RBF kernels.\nOn the other hand, it enables the introduction of a common-across-tasks prior\nthat promotes multioutput sparsity in the ELM view. This Bayesian approach\nfacilitates the simultaneous consideration of both the KM and ELM perspectives\nenabling (i) the optimisation of the RBF kernel parameter $\\gamma$ within a\nprobabilistic framework, (ii) the optimisation of the model complexity, and\n(iii) an efficient transfer of knowledge across tasks. The experimental results\nshow that this framework can lead to significant performance improvements\ncompared to the state-of-the-art methods in multitask nonlinear regression.",
          "link": "http://arxiv.org/abs/2209.03028",
          "publishedOn": "2023-11-07T00:44:07.411Z",
          "wordCount": null,
          "title": "Bayesian learning of feature spaces for multitasks problems. (arXiv:2209.03028v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.09136",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Atsidakou_A/0/1/0/all/0/1\">Alexia Atsidakou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katariya_S/0/1/0/all/0/1\">Sumeet Katariya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caramanis_C/0/1/0/all/0/1\">Constantine Caramanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanghavi_S/0/1/0/all/0/1\">Sujay Sanghavi</a>",
          "description": "We derive the first finite-time logarithmic Bayes regret upper bounds for\nBayesian bandits. In Gaussian bandits, we obtain $O(c_\\Delta \\log n)$ and\n$O(c_h \\log^2 n)$ bounds for an upper confidence bound algorithm, where $c_h$\nand $c_\\Delta$ are constants depending on the prior distribution and the gaps\nof random bandit instances sampled from it, respectively. The latter bound\nasymptotically matches the lower bound of Lai (1987). Our proofs are a major\ntechnical departure from prior works, while being simple and general. To show\nthe generality of our techniques, we apply them to linear bandits. Our results\nprovide insights on the value of prior in the Bayesian setting, both in the\nobjective and as a side information given to the learner. They significantly\nimprove upon existing $\\tilde{O}(\\sqrt{n})$ bounds, which have become standard\nin the literature despite the existing lower bounds.",
          "link": "http://arxiv.org/abs/2306.09136",
          "publishedOn": "2023-11-07T00:44:06.796Z",
          "wordCount": null,
          "title": "Finite-Time Logarithmic Bayes Regret Upper Bounds. (arXiv:2306.09136v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Puheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huishuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>",
          "description": "Diffusion models are a class of generative models that serve to establish a\nstochastic transport map between an empirically observed, yet unknown, target\ndistribution and a known prior. Despite their remarkable success in real-world\napplications, a theoretical understanding of their generalization capabilities\nremains underdeveloped. This work embarks on a comprehensive theoretical\nexploration of the generalization attributes of diffusion models. We establish\ntheoretical estimates of the generalization gap that evolves in tandem with the\ntraining dynamics of score-based diffusion models, suggesting a polynomially\nsmall generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$\nand the model capacity $m$, evading the curse of dimensionality (i.e., not\nexponentially large in the data dimension) when early-stopped. Furthermore, we\nextend our quantitative analysis to a data-dependent scenario, wherein target\ndistributions are portrayed as a succession of densities with progressively\nincreasing distances between modes. This precisely elucidates the adverse\neffect of \"modes shift\" in ground truths on the model generalization. Moreover,\nthese estimates are not solely theoretical constructs but have also been\nconfirmed through numerical simulations. Our findings contribute to the\nrigorous understanding of diffusion models' generalization properties and\nprovide insights that may guide practical applications.",
          "link": "http://arxiv.org/abs/2311.01797",
          "publishedOn": "2023-11-07T00:44:05.710Z",
          "wordCount": 699,
          "title": "On the Generalization Properties of Diffusion Models. (arXiv:2311.01797v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01762",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Allerbo_O/0/1/0/all/0/1\">Oskar Allerbo</a>",
          "description": "Kernel ridge regression, KRR, is a generalization of linear ridge regression\nthat is non-linear in the data, but linear in the parameters. The solution can\nbe obtained either as a closed-form solution, which includes a matrix\ninversion, or iteratively through gradient descent. Using the iterative\napproach opens up for changing the kernel during training, something that is\ninvestigated in this paper. We theoretically address the effects this has on\nmodel complexity and generalization. Based on our findings, we propose an\nupdate scheme for the bandwidth of translational-invariant kernels, where we\nlet the bandwidth decrease to zero during training, thus circumventing the need\nfor hyper-parameter selection. We demonstrate on real and synthetic data how\ndecreasing the bandwidth during training outperforms using a constant\nbandwidth, selected by cross-validation and marginal likelihood maximization.\nWe also show theoretically and empirically that using a decreasing bandwidth,\nwe are able to achieve both zero training error in combination with good\ngeneralization, and a double descent behavior, phenomena that do not occur for\nKRR with constant bandwidth but are known to appear for neural networks.",
          "link": "http://arxiv.org/abs/2311.01762",
          "publishedOn": "2023-11-07T00:44:05.683Z",
          "wordCount": 713,
          "title": "Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel. (arXiv:2311.01762v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.02019",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Huggins_J/0/1/0/all/0/1\">Jonathan H. Huggins</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Miller_J/0/1/0/all/0/1\">Jeffrey W. Miller</a>",
          "description": "Under model misspecification, it is known that Bayesian posteriors often do\nnot properly quantify uncertainty about true or pseudo-true parameters. Even\nmore fundamentally, misspecification leads to a lack of reproducibility in the\nsense that the same model will yield contradictory posteriors on independent\ndata sets from the true distribution. To define a criterion for reproducible\nuncertainty quantification under misspecification, we consider the probability\nthat two confidence sets constructed from independent data sets have nonempty\noverlap, and we establish a lower bound on this overlap probability that holds\nfor any valid confidence sets. We prove that credible sets from the standard\nposterior can strongly violate this bound, particularly in high-dimensional\nsettings (i.e., with dimension increasing with sample size), indicating that it\nis not internally coherent under misspecification. To improve reproducibility\nin an easy-to-use and widely applicable way, we propose to apply bagging to the\nBayesian posterior (\"BayesBag\"'); that is, to use the average of posterior\ndistributions conditioned on bootstrapped datasets. We motivate BayesBag from\nfirst principles based on Jeffrey conditionalization and show that the bagged\nposterior typically satisfies the overlap lower bound. Further, we prove a\nBernstein--Von Mises theorem for the bagged posterior, establishing its\nasymptotic normal distribution. We demonstrate the benefits of BayesBag via\nsimulation experiments and an application to crime rate prediction.",
          "link": "http://arxiv.org/abs/2311.02019",
          "publishedOn": "2023-11-07T00:44:05.675Z",
          "wordCount": 720,
          "title": "Reproducible Parameter Inference Using Bagged Posteriors. (arXiv:2311.02019v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01709",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yuhang Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_J/0/1/0/all/0/1\">Jinghai He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_Z/0/1/0/all/0/1\">Zeyu Zheng</a>",
          "description": "Utilizing covariate information has been a powerful approach to improve the\nefficiency and accuracy for causal inference, which support massive amount of\nrandomized experiments run on data-driven enterprises. However, state-of-art\napproaches can become practically unreliable when the dimension of covariate\nincreases to just 50, whereas experiments on large platforms can observe even\nhigher dimension of covariate. We propose a machine-learning-assisted covariate\nrepresentation approach that can effectively make use of historical experiment\nor observational data that are run on the same platform to understand which\nlower dimensions can effectively represent the higher-dimensional covariate. We\nthen propose design and estimation methods with the covariate representation.\nWe prove statistically reliability and performance guarantees for the proposed\nmethods. The empirical performance is demonstrated using numerical experiments.",
          "link": "http://arxiv.org/abs/2311.01709",
          "publishedOn": "2023-11-07T00:44:05.668Z",
          "wordCount": 610,
          "title": "Causal inference with Machine Learning-Based Covariate Representation. (arXiv:2311.01709v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01888",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Velychko_D/0/1/0/all/0/1\">Dmytro Velychko</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Damm_S/0/1/0/all/0/1\">Simon Damm</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fischer_A/0/1/0/all/0/1\">Asja Fischer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lucke_J/0/1/0/all/0/1\">J&#xf6;rg L&#xfc;cke</a>",
          "description": "Standard probabilistic sparse coding assumes a Laplace prior, a linear\nmapping from latents to observables, and Gaussian observable distributions. We\nhere derive a solely entropy-based learning objective for the parameters of\nstandard sparse coding. The novel variational objective has the following\nfeatures: (A) unlike MAP approximations, it uses non-trivial posterior\napproximations for probabilistic inference; (B) unlike for previous non-trivial\napproximations, the novel objective is fully analytical; and (C) the objective\nallows for a novel principled form of annealing. The objective is derived by\nfirst showing that the standard ELBO objective converges to a sum of entropies,\nwhich matches similar recent results for generative models with Gaussian\npriors. The conditions under which the ELBO becomes equal to entropies are then\nshown to have analytical solutions, which leads to the fully analytical\nobjective. Numerical experiments are used to demonstrate the feasibility of\nlearning with such entropy-based ELBOs. We investigate different posterior\napproximations including Gaussians with correlated latents and deep amortized\napproximations. Furthermore, we numerically investigate entropy-based annealing\nwhich results in improved learning. Our main contributions are theoretical,\nhowever, and they are twofold: (1) for non-trivial posterior approximations, we\nprovide the (to the knowledge of the authors) first analytical ELBO objective\nfor standard probabilistic sparse coding; and (2) we provide the first\ndemonstration on how a recently shown convergence of the ELBO to entropy sums\ncan be used for learning.",
          "link": "http://arxiv.org/abs/2311.01888",
          "publishedOn": "2023-11-07T00:44:05.652Z",
          "wordCount": 716,
          "title": "Learning Sparse Codes with Entropy-Based ELBOs. (arXiv:2311.01888v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01900",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Concha_A/0/1/0/all/0/1\">Alejandro de la Concha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vayatis_N/0/1/0/all/0/1\">Nicolas Vayatis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kalogeratos_A/0/1/0/all/0/1\">Argyris Kalogeratos</a>",
          "description": "Quantifying the difference between two probability density functions, $p$ and\n$q$, using available data, is a fundamental problem in Statistics and Machine\nLearning. A usual approach for addressing this problem is the likelihood-ratio\nestimation (LRE) between $p$ and $q$, which -- to our best knowledge -- has\nbeen investigated mainly for the offline case. This paper contributes by\nintroducing a new framework for online non-parametric LRE (OLRE) for the\nsetting where pairs of iid observations $(x_t \\sim p, x'_t \\sim q)$ are\nobserved over time. The non-parametric nature of our approach has the advantage\nof being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on the\nrecent advances in Kernel Methods and functional minimization to develop an\nestimator that can be efficiently updated online. We provide theoretical\nguarantees for the performance of the OLRE method along with empirical\nvalidation in synthetic experiments.",
          "link": "http://arxiv.org/abs/2311.01900",
          "publishedOn": "2023-11-07T00:44:05.629Z",
          "wordCount": 652,
          "title": "Online non-parametric likelihood-ratio estimation by Pearson-divergence functional minimization. (arXiv:2311.01900v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.02000",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hong_Y/0/1/0/all/0/1\">Yusu Hong</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lin_J/0/1/0/all/0/1\">Junhong Lin</a>",
          "description": "In this paper, we study the convergence of the Adaptive Moment Estimation\n(Adam) algorithm under unconstrained non-convex smooth stochastic\noptimizations. Despite the widespread usage in machine learning areas, its\ntheoretical properties remain limited. Prior researches primarily investigated\nAdam's convergence from an expectation view, often necessitating strong\nassumptions like uniformly stochastic bounded gradients or problem-dependent\nknowledge in prior. As a result, the applicability of these findings in\npractical real-world scenarios has been constrained. To overcome these\nlimitations, we provide a deep analysis and show that Adam could converge to\nthe stationary point in high probability with a rate of $\\mathcal{O}\\left({\\rm\npoly}(\\log T)/\\sqrt{T}\\right)$ under coordinate-wise \"affine\" variance noise,\nnot requiring any bounded gradient assumption and any problem-dependent\nknowledge in prior to tune hyper-parameters. Additionally, it is revealed that\nAdam confines its gradients' magnitudes within an order of\n$\\mathcal{O}\\left({\\rm poly}(\\log T)\\right)$. Finally, we also investigate a\nsimplified version of Adam without one of the corrective terms and obtain a\nconvergence rate that is adaptive to the noise level.",
          "link": "http://arxiv.org/abs/2311.02000",
          "publishedOn": "2023-11-07T00:44:05.620Z",
          "wordCount": 683,
          "title": "High Probability Convergence of Adam Under Unbounded Gradients and Affine Variance Noise. (arXiv:2311.02000v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01596",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kejzlar_V/0/1/0/all/0/1\">Vojtech Kejzlar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Neufcourt_L/0/1/0/all/0/1\">L&#xe9;o Neufcourt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nazarewicz_W/0/1/0/all/0/1\">Witold Nazarewicz</a>",
          "description": "To improve the predictability of complex computational models in the\nexperimentally-unknown domains, we propose a Bayesian statistical machine\nlearning framework utilizing the Dirichlet distribution that combines results\nof several imperfect models. This framework can be viewed as an extension of\nBayesian stacking. To illustrate the method, we study the ability of Bayesian\nmodel averaging and mixing techniques to mine nuclear masses. We show that the\nglobal and local mixtures of models reach excellent performance on both\nprediction accuracy and uncertainty quantification and are preferable to\nclassical Bayesian model averaging. Additionally, our statistical analysis\nindicates that improving model predictions through mixing rather than mixing of\ncorrected models leads to more robust extrapolations.",
          "link": "http://arxiv.org/abs/2311.01596",
          "publishedOn": "2023-11-07T00:44:05.614Z",
          "wordCount": 607,
          "title": "Local Bayesian Dirichlet mixing of imperfect models. (arXiv:2311.01596v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1\">Qianxin Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yiyang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Shaojie Tang</a>",
          "description": "In this paper, we aim to build a novel bandits algorithm that is capable of\nfully harnessing the power of multi-dimensional data and the inherent\nnon-linearity of reward functions to provide high-usable and accountable\ndecision-making services. To this end, we introduce a generalized low-rank\ntensor contextual bandits model in which an action is formed from three feature\nvectors, and thus can be represented by a tensor. In this formulation, the\nreward is determined through a generalized linear function applied to the inner\nproduct of the action's feature tensor and a fixed but unknown parameter tensor\nwith a low tubal rank. To effectively achieve the trade-off between exploration\nand exploitation, we introduce a novel algorithm called \"Generalized Low-Rank\nTensor Exploration Subspace then Refine\" (G-LowTESTR). This algorithm first\ncollects raw data to explore the intrinsic low-rank tensor subspace information\nembedded in the decision-making scenario, and then converts the original\nproblem into an almost lower-dimensional generalized linear contextual bandits\nproblem. Rigorous theoretical analysis shows that the regret bound of\nG-LowTESTR is superior to those in vectorization and matricization cases. We\nconduct a series of simulations and real data experiments to further highlight\nthe effectiveness of G-LowTESTR, leveraging its ability to capitalize on the\nlow-rank tensor structure for enhanced learning.",
          "link": "http://arxiv.org/abs/2311.01771",
          "publishedOn": "2023-11-07T00:44:05.607Z",
          "wordCount": 706,
          "title": "Efficient Generalized Low-Rank Tensor Contextual Bandits. (arXiv:2311.01771v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01489",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bica_I/0/1/0/all/0/1\">Ioana Bica</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jarrett_D/0/1/0/all/0/1\">Daniel Jarrett</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Consider learning an imitation policy on the basis of demonstrated behavior\nfrom multiple environments, with an eye towards deployment in an unseen\nenvironment. Since the observable features from each setting may be different,\ndirectly learning individual policies as mappings from features to actions is\nprone to spurious correlations -- and may not generalize well. However, the\nexpert's policy is often a function of a shared latent structure underlying\nthose observable features that is invariant across settings. By leveraging data\nfrom multiple environments, we propose Invariant Causal Imitation Learning\n(ICIL), a novel technique in which we learn a feature representation that is\ninvariant across domains, on the basis of which we learn an imitation policy\nthat matches expert behavior. To cope with transition dynamics mismatch, ICIL\nlearns a shared representation of causal features (for all training\nenvironments), that is disentangled from the specific representations of noise\nvariables (for each of those environments). Moreover, to ensure that the\nlearned policy matches the observation distribution of the expert's policy,\nICIL estimates the energy of the expert's observations and uses a\nregularization term that minimizes the imitator policy's next state energy.\nExperimentally, we compare our methods against several benchmarks in control\nand healthcare tasks and show its effectiveness in learning imitation policies\ncapable of generalizing to unseen environments.",
          "link": "http://arxiv.org/abs/2311.01489",
          "publishedOn": "2023-11-07T00:44:05.598Z",
          "wordCount": 723,
          "title": "Invariant Causal Imitation Learning for Generalizable Policies. (arXiv:2311.01489v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01994",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dash_S/0/1/0/all/0/1\">Sanjeeb Dash</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1\">Soumyadip Ghosh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Goncalves_J/0/1/0/all/0/1\">Joao Goncalves</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Squillante_M/0/1/0/all/0/1\">Mark S. Squillante</a>",
          "description": "Model explainability is crucial for human users to be able to interpret how a\nproposed classifier assigns labels to data based on its feature values. We\nstudy generalized linear models constructed using sets of feature value rules,\nwhich can capture nonlinear dependencies and interactions. An inherent\ntrade-off exists between rule set sparsity and its prediction accuracy. It is\ncomputationally expensive to find the right choice of sparsity -- e.g., via\ncross-validation -- with existing methods. We propose a new formulation to\nlearn an ensemble of rule sets that simultaneously addresses these competing\nfactors. Good generalization is ensured while keeping computational costs low\nby utilizing distributionally robust optimization. The formulation utilizes\ncolumn generation to efficiently search the space of rule sets and constructs a\nsparse ensemble of rule sets, in contrast with techniques like random forests\nor boosting and their variants. We present theoretical results that motivate\nand justify the use of our distributionally robust formulation. Extensive\nnumerical experiments establish that our method improves over competing methods\n-- on a large set of publicly available binary classification problem instances\n-- with respect to one or more of the following metrics: generalization\nquality, computational cost, and explainability.",
          "link": "http://arxiv.org/abs/2311.01994",
          "publishedOn": "2023-11-07T00:44:05.592Z",
          "wordCount": 703,
          "title": "Obtaining Explainable Classification Models using Distributionally Robust Optimization. (arXiv:2311.01994v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01806",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Yang_Y/0/1/0/all/0/1\">Yingzhen Yang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>",
          "description": "Randomized algorithms are important for solving large-scale optimization\nproblems. In this paper, we propose a fast sketching algorithm for least square\nproblems regularized by convex or nonconvex regularization functions, Sketching\nfor Regularized Optimization (SRO). Our SRO algorithm first generates a sketch\nof the original data matrix, then solves the sketched problem. Different from\nexisting randomized algorithms, our algorithm handles general Frechet\nsubdifferentiable regularization functions in an unified framework. We present\ngeneral theoretical result for the approximation error between the optimization\nresults of the original problem and the sketched problem for regularized least\nsquare problems which can be convex or nonconvex. For arbitrary convex\nregularizer, relative-error bound is proved for the approximation error.\nImportantly, minimax rates for sparse signal estimation by solving the sketched\nsparse convex or nonconvex learning problems are also obtained using our\ngeneral theoretical result under mild conditions. To the best of our knowledge,\nour results are among the first to demonstrate minimax rates for convex or\nnonconvex sparse learning problem by sketching under a unified theoretical\nframework. We further propose an iterative sketching algorithm which reduces\nthe approximation error exponentially by iteratively invoking the sketching\nalgorithm. Experimental results demonstrate the effectiveness of the proposed\nSRO and Iterative SRO algorithms.",
          "link": "http://arxiv.org/abs/2311.01806",
          "publishedOn": "2023-11-07T00:44:05.554Z",
          "wordCount": 721,
          "title": "Sketching for Convex and Nonconvex Regularized Least Squares with Sharp Guarantees. (arXiv:2311.01806v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simsek_B/0/1/0/all/0/1\">Berfin &#x15e;im&#x15f;ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendjeddou_A/0/1/0/all/0/1\">Amire Bendjeddou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstner_W/0/1/0/all/0/1\">Wulfram Gerstner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brea_J/0/1/0/all/0/1\">Johanni Brea</a>",
          "description": "Any continuous function $f^*$ can be approximated arbitrarily well by a\nneural network with sufficiently many neurons $k$. We consider the case when\n$f^*$ itself is a neural network with one hidden layer and $k$ neurons.\nApproximating $f^*$ with a neural network with $n< k$ neurons can thus be seen\nas fitting an under-parameterized \"student\" network with $n$ neurons to a\n\"teacher\" network with $k$ neurons. As the student has fewer neurons than the\nteacher, it is unclear, whether each of the $n$ student neurons should copy one\nof the teacher neurons or rather average a group of teacher neurons. For\nshallow neural networks with erf activation function and for the standard\nGaussian input distribution, we prove that \"copy-average\" configurations are\ncritical points if the teacher's incoming vectors are orthonormal and its\noutgoing weights are unitary. Moreover, the optimum among such configurations\nis reached when $n-1$ student neurons each copy one teacher neuron and the\n$n$-th student neuron averages the remaining $k-n+1$ teacher neurons. For the\nstudent network with $n=1$ neuron, we provide additionally a closed-form\nsolution of the non-trivial critical point(s) for commonly used activation\nfunctions through solving an equivalent constrained optimization problem.\nEmpirically, we find for the erf activation function that gradient flow\nconverges either to the optimal copy-average critical point or to another point\nwhere each student neuron approximately copies a different teacher neuron.\nFinally, we find similar results for the ReLU activation function, suggesting\nthat the optimal solution of underparameterized networks has a universal\nstructure.",
          "link": "http://arxiv.org/abs/2311.01644",
          "publishedOn": "2023-11-07T00:44:05.547Z",
          "wordCount": 774,
          "title": "Should Under-parameterized Student Networks Copy or Average Teacher Weights?. (arXiv:2311.01644v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.02076",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalra_D/0/1/0/all/0/1\">Dayal Singh Kalra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tianyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barkeshli_M/0/1/0/all/0/1\">Maissam Barkeshli</a>",
          "description": "In gradient descent dynamics of neural networks, the top eigenvalue of the\nHessian of the loss (sharpness) displays a variety of robust phenomena\nthroughout training. This includes early time regimes where the sharpness may\ndecrease during early periods of training (sharpness reduction), and later time\nbehavior such as progressive sharpening and edge of stability. We demonstrate\nthat a simple $2$-layer linear network (UV model) trained on a single training\nexample exhibits all of the essential sharpness phenomenology observed in\nreal-world scenarios. By analyzing the structure of dynamical fixed points in\nfunction space and the vector field of function updates, we uncover the\nunderlying mechanisms behind these sharpness trends. Our analysis reveals (i)\nthe mechanism behind early sharpness reduction and progressive sharpening, (ii)\nthe required conditions for edge of stability, and (iii) a period-doubling\nroute to chaos on the edge of stability manifold as learning rate is increased.\nFinally, we demonstrate that various predictions from this simplified model\ngeneralize to real-world scenarios and discuss its limitations.",
          "link": "http://arxiv.org/abs/2311.02076",
          "publishedOn": "2023-11-07T00:44:05.524Z",
          "wordCount": 727,
          "title": "Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos. (arXiv:2311.02076v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ketenci_M/0/1/0/all/0/1\">Mert Ketenci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhave_S/0/1/0/all/0/1\">Shreyas Bhave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhadad_N/0/1/0/all/0/1\">No&#xe9;mie Elhadad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perotte_A/0/1/0/all/0/1\">Adler Perotte</a>",
          "description": "Survival analysis is a widely-used technique for analyzing time-to-event data\nin the presence of censoring. In recent years, numerous survival analysis\nmethods have emerged which scale to large datasets and relax traditional\nassumptions such as proportional hazards. These models, while being performant,\nare very sensitive to model hyperparameters including: (1) number of bins and\nbin size for discrete models and (2) number of cluster assignments for\nmixture-based models. Each of these choices requires extensive tuning by\npractitioners to achieve optimal performance. In addition, we demonstrate in\nempirical studies that: (1) optimal bin size may drastically differ based on\nthe metric of interest (e.g., concordance vs brier score), and (2) mixture\nmodels may suffer from mode collapse and numerical instability. We propose a\nsurvival analysis approach which eliminates the need to tune hyperparameters\nsuch as mixture assignments and bin sizes, reducing the burden on\npractitioners. We show that the proposed approach matches or outperforms\nbaselines on several real-world datasets.",
          "link": "http://arxiv.org/abs/2311.01660",
          "publishedOn": "2023-11-07T00:44:02.386Z",
          "wordCount": 684,
          "title": "Maximum Likelihood Estimation of Flexible Survival Densities with Importance Sampling. (arXiv:2311.01660v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01476",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lin_F/0/1/0/all/0/1\">Fangyuan Lin</a>",
          "description": "A stochastic process that arises by composing a function with a Markov\nprocess is called an aggregated Markov process (AMP). The purpose of composing\na Markov process with a function can be a reduction of dimensions, e.g., a\nprojection onto certain coordinates. The theory around AMP has been extensively\nstudied e.g. by Dynkin, Cameron, Rogers and Pitman, and Kelly, all of whom\nprovided sufficient conditions for an AMP to remain Markov. In another\ndirection, Larget provided a canonical representation for AMP, which can be\nused to verify the equivalence of two AMPs. The purpose of this paper is to\ndescribe how the theory of AMP can be applied to stochastic learning theory as\nthey learn a particular task.",
          "link": "http://arxiv.org/abs/2311.01476",
          "publishedOn": "2023-11-07T00:44:02.379Z",
          "wordCount": 627,
          "title": "Applications of the Theory of Aggregated Markov Processes in Stochastic Learning Theory. (arXiv:2311.01476v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.00973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Li Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1\">Ruida Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1\">Chao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Cong Shen</a>",
          "description": "We study a federated linear bandits model, where $M$ clients communicate with\na central server to solve a linear contextual bandits problem with finite\nadversarial action sets that may be different across clients. To address the\nunique challenges of adversarial finite action sets, we propose the\nFedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL\nalgorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a\ntotal regret of $\\tilde{O}(\\sqrt{d T})$, where $T$ is the total number of arm\npulls from all clients, and $d$ is the ambient dimension of the linear model.\nThis matches the minimax lower bound and thus is order-optimal (up to polylog\nterms). We study both asynchronous and synchronous cases and show that the\ncommunication cost can be controlled as $O(d M^2 \\log(d)\\log(T))$ and\n$O(\\sqrt{d^3 M^3} \\log(d))$, respectively. The FedSupLinUCB design is further\nextended to two scenarios: (1) variance-adaptive, where a total regret of\n$\\tilde{O} (\\sqrt{d \\sum \\nolimits_{t=1}^{T} \\sigma_t^2})$ can be achieved with\n$\\sigma_t^2$ being the noise variance of round $t$; and (2) adversarial\ncorruption, where a total regret of $\\tilde{O}(\\sqrt{dT} + d C_p)$ can be\nachieved with $C_p$ being the total corruption budget. Experiment results\ncorroborate the theoretical analysis and demonstrate the effectiveness of\nFedSupLinUCB on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2311.00973",
          "publishedOn": "2023-11-04T00:42:37.484Z",
          "wordCount": null,
          "title": "Federated Linear Bandits with Finite Adversarial Actions. (arXiv:2311.00973v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.04015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Javanmard_A/0/1/0/all/0/1\">Adel Javanmard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1\">Vahab Mirrokni</a>",
          "description": "While personalized recommendations systems have become increasingly popular,\nensuring user data protection remains a top concern in the development of these\nlearning systems. A common approach to enhancing privacy involves training\nmodels using anonymous data rather than individual data. In this paper, we\nexplore a natural technique called \\emph{look-alike clustering}, which involves\nreplacing sensitive features of individuals with the cluster's average values.\nWe provide a precise analysis of how training models using anonymous cluster\ncenters affects their generalization capabilities. We focus on an asymptotic\nregime where the size of the training set grows in proportion to the features\ndimension. Our analysis is based on the Convex Gaussian Minimax Theorem (CGMT)\nand allows us to theoretically understand the role of different model\ncomponents on the generalization error. In addition, we demonstrate that in\ncertain high-dimensional regimes, training over anonymous cluster centers acts\nas a regularization and improves generalization error of the trained models.\nFinally, we corroborate our asymptotic theory with finite-sample numerical\nexperiments where we observe a perfect match when the sample size is only of\norder of a few hundreds.",
          "link": "http://arxiv.org/abs/2310.04015",
          "publishedOn": "2023-11-04T00:42:37.483Z",
          "wordCount": null,
          "title": "Anonymous Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization. (arXiv:2310.04015v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01453",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Angelopoulos_A/0/1/0/all/0/1\">Anastasios N. Angelopoulos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duchi_J/0/1/0/all/0/1\">John C. Duchi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zrnic_T/0/1/0/all/0/1\">Tijana Zrnic</a>",
          "description": "We present PPI++: a computationally lightweight methodology for estimation\nand inference based on a small labeled dataset and a typically much larger\ndataset of machine-learning predictions. The methods automatically adapt to the\nquality of available predictions, yielding easy-to-compute confidence sets --\nfor parameters of any dimensionality -- that always improve on classical\nintervals using only the labeled data. PPI++ builds on prediction-powered\ninference (PPI), which targets the same problem setting, improving its\ncomputational and statistical efficiency. Real and synthetic experiments\ndemonstrate the benefits of the proposed adaptations.",
          "link": "http://arxiv.org/abs/2311.01453",
          "publishedOn": "2023-11-04T00:42:37.481Z",
          "wordCount": null,
          "title": "PPI++: Efficient Prediction-Powered Inference. (arXiv:2311.01453v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.02598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lachapelle_S/0/1/0/all/0/1\">S&#xe9;bastien Lachapelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahajan_D/0/1/0/all/0/1\">Divyat Mahajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitliagkas_I/0/1/0/all/0/1\">Ioannis Mitliagkas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1\">Simon Lacoste-Julien</a>",
          "description": "We tackle the problems of latent variables identification and\n``out-of-support'' image generation in representation learning. We show that\nboth are possible for a class of decoders that we call additive, which are\nreminiscent of decoders used for object-centric representation learning (OCRL)\nand well suited for images that can be decomposed as a sum of object-specific\nimages. We provide conditions under which exactly solving the reconstruction\nproblem using an additive decoder is guaranteed to identify the blocks of\nlatent variables up to permutation and block-wise invertible transformations.\nThis guarantee relies only on very weak assumptions about the distribution of\nthe latent factors, which might present statistical dependencies and have an\nalmost arbitrarily shaped support. Our result provides a new setting where\nnonlinear independent component analysis (ICA) is possible and adds to our\ntheoretical understanding of OCRL methods. We also show theoretically that\nadditive decoders can generate novel images by recombining observed factors of\nvariations in novel ways, an ability we refer to as Cartesian-product\nextrapolation. We show empirically that additivity is crucial for both\nidentifiability and extrapolation on simulated data.",
          "link": "http://arxiv.org/abs/2307.02598",
          "publishedOn": "2023-11-04T00:42:37.481Z",
          "wordCount": null,
          "title": "Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation. (arXiv:2307.02598v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01358",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Levi_N/0/1/0/all/0/1\">Noam Levi</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Oz_Y/0/1/0/all/0/1\">Yaron Oz</a>",
          "description": "Turbulence is a complex spatial and temporal structure created by the strong\nnon-linear dynamics of fluid flows at high Reynolds numbers. Despite being an\nubiquitous phenomenon that has been studied for centuries, a full understanding\nof turbulence remained a formidable challenge. Here, we introduce tools from\nthe fields of quantum chaos and Random Matrix Theory (RMT) and present a\ndetailed analysis of image datasets generated from turbulence simulations of\nincompressible and compressible fluid flows. Focusing on two observables: the\ndata Gram matrix and the single image distribution, we study both the local and\nglobal eigenvalue statistics and compare them to classical chaos, uncorrelated\nnoise and natural images. We show that from the RMT perspective, the turbulence\nGram matrices lie in the same universality class as quantum chaotic rather than\nintegrable systems, and the data exhibits power-law scalings in the bulk of its\neigenvalues which are vastly different from uncorrelated classical chaos,\nrandom data, natural images. Interestingly, we find that the single sample\ndistribution only appears as fully RMT chaotic, but deviates from chaos at\nlarger correlation lengths, as well as exhibiting different scaling properties.",
          "link": "http://arxiv.org/abs/2311.01358",
          "publishedOn": "2023-11-04T00:42:37.463Z",
          "wordCount": null,
          "title": "The Universal Statistical Structure and Scaling Laws of Chaos and Turbulence. (arXiv:2311.01358v1 [cond-mat.stat-mech])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08337",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bartosh_G/0/1/0/all/0/1\">Grigory Bartosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naesseth_C/0/1/0/all/0/1\">Christian A. Naesseth</a>",
          "description": "Diffusion models have shown remarkable performance on many generative tasks.\nDespite recent success, most diffusion models are restricted in that they only\nallow linear transformation of the data distribution. In contrast, broader\nfamily of transformations can potentially help train generative distributions\nmore efficiently, simplifying the reverse process and closing the gap between\nthe true negative log-likelihood and the variational approximation. In this\npaper, we present Neural Diffusion Models (NDMs), a generalization of\nconventional diffusion models that enables defining and learning time-dependent\nnon-linear transformations of data. We show how to optimise NDMs using a\nvariational bound in a simulation-free setting. Moreover, we derive a\ntime-continuous formulation of NDMs, which allows fast and reliable inference\nusing off-the-shelf numerical ODE and SDE solvers. Finally, we demonstrate the\nutility of NDMs with learnable transformations through experiments on standard\nimage generation benchmarks, including CIFAR-10, downsampled versions of\nImageNet and CelebA-HQ. NDMs outperform conventional diffusion models in terms\nof likelihood and produce high-quality samples.",
          "link": "http://arxiv.org/abs/2310.08337",
          "publishedOn": "2023-11-04T00:42:37.463Z",
          "wordCount": null,
          "title": "Neural Diffusion Models. (arXiv:2310.08337v1 [cs.LG] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01853",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rozet_F/0/1/0/all/0/1\">Fran&#xe7;ois Rozet</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Louppe_G/0/1/0/all/0/1\">Gilles Louppe</a>",
          "description": "Data assimilation addresses the problem of identifying plausible state\ntrajectories of dynamical systems given noisy or incomplete observations. In\ngeosciences, it presents challenges due to the high-dimensionality of\ngeophysical dynamical systems, often exceeding millions of dimensions. This\nwork assesses the scalability of score-based data assimilation (SDA), a novel\ndata assimilation method, in the context of such systems. We propose\nmodifications to the score network architecture aimed at significantly reducing\nmemory consumption and execution time. We demonstrate promising results for a\ntwo-layer quasi-geostrophic model.",
          "link": "http://arxiv.org/abs/2310.01853",
          "publishedOn": "2023-11-04T00:42:37.459Z",
          "wordCount": null,
          "title": "Score-based Data Assimilation for a Two-Layer Quasi-Geostrophic Model. (arXiv:2310.01853v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01377",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Dias_S/0/1/0/all/0/1\">Sathsara Dias</a>, <a href=\"http://arxiv.org/find/math/1/au:+Surasinghe_S/0/1/0/all/0/1\">Sudam Surasinghe</a>, <a href=\"http://arxiv.org/find/math/1/au:+Priyankara_K/0/1/0/all/0/1\">Kanaththa Priyankara</a>, <a href=\"http://arxiv.org/find/math/1/au:+Budisic_M/0/1/0/all/0/1\">Marko Budi&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/math/1/au:+Pratt_L/0/1/0/all/0/1\">Larry Pratt</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sanchez_Garrido_J/0/1/0/all/0/1\">Jos&#xe9; C. Sanchez-Garrido</a>, <a href=\"http://arxiv.org/find/math/1/au:+Bollt_E/0/1/0/all/0/1\">Erik M.Bollt</a>",
          "description": "The Strait of Gibraltar is a region characterized by intricate oceanic\nsub-mesoscale features, influenced by topography, tidal forces, instabilities,\nand nonlinear hydraulic processes, all governed by the nonlinear equations of\nfluid motion. In this study, we aim to uncover the underlying physics of these\nphenomena within 3D MIT general circulation model simulations, including waves,\neddies, and gyres. To achieve this, we employ Dynamic Mode Decomposition (DMD)\nto break down simulation snapshots into Koopman modes, with distinct\nexponential growth/decay rates and oscillation frequencies. Our objectives\nencompass evaluating DMD's efficacy in capturing known features, unveiling new\nelements, ranking modes, and exploring order reduction. We also introduce\nmodifications to enhance DMD's robustness, numerical accuracy, and robustness\nof eigenvalues. DMD analysis yields a comprehensive understanding of flow\npatterns, internal wave formation, and the dynamics of the Strait of Gibraltar,\nits meandering behaviors, and the formation of a secondary gyre, notably the\nWestern Alboran Gyre, as well as the propagation of Kelvin and coastal-trapped\nwaves along the African coast. In doing so, it significantly advances our\ncomprehension of intricate oceanographic phenomena and underscores the immense\nutility of DMD as an analytical tool for such complex datasets, suggesting that\nDMD could serve as a valuable addition to the toolkit of oceanographers.",
          "link": "http://arxiv.org/abs/2311.01377",
          "publishedOn": "2023-11-04T00:42:37.451Z",
          "wordCount": null,
          "title": "Analysis of tidal flows through the Strait of Gibraltar using Dynamic Mode Decomposition. (arXiv:2311.01377v1 [math.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alain_M/0/1/0/all/0/1\">Mathieu Alain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takao_S/0/1/0/all/0/1\">So Takao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paige_B/0/1/0/all/0/1\">Brooks Paige</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deisenroth_M/0/1/0/all/0/1\">Marc Peter Deisenroth</a>",
          "description": "In recent years, there has been considerable interest in developing machine\nlearning models on graphs in order to account for topological inductive biases.\nIn particular, recent attention was given to Gaussian processes on such\nstructures since they can additionally account for uncertainty. However, graphs\nare limited to modelling relations between two vertices. In this paper, we go\nbeyond this dyadic setting and consider polyadic relations that include\ninteractions between vertices, edges and one of their generalisations, known as\ncells. Specifically, we propose Gaussian processes on cellular complexes, a\ngeneralisation of graphs that captures interactions between these higher-order\ncells. One of our key contributions is the derivation of two novel kernels, one\nthat generalises the graph Mat\\'ern kernel and one that additionally mixes\ninformation of different cell types.",
          "link": "http://arxiv.org/abs/2311.01198",
          "publishedOn": "2023-11-04T00:42:37.449Z",
          "wordCount": null,
          "title": "Gaussian Processes on Cellular Complexes. (arXiv:2311.01198v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Futami_F/0/1/0/all/0/1\">Futoshi Futami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujisawa_M/0/1/0/all/0/1\">Masahiro Fujisawa</a>",
          "description": "We provide novel information-theoretic generalization bounds for stochastic\ngradient Langevin dynamics (SGLD) under the assumptions of smoothness and\ndissipativity, which are widely used in sampling and non-convex optimization\nstudies. Our bounds are time-independent and decay to zero as the sample size\nincreases, regardless of the number of iterations and whether the step size is\nfixed. Unlike previous studies, we derive the generalization error bounds by\nfocusing on the time evolution of the Kullback--Leibler divergence, which is\nrelated to the stability of datasets and is the upper bound of the mutual\ninformation between output parameters and an input dataset. Additionally, we\nestablish the first information-theoretic generalization bound when the\ntraining and test loss are the same by showing that a loss function of SGLD is\nsub-exponential. This bound is also time-independent and removes the\nproblematic step size dependence in existing work, leading to an improved\nexcess risk bound by combining our analysis with the existing non-convex\noptimization error bounds.",
          "link": "http://arxiv.org/abs/2311.01046",
          "publishedOn": "2023-11-04T00:42:37.447Z",
          "wordCount": null,
          "title": "Time-Independent Information-Theoretic Generalization Bounds for SGLD. (arXiv:2311.01046v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.18230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saez_Maldonado_F/0/1/0/all/0/1\">Francisco Javier S&#xe1;ez-Maldonado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maronas_J/0/1/0/all/0/1\">Juan Maro&#xf1;as</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1\">Daniel Hern&#xe1;ndez-Lobato</a>",
          "description": "Transformed Gaussian Processes (TGPs) are stochastic processes specified by\ntransforming samples from the joint distribution from a prior process\n(typically a GP) using an invertible transformation; increasing the flexibility\nof the base process.\n\nFurthermore, they achieve competitive results compared with Deep Gaussian\nProcesses (DGPs), which are another generalization constructed by a\nhierarchical concatenation of GPs. In this work, we propose a generalization of\nTGPs named Deep Transformed Gaussian Processes (DTGPs), which follows the trend\nof concatenating layers of stochastic processes. More precisely, we obtain a\nmulti-layer model in which each layer is a TGP. This generalization implies an\nincrement of flexibility with respect to both TGPs and DGPs. Exact inference in\nsuch a model is intractable. However, we show that one can use variational\ninference to approximate the required computations yielding a straightforward\nextension of the popular DSVI inference algorithm Salimbeni et al (2017). The\nexperiments conducted evaluate the proposed novel DTGPs in multiple regression\ndatasets, achieving good scalability and performance.",
          "link": "http://arxiv.org/abs/2310.18230",
          "publishedOn": "2023-11-04T00:42:37.438Z",
          "wordCount": null,
          "title": "Deep Transformed Gaussian Processes. (arXiv:2310.18230v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.00966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramaniam_G/0/1/0/all/0/1\">Gargi Balasubramaniam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_H/0/1/0/all/0/1\">Haozhe Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>",
          "description": "Domain generalization asks for models trained over a set of training\nenvironments to generalize well in unseen test environments. Recently, a series\nof algorithms such as Invariant Risk Minimization (IRM) have been proposed for\ndomain generalization. However, Rosenfeld et al. (2021) shows that in a simple\nlinear data model, even if non-convexity issues are ignored, IRM and its\nextensions cannot generalize to unseen environments with less than $d_s+1$\ntraining environments, where $d_s$ is the dimension of the spurious-feature\nsubspace. In this work, we propose Invariant-feature Subspace Recovery (ISR): a\nnew class of algorithms to achieve provable domain generalization across the\nsettings of classification and regression problems. First, in the binary\nclassification setup of Rosenfeld et al. (2021), we show that our first\nalgorithm, ISR-Mean, can identify the subspace spanned by invariant features\nfrom the first-order moments of the class-conditional distributions, and\nachieve provable domain generalization with $d_s+1$ training environments. Our\nsecond algorithm, ISR-Cov, further reduces the required number of training\nenvironments to $O(1)$ using the information of second-order moments. Notably,\nunlike IRM, our algorithms bypass non-convexity issues and enjoy global\nconvergence guarantees. Next, we extend ISR-Mean to the more general setting of\nmulti-class classification and propose ISR-Multiclass, which leverages class\ninformation and provably recovers the invariant-feature subspace with $\\lceil\nd_s/k\\rceil+1$ training environments for $k$-class classification. Finally, for\nregression problems, we propose ISR-Regression that can identify the\ninvariant-feature subspace with $d_s+1$ training environments. Empirically, we\ndemonstrate the superior performance of our ISRs on synthetic benchmarks.\nFurther, ISR can be used as post-processing methods for feature extractors such\nas neural nets.",
          "link": "http://arxiv.org/abs/2311.00966",
          "publishedOn": "2023-11-04T00:42:37.435Z",
          "wordCount": null,
          "title": "Invariant-Feature Subspace Recovery: A New Class of Provable Domain Generalization Algorithms. (arXiv:2311.00966v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.13441",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cheng_T/0/1/0/all/0/1\">Taoli Cheng</a>",
          "description": "The application of machine learning in sciences has seen exciting advances in\nrecent years. As a widely applicable technique, anomaly detection has been long\nstudied in the machine learning community. Especially, deep neural nets-based\nout-of-distribution detection has made great progress for high-dimensional\ndata. Recently, these techniques have been showing their potential in\nscientific disciplines. We take a critical look at their applicative prospects\nincluding data universality, experimental protocols, model robustness, etc. We\ndiscuss examples that display transferable practices and domain-specific\nchallenges simultaneously, providing a starting point for establishing a novel\ninterdisciplinary research paradigm in the near future.",
          "link": "http://arxiv.org/abs/2210.13441",
          "publishedOn": "2023-11-04T00:42:37.423Z",
          "wordCount": null,
          "title": "Bridging Machine Learning and Sciences: Opportunities and Challenges. (arXiv:2210.13441v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13398",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Chernozhukov_V/0/1/0/all/0/1\">Victor Chernozhukov</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Cinelli_C/0/1/0/all/0/1\">Carlos Cinelli</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Newey_W/0/1/0/all/0/1\">Whitney Newey</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Sharma_A/0/1/0/all/0/1\">Amit Sharma</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Syrgkanis_V/0/1/0/all/0/1\">Vasilis Syrgkanis</a>",
          "description": "We derive general, yet simple, sharp bounds on the size of the omitted\nvariable bias for a broad class of causal parameters that can be identified as\nlinear functionals of the conditional expectation function of the outcome. Such\nfunctionals encompass many of the traditional targets of investigation in\ncausal inference studies, such as, for example, (weighted) average of potential\noutcomes, average treatment effects (including subgroup effects, such as the\neffect on the treated), (weighted) average derivatives, and policy effects from\nshifts in covariate distribution -- all for general, nonparametric causal\nmodels. Our construction relies on the Riesz-Frechet representation of the\ntarget functional. Specifically, we show how the bound on the bias depends only\non the additional variation that the latent variables create both in the\noutcome and in the Riesz representer for the parameter of interest. Moreover,\nin many important cases (e.g, average treatment effects and avearage\nderivatives) the bound is shown to depend on easily interpretable quantities\nthat measure the explanatory power of the omitted variables. Therefore, simple\nplausibility judgments on the maximum explanatory power of omitted variables\n(in explaining treatment and outcome variation) are sufficient to place overall\nbounds on the size of the bias. Furthermore, we use debiased machine learning\nto provide flexible and efficient statistical inference on learnable components\nof the bounds. Finally, empirical examples demonstrate the usefulness of the\napproach.",
          "link": "http://arxiv.org/abs/2112.13398",
          "publishedOn": "2023-11-04T00:42:37.418Z",
          "wordCount": null,
          "title": "Long Story Short: Omitted Variable Bias in Causal Machine Learning. (arXiv:2112.13398v4 [econ.EM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ludke_D/0/1/0/all/0/1\">David L&#xfc;dke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilos_M/0/1/0/all/0/1\">Marin Bilo&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shchur_O/0/1/0/all/0/1\">Oleksandr Shchur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lienen_M/0/1/0/all/0/1\">Marten Lienen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>",
          "description": "Autoregressive neural networks within the temporal point process (TPP)\nframework have become the standard for modeling continuous-time event data.\nEven though these models can expressively capture event sequences in a\none-step-ahead fashion, they are inherently limited for long-term forecasting\napplications due to the accumulation of errors caused by their sequential\nnature. To overcome these limitations, we derive ADD-THIN, a principled\nprobabilistic denoising diffusion model for TPPs that operates on entire event\nsequences. Unlike existing diffusion approaches, ADD-THIN naturally handles\ndata with discrete and continuous components. In experiments on synthetic and\nreal-world datasets, our model matches the state-of-the-art TPP models in\ndensity estimation and strongly outperforms them in forecasting.",
          "link": "http://arxiv.org/abs/2311.01139",
          "publishedOn": "2023-11-04T00:42:37.416Z",
          "wordCount": null,
          "title": "Add and Thin: Diffusion for Temporal Point Processes. (arXiv:2311.01139v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.12658",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bayraktar_E/0/1/0/all/0/1\">Erhan Bayraktar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Han_B/0/1/0/all/0/1\">Bingyan Han</a>",
          "description": "We develop a fitted value iteration (FVI) method to compute bicausal optimal\ntransport (OT) where couplings have an adapted structure. Based on the dynamic\nprogramming formulation, FVI adopts a function class to approximate the value\nfunctions in bicausal OT. Under the concentrability condition and approximate\ncompleteness assumption, we prove the sample complexity using (local)\nRademacher complexity. Furthermore, we demonstrate that multilayer neural\nnetworks with appropriate structures satisfy the crucial assumptions required\nin sample complexity proofs. Numerical experiments reveal that FVI outperforms\nlinear programming and adapted Sinkhorn methods in scalability as the time\nhorizon increases, while still maintaining acceptable accuracy.",
          "link": "http://arxiv.org/abs/2306.12658",
          "publishedOn": "2023-11-04T00:42:37.416Z",
          "wordCount": null,
          "title": "Fitted Value Iteration Methods for Bicausal Optimal Transport. (arXiv:2306.12658v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.07843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuangning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niell_L/0/1/0/all/0/1\">Lluis Salvat Niell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Sung Won Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nahum_Shani_I/0/1/0/all/0/1\">Inbal Nahum-Shani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shani_G/0/1/0/all/0/1\">Guy Shani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_S/0/1/0/all/0/1\">Susan Murphy</a>",
          "description": "Mobile health aims to enhance health outcomes by delivering interventions to\nindividuals as they go about their daily life. The involvement of care partners\nand social support networks often proves crucial in helping individuals\nmanaging burdensome medical conditions. This presents opportunities in mobile\nhealth to design interventions that target the dyadic relationship -- the\nrelationship between a target person and their care partner -- with the aim of\nenhancing social support. In this paper, we develop dyadic RL, an online\nreinforcement learning algorithm designed to personalize intervention delivery\nbased on contextual factors and past responses of a target person and their\ncare partner. Here, multiple sets of interventions impact the dyad across\nmultiple time intervals. The developed dyadic RL is Bayesian and hierarchical.\nWe formally introduce the problem setup, develop dyadic RL and establish a\nregret bound. We demonstrate dyadic RL's empirical performance through\nsimulation studies on both toy scenarios and on a realistic test bed\nconstructed from data collected in a mobile health study.",
          "link": "http://arxiv.org/abs/2308.07843",
          "publishedOn": "2023-11-04T00:42:37.416Z",
          "wordCount": null,
          "title": "Dyadic Reinforcement Learning. (arXiv:2308.07843v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01434",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bouniot_Q/0/1/0/all/0/1\">Quentin Bouniot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozharovskyi_P/0/1/0/all/0/1\">Pavlo Mozharovskyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1\">Florence d&#x27;Alch&#xe9;-Buc</a>",
          "description": "Data augmentation is an essential building block for learning efficient deep\nlearning models. Among all augmentation techniques proposed so far, linear\ninterpolation of training data points, also called mixup, has found to be\neffective for a large panel of applications. While the majority of works have\nfocused on selecting the right points to mix, or applying complex non-linear\ninterpolation, we are interested in mixing similar points more frequently and\nstrongly than less similar ones. To this end, we propose to dynamically change\nthe underlying distribution of interpolation coefficients through warping\nfunctions, depending on the similarity between data points to combine. We\ndefine an efficient and flexible framework to do so without losing in\ndiversity. We provide extensive experiments for classification and regression\ntasks, showing that our proposed method improves both performance and\ncalibration of models. Code available in\nhttps://github.com/ENSTA-U2IS/torch-uncertainty",
          "link": "http://arxiv.org/abs/2311.01434",
          "publishedOn": "2023-11-04T00:42:37.414Z",
          "wordCount": null,
          "title": "Tailoring Mixup to Data using Kernel Warping functions. (arXiv:2311.01434v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.14319",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Harkonen_M/0/1/0/all/0/1\">Marc H&#xe4;rk&#xf6;nen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lange_Hegermann_M/0/1/0/all/0/1\">Markus Lange-Hegermann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Raita_B/0/1/0/all/0/1\">Bogdan Rai&#x163;&#x103;</a>",
          "description": "Partial differential equations (PDEs) are important tools to model physical\nsystems and including them into machine learning models is an important way of\nincorporating physical knowledge. Given any system of linear PDEs with constant\ncoefficients, we propose a family of Gaussian process (GP) priors, which we\ncall EPGP, such that all realizations are exact solutions of this system. We\napply the Ehrenpreis-Palamodov fundamental principle, which works as a\nnon-linear Fourier transform, to construct GP kernels mirroring standard\nspectral methods for GPs. Our approach can infer probable solutions of linear\nPDE systems from any data such as noisy measurements, or pointwise defined\ninitial and boundary conditions. Constructing EPGP-priors is algorithmic,\ngenerally applicable, and comes with a sparse version (S-EPGP) that learns the\nrelevant spectral frequencies and works better for big data sets. We\ndemonstrate our approach on three families of systems of PDEs, the heat\nequation, wave equation, and Maxwell's equations, where we improve upon the\nstate of the art in computation time and precision, in some experiments by\nseveral orders of magnitude.",
          "link": "http://arxiv.org/abs/2212.14319",
          "publishedOn": "2023-11-04T00:42:37.414Z",
          "wordCount": null,
          "title": "Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients. (arXiv:2212.14319v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.10649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oostrum_J/0/1/0/all/0/1\">Jesse van Oostrum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hintum_P/0/1/0/all/0/1\">Peter van Hintum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ay_N/0/1/0/all/0/1\">Nihat Ay</a>",
          "description": "Variational autoencoders and Helmholtz machines use a recognition network\n(encoder) to approximate the posterior distribution of a generative model\n(decoder). In this paper we study the necessary and sufficient properties of a\nrecognition network so that it can model the true posterior distribution\nexactly. These results are derived in the general context of probabilistic\ngraphical modelling / Bayesian networks, for which the network represents a set\nof conditional independence statements. We derive both global conditions, in\nterms of d-separation, and local conditions for the recognition network to have\nthe desired qualities. It turns out that for the local conditions the property\nperfectness (for every node, all parents are joined) plays an important role.",
          "link": "http://arxiv.org/abs/2212.10649",
          "publishedOn": "2023-11-04T00:42:37.411Z",
          "wordCount": null,
          "title": "Inversion of Bayesian Networks. (arXiv:2212.10649v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01409",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ketenci_M/0/1/0/all/0/1\">Mert Ketenci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perotte_A/0/1/0/all/0/1\">Adler Perotte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhadad_N/0/1/0/all/0/1\">No&#xe9;mie Elhadad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urteaga_I/0/1/0/all/0/1\">I&#xf1;igo Urteaga</a>",
          "description": "We present a novel stochastic variational Gaussian process ($\\mathcal{GP}$)\ninference method, based on a posterior over a learnable set of weighted pseudo\ninput-output points (coresets). Instead of a free-form variational family, the\nproposed coreset-based, variational tempered family for $\\mathcal{GP}$s (CVTGP)\nis defined in terms of the $\\mathcal{GP}$ prior and the data-likelihood; hence,\naccommodating the modeling inductive biases. We derive CVTGP's lower bound for\nthe log-marginal likelihood via marginalization of the proposed posterior over\nlatent $\\mathcal{GP}$ coreset variables, and show it is amenable to stochastic\noptimization. CVTGP reduces the learnable parameter size to $\\mathcal{O}(M)$,\nenjoys numerical stability, and maintains $\\mathcal{O}(M^3)$ time- and\n$\\mathcal{O}(M^2)$ space-complexity, by leveraging a coreset-based tempered\nposterior that, in turn, provides sparse and explainable representations of the\ndata. Results on simulated and real-world regression problems with Gaussian\nobservation noise validate that CVTGP provides better evidence lower-bound\nestimates and predictive root mean squared error than alternative stochastic\n$\\mathcal{GP}$ inference methods.",
          "link": "http://arxiv.org/abs/2311.01409",
          "publishedOn": "2023-11-04T00:42:37.405Z",
          "wordCount": null,
          "title": "A Coreset-based, Tempered Variational Posterior for Accurate and Scalable Stochastic Gaussian Process Inference. (arXiv:2311.01409v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01356",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Geuchen_P/0/1/0/all/0/1\">Paul Geuchen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heindl_T/0/1/0/all/0/1\">Thomas Heindl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stoger_D/0/1/0/all/0/1\">Dominik St&#xf6;ger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Voigtlaender_F/0/1/0/all/0/1\">Felix Voigtlaender</a>",
          "description": "Empirical studies have widely demonstrated that neural networks are highly\nsensitive to small, adversarial perturbations of the input. The worst-case\nrobustness against these so-called adversarial examples can be quantified by\nthe Lipschitz constant of the neural network. However, only few theoretical\nresults regarding this quantity exist in the literature. In this paper, we\ninitiate the study of the Lipschitz constant of random ReLU neural networks,\ni.e., neural networks whose weights are chosen at random and which employ the\nReLU activation function. For shallow neural networks, we characterize the\nLipschitz constant up to an absolute numerical constant. Moreover, we extend\nour analysis to deep neural networks of sufficiently large width where we prove\nupper and lower bounds for the Lipschitz constant. These bounds match up to a\nlogarithmic factor that depends on the depth.",
          "link": "http://arxiv.org/abs/2311.01356",
          "publishedOn": "2023-11-04T00:42:37.402Z",
          "wordCount": null,
          "title": "On the Lipschitz constant of random neural networks. (arXiv:2311.01356v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2311.01349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weber_T/0/1/0/all/0/1\">Tobias Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ingrisch_M/0/1/0/all/0/1\">Michael Ingrisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1\">David R&#xfc;gamer</a>",
          "description": "Purpose: To analyze and remove protected feature effects in chest radiograph\nembeddings of deep learning models.\n\nMaterials and Methods: An orthogonalization is utilized to remove the\ninfluence of protected features (e.g., age, sex, race) in chest radiograph\nembeddings, ensuring feature-independent results. To validate the efficacy of\nthe approach, we retrospectively study the MIMIC and CheXpert datasets using\nthree pre-trained models, namely a supervised contrastive, a self-supervised\ncontrastive, and a baseline classifier model. Our statistical analysis involves\ncomparing the original versus the orthogonalized embeddings by estimating\nprotected feature influences and evaluating the ability to predict race, age,\nor sex using the two types of embeddings.\n\nResults: Our experiments reveal a significant influence of protected features\non predictions of pathologies. Applying orthogonalization removes these feature\neffects. Apart from removing any influence on pathology classification, while\nmaintaining competitive predictive performance, orthogonalized embeddings\nfurther make it infeasible to directly predict protected attributes and\nmitigate subgroup disparities.\n\nConclusion: The presented work demonstrates the successful application and\nevaluation of the orthogonalization technique in the domain of chest X-ray\nclassification.",
          "link": "http://arxiv.org/abs/2311.01349",
          "publishedOn": "2023-11-04T00:42:36.886Z",
          "wordCount": null,
          "title": "Unreading Race: Purging Protected Features from Chest X-ray Embeddings. (arXiv:2311.01349v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.09721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiaxin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "We provide the first finite-particle convergence rate for Stein variational\ngradient descent (SVGD), a popular algorithm for approximating a probability\ndistribution with a collection of particles. Specifically, whenever the target\ndistribution is sub-Gaussian with a Lipschitz score, SVGD with n particles and\nan appropriate step size sequence drives the kernel Stein discrepancy to zero\nat an order 1/sqrt(log log n) rate. We suspect that the dependence on n can be\nimproved, and we hope that our explicit, non-asymptotic proof strategy will\nserve as a template for future refinements.",
          "link": "http://arxiv.org/abs/2211.09721",
          "publishedOn": "2023-11-04T00:42:36.886Z",
          "wordCount": null,
          "title": "A Finite-Particle Convergence Rate for Stein Variational Gradient Descent. (arXiv:2211.09721v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.08529",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_Z/0/1/0/all/0/1\">Zhaolu Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Peach_R/0/1/0/all/0/1\">Robert L. Peach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Laumann_F/0/1/0/all/0/1\">Felix Laumann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mengod_S/0/1/0/all/0/1\">Sara Vallejo Mengod</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Barahona_M/0/1/0/all/0/1\">Mauricio Barahona</a>",
          "description": "Multivariate time series data that capture the temporal evolution of\ninterconnected systems are ubiquitous in diverse areas. Understanding the\ncomplex relationships and potential dependencies among co-observed variables is\ncrucial for the accurate statistical modelling and analysis of such systems.\nHere, we introduce kernel-based statistical tests of joint independence in\nmultivariate time series by extending the $d$-variable Hilbert-Schmidt\nindependence criterion (dHSIC) to encompass both stationary and non-stationary\nprocesses, thus allowing broader real-world applications. By leveraging\nresampling techniques tailored for both single- and multiple-realisation time\nseries, we show how the method robustly uncovers significant higher-order\ndependencies in synthetic examples, including frequency mixing data and logic\ngates, as well as real-world climate, neuroscience, and socioeconomic data. Our\nmethod adds to the mathematical toolbox for the analysis of multivariate time\nseries and can aid in uncovering high-order interactions in data.",
          "link": "http://arxiv.org/abs/2305.08529",
          "publishedOn": "2023-11-04T00:42:36.844Z",
          "wordCount": null,
          "title": "Kernel-based Joint Independence Tests for Multivariate Stationary and Non-stationary Time Series. (arXiv:2305.08529v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.19793",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bietti_A/0/1/0/all/0/1\">Alberto Bietti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1\">Loucas Pillaud-Vivien</a>",
          "description": "We study gradient flow on the multi-index regression problem for\nhigh-dimensional Gaussian data. Multi-index functions consist of a composition\nof an unknown low-rank linear projection and an arbitrary unknown,\nlow-dimensional link function. As such, they constitute a natural template for\nfeature learning in neural networks.\n\nWe consider a two-timescale algorithm, whereby the low-dimensional link\nfunction is learnt with a non-parametric model infinitely faster than the\nsubspace parametrizing the low-rank projection. By appropriately exploiting the\nmatrix semigroup structure arising over the subspace correlation matrices, we\nestablish global convergence of the resulting Grassmannian population gradient\nflow dynamics, and provide a quantitative description of its associated\n`saddle-to-saddle' dynamics. Notably, the timescales associated with each\nsaddle can be explicitly characterized in terms of an appropriate Hermite\ndecomposition of the target link function. In contrast with these positive\nresults, we also show that the related \\emph{planted} problem, where the link\nfunction is known and fixed, in fact has a rough optimization landscape, in\nwhich gradient flow dynamics might get trapped with high probability.",
          "link": "http://arxiv.org/abs/2310.19793",
          "publishedOn": "2023-11-04T00:42:36.813Z",
          "wordCount": null,
          "title": "On Learning Gaussian Multi-index Models with Gradient Flow. (arXiv:2310.19793v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hadiji_H/0/1/0/all/0/1\">H&#xe9;di Hadiji</a> (L2S), <a href=\"http://arxiv.org/find/cs/1/au:+Sachs_S/0/1/0/all/0/1\">Sarah Sachs</a> (UvA), <a href=\"http://arxiv.org/find/cs/1/au:+Erven_T/0/1/0/all/0/1\">Tim van Erven</a> (UvA), <a href=\"http://arxiv.org/find/cs/1/au:+Koolen_W/0/1/0/all/0/1\">Wouter M. Koolen</a> (CWI)",
          "description": "In the first-order query model for zero-sum $K\\times K$ matrix games, players\nobserve the expected pay-offs for all their possible actions under the\nrandomized action played by their opponent. This classical model has received\nrenewed interest after the discovery by Rakhlin and Sridharan that\n$\\epsilon$-approximate Nash equilibria can be computed efficiently from\n$O(\\frac{\\ln K}{\\epsilon})$ instead of $O(\\frac{\\ln K}{\\epsilon^2})$ queries.\nSurprisingly, the optimal number of such queries, as a function of both\n$\\epsilon$ and $K$, is not known. We make progress on this question on two\nfronts. First, we fully characterise the query complexity of learning exact\nequilibria ($\\epsilon=0$), by showing that they require a number of queries\nthat is linear in $K$, which means that it is essentially as hard as querying\nthe whole matrix, which can also be done with $K$ queries. Second, for\n$\\epsilon > 0$, the current query complexity upper bound stands at\n$O(\\min(\\frac{\\ln(K)}{\\epsilon} , K))$. We argue that, unfortunately, obtaining\na matching lower bound is not possible with existing techniques: we prove that\nno lower bound can be derived by constructing hard matrices whose entries take\nvalues in a known countable set, because such matrices can be fully identified\nby a single query. This rules out, for instance, reducing to an optimization\nproblem over the hypercube by encoding it as a binary payoff matrix. We then\nintroduce a new technique for lower bounds, which allows us to obtain lower\nbounds of order $\\tilde\\Omega(\\log(\\frac{1}{K\\epsilon})$ for any $\\epsilon \\leq\n1 / (cK^4)$, where $c$ is a constant independent of $K$. We further discuss\npossible future directions to improve on our techniques in order to close the\ngap with the upper bounds.",
          "link": "http://arxiv.org/abs/2304.12768",
          "publishedOn": "2023-11-04T00:42:36.788Z",
          "wordCount": null,
          "title": "Towards Characterizing the First-order Query Complexity of Learning (Approximate) Nash Equilibria in Zero-sum Matrix Games. (arXiv:2304.12768v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15208",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gao_R/0/1/0/all/0/1\">Richard Gao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deistler_M/0/1/0/all/0/1\">Michael Deistler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Macke_J/0/1/0/all/0/1\">Jakob H. Macke</a>",
          "description": "Simulation-based inference (SBI) enables amortized Bayesian inference for\nsimulators with implicit likelihoods. But when we are primarily interested in\nthe quality of predictive simulations, or when the model cannot exactly\nreproduce the observed data (i.e., is misspecified), targeting the Bayesian\nposterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims\nto robustify inference for (misspecified) simulator models, replacing the\nlikelihood-function with a cost function that evaluates the goodness of\nparameters relative to data. However, GBI methods generally require running\nmultiple simulations to estimate the cost function at each parameter value\nduring inference, making the approach computationally infeasible for even\nmoderately complex simulators. Here, we propose amortized cost estimation (ACE)\nfor GBI to address this challenge: We train a neural network to approximate the\ncost function, which we define as the expected distance between simulations\nproduced by a parameter and observed data. The trained network can then be used\nwith MCMC to infer GBI posteriors for any observation without running\nadditional simulations. We show that, on several benchmark tasks, ACE\naccurately predicts cost and provides predictive simulations that are closer to\nsynthetic observations than other SBI methods, especially for misspecified\nsimulators. Finally, we apply ACE to infer parameters of the Hodgkin-Huxley\nmodel given real intracellular recordings from the Allen Cell Types Database.\nACE identifies better data-matching parameters while being an order of\nmagnitude more simulation-efficient than a standard SBI method. In summary, ACE\ncombines the strengths of SBI methods and GBI to perform robust and\nsimulation-amortized inference for scientific simulators.",
          "link": "http://arxiv.org/abs/2305.15208",
          "publishedOn": "2023-11-04T00:42:36.770Z",
          "wordCount": null,
          "title": "Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation. (arXiv:2305.15208v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.10284",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gregoratti_D/0/1/0/all/0/1\">David Gregoratti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mestre_X/0/1/0/all/0/1\">Xavier Mestre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buelga_C/0/1/0/all/0/1\">Carlos Buelga</a>",
          "description": "A structured variable selection problem is considered in which the\ncovariates, divided into predefined groups, activate according to sparse\npatterns with few nonzero entries per group. Capitalizing on the concept of\natomic norm, a composite norm can be properly designed to promote such\nexclusive group sparsity patterns. The resulting norm lends itself to efficient\nand flexible regularized optimization algorithms for support recovery, like the\nproximal algorithm. Moreover, an active set algorithm is proposed that builds\nthe solution by successively including structure atoms into the estimated\nsupport. It is also shown that such an algorithm can be tailored to match more\nrigid structures than plain exclusive group sparsity. Asymptotic consistency\nanalysis (with both the number of parameters as well as the number of groups\ngrowing with the observation size) establishes the effectiveness of the\nproposed solution in terms of signed support recovery under conventional\nassumptions. Finally, a set of numerical simulations further corroborates the\nresults.",
          "link": "http://arxiv.org/abs/2108.10284",
          "publishedOn": "2023-11-04T00:42:36.702Z",
          "wordCount": null,
          "title": "Exclusive Group Lasso for Structured Variable Selection. (arXiv:2108.10284v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.12835",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Barp_A/0/1/0/all/0/1\">Alessandro Barp</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Simon_Gabriel_C/0/1/0/all/0/1\">Carl-Johann Simon-Gabriel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">Mark Girolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "Maximum mean discrepancies (MMDs) like the kernel Stein discrepancy (KSD)\nhave grown central to a wide range of applications, including hypothesis\ntesting, sampler selection, distribution approximation, and variational\ninference. In each setting, these kernel-based discrepancy measures are\nrequired to (i) separate a target P from other probability measures or even\n(ii) control weak convergence to P. In this article we derive new sufficient\nand necessary conditions to ensure (i) and (ii). For MMDs on separable metric\nspaces, we characterize those kernels that separate Bochner embeddable measures\nand introduce simple conditions for separating all measures with unbounded\nkernels and for controlling convergence with bounded kernels. We use these\nresults on $\\mathbb{R}^d$ to substantially broaden the known conditions for KSD\nseparation and convergence control and to develop the first KSDs known to\nexactly metrize weak convergence to P. Along the way, we highlight the\nimplications of our results for hypothesis testing, measuring and improving\nsample quality, and sampling with Stein variational gradient descent.",
          "link": "http://arxiv.org/abs/2209.12835",
          "publishedOn": "2023-11-04T00:42:36.371Z",
          "wordCount": 679,
          "title": "Targeted Separation and Convergence with Kernel Discrepancies. (arXiv:2209.12835v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15572",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kaiwen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kyurae Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garnett_R/0/1/0/all/0/1\">Roman Garnett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1\">Jacob R. Gardner</a>",
          "description": "A recent development in Bayesian optimization is the use of local\noptimization strategies, which can deliver strong empirical performance on\nhigh-dimensional problems compared to traditional global strategies. The \"folk\nwisdom\" in the literature is that the focus on local optimization sidesteps the\ncurse of dimensionality; however, little is known concretely about the expected\nbehavior or convergence of Bayesian local optimization routines. We first study\nthe behavior of the local approach, and find that the statistics of individual\nlocal solutions of Gaussian process sample paths are surprisingly good compared\nto what we would expect to recover from global methods. We then present the\nfirst rigorous analysis of such a Bayesian local optimization algorithm\nrecently proposed by M\\\"uller et al. (2021), and derive convergence rates in\nboth the noisy and noiseless settings.",
          "link": "http://arxiv.org/abs/2305.15572",
          "publishedOn": "2023-11-04T00:42:36.365Z",
          "wordCount": 657,
          "title": "The Behavior and Convergence of Local Bayesian Optimization. (arXiv:2305.15572v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2005.05163",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Ren_Y/0/1/0/all/0/1\">Yuanfang Ren</a> (1) (2), <a href=\"http://arxiv.org/find/q-bio/1/au:+Balch_J/0/1/0/all/0/1\">Jeremy Balch</a> (3), <a href=\"http://arxiv.org/find/q-bio/1/au:+Abbott_K/0/1/0/all/0/1\">Kenneth L. Abbott</a> (3), <a href=\"http://arxiv.org/find/q-bio/1/au:+Loftus_T/0/1/0/all/0/1\">Tyler J. Loftus</a> (1) (3), <a href=\"http://arxiv.org/find/q-bio/1/au:+Shickel_B/0/1/0/all/0/1\">Benjamin Shickel</a> (1) (2), <a href=\"http://arxiv.org/find/q-bio/1/au:+Rashidi_P/0/1/0/all/0/1\">Parisa Rashidi</a> (1) (4), <a href=\"http://arxiv.org/find/q-bio/1/au:+Bihorac_A/0/1/0/all/0/1\">Azra Bihorac</a> (1) (2), <a href=\"http://arxiv.org/find/q-bio/1/au:+Ozrazgat_Baslanti_T/0/1/0/all/0/1\">Tezcan Ozrazgat-Baslanti</a> (1) (2) ((1) Intelligent Clinical Care Center (IC3), University of Florida, Gainesville, FL, USA, (2) Department of Medicine, College of Medicine, University of Florida, Gainesville, FL, USA, (3) Department of Surgery, College of Medicine, University of Florida, Gainesville, FL, USA, (4) J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, FL)",
          "description": "Continuous monitoring and patient acuity assessments are key aspects of\nIntensive Care Unit (ICU) practice, but both are limited by time constraints\nimposed on healthcare providers. Moreover, anticipating clinical trajectories\nremains imprecise. The objectives of this study are to (1) develop an\nelectronic phenotype of acuity using automated variable retrieval within the\nelectronic health records and (2) describe transitions between acuity states\nthat illustrate the clinical trajectories of ICU patients. We gathered two\nsingle-center, longitudinal electronic health record datasets for 51,372 adult\nICU patients admitted to the University of Florida Health (UFH) Gainesville\n(GNV) and Jacksonville (JAX). We developed algorithms to quantify acuity status\nat four-hour intervals for each ICU admission and identify acuity phenotypes\nusing continuous acuity status and k-means clustering approach. 51,073\nadmissions for 38,749 patients in the UFH GNV dataset and 22,219 admissions for\n12,623 patients in the UFH JAX dataset had at least one ICU stay lasting more\nthan four hours. There were three phenotypes: persistently stable, persistently\nunstable, and transitioning from unstable to stable. For stable patients,\napproximately 0.7%-1.7% would transition to unstable, 0.02%-0.1% would expire,\n1.2%-3.4% would be discharged, and the remaining 96%-97% would remain stable in\nthe ICU every four hours. For unstable patients, approximately 6%-10% would\ntransition to stable, 0.4%-0.5% would expire, and the remaining 89%-93% would\nremain unstable in the ICU in the next four hours. We developed phenotyping\nalgorithms for patient acuity status every four hours while admitted to the\nICU. This approach may be useful in developing prognostic and clinical\ndecision-support tools to aid patients, caregivers, and providers in shared\ndecision-making processes regarding escalation of care and patient values.",
          "link": "http://arxiv.org/abs/2005.05163",
          "publishedOn": "2023-11-04T00:42:36.307Z",
          "wordCount": 877,
          "title": "Computable Phenotypes of Patient Acuity in the Intensive Care Unit. (arXiv:2005.05163v2 [q-bio.QM] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.07769",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kadhim_A/0/1/0/all/0/1\">Ali Al Kadhim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Prosper_H/0/1/0/all/0/1\">Harrison B. Prosper</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Prosper_O/0/1/0/all/0/1\">Olivia F. Prosper</a>",
          "description": "High-fidelity simulators that connect theoretical models with observations\nare indispensable tools in many sciences. When coupled with machine learning, a\nsimulator makes it possible to infer the parameters of a theoretical model\ndirectly from real and simulated observations without explicit use of the\nlikelihood function. This is of particular interest when the latter is\nintractable. In this work, we introduce a simple extension of the recently\nproposed likelihood-free frequentist inference (LF2I) approach that has some\ncomputational advantages. Like LF2I, this extension yields provably valid\nconfidence sets in parameter inference problems in which a high-fidelity\nsimulator is available. The utility of our algorithm is illustrated by applying\nit to three pedagogically interesting examples: the first is from cosmology,\nthe second from high-energy physics and astronomy, both with tractable\nlikelihoods, while the third, with an intractable likelihood, is from\nepidemiology.",
          "link": "http://arxiv.org/abs/2306.07769",
          "publishedOn": "2023-11-04T00:42:36.184Z",
          "wordCount": 667,
          "title": "Amortized Simulation-Based Frequentist Inference for Tractable and Intractable Likelihoods. (arXiv:2306.07769v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2203.05164",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ebers_M/0/1/0/all/0/1\">Megan R. Ebers</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steele_K/0/1/0/all/0/1\">Katherine M. Steele</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kutz_J/0/1/0/all/0/1\">J. Nathan Kutz</a>",
          "description": "Physics-based and first-principles models pervade the engineering and\nphysical sciences, allowing for the ability to model the dynamics of complex\nsystems with a prescribed accuracy. The approximations used in deriving\ngoverning equations often result in discrepancies between the model and\nsensor-based measurements of the system, revealing the approximate nature of\nthe equations and/or the signal-to-noise ratio of the sensor itself. In modern\ndynamical systems, such discrepancies between model and measurement can lead to\npoor quantification, often undermining the ability to produce accurate and\nprecise control algorithms. We introduce a discrepancy modeling framework to\nidentify the missing physics and resolve the model-measurement mismatch with\ntwo distinct approaches: (i) by learning a model for the evolution of\nsystematic state-space residual, and (ii) by discovering a model for the\ndeterministic dynamical error. Regardless of approach, a common suite of\ndata-driven model discovery methods can be used. The choice of method depends\non one's intent (e.g., mechanistic interpretability) for discrepancy modeling,\nsensor measurement characteristics (e.g., quantity, quality, resolution), and\nconstraints imposed by practical applications (e.g., modeling approaches using\nthe suite of data-driven modeling methods on three continuous dynamical systems\nunder varying signal-to-noise ratios. Finally, we emphasize structural\nshortcomings of each discrepancy modeling approach depending on error type. In\nsummary, if the true dynamics are unknown (i.e., an imperfect model), one\nshould learn a discrepancy model of the missing physics in the dynamical space.\nYet, if the true dynamics are known yet model-measurement mismatch still\nexists, one should learn a discrepancy model in the state space.",
          "link": "http://arxiv.org/abs/2203.05164",
          "publishedOn": "2023-11-04T00:42:36.160Z",
          "wordCount": 807,
          "title": "Discrepancy Modeling Framework: Learning missing physics, modeling systematic residuals, and disambiguating between deterministic and random effects. (arXiv:2203.05164v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.01638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiaxin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Ke Alexander Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_E/0/1/0/all/0/1\">Emily B. Fox</a>",
          "description": "Efficiently capturing the long-range patterns in sequential data sources\nsalient to a given task -- such as classification and generative modeling --\nposes a fundamental challenge. Popular approaches in the space tradeoff between\nthe memory burden of brute-force enumeration and comparison, as in\ntransformers, the computational burden of complicated sequential dependencies,\nas in recurrent neural networks, or the parameter burden of convolutional\nnetworks with many or large filters. We instead take inspiration from\nwavelet-based multiresolution analysis to define a new building block for\nsequence modeling, which we call a MultiresLayer. The key component of our\nmodel is the multiresolution convolution, capturing multiscale trends in the\ninput sequence. Our MultiresConv can be implemented with shared filters across\na dilated causal convolution tree. Thus it garners the computational advantages\nof convolutional networks and the principled theoretical motivation of wavelet\ndecompositions. Our MultiresLayer is straightforward to implement, requires\nsignificantly fewer parameters, and maintains at most a $\\mathcal{O}(N\\log N)$\nmemory footprint for a length $N$ sequence. Yet, by stacking such layers, our\nmodel yields state-of-the-art performance on a number of sequence\nclassification and autoregressive density estimation tasks using CIFAR-10,\nListOps, and PTB-XL datasets.",
          "link": "http://arxiv.org/abs/2305.01638",
          "publishedOn": "2023-11-04T00:42:36.154Z",
          "wordCount": 721,
          "title": "Sequence Modeling with Multiresolution Convolutional Memory. (arXiv:2305.01638v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.12783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Auer_A/0/1/0/all/0/1\">Andreas Auer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gauch_M/0/1/0/all/0/1\">Martin Gauch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klotz_D/0/1/0/all/0/1\">Daniel Klotz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>",
          "description": "To quantify uncertainty, conformal prediction methods are gaining\ncontinuously more interest and have already been successfully applied to\nvarious domains. However, they are difficult to apply to time series as the\nautocorrelative structure of time series violates basic assumptions required by\nconformal prediction. We propose HopCPT, a novel conformal prediction approach\nfor time series that not only copes with temporal structures but leverages\nthem. We show that our approach is theoretically well justified for time series\nwhere temporal dependencies are present. In experiments, we demonstrate that\nour new approach outperforms state-of-the-art conformal prediction methods on\nmultiple real-world time series datasets from four different domains.",
          "link": "http://arxiv.org/abs/2303.12783",
          "publishedOn": "2023-11-04T00:42:36.147Z",
          "wordCount": 642,
          "title": "Conformal Prediction for Time Series with Modern Hopfield Networks. (arXiv:2303.12783v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.06157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kelshaw_D/0/1/0/all/0/1\">Daniel Kelshaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magri_L/0/1/0/all/0/1\">Luca Magri</a>",
          "description": "Manifolds discovered by machine learning models provide a compact\nrepresentation of the underlying data. Geodesics on these manifolds define\nlocally length-minimising curves and provide a notion of distance, which are\nkey for reduced-order modelling, statistical inference, and interpolation. In\nthis work, we propose a model-based parameterisation for distance fields and\ngeodesic flows on manifolds, exploiting solutions of a manifold-augmented\nEikonal equation. We demonstrate how the geometry of the manifold impacts the\ndistance field, and exploit the geodesic flow to obtain globally\nlength-minimising curves directly. This work opens opportunities for statistics\nand reduced-order modelling on differentiable manifolds.",
          "link": "http://arxiv.org/abs/2310.06157",
          "publishedOn": "2023-11-04T00:42:36.123Z",
          "wordCount": 633,
          "title": "Manifold-augmented Eikonal Equations: Geodesic Distances and Flows on Differentiable Manifolds. (arXiv:2310.06157v2 [cs.CG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.04040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yiheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jialu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1\">Chaowen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jiahuan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Chang-Yu Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_T/0/1/0/all/0/1\">Tingjun Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>",
          "description": "Many crucial scientific problems involve designing novel molecules with\ndesired properties, which can be formulated as a black-box optimization problem\nover the discrete chemical space. In practice, multiple conflicting objectives\nand costly evaluations (e.g., wet-lab experiments) make the diversity of\ncandidates paramount. Computational methods have achieved initial success but\nstill struggle with considering diversity in both objective and search space.\nTo fill this gap, we propose a multi-objective Bayesian optimization (MOBO)\nalgorithm leveraging the hypernetwork-based GFlowNets (HN-GFN) as an\nacquisition function optimizer, with the purpose of sampling a diverse batch of\ncandidate molecular graphs from an approximate Pareto front. Using a single\npreference-conditioned hypernetwork, HN-GFN learns to explore various\ntrade-offs between objectives. We further propose a hindsight-like off-policy\nstrategy to share high-performing molecules among different preferences in\norder to speed up learning for HN-GFN. We empirically illustrate that HN-GFN\nhas adequate capacity to generalize over preferences. Moreover, experiments in\nvarious real-world MOBO settings demonstrate that our framework predominantly\noutperforms existing methods in terms of candidate quality and sample\nefficiency. The code is available at https://github.com/violet-sto/HN-GFN.",
          "link": "http://arxiv.org/abs/2302.04040",
          "publishedOn": "2023-11-04T00:42:36.113Z",
          "wordCount": 701,
          "title": "Sample-efficient Multi-objective Molecular Optimization with GFlowNets. (arXiv:2302.04040v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.06950",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yang_R/0/1/0/all/0/1\">Ruihan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "This paper outlines an end-to-end optimized lossy image compression framework\nusing diffusion generative models. The approach relies on the transform coding\nparadigm, where an image is mapped into a latent space for entropy coding and,\nfrom there, mapped back to the data space for reconstruction. In contrast to\nVAE-based neural compression, where the (mean) decoder is a deterministic\nneural network, our decoder is a conditional diffusion model. Our approach thus\nintroduces an additional \"content\" latent variable on which the reverse\ndiffusion process is conditioned and uses this variable to store information\nabout the image. The remaining \"texture\" variables characterizing the diffusion\nprocess are synthesized at decoding time. We show that the model's performance\ncan be tuned toward perceptual metrics of interest. Our extensive experiments\ninvolving multiple datasets and image quality assessment metrics show that our\napproach yields stronger reported FID scores than the GAN-based model, while\nalso yielding competitive performance with VAE-based models in several\ndistortion metrics. Furthermore, training the diffusion with X-parameterization\nenables high-quality reconstructions in only a handful of decoding steps,\ngreatly affecting the model's practicality.",
          "link": "http://arxiv.org/abs/2209.06950",
          "publishedOn": "2023-11-04T00:42:36.051Z",
          "wordCount": 742,
          "title": "Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v6 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.00871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yadlowsky_S/0/1/0/all/0/1\">Steve Yadlowsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_L/0/1/0/all/0/1\">Lyric Doshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tripuraneni_N/0/1/0/all/0/1\">Nilesh Tripuraneni</a>",
          "description": "Transformer models, notably large language models (LLMs), have the remarkable\nability to perform in-context learning (ICL) -- to perform new tasks when\nprompted with unseen input-output examples without any explicit model training.\nIn this work, we study how effectively transformers can bridge between their\npretraining data mixture, comprised of multiple distinct task families, to\nidentify and learn new tasks in-context which are both inside and outside the\npretraining distribution. Building on previous work, we investigate this\nquestion in a controlled setting, where we study transformer models trained on\nsequences of $(x, f(x))$ pairs rather than natural language. Our empirical\nresults show transformers demonstrate near-optimal unsupervised model selection\ncapabilities, in their ability to first in-context identify different task\nfamilies and in-context learn within them when the task families are\nwell-represented in their pretraining data. However when presented with tasks\nor functions which are out-of-domain of their pretraining data, we demonstrate\nvarious failure modes of transformers and degradation of their generalization\nfor even simple extrapolation tasks. Together our results highlight that the\nimpressive ICL abilities of high-capacity sequence models may be more closely\ntied to the coverage of their pretraining data mixtures than inductive biases\nthat create fundamental generalization capabilities.",
          "link": "http://arxiv.org/abs/2311.00871",
          "publishedOn": "2023-11-04T00:42:36.022Z",
          "wordCount": 720,
          "title": "Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models. (arXiv:2311.00871v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xinyuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1\">Santosh S. Vempala</a>",
          "description": "We give a polynomial-time algorithm for learning high-dimensional halfspaces\nwith margins in $d$-dimensional space to within desired TV distance when the\nambient distribution is an unknown affine transformation of the $d$-fold\nproduct of an (unknown) symmetric one-dimensional logconcave distribution, and\nthe halfspace is introduced by deleting at least an $\\epsilon$ fraction of the\ndata in one of the component distributions. Notably, our algorithm does not\nneed labels and establishes the unique (and efficient) identifiability of the\nhidden halfspace under this distributional assumption. The sample and time\ncomplexity of the algorithm are polynomial in the dimension and $1/\\epsilon$.\nThe algorithm uses only the first two moments of suitable re-weightings of the\nempirical distribution, which we call contrastive moments; its analysis uses\nclassical facts about generalized Dirichlet polynomials and relies crucially on\na new monotonicity property of the moment ratio of truncations of logconcave\ndistributions. Such algorithms, based only on first and second moments were\nsuggested in earlier work, but hitherto eluded rigorous guarantees.\n\nPrior work addressed the special case when the underlying distribution is\nGaussian via Non-Gaussian Component Analysis. We improve on this by providing\npolytime guarantees based on Total Variation (TV) distance, in place of\nexisting moment-bound guarantees that can be super-polynomial. Our work is also\nthe first to go beyond Gaussians in this setting.",
          "link": "http://arxiv.org/abs/2311.01435",
          "publishedOn": "2023-11-04T00:42:36.016Z",
          "wordCount": 729,
          "title": "Contrastive Moments: Unsupervised Halfspace Learning in Polynomial Time. (arXiv:2311.01435v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.00866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yujia Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>",
          "description": "Nonlinear independent component analysis (ICA) aims to uncover the true\nlatent sources from their observable nonlinear mixtures. Despite its\nsignificance, the identifiability of nonlinear ICA is known to be impossible\nwithout additional assumptions. Recent advances have proposed conditions on the\nconnective structure from sources to observed variables, known as Structural\nSparsity, to achieve identifiability in an unsupervised manner. However, the\nsparsity constraint may not hold universally for all sources in practice.\nFurthermore, the assumptions of bijectivity of the mixing process and\nindependence among all sources, which arise from the setting of ICA, may also\nbe violated in many real-world scenarios. To address these limitations and\ngeneralize nonlinear ICA, we propose a set of new identifiability results in\nthe general settings of undercompleteness, partial sparsity and source\ndependence, and flexible grouping structures. Specifically, we prove\nidentifiability when there are more observed variables than sources\n(undercomplete), and when certain sparsity and/or source independence\nassumptions are not met for some changing sources. Moreover, we show that even\nin cases with flexible grouping structures (e.g., part of the sources can be\ndivided into irreducible independent groups with various sizes), appropriate\nidentifiability results can also be established. Theoretical claims are\nsupported empirically on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2311.00866",
          "publishedOn": "2023-11-04T00:42:36.009Z",
          "wordCount": 703,
          "title": "Generalizing Nonlinear ICA Beyond Structural Sparsity. (arXiv:2311.00866v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.00944",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_M/0/1/0/all/0/1\">Minhui Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiawei Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1\">Cong Shen</a>",
          "description": "In recent years, federated minimax optimization has attracted growing\ninterest due to its extensive applications in various machine learning tasks.\nWhile Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved\nits success in centralized nonconvex minimax optimization, how and whether\nsmoothing technique could be helpful in federated setting remains unexplored.\nIn this paper, we propose a new algorithm termed Federated Stochastic Smoothed\nGradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for\nfederated minimax optimization. We prove that FESS-GDA can be uniformly used to\nsolve several classes of federated minimax problems and prove new or better\nanalytical convergence results for these settings. We showcase the practical\nefficiency of FESS-GDA in practical federated learning tasks of training\ngenerative adversarial networks (GANs) and fair classification.",
          "link": "http://arxiv.org/abs/2311.00944",
          "publishedOn": "2023-11-04T00:42:36.002Z",
          "wordCount": 635,
          "title": "Stochastic Smoothed Gradient Descent Ascent for Federated Minimax Optimization. (arXiv:2311.00944v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.00927",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pham_T/0/1/0/all/0/1\">Thong Pham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shimizu_S/0/1/0/all/0/1\">Shohei Shimizu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hino_H/0/1/0/all/0/1\">Hideitsu Hino</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1\">Tam Le</a>",
          "description": "We consider the problem of estimating the counterfactual joint distribution\nof multiple quantities of interests (e.g., outcomes) in a multivariate causal\nmodel extended from the classical difference-in-difference design. Existing\nmethods for this task either ignore the correlation structures among dimensions\nof the multivariate outcome by considering univariate causal models on each\ndimension separately and hence produce incorrect counterfactual distributions,\nor poorly scale even for moderate-size datasets when directly dealing with such\nmultivariate causal model. We propose a method that alleviates both issues\nsimultaneously by leveraging a robust latent one-dimensional subspace of the\noriginal high-dimension space and exploiting the efficient estimation from the\nunivariate causal model on such space. Since the construction of the\none-dimensional subspace uses information from all the dimensions, our method\ncan capture the correlation structures and produce good estimates of the\ncounterfactual distribution. We demonstrate the advantages of our approach over\nexisting methods on both synthetic and real-world data.",
          "link": "http://arxiv.org/abs/2311.00927",
          "publishedOn": "2023-11-04T00:42:35.989Z",
          "wordCount": 655,
          "title": "Scalable Counterfactual Distribution Estimation in Multivariate Causal Models. (arXiv:2311.00927v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01052",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Letzelter_V/0/1/0/all/0/1\">Victor Letzelter</a> (S2A, IDS), <a href=\"http://arxiv.org/find/stat/1/au:+Fontaine_M/0/1/0/all/0/1\">Mathieu Fontaine</a> (S2A, IDS), <a href=\"http://arxiv.org/find/stat/1/au:+Chen_M/0/1/0/all/0/1\">Micka&#xeb;l Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Perez_P/0/1/0/all/0/1\">Patrick P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Richard_G/0/1/0/all/0/1\">Gael Richard</a> (S2A, IDS), <a href=\"http://arxiv.org/find/stat/1/au:+Essid_S/0/1/0/all/0/1\">Slim Essid</a> (IDS, S2A)",
          "description": "We introduce Resilient Multiple Choice Learning (rMCL), an extension of the\nMCL approach for conditional distribution estimation in regression settings\nwhere multiple targets may be sampled for each training input. Multiple Choice\nLearning is a simple framework to tackle multimodal density estimation, using\nthe Winner-Takes-All (WTA) loss for a set of hypotheses. In regression\nsettings, the existing MCL variants focus on merging the hypotheses, thereby\neventually sacrificing the diversity of the predictions. In contrast, our\nmethod relies on a novel learned scoring scheme underpinned by a mathematical\nframework based on Voronoi tessellations of the output space, from which we can\nderive a probabilistic interpretation. After empirically validating rMCL with\nexperiments on synthetic data, we further assess its merits on the sound source\nlocalization problem, demonstrating its practical usefulness and the relevance\nof its interpretation.",
          "link": "http://arxiv.org/abs/2311.01052",
          "publishedOn": "2023-11-04T00:42:35.984Z",
          "wordCount": 687,
          "title": "Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis. (arXiv:2311.01052v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01327",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wanteng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_D/0/1/0/all/0/1\">Dong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jiashuo Jiang</a>",
          "description": "We study the contextual bandits with knapsack (CBwK) problem under the\nhigh-dimensional setting where the dimension of the feature is large. The\nreward of pulling each arm equals the multiplication of a sparse\nhigh-dimensional weight vector and the feature of the current arrival, with\nadditional random noise. In this paper, we investigate how to exploit this\nsparsity structure to achieve improved regret for the CBwK problem. To this\nend, we first develop an online variant of the hard thresholding algorithm that\nperforms the sparse estimation in an online manner. We further combine our\nonline estimator with a primal-dual framework, where we assign a dual variable\nto each knapsack constraint and utilize an online learning algorithm to update\nthe dual variable, thereby controlling the consumption of the knapsack\ncapacity. We show that this integrated approach allows us to achieve a\nsublinear regret that depends logarithmically on the feature dimension, thus\nimproving the polynomial dependency established in the previous literature. We\nalso apply our framework to the high-dimension contextual bandit problem\nwithout the knapsack constraint and achieve optimal regret in both the\ndata-poor regime and the data-rich regime. We finally conduct numerical\nexperiments to show the efficient empirical performance of our algorithms under\nthe high dimensional setting.",
          "link": "http://arxiv.org/abs/2311.01327",
          "publishedOn": "2023-11-04T00:42:35.977Z",
          "wordCount": 702,
          "title": "High-dimensional Linear Bandits with Knapsacks. (arXiv:2311.01327v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.01388",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jarrett_D/0/1/0/all/0/1\">Daniel Jarrett</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bica_I/0/1/0/all/0/1\">Ioana Bica</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Consider learning a generative model for time-series data. The sequential\nsetting poses a unique challenge: Not only should the generator capture the\nconditional dynamics of (stepwise) transitions, but its open-loop rollouts\nshould also preserve the joint distribution of (multi-step) trajectories. On\none hand, autoregressive models trained by MLE allow learning and computing\nexplicit transition distributions, but suffer from compounding error during\nrollouts. On the other hand, adversarial models based on GAN training alleviate\nsuch exposure bias, but transitions are implicit and hard to assess. In this\nwork, we study a generative framework that seeks to combine the strengths of\nboth: Motivated by a moment-matching objective to mitigate compounding error,\nwe optimize a local (but forward-looking) transition policy, where the\nreinforcement signal is provided by a global (but stepwise-decomposable) energy\nmodel trained by contrastive estimation. At training, the two components are\nlearned cooperatively, avoiding the instabilities typical of adversarial\nobjectives. At inference, the learned policy serves as the generator for\niterative sampling, and the learned energy serves as a trajectory-level measure\nfor evaluating sample quality. By expressly training a policy to imitate\nsequential behavior of time-series features in a dataset, this approach\nembodies \"generation by imitation\". Theoretically, we illustrate the\ncorrectness of this formulation and the consistency of the algorithm.\nEmpirically, we evaluate its ability to generate predictively useful samples\nfrom real-world datasets, verifying that it performs at the standard of\nexisting benchmarks.",
          "link": "http://arxiv.org/abs/2311.01388",
          "publishedOn": "2023-11-04T00:42:35.971Z",
          "wordCount": 732,
          "title": "Time-series Generation by Contrastive Imitation. (arXiv:2311.01388v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2112.03152",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Biswas_N/0/1/0/all/0/1\">Niloy Biswas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "Markov chain Monte Carlo (MCMC) provides asymptotically consistent estimates\nof intractable posterior expectations as the number of iterations tends to\ninfinity. However, in large data applications, MCMC can be computationally\nexpensive per iteration. This has catalyzed interest in approximating MCMC in a\nmanner that improves computational speed per iteration but does not produce\nasymptotically consistent estimates. In this article, we propose estimators\nbased on couplings of Markov chains to assess the quality of such\nasymptotically biased sampling methods. The estimators give empirical upper\nbounds of the Wasserstein distance between the limiting distribution of the\nasymptotically biased sampling method and the original target distribution of\ninterest. We establish theoretical guarantees for our upper bounds and show\nthat our estimators can remain effective in high dimensions. We apply our\nquality measures to stochastic gradient MCMC, variational Bayes, and Laplace\napproximations for tall data and to approximate MCMC for Bayesian logistic\nregression in 4500 dimensions and Bayesian linear regression in 50000\ndimensions.",
          "link": "http://arxiv.org/abs/2112.03152",
          "publishedOn": "2023-11-04T00:42:35.928Z",
          "wordCount": 674,
          "title": "Bounding Wasserstein distance with couplings. (arXiv:2112.03152v3 [stat.CO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2311.00902",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_J/0/1/0/all/0/1\">Jinchao Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kulick_C/0/1/0/all/0/1\">Charles Kulick</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tang_S/0/1/0/all/0/1\">Sui Tang</a>",
          "description": "In this paper, we focus on the data-driven discovery of a general\nsecond-order particle-based model that contains many state-of-the-art models\nfor modeling the aggregation and collective behavior of interacting agents of\nsimilar size and body type. This model takes the form of a high-dimensional\nsystem of ordinary differential equations parameterized by two interaction\nkernels that appraise the alignment of positions and velocities. We propose a\nGaussian Process-based approach to this problem, where the unknown model\nparameters are marginalized by using two independent Gaussian Process (GP)\npriors on latent interaction kernels constrained to dynamics and observational\ndata. This results in a nonparametric model for interacting dynamical systems\nthat accounts for uncertainty quantification. We also develop acceleration\ntechniques to improve scalability. Moreover, we perform a theoretical analysis\nto interpret the methodology and investigate the conditions under which the\nkernels can be recovered. We demonstrate the effectiveness of the proposed\napproach on various prototype systems, including the selection of the order of\nthe systems and the types of interactions. In particular, we present\napplications to modeling two real-world fish motion datasets that display\nflocking and milling patterns up to 248 dimensions. Despite the use of small\ndata sets, the GP-based approach learns an effective representation of the\nnonlinear dynamics in these spaces and outperforms competitor methods.",
          "link": "http://arxiv.org/abs/2311.00902",
          "publishedOn": "2023-11-04T00:42:35.912Z",
          "wordCount": 752,
          "title": "Data-Driven Model Selections of Second-Order Particle Dynamics via Integrating Gaussian Processes with Low-Dimensional Interacting Structures. (arXiv:2311.00902v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.01951",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kothapalli_V/0/1/0/all/0/1\">Vignesh Kothapalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tirer_T/0/1/0/all/0/1\">Tom Tirer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>",
          "description": "Graph neural networks (GNNs) have become increasingly popular for\nclassification tasks on graph-structured data. Yet, the interplay between graph\ntopology and feature evolution in GNNs is not well understood. In this paper,\nwe focus on node-wise classification, illustrated with community detection on\nstochastic block model graphs, and explore the feature evolution through the\nlens of the \"Neural Collapse\" (NC) phenomenon. When training instance-wise deep\nclassifiers (e.g. for image classification) beyond the zero training error\npoint, NC demonstrates a reduction in the deepest features' within-class\nvariability and an increased alignment of their class means to certain\nsymmetric structures. We start with an empirical study that shows that a\ndecrease in within-class variability is also prevalent in the node-wise\nclassification setting, however, not to the extent observed in the\ninstance-wise case. Then, we theoretically study this distinction.\nSpecifically, we show that even an \"optimistic\" mathematical model requires\nthat the graphs obey a strict structural condition in order to possess a\nminimizer with exact collapse. Interestingly, this condition is viable also for\nheterophilic graphs and relates to recent empirical studies on settings with\nimproved GNNs' generalization. Furthermore, by studying the gradient dynamics\nof the theoretical model, we provide reasoning for the partial collapse\nobserved empirically. Finally, we present a study on the evolution of within-\nand between-class feature variability across layers of a well-trained GNN and\ncontrast the behavior with spectral methods.",
          "link": "http://arxiv.org/abs/2307.01951",
          "publishedOn": "2023-10-28T00:41:32.049Z",
          "wordCount": 806,
          "title": "A Neural Collapse Perspective on Feature Evolution in Graph Neural Networks. (arXiv:2307.01951v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16502",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schultheiss_C/0/1/0/all/0/1\">Christoph Schultheiss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Buhlmann_P/0/1/0/all/0/1\">Peter B&#xfc;hlmann</a>",
          "description": "We propose a method to detect model misspecifications in nonlinear causal\nadditive and potentially heteroscedastic noise models. We aim to identify\npredictor variables for which we can infer the causal effect even in cases of\nsuch misspecification. We develop a general framework based on knowledge of the\nmultivariate observational data distribution and we then propose an algorithm\nfor finite sample data, discuss its asymptotic properties, and illustrate its\nperformance on simulated and real data.",
          "link": "http://arxiv.org/abs/2310.16502",
          "publishedOn": "2023-10-28T00:41:29.988Z",
          "wordCount": null,
          "title": "Assessing the overall and partial causal well-specification of nonlinear additive noise models. (arXiv:2310.16502v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14943",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sharrock_L/0/1/0/all/0/1\">Louis Sharrock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nemeth_C/0/1/0/all/0/1\">Christopher Nemeth</a>",
          "description": "We introduce a suite of new particle-based algorithms for sampling on\nconstrained domains which are entirely learning rate free. Our approach\nleverages coin betting ideas from convex optimisation, and the viewpoint of\nconstrained sampling as a mirrored optimisation problem on the space of\nprobability measures. Based on this viewpoint, we also introduce a unifying\nframework for several existing constrained sampling algorithms, including\nmirrored Langevin dynamics and mirrored Stein variational gradient descent. We\ndemonstrate the performance of our algorithms on a range of numerical examples,\nincluding sampling from targets on the simplex, sampling with fairness\nconstraints, and constrained sampling problems in post-selection inference. Our\nresults indicate that our algorithms achieve competitive performance with\nexisting constrained sampling methods, without the need to tune any\nhyperparameters.",
          "link": "http://arxiv.org/abs/2305.14943",
          "publishedOn": "2023-10-28T00:41:29.740Z",
          "wordCount": null,
          "title": "Learning Rate Free Bayesian Inference in Constrained Domains. (arXiv:2305.14943v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.16779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1\">Jongheon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>",
          "description": "Along with recent diffusion models, randomized smoothing has become one of a\nfew tangible approaches that offers adversarial robustness to models at scale,\ne.g., those of large pre-trained models. Specifically, one can perform\nrandomized smoothing on any classifier via a simple \"denoise-and-classify\"\npipeline, so-called denoised smoothing, given that an accurate denoiser is\navailable - such as diffusion model. In this paper, we present scalable methods\nto address the current trade-off between certified robustness and accuracy in\ndenoised smoothing. Our key idea is to \"selectively\" apply smoothing among\nmultiple noise scales, coined multi-scale smoothing, which can be efficiently\nimplemented with a single diffusion model. This approach also suggests a new\nobjective to compare the collective robustness of multi-scale smoothed\nclassifiers, and questions which representation of diffusion model would\nmaximize the objective. To address this, we propose to further fine-tune\ndiffusion model (a) to perform consistent denoising whenever the original image\nis recoverable, but (b) to generate rather diverse outputs otherwise. Our\nexperiments show that the proposed multi-scale smoothing scheme combined with\ndiffusion fine-tuning enables strong certified robustness available with high\nnoise level while maintaining its accuracy closer to non-smoothed classifiers.",
          "link": "http://arxiv.org/abs/2310.16779",
          "publishedOn": "2023-10-28T00:41:29.298Z",
          "wordCount": 740,
          "title": "Multi-scale Diffusion Denoised Smoothing. (arXiv:2310.16779v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.13612",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vahdat_K/0/1/0/all/0/1\">Kimia Vahdat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shashaani_S/0/1/0/all/0/1\">Sara Shashaani</a>",
          "description": "In predictive modeling with simulation or machine learning, it is critical to\naccurately assess the quality of estimated values through output analysis. In\nrecent decades output analysis has become enriched with methods that quantify\nthe impact of input data uncertainty in the model outputs to increase\nrobustness. However, most developments are applicable assuming that the input\ndata adheres to a parametric family of distributions. We propose a unified\noutput analysis framework for simulation and machine learning outputs through\nthe lens of Monte Carlo sampling. This framework provides nonparametric\nquantification of the variance and bias induced in the outputs with\nhigher-order accuracy. Our new bias-corrected estimation from the model outputs\nleverages the extension of fast iterative bootstrap sampling and higher-order\ninfluence functions. For the scalability of the proposed estimation methods, we\ndevise budget-optimal rules and leverage control variates for variance\nreduction. Our theoretical and numerical results demonstrate a clear advantage\nin building more robust confidence intervals from the model outputs with higher\ncoverage probability.",
          "link": "http://arxiv.org/abs/2207.13612",
          "publishedOn": "2023-10-28T00:41:29.126Z",
          "wordCount": 709,
          "title": "Robust Output Analysis with Monte-Carlo Methodology. (arXiv:2207.13612v3 [stat.ME] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16843",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Mukherjee_S/0/1/0/all/0/1\">Sumit Mukherjee</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sen_B/0/1/0/all/0/1\">Bodhisattva Sen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sen_S/0/1/0/all/0/1\">Subhabrata Sen</a>",
          "description": "We study empirical Bayes estimation in high-dimensional linear regression. To\nfacilitate computationally efficient estimation of the underlying prior, we\nadopt a variational empirical Bayes approach, introduced originally in\nCarbonetto and Stephens (2012) and Kim et al. (2022). We establish asymptotic\nconsistency of the nonparametric maximum likelihood estimator (NPMLE) and its\n(computable) naive mean field variational surrogate under mild assumptions on\nthe design and the prior. Assuming, in addition, that the naive mean field\napproximation has a dominant optimizer, we develop a computationally efficient\napproximation to the oracle posterior distribution, and establish its accuracy\nunder the 1-Wasserstein metric. This enables computationally feasible Bayesian\ninference; e.g., construction of posterior credible intervals with an average\ncoverage guarantee, Bayes optimal estimation for the regression coefficients,\nestimation of the proportion of non-nulls, etc. Our analysis covers both\ndeterministic and random designs, and accommodates correlations among the\nfeatures. To the best of our knowledge, this provides the first rigorous\nnonparametric empirical Bayes method in a high-dimensional regression setting\nwithout sparsity.",
          "link": "http://arxiv.org/abs/2309.16843",
          "publishedOn": "2023-10-28T00:41:29.077Z",
          "wordCount": 740,
          "title": "A Mean Field Approach to Empirical Bayes Estimation in High-dimensional Linear Regression. (arXiv:2309.16843v2 [math.ST] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chamma_A/0/1/0/all/0/1\">Ahmad Chamma</a> (1 and 2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Engemann_D/0/1/0/all/0/1\">Denis A. Engemann</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Thirion_B/0/1/0/all/0/1\">Bertrand Thirion</a> (1 and 2 and 3) ((1) Inria, (2) Universite Paris Saclay, (3) CEA, (4) Roche Pharma Research and Early Development, Neuroscience and Rare Diseases, Roche Innovation Center Basel, F. Hoffmann-La Roche Ltd., Basel, Switzerland)",
          "description": "Variable importance assessment has become a crucial step in machine-learning\napplications when using complex learners, such as deep neural networks, on\nlarge-scale data. Removal-based importance assessment is currently the\nreference approach, particularly when statistical guarantees are sought to\njustify variable inclusion. It is often implemented with variable permutation\nschemes. On the flip side, these approaches risk misidentifying unimportant\nvariables as important in the presence of correlations among covariates. Here\nwe develop a systematic approach for studying Conditional Permutation\nImportance (CPI) that is model agnostic and computationally lean, as well as\nreusable benchmarks of state-of-the-art variable importance estimators. We show\ntheoretically and empirically that $\\textit{CPI}$ overcomes the limitations of\nstandard permutation importance by providing accurate type-I error control.\nWhen used with a deep neural network, $\\textit{CPI}$ consistently showed top\naccuracy across benchmarks. An experiment on real-world data analysis in a\nlarge-scale medical dataset showed that $\\textit{CPI}$ provides a more\nparsimonious selection of statistically significant variables. Our results\nsuggest that $\\textit{CPI}$ can be readily used as drop-in replacement for\npermutation-based methods.",
          "link": "http://arxiv.org/abs/2309.07593",
          "publishedOn": "2023-10-28T00:41:29.047Z",
          "wordCount": 771,
          "title": "Statistically Valid Variable Importance Assessment through Conditional Permutations. (arXiv:2309.07593v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.13349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "Motivated by the challenge of nonstationarity in sequential decision making,\nwe study Online Convex Optimization (OCO) under the coupling of two problem\nstructures: the domain is unbounded, and the comparator sequence\n$u_1,\\ldots,u_T$ is arbitrarily time-varying. As no algorithm can guarantee low\nregret simultaneously against all comparator sequences, handling this setting\nrequires moving from minimax optimality to comparator adaptivity. That is,\nsensible regret bounds should depend on certain complexity measures of the\ncomparator relative to one's prior knowledge.\n\nThis paper achieves a new type of these adaptive regret bounds via a sparse\ncoding framework. The complexity of the comparator is measured by its energy\nand its sparsity on a user-specified dictionary, which offers considerable\nversatility. Equipped with a wavelet dictionary for example, our framework\nimproves the state-of-the-art bound (Jacobsen & Cutkosky, 2022) by adapting to\nboth ($i$) the magnitude of the comparator average $||\\bar\nu||=||\\sum_{t=1}^Tu_t/T||$, rather than the maximum $\\max_t||u_t||$; and ($ii$)\nthe comparator variability $\\sum_{t=1}^T||u_t-\\bar u||$, rather than the\nuncentered sum $\\sum_{t=1}^T||u_t||$. Furthermore, our analysis is simpler due\nto decoupling function approximation from regret minimization.",
          "link": "http://arxiv.org/abs/2301.13349",
          "publishedOn": "2023-10-28T00:41:29.014Z",
          "wordCount": 753,
          "title": "Unconstrained Dynamic Regret via Sparse Coding. (arXiv:2301.13349v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16638",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kato_M/0/1/0/all/0/1\">Masahiro Kato</a>",
          "description": "Consider a scenario where we have access to train data with both covariates\nand outcomes while test data only contains covariates. In this scenario, our\nprimary aim is to predict the missing outcomes of the test data. With this\nobjective in mind, we train parametric regression models under a covariate\nshift, where covariate distributions are different between the train and test\ndata. For this problem, existing studies have proposed covariate shift\nadaptation via importance weighting using the density ratio. This approach\naverages the train data losses, each weighted by an estimated ratio of the\ncovariate densities between the train and test data, to approximate the\ntest-data risk. Although it allows us to obtain a test-data risk minimizer, its\nperformance heavily relies on the accuracy of the density ratio estimation.\nMoreover, even if the density ratio can be consistently estimated, the\nestimation errors of the density ratio also yield bias in the estimators of the\nregression model's parameters of interest. To mitigate these challenges, we\nintroduce a doubly robust estimator for covariate shift adaptation via\nimportance weighting, which incorporates an additional estimator for the\nregression function. Leveraging double machine learning techniques, our\nestimator reduces the bias arising from the density ratio estimation errors. We\ndemonstrate the asymptotic distribution of the regression parameter estimator.\nNotably, our estimator remains consistent if either the density ratio estimator\nor the regression function is consistent, showcasing its robustness against\npotential errors in density ratio estimation. Finally, we confirm the soundness\nof our proposed method via simulation studies.",
          "link": "http://arxiv.org/abs/2310.16638",
          "publishedOn": "2023-10-28T00:41:28.985Z",
          "wordCount": null,
          "title": "Robust Covariate Shift Adaptation for Density-Ratio Estimation. (arXiv:2310.16638v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.12930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiangyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulte_O/0/1/0/all/0/1\">Oliver Schulte</a>",
          "description": "A fundamental problem of causal discovery is cause-effect inference, learning\nthe correct causal direction between two random variables. Significant progress\nhas been made through modelling the effect as a function of its cause and a\nnoise term, which allows us to leverage assumptions about the generating\nfunction class. The recently introduced heteroscedastic location-scale noise\nfunctional models (LSNMs) combine expressive power with identifiability\nguarantees. LSNM model selection based on maximizing likelihood achieves\nstate-of-the-art accuracy, when the noise distributions are correctly\nspecified. However, through an extensive empirical evaluation, we demonstrate\nthat the accuracy deteriorates sharply when the form of the noise distribution\nis misspecified by the user. Our analysis shows that the failure occurs mainly\nwhen the conditional variance in the anti-causal direction is smaller than that\nin the causal direction. As an alternative, we find that causal model selection\nthrough residual independence testing is much more robust to noise\nmisspecification and misleading conditional variance.",
          "link": "http://arxiv.org/abs/2301.12930",
          "publishedOn": "2023-10-28T00:41:24.766Z",
          "wordCount": 724,
          "title": "Cause-Effect Inference in Location-Scale Noise Models: Maximum Likelihood vs. Independence Testing. (arXiv:2301.12930v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Minhak Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_C/0/1/0/all/0/1\">Chulhee Yun</a>",
          "description": "Cohen et al. (2021) empirically study the evolution of the largest eigenvalue\nof the loss Hessian, also known as sharpness, along the gradient descent (GD)\ntrajectory and observe the Edge of Stability (EoS) phenomenon. The sharpness\nincreases at the early phase of training (referred to as progressive\nsharpening), and eventually saturates close to the threshold of $2 /\n\\text{(step size)}$. In this paper, we start by demonstrating through empirical\nstudies that when the EoS phenomenon occurs, different GD trajectories (after a\nproper reparameterization) align on a specific bifurcation diagram independent\nof initialization. We then rigorously prove this trajectory alignment\nphenomenon for a two-layer fully-connected linear network and a single-neuron\nnonlinear network trained with a single data point. Our trajectory alignment\nanalysis establishes both progressive sharpening and EoS phenomena,\nencompassing and extending recent findings in the literature.",
          "link": "http://arxiv.org/abs/2307.04204",
          "publishedOn": "2023-10-28T00:41:24.522Z",
          "wordCount": 707,
          "title": "Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory. (arXiv:2307.04204v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.15012",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Blancard_B/0/1/0/all/0/1\">Bruno R&#xe9;galdo-Saint Blancard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Eickenberg_M/0/1/0/all/0/1\">Michael Eickenberg</a>",
          "description": "Separating signals from an additive mixture may be an unnecessarily hard\nproblem when one is only interested in specific properties of a given signal.\nIn this work, we tackle simpler \"statistical component separation\" problems\nthat focus on recovering a predefined set of statistical descriptors of a\ntarget signal from a noisy mixture. Assuming access to samples of the noise\nprocess, we investigate a method devised to match the statistics of the\nsolution candidate corrupted by noise samples with those of the observed\nmixture. We first analyze the behavior of this method using simple examples\nwith analytically tractable calculations. Then, we apply it in an image\ndenoising context employing 1) wavelet-based descriptors, 2) ConvNet-based\ndescriptors on astrophysics and ImageNet data. In the case of 1), we show that\nour method better recovers the descriptors of the target data than a standard\ndenoising method in most situations. Additionally, despite not constructed for\nthis purpose, it performs surprisingly well in terms of peak signal-to-noise\nratio on full signal reconstruction. In comparison, representation 2) appears\nless suitable for image denoising. Finally, we extend this method by\nintroducing a diffusive stepwise algorithm which gives a new perspective to the\ninitial method and leads to promising results for image denoising under\nspecific circumstances.",
          "link": "http://arxiv.org/abs/2306.15012",
          "publishedOn": "2023-10-28T00:41:24.516Z",
          "wordCount": 782,
          "title": "Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures. (arXiv:2306.15012v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14077",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Haas_M/0/1/0/all/0/1\">Moritz Haas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holzmuller_D/0/1/0/all/0/1\">David Holzm&#xfc;ller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Luxburg_U/0/1/0/all/0/1\">Ulrike von Luxburg</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steinwart_I/0/1/0/all/0/1\">Ingo Steinwart</a>",
          "description": "The success of over-parameterized neural networks trained to near-zero\ntraining error has caused great interest in the phenomenon of benign\noverfitting, where estimators are statistically consistent even though they\ninterpolate noisy training data. While benign overfitting in fixed dimension\nhas been established for some learning methods, current literature suggests\nthat for regression with typical kernel methods and wide neural networks,\nbenign overfitting requires a high-dimensional setting where the dimension\ngrows with the sample size. In this paper, we show that the smoothness of the\nestimators, and not the dimension, is the key: benign overfitting is possible\nif and only if the estimator's derivatives are large enough. We generalize\nexisting inconsistency results to non-interpolating models and more kernels to\nshow that benign overfitting with moderate derivatives is impossible in fixed\ndimension. Conversely, we show that rate-optimal benign overfitting is possible\nfor regression with a sequence of spiky-smooth kernels with large derivatives.\nUsing neural tangent kernels, we translate our results to wide neural networks.\nWe prove that while infinite-width networks do not overfit benignly with the\nReLU activation, this can be fixed by adding small high-frequency fluctuations\nto the activation function. Our experiments verify that such neural networks,\nwhile overfitting, can indeed generalize well even on low-dimensional data\nsets.",
          "link": "http://arxiv.org/abs/2305.14077",
          "publishedOn": "2023-10-28T00:41:24.498Z",
          "wordCount": 790,
          "title": "Mind the spikes: Benign overfitting of kernels and neural networks in fixed dimension. (arXiv:2305.14077v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.19470",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scott_C/0/1/0/all/0/1\">Clayton Scott</a>",
          "description": "Label embedding is a framework for multiclass classification problems where\neach label is represented by a distinct vector of some fixed dimension, and\ntraining involves matching model output to the vector representing the correct\nlabel. While label embedding has been successfully applied in extreme\nclassification and zero-shot learning, and offers both computational and\nstatistical advantages, its theoretical foundations remain poorly understood.\nThis work presents an analysis of label embedding in the context of extreme\nmulticlass classification, where the number of classes $C$ is very large. We\npresent an excess risk bound that reveals a trade-off between computational and\nstatistical efficiency, quantified via the coherence of the embedding matrix.\nWe further show that under the Massart noise condition, the statistical penalty\nfor label embedding vanishes with sufficiently low coherence. Our analysis\nsupports an algorithm that is simple, scalable, and easily parallelizable, and\nexperimental results demonstrate its effectiveness in large-scale applications.",
          "link": "http://arxiv.org/abs/2305.19470",
          "publishedOn": "2023-10-28T00:41:24.492Z",
          "wordCount": 689,
          "title": "Label Embedding via Low-Coherence Matrices. (arXiv:2305.19470v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.12283",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zhongze Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaocheng Li</a>",
          "description": "In this paper, we consider the uncertainty quantification problem for\nregression models. Specifically, we consider an individual calibration\nobjective for characterizing the quantiles of the prediction model. While such\nan objective is well-motivated from downstream tasks such as newsvendor cost,\nthe existing methods have been largely heuristic and lack of statistical\nguarantee in terms of individual calibration. We show via simple examples that\nthe existing methods focusing on population-level calibration guarantees such\nas average calibration or sharpness can lead to harmful and unexpected results.\nWe propose simple nonparametric calibration methods that are agnostic of the\nunderlying prediction model and enjoy both computational efficiency and\nstatistical consistency. Our approach enables a better understanding of the\npossibility of individual calibration, and we establish matching upper and\nlower bounds for the calibration error of our proposed methods. Technically,\nour analysis combines the nonparametric analysis with a covering number\nargument for parametric analysis, which advances the existing theoretical\nanalyses in the literature of nonparametric density estimation and quantile\nbandit problems. Importantly, the nonparametric perspective sheds new\ntheoretical insights into regression calibration in terms of the curse of\ndimensionality and reconciles the existing results on the impossibility of\nindividual calibration. To our knowledge, we make the first effort to reach\nboth individual calibration and finite-sample guarantee with minimal\nassumptions in terms of conformal prediction. Numerical experiments show the\nadvantage of such a simple approach under various metrics, and also under\ncovariates shift. We hope our work provides a simple benchmark and a starting\npoint of theoretical ground for future research on regression calibration.",
          "link": "http://arxiv.org/abs/2305.12283",
          "publishedOn": "2023-10-28T00:41:24.485Z",
          "wordCount": 822,
          "title": "Distribution-Free Model-Agnostic Regression Calibration via Nonparametric Methods. (arXiv:2305.12283v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.17380",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_T/0/1/0/all/0/1\">Tiancheng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junyan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouyer_C/0/1/0/all/0/1\">Chlo&#xe9; Rouyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_W/0/1/0/all/0/1\">William Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chen-Yu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>",
          "description": "Existing online learning algorithms for adversarial Markov Decision Processes\nachieve ${O}(\\sqrt{T})$ regret after $T$ rounds of interactions even if the\nloss functions are chosen arbitrarily by an adversary, with the caveat that the\ntransition function has to be fixed. This is because it has been shown that\nadversarial transition functions make no-regret learning impossible. Despite\nsuch impossibility results, in this work, we develop algorithms that can handle\nboth adversarial losses and adversarial transitions, with regret increasing\nsmoothly in the degree of maliciousness of the adversary. More concretely, we\nfirst propose an algorithm that enjoys $\\widetilde{{O}}(\\sqrt{T} +\nC^{\\textsf{P}})$ regret where $C^{\\textsf{P}}$ measures how adversarial the\ntransition functions are and can be at most ${O}(T)$. While this algorithm\nitself requires knowledge of $C^{\\textsf{P}}$, we further develop a black-box\nreduction approach that removes this requirement. Moreover, we also show that\nfurther refinements of the algorithm not only maintains the same regret bound,\nbut also simultaneously adapts to easier environments (where losses are\ngenerated in a certain stochastically constrained manner as in Jin et al.\n[2021]) and achieves $\\widetilde{{O}}(U + \\sqrt{UC^{\\textsf{L}}} +\nC^{\\textsf{P}})$ regret, where $U$ is some standard gap-dependent coefficient\nand $C^{\\textsf{L}}$ is the amount of corruption on losses.",
          "link": "http://arxiv.org/abs/2305.17380",
          "publishedOn": "2023-10-28T00:41:24.478Z",
          "wordCount": 775,
          "title": "No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions. (arXiv:2305.17380v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.13534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_T/0/1/0/all/0/1\">Tiancheng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junyan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>",
          "description": "We study the problem of designing adaptive multi-armed bandit algorithms that\nperform optimally in both the stochastic setting and the adversarial setting\nsimultaneously (often known as a best-of-both-world guarantee). A line of\nrecent works shows that when configured and analyzed properly, the\nFollow-the-Regularized-Leader (FTRL) algorithm, originally designed for the\nadversarial setting, can in fact optimally adapt to the stochastic setting as\nwell. Such results, however, critically rely on an assumption that there exists\none unique optimal arm. Recently, Ito (2021) took the first step to remove such\nan undesirable uniqueness assumption for one particular FTRL algorithm with the\n$\\frac{1}{2}$-Tsallis entropy regularizer. In this work, we significantly\nimprove and generalize this result, showing that uniqueness is unnecessary for\nFTRL with a broad family of regularizers and a new learning rate schedule. For\nsome regularizers, our regret bounds also improve upon prior results even when\nuniqueness holds. We further provide an application of our results to the\ndecoupled exploration and exploitation problem, demonstrating that our\ntechniques are broadly applicable.",
          "link": "http://arxiv.org/abs/2302.13534",
          "publishedOn": "2023-10-28T00:41:24.462Z",
          "wordCount": 754,
          "title": "Improved Best-of-Both-Worlds Guarantees for Multi-Armed Bandits: FTRL with General Regularizers and Multiple Optimal Arms. (arXiv:2302.13534v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.07983",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cardoso_G/0/1/0/all/0/1\">Gabriel Cardoso</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Idrissi_Y/0/1/0/all/0/1\">Yazid Janati El Idrissi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Corff_S/0/1/0/all/0/1\">Sylvain Le Corff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1\">Eric Moulines</a>",
          "description": "Ill-posed linear inverse problems arise frequently in various applications,\nfrom computational photography to medical imaging. A recent line of research\nexploits Bayesian inference with informative priors to handle the ill-posedness\nof such problems. Amongst such priors, score-based generative models (SGM) have\nrecently been successfully applied to several different inverse problems. In\nthis study, we exploit the particular structure of the prior defined by the SGM\nto define a sequence of intermediate linear inverse problems. As the noise\nlevel decreases, the posteriors of these inverse problems get closer to the\ntarget posterior of the original inverse problem. To sample from this sequence\nof posteriors, we propose the use of Sequential Monte Carlo (SMC) methods. The\nproposed algorithm, MCGDiff, is shown to be theoretically grounded and we\nprovide numerical simulations showing that it outperforms competing baselines\nwhen dealing with ill-posed inverse problems in a Bayesian setting.",
          "link": "http://arxiv.org/abs/2308.07983",
          "publishedOn": "2023-10-28T00:41:24.456Z",
          "wordCount": 698,
          "title": "Monte Carlo guided Diffusion for Bayesian linear inverse problems. (arXiv:2308.07983v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.05683",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gagolewski_M/0/1/0/all/0/1\">Marek Gagolewski</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cena_A/0/1/0/all/0/1\">Anna Cena</a>, <a href=\"http://arxiv.org/find/stat/1/au:+James_S/0/1/0/all/0/1\">Simon James</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beliakov_G/0/1/0/all/0/1\">Gleb Beliakov</a>",
          "description": "Agglomerative hierarchical clustering based on Ordered Weighted Averaging\n(OWA) operators not only generalises the single, complete, and average\nlinkages, but also includes intercluster distances based on a few nearest or\nfarthest neighbours, trimmed and winsorised means of pairwise point\nsimilarities, amongst many others. We explore the relationships between the\nfamous Lance-Williams update formula and the extended OWA-based linkages with\nweights generated via infinite coefficient sequences. Furthermore, we provide\nsome conditions for the weight generators to guarantee the resulting\ndendrograms to be free from unaesthetic inversions.",
          "link": "http://arxiv.org/abs/2303.05683",
          "publishedOn": "2023-10-28T00:41:24.412Z",
          "wordCount": 660,
          "title": "Hierarchical clustering with OWA-based linkages, the Lance-Williams formula, and dendrogram inversions. (arXiv:2303.05683v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.01757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhuoqun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marchant_N/0/1/0/all/0/1\">Neil G. Marchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucas_K/0/1/0/all/0/1\">Keane Lucas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_L/0/1/0/all/0/1\">Lujo Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohrimenko_O/0/1/0/all/0/1\">Olga Ohrimenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1\">Benjamin I. P. Rubinstein</a>",
          "description": "Randomized smoothing is a leading approach for constructing classifiers that\nare certifiably robust against adversarial examples. Existing work on\nrandomized smoothing has focused on classifiers with continuous inputs, such as\nimages, where $\\ell_p$-norm bounded adversaries are commonly studied. However,\nthere has been limited work for classifiers with discrete or variable-size\ninputs, such as for source code, which require different threat models and\nsmoothing mechanisms. In this work, we adapt randomized smoothing for discrete\nsequence classifiers to provide certified robustness against edit\ndistance-bounded adversaries. Our proposed smoothing mechanism randomized\ndeletion (RS-Del) applies random deletion edits, which are (perhaps\nsurprisingly) sufficient to confer robustness against adversarial deletion,\ninsertion and substitution edits. Our proof of certification deviates from the\nestablished Neyman-Pearson approach, which is intractable in our setting, and\nis instead organized around longest common subsequences. We present a case\nstudy on malware detection--a binary classification problem on byte sequences\nwhere classifier evasion is a well-established threat model. When applied to\nthe popular MalConv malware detection model, our smoothing mechanism RS-Del\nachieves a certified accuracy of 91% at an edit distance radius of 128 bytes.",
          "link": "http://arxiv.org/abs/2302.01757",
          "publishedOn": "2023-10-28T00:41:24.394Z",
          "wordCount": 768,
          "title": "RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion. (arXiv:2302.01757v2 [cs.CR] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.13412",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Bialas_P/0/1/0/all/0/1\">Piotr Bia&#x142;as</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Korcyl_P/0/1/0/all/0/1\">Piotr Korcyl</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Stebel_T/0/1/0/all/0/1\">Tomasz Stebel</a>",
          "description": "We describe a new direct method to estimate bipartite mutual information of a\nclassical spin system based on Monte Carlo sampling enhanced by autoregressive\nneural networks. It allows studying arbitrary geometries of subsystems and can\nbe generalized to classical field theories. We demonstrate it on the Ising\nmodel for four partitionings, including a multiply-connected even-odd division.\nWe show that the area law is satisfied for temperatures away from the critical\ntemperature: the constant term is universal, whereas the proportionality\ncoefficient is different for the even-odd partitioning.",
          "link": "http://arxiv.org/abs/2304.13412",
          "publishedOn": "2023-10-28T00:41:24.388Z",
          "wordCount": 665,
          "title": "Mutual information of spin systems from autoregressive neural networks. (arXiv:2304.13412v2 [cond-mat.stat-mech] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.07273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leemann_T/0/1/0/all/0/1\">Tobias Leemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pawelczyk_M/0/1/0/all/0/1\">Martin Pawelczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1\">Gjergji Kasneci</a>",
          "description": "We propose a novel and practical privacy notion called $f$-Membership\nInference Privacy ($f$-MIP), which explicitly considers the capabilities of\nrealistic adversaries under the membership inference attack threat model.\nConsequently, $f$-MIP offers interpretable privacy guarantees and improved\nutility (e.g., better classification accuracy). In particular, we derive a\nparametric family of $f$-MIP guarantees that we refer to as $\\mu$-Gaussian\nMembership Inference Privacy ($\\mu$-GMIP) by theoretically analyzing likelihood\nratio-based membership inference attacks on stochastic gradient descent (SGD).\nOur analysis highlights that models trained with standard SGD already offer an\nelementary level of MIP. Additionally, we show how $f$-MIP can be amplified by\nadding noise to gradient updates. Our analysis further yields an analytical\nmembership inference attack that offers two distinct advantages over previous\napproaches. First, unlike existing state-of-the-art attacks that require\ntraining hundreds of shadow models, our attack does not require any shadow\nmodel. Second, our analytical attack enables straightforward auditing of our\nprivacy notion $f$-MIP. Finally, we quantify how various hyperparameters (e.g.,\nbatch size, number of model parameters) and specific data characteristics\ndetermine an attacker's ability to accurately infer a point's membership in the\ntraining set. We demonstrate the effectiveness of our method on models trained\non vision and tabular datasets.",
          "link": "http://arxiv.org/abs/2306.07273",
          "publishedOn": "2023-10-28T00:41:23.748Z",
          "wordCount": 747,
          "title": "Gaussian Membership Inference Privacy. (arXiv:2306.07273v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.07163",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshida_Y/0/1/0/all/0/1\">Yuichi Yoshida</a>",
          "description": "We introduce a transformation framework that can be utilized to develop\nonline algorithms with low $\\epsilon$-approximate regret in the random-order\nmodel from offline approximation algorithms. We first give a general reduction\ntheorem that transforms an offline approximation algorithm with low average\nsensitivity to an online algorithm with low $\\epsilon$-approximate regret. We\nthen demonstrate that offline approximation algorithms can be transformed into\na low-sensitivity version using a coreset construction method. To showcase the\nversatility of our approach, we apply it to various problems, including online\n$(k,z)$-clustering, online matrix approximation, and online regression, and\nsuccessfully achieve polylogarithmic $\\epsilon$-approximate regret for each\nproblem. Moreover, we show that in all three cases, our algorithm also enjoys\nlow inconsistency, which may be desired in some online applications.",
          "link": "http://arxiv.org/abs/2306.07163",
          "publishedOn": "2023-10-28T00:41:23.102Z",
          "wordCount": 659,
          "title": "A Batch-to-Online Transformation under Random-Order Model. (arXiv:2306.07163v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Turnbull_O/0/1/0/all/0/1\">Oliver Turnbull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cevora_G/0/1/0/all/0/1\">George Cevora</a>",
          "description": "Adversarial examples resulting from instability of current computer vision\nmodels are an extremely important topic due to their potential to compromise\nany application. In this paper we demonstrate that instability is inevitable\ndue to a) symmetries (translational invariance) of the data, b) the categorical\nnature of the classification task, and c) the fundamental discrepancy of\nclassifying images as objects themselves. The issue is further exacerbated by\nnon-exhaustive labelling of the training data. Therefore we conclude that\ninstability is a necessary result of how the problem of computer vision is\ncurrently formulated. While the problem cannot be eliminated, through the\nanalysis of the causes, we have arrived at ways how it can be partially\nalleviated. These include i) increasing the resolution of images, ii) providing\ncontextual information for the image, iii) exhaustive labelling of training\ndata, and iv) preventing attackers from frequent access to the computer vision\nsystem.",
          "link": "http://arxiv.org/abs/2310.17559",
          "publishedOn": "2023-10-28T00:41:23.096Z",
          "wordCount": 696,
          "title": "Instability of computer vision models is a necessary result of the task itself. (arXiv:2310.17559v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17582",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cheng_X/0/1/0/all/0/1\">Xiuyuan Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lu_J/0/1/0/all/0/1\">Jianfeng Lu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tan_Y/0/1/0/all/0/1\">Yixin Tan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>",
          "description": "Flow-based generative models enjoy certain advantages in computing the data\ngeneration and the likelihood, and have recently shown competitive empirical\nperformance. Compared to the accumulating theoretical studies on related\nscore-based diffusion models, analysis of flow-based models, which are\ndeterministic in both forward (data-to-noise) and reverse (noise-to-data)\ndirections, remain sparse. In this paper, we provide a theoretical guarantee of\ngenerating data distribution by a progressive flow model, the so-called JKO\nflow model, which implements the Jordan-Kinderleherer-Otto (JKO) scheme in a\nnormalizing flow network. Leveraging the exponential convergence of the\nproximal gradient descent (GD) in Wasserstein space, we prove the\nKullback-Leibler (KL) guarantee of data generation by a JKO flow model to be\n$O(\\varepsilon^2)$ when using $N \\lesssim \\log (1/\\varepsilon)$ many JKO steps\n($N$ Residual Blocks in the flow) where $\\varepsilon $ is the error in the\nper-step first-order condition. The assumption on data density is merely a\nfinite second moment, and the theory extends to data distributions without\ndensity and when there are inversion errors in the reverse process where we\nobtain KL-$W_2$ mixed error guarantees. The non-asymptotic convergence rate of\nthe JKO-type $W_2$-proximal GD is proved for a general class of convex\nobjective functionals that includes the KL divergence as a special case, which\ncan be of independent interest.",
          "link": "http://arxiv.org/abs/2310.17582",
          "publishedOn": "2023-10-28T00:41:23.089Z",
          "wordCount": 760,
          "title": "Convergence of flow-based generative models via proximal gradient descent in Wasserstein space. (arXiv:2310.17582v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.11588",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Inatsu_Y/0/1/0/all/0/1\">Yu Inatsu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeno_S/0/1/0/all/0/1\">Shion Takeno</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanada_H/0/1/0/all/0/1\">Hiroyuki Hanada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iwata_K/0/1/0/all/0/1\">Kazuki Iwata</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1\">Ichiro Takeuchi</a>",
          "description": "In this study, we propose a novel multi-objective Bayesian optimization\n(MOBO) method to efficiently identify the Pareto front (PF) defined by risk\nmeasures for black-box functions under the presence of input uncertainty (IU).\nExisting BO methods for Pareto optimization in the presence of IU are\nrisk-specific or without theoretical guarantees, whereas our proposed method\naddresses general risk measures and has theoretical guarantees. The basic idea\nof the proposed method is to assume a Gaussian process (GP) model for the\nblack-box function and to construct high-probability bounding boxes for the\nrisk measures using the GP model. Furthermore, in order to reduce the\nuncertainty of non-dominated bounding boxes, we propose a method of selecting\nthe next evaluation point using a maximin distance defined by the maximum value\nof a quasi distance based on bounding boxes. As theoretical analysis, we prove\nthat the algorithm can return an arbitrary-accurate solution in a finite number\nof iterations with high probability, for various risk measures such as Bayes\nrisk, worst-case risk, and value-at-risk. We also give a theoretical analysis\nthat takes into account approximation errors because there exist non-negligible\napproximation errors (e.g., finite approximation of PFs and sampling-based\napproximation of bounding boxes) in practice. We confirm that the proposed\nmethod outperforms compared with existing methods not only in the setting with\nIU but also in the setting of ordinary MOBO through numerical experiments.",
          "link": "http://arxiv.org/abs/2301.11588",
          "publishedOn": "2023-10-28T00:41:23.083Z",
          "wordCount": 788,
          "title": "Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under Input Uncertainty. (arXiv:2301.11588v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.12906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Southern_J/0/1/0/all/0/1\">Joshua Southern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wayland_J/0/1/0/all/0/1\">Jeremy Wayland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1\">Bastian Rieck</a>",
          "description": "Graph generative model evaluation necessitates understanding differences\nbetween graphs on the distributional level. This entails being able to harness\nsalient attributes of graphs in an efficient manner. Curvature constitutes one\nsuch property that has recently proved its utility in characterising graphs.\nIts expressive properties, stability, and practical utility in model evaluation\nremain largely unexplored, however. We combine graph curvature descriptors with\nemerging methods from topological data analysis to obtain robust, expressive\ndescriptors for evaluating graph generative models.",
          "link": "http://arxiv.org/abs/2301.12906",
          "publishedOn": "2023-10-28T00:41:23.067Z",
          "wordCount": 651,
          "title": "Curvature Filtrations for Graph Generative Model Evaluation. (arXiv:2301.12906v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17467",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ambrogioni_L/0/1/0/all/0/1\">Luca Ambrogioni</a>",
          "description": "Generative diffusion models have achieved spectacular performance in many\nareas of generative modeling. While the fundamental ideas behind these models\ncome from non-equilibrium physics, in this paper we show that many aspects of\nthese models can be understood using the tools of equilibrium statistical\nmechanics. Using this reformulation, we show that generative diffusion models\nundergo second-order phase transitions corresponding to symmetry breaking\nphenomena. We argue that this lead to a form of instability that lies at the\nheart of their generative capabilities and that can be described by a set of\nmean field critical exponents. We conclude by analyzing recent work connecting\ndiffusion models and associative memory networks in view of the thermodynamic\nformulations.",
          "link": "http://arxiv.org/abs/2310.17467",
          "publishedOn": "2023-10-28T00:41:23.061Z",
          "wordCount": 620,
          "title": "The statistical thermodynamics of generative diffusion models. (arXiv:2310.17467v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11982",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Tang_M/0/1/0/all/0/1\">Mufeng Tang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Barron_H/0/1/0/all/0/1\">Helen Barron</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bogacz_R/0/1/0/all/0/1\">Rafal Bogacz</a>",
          "description": "Forming accurate memory of sequential stimuli is a fundamental function of\nbiological agents. However, the computational mechanism underlying sequential\nmemory in the brain remains unclear. Inspired by neuroscience theories and\nrecent successes in applying predictive coding (PC) to \\emph{static} memory\ntasks, in this work we propose a novel PC-based model for \\emph{sequential}\nmemory, called \\emph{temporal predictive coding} (tPC). We show that our tPC\nmodels can memorize and retrieve sequential inputs accurately with a\nbiologically plausible neural implementation. Importantly, our analytical study\nreveals that tPC can be viewed as a classical Asymmetric Hopfield Network (AHN)\nwith an implicit statistical whitening process, which leads to more stable\nperformance in sequential memory tasks of structured inputs. Moreover, we find\nthat tPC exhibits properties consistent with behavioral observations and\ntheories in neuroscience, thereby strengthening its biological relevance. Our\nwork establishes a possible computational mechanism underlying sequential\nmemory in the brain that can also be theoretically interpreted using existing\nmemory model frameworks.",
          "link": "http://arxiv.org/abs/2305.11982",
          "publishedOn": "2023-10-28T00:41:23.055Z",
          "wordCount": 705,
          "title": "Sequential Memory with Temporal Predictive Coding. (arXiv:2305.11982v2 [q-bio.NC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15807",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chzhen_E/0/1/0/all/0/1\">Evgenii Chzhen</a> (LMO, CELESTE), <a href=\"http://arxiv.org/find/stat/1/au:+Giraud_C/0/1/0/all/0/1\">Christophe Giraud</a> (LMO, CELESTE), <a href=\"http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stoltz_G/0/1/0/all/0/1\">Gilles Stoltz</a> (LMO, CELESTE, HEC Paris)",
          "description": "We consider contextual bandit problems with knapsacks [CBwK], a problem where\nat each round, a scalar reward is obtained and vector-valued costs are\nsuffered. The learner aims to maximize the cumulative rewards while ensuring\nthat the cumulative costs are lower than some predetermined cost constraints.\nWe assume that contexts come from a continuous set, that costs can be signed,\nand that the expected reward and cost functions, while unknown, may be\nuniformly estimated -- a typical assumption in the literature. In this setting,\ntotal cost constraints had so far to be at least of order $T^{3/4}$, where $T$\nis the number of rounds, and were even typically assumed to depend linearly on\n$T$. We are however motivated to use CBwK to impose a fairness constraint of\nequalized average costs between groups: the budget associated with the\ncorresponding cost constraints should be as close as possible to the natural\ndeviations, of order $\\sqrt{T}$. To that end, we introduce a dual strategy\nbased on projected-gradient-descent updates, that is able to deal with\ntotal-cost constraints of the order of $\\sqrt{T}$ up to poly-logarithmic terms.\nThis strategy is more direct and simpler than existing strategies in the\nliterature. It relies on a careful, adaptive, tuning of the step size.",
          "link": "http://arxiv.org/abs/2305.15807",
          "publishedOn": "2023-10-28T00:41:23.017Z",
          "wordCount": 790,
          "title": "Small Total-Cost Constraints in Contextual Bandits with Knapsacks, with Application to Fairness. (arXiv:2305.15807v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1\">Miao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Beining Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1\">Difan Zou</a>",
          "description": "In this work, we theoretically investigate the generalization properties of\nneural networks (NN) trained by stochastic gradient descent (SGD) algorithm\nwith large learning rates. Under such a training regime, our finding is that,\nthe oscillation of the NN weights caused by the large learning rate SGD\ntraining turns out to be beneficial to the generalization of the NN, which\npotentially improves over the same NN trained by SGD with small learning rates\nthat converges more smoothly. In view of this finding, we call such a\nphenomenon \"benign oscillation\". Our theory towards demystifying such a\nphenomenon builds upon the feature learning perspective of deep learning.\nSpecifically, we consider a feature-noise data generation model that consists\nof (i) weak features which have a small $\\ell_2$-norm and appear in each data\npoint; (ii) strong features which have a larger $\\ell_2$-norm but only appear\nin a certain fraction of all data points; and (iii) noise. We prove that NNs\ntrained by oscillating SGD with a large learning rate can effectively learn the\nweak features in the presence of those strong features. In contrast, NNs\ntrained by SGD with a small learning rate can only learn the strong features\nbut makes little progress in learning the weak features. Consequently, when it\ncomes to the new testing data which consist of only weak features, the NN\ntrained by oscillating SGD with a large learning rate could still make correct\npredictions consistently, while the NN trained by small learning rate SGD\nfails. Our theory sheds light on how large learning rate training benefits the\ngeneralization of NNs. Experimental results demonstrate our finding on \"benign\noscillation\".",
          "link": "http://arxiv.org/abs/2310.17074",
          "publishedOn": "2023-10-28T00:41:23.010Z",
          "wordCount": 818,
          "title": "Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates. (arXiv:2310.17074v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.16150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Franceschi_J/0/1/0/all/0/1\">Jean-Yves Franceschi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gartrell_M/0/1/0/all/0/1\">Mike Gartrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_L/0/1/0/all/0/1\">Ludovic Dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Issenhuth_T/0/1/0/all/0/1\">Thibaut Issenhuth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1\">Emmanuel de B&#xe9;zenac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Micka&#xeb;l Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakotomamonjy_A/0/1/0/all/0/1\">Alain Rakotomamonjy</a>",
          "description": "Particle-based deep generative models, such as gradient flows and score-based\ndiffusion models, have recently gained traction thanks to their striking\nperformance. Their principle of displacing particle distributions using\ndifferential equations is conventionally seen as opposed to the previously\nwidespread generative adversarial networks (GANs), which involve training a\npushforward generator network. In this paper we challenge this interpretation,\nand propose a novel framework that unifies particle and adversarial generative\nmodels by framing generator training as a generalization of particle models.\nThis suggests that a generator is an optional addition to any such generative\nmodel. Consequently, integrating a generator into a score-based diffusion model\nand training a GAN without a generator naturally emerge from our framework. We\nempirically test the viability of these original models as proofs of concepts\nof potential applications of our framework.",
          "link": "http://arxiv.org/abs/2305.16150",
          "publishedOn": "2023-10-28T00:41:22.940Z",
          "wordCount": 727,
          "title": "Unifying GANs and Score-Based Diffusion as Generative Particle Models. (arXiv:2305.16150v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2107.11419",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Komiyama_J/0/1/0/all/0/1\">Junpei Komiyama</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fouche_E/0/1/0/all/0/1\">Edouard Fouch&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Honda_J/0/1/0/all/0/1\">Junya Honda</a>",
          "description": "We consider nonstationary multi-armed bandit problems where the model\nparameters of the arms change over time. We introduce the adaptive resetting\nbandit (ADR-bandit), a bandit algorithm class that leverages adaptive windowing\ntechniques from literature on data streams. We first provide new guarantees on\nthe quality of estimators resulting from adaptive windowing techniques, which\nare of independent interest. Furthermore, we conduct a finite-time analysis of\nADR-bandit in two typical environments: an abrupt environment where changes\noccur instantaneously and a gradual environment where changes occur\nprogressively. We demonstrate that ADR-bandit has nearly optimal performance\nwhen abrupt or gradual changes occur in a coordinated manner that we call\nglobal changes. We demonstrate that forced exploration is unnecessary when we\nassume such global changes. Unlike the existing nonstationary bandit\nalgorithms, ADR-bandit has optimal performance in stationary environments as\nwell as nonstationary environments with global changes. Our experiments show\nthat the proposed algorithms outperform the existing approaches in synthetic\nand real-world environments.",
          "link": "http://arxiv.org/abs/2107.11419",
          "publishedOn": "2023-10-28T00:41:22.933Z",
          "wordCount": 699,
          "title": "Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits. (arXiv:2107.11419v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yuchen Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kangwook Lee</a>",
          "description": "Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that\nleverages low-rank adaptation of weight matrices, has emerged as a prevalent\ntechnique for fine-tuning pre-trained models such as large language models and\ndiffusion models. Despite its huge success in practice, the theoretical\nunderpinnings of LoRA have largely remained unexplored. This paper takes the\nfirst step to bridge this gap by theoretically analyzing the expressive power\nof LoRA. We prove that, for fully connected neural networks, LoRA can adapt any\nmodel $f$ to accurately represent any smaller target model $\\overline{f}$ if\nLoRA-rank $\\geq(\\text{width of }f) \\times \\frac{\\text{depth of\n}\\overline{f}}{\\text{depth of }f}$. We also quantify the approximation error\nwhen LoRA-rank is lower than the threshold. For Transformer networks, we show\nany model can be adapted to a target model of the same size with\nrank-$(\\frac{\\text{embedding size}}{2})$ LoRA adapters.",
          "link": "http://arxiv.org/abs/2310.17513",
          "publishedOn": "2023-10-28T00:41:22.922Z",
          "wordCount": 668,
          "title": "The Expressive Power of Low-Rank Adaptation. (arXiv:2310.17513v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.13552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsuchida_R/0/1/0/all/0/1\">Russell Tsuchida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_C/0/1/0/all/0/1\">Cheng Soon Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sejdinovic_D/0/1/0/all/0/1\">Dino Sejdinovic</a>",
          "description": "Flexible models for probability distributions are an essential ingredient in\nmany machine learning tasks. We develop and investigate a new class of\nprobability distributions, which we call a Squared Neural Family (SNEFY),\nformed by squaring the 2-norm of a neural network and normalising it with\nrespect to a base measure. Following the reasoning similar to the well\nestablished connections between infinitely wide neural networks and Gaussian\nprocesses, we show that SNEFYs admit closed form normalising constants in many\ncases of interest, thereby resulting in flexible yet fully tractable density\nmodels. SNEFYs strictly generalise classical exponential families, are closed\nunder conditioning, and have tractable marginal distributions. Their utility is\nillustrated on a variety of density estimation, conditional density estimation,\nand density estimation with missing data tasks.",
          "link": "http://arxiv.org/abs/2305.13552",
          "publishedOn": "2023-10-28T00:41:22.909Z",
          "wordCount": 698,
          "title": "Squared Neural Families: A New Class of Tractable Density Models. (arXiv:2305.13552v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nobis_G/0/1/0/all/0/1\">Gabriel Nobis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aversa_M/0/1/0/all/0/1\">Marco Aversa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Springenberg_M/0/1/0/all/0/1\">Maximilian Springenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Detzel_M/0/1/0/all/0/1\">Michael Detzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakajima_S/0/1/0/all/0/1\">Shinichi Nakajima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murray_Smith_R/0/1/0/all/0/1\">Roderick Murray-Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapuschkin_S/0/1/0/all/0/1\">Sebastian Lapuschkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knochenhauer_C/0/1/0/all/0/1\">Christoph Knochenhauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oala_L/0/1/0/all/0/1\">Luis Oala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samek_W/0/1/0/all/0/1\">Wojciech Samek</a>",
          "description": "We generalize the continuous time framework for score-based generative models\nfrom an underlying Brownian motion (BM) to an approximation of fractional\nBrownian motion (FBM). We derive a continuous reparameterization trick and the\nreverse time model by representing FBM as a stochastic integral over a family\nof Ornstein-Uhlenbeck processes to define generative fractional diffusion\nmodels (GFDM) with driving noise converging to a non-Markovian process of\ninfinite quadratic variation. The Hurst index $H\\in(0,1)$ of FBM enables\ncontrol of the roughness of the distribution transforming path. To the best of\nour knowledge, this is the first attempt to build a generative model upon a\nstochastic process with infinite quadratic variation.",
          "link": "http://arxiv.org/abs/2310.17638",
          "publishedOn": "2023-10-28T00:41:22.884Z",
          "wordCount": 641,
          "title": "Generative Fractional Diffusion Models. (arXiv:2310.17638v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.16905",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bouchiat_K/0/1/0/all/0/1\">Kouroche Bouchiat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Immer_A/0/1/0/all/0/1\">Alexander Immer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yeche_H/0/1/0/all/0/1\">Hugo Y&#xe8;che</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ratsch_G/0/1/0/all/0/1\">Gunnar R&#xe4;tsch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>",
          "description": "Neural additive models (NAMs) can improve the interpretability of deep neural\nnetworks by handling input features in separate additive sub-networks. However,\nthey lack inherent mechanisms that provide calibrated uncertainties and enable\nselection of relevant features and interactions. Approaching NAMs from a\nBayesian perspective, we enhance them in three primary ways, namely by a)\nproviding credible intervals for the individual additive sub-networks; b)\nestimating the marginal likelihood to perform an implicit selection of features\nvia an empirical Bayes procedure; and c) enabling a ranking of feature pairs as\ncandidates for second-order interaction in fine-tuned models. In particular, we\ndevelop Laplace-approximated NAMs (LA-NAMs), which show improved empirical\nperformance on tabular datasets and challenging real-world medical tasks.",
          "link": "http://arxiv.org/abs/2305.16905",
          "publishedOn": "2023-10-28T00:41:22.809Z",
          "wordCount": 654,
          "title": "Improving Neural Additive Models with Bayesian Principles. (arXiv:2305.16905v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adachi_M/0/1/0/all/0/1\">Masaki Adachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Planden_B/0/1/0/all/0/1\">Brady Planden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howey_D/0/1/0/all/0/1\">David A. Howey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maundet_K/0/1/0/all/0/1\">Krikamol Maundet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osborne_M/0/1/0/all/0/1\">Michael A. Osborne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_S/0/1/0/all/0/1\">Siu Lun Chau</a>",
          "description": "Like many optimizers, Bayesian optimization often falls short of gaining user\ntrust due to opacity. While attempts have been made to develop human-centric\noptimizers, they typically assume user knowledge is well-specified and\nerror-free, employing users mainly as supervisors of the optimization process.\nWe relax these assumptions and propose a more balanced human-AI partnership\nwith our Collaborative and Explainable Bayesian Optimization (CoExBO)\nframework. Instead of explicitly requiring a user to provide a knowledge model,\nCoExBO employs preference learning to seamlessly integrate human insights into\nthe optimization, resulting in algorithmic suggestions that resonate with user\npreference. CoExBO explains its candidate selection every iteration to foster\ntrust, empowering users with a clearer grasp of the optimization. Furthermore,\nCoExBO offers a no-harm guarantee, allowing users to make mistakes; even with\nextreme adversarial interventions, the algorithm converges asymptotically to a\nvanilla Bayesian optimization. We validate CoExBO's efficacy through human-AI\nteaming experiments in lithium-ion battery design, highlighting substantial\nimprovements over conventional methods.",
          "link": "http://arxiv.org/abs/2310.17273",
          "publishedOn": "2023-10-28T00:41:22.802Z",
          "wordCount": 711,
          "title": "Looping in the Human: Collaborative and Explainable Bayesian Optimization. (arXiv:2310.17273v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.09493",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gagolewski_M/0/1/0/all/0/1\">Marek Gagolewski</a>",
          "description": "The evaluation of clustering algorithms can involve running them on a variety\nof benchmark problems, and comparing their outputs to the reference,\nground-truth groupings provided by experts. Unfortunately, many research papers\nand graduate theses consider only a small number of datasets. Also, the fact\nthat there can be many equally valid ways to cluster a given problem set is\nrarely taken into account. In order to overcome these limitations, we have\ndeveloped a framework whose aim is to introduce a consistent methodology for\ntesting clustering algorithms. Furthermore, we have aggregated, polished, and\nstandardised many clustering benchmark dataset collections referred to across\nthe machine learning and data mining literature, and included new datasets of\ndifferent dimensionalities, sizes, and cluster types. An interactive datasets\nexplorer, the documentation of the Python API, a description of the ways to\ninteract with the framework from other programming languages such as R or\nMATLAB, and other details are all provided at\n<https://clustering-benchmarks.gagolewski.com>.",
          "link": "http://arxiv.org/abs/2209.09493",
          "publishedOn": "2023-10-28T00:41:22.787Z",
          "wordCount": 719,
          "title": "A framework for benchmarking clustering algorithms. (arXiv:2209.09493v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.13528",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Benard_C/0/1/0/all/0/1\">Cl&#xe9;ment B&#xe9;nard</a>, <a href=\"http://arxiv.org/find/math/1/au:+Staber_B/0/1/0/all/0/1\">Brian Staber</a>, <a href=\"http://arxiv.org/find/math/1/au:+Veiga_S/0/1/0/all/0/1\">S&#xe9;bastien Da Veiga</a> (CREST)",
          "description": "Stein thinning is a promising algorithm proposed by (Riabiz et al., 2022) for\npost-processing outputs of Markov chain Monte Carlo (MCMC). The main principle\nis to greedily minimize the kernelized Stein discrepancy (KSD), which only\nrequires the gradient of the log-target distribution, and is thus well-suited\nfor Bayesian inference. The main advantages of Stein thinning are the automatic\nremove of the burn-in period, the correction of the bias introduced by recent\nMCMC algorithms, and the asymptotic properties of convergence towards the\ntarget distribution. Nevertheless, Stein thinning suffers from several\nempirical pathologies, which may result in poor approximations, as observed in\nthe literature. In this article, we conduct a theoretical analysis of these\npathologies, to clearly identify the mechanisms at stake, and suggest improved\nstrategies. Then, we introduce the regularized Stein thinning algorithm to\nalleviate the identified pathologies. Finally, theoretical guarantees and\nextensive experiments show the high efficiency of the proposed algorithm. An\nimplementation of regularized Stein thinning as the kernax library in python\nand JAX is available at https://gitlab.com/drti/kernax.",
          "link": "http://arxiv.org/abs/2301.13528",
          "publishedOn": "2023-10-28T00:41:22.746Z",
          "wordCount": 754,
          "title": "Kernel Stein Discrepancy thinning: a theoretical perspective of pathologies and a practical fix with regularization. (arXiv:2301.13528v3 [math.ST] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17629",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Auddy_A/0/1/0/all/0/1\">Arnab Auddy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zou_H/0/1/0/all/0/1\">Haolin Zou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rad_K/0/1/0/all/0/1\">Kamiar Rahnama Rad</a>, <a href=\"http://arxiv.org/find/math/1/au:+Maleki_A/0/1/0/all/0/1\">Arian Maleki</a>",
          "description": "The out-of-sample error (OO) is the main quantity of interest in risk\nestimation and model selection. Leave-one-out cross validation (LO) offers a\n(nearly) distribution-free yet computationally demanding approach to estimate\nOO. Recent theoretical work showed that approximate leave-one-out cross\nvalidation (ALO) is a computationally efficient and statistically reliable\nestimate of LO (and OO) for generalized linear models with differentiable\nregularizers. For problems involving non-differentiable regularizers, despite\nsignificant empirical evidence, the theoretical understanding of ALO's error\nremains unknown. In this paper, we present a novel theory for a wide class of\nproblems in the generalized linear model family with non-differentiable\nregularizers. We bound the error |ALO - LO| in terms of intuitive metrics such\nas the size of leave-i-out perturbations in active sets, sample size n, number\nof features p and regularization parameters. As a consequence, for the\n$\\ell_1$-regularized problems, we show that |ALO - LO| goes to zero as p goes\nto infinity while n/p and SNR are fixed and bounded.",
          "link": "http://arxiv.org/abs/2310.17629",
          "publishedOn": "2023-10-28T00:41:22.724Z",
          "wordCount": 700,
          "title": "Approximate Leave-one-out Cross Validation for Regression with $\\ell_1$ Regularizers (extended version). (arXiv:2310.17629v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.12593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Queeney_J/0/1/0/all/0/1\">James Queeney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benosman_M/0/1/0/all/0/1\">Mouhacine Benosman</a>",
          "description": "Many real-world domains require safe decision making in uncertain\nenvironments. In this work, we introduce a deep reinforcement learning\nframework for approaching this important problem. We consider a distribution\nover transition models, and apply a risk-averse perspective towards model\nuncertainty through the use of coherent distortion risk measures. We provide\nrobustness guarantees for this framework by showing it is equivalent to a\nspecific class of distributionally robust safe reinforcement learning problems.\nUnlike existing approaches to robustness in deep reinforcement learning,\nhowever, our formulation does not involve minimax optimization. This leads to\nan efficient, model-free implementation of our approach that only requires\nstandard data collection from a single training environment. In experiments on\ncontinuous control tasks with safety constraints, we demonstrate that our\nframework produces robust performance and safety at deployment time across a\nrange of perturbed test environments.",
          "link": "http://arxiv.org/abs/2301.12593",
          "publishedOn": "2023-10-28T00:41:22.654Z",
          "wordCount": 699,
          "title": "Risk-Averse Model Uncertainty for Distributionally Robust Safe Reinforcement Learning. (arXiv:2301.12593v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2009.01742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_G/0/1/0/all/0/1\">Guanhua Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ward_O/0/1/0/all/0/1\">Owen G. Ward</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1\">Tian Zheng</a>",
          "description": "A common goal in network modeling is to uncover the latent community\nstructure present among nodes. For many real-world networks, the true\nconnections consist of events arriving as streams, which are then aggregated to\nform edges, ignoring the dynamic temporal component. A natural way to take\naccount of these temporal dynamics of interactions is to use point processes as\nthe foundation of network models for community detection. Computational\ncomplexity hampers the scalability of such approaches to large sparse networks.\nTo circumvent this challenge, we propose a fast online variational inference\nalgorithm for estimating the latent structure underlying dynamic event arrivals\non a network, using continuous-time point process latent network models. We\ndescribe this procedure for networks models capturing community structure. This\nstructure can be learned as new events are observed on the network, updating\nthe inferred community assignments. We investigate the theoretical properties\nof such an inference scheme, and provide regret bounds on the loss function of\nthis procedure. The proposed inference procedure is then thoroughly compared,\nusing both simulation studies and real data, to non-online variants. We\ndemonstrate that online inference can obtain comparable performance, in terms\nof community recovery, to non-online variants, while realising computational\ngains. Our proposed inference framework can also be readily modified to\nincorporate other popular network structures.",
          "link": "http://arxiv.org/abs/2009.01742",
          "publishedOn": "2023-10-28T00:41:22.637Z",
          "wordCount": 807,
          "title": "Online Estimation and Community Detection of Network Point Processes for Event Streams. (arXiv:2009.01742v3 [cs.SI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yibo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aragam_B/0/1/0/all/0/1\">Bryon Aragam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veitch_V/0/1/0/all/0/1\">Victor Veitch</a>",
          "description": "Machine learning tools often rely on embedding text as vectors of real\nnumbers. In this paper, we study how the semantic structure of language is\nencoded in the algebraic structure of such embeddings. Specifically, we look at\na notion of ``semantic independence'' capturing the idea that, e.g.,\n``eggplant'' and ``tomato'' are independent given ``vegetable''. Although such\nexamples are intuitive, it is difficult to formalize such a notion of semantic\nindependence. The key observation here is that any sensible formalization\nshould obey a set of so-called independence axioms, and thus any algebraic\nencoding of this structure should also obey these axioms. This leads us\nnaturally to use partial orthogonality as the relevant algebraic structure. We\ndevelop theory and methods that allow us to demonstrate that partial\northogonality does indeed capture semantic independence. Complementary to this,\nwe also introduce the concept of independence preserving embeddings where\nembeddings preserve the conditional independence structures of a distribution,\nand we prove the existence of such embeddings and approximations to them.",
          "link": "http://arxiv.org/abs/2310.17611",
          "publishedOn": "2023-10-28T00:41:22.603Z",
          "wordCount": 697,
          "title": "Uncovering Meanings of Embeddings via Partial Orthogonality. (arXiv:2310.17611v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kaiwen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wenger_J/0/1/0/all/0/1\">Jonathan Wenger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_H/0/1/0/all/0/1\">Haydn Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1\">Geoff Pleiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1\">Jacob R. Gardner</a>",
          "description": "Gaussian process (GP) hyperparameter optimization requires repeatedly solving\nlinear systems with $n \\times n$ kernel matrices. To address the prohibitive\n$\\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative\nnumerical methods, like conjugate gradients (CG). However, as datasets increase\nin magnitude, the corresponding kernel matrices become increasingly\nill-conditioned and still require $\\mathcal{O}(n^2)$ space without\npartitioning. Thus, while CG increases the size of datasets GPs can be trained\non, modern datasets reach scales beyond its applicability. In this work, we\npropose an iterative method which only accesses subblocks of the kernel matrix,\neffectively enabling \\emph{mini-batching}. Our algorithm, based on alternating\nprojection, has $\\mathcal{O}(n)$ per-iteration time and space complexity,\nsolving many of the practical challenges of scaling GPs to very large datasets.\nTheoretically, we prove our method enjoys linear convergence and empirically we\ndemonstrate its robustness to ill-conditioning. On large-scale benchmark\ndatasets up to four million datapoints our approach accelerates training by a\nfactor of 2$\\times$ to 27$\\times$ compared to CG.",
          "link": "http://arxiv.org/abs/2310.17137",
          "publishedOn": "2023-10-28T00:41:22.585Z",
          "wordCount": 685,
          "title": "Large-Scale Gaussian Processes via Alternating Projection. (arXiv:2310.17137v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andaz_S/0/1/0/all/0/1\">Sohrab Andaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenach_C/0/1/0/all/0/1\">Carson Eisenach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madeka_D/0/1/0/all/0/1\">Dhruv Madeka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torkkola_K/0/1/0/all/0/1\">Kari Torkkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Randy Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1\">Dean Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>",
          "description": "In this paper we address the problem of learning and backtesting inventory\ncontrol policies in the presence of general arrival dynamics -- which we term\nas a quantity-over-time arrivals model (QOT). We also allow for order\nquantities to be modified as a post-processing step to meet vendor constraints\nsuch as order minimum and batch size constraints -- a common practice in real\nsupply chains. To the best of our knowledge this is the first work to handle\neither arbitrary arrival dynamics or an arbitrary downstream post-processing of\norder quantities. Building upon recent work (Madeka et al., 2022) we similarly\nformulate the periodic review inventory control problem as an exogenous\ndecision process, where most of the state is outside the control of the agent.\nMadeka et al. (2022) show how to construct a simulator that replays historic\ndata to solve this class of problem. In our case, we incorporate a deep\ngenerative model for the arrivals process as part of the history replay. By\nformulating the problem as an exogenous decision process, we can apply results\nfrom Madeka et al. (2022) to obtain a reduction to supervised learning.\nFinally, we show via simulation studies that this approach yields statistically\nsignificant improvements in profitability over production baselines. Using data\nfrom an ongoing real-world A/B test, we show that Gen-QOT generalizes well to\noff-policy data.",
          "link": "http://arxiv.org/abs/2310.17168",
          "publishedOn": "2023-10-28T00:41:22.577Z",
          "wordCount": 767,
          "title": "Learning an Inventory Control Policy with General Inventory Arrival Dynamics. (arXiv:2310.17168v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhenghao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1\">Molei Tao</a>",
          "description": "Large learning rates, when applied to gradient descent for nonconvex\noptimization, yield various implicit biases including the edge of stability\n(Cohen et al., 2021), balancing (Wang et al., 2022), and catapult (Lewkowycz et\nal., 2020). These phenomena cannot be well explained by classical optimization\ntheory. Though significant theoretical progress has been made in understanding\nthese implicit biases, it remains unclear for which objective functions would\nthey occur. This paper provides an initial step in answering this question,\nnamely that these implicit biases are in fact various tips of the same iceberg.\nThey occur when the objective function of optimization has some good\nregularity, which, in combination with a provable preference of large learning\nrate gradient descent for moving toward flatter regions, results in these\nnontrivial dynamical phenomena. To establish this result, we develop a new\nglobal convergence theory under large learning rates, for a family of nonconvex\nfunctions without globally Lipschitz continuous gradient, which was typically\nassumed in existing convergence analysis. A byproduct is the first\nnon-asymptotic convergence rate bound for large-learning-rate gradient descent\noptimization of nonconvex functions. We also validate our theory with\nexperiments on neural networks, where different losses, activation functions,\nand batch normalization all can significantly affect regularity and lead to\nvery different training dynamics.",
          "link": "http://arxiv.org/abs/2310.17087",
          "publishedOn": "2023-10-28T00:41:22.571Z",
          "wordCount": 775,
          "title": "Good regularity creates large learning rate implicit biases: edge of stability, balancing, and catapult. (arXiv:2310.17087v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fengzhuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1\">Vincent Y. F. Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>",
          "description": "We design and analyze reinforcement learning algorithms for Graphon\nMean-Field Games (GMFGs). In contrast to previous works that require the\nprecise values of the graphons, we aim to learn the Nash Equilibrium (NE) of\nthe regularized GMFGs when the graphons are unknown. Our contributions are\nthreefold. First, we propose the Proximal Policy Optimization for GMFG\n(GMFG-PPO) algorithm and show that it converges at a rate of $O(T^{-1/3})$\nafter $T$ iterations with an estimation oracle, improving on a previous work by\nXie et al. (ICML, 2021). Second, using kernel embedding of distributions, we\ndesign efficient algorithms to estimate the transition kernels, reward\nfunctions, and graphons from sampled agents. Convergence rates are then derived\nwhen the positions of the agents are either known or unknown. Results for the\ncombination of the optimization algorithm GMFG-PPO and the estimation algorithm\nare then provided. These algorithms are the first specifically designed for\nlearning graphons from sampled agents. Finally, the efficacy of the proposed\nalgorithms are corroborated through simulations. These simulations demonstrate\nthat learning the unknown graphons reduces the exploitability effectively.",
          "link": "http://arxiv.org/abs/2310.17531",
          "publishedOn": "2023-10-28T00:41:22.553Z",
          "wordCount": 712,
          "title": "Learning Regularized Graphon Mean-Field Games with Unknown Graphons. (arXiv:2310.17531v1 [cs.GT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17023",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1\">Jiawen Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mu_W/0/1/0/all/0/1\">Wancen Mu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yun Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_D/0/1/0/all/0/1\">Didong Li</a>",
          "description": "In this paper, we critically examine the prevalent practice of using additive\nmixtures of Mat\\'ern kernels in single-output Gaussian process (GP) models and\nexplore the properties of multiplicative mixtures of Mat\\'ern kernels for\nmulti-output GP models. For the single-output case, we derive a series of\ntheoretical results showing that the smoothness of a mixture of Mat\\'ern\nkernels is determined by the least smooth component and that a GP with such a\nkernel is effectively equivalent to the least smooth kernel component.\nFurthermore, we demonstrate that none of the mixing weights or parameters\nwithin individual kernel components are identifiable. We then turn our\nattention to multi-output GP models and analyze the identifiability of the\ncovariance matrix $A$ in the multiplicative kernel $K(x,y) = AK_0(x,y)$, where\n$K_0$ is a standard single output kernel such as Mat\\'ern. We show that $A$ is\nidentifiable up to a multiplicative constant, suggesting that multiplicative\nmixtures are well suited for multi-output tasks. Our findings are supported by\nextensive simulations and real applications for both single- and multi-output\nsettings. This work provides insight into kernel selection and interpretation\nfor GP models, emphasizing the importance of choosing appropriate kernel\nstructures for different tasks.",
          "link": "http://arxiv.org/abs/2310.17023",
          "publishedOn": "2023-10-28T00:41:22.538Z",
          "wordCount": 733,
          "title": "On the Identifiability and Interpretability of Gaussian Process Models. (arXiv:2310.17023v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.05794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galanti_T/0/1/0/all/0/1\">Tomer Galanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siegel_Z/0/1/0/all/0/1\">Zachary S. Siegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupte_A/0/1/0/all/0/1\">Aparna Gupte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poggio_T/0/1/0/all/0/1\">Tomaso Poggio</a>",
          "description": "We study the bias of Stochastic Gradient Descent (SGD) to learn low-rank\nweight matrices when training deep neural networks. Our results show that\ntraining neural networks with mini-batch SGD and weight decay causes a bias\ntowards rank minimization over the weight matrices. Specifically, we show, both\ntheoretically and empirically, that this bias is more pronounced when using\nsmaller batch sizes, higher learning rates, or increased weight decay.\nAdditionally, we predict and observe empirically that weight decay is necessary\nto achieve this bias. Unlike previous literature, our analysis does not rely on\nassumptions about the data, convergence, or optimality of the weight matrices\nand applies to a wide range of neural network architectures of any width or\ndepth. Finally, we empirically investigate the connection between this bias and\ngeneralization, finding that it has a marginal effect on generalization.",
          "link": "http://arxiv.org/abs/2206.05794",
          "publishedOn": "2023-10-28T00:41:22.532Z",
          "wordCount": 731,
          "title": "Characterizing the Implicit Bias of Regularized SGD in Rank Minimization. (arXiv:2206.05794v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17063",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_N/0/1/0/all/0/1\">Naitong Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Campbell_T/0/1/0/all/0/1\">Trevor Campbell</a>",
          "description": "A Bayesian coreset is a small, weighted subset of data that replaces the full\ndataset during inference in order to reduce computational cost. However, state\nof the art methods for tuning coreset weights are expensive, require nontrivial\nuser input, and impose constraints on the model. In this work, we propose a new\nmethod -- Coreset MCMC -- that simulates a Markov chain targeting the coreset\nposterior, while simultaneously updating the coreset weights using those same\ndraws. Coreset MCMC is simple to implement and tune, and can be used with any\nexisting MCMC kernel. We analyze Coreset MCMC in a representative setting to\nobtain key insights about the convergence behaviour of the method. Empirical\nresults demonstrate that Coreset MCMC provides higher quality posterior\napproximations and reduced computational cost compared with other coreset\nconstruction methods. Further, compared with other general subsampling MCMC\nmethods, we find that Coreset MCMC has a higher sampling efficiency with\ncompetitively accurate posterior approximations.",
          "link": "http://arxiv.org/abs/2310.17063",
          "publishedOn": "2023-10-28T00:41:22.515Z",
          "wordCount": 661,
          "title": "Coreset Markov Chain Monte Carlo. (arXiv:2310.17063v1 [stat.CO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17571",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Chung_S/0/1/0/all/0/1\">Seulki Chung</a>",
          "description": "Feedforward neural network (FFN) and two specific types of recurrent neural\nnetwork, long short-term memory (LSTM) and gated recurrent unit (GRU), are used\nfor modeling US recessions in the period from 1967 to 2021. The estimated\nmodels are then employed to conduct real-time predictions of the Great\nRecession and the Covid-19 recession in US. Their predictive performances are\ncompared to those of the traditional linear models, the logistic regression\nmodel both with and without the ridge penalty. The out-of-sample performance\nsuggests the application of LSTM and GRU in the area of recession forecasting,\nespecially for the long-term forecasting tasks. They outperform other types of\nmodels across 5 forecasting horizons with respect to different types of\nstatistical performance metrics. Shapley additive explanations (SHAP) method is\napplied to the fitted GRUs across different forecasting horizons to gain\ninsight into the feature importance. The evaluation of predictor importance\ndiffers between the GRU and ridge logistic regression models, as reflected in\nthe variable order determined by SHAP values. When considering the top 5\npredictors, key indicators such as the S\\&P 500 index, real GDP, and private\nresidential fixed investment consistently appear for short-term forecasts (up\nto 3 months). In contrast, for longer-term predictions (6 months or more), the\nterm spread and producer price index become more prominent. These findings are\nsupported by both local interpretable model-agnostic explanations (LIME) and\nmarginal effects.",
          "link": "http://arxiv.org/abs/2310.17571",
          "publishedOn": "2023-10-28T00:41:22.508Z",
          "wordCount": 792,
          "title": "Inside the black box: Neural network-based real-time prediction of US recessions. (arXiv:2310.17571v1 [econ.EM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17610",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Siegel_J/0/1/0/all/0/1\">Jonathan W. Siegel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>",
          "description": "We consider gradient flow/gradient descent and heavy ball/accelerated\ngradient descent optimization for convex objective functions. In the gradient\nflow case, we prove the following:\n\n1. If $f$ does not have a minimizer, the convergence $f(x_t)\\to \\inf f$ can\nbe arbitrarily slow.\n\n2. If $f$ does have a minimizer, the excess energy $f(x_t) - \\inf f$ is\nintegrable/summable in time. In particular, $f(x_t) - \\inf f = o(1/t)$ as\n$t\\to\\infty$.\n\n3. In Hilbert spaces, this is optimal: $f(x_t) - \\inf f$ can decay to $0$ as\nslowly as any given function which is monotone decreasing and integrable at\n$\\infty$, even for a fixed quadratic objective.\n\n4. In finite dimension (or more generally, for all gradient flow curves of\nfinite length), this is not optimal: We prove that there are convex monotone\ndecreasing integrable functions $g(t)$ which decrease to zero slower than\n$f(x_t)-\\inf f$ for the gradient flow of any convex function on $\\mathbb R^d$.\nFor instance, we show that any gradient flow $x_t$ of a convex function $f$ in\nfinite dimension satisfies $\\liminf_{t\\to\\infty} \\big(t\\cdot \\log^2(t)\\cdot\n\\big\\{f(x_t) -\\inf f\\big\\}\\big)=0$.\n\nThis improves on the commonly reported $O(1/t)$ rate and provides a sharp\ncharacterization of the energy decay law. We also note that it is impossible to\nestablish a rate $O(1/(t\\phi(t))$ for any function $\\phi$ which satisfies\n$\\lim_{t\\to\\infty}\\phi(t) = \\infty$, even asymptotically.\n\nSimilar results are obtained in related settings for (1) discrete time\ngradient descent, (2) stochastic gradient descent with multiplicative noise and\n(3) the heavy ball ODE. In the case of stochastic gradient descent, the\nsummability of $\\mathbb E[f(x_n) - \\inf f]$ is used to prove that $f(x_n)\\to\n\\inf f$ almost surely - an improvement on the convergence almost surely up to a\nsubsequence which follows from the $O(1/n)$ decay estimate.",
          "link": "http://arxiv.org/abs/2310.17610",
          "publishedOn": "2023-10-28T00:41:22.476Z",
          "wordCount": 861,
          "title": "A qualitative difference between gradient flows of convex functions in finite- and infinite-dimensional Hilbert spaces. (arXiv:2310.17610v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16945",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lan_H/0/1/0/all/0/1\">Hui Lan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Syrgkanis_V/0/1/0/all/0/1\">Vasilis Syrgkanis</a>",
          "description": "Accurate estimation of conditional average treatment effects (CATE) is at the\ncore of personalized decision making. While there is a plethora of models for\nCATE estimation, model selection is a nontrivial task, due to the fundamental\nproblem of causal inference. Recent empirical work provides evidence in favor\nof proxy loss metrics with double robust properties and in favor of model\nensembling. However, theoretical understanding is lacking. Direct application\nof prior theoretical work leads to suboptimal oracle model selection rates due\nto the non-convexity of the model selection problem. We provide regret rates\nfor the major existing CATE ensembling approaches and propose a new CATE model\nensembling approach based on Q-aggregation using the doubly robust loss. Our\nmain result shows that causal Q-aggregation achieves statistically optimal\noracle model selection regret rates of $\\frac{\\log(M)}{n}$ (with $M$ models and\n$n$ samples), with the addition of higher-order estimation error terms related\nto products of errors in the nuisance functions. Crucially, our regret rate\ndoes not require that any of the candidate CATE models be close to the truth.\nWe validate our new method on many semi-synthetic datasets and also provide\nextensions of our work to CATE model selection with instrumental variables and\nunobserved confounding.",
          "link": "http://arxiv.org/abs/2310.16945",
          "publishedOn": "2023-10-28T00:41:22.430Z",
          "wordCount": 732,
          "title": "Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1\">Jack Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ONeill_C/0/1/0/all/0/1\">Charles O&#x27;Neill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1\">Thang Bui</a>",
          "description": "In some settings neural networks exhibit a phenomenon known as grokking,\nwhere they achieve perfect or near-perfect accuracy on the validation set long\nafter the same performance has been achieved on the training set. In this\npaper, we discover that grokking is not limited to neural networks but occurs\nin other settings such as Gaussian process (GP) classification, GP regression\nand linear regression. We also uncover a mechanism by which to induce grokking\non algorithmic datasets via the addition of dimensions containing spurious\ninformation. The presence of the phenomenon in non-neural architectures\nprovides evidence that grokking is not specific to SGD or weight norm\nregularisation. Instead, grokking may be possible in any setting where solution\nsearch is guided by complexity and error. Based on this insight and further\ntrends we see in the training trajectories of a Bayesian neural network (BNN)\nand GP regression model, we make progress towards a more general theory of\ngrokking. Specifically, we hypothesise that the phenomenon is governed by the\naccessibility of certain regions in the error and complexity landscapes.",
          "link": "http://arxiv.org/abs/2310.17247",
          "publishedOn": "2023-10-28T00:41:22.354Z",
          "wordCount": 714,
          "title": "Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity. (arXiv:2310.17247v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17114",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mazumder_R/0/1/0/all/0/1\">Rahul Mazumder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_H/0/1/0/all/0/1\">Haoyue Wang</a>",
          "description": "The decision tree is a flexible machine learning model that finds its success\nin numerous applications. It is usually fitted in a recursively greedy manner\nusing CART. In this paper, we investigate the convergence rate of CART under a\nregression setting. First, we establish an upper bound on the prediction error\nof CART under a sufficient impurity decrease (SID) condition\n\\cite{chi2022asymptotic} -- our result improves upon the known result by\n\\cite{chi2022asymptotic} under a similar assumption. Furthermore, we provide\nexamples that demonstrate the error bound cannot be further improved by more\nthan a constant or a logarithmic factor. Second, we introduce a set of easily\nverifiable sufficient conditions for the SID condition. Specifically, we\ndemonstrate that the SID condition can be satisfied in the case of an additive\nmodel, provided that the component functions adhere to a ``locally reverse\nPoincar{\\'e} inequality\". We discuss several well-known function classes in\nnon-parametric estimation to illustrate the practical utility of this concept.",
          "link": "http://arxiv.org/abs/2310.17114",
          "publishedOn": "2023-10-28T00:41:22.345Z",
          "wordCount": 685,
          "title": "On the Convergence of CART under Sufficient Impurity Decrease Condition. (arXiv:2310.17114v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17386",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ivanova_A/0/1/0/all/0/1\">Anastasia Ivanova</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ablin_P/0/1/0/all/0/1\">Pierre Ablin</a>",
          "description": "In many scenarios, one uses a large training set to train a model with the\ngoal of performing well on a smaller testing set with a different distribution.\nLearning a weight for each data point of the training set is an appealing\nsolution, as it ideally allows one to automatically learn the importance of\neach training point for generalization on the testing set. This task is usually\nformalized as a bilevel optimization problem. Classical bilevel solvers are\nbased on a warm-start strategy where both the parameters of the models and the\ndata weights are learned at the same time. We show that this joint dynamic may\nlead to sub-optimal solutions, for which the final data weights are very\nsparse. This finding illustrates the difficulty of data reweighting and offers\na clue as to why this method is rarely used in practice.",
          "link": "http://arxiv.org/abs/2310.17386",
          "publishedOn": "2023-10-28T00:41:22.322Z",
          "wordCount": 657,
          "title": "A Challenge in Reweighting Data with Bilevel Optimization. (arXiv:2310.17386v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Celis_L/0/1/0/all/0/1\">L. Elisa Celis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Amit Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehrotra_A/0/1/0/all/0/1\">Anay Mehrotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1\">Nisheeth K. Vishnoi</a>",
          "description": "Biases with respect to socially-salient attributes of individuals have been\nwell documented in evaluation processes used in settings such as admissions and\nhiring. We view such an evaluation process as a transformation of a\ndistribution of the true utility of an individual for a task to an observed\ndistribution and model it as a solution to a loss minimization problem subject\nto an information constraint. Our model has two parameters that have been\nidentified as factors leading to biases: the resource-information trade-off\nparameter in the information constraint and the risk-averseness parameter in\nthe loss function. We characterize the distributions that arise from our model\nand study the effect of the parameters on the observed distribution. The\noutputs of our model enrich the class of distributions that can be used to\ncapture variation across groups in the observed evaluations. We empirically\nvalidate our model by fitting real-world datasets and use it to study the\neffect of interventions in a downstream selection task. These results\ncontribute to an understanding of the emergence of bias in evaluation processes\nand provide tools to guide the deployment of interventions to mitigate biases.",
          "link": "http://arxiv.org/abs/2310.17489",
          "publishedOn": "2023-10-28T00:41:22.301Z",
          "wordCount": 743,
          "title": "Bias in Evaluation Processes: An Optimization-Based Model. (arXiv:2310.17489v1 [cs.CY])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.17303",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tiapkin_D/0/1/0/all/0/1\">Daniil Tiapkin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Belomestny_D/0/1/0/all/0/1\">Denis Belomestny</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Calandriello_D/0/1/0/all/0/1\">Daniele Calandriello</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1\">Eric Moulines</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Naumov_A/0/1/0/all/0/1\">Alexey Naumov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Perrault_P/0/1/0/all/0/1\">Pierre Perrault</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Menard_P/0/1/0/all/0/1\">Pierre Menard</a>",
          "description": "Incorporating expert demonstrations has empirically helped to improve the\nsample efficiency of reinforcement learning (RL). This paper quantifies\ntheoretically to what extent this extra information reduces RL's sample\ncomplexity. In particular, we study the demonstration-regularized reinforcement\nlearning that leverages the expert demonstrations by KL-regularization for a\npolicy learned by behavior cloning. Our findings reveal that using\n$N^{\\mathrm{E}}$ expert demonstrations enables the identification of an optimal\npolicy at a sample complexity of order\n$\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(S,A,H)/(\\varepsilon^2 N^{\\mathrm{E}}))$\nin finite and $\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(d,H)/(\\varepsilon^2\nN^{\\mathrm{E}}))$ in linear Markov decision processes, where $\\varepsilon$ is\nthe target precision, $H$ the horizon, $A$ the number of action, $S$ the number\nof states in the finite case and $d$ the dimension of the feature space in the\nlinear case. As a by-product, we provide tight convergence guarantees for the\nbehaviour cloning procedure under general assumptions on the policy classes.\nAdditionally, we establish that demonstration-regularized methods are provably\nefficient for reinforcement learning from human feedback (RLHF). In this\nrespect, we provide theoretical evidence showing the benefits of\nKL-regularization for RLHF in tabular and linear MDPs. Interestingly, we avoid\npessimism injection by employing computationally feasible regularization to\nhandle reward estimation uncertainty, thus setting our approach apart from the\nprior works.",
          "link": "http://arxiv.org/abs/2310.17303",
          "publishedOn": "2023-10-28T00:41:22.287Z",
          "wordCount": 706,
          "title": "Demonstration-Regularized RL. (arXiv:2310.17303v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.16975",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Zheyu Oliver Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baptista_R/0/1/0/all/0/1\">Ricardo Baptista</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marzouk_Y/0/1/0/all/0/1\">Youssef Marzouk</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ruthotto_L/0/1/0/all/0/1\">Lars Ruthotto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Verma_D/0/1/0/all/0/1\">Deepanshu Verma</a>",
          "description": "We present two neural network approaches that approximate the solutions of\nstatic and dynamic conditional optimal transport (COT) problems, respectively.\nBoth approaches enable sampling and density estimation of conditional\nprobability distributions, which are core tasks in Bayesian inference. Our\nmethods represent the target conditional distributions as transformations of a\ntractable reference distribution and, therefore, fall into the framework of\nmeasure transport. COT maps are a canonical choice within this framework, with\ndesirable properties such as uniqueness and monotonicity. However, the\nassociated COT problems are computationally challenging, even in moderate\ndimensions. To improve the scalability, our numerical algorithms leverage\nneural networks to parameterize COT maps. Our methods exploit the structure of\nthe static and dynamic formulations of the COT problem. PCP-Map models\nconditional transport maps as the gradient of a partially input convex neural\nnetwork (PICNN) and uses a novel numerical implementation to increase\ncomputational efficiency compared to state-of-the-art alternatives. COT-Flow\nmodels conditional transports via the flow of a regularized neural ODE; it is\nslower to train but offers faster sampling. We demonstrate their effectiveness\nand efficiency by comparing them with state-of-the-art approaches using\nbenchmark datasets and Bayesian inverse problems.",
          "link": "http://arxiv.org/abs/2310.16975",
          "publishedOn": "2023-10-28T00:41:22.279Z",
          "wordCount": 748,
          "title": "Efficient Neural Network Approaches for Conditional Optimal Transport with Applications in Bayesian Inference. (arXiv:2310.16975v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.07960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kini_G/0/1/0/all/0/1\">Ganesh Ramachandra Kini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakilian_V/0/1/0/all/0/1\">Vala Vakilian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behnia_T/0/1/0/all/0/1\">Tina Behnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gill_J/0/1/0/all/0/1\">Jaidev Gill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "Supervised contrastive loss (SCL) is a competitive and often superior\nalternative to the cross-entropy loss for classification. While prior studies\nhave demonstrated that both losses yield symmetric training representations\nunder balanced data, this symmetry breaks under class imbalances. This paper\npresents an intriguing discovery: the introduction of a ReLU activation at the\nfinal layer effectively restores the symmetry in SCL-learned representations.\nWe arrive at this finding analytically, by establishing that the global\nminimizers of an unconstrained features model with SCL loss and entry-wise\nnon-negativity constraints form an orthogonal frame. Extensive experiments\nconducted across various datasets, architectures, and imbalance scenarios\ncorroborate our finding. Importantly, our experiments reveal that the inclusion\nof the ReLU activation restores symmetry without compromising test accuracy.\nThis constitutes the first geometry characterization of SCL under imbalances.\nAdditionally, our analysis and experiments underscore the pivotal role of batch\nselection strategies in representation geometry. By proving necessary and\nsufficient conditions for mini-batch choices that ensure invariant symmetric\nrepresentations, we introduce batch-binding as an efficient strategy that\nguarantees these conditions hold.",
          "link": "http://arxiv.org/abs/2306.07960",
          "publishedOn": "2023-10-21T00:41:39.661Z",
          "wordCount": 731,
          "title": "Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching. (arXiv:2306.07960v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.10649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neklyudov_K/0/1/0/all/0/1\">Kirill Neklyudov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brekelmans_R/0/1/0/all/0/1\">Rob Brekelmans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_A/0/1/0/all/0/1\">Alexander Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atanackovic_L/0/1/0/all/0/1\">Lazar Atanackovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makhzani_A/0/1/0/all/0/1\">Alireza Makhzani</a>",
          "description": "The dynamical formulation of the optimal transport can be extended through\nvarious choices of the underlying geometry ($\\textit{kinetic energy}$), and the\nregularization of density paths ($\\textit{potential energy}$). These\ncombinations yield different variational problems ($\\textit{Lagrangians}$),\nencompassing many variations of the optimal transport problem such as the\nSchr\\\"odinger bridge, unbalanced optimal transport, and optimal transport with\nphysical constraints, among others. In general, the optimal density path is\nunknown, and solving these variational problems can be computationally\nchallenging. Leveraging the dual formulation of the Lagrangians, we propose a\nnovel deep learning based framework approaching all of these problems from a\nunified perspective. Our method does not require simulating or backpropagating\nthrough the trajectories of the learned dynamics, and does not need access to\noptimal couplings. We showcase the versatility of the proposed framework by\noutperforming previous approaches for the single-cell trajectory inference,\nwhere incorporating prior knowledge into the dynamics is crucial for correct\npredictions.",
          "link": "http://arxiv.org/abs/2310.10649",
          "publishedOn": "2023-10-21T00:41:39.654Z",
          "wordCount": 689,
          "title": "A Computational Framework for Solving Wasserstein Lagrangian Flows. (arXiv:2310.10649v2 [cs.LG] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.06949",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saligkaras_D/0/1/0/all/0/1\">Dimitrios Saligkaras</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papageorgiou_V/0/1/0/all/0/1\">Vasileios E. Papageorgiou</a>",
          "description": "Clustering is an unsupervised machine learning methodology where unlabeled\nelements/objects are grouped together aiming to the construction of\nwell-established clusters that their elements are classified according to their\nsimilarity. The goal of this process is to provide a useful aid to the\nresearcher that will help her/him to identify patterns among the data. Dealing\nwith large databases, such patterns may not be easily detectable without the\ncontribution of a clustering algorithm. This article provides a deep\ndescription of the most widely used clustering methodologies accompanied by\nuseful presentations concerning suitable parameter selection and\ninitializations. Simultaneously, this article not only represents a review\nhighlighting the major elements of examined clustering techniques but\nemphasizes the comparison of these algorithms' clustering efficiency based on 3\ndatasets, revealing their existing weaknesses and capabilities through accuracy\nand complexity, during the confrontation of discrete and continuous\nobservations. The produced results help us extract valuable conclusions about\nthe appropriateness of the examined clustering techniques in accordance with\nthe dataset's size.",
          "link": "http://arxiv.org/abs/2207.06949",
          "publishedOn": "2023-10-21T00:41:39.505Z",
          "wordCount": 767,
          "title": "Seeking the Truth Beyond the Data. An Unsupervised Machine Learning Approach. (arXiv:2207.06949v4 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1811.11479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_E/0/1/0/all/0/1\">Eunjeong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seungeun Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyesung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jihong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1\">Mehdi Bennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seong-Lyun Kim</a>",
          "description": "On-device machine learning (ML) enables the training process to exploit a\nmassive amount of user-generated private data samples. To enjoy this benefit,\ninter-device communication overhead should be minimized. With this end, we\npropose federated distillation (FD), a distributed model training algorithm\nwhose communication payload size is much smaller than a benchmark scheme,\nfederated learning (FL), particularly when the model size is large. Moreover,\nuser-generated data samples are likely to become non-IID across devices, which\ncommonly degrades the performance compared to the case with an IID dataset. To\ncope with this, we propose federated augmentation (FAug), where each device\ncollectively trains a generative model, and thereby augments its local data\ntowards yielding an IID dataset. Empirical studies demonstrate that FD with\nFAug yields around 26x less communication overhead while achieving 95-98% test\naccuracy compared to FL.",
          "link": "http://arxiv.org/abs/1811.11479",
          "publishedOn": "2023-10-21T00:41:39.369Z",
          "wordCount": 732,
          "title": "Communication-Efficient On-Device Machine Learning: Federated Distillation and Augmentation under Non-IID Private Data. (arXiv:1811.11479v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.05015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lim_M/0/1/0/all/0/1\">Michael H. Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Becker_T/0/1/0/all/0/1\">Tyler J. Becker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1\">Mykel J. Kochenderfer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomlin_C/0/1/0/all/0/1\">Claire J. Tomlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunberg_Z/0/1/0/all/0/1\">Zachary N. Sunberg</a>",
          "description": "Partially observable Markov decision processes (POMDPs) provide a flexible\nrepresentation for real-world decision and control problems. However, POMDPs\nare notoriously difficult to solve, especially when the state and observation\nspaces are continuous or hybrid, which is often the case for physical systems.\nWhile recent online sampling-based POMDP algorithms that plan with observation\nlikelihood weighting have shown practical effectiveness, a general theory\ncharacterizing the approximation error of the particle filtering techniques\nthat these algorithms use has not previously been proposed. Our main\ncontribution is bounding the error between any POMDP and its corresponding\nfinite sample particle belief MDP (PB-MDP) approximation. This fundamental\nbridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP\nalgorithm to a POMDP by solving the corresponding particle belief MDP, thereby\nextending the convergence guarantees of the MDP algorithm to the POMDP.\nPractically, this is implemented by using the particle filter belief transition\nmodel as the generative model for the MDP solver. While this requires access to\nthe observation density model from the POMDP, it only increases the transition\nsampling complexity of the MDP solver by a factor of $\\mathcal{O}(C)$, where\n$C$ is the number of particles. Thus, when combined with sparse sampling MDP\nalgorithms, this approach can yield algorithms for POMDPs that have no direct\ntheoretical dependence on the size of the state and observation spaces. In\naddition to our theoretical contribution, we perform five numerical experiments\non benchmark POMDPs to demonstrate that a simple MDP algorithm adapted using\nPB-MDP approximation, Sparse-PFT, achieves performance competitive with other\nleading continuous observation POMDP solvers.",
          "link": "http://arxiv.org/abs/2210.05015",
          "publishedOn": "2023-10-21T00:41:39.357Z",
          "wordCount": 843,
          "title": "Optimality Guarantees for Particle Belief Approximation of POMDPs. (arXiv:2210.05015v5 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12975",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daems_R/0/1/0/all/0/1\">Rembert Daems</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opper_M/0/1/0/all/0/1\">Manfred Opper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crevecoeur_G/0/1/0/all/0/1\">Guillaume Crevecoeur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1\">Tolga Birdal</a>",
          "description": "We present a novel variational framework for performing inference in (neural)\nstochastic differential equations (SDEs) driven by Markov-approximate\nfractional Brownian motion (fBM). SDEs offer a versatile tool for modeling\nreal-world continuous-time dynamic systems with inherent noise and randomness.\nCombining SDEs with the powerful inference capabilities of variational methods,\nenables the learning of representative function distributions through\nstochastic gradient descent. However, conventional SDEs typically assume the\nunderlying noise to follow a Brownian motion (BM), which hinders their ability\nto capture long-term dependencies. In contrast, fractional Brownian motion\n(fBM) extends BM to encompass non-Markovian dynamics, but existing methods for\ninferring fBM parameters are either computationally demanding or statistically\ninefficient. In this paper, building upon the Markov approximation of fBM, we\nderive the evidence lower bound essential for efficient variational inference\nof posterior path measures, drawing from the well-established field of\nstochastic analysis. Additionally, we provide a closed-form expression to\ndetermine optimal approximation coefficients. Furthermore, we propose the use\nof neural networks to learn the drift, diffusion and control terms within our\nvariational posterior, leading to the variational training of neural-SDEs. In\nthis framework, we also optimize the Hurst index, governing the nature of our\nfractional noise. Beyond validation on synthetic data, we contribute a novel\narchitecture for variational latent video prediction,-an approach that, to the\nbest of our knowledge, enables the first variational neural-SDE application to\nvideo perception.",
          "link": "http://arxiv.org/abs/2310.12975",
          "publishedOn": "2023-10-21T00:41:39.340Z",
          "wordCount": 765,
          "title": "Variational Inference for SDEs Driven by Fractional Noise. (arXiv:2310.12975v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.10194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+McCarter_C/0/1/0/all/0/1\">Calvin McCarter</a>",
          "description": "Feature preprocessing continues to play a critical role when applying machine\nlearning and statistical methods to tabular data. In this paper, we propose the\nuse of the kernel density integral transformation as a feature preprocessing\nstep. Our approach subsumes the two leading feature preprocessing methods as\nlimiting cases: linear min-max scaling and quantile transformation. We\ndemonstrate that, without hyperparameter tuning, the kernel density integral\ntransformation can be used as a simple drop-in replacement for either method,\noffering protection from the weaknesses of each. Alternatively, with tuning of\na single continuous hyperparameter, we frequently outperform both of these\nmethods. Finally, we show that the kernel density transformation can be\nprofitably applied to statistical data analysis, particularly in correlation\nanalysis and univariate clustering.",
          "link": "http://arxiv.org/abs/2309.10194",
          "publishedOn": "2023-10-21T00:41:39.334Z",
          "wordCount": 621,
          "title": "The Kernel Density Integral Transformation. (arXiv:2309.10194v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12964",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Si_W/0/1/0/all/0/1\">Wenwen Si</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_S/0/1/0/all/0/1\">Sangdon Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Prediction sets capture uncertainty by predicting sets of labels rather than\nindividual labels, enabling downstream decisions to conservatively account for\nall plausible outcomes. Conformal inference algorithms construct prediction\nsets guaranteed to contain the true label with high probability. These\nguarantees fail to hold in the face of distribution shift, which is precisely\nwhen reliable uncertainty quantification can be most useful. We propose a novel\nalgorithm for constructing prediction sets with PAC guarantees in the label\nshift setting. This method estimates the predicted probabilities of the classes\nin a target domain, as well as the confusion matrix, then propagates\nuncertainty in these estimates through a Gaussian elimination algorithm to\ncompute confidence intervals for importance weights. Finally, it uses these\nintervals to construct prediction sets. We evaluate our approach on five\ndatasets: the CIFAR-10, ChestX-Ray and Entity-13 image datasets, the tabular\nCDC Heart dataset, and the AGNews text dataset. Our algorithm satisfies the PAC\nguarantee while producing smaller, more informative, prediction sets compared\nto several baselines.",
          "link": "http://arxiv.org/abs/2310.12964",
          "publishedOn": "2023-10-21T00:41:39.326Z",
          "wordCount": 659,
          "title": "PAC Prediction Sets Under Label Shift. (arXiv:2310.12964v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.09310",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mozafari_Majd_E/0/1/0/all/0/1\">Emadaldin Mozafari-Majd</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Koivunen_V/0/1/0/all/0/1\">Visa Koivunen</a>",
          "description": "This paper introduces a new regularized version of the robust\n$\\tau$-regression estimator for analyzing high-dimensional datasets subject to\ngross contamination in the response variables and covariates (explanatory\nvariables). The resulting estimator, termed adaptive $\\tau$-Lasso, is robust to\noutliers and high-leverage points. It also incorporates an adaptive\n$\\ell_1$-norm penalty term, which enables the selection of relevant variables\nand reduces the bias associated with large true regression coefficients. More\nspecifically, this adaptive $\\ell_1$-norm penalty term assigns a weight to each\nregression coefficient. For a fixed number of predictors $p$, we show that the\nadaptive $\\tau$-Lasso has the oracle property, ensuring both variable-selection\nconsistency and asymptotic normality. Asymptotic normality applies only to the\nentries of the regression vector corresponding to the true support, assuming\nknowledge of the true regression vector support. We characterize its robustness\nvia the finite-sample breakdown point and the influence function. We carry out\nextensive simulations and observe that the class of $\\tau$-Lasso estimators\nexhibits robustness and reliable performance in both contaminated and\nuncontaminated data settings. We also validate our theoretical findings on\nrobustness properties through simulation experiments. In the face of outliers\nand high-leverage points, the adaptive $\\tau$-Lasso and $\\tau$-Lasso estimators\nachieve the best performance or close-to-best performance in terms of\nprediction and variable selection accuracy compared to other competing\nregularized estimators for all scenarios considered in this study. Therefore,\nthe adaptive $\\tau$-Lasso and $\\tau$-Lasso estimators can be effectively\nemployed for a variety of sparse linear regression problems, particularly in\nhigh-dimensional settings and when the data is contaminated by outliers and\nhigh-leverage points.",
          "link": "http://arxiv.org/abs/2304.09310",
          "publishedOn": "2023-10-21T00:41:39.312Z",
          "wordCount": 769,
          "title": "The Adaptive $\\tau$-Lasso: Robustness and Oracle Properties. (arXiv:2304.09310v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.03810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kirchhof_M/0/1/0/all/0/1\">Michael Kirchhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mucsanyi_B/0/1/0/all/0/1\">B&#xe1;lint Mucs&#xe1;nyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seong Joon Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1\">Enkelejda Kasneci</a>",
          "description": "Representation learning has significantly driven the field to develop\npretrained models that can act as a valuable starting point when transferring\nto new datasets. With the rising demand for reliable machine learning and\nuncertainty quantification, there is a need for pretrained models that not only\nprovide embeddings but also transferable uncertainty estimates. To guide the\ndevelopment of such models, we propose the Uncertainty-aware Representation\nLearning (URL) benchmark. Besides the transferability of the representations,\nit also measures the zero-shot transferability of the uncertainty estimate\nusing a novel metric. We apply URL to evaluate eleven uncertainty quantifiers\nthat are pretrained on ImageNet and transferred to eight downstream datasets.\nWe find that approaches that focus on the uncertainty of the representation\nitself or estimate the prediction risk directly outperform those that are based\non the probabilities of upstream classes. Yet, achieving transferable\nuncertainty quantification remains an open challenge. Our findings indicate\nthat it is not necessarily in conflict with traditional representation learning\ngoals. Code is provided under https://github.com/mkirchhof/url .",
          "link": "http://arxiv.org/abs/2307.03810",
          "publishedOn": "2023-10-21T00:41:39.305Z",
          "wordCount": 731,
          "title": "URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates. (arXiv:2307.03810v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12882",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Winter_S/0/1/0/all/0/1\">Steven Winter</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Melikechi_O/0/1/0/all/0/1\">Omar Melikechi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dunson_D/0/1/0/all/0/1\">David B. Dunson</a>",
          "description": "Gibbs posteriors are proportional to a prior distribution multiplied by an\nexponentiated loss function, with a key tuning parameter weighting information\nin the loss relative to the prior and providing a control of posterior\nuncertainty. Gibbs posteriors provide a principled framework for\nlikelihood-free Bayesian inference, but in many situations, including a single\ntuning parameter inevitably leads to poor uncertainty quantification. In\nparticular, regardless of the value of the parameter, credible regions have far\nfrom the nominal frequentist coverage even in large samples. We propose a\nsequential extension to Gibbs posteriors to address this problem. We prove the\nproposed sequential posterior exhibits concentration and a Bernstein-von Mises\ntheorem, which holds under easy to verify conditions in Euclidean space and on\nmanifolds. As a byproduct, we obtain the first Bernstein-von Mises theorem for\ntraditional likelihood-based Bayesian posteriors on manifolds. All methods are\nillustrated with an application to principal component analysis.",
          "link": "http://arxiv.org/abs/2310.12882",
          "publishedOn": "2023-10-21T00:41:39.297Z",
          "wordCount": 647,
          "title": "Sequential Gibbs Posteriors with Applications to Principal Component Analysis. (arXiv:2310.12882v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.01225",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gonon_A/0/1/0/all/0/1\">Antoine Gonon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brisebarre_N/0/1/0/all/0/1\">Nicolas Brisebarre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Riccietti_E/0/1/0/all/0/1\">Elisa Riccietti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gribonval_R/0/1/0/all/0/1\">R&#xe9;mi Gribonval</a>",
          "description": "This work introduces the first toolkit around path-norms that is fully able\nto encompass general DAG ReLU networks with biases, skip connections and any\noperation based on the extraction of order statistics: max pooling, GroupSort\netc. This toolkit notably allows us to establish generalization bounds for\nmodern neural networks that are not only the most widely applicable path-norm\nbased ones, but also recover or beat the sharpest known bounds of this type.\nThese extended path-norms further enjoy the usual benefits of path-norms: ease\nof computation, invariance under the symmetries of the network, and improved\nsharpness on feedforward networks compared to the product of operators' norms,\nanother complexity measure most commonly used.\n\nThe versatility of the toolkit and its ease of implementation allow us to\nchallenge the concrete promises of path-norm-based generalization bounds, by\nnumerically evaluating the sharpest known bounds for ResNets on ImageNet.",
          "link": "http://arxiv.org/abs/2310.01225",
          "publishedOn": "2023-10-21T00:41:39.290Z",
          "wordCount": 676,
          "title": "A path-norm toolkit for modern networks: consequences, promises and challenges. (arXiv:2310.01225v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.09983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fluri_L/0/1/0/all/0/1\">Lukas Fluri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paleka_D/0/1/0/all/0/1\">Daniel Paleka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tramer_F/0/1/0/all/0/1\">Florian Tram&#xe8;r</a>",
          "description": "If machine learning models were to achieve superhuman abilities at various\nreasoning or decision-making tasks, how would we go about evaluating such\nmodels, given that humans would necessarily be poor proxies for ground truth?\nIn this paper, we propose a framework for evaluating superhuman models via\nconsistency checks. Our premise is that while the correctness of superhuman\ndecisions may be impossible to evaluate, we can still surface mistakes if the\nmodel's decisions fail to satisfy certain logical, human-interpretable rules.\nWe instantiate our framework on three tasks where correctness of decisions is\nhard to evaluate due to either superhuman model abilities, or to otherwise\nmissing ground truth: evaluating chess positions, forecasting future events,\nand making legal judgments. We show that regardless of a model's (possibly\nsuperhuman) performance on these tasks, we can discover logical inconsistencies\nin decision making. For example: a chess engine assigning opposing valuations\nto semantically identical boards; GPT-4 forecasting that sports records will\nevolve non-monotonically over time; or an AI judge assigning bail to a\ndefendant only after we add a felony to their criminal record.",
          "link": "http://arxiv.org/abs/2306.09983",
          "publishedOn": "2023-10-21T00:41:39.254Z",
          "wordCount": 726,
          "title": "Evaluating Superhuman Models with Consistency Checks. (arXiv:2306.09983v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12842",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wood_D/0/1/0/all/0/1\">Danny Wood</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papamarkou_T/0/1/0/all/0/1\">Theodore Papamarkou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Benatan_M/0/1/0/all/0/1\">Matt Benatan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Allmendinger_R/0/1/0/all/0/1\">Richard Allmendinger</a>",
          "description": "In order to trust the predictions of a machine learning algorithm, it is\nnecessary to understand the factors that contribute to those predictions. In\nthe case of probabilistic and uncertainty-aware models, it is necessary to\nunderstand not only the reasons for the predictions themselves, but also the\nmodel's level of confidence in those predictions. In this paper, we show how\nexisting methods in explainability can be extended to uncertainty-aware models\nand how such extensions can be used to understand the sources of uncertainty in\na model's predictive distribution. In particular, by adapting permutation\nfeature importance, partial dependence plots, and individual conditional\nexpectation plots, we demonstrate that novel insights into model behaviour may\nbe obtained and that these methods can be used to measure the impact of\nfeatures on both the entropy of the predictive distribution and the\nlog-likelihood of the ground truth labels under that distribution. With\nexperiments using both synthetic and real-world data, we demonstrate the\nutility of these approaches in understanding both the sources of uncertainty\nand their impact on model performance.",
          "link": "http://arxiv.org/abs/2310.12842",
          "publishedOn": "2023-10-21T00:41:39.194Z",
          "wordCount": 687,
          "title": "Model-agnostic variable importance for predictive uncertainty: an entropy-based approach. (arXiv:2310.12842v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.01746",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kleppe_T/0/1/0/all/0/1\">Tore Selland Kleppe</a>",
          "description": "A metric tensor for Riemann manifold Monte Carlo particularly suited for\nnon-linear Bayesian hierarchical models is proposed. The metric tensor is built\nfrom symmetric positive semidefinite log-density gradient covariance (LGC)\nmatrices, which are also proposed and further explored here. The LGCs\ngeneralize the Fisher information matrix by measuring the joint information\ncontent and dependence structure of both a random variable and the parameters\nof said variable. Consequently, positive definite Fisher/LGC-based metric\ntensors may be constructed not only from the observation likelihoods as is\ncurrent practice, but also from arbitrarily complicated non-linear prior/latent\nvariable structures, provided the LGC may be derived for each conditional\ndistribution used to construct said structures. The proposed methodology is\nhighly automatic and allows for exploitation of any sparsity associated with\nthe model in question. When implemented in conjunction with a Riemann manifold\nvariant of the recently proposed numerical generalized randomized Hamiltonian\nMonte Carlo processes, the proposed methodology is highly competitive, in\nparticular for the more challenging target distributions associated with\nBayesian hierarchical models.",
          "link": "http://arxiv.org/abs/2211.01746",
          "publishedOn": "2023-10-21T00:41:39.141Z",
          "wordCount": 694,
          "title": "Log-density gradient covariance and automatic metric tensors for Riemann manifold Monte Carlo methods. (arXiv:2211.01746v2 [stat.CO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.14090",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Dai_Z/0/1/0/all/0/1\">Zhenyu Dai</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Moews_B/0/1/0/all/0/1\">Ben Moews</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Vilalta_R/0/1/0/all/0/1\">Ricardo Vilalta</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Dave_R/0/1/0/all/0/1\">Romeel Dave</a>",
          "description": "Physics-informed neural networks have emerged as a coherent framework for\nbuilding predictive models that combine statistical patterns with domain\nknowledge. The underlying notion is to enrich the optimization loss function\nwith known relationships to constrain the space of possible solutions.\nHydrodynamic simulations are a core constituent of modern cosmology, while the\nrequired computations are both expensive and time-consuming. At the same time,\nthe comparatively fast simulation of dark matter requires fewer resources,\nwhich has led to the emergence of machine learning algorithms for baryon\ninpainting as an active area of research; here, recreating the scatter found in\nhydrodynamic simulations is an ongoing challenge. This paper presents the first\napplication of physics-informed neural networks to baryon inpainting by\ncombining advances in neural network architectures with physical constraints,\ninjecting theory on baryon conversion efficiency into the model loss function.\nWe also introduce a punitive prediction comparison based on the\nKullback-Leibler divergence, which enforces scatter reproduction. By\nsimultaneously extracting the complete set of baryonic properties for the Simba\nsuite of cosmological simulations, our results demonstrate improved accuracy of\nbaryonic predictions based on dark matter halo properties, successful recovery\nof the fundamental metallicity relation, and retrieve scatter that traces the\ntarget simulation's distribution.",
          "link": "http://arxiv.org/abs/2303.14090",
          "publishedOn": "2023-10-21T00:41:39.080Z",
          "wordCount": 758,
          "title": "Physics-informed neural networks in the recreation of hydrodynamic simulations from dark matter. (arXiv:2303.14090v2 [astro-ph.CO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.12410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brehmer_J/0/1/0/all/0/1\">Johann Brehmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bose_J/0/1/0/all/0/1\">Joey Bose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haan_P/0/1/0/all/0/1\">Pim de Haan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1\">Taco Cohen</a>",
          "description": "Embodied agents operate in a structured world, often solving tasks with\nspatial, temporal, and permutation symmetries. Most algorithms for planning and\nmodel-based reinforcement learning (MBRL) do not take this rich geometric\nstructure into account, leading to sample inefficiency and poor generalization.\nWe introduce the Equivariant Diffuser for Generating Interactions (EDGI), an\nalgorithm for MBRL and planning that is equivariant with respect to the product\nof the spatial symmetry group SE(3), the discrete-time translation group Z, and\nthe object permutation group Sn. EDGI follows the Diffuser framework (Janner et\nal., 2022) in treating both learning a world model and planning in it as a\nconditional generative modeling problem, training a diffusion model on an\noffline trajectory dataset. We introduce a new SE(3)xZxSn-equivariant diffusion\nmodel that supports multiple representations. We integrate this model in a\nplanning loop, where conditioning and classifier guidance let us softly break\nthe symmetry for specific tasks as needed. On object manipulation and\nnavigation tasks, EDGI is substantially more sample efficient and generalizes\nbetter across the symmetry group than non-equivariant models.",
          "link": "http://arxiv.org/abs/2303.12410",
          "publishedOn": "2023-10-21T00:41:39.073Z",
          "wordCount": 713,
          "title": "EDGI: Equivariant Diffusion for Planning with Embodied Agents. (arXiv:2303.12410v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tiapkin_D/0/1/0/all/0/1\">Daniil Tiapkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morozov_N/0/1/0/all/0/1\">Nikita Morozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumov_A/0/1/0/all/0/1\">Alexey Naumov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>",
          "description": "The recently proposed generative flow networks (GFlowNets) are a method of\ntraining a policy to sample compositional discrete objects with probabilities\nproportional to a given reward via a sequence of actions. GFlowNets exploit the\nsequential nature of the problem, drawing parallels with reinforcement learning\n(RL). Our work extends the connection between RL and GFlowNets to a general\ncase. We demonstrate how the task of learning a generative flow network can be\nefficiently redefined as an entropy-regularized RL problem with a specific\nreward and regularizer structure. Furthermore, we illustrate the practical\nefficiency of this reformulation by applying standard soft RL algorithms to\nGFlowNet training across several probabilistic modeling tasks. Contrary to\npreviously reported results, we show that entropic RL approaches can be\ncompetitive against established GFlowNet training methods. This perspective\nopens a direct path for integrating reinforcement learning principles into the\nrealm of generative flow networks.",
          "link": "http://arxiv.org/abs/2310.12934",
          "publishedOn": "2023-10-21T00:41:39.054Z",
          "wordCount": 647,
          "title": "Generative Flow Networks as Entropy-Regularized RL. (arXiv:2310.12934v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.08724",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Goan_E/0/1/0/all/0/1\">Ethan Goan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Perrin_D/0/1/0/all/0/1\">Dimitri Perrin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mengersen_K/0/1/0/all/0/1\">Kerrie Mengersen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fookes_C/0/1/0/all/0/1\">Clinton Fookes</a>",
          "description": "Inference on modern Bayesian Neural Networks (BNNs) often relies on a\nvariational inference treatment, imposing violated assumptions of independence\nand the form of the posterior. Traditional MCMC approaches avoid these\nassumptions at the cost of increased computation due to its incompatibility to\nsubsampling of the likelihood. New Piecewise Deterministic Markov Process\n(PDMP) samplers permit subsampling, though introduce a model specific\ninhomogenous Poisson Process (IPPs) which is difficult to sample from. This\nwork introduces a new generic and adaptive thinning scheme for sampling from\nthese IPPs, and demonstrates how this approach can accelerate the application\nof PDMPs for inference in BNNs. Experimentation illustrates how inference with\nthese methods is computationally feasible, can improve predictive accuracy,\nMCMC mixing performance, and provide informative uncertainty measurements when\ncompared against other approximate inference schemes.",
          "link": "http://arxiv.org/abs/2302.08724",
          "publishedOn": "2023-10-21T00:41:39.047Z",
          "wordCount": 658,
          "title": "Piecewise Deterministic Markov Processes for Bayesian Neural Networks. (arXiv:2302.08724v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2201.13001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dey_J/0/1/0/all/0/1\">Jayanta Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeVine_W/0/1/0/all/0/1\">Will LeVine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoyin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1\">Ashwin De Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomita_T/0/1/0/all/0/1\">Tyler M. Tomita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geisa_A/0/1/0/all/0/1\">Ali Geisa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1\">Tiffany Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desman_J/0/1/0/all/0/1\">Jacob Desman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>",
          "description": "Deep discriminative approaches like random forests and deep neural networks\nhave recently found applications in many important real-world scenarios.\nHowever, deploying these learning algorithms in safety-critical applications\nraises concerns, particularly when it comes to ensuring confidence calibration\nfor both in-distribution and out-of-distribution data points. Many popular\nmethods for in-distribution (ID) calibration, such as isotonic regression and\nPlatt's sigmoidal regression, exhibit excellent ID calibration performance but\noften at the cost of classification accuracy. Moreover, these methods are not\ncalibrated for the entire feature space, leading to overconfidence in the case\nof out-of-distribution (OOD) samples. In this paper, we leveraged the fact that\ndeep models, including both random forests and deep-nets, learn internal\nrepresentations which are unions of polytopes with affine activation functions\nto conceptualize them both as partitioning rules of the feature space. We\nreplace the affine function in each polytope populated by the training data\nwith a Gaussian kernel. We propose sufficient conditions for our proposed\nmethods to be consistent estimators of the corresponding class conditional\ndensities. Moreover, our experiments on both tabular and vision benchmarks show\nthat the proposed approaches obtain well-calibrated posteriors while mostly\npreserving or improving the classification accuracy of the original algorithm\nfor in-distribution region, and extrapolates beyond the training data to handle\nout-of-distribution inputs appropriately.",
          "link": "http://arxiv.org/abs/2201.13001",
          "publishedOn": "2023-10-21T00:41:38.882Z",
          "wordCount": 817,
          "title": "Deep Discriminative to Kernel Density Networks for Calibrated Inference. (arXiv:2201.13001v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sehgal_A/0/1/0/all/0/1\">Atharva Sehgal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grayeli_A/0/1/0/all/0/1\">Arya Grayeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1\">Swarat Chaudhuri</a>",
          "description": "We introduce Cosmos, a framework for object-centric world modeling that is\ndesigned for compositional generalization (CG), i.e., high performance on\nunseen input scenes obtained through the composition of known visual \"atoms.\"\nThe central insight behind Cosmos is the use of a novel form of neurosymbolic\ngrounding. Specifically, the framework introduces two new tools: (i)\nneurosymbolic scene encodings, which represent each entity in a scene using a\nreal vector computed using a neural encoder, as well as a vector of composable\nsymbols describing attributes of the entity, and (ii) a neurosymbolic attention\nmechanism that binds these entities to learned rules of interaction. Cosmos is\nend-to-end differentiable; also, unlike traditional neurosymbolic methods that\nrequire representations to be manually mapped to symbols, it computes an\nentity's symbolic attributes using vision-language foundation models. Through\nan evaluation that considers two different forms of CG on an established\nblocks-pushing domain, we show that the framework establishes a new\nstate-of-the-art for CG in world modeling.",
          "link": "http://arxiv.org/abs/2310.12690",
          "publishedOn": "2023-10-21T00:41:38.870Z",
          "wordCount": 663,
          "title": "Neurosymbolic Grounding for Compositional World Models. (arXiv:2310.12690v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12806",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gauss_J/0/1/0/all/0/1\">Jana Gauss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scheipl_F/0/1/0/all/0/1\">Fabian Scheipl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Herrmann_M/0/1/0/all/0/1\">Moritz Herrmann</a>",
          "description": "Whether class labels in a given data set correspond to meaningful clusters is\ncrucial for the evaluation of clustering algorithms using real-world data sets.\nThis property can be quantified by separability measures. A review of the\nexisting literature shows that neither classification-based complexity measures\nnor cluster validity indices (CVIs) adequately incorporate the central aspects\nof separability for density-based clustering: between-class separation and\nwithin-class connectedness. A newly developed measure (density cluster\nseparability index, DCSI) aims to quantify these two characteristics and can\nalso be used as a CVI. Extensive experiments on synthetic data indicate that\nDCSI correlates strongly with the performance of DBSCAN measured via the\nadjusted rand index (ARI) but lacks robustness when it comes to multi-class\ndata sets with overlapping classes that are ill-suited for density-based hard\nclustering. Detailed evaluation on frequently used real-world data sets shows\nthat DCSI can correctly identify touching or overlapping classes that do not\nform meaningful clusters.",
          "link": "http://arxiv.org/abs/2310.12806",
          "publishedOn": "2023-10-21T00:41:38.845Z",
          "wordCount": 670,
          "title": "DCSI -- An improved measure of cluster separability based on separation and connectedness. (arXiv:2310.12806v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maison_L/0/1/0/all/0/1\">Lucas Maison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bourboux_H/0/1/0/all/0/1\">H&#xe9;lion du Mas des Bourboux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courtat_T/0/1/0/all/0/1\">Thomas Courtat</a>",
          "description": "Compressing neural networks is a key step when deploying models for real-time\nor embedded applications. Factorizing the model's matrices using low-rank\napproximations is a promising method for achieving compression. While it is\npossible to set the rank before training, this approach is neither flexible nor\noptimal. In this work, we propose a post-training rank-selection method called\nRank-Tuning that selects a different rank for each matrix. Used in combination\nwith training adaptations, our method achieves high compression rates with no\nor little performance degradation. Our numerical experiments on signal\nprocessing tasks show that we can compress recurrent neural networks up to 14x\nwith at most 1.4% relative performance reduction.",
          "link": "http://arxiv.org/abs/2310.12688",
          "publishedOn": "2023-10-21T00:41:38.836Z",
          "wordCount": 621,
          "title": "Compression of Recurrent Neural Networks using Matrix Factorization. (arXiv:2310.12688v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12781",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xiong_X/0/1/0/all/0/1\">Xiaofei Xiong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ju_N/0/1/0/all/0/1\">Nianqiao P. Ju</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Sanguo Zhang</a>",
          "description": "Many modern statistical analysis and machine learning applications require\ntraining models on sensitive user data. Differential privacy provides a formal\nguarantee that individual-level information about users does not leak. In this\nframework, randomized algorithms inject calibrated noise into the confidential\ndata, resulting in privacy-protected datasets or queries. However, restricting\naccess to only the privatized data during statistical analysis makes it\ncomputationally challenging to perform valid inferences on parameters\nunderlying the confidential data. In this work, we propose simulation-based\ninference methods from privacy-protected datasets. Specifically, we use neural\nconditional density estimators as a flexible family of distributions to\napproximate the posterior distribution of model parameters given the observed\nprivate query results. We illustrate our methods on discrete time-series data\nunder an infectious disease model and on ordinary linear regression models.\nIllustrating the privacy-utility trade-off, our experiments and analysis\ndemonstrate the necessity and feasibility of designing valid statistical\ninference procedures to correct for biases introduced by the privacy-protection\nmechanisms.",
          "link": "http://arxiv.org/abs/2310.12781",
          "publishedOn": "2023-10-21T00:41:38.806Z",
          "wordCount": 650,
          "title": "Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12595",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wharrie_S/0/1/0/all/0/1\">Sophie Wharrie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "The key challenge underlying machine learning is generalisation to new data.\nThis work studies generalisation for datasets consisting of related tasks that\nmay differ in causal mechanisms. For example, observational medical data for\ncomplex diseases suffers from heterogeneity in causal mechanisms of disease\nacross patients, creating challenges for machine learning algorithms that need\nto generalise to new patients outside of the training dataset. Common\napproaches for learning supervised models with heterogeneous datasets include\nlearning a global model for the entire dataset, learning local models for each\ntasks' data, or utilising hierarchical, meta-learning and multi-task learning\napproaches to learn how to generalise from data pooled across multiple tasks.\nIn this paper we propose causal similarity-based hierarchical Bayesian models\nto improve generalisation to new tasks by learning how to pool data from\ntraining tasks with similar causal mechanisms. We apply this general modelling\nprinciple to Bayesian neural networks and compare a variety of methods for\nestimating causal task similarity (for both known and unknown causal models).\nWe demonstrate the benefits of our approach and applicability to real world\nproblems through a range of experiments on simulated and real data.",
          "link": "http://arxiv.org/abs/2310.12595",
          "publishedOn": "2023-10-21T00:41:38.776Z",
          "wordCount": 679,
          "title": "Causal Similarity-Based Hierarchical Bayesian Models. (arXiv:2310.12595v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12667",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Karimi_B/0/1/0/all/0/1\">Belhal Karimi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_J/0/1/0/all/0/1\">Jianwen Xie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>",
          "description": "We propose in this paper, STANLEY, a STochastic gradient ANisotropic LangEvin\ndYnamics, for sampling high dimensional data. With the growing efficacy and\npotential of Energy-Based modeling, also known as non-normalized probabilistic\nmodeling, for modeling a generative process of different natures of high\ndimensional data observations, we present an end-to-end learning algorithm for\nEnergy-Based models (EBM) with the purpose of improving the quality of the\nresulting sampled data points. While the unknown normalizing constant of EBMs\nmakes the training procedure intractable, resorting to Markov Chain Monte Carlo\n(MCMC) is in general a viable option. Realizing what MCMC entails for the EBM\ntraining, we propose in this paper, a novel high dimensional sampling method,\nbased on an anisotropic stepsize and a gradient-informed covariance matrix,\nembedded into a discretized Langevin diffusion. We motivate the necessity for\nan anisotropic update of the negative samples in the Markov Chain by the\nnonlinearity of the backbone of the EBM, here a Convolutional Neural Network.\nOur resulting method, namely STANLEY, is an optimization algorithm for training\nEnergy-Based models via our newly introduced MCMC method. We provide a\ntheoretical understanding of our sampling scheme by proving that the sampler\nleads to a geometrically uniformly ergodic Markov Chain. Several image\ngeneration experiments are provided in our paper to show the effectiveness of\nour method.",
          "link": "http://arxiv.org/abs/2310.12667",
          "publishedOn": "2023-10-21T00:41:38.769Z",
          "wordCount": 731,
          "title": "STANLEY: Stochastic Gradient Anisotropic Langevin Dynamics for Learning Energy-Based Models. (arXiv:2310.12667v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12822",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Carrizosa_E/0/1/0/all/0/1\">Emilio Carrizosa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramirez_Ayerbe_J/0/1/0/all/0/1\">Jasone Ram&#xed;rez-Ayerbe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Morales_D/0/1/0/all/0/1\">Dolores Romero Morales</a>",
          "description": "Due to the increasing use of Machine Learning models in high stakes decision\nmaking settings, it has become increasingly important to have tools to\nunderstand how models arrive at decisions. Assuming a trained Supervised\nClassification model, explanations can be obtained via counterfactual analysis:\na counterfactual explanation of an instance indicates how this instance should\nbe minimally modified so that the perturbed instance is classified in the\ndesired class by the Machine Learning classification model. Most of the\nCounterfactual Analysis literature focuses on the single-instance\nsingle-counterfactual setting, in which the analysis is done for one single\ninstance to provide one single explanation. Taking a stakeholder's perspective,\nin this paper we introduce the so-called collective counterfactual\nexplanations. By means of novel Mathematical Optimization models, we provide a\ncounterfactual explanation for each instance in a group of interest, so that\nthe total cost of the perturbations is minimized under some linking\nconstraints. Making the process of constructing counterfactuals collective\ninstead of individual enables us to detect the features that are critical to\nthe entire dataset to have the individuals classified in the desired class. Our\nmethodology allows for some instances to be treated individually, performing\nthe collective counterfactual analysis for a fraction of records of the group\nof interest. This way, outliers are identified and handled appropriately. Under\nsome assumptions on the classifier and the space in which counterfactuals are\nsought, finding collective counterfactuals is reduced to solving a convex\nquadratic linearly constrained mixed integer optimization problem, which, for\ndatasets of moderate size, can be solved to optimality using existing solvers.\nThe performance of our approach is illustrated on real-world datasets,\ndemonstrating its usefulness.",
          "link": "http://arxiv.org/abs/2310.12822",
          "publishedOn": "2023-10-21T00:41:38.760Z",
          "wordCount": 840,
          "title": "Generating collective counterfactual explanations in score-based classification via mathematical optimization. (arXiv:2310.12822v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deora_P/0/1/0/all/0/1\">Puneesh Deora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaderi_R/0/1/0/all/0/1\">Rouzbeh Ghaderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taheri_H/0/1/0/all/0/1\">Hossein Taheri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "The training and generalization dynamics of the Transformer's core mechanism,\nnamely the Attention mechanism, remain under-explored. Besides, existing\nanalyses primarily focus on single-head attention. Inspired by the demonstrated\nbenefits of overparameterization when training fully-connected networks, we\ninvestigate the potential optimization and generalization advantages of using\nmultiple attention heads. Towards this goal, we derive convergence and\ngeneralization guarantees for gradient-descent training of a single-layer\nmulti-head self-attention model, under a suitable realizability condition on\nthe data. We then establish primitive conditions on the initialization that\nensure realizability holds. Finally, we demonstrate that these conditions are\nsatisfied for a simple tokenized-mixture model. We expect the analysis can be\nextended to various data-model and architecture variations.",
          "link": "http://arxiv.org/abs/2310.12680",
          "publishedOn": "2023-10-21T00:41:38.731Z",
          "wordCount": 639,
          "title": "On the Optimization and Generalization of Multi-head Attention. (arXiv:2310.12680v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giambagli_L/0/1/0/all/0/1\">Lorenzo Giambagli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buffoni_L/0/1/0/all/0/1\">Lorenzo Buffoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chicchi_L/0/1/0/all/0/1\">Lorenzo Chicchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fanelli_D/0/1/0/all/0/1\">Duccio Fanelli</a>",
          "description": "In theoretical ML, the teacher-student paradigm is often employed as an\neffective metaphor for real-life tuition. The above scheme proves particularly\nrelevant when the student network is overparameterized as compared to the\nteacher network. Under these operating conditions, it is tempting to speculate\nthat the student ability to handle the given task could be eventually stored in\na sub-portion of the whole network. This latter should be to some extent\nreminiscent of the frozen teacher structure, according to suitable metrics,\nwhile being approximately invariant across different architectures of the\nstudent candidate network. Unfortunately, state-of-the-art conventional\nlearning techniques could not help in identifying the existence of such an\ninvariant subnetwork, due to the inherent degree of non-convexity that\ncharacterizes the examined problem. In this work, we take a leap forward by\nproposing a radically different optimization scheme which builds on a spectral\nrepresentation of the linear transfer of information between layers. The\ngradient is hence calculated with respect to both eigenvalues and eigenvectors\nwith negligible increase in terms of computational and complexity load, as\ncompared to standard training algorithms. Working in this framework, we could\nisolate a stable student substructure, that mirrors the true complexity of the\nteacher in terms of computing neurons, path distribution and topological\nattributes. When pruning unimportant nodes of the trained student, as follows a\nranking that reflects the optimized eigenvalues, no degradation in the recorded\nperformance is seen above a threshold that corresponds to the effective teacher\nsize. The observed behavior can be pictured as a genuine second-order phase\ntransition that bears universality traits.",
          "link": "http://arxiv.org/abs/2310.12612",
          "publishedOn": "2023-10-21T00:41:38.696Z",
          "wordCount": 805,
          "title": "How a student becomes a teacher: learning and forgetting through Spectral methods. (arXiv:2310.12612v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12447",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_A/0/1/0/all/0/1\">Abhisek Chakraborty</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Anirban Bhattacharya</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pati_D/0/1/0/all/0/1\">Debdeep Pati</a>",
          "description": "We commonly encounter the problem of identifying an optimally weight adjusted\nversion of the empirical distribution of observed data, adhering to predefined\nconstraints on the weights. Such constraints often manifest as restrictions on\nthe moments, tail behaviour, shapes, number of modes, etc., of the resulting\nweight adjusted empirical distribution. In this article, we substantially\nenhance the flexibility of such methodology by introducing a nonparametrically\nimbued distributional constraints on the weights, and developing a general\nframework leveraging the maximum entropy principle and tools from optimal\ntransport. The key idea is to ensure that the maximum entropy weight adjusted\nempirical distribution of the observed data is close to a pre-specified\nprobability distribution in terms of the optimal transport metric while\nallowing for subtle departures. The versatility of the framework is\ndemonstrated in the context of three disparate applications where data\nre-weighting is warranted to satisfy side constraints on the optimization\nproblem at the heart of the statistical task: namely, portfolio allocation,\nsemi-parametric inference for complex surveys, and ensuring algorithmic\nfairness in machine learning algorithms.",
          "link": "http://arxiv.org/abs/2310.12447",
          "publishedOn": "2023-10-21T00:41:38.690Z",
          "wordCount": 677,
          "title": "Constrained Reweighting of Distributions: an Optimal Transport Approach. (arXiv:2310.12447v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12743",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Flouris_K/0/1/0/all/0/1\">Kyriakos Flouris</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Konukoglu_E/0/1/0/all/0/1\">Ender Konukoglu</a>",
          "description": "Manifold learning flows are a class of generative modelling techniques that\nassume a low-dimensional manifold description of the data. The embedding of\nsuch manifold into the high-dimensional space of the data is achieved via\nlearnable invertible transformations. Therefore, once the manifold is properly\naligned via a reconstruction loss, the probability density is tractable on the\nmanifold and maximum likelihood can be used optimize the network parameters.\nNaturally, the lower-dimensional representation of the data requires an\ninjective-mapping. Recent approaches were able to enforce that density aligns\nwith the modelled manifold, while efficiently calculating the density\nvolume-change term when embedding to the higher-dimensional space. However,\nunless the injective-mapping is analytically predefined, the learned manifold\nis not necessarily an efficient representation of the data. Namely, the latent\ndimensions of such models frequently learn an entangled intrinsic basis with\ndegenerate information being stored in each dimension. Alternatively, if a\nlocally orthogonal and/or sparse basis is to be learned, here coined canonical\nintrinsic basis, it can serve in learning a more compact latent space\nrepresentation. Towards this end, we propose a canonical manifold learning flow\nmethod, where a novel optimization objective enforces the transformation matrix\nto have few prominent and orthogonal basis functions. Canonical manifold flow\nyields a more efficient use of the latent space, automatically generating fewer\nprominent and distinct dimensions to represent data, and consequently a better\napproximation of target distributions than other manifold flow methods in most\nexperiments we conducted, resulting in lower FID scores.",
          "link": "http://arxiv.org/abs/2310.12743",
          "publishedOn": "2023-10-21T00:41:38.595Z",
          "wordCount": 739,
          "title": "Canonical normalizing flows for manifold learning. (arXiv:2310.12743v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Barbier__Chebbah_A/0/1/0/all/0/1\">Alex Barbier--Chebbah</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Vestergaard_C/0/1/0/all/0/1\">Christian L. Vestergaard</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Masson_J/0/1/0/all/0/1\">Jean-Baptiste Masson</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Boursier_E/0/1/0/all/0/1\">Etienne Boursier</a> (CELESTE)",
          "description": "Entropy maximization and free energy minimization are general physical\nprinciples for modeling the dynamics of various physical systems. Notable\nexamples include modeling decision-making within the brain using the\nfree-energy principle, optimizing the accuracy-complexity trade-off when\naccessing hidden variables with the information bottleneck principle (Tishby et\nal., 2000), and navigation in random environments using information\nmaximization (Vergassola et al., 2007). Built on this principle, we propose a\nnew class of bandit algorithms that maximize an approximation to the\ninformation of a key variable within the system. To this end, we develop an\napproximated analytical physics-based representation of an entropy to forecast\nthe information gain of each action and greedily choose the one with the\nlargest information gain. This method yields strong performances in classical\nbandit settings. Motivated by its empirical success, we prove its asymptotic\noptimality for the two-armed bandit problem with Gaussian rewards. Owing to its\nability to encompass the system's properties in a global physical functional,\nthis approach can be efficiently adapted to more complex bandit settings,\ncalling for further investigation of information maximization approaches for\nmulti-armed bandit problems.",
          "link": "http://arxiv.org/abs/2310.12563",
          "publishedOn": "2023-10-21T00:41:38.484Z",
          "wordCount": 689,
          "title": "Approximate information maximization for bandit games. (arXiv:2310.12563v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12437",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hanchi_A/0/1/0/all/0/1\">Ayoub El Hanchi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>",
          "description": "We study the performance of empirical risk minimization on the $p$-norm\nlinear regression problem for $p \\in (1, \\infty)$. We show that, in the\nrealizable case, under no moment assumptions, and up to a\ndistribution-dependent constant, $O(d)$ samples are enough to exactly recover\nthe target. Otherwise, for $p \\in [2, \\infty)$, and under weak moment\nassumptions on the target and the covariates, we prove a high probability\nexcess risk bound on the empirical risk minimizer whose leading term matches,\nup to a constant that depends only on $p$, the asymptotically exact rate. We\nextend this result to the case $p \\in (1, 2)$ under mild assumptions that\nguarantee the existence of the Hessian of the risk at its minimizer.",
          "link": "http://arxiv.org/abs/2310.12437",
          "publishedOn": "2023-10-21T00:41:38.457Z",
          "wordCount": 636,
          "title": "Optimal Excess Risk Bounds for Empirical Risk Minimization on $p$-norm Linear Regression. (arXiv:2310.12437v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoshikawa_u/0/1/0/all/0/1\">uya Yoshikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1\">Tomoharu Iwata</a>",
          "description": "The quality of explanations for the predictions of complex machine learning\npredictors is often measured using insertion and deletion metrics, which assess\nthe faithfulness of the explanations, i.e., how correctly the explanations\nreflect the predictor's behavior. To improve the faithfulness, we propose\ninsertion/deletion metric-aware explanation-based optimization (ID-ExpO), which\noptimizes differentiable predictors to improve both insertion and deletion\nscores of the explanations while keeping their predictive accuracy. Since the\noriginal insertion and deletion metrics are indifferentiable with respect to\nthe explanations and directly unavailable for gradient-based optimization, we\nextend the metrics to be differentiable and use them to formalize insertion and\ndeletion metric-based regularizers. The experimental results on image and\ntabular datasets show that the deep neural networks-based predictors fine-tuned\nusing ID-ExpO enable popular post-hoc explainers to produce more faithful and\neasy-to-interpret explanations while keeping high predictive accuracy.",
          "link": "http://arxiv.org/abs/2310.12553",
          "publishedOn": "2023-10-21T00:41:38.442Z",
          "wordCount": 646,
          "title": "Explanation-Based Training with Differentiable Insertion/Deletion Metric-Aware Regularizers. (arXiv:2310.12553v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yichuan Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shenghao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chiwun Yang</a>",
          "description": "In the realm of deep learning, transformers have emerged as a dominant\narchitecture, particularly in natural language processing tasks. However, with\ntheir widespread adoption, concerns regarding the security and privacy of the\ndata processed by these models have arisen. In this paper, we address a pivotal\nquestion: Can the data fed into transformers be recovered using their attention\nweights and outputs? We introduce a theoretical framework to tackle this\nproblem. Specifically, we present an algorithm that aims to recover the input\ndata $X \\in \\mathbb{R}^{d \\times n}$ from given attention weights $W = QK^\\top\n\\in \\mathbb{R}^{d \\times d}$ and output $B \\in \\mathbb{R}^{n \\times n}$ by\nminimizing the loss function $L(X)$. This loss function captures the\ndiscrepancy between the expected output and the actual output of the\ntransformer. Our findings have significant implications for the Localized\nLayer-wise Mechanism (LLM), suggesting potential vulnerabilities in the model's\ndesign from a security and privacy perspective. This work underscores the\nimportance of understanding and safeguarding the internal workings of\ntransformers to ensure the confidentiality of processed data.",
          "link": "http://arxiv.org/abs/2310.12462",
          "publishedOn": "2023-10-21T00:41:38.430Z",
          "wordCount": 698,
          "title": "Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights. (arXiv:2310.12462v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12544",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+OLoughlin_L/0/1/0/all/0/1\">Luke O&#x27;Loughlin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maclean_J/0/1/0/all/0/1\">John Maclean</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Black_A/0/1/0/all/0/1\">Andrew Black</a>",
          "description": "Stochastic processes defined on integer valued state spaces are popular\nwithin the physical and biological sciences. These models are necessary for\ncapturing the dynamics of small systems where the individual nature of the\npopulations cannot be ignored and stochastic effects are important. The\ninference of the parameters of such models, from time series data, is difficult\ndue to intractability of the likelihood; current methods, based on simulations\nof the underlying model, can be so computationally expensive as to be\nprohibitive. In this paper we construct a neural likelihood approximation for\ninteger valued time series data using causal convolutions, which allows us to\nevaluate the likelihood of the whole time series in parallel. We demonstrate\nour method by performing inference on a number of ecological and\nepidemiological models, showing that we can accurately approximate the true\nposterior while achieving significant computational speed ups in situations\nwhere current methods struggle.",
          "link": "http://arxiv.org/abs/2310.12544",
          "publishedOn": "2023-10-21T00:41:38.186Z",
          "wordCount": 651,
          "title": "Neural Likelihood Approximation for Integer Valued Time Series Data. (arXiv:2310.12544v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scarvelis_C/0/1/0/all/0/1\">Christopher Scarvelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borde_H/0/1/0/all/0/1\">Haitz S&#xe1;ez de Oc&#xe1;riz Borde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1\">Justin Solomon</a>",
          "description": "Score-based generative models (SGMs) sample from a target distribution by\niteratively transforming noise using the score function of the perturbed\ntarget. For any finite training set, this score function can be evaluated in\nclosed form, but the resulting SGM memorizes its training data and does not\ngenerate novel samples. In practice, one approximates the score by training a\nneural network via score-matching. The error in this approximation promotes\ngeneralization, but neural SGMs are costly to train and sample, and the\neffective regularization this error provides is not well-understood\ntheoretically. In this work, we instead explicitly smooth the closed-form score\nto obtain an SGM that generates novel samples without training. We analyze our\nmodel and propose an efficient nearest-neighbor-based estimator of its score\nfunction. Using this estimator, our method achieves sampling times competitive\nwith neural SGMs while running on consumer-grade CPUs.",
          "link": "http://arxiv.org/abs/2310.12395",
          "publishedOn": "2023-10-21T00:41:38.179Z",
          "wordCount": 634,
          "title": "Closed-Form Diffusion Models. (arXiv:2310.12395v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rosaler_J/0/1/0/all/0/1\">Joshua Rosaler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Desai_D/0/1/0/all/0/1\">Dhruv Desai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sarmah_B/0/1/0/all/0/1\">Bhaskarjit Sarmah</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vamvourellis_D/0/1/0/all/0/1\">Dimitrios Vamvourellis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Onay_D/0/1/0/all/0/1\">Deran Onay</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mehta_D/0/1/0/all/0/1\">Dhagash Mehta</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pasquali_S/0/1/0/all/0/1\">Stefano Pasquali</a>",
          "description": "We initiate a novel approach to explain the out of sample performance of\nrandom forest (RF) models by exploiting the fact that any RF can be formulated\nas an adaptive weighted K nearest-neighbors model. Specifically, we use the\nproximity between points in the feature space learned by the RF to re-write\nrandom forest predictions exactly as a weighted average of the target labels of\ntraining data points. This linearity facilitates a local notion of\nexplainability of RF predictions that generates attributions for any model\nprediction across observations in the training set, and thereby complements\nestablished methods like SHAP, which instead generates attributions for a model\nprediction across dimensions of the feature space. We demonstrate this approach\nin the context of a bond pricing model trained on US corporate bond trades, and\ncompare our approach to various existing approaches to model explainability.",
          "link": "http://arxiv.org/abs/2310.12428",
          "publishedOn": "2023-10-21T00:41:38.035Z",
          "wordCount": 673,
          "title": "Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12285",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zgodic_A/0/1/0/all/0/1\">Anja Zgodic</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bai_R/0/1/0/all/0/1\">Ray Bai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiajia Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McLain_A/0/1/0/all/0/1\">Alexander C. McLain</a>",
          "description": "High-dimensional longitudinal data is increasingly used in a wide range of\nscientific studies. However, there are few statistical methods for\nhigh-dimensional linear mixed models (LMMs), as most Bayesian variable\nselection or penalization methods are designed for independent observations.\nAdditionally, the few available software packages for high-dimensional LMMs\nsuffer from scalability issues. This work presents an efficient and accurate\nBayesian framework for high-dimensional LMMs. We use empirical Bayes estimators\nof hyperparameters for increased flexibility and an\nExpectation-Conditional-Minimization (ECM) algorithm for computationally\nefficient maximum a posteriori probability (MAP) estimation of parameters. The\nnovelty of the approach lies in its partitioning and parameter expansion as\nwell as its fast and scalable computation. We illustrate Linear Mixed Modeling\nwith PaRtitiOned empirical Bayes ECM (LMM-PROBE) in simulation studies\nevaluating fixed and random effects estimation along with computation time. A\nreal-world example is provided using data from a study of lupus in children,\nwhere we identify genes and clinical factors associated with a new lupus\nbiomarker and predict the biomarker over time.",
          "link": "http://arxiv.org/abs/2310.12285",
          "publishedOn": "2023-10-21T00:41:38.001Z",
          "wordCount": 684,
          "title": "Sparse high-dimensional linear mixed modeling with a partitioned empirical Bayes ECM algorithm. (arXiv:2310.12285v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12304",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Park_R/0/1/0/all/0/1\">Ryan Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Theisen_R/0/1/0/all/0/1\">Ryan Theisen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sahni_N/0/1/0/all/0/1\">Navriti Sahni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Patek_M/0/1/0/all/0/1\">Marcel Patek</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cichonska_A/0/1/0/all/0/1\">Anna Cicho&#x144;ska</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rahman_R/0/1/0/all/0/1\">Rayees Rahman</a>",
          "description": "Molecular language modeling is an effective approach to generating novel\nchemical structures. However, these models do not \\emph{a priori} encode\ncertain preferences a chemist may desire. We investigate the use of fine-tuning\nusing Direct Preference Optimization to better align generated molecules with\nchemist preferences. Our findings suggest that this approach is simple,\nefficient, and highly effective.",
          "link": "http://arxiv.org/abs/2310.12304",
          "publishedOn": "2023-10-21T00:41:37.989Z",
          "wordCount": 557,
          "title": "Preference Optimization for Molecular Language Models. (arXiv:2310.12304v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Day_H/0/1/0/all/0/1\">Hannah Day</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahn_Y/0/1/0/all/0/1\">Yonatan Kahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_D/0/1/0/all/0/1\">Daniel A. Roberts</a>",
          "description": "Fully-connected deep neural networks with weights initialized from\nindependent Gaussian distributions can be tuned to criticality, which prevents\nthe exponential growth or decay of signals propagating through the network.\nHowever, such networks still exhibit fluctuations that grow linearly with the\ndepth of the network, which may impair the training of networks with width\ncomparable to depth. We show analytically that rectangular networks with tanh\nactivations and weights initialized from the ensemble of orthogonal matrices\nhave corresponding preactivation fluctuations which are independent of depth,\nto leading order in inverse width. Moreover, we demonstrate numerically that,\nat initialization, all correlators involving the neural tangent kernel (NTK)\nand its descendants at leading order in inverse width -- which govern the\nevolution of observables during training -- saturate at a depth of $\\sim 20$,\nrather than growing without bound as in the case of Gaussian initializations.\nWe speculate that this structure preserves finite-width feature learning while\nreducing overall noise, thus improving both generalization and training speed.\nWe provide some experimental justification by relating empirical measurements\nof the NTK to the superior performance of deep nonlinear orthogonal networks\ntrained under full-batch gradient descent on the MNIST and CIFAR-10\nclassification tasks.",
          "link": "http://arxiv.org/abs/2310.07765",
          "publishedOn": "2023-10-14T00:41:46.967Z",
          "wordCount": 734,
          "title": "Feature Learning and Generalization in Deep Networks with Orthogonal Weights. (arXiv:2310.07765v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yite Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jiahao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanlin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Cong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jianbo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haibin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruoyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Scaling of deep neural networks, especially Transformers, is pivotal for\ntheir surging performance and has further led to the emergence of sophisticated\nreasoning capabilities in foundation models. Such scaling generally requires\ntraining large models from scratch with random initialization, failing to\nleverage the knowledge acquired by their smaller counterparts, which are\nalready resource-intensive to obtain. To tackle this inefficiency, we present\n$\\textbf{L}$ossl$\\textbf{E}$ss $\\textbf{MO}$del Expansio$\\textbf{N}$ (LEMON), a\nrecipe to initialize scaled models using the weights of their smaller but\npre-trained counterparts. This is followed by model training with an optimized\nlearning rate scheduler tailored explicitly for the scaled models,\nsubstantially reducing the training time compared to training from scratch.\nNotably, LEMON is versatile, ensuring compatibility with various network\nstructures, including models like Vision Transformers and BERT. Our empirical\nresults demonstrate that LEMON reduces computational costs by 56.7% for Vision\nTransformers and 33.2% for BERT when compared to training from scratch.",
          "link": "http://arxiv.org/abs/2310.07999",
          "publishedOn": "2023-10-14T00:41:34.875Z",
          "wordCount": null,
          "title": "LEMON: Lossless model expansion. (arXiv:2310.07999v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.09129",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Barnes_L/0/1/0/all/0/1\">Leighton P. Barnes</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dytso_A/0/1/0/all/0/1\">Alex Dytso</a>, <a href=\"http://arxiv.org/find/math/1/au:+Liu_J/0/1/0/all/0/1\">Jingbo Liu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Poor_H/0/1/0/all/0/1\">H. Vincent Poor</a>",
          "description": "Consider the problem of estimating a random variable $X$ from noisy\nobservations $Y = X+ Z$, where $Z$ is standard normal, under the $L^1$ fidelity\ncriterion. It is well known that the optimal Bayesian estimator in this setting\nis the conditional median. This work shows that the only prior distribution on\n$X$ that induces linearity in the conditional median is Gaussian.\n\nAlong the way, several other results are presented. In particular, it is\ndemonstrated that if the conditional distribution $P_{X|Y=y}$ is symmetric for\nall $y$, then $X$ must follow a Gaussian distribution. Additionally, we\nconsider other $L^p$ losses and observe the following phenomenon: for $p \\in\n[1,2]$, Gaussian is the only prior distribution that induces a linear optimal\nBayesian estimator, and for $p \\in (2,\\infty)$, infinitely many prior\ndistributions on $X$ can induce linearity. Finally, extensions are provided to\nencompass noise models leading to conditional distributions from certain\nexponential families.",
          "link": "http://arxiv.org/abs/2309.09129",
          "publishedOn": "2023-10-14T00:41:34.685Z",
          "wordCount": null,
          "title": "$L^1$ Estimation: On the Optimality of Linear Estimators. (arXiv:2309.09129v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08287",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Laurent_O/0/1/0/all/0/1\">Olivier Laurent</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aldea_E/0/1/0/all/0/1\">Emanuel Aldea</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Franchi_G/0/1/0/all/0/1\">Gianni Franchi</a>",
          "description": "The distribution of the weights of modern deep neural networks (DNNs) -\ncrucial for uncertainty quantification and robustness - is an eminently complex\nobject due to its extremely high dimensionality. This paper proposes one of the\nfirst large-scale explorations of the posterior distribution of deep Bayesian\nNeural Networks (BNNs), expanding its study to real-world vision tasks and\narchitectures. Specifically, we investigate the optimal approach for\napproximating the posterior, analyze the connection between posterior quality\nand uncertainty quantification, delve into the impact of modes on the\nposterior, and explore methods for visualizing the posterior. Moreover, we\nuncover weight-space symmetries as a critical aspect for understanding the\nposterior. To this extent, we develop an in-depth assessment of the impact of\nboth permutation and scaling symmetries that tend to obfuscate the Bayesian\nposterior. While the first type of transformation is known for duplicating\nmodes, we explore the relationship between the latter and L2 regularization,\nchallenging previous misconceptions. Finally, to help the community improve our\nunderstanding of the Bayesian posterior, we will shortly release the first\nlarge-scale checkpoint dataset, including thousands of real-world models and\nour codes.",
          "link": "http://arxiv.org/abs/2310.08287",
          "publishedOn": "2023-10-14T00:41:34.404Z",
          "wordCount": null,
          "title": "A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors. (arXiv:2310.08287v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.14219",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sousa_M/0/1/0/all/0/1\">Martim Sousa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tome_A/0/1/0/all/0/1\">Ana Maria Tom&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moreira_J/0/1/0/all/0/1\">Jos&#xe9; Moreira</a>",
          "description": "This paper introduces a novel model-agnostic algorithm called adaptive\nensemble batch multi-input multi-output conformalized quantile regression\n(AEnbMIMOCQR} that enables forecasters to generate multi-step ahead prediction\nintervals for a fixed pre-specified miscoverage rate in a distribution-free\nmanner. Our method is grounded on conformal prediction principles, however, it\ndoes not require data splitting and provides close to exact coverage even when\nthe data is not exchangeable. Moreover, the resulting prediction intervals,\nbesides being empirically valid along the forecast horizon, do not neglect\nheteroscedasticity. AEnbMIMOCQR is designed to be robust to distribution\nshifts, which means that its prediction intervals remain reliable over an\nunlimited period of time, without entailing retraining or imposing unrealistic\nstrict assumptions on the data-generating process. Through methodically\nexperimentation, we demonstrate that our approach outperforms other competitive\nmethods on both real-world and synthetic datasets. The code used in the\nexperimental part and a tutorial on how to use AEnbMIMOCQR can be found at the\nfollowing GitHub repository: https://github.com/Quilograma/AEnbMIMOCQR.",
          "link": "http://arxiv.org/abs/2207.14219",
          "publishedOn": "2023-10-14T00:41:34.247Z",
          "wordCount": null,
          "title": "A general framework for multi-step ahead adaptive conformal heteroscedastic time series forecasting. (arXiv:2207.14219v9 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Luyao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alghunaim_S/0/1/0/all/0/1\">Sulaiman A. Alghunaim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1\">Kun Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Condat_L/0/1/0/all/0/1\">Laurent Condat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jinde Cao</a>",
          "description": "Distributed optimization methods with random communication skips are gaining\nincreasing attention due to their proven benefits in accelerating communication\ncomplexity. Nevertheless, existing research mainly focuses on centralized\ncommunication protocols for strongly convex deterministic settings. In this\nwork, we provide a decentralized optimization method called RandCom, which\nincorporates probabilistic local updates. We analyze the performance of RandCom\nin stochastic non-convex, convex, and strongly convex settings and demonstrate\nits ability to asymptotically reduce communication overhead by the probability\nof communication. Additionally, we prove that RandCom achieves linear speedup\nas the number of nodes increases. In stochastic strongly convex settings, we\nfurther prove that RandCom can achieve linear speedup with network-independent\nstepsizes. Moreover, we apply RandCom to federated learning and provide\npositive results concerning the potential for achieving linear speedup and the\nsuitability of the probabilistic local update approach for non-convex settings.",
          "link": "http://arxiv.org/abs/2310.07983",
          "publishedOn": "2023-10-14T00:41:33.641Z",
          "wordCount": 677,
          "title": "RandCom: Random Communication Skipping Method for Decentralized Stochastic Optimization. (arXiv:2310.07983v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08495",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Goode_K/0/1/0/all/0/1\">Katherine Goode</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ries_D/0/1/0/all/0/1\">Daniel Ries</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McClernon_K/0/1/0/all/0/1\">Kellie McClernon</a>",
          "description": "The 2022 National Defense Strategy of the United States listed climate change\nas a serious threat to national security. Climate intervention methods, such as\nstratospheric aerosol injection, have been proposed as mitigation strategies,\nbut the downstream effects of such actions on a complex climate system are not\nwell understood. The development of algorithmic techniques for quantifying\nrelationships between source and impact variables related to a climate event\n(i.e., a climate pathway) would help inform policy decisions. Data-driven deep\nlearning models have become powerful tools for modeling highly nonlinear\nrelationships and may provide a route to characterize climate variable\nrelationships. In this paper, we explore the use of an echo state network (ESN)\nfor characterizing climate pathways. ESNs are a computationally efficient\nneural network variation designed for temporal data, and recent work proposes\nESNs as a useful tool for forecasting spatio-temporal climate data. Like other\nneural networks, ESNs are non-interpretable black-box models, which poses a\nhurdle for understanding variable relationships. We address this issue by\ndeveloping feature importance methods for ESNs in the context of\nspatio-temporal data to quantify variable relationships captured by the model.\nWe conduct a simulation study to assess and compare the feature importance\ntechniques, and we demonstrate the approach on reanalysis climate data. In the\nclimate application, we select a time period that includes the 1991 volcanic\neruption of Mount Pinatubo. This event was a significant stratospheric aerosol\ninjection, which we use as a proxy for an artificial stratospheric aerosol\ninjection. Using the proposed approach, we are able to characterize\nrelationships between pathway variables associated with this event.",
          "link": "http://arxiv.org/abs/2310.08495",
          "publishedOn": "2023-10-14T00:41:31.386Z",
          "wordCount": 766,
          "title": "Characterizing climate pathways using feature importance on echo state networks. (arXiv:2310.08495v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08331",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zangirolami_V/0/1/0/all/0/1\">Valentina Zangirolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Borrotti_M/0/1/0/all/0/1\">Matteo Borrotti</a>",
          "description": "Incomplete knowledge of the environment leads an agent to make decisions\nunder uncertainty. One of the major dilemmas in Reinforcement Learning (RL)\nwhere an autonomous agent has to balance two contrasting needs in making its\ndecisions is: exploiting the current knowledge of the environment to maximize\nthe cumulative reward as well as exploring actions that allow improving the\nknowledge of the environment, hopefully leading to higher reward values\n(exploration-exploitation trade-off). Concurrently, another relevant issue\nregards the full observability of the states, which may not be assumed in all\napplications. Such as when only 2D images are considered as input in a RL\napproach used for finding the optimal action within a 3D simulation\nenvironment. In this work, we address these issues by deploying and testing\nseveral techniques to balance exploration and exploitation trade-off on\npartially observable systems for predicting steering wheels in autonomous\ndriving scenario. More precisely, the final aim is to investigate the effects\nof using both stochastic and deterministic multi-armed bandit strategies\ncoupled with a Deep Recurrent Q-Network. Additionally, we adapted and evaluated\nthe impact of an innovative method to improve the learning phase of the\nunderlying Convolutional Recurrent Neural Network. We aim to show that adaptive\nstochastic methods for exploration better approximate the trade-off between\nexploration and exploitation as, in general, Softmax and Max-Boltzmann\nstrategies are able to outperform epsilon-greedy techniques.",
          "link": "http://arxiv.org/abs/2310.08331",
          "publishedOn": "2023-10-14T00:41:31.148Z",
          "wordCount": 725,
          "title": "Impact of multi-armed bandit strategies on deep recurrent reinforcement learning. (arXiv:2310.08331v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.05288",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Clark_K/0/1/0/all/0/1\">Katharine M. Clark</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McNicholas_P/0/1/0/all/0/1\">Paul D. McNicholas</a>",
          "description": "Matrix-variate distributions are a recent addition to the model-based\nclustering field, thereby making it possible to analyze data in matrix form\nwith complex structure such as images and time series. Due to its recent\nappearance, there is limited literature on matrix-variate data, with even less\non dealing with outliers in these models. An approach for clustering\nmatrix-variate normal data with outliers is discussed. The approach, which uses\nthe distribution of subset log-likelihoods, extends the OCLUST algorithm to\nmatrix-variate normal data and uses an iterative approach to detect and trim\noutliers.",
          "link": "http://arxiv.org/abs/2310.05288",
          "publishedOn": "2023-10-14T00:41:29.911Z",
          "wordCount": 594,
          "title": "Clustering Three-Way Data with Outliers. (arXiv:2310.05288v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deuschel_J/0/1/0/all/0/1\">Jannik Deuschel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellington_C/0/1/0/all/0/1\">Caleb N. Ellington</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lengerich_B/0/1/0/all/0/1\">Benjamin J. Lengerich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yingtao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friederich_P/0/1/0/all/0/1\">Pascal Friederich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>",
          "description": "Interpretable policy learning seeks to estimate intelligible decision\npolicies from observed actions; however, existing models fall short by forcing\na tradeoff between accuracy and interpretability. This tradeoff limits\ndata-driven interpretations of human decision-making process. e.g. to audit\nmedical decisions for biases and suboptimal practices, we require models of\ndecision processes which provide concise descriptions of complex behaviors.\nFundamentally, existing approaches are burdened by this tradeoff because they\nrepresent the underlying decision process as a universal policy, when in fact\nhuman decisions are dynamic and can change drastically with contextual\ninformation. Thus, we propose Contextualized Policy Recovery (CPR), which\nre-frames the problem of modeling complex decision processes as a multi-task\nlearning problem in which complex decision policies are comprised of\ncontext-specific policies. CPR models each context-specific policy as a linear\nobservation-to-action mapping, and generates new decision models\n$\\textit{on-demand}$ as contexts are updated with new observations. CPR is\ncompatible with fully offline and partially observable decision environments,\nand can be tailored to incorporate any recurrent black-box model or\ninterpretable decision model. We assess CPR through studies on simulated and\nreal data, achieving state-of-the-art performance on the canonical tasks of\npredicting antibiotic prescription in intensive care units ($+22\\%$ AUROC vs.\nprevious SOTA) and predicting MRI prescription for Alzheimer's patients\n($+7.7\\%$ AUROC vs. previous SOTA). With this improvement in predictive\nperformance, CPR closes the accuracy gap between interpretable and black-box\nmethods for policy learning, allowing high-resolution exploration and analysis\nof context-specific decision models.",
          "link": "http://arxiv.org/abs/2310.07918",
          "publishedOn": "2023-10-14T00:41:29.888Z",
          "wordCount": 771,
          "title": "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning. (arXiv:2310.07918v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.12345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldwaser_A/0/1/0/all/0/1\">Adrian Goldwaser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1\">Hong Ge</a>",
          "description": "Larger and deeper networks generalise well despite their increased capacity\nto overfit. Understanding why this happens is theoretically and practically\nimportant. One recent approach looks at the infinitely wide limits of such\nnetworks and their corresponding kernels. However, these theoretical tools\ncannot fully explain finite networks as the empirical kernel changes\nsignificantly during gradient-descent-based training in contrast to infinite\nnetworks. In this work, we derive an iterative linearised training method as a\nnovel empirical tool to further investigate this distinction, allowing us to\ncontrol for sparse (i.e. infrequent) feature updates and quantify the frequency\nof feature learning needed to achieve comparable performance. We justify\niterative linearisation as an interpolation between a finite analog of the\ninfinite width regime, which does not learn features, and standard gradient\ndescent training, which does. Informally, we also show that it is analogous to\na damped version of the Gauss-Newton algorithm -- a second-order method. We\nshow that in a variety of cases, iterative linearised training surprisingly\nperforms on par with standard training, noting in particular how much less\nfrequent feature learning is required to achieve comparable performance. We\nalso show that feature learning is essential for good performance. Since such\nfeature learning inevitably causes changes in the NTK kernel, we provide direct\nnegative evidence for the NTK theory, which states the NTK kernel remains\nconstant during training.",
          "link": "http://arxiv.org/abs/2211.12345",
          "publishedOn": "2023-10-14T00:41:29.866Z",
          "wordCount": 766,
          "title": "Understanding Sparse Feature Updates in Deep Networks using Iterative Linearisation. (arXiv:2211.12345v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.00152",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hanneke_S/0/1/0/all/0/1\">Steve Hanneke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mahdaviyeh_Y/0/1/0/all/0/1\">Yasaman Mahdaviyeh</a>",
          "description": "Theoretical studies on transfer learning or domain adaptation have so far\nfocused on situations with a known hypothesis class or model; however in\npractice, some amount of model selection is usually involved, often appearing\nunder the umbrella term of hyperparameter-tuning: for example, one may think of\nthe problem of tuning for the right neural network architecture towards a\ntarget task, while leveraging data from a related source task.\n\nNow, in addition to the usual tradeoffs on approximation vs estimation errors\ninvolved in model selection, this problem brings in a new complexity term,\nnamely, the transfer distance between source and target distributions, which is\nknown to vary with the choice of hypothesis class.\n\nWe present a first study of this problem, focusing on classification; in\nparticular, the analysis reveals some remarkable phenomena: adaptive rates,\ni.e., those achievable with no distributional information, can be arbitrarily\nslower than oracle rates, i.e., when given knowledge on distances.",
          "link": "http://arxiv.org/abs/2305.00152",
          "publishedOn": "2023-10-14T00:41:29.861Z",
          "wordCount": 693,
          "title": "Limits of Model Selection under Transfer Learning. (arXiv:2305.00152v4 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07891",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Moniri_B/0/1/0/all/0/1\">Behrad Moniri</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_D/0/1/0/all/0/1\">Donghwan Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>",
          "description": "Feature learning is thought to be one of the fundamental reasons for the\nsuccess of deep neural networks. It is rigorously known that in two-layer\nfully-connected neural networks under certain conditions, one step of gradient\ndescent on the first layer followed by ridge regression on the second layer can\nlead to feature learning; characterized by the appearance of a separated\nrank-one component -- spike -- in the spectrum of the feature matrix. However,\nwith a constant gradient descent step size, this spike only carries information\nfrom the linear component of the target function and therefore learning\nnon-linear components is impossible. We show that with a learning rate that\ngrows with the sample size, such training in fact introduces multiple rank-one\ncomponents, each corresponding to a specific polynomial feature. We further\nprove that the limiting large-dimensional and large sample training and test\nerrors of the updated neural networks are fully characterized by these spikes.\nBy precisely analyzing the improvement in the loss, we demonstrate that these\nnon-linear features can enhance learning.",
          "link": "http://arxiv.org/abs/2310.07891",
          "publishedOn": "2023-10-14T00:41:29.856Z",
          "wordCount": 690,
          "title": "A Theory of Non-Linear Feature Learning with One Gradient Step in Two-Layer Neural Networks. (arXiv:2310.07891v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08055",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Harkonen_T/0/1/0/all/0/1\">Teemu H&#xe4;rk&#xf6;nen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vartiainen_E/0/1/0/all/0/1\">Erik M. Vartiainen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lensu_L/0/1/0/all/0/1\">Lasse Lensu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moores_M/0/1/0/all/0/1\">Matthew T. Moores</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roininen_L/0/1/0/all/0/1\">Lassi Roininen</a>",
          "description": "We propose an approach utilizing gamma-distributed random variables, coupled\nwith log-Gaussian modeling, to generate synthetic datasets suitable for\ntraining neural networks. This addresses the challenge of limited real\nobservations in various applications. We apply this methodology to both Raman\nand coherent anti-Stokes Raman scattering (CARS) spectra, using experimental\nspectra to estimate gamma process parameters. Parameter estimation is performed\nusing Markov chain Monte Carlo methods, yielding a full Bayesian posterior\ndistribution for the model which can be sampled for synthetic data generation.\nAdditionally, we model the additive and multiplicative background functions for\nRaman and CARS with Gaussian processes. We train two Bayesian neural networks\nto estimate parameters of the gamma process which can then be used to estimate\nthe underlying Raman spectrum and simultaneously provide uncertainty through\nthe estimation of parameters of a probability distribution. We apply the\ntrained Bayesian neural networks to experimental Raman spectra of\nphthalocyanine blue, aniline black, naphthol red, and red 264 pigments and also\nto experimental CARS spectra of adenosine phosphate, fructose, glucose, and\nsucrose. The results agree with deterministic point estimates for the\nunderlying Raman and CARS spectral signatures.",
          "link": "http://arxiv.org/abs/2310.08055",
          "publishedOn": "2023-10-14T00:41:29.851Z",
          "wordCount": 709,
          "title": "Log-Gaussian Gamma Processes for Training Bayesian Neural Networks in Raman and CARS Spectroscopies. (arXiv:2310.08055v1 [stat.AP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08576",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ko_P/0/1/0/all/0/1\">Po-Chen Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yilun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shao-Hua Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>",
          "description": "In this work, we present an approach to construct a video-based robot policy\ncapable of reliably executing diverse tasks across different robots and\nenvironments from few video demonstrations without using any action\nannotations. Our method leverages images as a task-agnostic representation,\nencoding both the state and action information, and text as a general\nrepresentation for specifying robot goals. By synthesizing videos that\n``hallucinate'' robot executing actions and in combination with dense\ncorrespondences between frames, our approach can infer the closed-formed action\nto execute to an environment without the need of any explicit action labels.\nThis unique capability allows us to train the policy solely based on RGB videos\nand deploy learned policies to various robotic tasks. We demonstrate the\nefficacy of our approach in learning policies on table-top manipulation and\nnavigation tasks. Additionally, we contribute an open-source framework for\nefficient video modeling, enabling the training of high-fidelity policy models\nwith four GPUs within a single day.",
          "link": "http://arxiv.org/abs/2310.08576",
          "publishedOn": "2023-10-14T00:41:29.837Z",
          "wordCount": 677,
          "title": "Learning to Act from Actionless Videos through Dense Correspondences. (arXiv:2310.08576v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.01748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_K/0/1/0/all/0/1\">Kushagra Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Score-based Generative Models (SGMs) have demonstrated exceptional synthesis\noutcomes across various tasks. However, the current design landscape of the\nforward diffusion process remains largely untapped and often relies on physical\nheuristics or simplifying assumptions. Utilizing insights from the development\nof scalable Bayesian posterior samplers, we present a complete recipe for\nformulating forward processes in SGMs, ensuring convergence to the desired\ntarget distribution. Our approach reveals that several existing SGMs can be\nseen as specific manifestations of our framework. Building upon this method, we\nintroduce Phase Space Langevin Diffusion (PSLD), which relies on score-based\nmodeling within an augmented space enriched by auxiliary variables akin to\nphysical phase space. Empirical results exhibit the superior sample quality and\nimproved speed-quality trade-off of PSLD compared to various competing\napproaches on established image synthesis benchmarks. Remarkably, PSLD achieves\nsample quality akin to state-of-the-art SGMs (FID: 2.10 for unconditional\nCIFAR-10 generation). Lastly, we demonstrate the applicability of PSLD in\nconditional synthesis using pre-trained score networks, offering an appealing\nalternative as an SGM backbone for future advancements. Code and model\ncheckpoints can be accessed at \\url{https://github.com/mandt-lab/PSLD}.",
          "link": "http://arxiv.org/abs/2303.01748",
          "publishedOn": "2023-10-14T00:41:29.813Z",
          "wordCount": 709,
          "title": "A Complete Recipe for Diffusion Generative Models. (arXiv:2303.01748v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.14041",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenyuan Liu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Parys_B/0/1/0/all/0/1\">Bart P. G. Van Parys</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lam_H/0/1/0/all/0/1\">Henry Lam</a>",
          "description": "In data-driven optimization, sample average approximation (SAA) is known to\nsuffer from the so-called optimizer's curse that causes an over-optimistic\nevaluation of the solution performance. We argue that a special type of\ndistributionallly robust optimization (DRO) formulation offers theoretical\nadvantages in correcting for this optimizer's curse compared to simple\n``margin'' adjustments to SAA and other DRO approaches: It attains a\nstatistical bound on the out-of-sample performance, for a wide class of\nobjective functions and distributions, that is nearly tightest in terms of\nexponential decay rate. This DRO uses an ambiguity set based on a Kullback\nLeibler (KL) divergence smoothed by the Wasserstein or L\\'evy-Prokhorov (LP)\ndistance via a suitable distance optimization. Computationally, we also show\nthat such a DRO, and its generalized versions using smoothed $f$-divergence,\nare not harder than DRO problems based on $f$-divergence or Wasserstein\ndistances, rendering our DRO formulations both statistically optimal and\ncomputationally viable.",
          "link": "http://arxiv.org/abs/2306.14041",
          "publishedOn": "2023-10-14T00:41:29.803Z",
          "wordCount": 678,
          "title": "Smoothed $f$-Divergence Distributionally Robust Optimization. (arXiv:2306.14041v2 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.05925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kai Liu</a>",
          "description": "Sparse logistic regression is for classification and feature selection\nsimultaneously. Although many studies have been done to solve\n$\\ell_1$-regularized logistic regression, there is no equivalently abundant\nwork on solving sparse logistic regression with nonconvex regularization term.\nIn this paper, we propose a unified framework to solve $\\ell_1$-regularized\nlogistic regression, which can be naturally extended to nonconvex\nregularization term, as long as certain requirement is satisfied. In addition,\nwe also utilize a different line search criteria to guarantee monotone\nconvergence for various regularization terms. Empirical experiments on binary\nclassification tasks with real-world datasets demonstrate our proposed\nalgorithms are capable of performing classification and feature selection\neffectively at a lower computational cost.",
          "link": "http://arxiv.org/abs/2309.05925",
          "publishedOn": "2023-10-14T00:41:29.765Z",
          "wordCount": 625,
          "title": "On Regularized Sparse Logistic Regression. (arXiv:2309.05925v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Defazio_A/0/1/0/all/0/1\">Aaron Defazio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_H/0/1/0/all/0/1\">Harsh Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>",
          "description": "Learning rate schedules used in practice bear little resemblance to those\nrecommended by theory. We close much of this theory/practice gap, and as a\nconsequence are able to derive new problem-adaptive learning rate schedules.\nOur key technical contribution is a refined analysis of learning rate schedules\nfor a wide class of optimization algorithms (including SGD). In contrast to\nmost prior works that study the convergence of the average iterate, we study\nthe last iterate, which is what most people use in practice. When considering\nonly worst-case analysis, our theory predicts that the best choice is the\nlinear decay schedule: a popular choice in practice that sets the stepsize\nproportionally to $1 - t/T$, where $t$ is the current iteration and $T$ is the\ntotal number of steps. To go beyond this worst-case analysis, we use the\nobserved gradient norms to derive schedules refined for any particular task.\nThese refined schedules exhibit learning rate warm-up and rapid learning rate\nannealing near the end of training. Ours is the first systematic approach to\nautomatically yield both of these properties. We perform the most comprehensive\nevaluation of learning rate schedules to date, evaluating across 10 diverse\ndeep learning problems, a series of LLMs, and a suite of logistic regression\nproblems. We validate that overall, the linear-decay schedule matches or\noutperforms all commonly used default schedules including cosine annealing, and\nthat our schedule refinement method gives further improvements.",
          "link": "http://arxiv.org/abs/2310.07831",
          "publishedOn": "2023-10-14T00:41:29.728Z",
          "wordCount": 765,
          "title": "When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement. (arXiv:2310.07831v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Hanpu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng-Long Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Z/0/1/0/all/0/1\">Zihang Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_Y/0/1/0/all/0/1\">Yiming Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>",
          "description": "This paper focuses on the problem of Differentially Private Stochastic\nOptimization for (multi-layer) fully connected neural networks with a single\noutput node. In the first part, we examine cases with no hidden nodes,\nspecifically focusing on Generalized Linear Models (GLMs). We investigate the\nwell-specific model where the random noise possesses a zero mean, and the link\nfunction is both bounded and Lipschitz continuous. We propose several\nalgorithms and our analysis demonstrates the feasibility of achieving an excess\npopulation risk that remains invariant to the data dimension. We also delve\ninto the scenario involving the ReLU link function, and our findings mirror\nthose of the bounded link function. We conclude this section by contrasting\nwell-specified and misspecified models, using ReLU regression as a\nrepresentative example.\n\nIn the second part of the paper, we extend our ideas to two-layer neural\nnetworks with sigmoid or ReLU activation functions in the well-specified model.\nIn the third part, we study the theoretical guarantees of DP-SGD in Abadi et\nal. (2016) for fully connected multi-layer neural networks. By utilizing recent\nadvances in Neural Tangent Kernel theory, we provide the first excess\npopulation risk when both the sample size and the width of the network are\nsufficiently large. Additionally, we discuss the role of some parameters in\nDP-SGD regarding their utility, both theoretically and empirically.",
          "link": "http://arxiv.org/abs/2310.08425",
          "publishedOn": "2023-10-14T00:41:29.721Z",
          "wordCount": 746,
          "title": "Differentially Private Non-convex Learning for Multi-layer Neural Networks. (arXiv:2310.08425v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2006.05421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1\">Shujian Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_H/0/1/0/all/0/1\">Hao Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpruch_L/0/1/0/all/0/1\">Lukasz Szpruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiese_M/0/1/0/all/0/1\">Magnus Wiese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabate_Vidales_M/0/1/0/all/0/1\">Marc Sabate-Vidales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Baoren Xiao</a>",
          "description": "Generative adversarial networks (GANs) have been extremely successful in\ngenerating samples, from seemingly high dimensional probability measures.\nHowever, these methods struggle to capture the temporal dependence of joint\nprobability distributions induced by time-series data. Furthermore, long\ntime-series data streams hugely increase the dimension of the target space,\nwhich may render generative modelling infeasible. To overcome these challenges,\nmotivated by the autoregressive models in econometric, we are interested in the\nconditional distribution of future time series given the past information. We\npropose the generic conditional Sig-WGAN framework by integrating\nWasserstein-GANs (WGANs) with mathematically principled and efficient path\nfeature extraction called the signature of a path. The signature of a path is a\ngraded sequence of statistics that provides a universal description for a\nstream of data, and its expected value characterises the law of the time-series\nmodel. In particular, we develop the conditional Sig-$W_1$ metric, that\ncaptures the conditional joint law of time series models, and use it as a\ndiscriminator. The signature feature space enables the explicit representation\nof the proposed discriminators which alleviates the need for expensive\ntraining. We validate our method on both synthetic and empirical dataset and\nobserve that our method consistently and significantly outperforms\nstate-of-the-art benchmarks with respect to measures of similarity and\npredictive ability.",
          "link": "http://arxiv.org/abs/2006.05421",
          "publishedOn": "2023-10-14T00:41:29.712Z",
          "wordCount": 761,
          "title": "Conditional Sig-Wasserstein GANs for Time Series Generation. (arXiv:2006.05421v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.17823",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Okuno_A/0/1/0/all/0/1\">Akifumi Okuno</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Harada_K/0/1/0/all/0/1\">Kazuharu Harada</a>",
          "description": "This study proposes an interpretable neural network-based non-proportional\nodds model (N$^3$POM) for ordinal regression. N$^3$POM is different from\nconventional approaches to ordinal regression with non-proportional models in\nseveral ways: (1) N$^3$POM is designed to directly handle continuous responses,\nwhereas standard methods typically treat de facto ordered continuous variables\nas discrete, (2) instead of estimating response-dependent finite coefficients\nof linear models from discrete responses as is done in conventional approaches,\nwe train a non-linear neural network to serve as a coefficient function. Thanks\nto the neural network, N$^3$POM offers flexibility while preserving the\ninterpretability of conventional ordinal regression. We establish a sufficient\ncondition under which the predicted conditional cumulative probability locally\nsatisfies the monotonicity constraint over a user-specified region in the\ncovariate space. Additionally, we provide a monotonicity-preserving stochastic\n(MPS) algorithm for effectively training the neural network. We apply N$^3$POM\nto several real-world datasets.",
          "link": "http://arxiv.org/abs/2303.17823",
          "publishedOn": "2023-10-14T00:41:29.690Z",
          "wordCount": 679,
          "title": "An interpretable neural network-based non-proportional odds model for ordinal regression. (arXiv:2303.17823v3 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06648",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Marion_P/0/1/0/all/0/1\">Pierre Marion</a>",
          "description": "Neural ordinary differential equations (neural ODEs) are a popular family of\ncontinuous-depth deep learning models. In this work, we consider a large family\nof parameterized ODEs with continuous-in-time parameters, which include\ntime-dependent neural ODEs. We derive a generalization bound for this class by\na Lipschitz-based argument. By leveraging the analogy between neural ODEs and\ndeep residual networks, our approach yields in particular a generalization\nbound for a class of deep residual networks. The bound involves the magnitude\nof the difference between successive weight matrices. We illustrate numerically\nhow this quantity affects the generalization capability of neural networks.",
          "link": "http://arxiv.org/abs/2305.06648",
          "publishedOn": "2023-10-14T00:41:29.667Z",
          "wordCount": 616,
          "title": "Generalization bounds for neural ordinary differential equations and deep residual networks. (arXiv:2305.06648v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.06823",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ammar_M/0/1/0/all/0/1\">Mou&#xef;n Ben Ammar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Belkhir_N/0/1/0/all/0/1\">Nacim Belkhir</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Popescu_S/0/1/0/all/0/1\">Sebastian Popescu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Manzanera_A/0/1/0/all/0/1\">Antoine Manzanera</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Franchi_G/0/1/0/all/0/1\">Gianni Franchi</a>",
          "description": "Detecting out-of-distribution (OOD) data is a critical challenge in machine\nlearning due to model overconfidence, often without awareness of their\nepistemological limits. We hypothesize that ``neural collapse'', a phenomenon\naffecting in-distribution data for models trained beyond loss convergence, also\ninfluences OOD data. To benefit from this interplay, we introduce NECO, a novel\npost-hoc method for OOD detection, which leverages the geometric properties of\n``neural collapse'' and of principal component spaces to identify OOD data. Our\nextensive experiments demonstrate that NECO achieves state-of-the-art results\non both small and large-scale OOD detection tasks while exhibiting strong\ngeneralization capabilities across different network architectures.\nFurthermore, we provide a theoretical explanation for the effectiveness of our\nmethod in OOD detection. We plan to release the code after the anonymity\nperiod.",
          "link": "http://arxiv.org/abs/2310.06823",
          "publishedOn": "2023-10-14T00:41:29.660Z",
          "wordCount": 650,
          "title": "NECO: NEural Collapse Based Out-of-distribution detection. (arXiv:2310.06823v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.06599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>",
          "description": "Existing regression models tend to fall short in both accuracy and\nuncertainty estimation when the label distribution is imbalanced. In this\npaper, we propose a probabilistic deep learning model, dubbed variational\nimbalanced regression (VIR), which not only performs well in imbalanced\nregression but naturally produces reasonable uncertainty estimation as a\nbyproduct. Different from typical variational autoencoders assuming I.I.D.\nrepresentations (a data point's representation is not directly affected by\nother data points), our VIR borrows data with similar regression labels to\ncompute the latent representation's variational distribution; furthermore,\ndifferent from deterministic regression models producing point estimates, VIR\npredicts the entire normal-inverse-gamma distributions and modulates the\nassociated conjugate distributions to impose probabilistic reweighting on the\nimbalanced data, thereby providing better uncertainty estimation. Experiments\nin several real-world datasets show that our VIR can outperform\nstate-of-the-art imbalanced regression models in terms of both accuracy and\nuncertainty estimation. Code will soon be available at\n\\url{https://github.com/Wang-ML-Lab/variational-imbalanced-regression}.",
          "link": "http://arxiv.org/abs/2306.06599",
          "publishedOn": "2023-10-14T00:41:29.626Z",
          "wordCount": 713,
          "title": "Variational Imbalanced Regression: Fair Uncertainty Quantification via Probabilistic Smoothing. (arXiv:2306.06599v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nezami_N/0/1/0/all/0/1\">Nazanin Nezami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anahideh_H/0/1/0/all/0/1\">Hadis Anahideh</a>",
          "description": "Surrogate Optimization (SO) algorithms have shown promise for optimizing\nexpensive black-box functions. However, their performance is heavily influenced\nby hyperparameters related to sampling and surrogate fitting, which poses a\nchallenge to their widespread adoption. We investigate the impact of\nhyperparameters on various SO algorithms and propose a Hyperparameter Adaptive\nSearch for SO (HASSO) approach. HASSO is not a hyperparameter tuning algorithm,\nbut a generic self-adjusting SO algorithm that dynamically tunes its own\nhyperparameters while concurrently optimizing the primary objective function,\nwithout requiring additional evaluations. The aim is to improve the\naccessibility, effectiveness, and convergence speed of SO algorithms for\npractitioners. Our approach identifies and modifies the most influential\nhyperparameters specific to each problem and SO approach, reducing the need for\nmanual tuning without significantly increasing the computational burden.\nExperimental results demonstrate the effectiveness of HASSO in enhancing the\nperformance of various SO algorithms across different global optimization test\nproblems.",
          "link": "http://arxiv.org/abs/2310.07970",
          "publishedOn": "2023-10-14T00:41:29.582Z",
          "wordCount": 667,
          "title": "Hyperparameter Adaptive Search for Surrogate Optimization: A Self-Adjusting Approach. (arXiv:2310.07970v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_N/0/1/0/all/0/1\">Namiko Matsumoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>",
          "description": "In 1-bit compressed sensing, the aim is to estimate a $k$-sparse unit vector\n$x\\in S^{n-1}$ within an $\\epsilon$ error (in $\\ell_2$) from minimal number of\nlinear measurements that are quantized to just their signs, i.e., from\nmeasurements of the form $y = \\mathrm{Sign}(\\langle a, x\\rangle).$ In this\npaper, we study a noisy version where a fraction of the measurements can be\nflipped, potentially by an adversary. In particular, we analyze the Binary\nIterative Hard Thresholding (BIHT) algorithm, a proximal gradient descent on a\nproperly defined loss function used for 1-bit compressed sensing, in this noisy\nsetting. It is known from recent results that, with\n$\\tilde{O}(\\frac{k}{\\epsilon})$ noiseless measurements, BIHT provides an\nestimate within $\\epsilon$ error. This result is optimal and universal, meaning\none set of measurements work for all sparse vectors. In this paper, we show\nthat BIHT also provides better results than all known methods for the noisy\nsetting. We show that when up to $\\tau$-fraction of the sign measurements are\nincorrect (adversarial error), with the same number of measurements as before,\nBIHT agnostically provides an estimate of $x$ within an\n$\\tilde{O}(\\epsilon+\\tau)$ error, maintaining the universality of measurements.\nThis establishes stability of iterative hard thresholding in the presence of\nmeasurement error. To obtain the result, we use the restricted approximate\ninvertibility of Gaussian matrices, as well as a tight analysis of the\nhigh-dimensional geometry of the adversarially corrupted measurements.",
          "link": "http://arxiv.org/abs/2310.08019",
          "publishedOn": "2023-10-14T00:41:29.566Z",
          "wordCount": 753,
          "title": "Robust 1-bit Compressed Sensing with Iterative Hard Thresholding. (arXiv:2310.08019v1 [cs.IT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.02286",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zambon_L/0/1/0/all/0/1\">Lorenzo Zambon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Azzimonti_D/0/1/0/all/0/1\">Dario Azzimonti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Corani_G/0/1/0/all/0/1\">Giorgio Corani</a>",
          "description": "Hierarchical time series are common in several applied fields. The forecasts\nfor these time series are required to be coherent, that is, to satisfy the\nconstraints given by the hierarchy. The most popular technique to enforce\ncoherence is called reconciliation, which adjusts the base forecasts computed\nfor each time series. However, recent works on probabilistic reconciliation\npresent several limitations. In this paper, we propose a new approach based on\nconditioning to reconcile any type of forecast distribution. We then introduce\na new algorithm, called Bottom-Up Importance Sampling, to efficiently sample\nfrom the reconciled distribution. It can be used for any base forecast\ndistribution: discrete, continuous, or in the form of samples, providing a\nmajor speedup compared to the current methods. Experiments on several temporal\nhierarchies show a significant improvement over base probabilistic forecasts.",
          "link": "http://arxiv.org/abs/2210.02286",
          "publishedOn": "2023-10-14T00:41:29.522Z",
          "wordCount": 677,
          "title": "Efficient probabilistic reconciliation of forecasts for real-valued and count time series. (arXiv:2210.02286v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.00327",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dirksen_S/0/1/0/all/0/1\">Sjoerd Dirksen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Finke_P/0/1/0/all/0/1\">Patrick Finke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Genzel_M/0/1/0/all/0/1\">Martin Genzel</a>",
          "description": "In practice, deep neural networks are often able to easily interpolate their\ntraining data. To understand this phenomenon, many works have aimed to quantify\nthe memorization capacity of a neural network architecture: the largest number\nof points such that the architecture can interpolate any placement of these\npoints with any assignment of labels. For real-world data, however, one\nintuitively expects the presence of a benign structure so that interpolation\nalready occurs at a smaller network size than suggested by memorization\ncapacity. In this paper, we investigate interpolation by adopting an\ninstance-specific viewpoint. We introduce a simple randomized algorithm that,\ngiven a fixed finite dataset with two classes, with high probability constructs\nan interpolating three-layer neural network in polynomial time. The required\nnumber of parameters is linked to geometric properties of the two classes and\ntheir mutual arrangement. As a result, we obtain guarantees that are\nindependent of the number of samples and hence move beyond worst-case\nmemorization capacity bounds. We illustrate the effectiveness of the algorithm\nin non-pathological situations with extensive numerical experiments and link\nthe insights back to the theoretical results.",
          "link": "http://arxiv.org/abs/2310.00327",
          "publishedOn": "2023-10-14T00:41:29.495Z",
          "wordCount": 710,
          "title": "Memorization with neural nets: going beyond the worst case. (arXiv:2310.00327v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08115",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Ji_W/0/1/0/all/0/1\">Wenlong Ji</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Lei_L/0/1/0/all/0/1\">Lihua Lei</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Spector_A/0/1/0/all/0/1\">Asher Spector</a>",
          "description": "Many causal estimands are only partially identifiable since they depend on\nthe unobservable joint distribution between potential outcomes. Stratification\non pretreatment covariates can yield sharper partial identification bounds;\nhowever, unless the covariates are discrete with relatively small support, this\napproach typically requires consistent estimation of the conditional\ndistributions of the potential outcomes given the covariates. Thus, existing\napproaches may fail under model misspecification or if consistency assumptions\nare violated. In this study, we propose a unified and model-agnostic\ninferential approach for a wide class of partially identified estimands, based\non duality theory for optimal transport problems. In randomized experiments,\nour approach can wrap around any estimates of the conditional distributions and\nprovide uniformly valid inference, even if the initial estimates are\narbitrarily inaccurate. Also, our approach is doubly robust in observational\nstudies. Notably, this property allows analysts to use the multiplier bootstrap\nto select covariates and models without sacrificing validity even if the true\nmodel is not included. Furthermore, if the conditional distributions are\nestimated at semiparametric rates, our approach matches the performance of an\noracle with perfect knowledge of the outcome model. Finally, we propose an\nefficient computational framework, enabling implementation on many practical\nproblems in causal inference.",
          "link": "http://arxiv.org/abs/2310.08115",
          "publishedOn": "2023-10-14T00:41:29.489Z",
          "wordCount": 717,
          "title": "Model-Agnostic Covariate-Assisted Inference on Partially Identified Causal Effects. (arXiv:2310.08115v1 [econ.EM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.09663",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Botvinick_Greenhouse_J/0/1/0/all/0/1\">Jonah Botvinick-Greenhouse</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1\">Yunan Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maulik_R/0/1/0/all/0/1\">Romit Maulik</a>",
          "description": "Motivated by the computational difficulties incurred by popular deep learning\nalgorithms for the generative modeling of temporal densities, we propose a\ncheap alternative which requires minimal hyperparameter tuning and scales\nfavorably to high dimensional problems. In particular, we use a\nprojection-based optimal transport solver [Meng et al., 2019] to join\nsuccessive samples and subsequently use transport splines [Chewi et al., 2020]\nto interpolate the evolving density. When the sampling frequency is\nsufficiently high, the optimal maps are close to the identity and are thus\ncomputationally efficient to compute. Moreover, the training process is highly\nparallelizable as all optimal maps are independent and can thus be learned\nsimultaneously. Finally, the approach is based solely on numerical linear\nalgebra rather than minimizing a nonconvex objective function, allowing us to\neasily analyze and control the algorithm. We present several numerical\nexperiments on both synthetic and real-world datasets to demonstrate the\nefficiency of our method. In particular, these experiments show that the\nproposed approach is highly competitive compared with state-of-the-art\nnormalizing flows conditioned on time across a wide range of dimensionalities.",
          "link": "http://arxiv.org/abs/2304.09663",
          "publishedOn": "2023-10-14T00:41:29.473Z",
          "wordCount": 774,
          "title": "Generative modeling of time-dependent densities via optimal transport and projection pursuit. (arXiv:2304.09663v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weisz_G/0/1/0/all/0/1\">Gell&#xe9;rt Weisz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andr&#xe1;s Gy&#xf6;rgy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesv&#xe1;ri</a>",
          "description": "We consider online reinforcement learning (RL) in episodic Markov decision\nprocesses (MDPs) under the linear $q^\\pi$-realizability assumption, where it is\nassumed that the action-values of all policies can be expressed as linear\nfunctions of state-action features. This class is known to be more general than\nlinear MDPs, where the transition kernel and the reward function are assumed to\nbe linear functions of the feature vectors. As our first contribution, we show\nthat the difference between the two classes is the presence of states in\nlinearly $q^\\pi$-realizable MDPs where for any policy, all the actions have\napproximately equal values, and skipping over these states by following an\narbitrarily fixed policy in those states transforms the problem to a linear\nMDP. Based on this observation, we derive a novel (computationally inefficient)\nlearning algorithm for linearly $q^\\pi$-realizable MDPs that simultaneously\nlearns what states should be skipped over and runs another learning algorithm\non the linear MDP hidden in the problem. The method returns an\n$\\epsilon$-optimal policy after $\\text{polylog}(H, d)/\\epsilon^2$ interactions\nwith the MDP, where $H$ is the time horizon and $d$ is the dimension of the\nfeature vectors, giving the first polynomial-sample-complexity online RL\nalgorithm for this setting. The results are proved for the misspecified case,\nwhere the sample complexity is shown to degrade gracefully with the\nmisspecification error.",
          "link": "http://arxiv.org/abs/2310.07811",
          "publishedOn": "2023-10-14T00:41:29.433Z",
          "wordCount": 769,
          "title": "Online RL in Linearly $q^\\pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore. (arXiv:2310.07811v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08209",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cholaquidis_A/0/1/0/all/0/1\">Alejandro Cholaquidis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gamboa_F/0/1/0/all/0/1\">Fabrice Gamboa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moreno_L/0/1/0/all/0/1\">Leonardo Moreno</a>",
          "description": "Regression on manifolds, and, more broadly, statistics on manifolds, has\ngarnered significant importance in recent years due to the vast number of\napplications for this type of data. Circular data is a classic example, but so\nis data in the space of covariance matrices, data on the Grassmannian manifold\nobtained as a result of principal component analysis, among many others. In\nthis work we investigate prediction sets for regression scenarios when the\nresponse variable, denoted by $Y$, resides in a manifold, and the covariable,\ndenoted by X, lies in Euclidean space. This extends the concepts delineated in\n[Lei and Wasserman, 2014] to this novel context. Aligning with traditional\nprinciples in conformal inference, these prediction sets are distribution-free,\nindicating that no specific assumptions are imposed on the joint distribution\nof $(X, Y)$, and they maintain a non-parametric character. We prove the\nasymptotic almost sure convergence of the empirical version of these regions on\nthe manifold to their population counterparts. The efficiency of this method is\nshown through a comprehensive simulation study and an analysis involving\nreal-world data.",
          "link": "http://arxiv.org/abs/2310.08209",
          "publishedOn": "2023-10-14T00:41:29.425Z",
          "wordCount": 668,
          "title": "Conformal inference for regression on Riemannian Manifolds. (arXiv:2310.08209v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08150",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Steland_A/0/1/0/all/0/1\">Ansgar Steland</a>",
          "description": "Maximum-type statistics of certain functions of the sample covariance matrix\nof high-dimensional vector time series are studied to statistically confirm or\nreject the null hypothesis that a data set has been collected under normal\nconditions. The approach generalizes the case of the maximal deviation of the\nsample autocovariances function from its assumed values. Within a linear time\nseries framework it is shown that Gumbel-type extreme value asymptotics holds\ntrue. As applications we discuss long-only mimimal-variance portfolio\noptimization and subportfolio analysis with respect to idiosyncratic risks, ETF\nindex tracking by sparse tracking portfolios, convolutional deep learners for\nimage analysis and the analysis of array-of-sensors data.",
          "link": "http://arxiv.org/abs/2310.08150",
          "publishedOn": "2023-10-14T00:41:29.394Z",
          "wordCount": 634,
          "title": "On Extreme Value Asymptotics of Projected Sample Covariances in High Dimensions with Applications in Finance and Convolutional Networks. (arXiv:2310.08150v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luca_A/0/1/0/all/0/1\">Artur Back de Luca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fountoulakis_K/0/1/0/all/0/1\">Kimon Fountoulakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shenghao Yang</a>",
          "description": "The growing interest in machine learning problems over graphs with additional\nnode information such as texts, images, or labels has popularized methods that\nrequire the costly operation of processing the entire graph. Yet, little effort\nhas been made to the development of fast local methods (i.e. without accessing\nthe entire graph) that extract useful information from such data. To that end,\nwe propose a study of local graph clustering using noisy node labels as a proxy\nfor additional node information. In this setting, nodes receive initial binary\nlabels based on cluster affiliation: 1 if they belong to the target cluster and\n0 otherwise. Subsequently, a fraction of these labels is flipped. We\ninvestigate the benefits of incorporating noisy labels for local graph\nclustering. By constructing a weighted graph with such labels, we study the\nperformance of graph diffusion-based local clustering method on both the\noriginal and the weighted graphs. From a theoretical perspective, we consider\nrecovering an unknown target cluster with a single seed node in a random graph\nwith independent noisy node labels. We provide sufficient conditions on the\nlabel noise under which, with high probability, using diffusion in the weighted\ngraph yields a more accurate recovery of the target cluster. This approach\nproves more effective than using the given labels alone or using diffusion in\nthe label-free original graph. Empirically, we show that reliable node labels\ncan be obtained with just a few samples from an attributed graph. Moreover,\nutilizing these labels via diffusion in the weighted graph leads to\nsignificantly better local clustering performance across several real-world\ndatasets, improving F1 scores by up to 13%.",
          "link": "http://arxiv.org/abs/2310.08031",
          "publishedOn": "2023-10-14T00:41:29.335Z",
          "wordCount": 784,
          "title": "Local Graph Clustering with Noisy Labels. (arXiv:2310.08031v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08410",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wei_Q/0/1/0/all/0/1\">Qiuhong Wei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yao_Z/0/1/0/all/0/1\">Zhengxiong Yao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cui_Y/0/1/0/all/0/1\">Ying Cui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wei_B/0/1/0/all/0/1\">Bo Wei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jin_Z/0/1/0/all/0/1\">Zhezhen Jin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_X/0/1/0/all/0/1\">Ximing Xu</a>",
          "description": "Large language models such as ChatGPT are increasingly explored in medical\ndomains. However, the absence of standard guidelines for performance evaluation\nhas led to methodological inconsistencies. This study aims to summarize the\navailable evidence on evaluating ChatGPT's performance in medicine and provide\ndirection for future research. We searched ten medical literature databases on\nJune 15, 2023, using the keyword \"ChatGPT\". A total of 3520 articles were\nidentified, of which 60 were reviewed and summarized in this paper and 17 were\nincluded in the meta-analysis. The analysis showed that ChatGPT displayed an\noverall integrated accuracy of 56% (95% CI: 51%-60%, I2 = 87%) in addressing\nmedical queries. However, the studies varied in question resource,\nquestion-asking process, and evaluation metrics. Moreover, many studies failed\nto report methodological details, including the version of ChatGPT and whether\neach question was used independently or repeatedly. Our findings revealed that\nalthough ChatGPT demonstrated considerable potential for application in\nhealthcare, the heterogeneity of the studies and insufficient reporting may\naffect the reliability of these results. Further well-designed studies with\ncomprehensive and transparent reporting are needed to evaluate ChatGPT's\nperformance in medicine.",
          "link": "http://arxiv.org/abs/2310.08410",
          "publishedOn": "2023-10-14T00:41:29.254Z",
          "wordCount": 690,
          "title": "Evaluation of ChatGPT-Generated Medical Responses: A Systematic Review and Meta-Analysis. (arXiv:2310.08410v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08426",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Butts_J/0/1/0/all/0/1\">J. Butts</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wendt_C/0/1/0/all/0/1\">C. Wendt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bowler_R/0/1/0/all/0/1\">R. Bowler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hersh_C/0/1/0/all/0/1\">C.P. Hersh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Long_Q/0/1/0/all/0/1\">Q. Long</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Eberly_L/0/1/0/all/0/1\">L. Eberly</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Safo_S/0/1/0/all/0/1\">S. E. Safo</a>",
          "description": "Multiple data views measured on the same set of participants is becoming more\ncommon and has the potential to deepen our understanding of many complex\ndiseases by analyzing these different views simultaneously. Equally important,\nmany of these complex diseases show evidence of subgroup heterogeneity (e.g.,\nby sex or race). HIP (Heterogeneity in Integration and Prediction) is among the\nfirst methods proposed to integrate multiple data views while also accounting\nfor subgroup heterogeneity to identify common and subgroup-specific markers of\na particular disease. However, HIP is applicable to continuous outcomes and\nrequires programming expertise by the user. Here we propose extensions to HIP\nthat accommodate multi-class, Poisson, and Zero-Inflated Poisson outcomes while\nretaining the benefits of HIP. Additionally, we introduce an R Shiny\napplication, accessible on shinyapps.io at\nhttps://multi-viewlearn.shinyapps.io/HIP_ShinyApp/, that provides an interface\nwith the Python implementation of HIP to allow more researchers to use the\nmethod anywhere and on any device. We applied HIP to identify genes and\nproteins common and specific to males and females that are associated with\nexacerbation frequency. Although some of the identified genes and proteins show\nevidence of a relationship with chronic obstructive pulmonary disease (COPD) in\nexisting literature, others may be candidates for future research investigating\ntheir relationship with COPD. We demonstrate the use of the Shiny application\nwith a publicly available data. An R-package for HIP would be made available at\nhttps://github.com/lasandrall/HIP.",
          "link": "http://arxiv.org/abs/2310.08426",
          "publishedOn": "2023-10-14T00:41:29.206Z",
          "wordCount": 760,
          "title": "Extensions of Heterogeneity in Integration and Prediction (HIP) with R Shiny Application. (arXiv:2310.08426v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.05898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lizhang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kaizhao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>",
          "description": "Lion (Evolved Sign Momentum), a new optimizer discovered through program\nsearch, has shown promising results in training large AI models. It performs\ncomparably or favorably to AdamW but with greater memory efficiency. As we can\nexpect from the results of a random search program, Lion incorporates elements\nfrom several existing algorithms, including signed momentum, decoupled weight\ndecay, Polak, and Nesterov momentum, but does not fit into any existing\ncategory of theoretically grounded optimizers. Thus, even though Lion appears\nto perform well as a general-purpose optimizer for a wide range of tasks, its\ntheoretical basis remains uncertain. This lack of theoretical clarity limits\nopportunities to further enhance and expand Lion's efficacy.\n\nThis work aims to demystify Lion. Based on both continuous-time and\ndiscrete-time analysis, we demonstrate that Lion is a theoretically novel and\nprincipled approach for minimizing a general loss function $f(x)$ while\nenforcing a bound constraint $\\|x\\|_\\infty \\leq 1/\\lambda$. Lion achieves this\nthrough the incorporation of decoupled weight decay, where $\\lambda$ represents\nthe weight decay coefficient. Our analysis is made possible by the development\nof a new Lyapunov function for the Lion updates. It applies to a broader family\nof Lion-$\\kappa$ algorithms, where the $\\text{sign}(\\cdot)$ operator in Lion is\nreplaced by the subgradient of a convex function $\\kappa$, leading to the\nsolution of a general composite optimization problem of $\\min_x f(x) +\n\\kappa^*(x)$. Our findings provide valuable insights into the dynamics of Lion\nand pave the way for further improvements and extensions of Lion-related\nalgorithms.",
          "link": "http://arxiv.org/abs/2310.05898",
          "publishedOn": "2023-10-14T00:41:29.197Z",
          "wordCount": 788,
          "title": "Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts. (arXiv:2310.05898v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Licong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1\">Song Mei</a>",
          "description": "Large transformer models pretrained on offline reinforcement learning\ndatasets have demonstrated remarkable in-context reinforcement learning (ICRL)\ncapabilities, where they can make good decisions when prompted with interaction\ntrajectories from unseen environments. However, when and how transformers can\nbe trained to perform ICRL have not been theoretically well-understood. In\nparticular, it is unclear which reinforcement-learning algorithms transformers\ncan perform in context, and how distribution mismatch in offline training data\naffects the learned algorithms. This paper provides a theoretical framework\nthat analyzes supervised pretraining for ICRL. This includes two recently\nproposed training methods -- algorithm distillation and decision-pretrained\ntransformers. First, assuming model realizability, we prove the\nsupervised-pretrained transformer will imitate the conditional expectation of\nthe expert algorithm given the observed trajectory. The generalization error\nwill scale with model capacity and a distribution divergence factor between the\nexpert and offline algorithms. Second, we show transformers with ReLU attention\ncan efficiently approximate near-optimal online reinforcement learning\nalgorithms like LinUCB and Thompson sampling for stochastic linear bandits, and\nUCB-VI for tabular Markov decision processes. This provides the first\nquantitative analysis of the ICRL capabilities of transformers pretrained from\noffline trajectories.",
          "link": "http://arxiv.org/abs/2310.08566",
          "publishedOn": "2023-10-14T00:41:29.191Z",
          "wordCount": 717,
          "title": "Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining. (arXiv:2310.08566v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.07415",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1\">Jie Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dey_S/0/1/0/all/0/1\">Santanu S. Dey</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>",
          "description": "We consider the variable selection problem for two-sample tests, aiming to\nselect the most informative variables to distinguish samples from two groups.\nTo solve this problem, we propose a framework based on the kernel maximum mean\ndiscrepancy (MMD). Our approach seeks a group of variables with a pre-specified\nsize that maximizes the variance-regularized MMD statistics. This formulation\nalso corresponds to the minimization of asymptotic type-II error while\ncontrolling type-I error, as studied in the literature. We present\nmixed-integer programming formulations and develop exact and approximation\nalgorithms with performance guarantees for different choices of kernel\nfunctions. Furthermore, we provide a statistical testing power analysis of our\nproposed framework. Experiment results on synthetic and real datasets\ndemonstrate the superior performance of our approach.",
          "link": "http://arxiv.org/abs/2302.07415",
          "publishedOn": "2023-10-14T00:41:29.174Z",
          "wordCount": 646,
          "title": "Variable Selection for Kernel Two-Sample Tests. (arXiv:2302.07415v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08053",
          "author": "<a href=\"http://arxiv.org/find/hep-lat/1/au:+Alvestad_D/0/1/0/all/0/1\">Daniel Alvestad</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Rothkopf_A/0/1/0/all/0/1\">Alexander Rothkopf</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Sexty_D/0/1/0/all/0/1\">D&#xe9;nes Sexty</a>",
          "description": "We present a simulation strategy for the real-time dynamics of quantum\nfields, inspired by reinforcement learning. It builds on the complex Langevin\napproach, which it amends with system specific prior information, a necessary\nprerequisite to overcome this exceptionally severe sign problem. The\noptimization process underlying our machine learning approach is made possible\nby deploying inherently stable solvers of the complex Langevin stochastic\nprocess and a novel optimality criterion derived from insight into so-called\nboundary terms. This conceptual and technical progress allows us to both\nsignificantly extend the range of real-time simulations in 1+1d scalar field\ntheory beyond the state-of-the-art and to avoid discretization artifacts that\nplagued previous real-time field theory simulations. Limitations of and\npromising future directions are discussed.",
          "link": "http://arxiv.org/abs/2310.08053",
          "publishedOn": "2023-10-14T00:41:29.168Z",
          "wordCount": 636,
          "title": "Lattice real-time simulations with learned optimal kernels. (arXiv:2310.08053v1 [hep-lat])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07852",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Roy_S/0/1/0/all/0/1\">Saptarshi Roy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1\">Ambuj Tewari</a>",
          "description": "We consider the problem of model selection in a high-dimensional sparse\nlinear regression model under the differential privacy framework. In\nparticular, we consider the problem of differentially private best subset\nselection and study its utility guarantee. We adopt the well-known exponential\nmechanism for selecting the best model, and under a certain margin condition,\nwe establish its strong model recovery property. However, the exponential\nsearch space of the exponential mechanism poses a serious computational\nbottleneck. To overcome this challenge, we propose a Metropolis-Hastings\nalgorithm for the sampling step and establish its polynomial mixing time to its\nstationary distribution in the problem parameters $n,p$, and $s$. Furthermore,\nwe also establish approximate differential privacy for the final estimates of\nthe Metropolis-Hastings random walk using its mixing property. Finally, we also\nperform some illustrative simulations that echo the theoretical findings of our\nmain results.",
          "link": "http://arxiv.org/abs/2310.07852",
          "publishedOn": "2023-10-14T00:41:29.163Z",
          "wordCount": 663,
          "title": "On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08089",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fengzhuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1\">Vincent Y. F. Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>",
          "description": "This paper studies two fundamental problems in regularized Graphon Mean-Field\nGames (GMFGs). First, we establish the existence of a Nash Equilibrium (NE) of\nany $\\lambda$-regularized GMFG (for $\\lambda\\geq 0$). This result relies on\nweaker conditions than those in previous works for analyzing both unregularized\nGMFGs ($\\lambda=0$) and $\\lambda$-regularized MFGs, which are special cases of\nGMFGs. Second, we propose provably efficient algorithms to learn the NE in\nweakly monotone GMFGs, motivated by Lasry and Lions [2007]. Previous literature\neither only analyzed continuous-time algorithms or required extra conditions to\nanalyze discrete-time algorithms. In contrast, we design a discrete-time\nalgorithm and derive its convergence rate solely under weakly monotone\nconditions. Furthermore, we develop and analyze the action-value function\nestimation procedure during the online learning process, which is absent from\nalgorithms for monotone GMFGs. This serves as a sub-module in our optimization\nalgorithm. The efficiency of the designed algorithm is corroborated by\nempirical evaluations.",
          "link": "http://arxiv.org/abs/2310.08089",
          "publishedOn": "2023-10-14T00:41:29.156Z",
          "wordCount": 656,
          "title": "Learning Regularized Monotone Graphon Mean-Field Games. (arXiv:2310.08089v1 [cs.GT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_K/0/1/0/all/0/1\">Kushagra Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudolph_M/0/1/0/all/0/1\">Maja Rudolph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Diffusion models suffer from slow sample generation at inference time.\nTherefore, developing a principled framework for fast deterministic/stochastic\nsampling for a broader class of diffusion models is a promising direction. We\npropose two complementary frameworks for accelerating sample generation in\npre-trained models: Conjugate Integrators and Splitting Integrators. Conjugate\nintegrators generalize DDIM, mapping the reverse diffusion dynamics to a more\namenable space for sampling. In contrast, splitting-based integrators, commonly\nused in molecular dynamics, reduce the numerical simulation error by cleverly\nalternating between numerical updates involving the data and auxiliary\nvariables. After extensively studying these methods empirically and\ntheoretically, we present a hybrid method that leads to the best-reported\nperformance for diffusion models in augmented spaces. Applied to Phase Space\nLangevin Diffusion [Pandey & Mandt, 2023] on CIFAR-10, our deterministic and\nstochastic samplers achieve FID scores of 2.11 and 2.36 in only 100 network\nfunction evaluations (NFE) as compared to 2.57 and 2.63 for the best-performing\nbaselines, respectively. Our code and model checkpoints will be made publicly\navailable at \\url{https://github.com/mandt-lab/PSLD}.",
          "link": "http://arxiv.org/abs/2310.07894",
          "publishedOn": "2023-10-14T00:41:29.138Z",
          "wordCount": 676,
          "title": "Efficient Integrators for Diffusion Generative Models. (arXiv:2310.07894v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08391",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_J/0/1/0/all/0/1\">Jingfeng Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zou_D/0/1/0/all/0/1\">Difan Zou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1\">Zixiang Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Braverman_V/0/1/0/all/0/1\">Vladimir Braverman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "Transformers pretrained on diverse tasks exhibit remarkable in-context\nlearning (ICL) capabilities, enabling them to solve unseen tasks solely based\non input contexts without adjusting model parameters. In this paper, we study\nICL in one of its simplest setups: pretraining a linearly parameterized\nsingle-layer linear attention model for linear regression with a Gaussian\nprior. We establish a statistical task complexity bound for the attention model\npretraining, showing that effective pretraining only requires a small number of\nindependent tasks. Furthermore, we prove that the pretrained model closely\nmatches the Bayes optimal algorithm, i.e., optimally tuned ridge regression, by\nachieving nearly Bayes optimal risk on unseen tasks under a fixed context\nlength. These theoretical findings complement prior experimental research and\nshed light on the statistical foundations of ICL.",
          "link": "http://arxiv.org/abs/2310.08391",
          "publishedOn": "2023-10-14T00:41:29.132Z",
          "wordCount": 644,
          "title": "How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?. (arXiv:2310.08391v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08479",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chatton_A/0/1/0/all/0/1\">Arthur Chatton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bally_M/0/1/0/all/0/1\">Mich&#xe8;le Bally</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Levesque_R/0/1/0/all/0/1\">Ren&#xe9;e L&#xe9;vesque</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Malenica_I/0/1/0/all/0/1\">Ivana Malenica</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Platt_R/0/1/0/all/0/1\">Robert W. Platt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schnitzer_M/0/1/0/all/0/1\">Mireille E. Schnitzer</a>",
          "description": "Obtaining continuously updated predictions is a major challenge for\npersonalised medicine. Leveraging combinations of parametric regressions and\nmachine learning approaches, the personalised online super learner (POSL) can\nachieve such dynamic and personalised predictions. We adapt POSL to predict a\nrepeated continuous outcome dynamically and propose a new way to validate such\npersonalised or dynamic prediction models. We illustrate its performance by\npredicting the convection volume of patients undergoing hemodiafiltration. POSL\noutperformed its candidate learners with respect to median absolute error,\ncalibration-in-the-large, discrimination, and net benefit. We finally discuss\nthe choices and challenges underlying the use of POSL.",
          "link": "http://arxiv.org/abs/2310.08479",
          "publishedOn": "2023-10-14T00:41:29.127Z",
          "wordCount": 624,
          "title": "Personalised dynamic super learning: an application in predicting hemodiafiltration's convection volumes. (arXiv:2310.08479v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1908.04628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xindi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varol_O/0/1/0/all/0/1\">Onur Varol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1\">Tina Eliassi-Rad</a>",
          "description": "Many real-world prediction tasks have outcome variables that have\ncharacteristic heavy-tail distributions. Examples include copies of books sold,\nauction prices of art pieces, demand for commodities in warehouses, etc. By\nlearning heavy-tailed distributions, \"big and rare\" instances (e.g., the\nbest-sellers) will have accurate predictions. Most existing approaches are not\ndedicated to learning heavy-tailed distribution; thus, they heavily\nunder-predict such instances. To tackle this problem, we introduce Learning to\nPlace (L2P), which exploits the pairwise relationships between instances for\nlearning. In its training phase, L2P learns a pairwise preference classifier:\nis instance A > instance B? In its placing phase, L2P obtains a prediction by\nplacing the new instance among the known instances. Based on its placement, the\nnew instance is then assigned a value for its outcome variable. Experiments on\nreal data show that L2P outperforms competing approaches in terms of accuracy\nand ability to reproduce heavy-tailed outcome distribution. In addition, L2P\nprovides an interpretable model by placing each predicted instance in relation\nto its comparable neighbors. Interpretable models are highly desirable when\nlives and treasure are at stake.",
          "link": "http://arxiv.org/abs/1908.04628",
          "publishedOn": "2023-10-14T00:41:29.121Z",
          "wordCount": 776,
          "title": "L2P: Learning to Place for Estimating Heavy-Tailed Distributed Outcomes. (arXiv:1908.04628v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07973",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Michael Lingzhi Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Imai_K/0/1/0/all/0/1\">Kosuke Imai</a>",
          "description": "Across a wide array of disciplines, many researchers use machine learning\n(ML) algorithms to identify a subgroup of individuals, called exceptional\nresponders, who are likely to be helped by a treatment the most. A common\napproach consists of two steps. One first estimates the conditional average\ntreatment effect or its proxy using an ML algorithm. They then determine the\ncutoff of the resulting treatment prioritization score to select those\npredicted to benefit most from the treatment. Unfortunately, these estimated\ntreatment prioritization scores are often biased and noisy. Furthermore,\nutilizing the same data to both choose a cutoff value and estimate the average\ntreatment effect among the selected individuals suffer from a multiple testing\nproblem. To address these challenges, we develop a uniform confidence band for\nexperimentally evaluating the sorted average treatment effect (GATES) among the\nindividuals whose treatment prioritization score is at least as high as any\ngiven quantile value, regardless of how the quantile is chosen. This provides a\nstatistical guarantee that the GATES for the selected subgroup exceeds a\ncertain threshold. The validity of the proposed methodology depends solely on\nrandomization of treatment and random sampling of units without requiring\nmodeling assumptions or resampling methods. This widens its applicability\nincluding a wide range of other causal quantities. A simulation study shows\nthat the empirical coverage of the proposed uniform confidence bands is close\nto the nominal coverage when the sample is as small as 100. We analyze a\nclinical trial of late-stage prostate cancer and find a relatively large\nproportion of exceptional responders with a statistical performance guarantee.",
          "link": "http://arxiv.org/abs/2310.07973",
          "publishedOn": "2023-10-14T00:41:29.114Z",
          "wordCount": 778,
          "title": "Statistical Performance Guarantee for Selecting Those Predicted to Benefit Most from Treatment. (arXiv:2310.07973v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08237",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_X/0/1/0/all/0/1\">Xingdong Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_X/0/1/0/all/0/1\">Xin He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1\">Caixing Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1\">Chao Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jingnan Zhang</a>",
          "description": "Covariate shift occurs prevalently in practice, where the input distributions\nof the source and target data are substantially different. Despite its\npractical importance in various learning problems, most of the existing methods\nonly focus on some specific learning tasks and are not well validated\ntheoretically and numerically. To tackle this problem, we propose a unified\nanalysis of general nonparametric methods in a reproducing kernel Hilbert space\n(RKHS) under covariate shift. Our theoretical results are established for a\ngeneral loss belonging to a rich loss function family, which includes many\ncommonly used methods as special cases, such as mean regression, quantile\nregression, likelihood-based classification, and margin-based classification.\nTwo types of covariate shift problems are the focus of this paper and the sharp\nconvergence rates are established for a general loss function to provide a\nunified theoretical analysis, which concurs with the optimal results in\nliterature where the squared loss is used. Extensive numerical studies on\nsynthetic and real examples confirm our theoretical findings and further\nillustrate the effectiveness of our proposed method.",
          "link": "http://arxiv.org/abs/2310.08237",
          "publishedOn": "2023-10-14T00:41:29.097Z",
          "wordCount": 697,
          "title": "Towards a Unified Analysis of Kernel-based Methods Under Covariate Shift. (arXiv:2310.08237v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qingyue Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Banghua Zhu</a>",
          "description": "We characterize the statistical efficiency of knowledge transfer through $n$\nsamples from a teacher to a probabilistic student classifier with input space\n$\\mathcal S$ over labels $\\mathcal A$. We show that privileged information at\nthree progressive levels accelerates the transfer. At the first level, only\nsamples with hard labels are known, via which the maximum likelihood estimator\nattains the minimax rate $\\sqrt{{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. The\nsecond level has the teacher probabilities of sampled labels available in\naddition, which turns out to boost the convergence rate lower bound to\n${{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. However, under this second data\nacquisition protocol, minimizing a naive adaptation of the cross-entropy loss\nresults in an asymptotically biased student. We overcome this limitation and\nachieve the fundamental limit by using a novel empirical variant of the squared\nerror logit loss. The third level further equips the student with the soft\nlabels (complete logits) on ${\\mathcal A}$ given every sampled input, thereby\nprovably enables the student to enjoy a rate ${|{\\mathcal S}|}/{n}$ free of\n$|{\\mathcal A}|$. We find any Kullback-Leibler divergence minimizer to be\noptimal in the last case. Numerical simulations distinguish the four learners\nand corroborate our theory.",
          "link": "http://arxiv.org/abs/2310.07838",
          "publishedOn": "2023-10-14T00:41:29.079Z",
          "wordCount": 722,
          "title": "Towards the Fundamental Limits of Knowledge Transfer over Finite Domains. (arXiv:2310.07838v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        }
      ]
    },
    {
      "title": "Machine Learning",
      "feedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
      "siteUrl": "https://www.reddit.com/r/MachineLearning/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17phyws/d_reverse_engineering_gptvision_from_pricing/",
          "author": null,
          "description": "So I have been looking at GPT4-V pricing trying to determine what kind of pipeline they use, feel free to chime in, dispute, etc. I do not have many conclusions but hoping that the crowd is wiser.\n ​\n https://preview.redd.it/t4udi6lnntyb1.png?width=552&format=png&auto=webp&s=6f02a8c62cb9eb5b104ef36f50d2e8d0ee7a431c\n Observations:\n  \nyou are billed on the token count which can be calculated from the image resolution. This suggests they do not do append the OCR result to the GPT4 input.\n There are 85 base tokens irrespective of the image size. Maybe they run the whole image through some vision encoder and somehow get 85 tokens? 85 is a strange number, not close base of 2, no convenient squares, what does it have? why 85? Maybe to mess with us?\n The image is tiled with 512x512 tiles, each tile converts to 170 tokens. 170 = 13*13+1? Maybe they use some kind of OCR and 170 is the average number of tokens they expect? But that would mean that gpt4 should not be able to differentiate small things in an image (it would just have 85 global tokens). Knowing OpenAI it seems unlikely they would have the 2 stage pipeline.\n GPT4-V can accurately read text from image.\n  \nMy guess would be a strong vision encoder for the 85 tokens and some light encoder for the 512x512 tiles, where most of the processing happens inside gpt4.\n Retrofitting GPT4 with vision suggests they have a vision encoder which maps to GPT4 tokens.\n ​\n What do you think?\n    submitted by    /u/President_Xi_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17phyws/d_reverse_engineering_gptvision_from_pricing/",
          "publishedOn": "2023-11-07T00:40:30.000Z",
          "wordCount": null,
          "title": "[D] Reverse engineering GPT-vision from pricing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17phl5y/n_gpt4_turbo_with_128k_of_context/",
          "author": null,
          "description": "https://openai.com/blog/new-models-and-developer-products-announced-at-devday\n Excited for the RAG implementations this will support.\n Also, turbo!\n    submitted by    /u/gar1t  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17phl5y/n_gpt4_turbo_with_128k_of_context/",
          "publishedOn": "2023-11-07T00:22:28.000Z",
          "wordCount": null,
          "title": "[N] GPT-4 Turbo with 128K of context",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ph9nu/project_what_process_is_used_in_these/",
          "author": null,
          "description": "I have seen videos like this: https://www.youtube.com/watch?v=Dw3BZ6O_8LY and I'm curious as to how someone would do this. Some classmates and I want to recreate a board game and train a model on a digital recreation of it, but we're not sure where to start. Any help is useful! \n    submitted by    /u/Aboudi556  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ph9nu/project_what_process_is_used_in_these/",
          "publishedOn": "2023-11-07T00:07:14.000Z",
          "wordCount": null,
          "title": "[Project] What process is used in these reinforcement learning models I see on Youtube?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17pgvv5/d_if_your_company_is_ingesting_work_emails_and/",
          "author": null,
          "description": "Hi folks\n Firstly full disclosure I’m the CEO of DataFog (www.datafog.ai). This is NOT a sales pitch but rather an interest in hearing what the community thinks about the overall issue which I believe will ultimately be solved via an ML-based implementation.\n My contention is: - Generative AI has catalyzed widespread practice of ingesting email and work chat content to power AI training and inference - this introduces a risk of content concerning confidential corporate affairs* that can pass most privacy filters \n This results in Raw data alluding to sensitive business events flowing in freely for easy accidental unauthorized access by an internal - like MLOps - user\n My second contention is that the current security tools may not offer adequate coverage for what will be an evolving ongoin…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17pgvv5/d_if_your_company_is_ingesting_work_emails_and/",
          "publishedOn": "2023-11-06T23:49:02.000Z",
          "wordCount": null,
          "title": "[D] if your company is ingesting work emails and chats for AI/ML pipelines, is there concern around sensitive business info getting out?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17pg3f4/r_ai_alignment_a_comprehensive_survey/",
          "author": null,
          "description": "https://arxiv.org/abs/2310.19852\n ​\n AI alignment aims to make AI systems behave in line with human intentions and values. As AI systems grow more capable, the potential large-scale risks associated with misaligned AI systems become salient. Hundreds of AI experts and public figures have expressed concerns about AI risks, arguing that \"mitigating the risk of extinction from AI should be a global priority, alongside other societal-scale risks such as pandemics and nuclear war\". To provide a comprehensive and up-to-date overview of the alignment field, in this survey paper, we delve into the core concepts, methodology, and practice of alignment. We identify the RICE principles as the key objectives of AI alignment: Robustness, Interpretability, Controllability, and Ethicality. Guided by these four principles, we outline the landscape of current alignment research and decompose them into two key components: forward alignment and backward alignment. The former aims to make AI systems aligned via alignment training, while the latter aims to gain evidence about the systems' alignment and govern them appropriately to avoid exacerbating misalignment risks. Forward alignment and backward alignment form a recurrent process where the alignment of AI systems from the forward process is verified in the backward process, meanwhile providing updated objectives for forward alignment in the next round. On forward alignment, we discuss learning from feedback and learning under distribution shift. On backward alignment, we discuss assurance techniques and governance practices that apply to every stage of AI systems' lifecycle.\n    submitted by    /u/mcaleste  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17pg3f4/r_ai_alignment_a_comprehensive_survey/",
          "publishedOn": "2023-11-06T23:12:41.000Z",
          "wordCount": null,
          "title": "[R] AI Alignment: A Comprehensive Survey",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17pewug/d_what_are_the_top_3_best_application/",
          "author": null,
          "description": "I’d like to know for all three languages. Thank you.\n    submitted by    /u/hdtv2001  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17pewug/d_what_are_the_top_3_best_application/",
          "publishedOn": "2023-11-06T22:21:22.000Z",
          "wordCount": null,
          "title": "[D] What are the top 3 best application types/implementation types/system types of each of Java, Python, and C# and/or .NET with respect to current and likely future AI/ML developments?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17pemox/r_interpreting_clips_image_representation_via/",
          "author": null,
          "description": "Blog: https://yossigandelsman.github.io/clip_decomposition/index.html\n Paper: https://arxiv.org/abs/2310.05916\n This paper investigates the CLIP image encoder by analyzing how individual model components affect the final representation. The authors show that the CLIP image representation can be decomposed as a sum across individual image patches, model layers, and attention heads. They use CLIP's text representation to interpret these summands. Interpreting the attention heads, they characterize each head's role by automatically finding text representations that span its output space, which reveals property-specific roles for many heads (e.g. location, counting, texture, shape, and OCR). Interpreting the image patches, they uncover an emergent spatial localization within CLIP. Finally, they use this understanding to remove spurious features from CLIP and to create a strong zero-shot image segmenter.\n    submitted by    /u/Ordinary_Pollution70  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17pemox/r_interpreting_clips_image_representation_via/",
          "publishedOn": "2023-11-06T22:09:35.000Z",
          "wordCount": null,
          "title": "[R] Interpreting CLIP's Image Representation via Text-Based Decomposition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17pcqdc/d_how_can_a_selflearning_system_autonomously_and/",
          "author": null,
          "description": "Take something as chain-of-thought or \"let's think step by step\". There's a lot of anecdotal and research evidence to support that with this suffix added, GPT4 provides better reasoning (that's one example out of many).\n I'd like to believe that companies like OpenAI, Google, Anthropic, MSFT, etal. are making good use of the troves of user-data they collect.\n I feel like it's fairly easier to find \"negative\" prompts because the desired outcome is known -- for example, i can find prompts that are jailbreaking the LLM just by feeding every pair of input/output to another dedicated agent (that could run at a significantly much lower parameters count, and for a fraction of the cost of the main model) that evaluates whether there has been a \"mold breakout\". The same can also be said for finding…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17pcqdc/d_how_can_a_selflearning_system_autonomously_and/",
          "publishedOn": "2023-11-06T20:51:57.000Z",
          "wordCount": null,
          "title": "[D] How can a self-learning system, autonomously and without any user feedback, discover positive net value prompts that when incorporated could improve its overall performance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17pco8k/project_which_kind_of_machine_learning_should_be/",
          "author": null,
          "description": "Hello everyone\n I'm about to start writing my bachelor in Mechatronics and for this project I want to work with some kind of machine learning. The system I work with is a parallel pumping system for a cooling system. I have 2 years of data sampled every 10 minutes available of the power, pressure, flow and other necessary variables.\n I've seen some other papers implementing neural networks. Is that the only solution to this kind of problem?\n I'm not that knowledgeable about machine learning, so I was hoping some of you bright minds might help enlighten me in which direction I should go :)\n Thank you for taking the time to read!\n    submitted by    /u/vision_dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17pco8k/project_which_kind_of_machine_learning_should_be/",
          "publishedOn": "2023-11-06T20:49:31.000Z",
          "wordCount": null,
          "title": "[Project] Which kind of machine learning should be used for parallel pumping energy efficiency optimization?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17pckgt/project_looking_for_did_alternatives_for_my/",
          "author": null,
          "description": "What is my best bet for creating an ai avatar assistant of lets say myself where I am already using gpt-4 and elevelabs for tts. Considered using DI-D to generate videos for each response to the user or using the streaming method. But DI-D's costs are out of this world. I'd prefer going the open source route and using cloud tech to generate these ai generated clips/videos. In this case I don't need to use stable diffusion for creating avatars as my avatars will simple be a model of myself. What is the best open-source AI animation generator for that specific purpose of using images and can generate videos/clips fast with the right equipment?\n    submitted by    /u/Izzy-gang-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17pckgt/project_looking_for_did_alternatives_for_my/",
          "publishedOn": "2023-11-06T20:45:06.000Z",
          "wordCount": null,
          "title": "[Project] Looking for DI-D alternatives for my specific use case",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17pasvf/d_best_domain_specific_embeddings/",
          "author": null,
          "description": "Been building a bunch of RAG apps recently and was wondering what the best domain specific models were. OpenAI’s Ada embedding model is not great for field specific texts and encoders like bioBERT or sentence transformers on hugging face don’t quite achieve the level of performance I’m looking for. Was wondering if there were any better options people have found.\n    submitted by    /u/Primary-Track8298  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17pasvf/d_best_domain_specific_embeddings/",
          "publishedOn": "2023-11-06T19:28:55.000Z",
          "wordCount": null,
          "title": "[D] Best Domain Specific Embeddings?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17pa0co/d_understanding_the_diffusion_process_in/",
          "author": null,
          "description": "I'm reading the DDPM paper and I don't understand the diffusion process definition; question is in the caption to the below image:\n ​\n Why is the highlighted part there? Shouldn't the mean of the distribution literally be x_{t-1}? Why would the center of the distribution be something other than the \\\"starting point\\\" of this step?\n    submitted by    /u/OneQuadrillionOwls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17pa0co/d_understanding_the_diffusion_process_in/",
          "publishedOn": "2023-11-06T18:54:21.000Z",
          "wordCount": null,
          "title": "[D] Understanding the diffusion process in denoising diffusion models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17p9hy3/d_realworld_aimlcv_for_social_good_projects/",
          "author": null,
          "description": "Background: working at the forefront of Computer Vision and ML (PhD level) but I feel like all the academic research is anyway gonna be used by some companies for profit or buried under heaps of new papers coming out everyday.\n Fed up of working to make someone rich or on something many people are working anyway and has a very small probability to have any impact.\n Looking for ideas for such problems. I’d be interested to work on real-world impactful problems even if I can make a tiny dent.\n I’ll start: https://ai4good.org/\n    submitted by    /u/4_love_of_Sophia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17p9hy3/d_realworld_aimlcv_for_social_good_projects/",
          "publishedOn": "2023-11-06T18:32:35.000Z",
          "wordCount": null,
          "title": "[D] Real-world AI/ML/CV for social good projects, companies, startup ideas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17p99mj/n_openai_whisper_new_model_large_v3_just_released/",
          "author": null,
          "description": "Whisper made huge impact on the open source AI world\n I am using everyday to transcribe my videos with that\n I was waiting new Large model\n Whisper is much better than paid alternatives and it is 100% free\n Here my full tutorial about it\n How to do Free Speech-to-Text Transcription Better Than Google Premium API with OpenAI Whisper Model\n Repo link : https://github.com/openai/whisper\n ​\n https://preview.redd.it/k9kssc6csryb1.png?width=1920&format=png&auto=webp&s=caeaf4921c8b4f9337c4842c5ef897cf456adc20\n    submitted by    /u/CeFurkan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17p99mj/n_openai_whisper_new_model_large_v3_just_released/",
          "publishedOn": "2023-11-06T18:22:39.000Z",
          "wordCount": null,
          "title": "[N] OpenAI Whisper new model Large V3 just released and amazing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17p8b4h/r_analogues_of_azure_automated_ml/",
          "author": null,
          "description": "Hello, I am looking for analogues of Azure Automated Machine Learning. Main features I want are GUI, in which I can built wgole pipeline and the platform should be able to process non-table data (e.g. images, etc). Any help is appreciate, thanks in advance.\n    submitted by    /u/gubby235  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17p8b4h/r_analogues_of_azure_automated_ml/",
          "publishedOn": "2023-11-06T17:41:57.000Z",
          "wordCount": null,
          "title": "[R] Analogues of Azure Automated ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17p7sat/r_gateloop_fully_datacontrolled_linear_recurrence/",
          "author": null,
          "description": "​\n https://preview.redd.it/3qgz8mnnvryb1.png?width=8522&format=png&auto=webp&s=943198b1b40c366596abba514ffbe134aa74ee8b\n Paper: https://arxiv.org/abs/2311.01927\n The authors introduce GateLoop, a fully data-controlled linear recurrent model which generalizes the recently proposed RetNet. GateLoop crushes the state-of-the-art models (Transformer, SSM and Hyena) on natural language modeling.\n Abstract\n Linear Recurrence has proven to be a powerful tool for modeling long sequences efficiently. In this work, we show that existing models fail to take full advantage of its potential. Motivated by this finding, we develop GateLoop, a foundational sequence model that generalizes linear recurrent models such as S4, S5, LRU and RetNet, by employing data-controlled state transitions. Utilizing this theoretical advance, GateLoop empirically outperforms existing models for auto-regressive language modeling. Our method comes with a low-cost O(l) recurrent mode and an efficient O(l log l) parallel mode making use of highly optimized associative scan implementations. Furthermore, we derive an O(l^2) surrogate attention mode, revealing remarkable implications for Transformer and recently proposed architectures. Specifically, we prove that our approach can be interpreted as providing data-controlled relative-positional information to Attention. While many existing models solely rely on data-controlled cumulative sums for context aggregation, our findings suggest that incorporating data-controlled complex cumulative products may be a crucial step towards more powerful sequence models.\n    submitted by    /u/Gorgoroth117  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17p7sat/r_gateloop_fully_datacontrolled_linear_recurrence/",
          "publishedOn": "2023-11-06T17:19:23.000Z",
          "wordCount": 2740,
          "title": "[R] GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17p7f2h/d_ai_survey_paper_for_an_economist/",
          "author": null,
          "description": "Hi!\n My wife is writing her bachelors thesis in business economics/accountancy on the impact of AI in accountancy, especially from an ethical/good practices standpoint. She asked me for some papers that discuss a definition of AI and possibly a good (very) high level survey paper of the field.\n I have a sort of working definition in my head, as I suppose most do, but no good pappers to recommend. I could rattle of 50 of the most influential papers but that's not really useful as a survey for someone not in the field. I figured Artificial Intelligence: A modern approach would have a definition but it is a bit unwieldy and far to long as a survey.\n Any suggestions?\n    submitted by    /u/-Melchizedek-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17p7f2h/d_ai_survey_paper_for_an_economist/",
          "publishedOn": "2023-11-06T17:03:41.000Z",
          "wordCount": null,
          "title": "[D] AI survey paper for an economist",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17p784h/d_googles_vertex_ai_review/",
          "author": null,
          "description": "Our startup is looking into Google's Vertex AI for semantic search/embedding capabilities as opposed to what we built. Anyone here have experience using this? What was your overall impression and what was your final GCP bill lol.\n Any info you can provide helps!\n    submitted by    /u/SiftreeHQ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17p784h/d_googles_vertex_ai_review/",
          "publishedOn": "2023-11-06T16:55:46.000Z",
          "wordCount": null,
          "title": "[D] Google's Vertex AI Review?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17p6hb9/d_how_are_the_popular_llm_api_servings_optimized/",
          "author": null,
          "description": "Currently there are a ton of offerings of various large langauge models hosted by companies like Together AI, Perplexity, Replit and many others.\n They seem pretty fast especially for the 30B+ model sizes. Anyone know how these are optimized? Apart from the horizontal scaling across GPUs and probably dynamic batching (assuming the requests are large in number), what else are these companies doing?\n Some of these companies also released the APIs the very next day the models come out - which also means that libraries which do low level CUDA/system-level optimizations (vLLM, Fastertransformer) also don't support these models. Hence couldn't be used in those APIs probably.\n Looking to learn how these are served. TIA!\n    submitted by    /u/shreyansh26  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17p6hb9/d_how_are_the_popular_llm_api_servings_optimized/",
          "publishedOn": "2023-11-06T16:22:47.000Z",
          "wordCount": null,
          "title": "[D] How are the popular LLM API servings optimized?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17p42te/r_very_detailed_mathematical_introduction_to_deep/",
          "author": null,
          "description": "Arxiv: https://arxiv.org/abs/2310.20360\n 601 pages, 36 figures, 45 source codes \n  \nThis book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-Łojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet have any background in deep learning at all and would like to gain a solid foundation as well as for practitioners who would like to obtain a firmer mathematical understanding of the objects and methods considered in deep learning. \n  \n   submitted by    /u/ghosthamlet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17p42te/r_very_detailed_mathematical_introduction_to_deep/",
          "publishedOn": "2023-11-06T14:34:04.000Z",
          "wordCount": 2729,
          "title": "[R] (Very detailed) Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17p24dw/d_what_are_the_limits_of_input_and_output_tokens/",
          "author": null,
          "description": "Mostly looking for evolution of LLM token limits. Any blog or reading resource would be helpful. Thanks.\n    submitted by    /u/Current_Dark6603  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17p24dw/d_what_are_the_limits_of_input_and_output_tokens/",
          "publishedOn": "2023-11-06T12:56:51.000Z",
          "wordCount": null,
          "title": "[D] what are the limits of input and output tokens for different LLMs over time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ow8wf/d_is_there_any_work_regarding_the_effects_of_text/",
          "author": null,
          "description": "Most of the papers I read don't seem to address the quality of the data used when pre-training a CLIP-like model. What I'm trying to do is use longer and more descriptive text as well as their shorter caption-like counterparts. I was curious if there has been any work done in that direction but am not having any luck finding it.\n A technical report titled Scaling Language-Image Pre-training via Masking (Li et al., 2022) claims to have used a maximum sequence length of 32 tokens, whereas the original CLIP uses 77. They claim that the difference was marginal. However, the difference that I'm looking for is something like 77 vs. 512.\n If anyone has any idea on what kind of papers there may be, I'd appreciate the tip.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ow8wf/d_is_there_any_work_regarding_the_effects_of_text/",
          "publishedOn": "2023-11-06T06:04:08.000Z",
          "wordCount": null,
          "title": "[D] Is there any work regarding the effects of text quality when pre-training CLIP-like models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17otzfw/r_idempotent_generative_network/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2311.01462\n Blog: https://assafshocher.github.io/IGN/\n Abstract:\n  \nWe propose a new approach for generative modeling based on training a neural network to be idempotent. An idempotent operator is one that can be applied sequentially without changing the result beyond the initial application, namely f(f(z))=f(z). The proposed model f is trained to map a source distribution (e.g, Gaussian noise) to a target distribution (e.g. realistic images) using the following objectives: (1) Instances from the target distribution should map to themselves, namely f(x)=x. We define the target manifold as the set of all instances that f maps to themselves. (2) Instances that form the source distribution should map onto the defined target manifold. This is achieved by optimizing the idempotence term, f(f(z))=f(z) which encourages the range of f(z) to be on the target manifold. Under ideal assumptions such a process provably converges to the target distribution. This strategy results in a model capable of generating an output in one step, maintaining a consistent latent space, while also allowing sequential applications for refinement. Additionally, we find that by processing inputs from both target and source distributions, the model adeptly projects corrupted or modified data back to the target manifold. This work is a first step towards a ``global projector'' that enables projecting any input into a target data distribution.\n  \n​\n    submitted by    /u/APaperADay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17otzfw/r_idempotent_generative_network/",
          "publishedOn": "2023-11-06T03:42:43.000Z",
          "wordCount": null,
          "title": "[R] Idempotent Generative Network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17oqavp/d_is_there_an_ai_toolservice_that_converts_ui/",
          "author": null,
          "description": "Hi,\n I am looking for an AI tool/service that will convert UI screens (in image format) into HTML and CSS code. It should preferably also have a python API, or just a python library would be even better.\n Please help.\n    submitted by    /u/master-killerrr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17oqavp/d_is_there_an_ai_toolservice_that_converts_ui/",
          "publishedOn": "2023-11-06T00:32:51.000Z",
          "wordCount": 2588,
          "title": "[D] Is there an AI tool/service that converts UI images to HTML CSS code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17oq76n/r_popular_attention_mechanism/",
          "author": null,
          "description": "what are some popular attention mechanism? I know sparse attention, ghost attention, and flash attention, what else?\n    submitted by    /u/No_Oilve_6577  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17oq76n/r_popular_attention_mechanism/",
          "publishedOn": "2023-11-06T00:27:55.000Z",
          "wordCount": 2549,
          "title": "[R] Popular Attention mechanism?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17op9cl/d_data_cleaning_vs_feature_engineering_where_to/",
          "author": null,
          "description": "Nitpickers, please sharpen your pencils. I want to hear from you! \n Data Cleaning vs Feature Engineering - where do you draw the line? \n ex: Definitely Data Cleaning: Filling missing values\n ex: Definitely Feature Engineering: Creating 1 synthetic feature from 3 existing columns\n ex: ?? Maybe feature engineering: Applying StandardScaler() to normalize data\n (mean 0, standard deviation 1) before any training occurs\n    submitted by    /u/CuriousFemalle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17op9cl/d_data_cleaning_vs_feature_engineering_where_to/",
          "publishedOn": "2023-11-05T23:43:27.000Z",
          "wordCount": 2601,
          "title": "[D] Data Cleaning vs Feature Engineering - where to draw the line? Ex:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17onl71/d_ai_master_in_europe/",
          "author": null,
          "description": "Hi everyone,\n a bit of context about me. I'm in my last year of Computer Science in Italy, actually I'm one month into an internship which will last about 2 more months and hopefully next week I'll have my last exam.\n I've started looking around to see what to do next and I think I'll continue the studies with an Artificial Intelligence master's degree I still don't know where but the only thing I know is that I want to move abroad.\n I would like to ask you which would be the best options within Europe, I know some in Germany and Netherlands but I would love to hear your opinions about it.\n Thanks to everyone who will take some of their time to reply!\n    submitted by    /u/saasyp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17onl71/d_ai_master_in_europe/",
          "publishedOn": "2023-11-05T22:28:10.000Z",
          "wordCount": 2660,
          "title": "[D] AI Master in Europe",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ome23/eli5_what_is_analog_deep_learning_d/",
          "author": null,
          "description": "I just read about the push to develop analog computer chips, eg https://news.mit.edu/2022/analog-deep-learning-ai-computing-0728\n But how is analog hardware different from digital, and why specifically would it be better for neural networks? Is it better at matrix multiplication and if so how?\n    submitted by    /u/quantumofgalaxy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ome23/eli5_what_is_analog_deep_learning_d/",
          "publishedOn": "2023-11-05T21:36:13.000Z",
          "wordCount": 2582,
          "title": "ELI5: what is analog deep learning? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ofere/r_diffusion_might_be_a_better_way_to_model/",
          "author": null,
          "description": "Probabilistic programming languages (PPLs) like Stan simplify modeling uncertainty but inference is still slow and inaccurate. Markov chain Monte Carlo is precise but sometimes slow. Variational inference is faster but has other drawbacks.\n Is diffusion a better way to model probability? \n A new technique called diffusion model variational inference (DMVI) uses diffusion models to approximate the probability distributions for faster, more accurate automated inference. \n (BTW: This is part of a trend I've noticed lately, where researchers are increasingly applying diffusion to diverse problems like mapping heat flow to robot obstacle avoidance and anomaly detection.)\n DMVI sets up the guess distribution using a diffusion model run in reverse. It introduces a new way to calculate the marginal likelihood for better data fitting. It also adjusts parameters for an even better fit.\n Early tests show DMVI makes inferences generally more accurately than other PPL methods, with similar compute costs and limited tuning needed.\n TLDR: Framing inference as a diffusion problem can potentially overcome limitations of current methods. DMVI might become a core part of the PPL toolkit.\n Full summary is here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ofere/r_diffusion_might_be_a_better_way_to_model/",
          "publishedOn": "2023-11-05T16:20:26.000Z",
          "wordCount": 2729,
          "title": "[R] Diffusion might be a better way to model randomness in PPLs than Markov chain Monte Carlo or VI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ofalw/d_tall_and_narrow_database/",
          "author": null,
          "description": "I am currently training NN on a tall and narrow database (30 variables, about 1M observations, it is sports data). It trains reasonably fast, only a couple of minutes. However, I am going to be getting a lot more data soon. I want to understand if graphics cards will speed up all types of machine learning, or will they work better for different types of data. Are there any good articles explaining. Thank you\n    submitted by    /u/ajplant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ofalw/d_tall_and_narrow_database/",
          "publishedOn": "2023-11-05T16:15:18.000Z",
          "wordCount": 2614,
          "title": "[D] - Tall and narrow database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17oez09/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17oez09/d_simple_questions_thread/",
          "publishedOn": "2023-11-05T16:00:31.000Z",
          "wordCount": 2581,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17oel3c/d_from_rnns_to_gpt4_10_years_of_nlp_research/",
          "author": null,
          "description": "In this video from my YT channel, I explain 50 concepts that cover the basics of NLP like Tokenization and Word Embeddings, to seminal work like RNNs, Seq2Seq, Attention, to innovative Transformer models like BERT, GPT, XL-Net, and InstructGPT. I present the challenges we have faced in previous designs, and what the current architectures do to improve it, and upcoming challenges with Hallucination and Alignment. Sharing a link here for those interested.\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17oel3c/d_from_rnns_to_gpt4_10_years_of_nlp_research/",
          "publishedOn": "2023-11-05T15:41:49.000Z",
          "wordCount": 2621,
          "title": "[D] From RNNs to GPT4 - 10 years of NLP research explained in 50 concepts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17o9kt9/dthe_name_of_the_game_abbas_bj%C3%B6rn_on_ai_and_music/",
          "author": null,
          "description": "submitted by    /u/DutchTechJunkie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17o9kt9/dthe_name_of_the_game_abbas_bj%C3%B6rn_on_ai_and_music/",
          "publishedOn": "2023-11-05T11:06:10.000Z",
          "wordCount": 2557,
          "title": "[D]The Name of the Game: Abba’s Björn on AI and Music Rights",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17o8d9o/n_computer_vision_news_of_november_2023_with_best/",
          "author": null,
          "description": "Dear all,\n Here is Computer Vision News of November 2023.\n Read 64 pages with Best of ICCV and an inspiring interview with Yann LeCun.\n Online version (recommended)\n PDF version\n Free subscription on page 64.\n Enjoy!\n https://preview.redd.it/y7mnfljv0iyb1.jpg?width=400&format=pjpg&auto=webp&s=fee061d3dddf4837094acf849ad425d1afe2ddcd\n    submitted by    /u/Gletta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17o8d9o/n_computer_vision_news_of_november_2023_with_best/",
          "publishedOn": "2023-11-05T09:33:06.000Z",
          "wordCount": 2574,
          "title": "[N] Computer Vision News of November 2023 with BEST OF ICCV",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17o5q4j/n_everything_you_should_now_about_grok_47/",
          "author": null,
          "description": "submitted by    /u/SDMegaFan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17o5q4j/n_everything_you_should_now_about_grok_47/",
          "publishedOn": "2023-11-05T06:07:24.000Z",
          "wordCount": 2561,
          "title": "[N] Everything you should now about Grok 4/7",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17o4sxx/d_the_bar_for_technical_novelty_at_iclr_and/",
          "author": null,
          "description": "I just came across two papers submitted to ICLR this year by the same group:\n  \nhttps://openreview.net/pdf?id=IP28nY6TJQ\n https://openreview.net/pdf?id=lJYAkDVnRU\n  \nAlthough the two papers are in different domains, their proposed methods are almost identical if you swap out the encoders (see Figure 1 in both papers).\n idk, these papers technically don't break any ICLR rules (that I know of), but they seem to violate the spirit of the conference.\n What do you all think? The chance of the second paper being accepted at a conference would be much lower if the first paper is published first, and vice-versa. So, it seems like the authors are taking advantage of the fact that they came up with both variants of the method at the same time and are kind of \"double-dipping.\"\n ​\n    submitted by    /u/CrypticDNS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17o4sxx/d_the_bar_for_technical_novelty_at_iclr_and/",
          "publishedOn": "2023-11-05T05:02:51.000Z",
          "wordCount": 2671,
          "title": "[D] The bar for technical novelty at ICLR and simultaneous submissions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17o2bt3/d_cross_validation_and_training_auc/",
          "author": null,
          "description": "I am using gradient boosted tree for a classification problem with 2 percent event rate data. The top auc on cross validation Is 0.78 but when I am using the top hyperparameters from the croosvalidator and Training a separate model on the same data I am getting an AUC of 0.5. I am not getting why this is happening.\n    submitted by    /u/Snoo71755  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17o2bt3/d_cross_validation_and_training_auc/",
          "publishedOn": "2023-11-05T02:33:35.000Z",
          "wordCount": 2593,
          "title": "[D] Cross validation and Training Auc",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17o1m2l/projectp_creating_twin_delayed_deep_deterministic/",
          "author": null,
          "description": "Hi everyone (wasn't sure if this counts as a beginner project or not? Seams pretty advanced to me). I've been using ChatGPT(3.5) to help me convert Python code using TD3 into JavaScript with TensorFlow JS. This is for the community and not for personal gain. I've yet to find an example of this, hence the conversion.\n My goal is to make a basic blueprint for the community to use on TensorFlow JS projects. When complete, the agent will be displayed on an HTML5 canvas walking toward a civilian for good reward, while avoiding a zombie (negative penalty). Eventually I will develop a separate, far more advanced simulation based on this.\n The bad news: ChatGPT is shakey when it comes to complex conversions, and my Python/Tensorflow knowledge base isn't perfect. At the moment the agent isn't learning yet, but it's running without errors. I expect the code has mistakes I don't even know about yet.\n The good news: I have made a lot of progress and have a GitHub repository set up for the community to learn from and use the project: https://github.com/CloudZero2049/TD3-TensorFlowJS\n I would love for anyone who knows the intricacies of TD3 (DDPG is a close relative), and TensorFlow JS to help me get this blueprint project setup for everyone =) The README on GitHub has more info and resources.\n    submitted by    /u/CloudZero2049  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17o1m2l/projectp_creating_twin_delayed_deep_deterministic/",
          "publishedOn": "2023-11-05T01:56:12.000Z",
          "wordCount": 2767,
          "title": "[Project][P] Creating Twin Delayed Deep Deterministic Policy Gradient (TD3) with TensorFlow JS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17o0qr4/d_machine_learning_in_production/",
          "author": null,
          "description": "Hello everyone, I'm a full stack developer, I studied as a robotics engineer and completed different courses and certifications on machine learning.\n I would like to know what are the main technologies to know to work in machine learning in production?\n What courses gives a real skills and value to work in the industry?\n How machine learning models are deployed and exposed on servers?\n    submitted by    /u/AcquaFisc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17o0qr4/d_machine_learning_in_production/",
          "publishedOn": "2023-11-05T01:12:09.000Z",
          "wordCount": 2603,
          "title": "[D] Machine Learning in production",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nysgz/p_open_sourcing_llmtuner_an_experimental/",
          "author": null,
          "description": "Hi Folks,\n Happy to share an open source side project I've been working on - LLmtuner. It's a framework for finetuning large models like Whisper, Llama, Llama-2, etc with best practices like LoRA, QLoRA, through a sleek, scikit-learn-inspired interface.\n As someone who works with Large Models a lot, I found myself writing a lot of boilerplate code every time I wanted to finetune a model. Llmtuner aims to simplify the finetuning process down to just 2-3 lines to get training started, similar to scikit-learn. \n Sample usecase\n Supported Models\n 🚀 Features:\n  \n🧙‍♀️ Finetune state-of-the-art LLMs like Whisper, Llama with minimal code\n 🔨 Built-in utilities for techniques like LoRA and QLoRA\n ✌ Launch webapp demos for your finetuned models with one click\n 💥 Fast inference without separate code\n 🌐 Easy model sharing and deployment coming soon\n  \nThis is still experimental code I've been using for personal projects. I thought others might find it useful too so decided to open-source it. \n  \nGithub : https://github.com/promptslab/LLMtuner\n For quick demo : Colab\n  \nContributions and feedback are very welcome! I hope it will be helpful in your research & projects. Have a good weekend, Thanks :)\n    submitted by    /u/Traditional-Poet2746  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nysgz/p_open_sourcing_llmtuner_an_experimental/",
          "publishedOn": "2023-11-04T23:36:43.000Z",
          "wordCount": 2736,
          "title": "[P] Open Sourcing Llmtuner - An Experimental Framework for Finetuning Large Models Like Whisper and Llama with scikit-learn-inspired interface",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nym31/n_tropical_probabilistic_ai_school_tropical/",
          "author": null,
          "description": "Tropical Probabilistic AI School — Jan 29-Feb 2, 2024\n You are invited to apply for the 1st Tropical Probabilistic AI School (TropAI), held on January 29-Feb 2, 2024, in Rio de Janeiro, Brazil.\n APPLY NOW — The application deadline is November 23, AoE (Anywhere on Earth).\n The ProbAI is here to provide an inclusive educational environment that serves state-of-the-art machine learning and artificial intelligence expertise with a probabilistic twist. \n Whether you are a Ph.D. student, advanced MSc or BSc student, experienced researcher, engineer, or hobbyist, you're welcome to join our community of learners. \n With a carefully designed curriculum and a seamless blend of theory and hands-on sessions, our expert team of invited lecturers will guide you through five intensive days, each dedicat…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nym31/n_tropical_probabilistic_ai_school_tropical/",
          "publishedOn": "2023-11-04T23:28:07.000Z",
          "wordCount": 2973,
          "title": "[N] Tropical Probabilistic AI School (Tropical ProbAI), Rio de Janeiro — Jan 29-Feb 2, 2024",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nxap6/d_can_someone_please_help_me_find_this_research/",
          "author": null,
          "description": "submitted by    /u/sad_and_stupid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nxap6/d_can_someone_please_help_me_find_this_research/",
          "publishedOn": "2023-11-04T22:25:44.000Z",
          "wordCount": 2547,
          "title": "[D] Can someone please help me find this research paper? I can't find it anywhere",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nwzix/d_backpropagation_for_gradient_computation/",
          "author": null,
          "description": "Hi all, I'm studying Deep learning from Santanu Pattanayak's \"Pro Deep Learning with TensorFlow 2.0: A Mathematical Approach to Advanced Artificial Intelligence in Python\". At the section where Is explained backpropagation I can't get why partial derivatives have these result: can you help me please ? I post expressions for each layer of and XOR function and thus derivatives for each layer. In the 1st image there's the structore of the XOR itself. In particular I don't understand why dz3/di3 has this result (near black arrow). I read in the previous step z3 expressed as a function of z3 (typing error?) Thanks to all!\n    submitted by    /u/ArlingtonBeech343  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nwzix/d_backpropagation_for_gradient_computation/",
          "publishedOn": "2023-11-04T22:11:02.000Z",
          "wordCount": 2643,
          "title": "[D] Backpropagation for gradient computation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nw4wc/p_query_standardization_for_semantic_search/",
          "author": null,
          "description": "Hi all, I'm new to LLM-based app development and I need some help improving the performance of the semantic search part of my application.\n My system is pretty simple. User submits a query, the query is ran against a knowledge bank using semantic search. I'm using Azure Cognitive Search for the semantic search piece, so I think I'm good there. \n What I need help in is standardizing the query. More specifically:\n  \nTempletizing: I was thinking of using NER to replace places, companies and acronyms with placeholders in the query, but I doubt something open-source would work out of the box would work. Thoughts or suggestions on this?\n \nQuery breakdown: oftentimes, the query submitted by the user is a collection of multiple questions. I need to find a way to break them down individual queries. I feel like this must be a common problem with LLMs, is these are a tried-and-true solution that you could point me to?\n \n Thanks in advance\n    submitted by    /u/Different-Student859  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nw4wc/p_query_standardization_for_semantic_search/",
          "publishedOn": "2023-11-04T21:33:58.000Z",
          "wordCount": 2700,
          "title": "[P] Query standardization for semantic search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nsqw0/p_hello_i_need_some_recommendations_for/",
          "author": null,
          "description": "What Python or JavaScript module (or combination of modules) can I use to analyze images for the following purpose?\n The image provided must:\n - Contain a face.\n - Emotion has to be neutral.\n - Face has to be up-straight and not tilted.\n - Face has to be fully visible, no hair, no hats no nothing.\n - The image has to be clear and not blurry.\n - Not too zoomed in, Not too zoomed out.\n - No filters.\n - White background.\n I already know of the DeepFace repository, but I'm still collecting information before I can touch any of the code.\n Any help is greatly appreciated.\n    submitted by    /u/goatonamissionn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nsqw0/p_hello_i_need_some_recommendations_for/",
          "publishedOn": "2023-11-04T19:05:46.000Z",
          "wordCount": 2639,
          "title": "[P] Hello, I need some recommendations for libraries/modules I can use to help me with my project!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nquyg/r_a_survey_on_large_language_model_based/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2308.11432\n GitHub: https://github.com/Paitesanshi/LLM-Agent-Survey\n Abstract:\n  \nAutonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at this https URL.\n  \n​\n https://preview.redd.it/wq5wic33bdyb1.png?width=2464&format=png&auto=webp&s=56d061d2c0cfdc1aff9783ed4e3bae664c43c4b2\n    submitted by    /u/APaperADay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nquyg/r_a_survey_on_large_language_model_based/",
          "publishedOn": "2023-11-04T17:41:15.000Z",
          "wordCount": 2757,
          "title": "[R] A Survey on Large Language Model based Autonomous Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nqmnf/d_surveying_and_breaking_down_the_recent_history/",
          "author": null,
          "description": "submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nqmnf/d_surveying_and_breaking_down_the_recent_history/",
          "publishedOn": "2023-11-04T17:29:52.000Z",
          "wordCount": 2544,
          "title": "[D] Surveying and breaking down the recent history of Multimodal AI Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nposd/d_tensorflow_recommendation_model_system_design/",
          "author": null,
          "description": "I am a senior CS student and I am building my capstone. We are a team of two and are required to build and implement an AI model in our project.\n The model we are building will make recommendations, it uses an NN based on the Neural Collaborative Filtering paper.\n We are using Next.js for our frontend and some of the backend using the BFF pattern. We need a separate backend for one of the features that uses websockets.\n At first, we wanted to build the separate backend with FastAPI because our model would be built with Tensorflow and Python, but then someone suggested using Express.js or some other JS backend and exporting the model that was made in Python and using Tensorflow.js to include it in the app.\n I am concerned about the way we might continuously improve our recommendation model. Using Python and exporting it to Tensorflow.js every time does not seem like a good solution. Even if at this level and for a project this small we don't have to worry about it, professors might ask us about our plan for the future and we need to have an answer ready.\n My other concern is that Tensorflow.js would affect the performance of the model.\n How do big companies that use recommendation systems solve this? I know Netflix uses the microservices architecture which allows them to use different languages across services. What about the Modular Monolithic architecture, would the Netflix approach still work?\n    submitted by    /u/iTsObserv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nposd/d_tensorflow_recommendation_model_system_design/",
          "publishedOn": "2023-11-04T16:45:08.000Z",
          "wordCount": 2783,
          "title": "[D] Tensorflow Recommendation Model System Design and Use in Production",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17noyds/diffusion_clip_chunks_to_generate_image_with/",
          "author": null,
          "description": "I am trying to reconstruct an image from chunks of CLIP embeddings. My current workflow would be as follows:\n 1.) Chunk image into regions and generate CLIP embeddings for each region\n 2.) Modify CLIP embeddings with some structual control\n 3.) Re-generate the image from CLIP embeddings. (Use masked inpainting to generate each sub-region of the image at each timestep and combine regions together before the next pass).\n Motivation: Generate CLIP-like embeddings from a GPT model and use this model to modify specific parts of an image with text instructions.\n Does this approach seem sensible? Would I be able to do this with a pretrained diffusion model with decent results, or would an approach like concatenating the CLIP embeddings and passing them together with position embeddings work better?\n TLDR: Given CLIP embeddings from image chunks, what is the best way to reconstruct the image?\n    submitted by    /u/codys12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17noyds/diffusion_clip_chunks_to_generate_image_with/",
          "publishedOn": "2023-11-04T16:10:45.000Z",
          "wordCount": 2687,
          "title": "[D]iffusion + CLIP Chunks to Generate Image with Region Control.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nor15/tensorflow_vs_pytorch_vs_jax_github_star_counts/",
          "author": null,
          "description": "submitted by    /u/we_are_mammals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nor15/tensorflow_vs_pytorch_vs_jax_github_star_counts/",
          "publishedOn": "2023-11-04T16:01:13.000Z",
          "wordCount": 2565,
          "title": "TensorFlow vs PyTorch vs JAX: GitHub star counts seem surprisingly linear. What do you think the future holds for these frameworks? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17no5wg/r_anomaly_detection_in_multivariate_time_series/",
          "author": null,
          "description": "Identifying anomalies in time-series data enables the detection of major events such as medical conditions, financial fraud, network intrusions, or equipment failures.\n Recent improvements in autoencoders, GANs, and transformers have demonstrated promising results in identifying time series anomalies (I recently covered a paper about inverting transformers for time-series data here). However, consistently recognizing anomalies across diverse datasets remains challenging due to the complexity of modeling temporal dependencies.\n A new paper investigates a novel application of diffusion models, which have shown exceptional performance in image and audio generation tasks. The key hypothesis is that diffusion processes may smooth out normal patterns while amplifying irregularities in anomalies, improving detectability. \n At a high level:\n  \nThe authors propose training diffusion models on time series data corrupted with Gaussian noise. \n At test time, noise is added to inputs which the model must denoise. \n The difference between the original and denoised sequences produces an anomaly score.\n  \nExperiments were conducted on synthetic and real-world multivariate time series datasets containing various anomaly types. The paper uses evaluation metrics like F1K-AUC and ROCK-AUC rather than just F1 scores.\n Results demonstrate that a diffusion autoencoder model combining diffusion with autoencoders performs strongly on anomaly detection across the studied datasets.\n TLDR: Diffusion processes are great at smoothing out normal patterns while amplifying anomalies, which this paper finds makes them useful for anomaly detection.\n Full summary is here. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17no5wg/r_anomaly_detection_in_multivariate_time_series/",
          "publishedOn": "2023-11-04T15:33:44.000Z",
          "wordCount": 2772,
          "title": "[R] Anomaly Detection in Multivariate Time Series with Diffusion Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nnps0/d_pytorch_model_visualizer_that_makes_pretty/",
          "author": null,
          "description": "Hey everyone!\n I am looking for a python library or external tool that makes aesthetically pleasing diagrams of any Pytorch network. I know about libraries like torchviz and similar, but their visualizations don't fit the style I want. I am looking for something with a style similar to this:\n https://preview.redd.it/pi0ylecgkcyb1.png?width=1920&format=png&auto=webp&s=a2c89ddb0631fd8caadf326a16c6939fac0cacce\n Thanks in advance 🙂\n    submitted by    /u/Skirlaxx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nnps0/d_pytorch_model_visualizer_that_makes_pretty/",
          "publishedOn": "2023-11-04T15:12:19.000Z",
          "wordCount": 2589,
          "title": "[D] Pytorch model visualizer that makes pretty diagrams",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nm4eb/r_highlights_for_every_neurips_2023_paper/",
          "author": null,
          "description": "Here is the list of all NeurIPS 2023 (Neural Information Processing Systems) papers and a short highlight for each of them. Among all ~3,500 papers, authors of around 1,000 papers also made their code or data available. The 'related code' link under paper title will take you directly to the code base.\n https://www.paperdigest.org/2023/10/nips-2023-highlights/\n In addition, here is the link of \"search within NeurIPS 2023\" that can be used to find papers within NeurIPS-2023 related to a specific topic, e.g. \"diffusion model\":\n https://www.paperdigest.org/search/?topic=nips&year=2023&q=diffusion_model\n NeurIPS 2023 will take place at New Orleans on Dec 10, 2023.\n    submitted by    /u/biandangou  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nm4eb/r_highlights_for_every_neurips_2023_paper/",
          "publishedOn": "2023-11-04T13:52:31.000Z",
          "wordCount": 2635,
          "title": "[R] Highlights for every NeurIPS 2023 paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nlrj6/d_p_advice_needed_local_vs_cloud_based_processing/",
          "author": null,
          "description": "Hi all, newbie here hoping for advice from the community. \n Context: We run a charity focussed on biodiversity planting. Due to high costs, we’re developing a computer vision model for weed identification and targeting. This can increase environmental benefits by reducing chemical use\n Our technical team is looking to ramp up training of the computer vision model to differentiate between weeds and native plants. A mechanical or laser based weed removal mechanism will then target the weed.\n Problem: we are weighing up the benefits of cloud-based image-processing vs local-processing. Understand cloud-based solutions like AWS EC2 P3 enable training of more complex models. But as we are resource constrained, we are considering a more powerful machine to enable local processing and reduce long-term variable costs, which I understand are significant.\n Questions:\n  \nFeasibility: Is it even plausible that we could train a model locally with computer vision for weed identification? Some research suggests that this would be difficult if not impossible due to GPU and data requirements.\n If it is plausible, what specs would we need for a machine? A donor can buy us an Apple new MacBook M3 Max with 16 core CPU, 40 core GPU, 16 core neural engine, 126GB memory machine. Understand NVIDIA’s chips have superior ML performance and cost, but we are locked into Apple for various reasons (image based work etc). If pursuing local training, we guess 2-4TB may be better; if cloud-based, 1TB might suffice. \n At our early stage of planning, wondering what experts here think about our plan? Should we pursue cloud-based training regardless? \n  \nPlease excuse the newbie questions - we’re a charity and learning fast! Any help or advice welcome.\n    submitted by    /u/Complete-Baby8711  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nlrj6/d_p_advice_needed_local_vs_cloud_based_processing/",
          "publishedOn": "2023-11-04T13:32:46.000Z",
          "wordCount": 2832,
          "title": "[D] [P] Advice needed: local vs cloud based processing and software requirements - computer vision model for weed identification in biodiversity planting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17nkptb/p_research_papers_october_2023/",
          "author": null,
          "description": "submitted by    /u/seraschka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17nkptb/p_research_papers_october_2023/",
          "publishedOn": "2023-11-04T12:34:01.000Z",
          "wordCount": 2550,
          "title": "[P] Research Papers (October 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17niq22/pfast_and_portable_llama2_inference_on_the/",
          "author": null,
          "description": "submitted by    /u/smileymileycoin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17niq22/pfast_and_portable_llama2_inference_on_the/",
          "publishedOn": "2023-11-04T10:23:00.000Z",
          "wordCount": 2554,
          "title": "[P]Fast and Portable Llama2 Inference on the Heterogeneous Edge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17niec3/d_sampling_with_vs_without_replacement/",
          "author": null,
          "description": "In what context is sampling with replacement superior to sampling without replacement when training a machine learning algorithm, and vice versa? Opinions diverge, and I never encountered a good rule of thumb here.\n    submitted by    /u/Blutorangensaft  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17niec3/d_sampling_with_vs_without_replacement/",
          "publishedOn": "2023-11-04T10:00:06.000Z",
          "wordCount": 2573,
          "title": "[D]: Sampling with vs without replacement",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ni6sp/d_how_to_build_this_pipeline/",
          "author": null,
          "description": "Hey everyone!\n Right now I'm working on a project to finetune Speech to Text models with real-world data. Basically, users record audio on the frontend and it gets sent to the backend. The backend stores these audio recordings as audio files on a cloud bucket. The second step is transcribing these audio recordings. This is done by our contractors who use a UI we built that retrieves untranscribed audio recordings from the bucket, allows the contractor to listen to the audio and write a transcript and then submits the transcript to a backend which stores the transcript along with the id of the audio recordings in a SQL DB.\n ​\n Now we want to train/finetune ASR models (mostly whisper) on these labeled audio recordings. My question is, how do I design and implement a data pipeline that gets the data from the cloud bucket and the sql db (which has the transcript) and aggregates it and makes it ready for the asr training/finetuning.\n I have heard of Apache Airflow for building data pipelines but I've never used it. Will this be the right tool for the job? Can you please provide details/best practices/tool recommendation on how to build such a pipeline?\n What I'm thinking about is using a tool to create parquet files that have two main columns: audio (floating point array of audio data) and transcript (text column that has the transcription for audio) and some other columns for metadata\n ​\n Note: We're using a small cloud provider that is not AWS, Azure or GCP so please recommend open source tools\n    submitted by    /u/Amgadoz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ni6sp/d_how_to_build_this_pipeline/",
          "publishedOn": "2023-11-04T09:43:44.000Z",
          "wordCount": 2800,
          "title": "[D] How to build this pipeline",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ncisz/d_xgboost_with_limesharp/",
          "author": null,
          "description": "I built an xgboost model using Python that uses 10 features to make its predictions. Some of those features categorical and are encoded using one hot encoding. The model preforms well but I’m having trouble exploring feature weighting for a specific row instance.\n After encoding I go from 10 features to 5000+ as expected. The problem is I can’t figure out a way to show the feature value influences on a single rows instance for only the 10 features.\n Is this possible or do I need to use another form of encoding?\n    submitted by    /u/DataDojoDude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ncisz/d_xgboost_with_limesharp/",
          "publishedOn": "2023-11-04T03:06:30.000Z",
          "wordCount": 2630,
          "title": "[D] Xgboost with lime/sharp",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17naso2/dhow_to_fine_tune_llms_using_deepspeed_without/",
          "author": null,
          "description": "I've been trying to fine tune the llama 2 13b model (not quantized) on AWS g5.12x instance which has 4*24gb A10GPUs, and 192gb ram. I'm also using PEFT lora for fine tuning. I've been trying to fine-tune it with hugging face trainer along with deepspeed stage 3 because it could offload the parameters into the cpu, but I run into out of memory errors irrespective of the batch size or my sequence length. In the deepspeed configuration file I have given the offload optimizer and offload param to cpu as well. Any ideas on where I could be going wrong? Or is the model just too big for my machine even with deepspeed?\n    submitted by    /u/IXMachina  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17naso2/dhow_to_fine_tune_llms_using_deepspeed_without/",
          "publishedOn": "2023-11-04T01:35:50.000Z",
          "wordCount": 2657,
          "title": "[D]How to fine tune LLMs using deepspeed without OOM issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17n792o/research_which_python_libraries_do_you_recommend/",
          "author": null,
          "description": "I'm currently looking for python libraries that offer models for the label ranking problem. So provided with a context x and a set of Labels Y, the model should output a ranking of those labels.\n I'm mostly interested in models that implements the Ranking by comparison method (RPC) and the Plackett-Luce Model.\n I would be grateful for any hints.\n    submitted by    /u/Emergency_Caramel_69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17n792o/research_which_python_libraries_do_you_recommend/",
          "publishedOn": "2023-11-03T22:44:39.000Z",
          "wordCount": 2603,
          "title": "[Research] Which python libraries do you recommend for label ranking?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17n3hdf/d_tuning_models_for_closed_book_qa/",
          "author": null,
          "description": "After transitioning from a different career path into ML/AI, I've embarked on a self-learning journey that's been incredibly rewarding yet challenging at times. I'd love to get your insights on a project I'm working on. Here’s what I’ve done so far:\n  \nDived into AI research papers and theoretical foundations.\n Set up a personal server with high-end GPUs.\n Conducted experiments with models like Llama2.\n Implemented low-rank adapters in models for document generation.\n Trained transformers using pure PyTorch (steering clear of Hugging Face from now on).\n  \nMy current challenge is training a model that can perform Q&A on documents it has generated. While the Flan paper has provided some direction, practical application has proven to be complex, especially when balancing resource use and noise constraints(servers are very loud and I'd like to minimize training time for this reason).\n I'm reaching out for:\n  \nInsights on training Llama (or similar models) for Q&A tasks on generated content.\n Experiences or lessons learned from implementing advice from the Flan paper or similar research.\n Tips on efficient resource management during training (to alleviate time, noise, and power concerns).\n  \nYour collective wisdom would be a beacon for a lone learner like myself. If there are foundational concepts I might be missing or resources I should consult, please point me in the right direction.\n Thank you for your time and help!\n    submitted by    /u/TheRealBracketMaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17n3hdf/d_tuning_models_for_closed_book_qa/",
          "publishedOn": "2023-11-03T19:54:46.000Z",
          "wordCount": 2757,
          "title": "[D] Tuning Models for Closed Book Q&A",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17n3g8d/d_p_first_time_delving_into_gen_ai/",
          "author": null,
          "description": "Hi,\n I need to make a powerpoint presentation for a startup founder who might hire me. He owns a digital/social media marketing company that also does website development.\n So I need to show the following things in the presentation:-\n  \nCreate an automated LDM model/service with very high accuracy (>90%) for UI/UX design. Goal is to minimize the role of graphic designers as much as possible.\n Create an automated LLM model/service with very high accuracy (>95%) for onboarding/handling customers as well as customer support. Currently, the task is managed by a bunch of product managers and ChatGPT powered chatbots. Goal is to minimize the role of these product managers as much as possible.\n Besides the above, if you guys have any other AI solutions that I could include then I'd be very grateful. The more valuable solutions I can pitch to the founder, the better chances I'll have to getting a job in his company.\n  \nPlease help me because I've never really played with Gen AI before. Please point me in the right direction 🙏\n Thanks in advance!\n    submitted by    /u/master-killerrr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17n3g8d/d_p_first_time_delving_into_gen_ai/",
          "publishedOn": "2023-11-03T19:53:17.000Z",
          "wordCount": null,
          "title": "[D] [P] First time delving into Gen AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17n1wwn/d_label_my_own_data_for_finetuning_ocr/",
          "author": null,
          "description": "Hi! I was wondering if anyone could give me a heads up on what I can do to label my own corpus of data to fine tune an OCR model. An example of what I want to detect better is shown here https://files.catbox.moe/bnsb2i.png Right now stuff like amazon textextract can't pickup the superscript footnote markers (the small 1,2,3) very accurately, and I'd like to manually mark some datasets to hopefully increase this. This is actually a very common book format, and yeah I do realize it will take a lot of time but it's better than nothing I suppose.\n Thanks and God bless!\n    submitted by    /u/angel__-__-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17n1wwn/d_label_my_own_data_for_finetuning_ocr/",
          "publishedOn": "2023-11-03T18:43:04.000Z",
          "wordCount": 2639,
          "title": "[D] Label my own data for Fine-tuning OCR?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17n02zj/ddoes_view_function_in_pytorch_cause_loss_of/",
          "author": null,
          "description": "So let's say I have an encoded tensor of size [1024,4,20] which represents [number_of_people, 4 choices, embedding_dim]\n Which mean each individual person will have 4 choices on, let's say food, and this differ accross the entire population (which is now a batch). This tensor is already encoded with torch.nn.Embedding, where 20 is the dim size.\n I need to compress this into a tensor of size [4,20] so that all those \"meal choices\" information of each unique person is now a 2d tensor, since I need to multiply this matrix with another embeddings.\n I'm still in my learning phase with pytorch and trying to go through documents on dimension reduction (I'm familiar with all the reshaping and etc, but this is the first time I actually have to really think and be careful since it could mean I might lose information if I don't do this correctly). Could someone explain to me why using certain things, like view, would not lose these specific information about each individual person and ensuring that I can carry on to use this compressed \"choices embedding\" on other thing with a peace of mind that I'm doing it correctly.\n I guess this comes with my lack of understanding in linear algebra, any guidance on how to understand this topic deeply would be greatly appreciated.\n I was trying to get a resulting tensor of size [1024,4] but my scoring function would give the tensor of size [1024,1024,4] if I multiple [1024,20] with [1024,20,4] (permuted choices tensor). At this point I'm also not sure if I should reduce it earlier on with original encoded tensor or as the last step on the resulting tensor.\n    submitted by    /u/parz01000101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17n02zj/ddoes_view_function_in_pytorch_cause_loss_of/",
          "publishedOn": "2023-11-03T17:17:51.000Z",
          "wordCount": 2828,
          "title": "[D]Does view function in PyTorch cause loss of information? I want to understand more about tensor dimension compression",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mxzli/d_what_do_you_fine_folks_think_of_this_causal_ai/",
          "author": null,
          "description": "Stanford blog post - https://ssir.org/articles/entry/the_case_for_causal_ai\n Found this other link that seems more ready - https://causalens.com/\n What do you think ? Next wonder or smokescreen ?\n Update - \n Found causalens website - \n https://preview.redd.it/x8azqhw136yb1.png?width=527&format=png&auto=webp&s=2d0cb3e0139233b2e9f9598e10d6060a6a4105cb\n Makes me wonder why this cannot be implemented with a ML / DL model ? Its human designed input to be structured as a constraint.. what do you think ? \n    submitted by    /u/dpadhy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mxzli/d_what_do_you_fine_folks_think_of_this_causal_ai/",
          "publishedOn": "2023-11-03T15:45:17.000Z",
          "wordCount": 2608,
          "title": "[D] What do you fine folks think of this - Causal AI ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mwwnh/d_comparing_rl_and_llm_prompting_for_modern_game/",
          "author": null,
          "description": "Hey people, I wanted to share a video from my ML YouTube channel discussing the state of the art methods for game playing AI systems post the LLM boom. Of course, this space was dominated by Reinforcement Learning for most of the 2010s, but there has been some interesting work towards using LLMs solo or as an “RL assistant” to train better RL agents.\n Here’s my video breaking down the complex prompting systems that let LLMs like GPT4 play Minecraft-like open world games and reflect on their progress. Hope people who are interested find it worthwhile…\n https://youtu.be/cXfnNoMgCio\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mwwnh/d_comparing_rl_and_llm_prompting_for_modern_game/",
          "publishedOn": "2023-11-03T14:54:40.000Z",
          "wordCount": 2639,
          "title": "[D] Comparing RL and LLM Prompting for Modern Game Playing AI Systems (a video)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mui0l/p_vector_quantization_methods/",
          "author": null,
          "description": "​\n https://preview.redd.it/mq8y8as0q4yb1.jpg?width=1374&format=pjpg&auto=webp&s=41a28968c929bf5a44fab03bef67991319e5728b\n txtai is an all-in-one embeddings database for semantic search, LLM orchestration and language model workflows.\n txtai has built-in support for quantizing vectors. The code above shows how 1-bit (binary) quantization can be applied. With 1-bit quantization, each dimension is transformed into a 1-bit value (0 or 1). Those bits are grouped into uint8's. This method can retain a surprising amount of accuracy, especially with high dimension models. \n See the article below for more information along with benchmarks. \n Article: https://neuml.hashnode.dev/all-about-vector-quantization\n GitHub: https://github.com/neuml/txtai\n    submitted by    /u/davidmezzetti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mui0l/p_vector_quantization_methods/",
          "publishedOn": "2023-11-03T12:57:41.000Z",
          "wordCount": 2618,
          "title": "[P] Vector quantization methods",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17msfo1/d_overfitting/",
          "author": null,
          "description": "Assuming that my training and testing set have the same distribution.\n If my training performance is very good but clearing overfitting, can I say that there MUST be a way to tune the model so that the testing performance will also improve? Or what other assumptions on my data do I have to make?\n    submitted by    /u/jef_107  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17msfo1/d_overfitting/",
          "publishedOn": "2023-11-03T10:59:00.000Z",
          "wordCount": 2590,
          "title": "[D] Overfitting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mre05/d_seeking_clarification_on_lora_adapters_and/",
          "author": null,
          "description": "I've come across several \"parameters efficient\" finetuning methods, LoRA (Low-Rank Adaptation), adapters, and prefix tuning, and I'm trying to understand the differences between them in the context of LLMs.\n I'm curious about the specific advantages and disadvantages of each method. For instance, how does the efficiency and performance of LoRA (that modify a selected subset of parameters) compare to adapters and prefix tuning (that add a small amount of parameters)?\n Are there any significant trade-offs to consider when choosing between these methods?\n I've come across a lots of LLMs trained with LoRA, but I'm struggling to find models trained with adapters or prefix tuning. Any guidance on this would be greatly appreciated.\n Also, Is it possible to use LoRA, adapters, and prefix tuning simultaneously in a single LLM? If so, are there any known benefits or drawbacks to this approach?\n Thank you in advance for your insights.\n    submitted by    /u/Distinct-Target7503  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mre05/d_seeking_clarification_on_lora_adapters_and/",
          "publishedOn": "2023-11-03T09:46:27.000Z",
          "wordCount": 2686,
          "title": "[D] Seeking Clarification on LoRA, Adapters, and Prefix Tuning in LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mr1sg/d_making_an_autoencoder_rotation_invariant_for/",
          "author": null,
          "description": "I'm trying to cluster PDF files that I've converted into images, and I've gotten a good suggestion to train an autoencoder with convolutional layers and cluster in the latent space. I'm hoping to implement this with Keras.\n The problem I'm running into is that these PDF files are scans, so some of the files are slightly rotated, and some of them are rotated by a full 90 degrees. As far as I know autoencoders are generally not rotation invariant, and all I was able to find online is a solution to a weird problem that involves 2d images of objects rotated in 3d. Is there a way to make an autoencoder that does have simple rotation invariance?\n    submitted by    /u/TeenColonistWrangler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mr1sg/d_making_an_autoencoder_rotation_invariant_for/",
          "publishedOn": "2023-11-03T09:21:52.000Z",
          "wordCount": 2654,
          "title": "[D] Making an autoencoder rotation invariant for image clustering?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mo53j/d_data_extraction_with_llms_json_csv_or/",
          "author": null,
          "description": "I’ve been reading about a bunch of different methods for extracting structured data from text with LLMs (from docs, audio transcripts, etc). \n One approach is entity extraction into a connected knowledge graph (ie people, places, things). \n Another is providing a JSON schema to extract into, and outputting JSON. \n I’ve also seen table extraction and outputting CSV. \n 🙋‍♂️ If you’ve been using (or want to use) LLM data extraction in your workflows, which method have you been using (or are looking to use in future)?\n I’d be interested to learn what methods are needed for real apps, vs what’s just been used for one-off demos.\n Appreciate any insight!\n    submitted by    /u/DeadPukka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mo53j/d_data_extraction_with_llms_json_csv_or/",
          "publishedOn": "2023-11-03T05:45:37.000Z",
          "wordCount": null,
          "title": "[D] Data extraction with LLMs: JSON, CSV or …?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mnmgu/d_about_scientific_machine_learning/",
          "author": null,
          "description": "[D] Hi everyone!\n I am new to SciML. When I read papers like Neural ODEs or Liquid time-constant Neural Network (LTC), there are both familiar and new principles in mathematics.\n I can use Google or chatGPT to understand the new principles but I am looking for books that I can learn more and dive dive into the field of SciML.\n Anyone can suggest such kinds of books. Thank you!\n    submitted by    /u/luciffer_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mnmgu/d_about_scientific_machine_learning/",
          "publishedOn": "2023-11-03T05:10:02.000Z",
          "wordCount": null,
          "title": "[D] About Scientific Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mn3bx/d_trying_to_remember_the_name_of_a_famous_paper/",
          "author": null,
          "description": "I'm trying to find a paper a I read a while back. I believe I heard about it from this subreddit. It was old. Maybe even from the 50s or 60s.\n The way I remember it, it starts by discussing some general properties of entropy and then derives logistic regression as a maximum entropy model. It had sort of a physics/information theory flavor to it.\n At least thats how I remember it. Does that sound familiar to anyone?\n ​\n edit:\n Found it thanks to /u/TastyOs. \n \"Information theory and statistical mechanics\" by ET Jaynes (1957). \n https://journals.aps.org/pr/abstract/10.1103/PhysRev.106.620\n Non paywall version:\n https://bayes.wustl.edu/etj/articles/theory.1.pdf\n Although now I feel like \"Entropy shall be all that a Man requires\" would have been a much better title. \n    submitted by    /u/12tone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mn3bx/d_trying_to_remember_the_name_of_a_famous_paper/",
          "publishedOn": "2023-11-03T04:37:02.000Z",
          "wordCount": 2656,
          "title": "[D] Trying to remember the name of a famous paper...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mmh91/d_vit_model_design/",
          "author": null,
          "description": "Hello everyone,\n I have described my understanding of the ViT architecture in the below diagram, I did not use normalization, skip connection or Multi-head Self-attention. Otherwise, if you find any mistake please let me know. Further, I have some questions. \n 1- In self-attention according to my understanding we pass all 256 + 1 tokens (that is basically the whole image +1 class token) to the 3 different linear layers. and find the similarity between the 2 and then do element-wise multiplication with the third to increase or decrease the magnitude, is this correct?\n 2- Do these linear layers in self-attention have any relationship between them or are 3 distinguish layers?\n 3- Further I don't understand the concept behind the class token, why we are using that if we remove that and use all 256 tokens (that will make more sense) in the classification layer is it not possible?\n ​\n ​\n https://preview.redd.it/jcmfwx1x32yb1.jpg?width=1200&format=pjpg&auto=webp&s=1d3757feb06e7576e64c5725bd460c760eadf9af\n    submitted by    /u/NoEntertainment6225  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mmh91/d_vit_model_design/",
          "publishedOn": "2023-11-03T04:01:25.000Z",
          "wordCount": 2686,
          "title": "[D] ViT model design",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mm34q/d_model_downloading_speed_is_limited_if_not/",
          "author": null,
          "description": "When I directly click the download button on HuggingFace website repo:\n  \n(Logged in) Download speed 10m/s\n (Not logged in) Download speed less than 500k/s\n  \nI have searched over the entire internet and cannot find why. The problem is that, now I have to use git clone to download the model with command line in the linux server, however even if I use HuggingFace-cli and my token, the speed is still less than 500k/s, same as \"not logged in\".\n Does anyone have any idea? This problem is really confusing.\n    submitted by    /u/CindyIH  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mm34q/d_model_downloading_speed_is_limited_if_not/",
          "publishedOn": "2023-11-03T03:39:01.000Z",
          "wordCount": 2629,
          "title": "[D] Model downloading speed is limited if not logged in to HuggingFace, help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mk3lx/r_telling_gpt4_youre_scared_or_under_pressure/",
          "author": null,
          "description": "In a recent paper, researchers have discovered that LLMs show enhanced performance when provided with prompts infused with emotional context, which they call \"EmotionPrompts.\"\n These prompts incorporate sentiments of urgency or importance, such as \"It's crucial that I get this right for my thesis defense,\" as opposed to neutral prompts like \"Please provide feedback.\"\n The study's empirical evidence suggests substantial gains. This indicates a significant sensitivity of LLMs to the implied emotional stakes in a prompt:\n  \nDeterministic tasks saw an 8% performance boost\n Generative tasks experienced a 115% improvement when benchmarked using BIG-Bench.\n Human evaluators further validated these findings, observing a 10.9% increase in the perceived quality of responses when EmotionPrompts were used.\n  \nThis enhancement is attributed to the models' capacity to detect and prioritize the heightened language patterns that imply a need for precision and care in the response.\n The research delineates the potential of EmotionPrompts to refine the effectiveness of AI in applications where understanding the user's intent and urgency is paramount, even though the AI does not genuinely comprehend or feel emotions.\n TLDR: Research shows LLMs deliver better results when prompts signal emotional urgency. This insight can be leveraged to improve AI applications by integrating EmotionPrompts into the design of user interactions.\n Full summary is here. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mk3lx/r_telling_gpt4_youre_scared_or_under_pressure/",
          "publishedOn": "2023-11-03T01:55:35.000Z",
          "wordCount": 2755,
          "title": "[R] Telling GPT-4 you're scared or under pressure improves performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mjnzi/d_recent_discussion_on_x_on_doing_a_phd_vs/",
          "author": null,
          "description": "This tweet (https://x.com/sshkhr16/status/1719721507872506090?s=46) gathered a lot of discussion with each side making a lot of good points. Would be great to know opinions of folks in this community. Would be really helpful especially to people deciding what to do after their undergrad maybe. I made a post a while before but I realized the title was kinda misleading so making a new one.\n    submitted by    /u/doppler_effects  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mjnzi/d_recent_discussion_on_x_on_doing_a_phd_vs/",
          "publishedOn": "2023-11-03T01:33:40.000Z",
          "wordCount": 2604,
          "title": "[D] Recent discussion on X on doing a PhD vs working in industry",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mehsg/r_transformers_learn_higherorder_optimization/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.17086\n Abstract:\n  \nTransformers are remarkably good at in-context learning (ICL) -- learning from demonstrations without parameter updates -- but how they perform ICL remains a mystery. Recent work suggests that Transformers may learn in-context by internally running Gradient Descent, a first-order optimization method. In this paper, we instead demonstrate that Transformers learn to implement higher-order optimization methods to perform ICL. Focusing on in-context linear regression, we show that Transformers learn to implement an algorithm very similar to Iterative Newton's Method, a higher-order optimization method, rather than Gradient Descent. Empirically, we show that predictions from successive Transformer layers closely match different iterations of Newton's Method linearly, with each middle layer roughly computing 3 iterations. In contrast, exponentially more Gradient Descent steps are needed to match an additional Transformers layer; this suggests that Transformers have an comparable rate of convergence with high-order methods such as Iterative Newton, which are exponentially faster than Gradient Descent. We also show that Transformers can learn in-context on ill-conditioned data, a setting where Gradient Descent struggles but Iterative Newton succeeds. Finally, we show theoretical results which support our empirical findings and have a close correspondence with them: we prove that Transformers can implement k iterations of Newton's method with O(k) layers. \n  \n​\n https://preview.redd.it/i6hdcx1v60yb1.jpg?width=2036&format=pjpg&auto=webp&s=ed95fc0b625878ed88c3f36baa9ea3fb07430ff7\n    submitted by    /u/APaperADay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mehsg/r_transformers_learn_higherorder_optimization/",
          "publishedOn": "2023-11-02T21:36:05.000Z",
          "wordCount": 2753,
          "title": "[R] Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mcs6i/p_get_alerts_when_your_ai_fails_and_get_a_gift/",
          "author": null,
          "description": "Hey folks — I’m working on a platform that allows you to set up meaningful, automated tests and experiment tracking for your LLMs in just a few minutes (our tests go well beyond just the usual latency, token usage & cost stuff).\n If you’ve tried shipping LLMs and haven’t run into any issues with performance or trustworthiness, leave a comment on what your use-case is / how you did it!\n If not, here’s a free sign-up link to our app: https://app.openlayer.com.\n P.S. Will send a $50 amazon gift card your way if you’re interested in giving me additional feedback afterwards (30 min call). Just send me an email at [gabriel@openlayer.com](mailto:gabriel@openlayer.com).\n    submitted by    /u/byebaybay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mcs6i/p_get_alerts_when_your_ai_fails_and_get_a_gift/",
          "publishedOn": "2023-11-02T20:23:20.000Z",
          "wordCount": 2657,
          "title": "[P] Get alerts when your AI fails (and get a gift card too!)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mbp3j/p_benchmarking_machine_learning_frameworks/",
          "author": null,
          "description": "MLBench enables developers and maintainers to effortlessly gauge how their frameworks perform compared to other implementations, prior code versions, or across different boards, with respect to both runtime performance and other metrics.\n https://www.collabora.com/news-and-blog/news-and-events/benchmarking-machine-learning-frameworks.html\n    submitted by    /u/mfilion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mbp3j/p_benchmarking_machine_learning_frameworks/",
          "publishedOn": "2023-11-02T19:36:03.000Z",
          "wordCount": 2572,
          "title": "[P] Benchmarking machine learning frameworks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mamv1/d_one_llm_wont_rule_them_all/",
          "author": null,
          "description": "There isn't going to be one LLM to rule them all and here's why: https://generatingconversation.substack.com/p/one-llm-wont-rule-them-all\n    submitted by    /u/cgwuaqueduct  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mamv1/d_one_llm_wont_rule_them_all/",
          "publishedOn": "2023-11-02T18:48:49.000Z",
          "wordCount": 2556,
          "title": "[D] One LLM won't rule them all",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17mag80/d_can_somebody_share_their_experience_of/",
          "author": null,
          "description": "I'm planning to attend ICML 2024 in person. Can somebody share their experience of attending the conference? Is it worth attending if you don't have any paper to present? If yes, how to get the most out of it?\n    submitted by    /u/cpluscplus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17mag80/d_can_somebody_share_their_experience_of/",
          "publishedOn": "2023-11-02T18:41:01.000Z",
          "wordCount": 2583,
          "title": "[D] Can somebody share their experience of attending ICML conference?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m9tj4/d_could_it_be_advantageous_to_trainfinetune_some/",
          "author": null,
          "description": "This may be weird question, but I have tried looking for resources and haven't found anything at all. \n We are trying to train a classifier from some data using a pretrained LLM. The data consist of several features which are text, so we decided at some point to concatenate them in a string with the proper connectors and use as input the whole string. For instance, think about data of some product: \"name\", \"manufacturer\", \"specs\", etc. Then we create a string as \"The product televisor from this manufacturer which have the following specs: ...\". In this case the problem would be to decide the category of the product.\n For our particular case, our model makes some critical mistakes and it seems that they stem from not noticing that some features are critical (following the previous example, the manufacturer for instance). We were wondering if it would be beneficial to train the model first only using the substring corresponding to the feature that we think is more important and add features to the training little by little.\n I am a bit worried that this may lead to a bad local minimum and the model gets stuck there. Has anybody seen or done anything similar or has any reason why this would or wouldn't work?\n    submitted by    /u/soloetc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m9tj4/d_could_it_be_advantageous_to_trainfinetune_some/",
          "publishedOn": "2023-11-02T18:13:34.000Z",
          "wordCount": 2756,
          "title": "[D] Could it be advantageous to train/finetune some model (actually a LLM) feature by feature?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m9b64/r_grace_discriminatorguided_chainofthought/",
          "author": null,
          "description": "TLDR: The paper proposes a decoding approach that improves multi-step (chain-of-thought) reasoning by using a discriminator to score and guide the generation of correct reasoning steps. It outperforms self-consistency and verifiers on various tasks and enhances both final answer accuracy and intermediate reasoning correctness.\n ​\n Paper: arxiv.org/abs/2305.14934\n Code: https://github.com/mukhal/grace/\n ​\n ​\n    submitted by    /u/moyle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m9b64/r_grace_discriminatorguided_chainofthought/",
          "publishedOn": "2023-11-02T17:51:38.000Z",
          "wordCount": 2587,
          "title": "[R] GRACE: Discriminator-Guided Chain-of-Thought Reasoning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m8to3/d_from_i5_10400_to_i5_11400_or_another_monitor/",
          "author": null,
          "description": "My current CPU is i5 10400. For ML will i5 10400 bottleneck rtx 3060 12gb? heard it will because that i5 supports only 3rd Gen, then should I upgrade to i5 11400 just to get the support of Gen 4 or instead I should just buy another monitor for dual monitor set up?\n    submitted by    /u/speed-speed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m8to3/d_from_i5_10400_to_i5_11400_or_another_monitor/",
          "publishedOn": "2023-11-02T17:29:25.000Z",
          "wordCount": 2602,
          "title": "[D] From i5 10400 to i5 11400 or Another monitor for dual monitor set up",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m85ry/d_benefits_of_using_only_attention_weights_for/",
          "author": null,
          "description": "I'm confused as to why people would only use a subset of weights as learnable parameters for LoRA. If you are only using attention weights as update params, you still need the decomposed weights for the other layers to get the derivative of the loss with respect to the attention weights. That's how the chain rule works, so I don't see how it would help with memory consumption. Is there something I'm missing here?\n    submitted by    /u/skelly0311  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m85ry/d_benefits_of_using_only_attention_weights_for/",
          "publishedOn": "2023-11-02T17:00:37.000Z",
          "wordCount": 2617,
          "title": "[D] benefits of using only attention weights for LoRA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m7ufq/d_unsupervised_feature_selection/",
          "author": null,
          "description": "Hello, I am doing a simulation study to see how associations change when aggregating spatial data. I have a large number of continuous exposure variables to choose from (>100). Before creating my models, I want to choose a group of meaningful exposures that limit collinearity (maybe ~10). The outcome variable will be simulated, and I want to choose the exposures without regard to the outcome (therefore I believe this is unsupervised learning). What is the best way to select these features? How many features should I select? Thank you! \n    submitted by    /u/DefinitelyAmNotOP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m7ufq/d_unsupervised_feature_selection/",
          "publishedOn": "2023-11-02T16:46:36.000Z",
          "wordCount": 2627,
          "title": "[D] Unsupervised feature selection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m7s6i/d_thoughts_on_masked_language_modeling_objective/",
          "author": null,
          "description": "Google has published a number of papers showing their increasing affinity for what was originally called a masked language modeling objective and has now become corrupted spans.\n I first saw this in the T5 paper\n Later in the UL2 paper \"What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?\"\n And finally in Transcending Scaling Laws with 0.1% Extra Compute\n However, I don't see this mentioned in this sub or in any really in any discussions on LLM training, nor do I find documentation for it in any LLM training frameworks. Is this something any of you have used? Are you aware of any open source tools or code examples of this?\n One thing that confuses me is that these papers all discuss Prefix-LMs as being important in this process, though I'm unsure what they mean. I know a Prefix-LM has a portion of it's inputs with bi-directional attention, but it's not something any actual models do as far as I can tell.\n But, in the \"Transcending Scaling Laws\" paper it seems like they take PaLM training checkpoints and finish off the pre-training with their corrupted span method by converting PaLM to a Prefix-LM. They say:\n  \nWe train U-PaLM using the prefix language model (PrefixLM) architecture, also sometimes known as a non-causal decoder-only model. The PrefixLM architecture keeps a non-causal mask in its prefix (or inputs) and applies bidirectional attention to input tokens.\n  \nIs it really possible to take a causal LM and turn it into a prefix LM (partially bi-directional) by just changing the attention mask with no impact on the learned weights? Or do they mean they are training on completions only as described in the hugging face documentation\n    submitted by    /u/elbiot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m7s6i/d_thoughts_on_masked_language_modeling_objective/",
          "publishedOn": "2023-11-02T16:43:57.000Z",
          "wordCount": 2824,
          "title": "[D] Thoughts on Masked Language Modeling Objective and Corrupted Spans for Causal LM's?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m709f/d_imputing_the_testing_data_after_combining_the/",
          "author": null,
          "description": "Hello,\n I imputed my training data's missing values with the mean of each column, but my question is, after combining the training and validation datasets and re-training the model, when we go on to test the model on the testing dataset, should we impute the testing data's missing values with the old training data's mean values, or the newly combined (train and validation) dataset's means?\n    submitted by    /u/CrunchyMind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m709f/d_imputing_the_testing_data_after_combining_the/",
          "publishedOn": "2023-11-02T16:10:01.000Z",
          "wordCount": 2605,
          "title": "[D] Imputing the Testing data after combining the Training and Validation datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m6u28/research_detecting_annotation_errors_in_semantic/",
          "author": null,
          "description": "Would you trust medical AI that’s been trained on pathology/radiology images where tumors/injuries were overlooked by data annotators or otherwise mislabeled? Most image segmentation datasets today contain tons of errors because it is painstaking to annotate every pixel.\n Example of bone shard not labeled properly.\n After substantial research, I'm excited to introduce support for segmentation in cleanlab to automatically catch annotation errors in image segmentation datasets, before they harm your models! Quickly use this new addition to detect bad data and fix it before training/evaluating your segmentation models. This is the easiest way to increase the reliability of your data & AI!\n We have feely open-sourced our new method for improving segmentation data, published a paper on the research behind it, and released a 5-min code tutorial. You can also read more in the blog if you'd like.\n    submitted by    /u/cmauck10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m6u28/research_detecting_annotation_errors_in_semantic/",
          "publishedOn": "2023-11-02T16:02:34.000Z",
          "wordCount": 2674,
          "title": "[Research] Detecting Annotation Errors in Semantic Segmentation Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m58ps/d_aaai_2024_reviews/",
          "author": null,
          "description": "Reviews are out on CMT. What did you get?\n    submitted by    /u/TheTeoz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m58ps/d_aaai_2024_reviews/",
          "publishedOn": "2023-11-02T14:51:53.000Z",
          "wordCount": 2547,
          "title": "[D] AAAI 2024 Reviews",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m3a5e/r_help_with_rfe_in_r/",
          "author": null,
          "description": "Hi everyone, I’m working on a bioinformatics project for school and I’m having some trouble doing the RFE in R. I’ve got an affymetrix gene expression set that I’ve done preprocessing on and I’m at the point where I’m ready to do RFE but I’m struggling writing the code for this (my first iteration took 30 hours to run and I screwed it up still… gave me my sample names as top variables instead of my probe sets). \n With that being said, the goal is to mine a bio marker from the affymetrix data through SVM&RF RFE. I’d also like to investigate different bio marker sizes (2 probe sets, 50, 100, all the way up to the max number of probes I have) \n I’m a biochemist by education got thrown into R and am struggling to learn it. I will say, it has been kinda fun tho. Thank you in advance, if any of you are in the central CT, USA region I’ll buy ya a beer! — rusty\n    submitted by    /u/RustyShackleford2677  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m3a5e/r_help_with_rfe_in_r/",
          "publishedOn": "2023-11-02T13:17:19.000Z",
          "wordCount": 2709,
          "title": "[R] help with RFE in R",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m28jc/d_a_question_about_nvida_nemo_getty_images/",
          "author": null,
          "description": "Getty is pitching their new Generative AI tool in our company, it's based on Nvidia Nemo and their \"unique selling point\" is that the model is fully trained with Getty images.\n This sounds a bit odd to me, but I'm not sure if it is actually possible to have a model only trained with proprietary images. The legal team assumes this as a true statement but I still think this is some sort of finetuned version of NVIDIA Nemo model.\n Does any of you have any clue on where to look to make sure we are not being a bit too gullible.\n Thank you in advance.\n    submitted by    /u/legado  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m28jc/d_a_question_about_nvida_nemo_getty_images/",
          "publishedOn": "2023-11-02T12:21:03.000Z",
          "wordCount": 2649,
          "title": "[D] A question about Nvida Nemo + Getty Images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m1t0b/d_open_source_machine_learning_projects/",
          "author": null,
          "description": "Hey,\n So i consider myself as a beginner in ML and i was wondering if there are open source projects i could contribute to, to apply my knowledge and get a real world experience of how these things are built an. The only projects I could find are labs or libraries and not products used in real life. \n Does any one have any experience contributing to open source projects?\n    submitted by    /u/parvpareek  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m1t0b/d_open_source_machine_learning_projects/",
          "publishedOn": "2023-11-02T11:56:22.000Z",
          "wordCount": 2602,
          "title": "[D] Open Source Machine Learning Projects",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m1r00/r_facebook_research_archived_handrelated_repos/",
          "author": null,
          "description": "I find that recently, Facebook Research archived (at lease some) their repos about hand-related research.\n Even very recent research:\n https://github.com/facebookresearch/PressureVision\n Or very popular ones:\n https://github.com/facebookresearch/ContactPose\n Does anybody have any idea why this happend? Or is it a mistake?\n    submitted by    /u/Crow-Scare  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m1r00/r_facebook_research_archived_handrelated_repos/",
          "publishedOn": "2023-11-02T11:52:56.000Z",
          "wordCount": 2578,
          "title": "[R] Facebook Research archived hand-related repos",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17m0glx/d_tools_for_creating_asr_datasets/",
          "author": null,
          "description": "[D] please can anyone recommend tools for creating ASR datasets?\n    submitted by    /u/afrodata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17m0glx/d_tools_for_creating_asr_datasets/",
          "publishedOn": "2023-11-02T10:31:13.000Z",
          "wordCount": 2550,
          "title": "[D] Tools for creating ASR datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ly8n8/separate_model_for_outliers_r_outliers_regression/",
          "author": null,
          "description": "Hey\n Here is a situtation i found myself. There is a dataset with around 4K observations with near 10% outliers in target variable. Transformations like log, box-cox, winsorize didn't work out. Robust regression approaches didn't help either.Model performance metrics with and wo those outliers are 4x worse. Note Just removing those observations is not considered\n Here is my plan. Build another model aimed to detect the outliers first, model for \"regular\" observations and model for outliers. Does it make sense and i'm not overcomplicating? What is the common approach in such cases?\n Any help and ideas are highly apreciated.\n Thanks in advance\n    submitted by    /u/No_Purchase8883  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ly8n8/separate_model_for_outliers_r_outliers_regression/",
          "publishedOn": "2023-11-02T07:39:45.000Z",
          "wordCount": 2643,
          "title": "Separate model for outliers [R] [outliers] [regression]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lreuq/d_aaai_24_reviews/",
          "author": null,
          "description": "Creating this thread in anticipation of the upcoming Phase 2 reviews and results. If there already is a thread, please share!\n ​\n    submitted by    /u/tallguyfromstats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lreuq/d_aaai_24_reviews/",
          "publishedOn": "2023-11-02T00:54:55.000Z",
          "wordCount": null,
          "title": "[D] AAAI 24 Reviews",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lqpfp/d_career_path_for_pursuing_job_in_machine/",
          "author": null,
          "description": "I am a final-year Industrial Engineering Masters student at Purdue University. My major areas of interest are Machine Learning and Operations Research. I have an option to pursue a Dual Master with other Masters in Electrical and Computer Engineering. Should I choose that path to get better job opportunities ? Will the other degree help me in the long term? [D]\n    submitted by    /u/pulkit_mundra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lqpfp/d_career_path_for_pursuing_job_in_machine/",
          "publishedOn": "2023-11-02T00:21:38.000Z",
          "wordCount": 2601,
          "title": "[D] Career Path for pursuing job in Machine Learning and Operations Research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lo15m/d_self_attention_from_first_principles_a_video/",
          "author": null,
          "description": "Hello guys, I wanted to post a video I have been working on for my Deep Learning YT channel about Self Attention and Masked Self Attention. In the video, I tried to explain the essence of self-attention in an intuitive manner, describe how it works in practice, why it works how it works, its various strengths and applications…\n I’m kinda excited to share the video here for those that are interested.\n https://youtu.be/4naXLhVfeho\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lo15m/d_self_attention_from_first_principles_a_video/",
          "publishedOn": "2023-11-01T22:22:29.000Z",
          "wordCount": 2608,
          "title": "[D] Self Attention from First Principles (A video)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lmxk7/r_zephyr_direct_distillation_of_lm_alignment/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.16944\n GitHub: https://github.com/huggingface/alignment-handbook\n Hugging Face: https://huggingface.co/collections/HuggingFaceH4/zephyr-7b-6538c6d6d5ddd1cbb1744a66\n X thread: https://twitter.com/Thom_Wolf/status/1717821614467739796\n Abstract:\n  \nWe aim to produce a smaller language model that is aligned to user intent. Previous research has shown that applying distilled supervised fine-tuning (dSFT) on larger models significantly improves task accuracy; however, these models are unaligned, i.e. they do not respond well to natural prompts. To distill this property, we experiment with the use of preference data from AI Feedback (AIF). Starting from a dataset of outputs ranked by a teacher model, we apply distilled direct preference optimization (dDPO) to learn a chat model with significantly improved intent alignment. The approach requires only a few hours of training without any additional sampling during fine-tuning. The final result, Zephyr-7B, sets the state-of-the-art on chat benchmarks for 7B parameter models, and requires no human annotation. In particular, results on MT-Bench show that Zephyr-7B surpasses Llama2-Chat-70B, the best open-access RLHF-based model. Code, models, data, and tutorials for the system are available at this https URL.\n  \n​\n https://preview.redd.it/4y355lxv0txb1.jpg?width=1200&format=pjpg&auto=webp&s=76e7b8a2ff06e39e9189712a42b1e349423b5d3d\n ​\n    submitted by    /u/APaperADay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lmxk7/r_zephyr_direct_distillation_of_lm_alignment/",
          "publishedOn": "2023-11-01T21:35:01.000Z",
          "wordCount": 2705,
          "title": "[R] Zephyr: Direct Distillation of LM Alignment - state-of-the-art for 7B parameter chat models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lku39/d_how_to_understand_structural_equivalence/",
          "author": null,
          "description": "Hi, I am new to graph neural networks and have some issue understanding structural equivalence discovered by Node2Vec. For instance, given following plot generated by Node2Vec visualization (taken from https://towardsdatascience.com/complete-guide-to-understanding-node2vec-algorithm-4e9a35e5d147):\n ​\n https://preview.redd.it/kqjiiywelsxb1.png?width=500&format=png&auto=webp&s=6ad9d86f6f0a6dbe1a5d641272a5956d110c8770\n They claim that if we encourage BFS search in Node2Vec, then we are more likely to discover structural equivalence patterns in the bottom plot. What I do not quite get is if we encourage BFS, would discovered embeddings be more \"local\"? If so, why those distant nodes would have similar colors/embeddings?\n Any idea would be much appreciated, thanks!\n    submitted by    /u/Illustrious-Pay-7516  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lku39/d_how_to_understand_structural_equivalence/",
          "publishedOn": "2023-11-01T20:01:32.000Z",
          "wordCount": 2625,
          "title": "[D] how to understand structural equivalence discovered by Node2Vec?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lj74h/d_need_help_about_height_map_analysis/",
          "author": null,
          "description": "As mentiones in the title, I need help with height map analysis.\n I want to create an artificial intelligence that can analyze the height map given as an input and mark areas such as mountainous areas, river beds, plains, rocks, cliffs and other geographical details on the map.\n Is there any advice you can give me or could you provide suggestions which will help me to move forward? I really am insterested in this project and want to work on it. Also, if you know any examples and/or studies related to this subject, can you please share them? I am looking forward to discovering more information regarding this topic.\n Edit: Spelling errors\n    submitted by    /u/PlayerWell  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lj74h/d_need_help_about_height_map_analysis/",
          "publishedOn": "2023-11-01T18:48:31.000Z",
          "wordCount": 2647,
          "title": "[D] Need Help About Height Map Analysis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lhbat/dai_that_can_remove_emojisspiderman_filter_from/",
          "author": null,
          "description": "recently i saw an ai where it said it can remove emoji which was obviously fake but it made me curious\n is there an ai that can do this?\n because i think ai cant do it is because the face does not exist in the image so ai have no way of showing the face behind emoji\n    submitted by    /u/randomaccimade69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lhbat/dai_that_can_remove_emojisspiderman_filter_from/",
          "publishedOn": "2023-11-01T17:24:48.000Z",
          "wordCount": 2593,
          "title": "[D]ai that can remove emojis/spiderman filter from face",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lgjrl/d_with_llms_hallucinating_nature_how_do_we_create/",
          "author": null,
          "description": "I want to use LLMs to automate analysing data and use it to provide insights to my users, but often times I notice insights being generated on factually incorrect data. I tried fine tuning my prompts, the structure in which I pass data to LLM, few shot learning but there still some chance of it to hallucinate. How can I create a production ready application where this insights are surfaced to end users and presenting incorrect insights is not accepted? I am out of ideas. Any guidance is appreciated 🙏🏻\n    submitted by    /u/software-n-erd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lgjrl/d_with_llms_hallucinating_nature_how_do_we_create/",
          "publishedOn": "2023-11-01T16:51:39.000Z",
          "wordCount": 2632,
          "title": "[D] With LLMs hallucinating nature, how do we create a credible production ready application?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lfvit/d_professionally_is_data_collection_carried/",
          "author": null,
          "description": "I am building my first model and I am about to start the data collection process, building a csv dataset, but I do not know whether to do this within a python script, the jupyter notebook where i will write the model, or a separate notebook.\n I have tried researching this but I have not found a concise answer to my question.\n Thanks in advance.\n    submitted by    /u/obvslynot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lfvit/d_professionally_is_data_collection_carried/",
          "publishedOn": "2023-11-01T16:21:56.000Z",
          "wordCount": 2602,
          "title": "[D] professionally, is data collection carried within a notebook?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lcrfj/d_what_do_yall_think_about_bidens_new_ai/",
          "author": null,
          "description": "Would it stifle the opensource development and new AI startups and only benefit the established big tech companies? It's kinda vague and I couldn't understand in my first read but does the executive order lacks teeth? That is if the guideline is not followed closely can government do anything to opensource community or new startups? \n limk to one of articles (no paywall) : https://www.reuters.com/technology/white-house-unveils-wide-ranging-action-mitigate-ai-risks-2023-10-30/\n    submitted by    /u/ColumbiaGSAlum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lcrfj/d_what_do_yall_think_about_bidens_new_ai/",
          "publishedOn": "2023-11-01T13:59:16.000Z",
          "wordCount": 2602,
          "title": "[D] What do y'all think about Biden's new AI regulation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lcfc1/p_llmvm_finetune_anywhere_avoid_big_models/",
          "author": null,
          "description": "I wanted to share a project I’ve been working on, LLM-VM. It’s a community-first, open-source tool designed to enhance the efficiency of fine-tuning and inference for large language models (LLMs) both locally and in cloud environments.\n At its core, LLM-VM implements recursive synthesized distillation with automatic task discovery. This means it can iteratively refine training data and model parameters, aiming to optimize model performance with less computational overhead.\n Our goal with LLM-VM is to provide a practical and accessible platform for researchers and developers. By facilitating more efficient model training and deployment, we hope to contribute to the broader machine learning community’s efforts in advancing language model capabilities.\n I’d love to get your feedback, contributions, or any thoughts you might have. Let’s collaborate to push the boundaries of what we can achieve with LLMs!\n Cheers!\n    submitted by    /u/mmirman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lcfc1/p_llmvm_finetune_anywhere_avoid_big_models/",
          "publishedOn": "2023-11-01T13:42:39.000Z",
          "wordCount": 2671,
          "title": "[P] LLM-VM: Fine-tune anywhere & avoid big models.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lbvma/p_langcheck_a_multilingual_toolkit_to_evaluate/",
          "author": null,
          "description": "Hi! I wanted to share LangCheck, an open source toolkit to evaluate LLM applications (GitHub, Quickstart).\n It already supports English and Japanese text, and more languages soon – contributions welcome!\n Core functionality:\n  \nlangcheck.metrics – metrics to evaluate quality & structure of LLM-generated text\n langcheck.plot – interactive visualizations of text quality\n langcheck.augment – text augmentations to perturb prompts, references, etc (coming soon)\n  \nSuper open to feedback & curious how other people think about evaluation for LLM apps.\n    submitted by    /u/kennysong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lbvma/p_langcheck_a_multilingual_toolkit_to_evaluate/",
          "publishedOn": "2023-11-01T13:15:23.000Z",
          "wordCount": 2607,
          "title": "[P] LangCheck: a multi-lingual toolkit to evaluate LLM applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17lbocx/d_data_pipelines_for_data_products/",
          "author": null,
          "description": "Data pipelines are one of the key components of an ML product. Creating value from different resources only makes sense when it is available to the consumers. In the article, you will explore the most important elements of a data pipeline that fulfils the data product needs, and you will get practical guidelines to incorporate in your use cases. \n Here's the article: https://moderndata101.substack.com/p/data-pipelines-for-data-products\n    submitted by    /u/growth_man  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17lbocx/d_data_pipelines_for_data_products/",
          "publishedOn": "2023-11-01T13:05:02.000Z",
          "wordCount": 2597,
          "title": "[D] Data Pipelines for Data Products",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17laey5/research_r_project_p_dataset_for_evaluate/",
          "author": null,
          "description": "Hi everyone. I should evaluate the precision and accuracy of some machine learning algorithms to calibrate a sensor. In particular I should compare these algorithms and choose the best one to calibrate a sensor, to proceed to obtain a transfer function. I did various searches on known sites and repositories but found very little. In particular, I would need datasets from 3 different sensors, in order to test the various algorithms on different sensors. Therefore each dataset must have the data collected by the sensor and the target data of the sensor itself, so that it can be calibrated and to be able to evaluate the calibration algorithms. Can you help me?\n    submitted by    /u/Calosss22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17laey5/research_r_project_p_dataset_for_evaluate/",
          "publishedOn": "2023-11-01T11:57:11.000Z",
          "wordCount": 2651,
          "title": "[Research], [R], [Project], [P] Dataset for evaluate algorithms on sensor calibration",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17l9ev7/n_webinar_enable_and_manage_vector_search_in/",
          "author": null,
          "description": "Hi Community!\n Today we are hosting a hands-on \"Enable and manage Vector Search in MongoDB Atlas with SuperDuperDB Webinar\": https://www.eventbrite.com/e/enable-and-manage-vector-search-in-mongodb-atlas-with-superduperdb-webinar-tickets-744936223297\n The following questions will be answered in the workshop:\n · What is vector search and why is it so important?\n · What are vector databases?\n · Why is it a huge advantage to use vector search with MongoDB Atlas instead of a vector database?\n · What embedding models are there?\n · How do I use these models to generate vector embeddings for my data?\n · How do I perform vector search?\n · What AI applications can I build on top of vector search?\n When?\n Wednesday, November 1st\n 12pm - 1pm ET (Eastern Standard Time)\n Add to Google · Outlook · iCal · Yahoo\n    submitted by    /u/Sevyten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17l9ev7/n_webinar_enable_and_manage_vector_search_in/",
          "publishedOn": "2023-11-01T10:54:14.000Z",
          "wordCount": 2655,
          "title": "[N] Webinar - Enable and manage Vector Search in MongoDB Atlas with SuperDuperDB",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17l8fuh/d_rewrite_with_many_style_using_ai/",
          "author": null,
          "description": "Hi everyone.\n Recently I have done some research to build a writing AI tool such as Quillbot. I see them do really amazing in paraphrase. I am currently trying to learn and research some articles to create a Deep learning model that can change many different writing styles and allow users to customize it themselves.\n I tried starting with small models and a few pretrained models. I find that models are trained to specialize in only one writing style or the models simply rewrite without regard to the specific style. Next, I tried LLM models like mistral 7B or Llama-2 and using the results, I self-assessed them to be somewhat better.\n However, I want more than that. Is there a way to create many different writing styles using only one model and we can scale it with more styles? and whether anyone has applied it to real products.\n If you can, could you suggest me some more related research?\n    submitted by    /u/HughLee_1999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17l8fuh/d_rewrite_with_many_style_using_ai/",
          "publishedOn": "2023-11-01T09:44:36.000Z",
          "wordCount": 2688,
          "title": "[D] Rewrite with many style using AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17l88lw/r_llms_may_dominate_information_access_neural/",
          "author": null,
          "description": "[arXiv] https://arxiv.org/abs/2310.20501\n [Abstract] Recently, the emergence of large language models (LLMs) has revolutionized the paradigm of information retrieval (IR) applications, especially in web search. With their remarkable capabilities in generating human-like texts, LLMs have created enormous texts on the Internet. As a result, IR systems in the LLMs era are facing a new challenge: the indexed documents now are not only written by human beings but also automatically generated by the LLMs. How these LLM-generated documents influence the IR systems is a pressing and still unexplored question. In this work, we conduct a quantitative evaluation of different IR models in scenarios where both human-written and LLM-generated texts are involved. Surprisingly, our findings indicate that …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17l88lw/r_llms_may_dominate_information_access_neural/",
          "publishedOn": "2023-11-01T09:28:56.000Z",
          "wordCount": null,
          "title": "[R] LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17l7wbw/p_numpy_numba_implementation_of_ivfpq_ann_index/",
          "author": null,
          "description": "Hi, just sharing with my recent github project fast-ivf in which I implemented from scratch IVF (+PQ) index using purely numpy/numba libraries. I did it mostly for an educational purpose. I also implemented something which I called `CompressedFastIVF` index which trains auto shallow autoencoder using kmeans assignments to reduce the dimensionality of the source embeddings, which seems to be a nice alternative for PQ method, at least on my data.\n Surprisingly, when I compared my implementation with the faiss library, I got 10 times speed up on my custom dataset with about 900k vectors of size 1024 when using simple IVF index. There are probably multiple reasons for that e.g. I use numpy with mkl library for algebraic operations, different implementation for kmeans (which result in different clusters sizes distribution) etc.\n When I tested it on other publicly available datasets, the speedup is much slower, which showed me that we should always test ANN libraries on the target data. \n ​\n ​\n ​\n    submitted by    /u/kmkolasinski  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17l7wbw/p_numpy_numba_implementation_of_ivfpq_ann_index/",
          "publishedOn": "2023-11-01T09:02:17.000Z",
          "wordCount": 2702,
          "title": "[P] Numpy / Numba implementation of IVF/PQ ANN index which is as fast as faiss",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17l7bxm/d_machine_learning_in_health/",
          "author": null,
          "description": "I would like to know if someone currently works or has worked as a machine learning engineer in the field of medical science / health and if so, I would like to know about their experiences.\n The background is that I got the possibility to either work in the medical field or robotics and I can't really decide and thus looking for some input.\n I am most curious about what you did in your work and if it felt fun / rewarding. Thanks a lot!\n    submitted by    /u/Numerous_Talk7940  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17l7bxm/d_machine_learning_in_health/",
          "publishedOn": "2023-11-01T08:16:11.000Z",
          "wordCount": 2618,
          "title": "[D] Machine Learning in Health",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17l6su4/d_p_ml_forecasting_of_satellite_imagery_and/",
          "author": null,
          "description": "Currently working on a personal project using satellite imagery to identify and generate a forecast of algae on the oceans surface. Generally, using an algorithm to identify times/locations of algae on the surface and an ML model to generate a forecast.\n I have a method of identifying the algae down (not ML), where my output is a binary raster of where the algae is/not on a given day/period, which would be my target data. I also have plenty of possible predictor data (also rasters) to use in a model.\n In the past, the only ML I've done with raster data is supervised classification with images and their labels. This means I am having trouble even finding a starting point for this part of my project.\n Another issue I know will be a complication is that in both my target and predictor data, there are areas of missing values, where clouds were in the way of the sensor. I am hoping I can find a model that can handle missing values to avoid imputation.\n I am quite new to the ML space, and have very little experience using raster data in ML. Just hoping for some ideas or places to start reading up on possible methods dealing with similar issues. Any help is appreciated.\n    submitted by    /u/DisgustedApe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17l6su4/d_p_ml_forecasting_of_satellite_imagery_and/",
          "publishedOn": "2023-11-01T07:33:48.000Z",
          "wordCount": 2748,
          "title": "[D] [P] ML Forecasting of Satellite Imagery and Handling Missing Data (Clouds)? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17l0jdd/d_p_bitnet_in_pytorch_or_jax/",
          "author": null,
          "description": "I was interested by the new bitnet paper https://arxiv.org/pdf/2310.11453.pdf, and was wondering if there was any way to use the 1 bit (1 or -1) in actual practice and how? More specifically, I know that you can do this with cuda (which I don't have any experience with) but it would be much better if there was a way to do this on a TPU (Jax?). Any implementation I've seen so far just pretends like they are using 1 bit but representing it with higher precisions.\n    submitted by    /u/Additional-Ad-7043  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17l0jdd/d_p_bitnet_in_pytorch_or_jax/",
          "publishedOn": "2023-11-01T01:06:17.000Z",
          "wordCount": 2621,
          "title": "[D] [P] Bitnet in Pytorch or Jax",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kzc3m/d_omniai_etl_for_ai_applications/",
          "author": null,
          "description": "Hey r/MachineLearning,\n I'm one of the founders of OmniAI. We just got accepted into YC's W24 batch, and we’re super excited on simplifying AI data workflows.\n OmniAI is a data infrastructure layer for AI. We’re syncing a company's data into a central warehouse that's optimized for AI interactions (vectorized, graph relations, etc.). Models can be run directly on that warehouse and kept up to date with your business intelligence.\n We'd love to hear about any pain points you are having with vector databases. Any insight/feedback is very much appreciated 😊\n    submitted by    /u/travelingladybug23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kzc3m/d_omniai_etl_for_ai_applications/",
          "publishedOn": "2023-11-01T00:06:37.000Z",
          "wordCount": 2622,
          "title": "[D] OmniAI - ETL for AI applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ky0g6/macbook_pro_m3_for_llms_and_pytorch_d/",
          "author": null,
          "description": "My current PC laptop is soon ready to retire, having worked for seven years. As a replacement I'm considering the new Macbook Pros. It is mainly the battery time which makes me consider Apple. These are my requirements for the laptop:\n  \ngreat battery time\n 16\" since I'm old and my eyes are degraded\n dual external monitors\n software engineering including running some local docker images\n  \nThen I have two ML requirements which I don't know if I could fulfill using a laptop:\n  \ngood performance for working with local LLMs (30B and maybe larger)\n good performance for ML stuff like Pytorch, stable baselines and sklearn\n  \nIn order to fulfill the MUST items I think the following variant would meet the requirements:\n Apple M3 Pro chip with 12‑core CPU, 18‑core GPU, 16‑core Neural Engine 36 GB memory 512 GB SSD Price: $2899 \n Question: Do you think I could fulfill the ML requirements using a Macbook Pro M3? Which config would be smart to buy in such case?\n Thankful for advice!\n    submitted by    /u/nizego  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ky0g6/macbook_pro_m3_for_llms_and_pytorch_d/",
          "publishedOn": "2023-10-31T23:03:30.000Z",
          "wordCount": 2700,
          "title": "Macbook Pro M3 for LLMs and Pytorch? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kxrh5/d_is_nvidias_new_system_memory_fallback_for/",
          "author": null,
          "description": "Hi all, today Nvidia released a new driver version that appears to allow the GPU to use system memory instead of crashing when it runs out, seen here: https://nvidia.custhelp.com/app/answers/detail/a_id/5490/~/system-memory-fallback-for-stable-diffusion\n I was wondering if this is compatible with model training and inference in Tensorflow and/or PyTorch, and how I could enable that (or if it would just work by default). This is especially confusing to me as I run Tensorflow in WSL so I don't know if this setting would carry over.\n    submitted by    /u/joshglen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kxrh5/d_is_nvidias_new_system_memory_fallback_for/",
          "publishedOn": "2023-10-31T22:52:10.000Z",
          "wordCount": 2625,
          "title": "[D] Is Nvidia's new \"System Memory Fallback for Stable Diffusion\" also compatible with model training / inference in general?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kvj1h/d_can_diffusion_models_really_be_steered_not/",
          "author": null,
          "description": "While diffusion models (e.g. Stable Diffusion) are all the rage, they don't seem to be prepared for downstream tasks. ControlNet looks great (on paper), but open-source implementations for mere mortals aren't ready for prime time.\n Do you have examples that show the contrary? Will FAANGs and not-really-open Research Labs be the only ones capable of making it happen?\n    submitted by    /u/btcmx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kvj1h/d_can_diffusion_models_really_be_steered_not/",
          "publishedOn": "2023-10-31T21:12:03.000Z",
          "wordCount": 2598,
          "title": "[D] Can Diffusion Models really be Steered? Not really! Not even ControlNet, ICCV23 Best Paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kviz3/r_an_opensourced_data_contamination_reports_for/",
          "author": null,
          "description": "Data Contamination in Multi-choice QA Benchmarks\n How much test samples are included in Llama's training data?\n This presented how much test samples in popular Multi-Choise QA benchmarks are included in the training data of Llama models (Common Crawl 2017–2020).\n Three types of data contamination: input-only contamination, input-and-label contamination, and all contamination containing both.\n Input-only contamination represents contaminations where only input part of test samples was included in the training data. On the contrary, input-and-label contamination indicate both input and the answer were included in the training data.\n Impact on Model Performance\n How much data contamination affects model evaluation?\n The full open sourced data contamination report: https://arxiv.org/abs/2310.17589\n All data and code: https://github.com/liyucheng09/Contamination_Detector\n    submitted by    /u/Simple-Leopard-7646  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kviz3/r_an_opensourced_data_contamination_reports_for/",
          "publishedOn": "2023-10-31T21:11:58.000Z",
          "wordCount": 2647,
          "title": "[R] - An Open-sourced Data Contamination Reports for Llama Series Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kuqw2/r_small_language_models_finetuned_to_coordinate/",
          "author": null,
          "description": "Paper link http://arxiv.org/abs/2310.18338\n Description We introduce DaSLaM, which uses a decomposition generator to decompose complex problems into subproblems that require fewer reasoning steps. These subproblems are answered by a solver. We use a relatively small (13B parameters) LM as the decomposition generator, which we train using policy gradient optimization to interact with a solver LM (regarded as black-box) and guide it through subproblems, thereby rendering our method solver-agnostic. Evaluation on multiple different reasoning datasets reveal that with our method, a 175 billion parameter LM (text-davinci-003) can produce competitive or even better performance, compared to its orders-of-magnitude larger successor, GPT-4. Additionally, we show that DaSLaM is not limited by the solver's capabilities as a function of scale; e.g., solver LMs with diverse sizes give significant performance improvement with our solver-agnostic decomposition technique.\n    submitted by    /u/Gaussian_Kernel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kuqw2/r_small_language_models_finetuned_to_coordinate/",
          "publishedOn": "2023-10-31T20:37:37.000Z",
          "wordCount": 2669,
          "title": "[R] Small Language Models Fine-tuned to Coordinate Larger Language Models improve Complex Reasoning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kt3hu/p_opensource_modular_observability_for_ai_systems/",
          "author": null,
          "description": "Hi r/MachineLearning community!\n Over the last three years, we have collaborated with hundreds of teams to enhance our understanding of observability requirements in AI systems.\n ML teams are trying to log as much as they can at every possible dimension. To satisfy these needs, they must be able to:\n - Log anything from every part of the AI Infra,\n - Observe and interpret the logged data at scale in a flexible fashion,\n - Add layers and layers of automations around the logged data.\n Thrilled to share with you the new product we built - AimOS, a framework to connect the dots and ensure modular observability for AI Systems!\n  \nEasily log, connect, and observe any part of your AI Systems – from experimentation and production stages to input prompts and monitoring.\n  \nAI Systems are not determ…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kt3hu/p_opensource_modular_observability_for_ai_systems/",
          "publishedOn": "2023-10-31T19:24:07.000Z",
          "wordCount": 2953,
          "title": "[P] Open-source modular observability for AI Systems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ksjpa/d_do_you_calculate_the_accuracy_and_loss_of_a/",
          "author": null,
          "description": "Hello,\n I'm curious, when evaluating a neural network for both the training and validation data, do you calculate the accuracy across the entire dataset, or at every batch and then find the average at every batch?\n    submitted by    /u/CrunchyMind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ksjpa/d_do_you_calculate_the_accuracy_and_loss_of_a/",
          "publishedOn": "2023-10-31T19:01:03.000Z",
          "wordCount": 2579,
          "title": "[D] Do you calculate the accuracy and loss of a neural network or batches or the whole dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17krp2q/d_unsupervised_clustering_without_knowing_number/",
          "author": null,
          "description": "Does anyone know where to find the best models for unsupervised clustering problems that don't specify the number classes? For example I googled unsupervised MNIST but IIC which holds the record requires the output dimension (k=10) to be specified? Is there a name for unsupervised clustering without knowing the number of classes? (I know of density/hierarchical clustering algorithms but am unaware of many deep learning ones) And specifically are results charted anywhere? I'm researching the topic and it seems knowing the number of things you're looking for is half the battle. I can find papers on methods that aim to find the number of clusters etc but are there any benchmarks to compare?\n    submitted by    /u/BigBrainUrinal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17krp2q/d_unsupervised_clustering_without_knowing_number/",
          "publishedOn": "2023-10-31T18:24:39.000Z",
          "wordCount": 2646,
          "title": "[D] Unsupervised Clustering without knowing number of classes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kqvl6/r_announcing_distilwhisper_6x_faster_than/",
          "author": null,
          "description": "Hey r/MachineLearning!\n ​\n At Hugging Face, we've worked hard the last months to create a powerful, but fast distilled version of Whisper. We're excited to share our work with you now!\n Distil-Whisper is 6x faster than Whisper-large-v2 and performs within 1% WER on out-of-distribution datasets. On long-form audio, we even achieve better results thanks to a reduction in hallucinations.\n ​\n For more information, please have a look:\n - GitHub page: https://github.com/huggingface/distil-whisper/tree/main\n - Paper: https://github.com/huggingface/distil-whisper/blob/main/Distil_Whisper.pdf\n ​\n Quick summary:\n  \nDistillation Process\n  \nWe've kept the whole encoder, but reduced the decoder to just 2 layers. Encoding takes O(1) forward passes, decoding takes O(N). To improve speed, all that matters is the decoder! The encoder is frozen during distillation while we fine-tune all of the decoder. Both KL loss and pseudo-labeling next word prediction is used.\n  \n Data\n  \nWe use 20,000h of open-sourced audio data coming from 9 diverse audio datasets. A WER-filter is used to make sure low-quality training data is thrown out.\n  \n Results\n  \nWe've evaluated the model only on out-of-distribution datasets and are only 1% worse than Whisper-large-v2 on short-form evals (CHiME-4, Earnings-22, FLEURS, SPGISpeech). On long-form evals (Earnings, Meanwhile, Rev 16) we beat Whisper-large-v2 thanks to a reduction in hallucinations.\n  \n Robust to noise\n  \nDistil-Whisper is very robust to noise (similar to its teacher). We credit this to keeping the original encoder frozen during training.\n  \n Pushing for max inference time\n  \nDistil-Whisper is 6x faster than Whisper on both short-form and long-form audio. In addition, we employ Flash Attention and chunked decoding which helps us achieve a real-time factor of 0.01!\n  \n Checkpoints?!\n  \nCheckpoints will be released this Thursday and will be directly integrated into Transformers. All checkpoints will be licensed under MIT.\n ​\n    submitted by    /u/pvp239  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kqvl6/r_announcing_distilwhisper_6x_faster_than/",
          "publishedOn": "2023-10-31T17:49:08.000Z",
          "wordCount": 2820,
          "title": "[R] Announcing Distil-Whisper - 6x faster than Whisper-large-v2 and performs within 1% WER on out-of-distribution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kq4p6/d_model_for_understanding_dashcam_images/",
          "author": null,
          "description": "i have some dashcam footage from my car and want to see how a model could embed the images in an unsupervised (or self-supervised) way so i dont have to label everything. \n like if scenarios that are semantically similar, but different in pixel space (pulling out the driveway in the day versus pulling in at night) could be clustered close-ish together in latent space so that i could label fewer images and have the model get the other using something like k-nearest or whatever.\n i am starting off with just frame level before i try to tackle videos as a sequence of images (will probably lose interest by that point, so want to get images dealt with first). i looked in to VAEs and tried training one from scratch on my data but i dont have enough compute power for that. \n does anyone here have any ideas about this? any pretrained off the shelf models that i could use for this? any leads for a literature survey?\n    submitted by    /u/samrus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kq4p6/d_model_for_understanding_dashcam_images/",
          "publishedOn": "2023-10-31T17:16:15.000Z",
          "wordCount": 2698,
          "title": "[D] model for \"understanding\" dashcam images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kq2lu/d_people_here_who_mastered_out_of_their_phds_do/",
          "author": null,
          "description": "Hi everyone. I'm a third-year Ph.D. student doing ML-related research and have no publications so far. I do have a couple of ongoing projects that will lead to first-author papers in the next few months. I'm also at a point where I think mastering out and getting a job might be a better option. But I also worry that I might regret not getting a Ph.D. I love research but I feel the academic environment is not a good fit for me. I just want to hear from people who were in a similar position as me. Did you stick through your PhD or did you master out? How has the life been after that?\n I started my PhD straight out of my undergrad so I didn't get any industry experience. So I've been thinking that getting a job with my master's and spending some time in the industry could be a good option. Then I can return back to grad school if I still have that urge. Or I can simply brave through my current situation and just get a PhD and then work in the industry. Any opinions are welcome!\n    submitted by    /u/llmlift  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kq2lu/d_people_here_who_mastered_out_of_their_phds_do/",
          "publishedOn": "2023-10-31T17:13:36.000Z",
          "wordCount": 2738,
          "title": "[D] - People here who mastered out of their PhDs, do you regret it? How has your life been after that?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kpyca/p_webbased_ai_content_generative_tools_that/",
          "author": null,
          "description": "I need some AI generative tools for a state-sponsored 1 hour course a friend of mine is hosting for people aged from 12 to 60 years old. They are taking an \"induction\" into AI with the goal of learning how to produce content with the help of AI. The idea is that they have a range of web-based AI tools at disposal in a computer in order to do a \"collaborative creative film\" of sorts.\n The different people in the course will be grouped into pairs, and then they will choose some of AI tools in a list to help them with the creative process. The AI tools in the list should not require inscription.\n The no-inscription rule it's a requirement because of data protection laws (no personal e-mail or other personal info should be given). Also, it would be preferable that, if the AI requires text inpu…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kpyca/p_webbased_ai_content_generative_tools_that/",
          "publishedOn": "2023-10-31T17:08:28.000Z",
          "wordCount": 2910,
          "title": "[P] Web-based AI content generative tools that require no inscription to be used?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kpi4l/d_ctransformers_vs_llamacpppython/",
          "author": null,
          "description": "what's the difference between ctransformers and llama-cpp-python?\n    submitted by    /u/kaoutar-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kpi4l/d_ctransformers_vs_llamacpppython/",
          "publishedOn": "2023-10-31T16:48:40.000Z",
          "wordCount": 2530,
          "title": "[D] ctransformers vs llama-cpp-python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kntyj/rwhat_can_cause_the_silhouette_score_to_increase/",
          "author": null,
          "description": "​\n https://preview.redd.it/gkibii705kxb1.png?width=504&format=png&auto=webp&s=ae2820ab0d324224177fa971319cd82965eb0129\n    submitted by    /u/Gandalfthebrown7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kntyj/rwhat_can_cause_the_silhouette_score_to_increase/",
          "publishedOn": "2023-10-31T15:35:27.000Z",
          "wordCount": 2549,
          "title": "[R]What can cause the silhouette score to increase like this at the end? Value of K=10 for about 200 dataset seems too much, no?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kn0qz/d_using_c_for_training_a_vision_transformer_agent/",
          "author": null,
          "description": "Hey!\n So, I am currently enrolled in a Master's Degree program and started my thesis this semester. I still have a year to develop it, so what I'm doing now is gathering as much info as I can about libraries for ML. My adviser and I have decided that we're going to use Vision Transformers as our approach to train an agent to inspect products at factories.\n So, a little background on me: I am a self-taught game developer. I've learned Lua, C, C++, and C# to make games, that's what I'm good at. I've studied the basics of ML at uni, but it was on Python. My most proficient language is C++, as I've worked a lot with it and feel comfortable with it, so I was thinking: Are there any good ML libraries for C++? Libraries that are as easy to use as Python libs (TensorFlow, Pytorch, etc.), for example? I love the way that you have control over the resources when coding with C and/or C++. Runtime speed is a bonus too.\n Thanks for the help :)\n    submitted by    /u/retroJRPG_fan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kn0qz/d_using_c_for_training_a_vision_transformer_agent/",
          "publishedOn": "2023-10-31T15:00:02.000Z",
          "wordCount": 2714,
          "title": "[D] Using C++ for training a Vision Transformer Agent",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kltbs/p_visualizing_geopolitics_with_un_voting_data_and/",
          "author": null,
          "description": "Hi all,\n I'm upskilling myself in Machine Learning. As a learning project, I trained an embedding model to group countries in the UN based on their voting habits.\n  \nOne I thought the results are interesting so I wanted to share.\n  \nMedium post here: https://medium.com/@sambhattacharyya/visualizing-geopolitics-with-un-data-and-machine-learning-b93f84270900\n View the the interactive 3d graph of embeddings here: https://sambhattacharyya.com/visualizing-geopolitics/index.html,\n 2) I'm still learning, so if anyone has feedback on the technical approach (I'm especially sure that using MSE loss isn't ideal here).\n Colab notebook here: https://colab.research.google.com/drive/1YkM_AsHCcs_boOCqobyQAs38Q43cm1Th#scrollTo=6801c41a-03d2-447f-8929-15d4f399df0f\n Raw dataset I compiled here: https://huggingface.co/datasets/sam-bha/un-general-assembly-votes-2000-2023\n    submitted by    /u/sam_bha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kltbs/p_visualizing_geopolitics_with_un_voting_data_and/",
          "publishedOn": "2023-10-31T14:04:42.000Z",
          "wordCount": 2621,
          "title": "[P] Visualizing Geopolitics with UN Voting data and Embeddings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kljhy/d_has_anyone_experimented_with_neural_search_for/",
          "author": null,
          "description": "Hi. I’m an AI engineer of an emerging retailer. We’re continuously pushing the boundaries of our user search experience. We’ve got a massive inventory, hence a lot of data to be managed. This got me thinking about the untapped potential of neural search.\n I've had my hands on OpenAI's GPT and Deepset's Haystack lately. Both tools are great in specific scenarios, but integrating them seamlessly at an enterprise scale is challenging, especially when we're talking about real-time user interactions. The primary challenge remains in managing multimodal data efficiently without sacrificing speed.\n To add context, my goal in leveraging something like GPT for e-commerce is to create a more intuitive, conversational, and responsive search function. Imagine a user typing in a vague description or query, and the system providing product suggestions like a seasoned salesperson would. Given the vast product range, the neural search could bridge the gap between user intent and the most relevant product offerings.\n If anyone has experience with this I’d like to hear your thoughts, and if you have any other tool recommendations for this pls do share. I’d be grateful for any help\n    submitted by    /u/PositiveFixing12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kljhy/d_has_anyone_experimented_with_neural_search_for/",
          "publishedOn": "2023-10-31T13:52:05.000Z",
          "wordCount": 2722,
          "title": "[D] has anyone experimented with neural search for e-commerce applications?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kkbm0/d_is_this_close_enough_to_be_usable_need_your/",
          "author": null,
          "description": "Hey there, Redditors! \n I'm back with the latest installment on creating dependable AI data pipelines for real-world production. \n If you've been following along, you know I'm on a mission to move beyond the \"thin OpenAI wrapper\" trend and tackle the challenges of building robust data pipelines. \n With 18 months of hands-on experience and many user interviews, I realized that with the probabilistic nature of systems, we need better_testing.gpt:\n 1. As you build you should test\n The world of AI is a fast-moving one, and we've realized that just working on systems is not an optimal design choice. By the time your product ships, it might already be using outdated technology. So, what's the lesson here? Embrace change, test along, but be prepared to switch pace.\n 2. No Best Practices Yet for R…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kkbm0/d_is_this_close_enough_to_be_usable_need_your/",
          "publishedOn": "2023-10-31T12:52:24.000Z",
          "wordCount": 2928,
          "title": "[D] Is this close enough to be usable? Need your inputs: Automated RAG testing tool. AI Data Pipelines for Real-World Production (Part 3)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kk04m/p_a_site_where_you_can_ask_the_same_question_to/",
          "author": null,
          "description": "Hi /r/machinelearning! I've been working with my collaborators on a site where you can compare OpenAI models to get a sense of the improvement over time of the models: https://theaidigest.org/progress-and-dangers\n https://preview.redd.it/khruhgkp7jxb1.png?width=1960&format=png&auto=webp&s=21d13125145f7fae7351686d4078868d65cbf8c3\n It includes a number of things that you might be interested in:\n  \nYou can ask any question and compare the outputs from the OpenAI models:\n  \nhttps://preview.redd.it/s5e9acev8jxb1.png?width=1458&format=png&auto=webp&s=0c3e5ba3661fccfc4f4ba60db346b6142b1e52f3\n  \nVisualises OpenAI models benchmark performance across 22 benchmarks:\n  \nhttps://preview.redd.it/vhai63308jxb1.png?width=1948&format=png&auto=webp&s=07f65f131b2e6d5122400120a11d24205b7d08d6\n  \nShows examples of benchmark outputs for GPT-2 to GPT-4\n  \nhttps://preview.redd.it/f3p7ni068jxb1.png?width=1980&format=png&auto=webp&s=dfe25c8c4a486a0df3c4cce2e4497fd250163bd1\n  \nDiscusses some dangerous emerging capabilities, such as biological weapons:\n  \nhttps://preview.redd.it/n6hinz7b8jxb1.png?width=2002&format=png&auto=webp&s=70cf0a0c228e1ac194146040c23a7f41dfe4e09a\n  \nIncludes an example of a simple agent autonomously exploiting a vulnerability in a game's code:\n  \nhttps://preview.redd.it/5a584w7f8jxb1.png?width=1944&format=png&auto=webp&s=3867a865c06b6e36fc2424f6ced038248ee0cafd\n I hope you'll find this a valuable resource for getting familiar with older LMs, comparing the outputs, and thinking about what's next in this space. Here's a link to the site: https://theaidigest.org/progress-and-dangers\n    submitted by    /u/timegentlemenplease_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kk04m/p_a_site_where_you_can_ask_the_same_question_to/",
          "publishedOn": "2023-10-31T12:35:35.000Z",
          "wordCount": 2673,
          "title": "[P] A site where you can ask the same question to GPT-2, GPT-3, GPT-3.5 and GPT-4, and compare the outputs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17khfsx/d_problems_with_wgan_for_time_series_imputation/",
          "author": null,
          "description": "I am trying to implement a WGAN for time series imputation. However, I am facing many problems due to the fact that I am a novice in generational models and I am not used to many concepts related to WGAN.\n ​\n I know that WGAN have a problem with critical weights that make them diverge infinitely, and there are three main ways to solve this problem as discussed in this other post. However, implementing them with the use of recurrent neural networks have been a total headache.\n ​\n 1- With a weight clipping with a threshold of 0.1 (as suggested in the literature) my critical loss does not change at all. I think this may be due to a gradient vanishing problem in recurrent networks.\n ​\n 2- Using Spectral Normalization is not well implemented in Torch for recurrent layers as it only handles one layer weight.\n ​\n 3- I cannot use Gradient Penalty because its implementation, as far as I know, depends on an interpolation of the critical value of an interpolated data between real and generated samples, which is not available to me as all samples have a mixture of real and missing values.\n ​\n Is there a solution to this problem that I am missing?\n    submitted by    /u/SrPinko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17khfsx/d_problems_with_wgan_for_time_series_imputation/",
          "publishedOn": "2023-10-31T09:59:48.000Z",
          "wordCount": 2735,
          "title": "[D] Problems with WGAN for time series imputation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kh39s/d_how_to_train_a_model_thatll_generate_an_average/",
          "author": null,
          "description": "There's a lot of image generators that'll allow you to generate multiple images based on the input data. Is there something that'll generate an image that's an average of the trained model instead?\n Didn't plan on using machine learning for this project but realized it might be an interesting path to explore.\n    submitted by    /u/max_b_jo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kh39s/d_how_to_train_a_model_thatll_generate_an_average/",
          "publishedOn": "2023-10-31T09:34:21.000Z",
          "wordCount": 2595,
          "title": "[D] How to train a model that'll generate an \"average\" image based on a large set of images?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17kgob4/d_fast_and_reliable_keyword_extraction/",
          "author": null,
          "description": "Please forgive my ignorance as I am a software engineer and fairly new to datascience and machine learning. Also, feel free to delete my post if this is not the right place to ask.\n I am currently working on a bookmark manager app that offers content preservation and automatic keywords extraction among other features to extend these bookmarks and make them more discoverable.\n For the life of me, I can't find a reliable way to extract keywords. I so far tried to use a python library called Newspaper3k But results were a mixed bag, half of the time, it will knock it out of the park with very accurate results, the other half, it will just output garbage.\n I have switched to using openai gpt3.5 APls but I really hate it. It's slow, very verbose and give me feeling of disgust because it's like using a machine gun to get rid of a fly.\n I have looked in huggingface and tried a couple of models but no luck so far.\n Please help. I am happy to selfhost something or just pay for a good APls\n    submitted by    /u/goodkernel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17kgob4/d_fast_and_reliable_keyword_extraction/",
          "publishedOn": "2023-10-31T09:02:50.000Z",
          "wordCount": 2716,
          "title": "[D] Fast and reliable keyword extraction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17k77av/executive_order_on_the_safe_secure_and/",
          "author": null,
          "description": "https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/\n It looks like content will have to be labeled, showing if it's AI-generated or not.\n And special rules will apply to:\n  \nany model that was trained using a quantity of computing power greater than 1026 integer or floating-point operations, or using primarily biological sequence data and using a quantity of computing power greater than 1023 integer or floating-point operations; and\n any computing cluster that has a set of machines physically co-located in a single datacenter, transitively connected by data center networking of over 100 Gbit/s, and having a theoretical maximum computing capacity of 1020 integer or floating-point operations per second for training AI.\n  \nAlso, easier visas for \"AI talent\".\n    submitted by    /u/we_are_mammals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17k77av/executive_order_on_the_safe_secure_and/",
          "publishedOn": "2023-10-30T23:39:21.000Z",
          "wordCount": 2651,
          "title": "Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17k6iha/d_relevance_extraction_in_rag_pipelines/",
          "author": null,
          "description": "I came across this interesting problem in RAG, what I call Relevance Extraction.\n After retrieving relevant documents (or chunks), these chunks are often large and may contain several portions irrelevant to the query at hand. Stuffing the entire chunk into an LLM prompt impacts token-cost as well as response accuracy (distracting the LLM with irrelevant text), and and can also cause bumping into context-length limits.\n So a critical step in most pipelines is Relevance Extraction: use the LLM to extract verbatim only the portions relevant to the query. This is known by other names, e.g. LangChain calls it Contextual Compression, and the RECOMP paper calls it Extractive Compression https://twitter.com/manelferreira_/status/1713214439715938528\n Thinking about how best to do this, I realized i…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17k6iha/d_relevance_extraction_in_rag_pipelines/",
          "publishedOn": "2023-10-30T23:07:26.000Z",
          "wordCount": 2993,
          "title": "[D] Relevance Extraction in RAG Pipelines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17k6bdy/d_face_recognition/",
          "author": null,
          "description": "I am working for a months on facial recognition system. I have 500 classes with 10 template for each class. I have applied almost and tested almost every model. Some of them are dlib 128 dim. Facenet (512), Insightface, Arcface. But none of them reduced the rate of false positive. I also fine tuned those models, I also trained a clasifier and I reached to 91 percent of accuracy with a very low quality images and also have a backlight effect. But the what I want my setup to be 99 percent which correctly classifies the person with a high similarity on true positive and a low similarity around 0.1 or 0.2 for an unknown class. Now my problem is that similarity is also high with unknown almost around 99 and I also used some distance metrics and it also not helping out. Note: the environment is a real world environment and I used CCTVs at a place where hundreds of unknown people visit daily.\n    submitted by    /u/No_Garbage9512  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17k6bdy/d_face_recognition/",
          "publishedOn": "2023-10-30T22:58:38.000Z",
          "wordCount": 2694,
          "title": "[D] Face Recognition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17k5yfw/d_computation_graphs_with_inplace_operations/",
          "author": null,
          "description": "With a computation graph typically used to represent NNs, where nodes represent operations and edges represent data dependencies, is it possible to represent in-place operations?\n    submitted by    /u/thanrl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17k5yfw/d_computation_graphs_with_inplace_operations/",
          "publishedOn": "2023-10-30T22:42:54.000Z",
          "wordCount": 2557,
          "title": "[D] Computation graphs with in-place operations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17k5aco/d_how_to_evaluate_if_llms_are_following_certain/",
          "author": null,
          "description": "I recently wrote a blog on evaluating whether your LLM applications are following required guidelines: https://uptrain.ai/blog/lost-in-translation-the-critical-impact-of-neglecting-guideline-adherence-in-llms?utm_source=reddit&utm_medium=reddit&utm_campaign=reddit\n Please let me know your feedback in the comment section\n    submitted by    /u/Vegetable-Skill-9700  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17k5aco/d_how_to_evaluate_if_llms_are_following_certain/",
          "publishedOn": "2023-10-30T22:14:01.000Z",
          "wordCount": 2564,
          "title": "[D] How to evaluate if LLMs are following certain guidelines or not?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17k4u40/r_redpajamadatav2_an_open_dataset_with_30/",
          "author": null,
          "description": "Blog: https://together.ai/blog/redpajama-data-v2\n Hugging Face: https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2\n GitHub: https://github.com/togethercomputer/RedPajama-Data\n Description:\n  \nRedPajama-V2 is an open dataset for training large language models. The dataset includes over 100B text documents coming from 84 CommonCrawl snapshots and processed using the CCNet pipeline. Out of these, there are 30B documents in the corpus that additionally come with quality signals, and 20B documents that are deduplicated.\n  \n   submitted by    /u/APaperADay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17k4u40/r_redpajamadatav2_an_open_dataset_with_30/",
          "publishedOn": "2023-10-30T21:55:00.000Z",
          "wordCount": 2598,
          "title": "[R] RedPajama-Data-v2: an Open Dataset with 30 Trillion Tokens for Training Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17k3fpb/r_fantom_a_benchmark_for_stresstesting_machine/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.15421\n Code: https://github.com/skywalker023/fantom\n Blog: https://hyunw.kim/fantom/\n Abstract:\n  \nTheory of mind (ToM) evaluations currently focus on testing models using passive narratives that inherently lack interactivity. We introduce FANToM 👻, a new benchmark designed to stress-test ToM within information-asymmetric conversational contexts via question answering. Our benchmark draws upon important theoretical requisites from psychology and necessary empirical considerations when evaluating large language models (LLMs). In particular, we formulate multiple types of questions that demand the same underlying reasoning to identify illusory or false sense of ToM capabilities in LLMs. We show that FANToM is challenging for state-of-the-art LLMs, which perform significantly worse than humans even with chain-of-thought reasoning or fine-tuning.\n  \n​\n https://preview.redd.it/mxb85o2vkexb1.png?width=1367&format=png&auto=webp&s=8749cddd15e6740e69ae47ef5edf3a1da96d89c2\n    submitted by    /u/APaperADay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17k3fpb/r_fantom_a_benchmark_for_stresstesting_machine/",
          "publishedOn": "2023-10-30T20:54:21.000Z",
          "wordCount": 2645,
          "title": "[R] FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17k34du/d_whos_ab_testing_in_prod/",
          "author": null,
          "description": "I never hear much about A/B testing in the ML community. Do you all tend to A/B test your changes? I have to imagine this is becoming more prevalent with LLMs and prompts.\n In my experience, every model change we made was through an A/B test. There is some literature in our domain that offline metrics may not correlate to online metrics, so we looked at both very closely.\n My team was heavily involved in A/B testing as well as managing the data pipeline from those exposures to create training data for the models.\n What do your experience look like?\n    submitted by    /u/mtbarta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17k34du/d_whos_ab_testing_in_prod/",
          "publishedOn": "2023-10-30T20:40:34.000Z",
          "wordCount": 2632,
          "title": "[D] Who's A/B testing in prod?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17k1cl5/p_looking_for_partner_for_a_doing_a_research/",
          "author": null,
          "description": "[P] Dm for further info but all in all its abt adding an extra feature (feature engg.) To our ML model to detect politeness in a language\n    submitted by    /u/PrudentFly8507  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17k1cl5/p_looking_for_partner_for_a_doing_a_research/",
          "publishedOn": "2023-10-30T19:24:31.000Z",
          "wordCount": 2567,
          "title": "[P] Looking for partner for a doing a research paper in ML/NLP politeness identification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jzf63/p_deconstructing_interface_design_for_generative/",
          "author": null,
          "description": "Recently, niji journey launched a mobile app, and there, they talked about how hard it is for people who are new to the concept of generative AI art to get started, and some of the workarounds they came up with. \n https://sizigi.notion.site/Kindling-the-Spark-of-Inspiration-d8edd06cede04401b4efba8324005cf3?pvs=4\n Thought it would be interesting to share, especially with how they try to push forward the ideas from other users as a font of knowledge kind of thing.\n    submitted by    /u/kalmatos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jzf63/p_deconstructing_interface_design_for_generative/",
          "publishedOn": "2023-10-30T17:59:14.000Z",
          "wordCount": null,
          "title": "[P] Deconstructing interface design for generative AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jyd2m/d_wer_improved_before_finetuning_whisper_but/",
          "author": null,
          "description": "Hey everyone,\n I've been working on fine-tuning Whisper using generated transcribed audio data. Before I began the fine-tuning, I evaluated the base model's accuracy on a test set, which showed:\n Test_accuracy: WER = 23.078% \n I then fine-tuned the model for 3,000 steps using a dataset of 1,000 samples: 700 for training and 300 for testing. This amounts to roughly 4 hours of data, with each audio clip being around 30 seconds in duration. However, post-fine-tuning, the WER started off at 30%, which is higher than the base model's 23.078%. Intuitively, I'd expect the WER to start lower after fine-tuning.\n Does anyone have insights or suggestions on what might be causing this discrepancy? Any advice would be greatly appreciated!\n https://preview.redd.it/b619v95rgdxb1.png?width=906&format=png&auto=webp&s=fa17f311301919ccfcd7a8cea47f47478e1cd91d\n Edit: Solved the issue.\n    submitted by    /u/stoicbats_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jyd2m/d_wer_improved_before_finetuning_whisper_but/",
          "publishedOn": "2023-10-30T17:12:03.000Z",
          "wordCount": 2658,
          "title": "[D] WER improved before Fine-Tuning Whisper, but increased afterward: Why?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jwrby/r_do_any_solutions_exist_for_this_ranking/",
          "author": null,
          "description": "Let’s say I already have a ranking method (a learning to rank approach) to sort search results (items) based on their utility to user. However, I also want to make sure certain groups of items get enough exposure across all the searches. I have defined target exposure for each group but I’m struggling to find a method that would balance utility and this exposure. Particularly because utility can be defined for a given search and item, but the group target exposure is only defined for an aggregated set of search results. Any ideas for a multi objective optimization method or even a post hoc re-ranking approach?\n    submitted by    /u/MLE-MAP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jwrby/r_do_any_solutions_exist_for_this_ranking/",
          "publishedOn": "2023-10-30T16:01:31.000Z",
          "wordCount": 2642,
          "title": "[R] Do any solutions exist for this ranking optimization problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jvcfh/from_data_architect_to_machine_learning/",
          "author": null,
          "description": "Please read, clap and follow: https://medium.com/@andysingal/from-data-architect-to-machine-learning-enthusiast-e132f6cd35fc?sk=d7d2a04a08ca7f328c4ae7ee3769ec50\n    submitted by    /u/Fit_Maintenance_2455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jvcfh/from_data_architect_to_machine_learning/",
          "publishedOn": "2023-10-30T14:59:42.000Z",
          "wordCount": null,
          "title": "From Data Architect to Machine Learning Enthusiast [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17juwj2/d_pixel_perfect_segmentation_datasets/",
          "author": null,
          "description": "Hi! Looking for any insights/direction on high-quality (near pixel-perfect) segmentation datasets for benchmarking various segmentation models in a way that others can reproduce - not sure if these exist or if anyone has specific examples they have worked with?\n Working with the usual suspects for segmentation like ADE20K and Cityscapes I have seen results using the pre-trained models on these datasets are a bit disappointing wrt high quality (clean edges, label consistency) segmentation - even models considered SOTA in 2023 like OneFormer/SegFormer/etc. Though my hypothesis is that this is largely due to the label approximations (many are drawn as rough polygons) and labeling inconsistencies building these large datasets with many classes.\n My observations and personal experience is many private companies have custom, high-quality segmentation data they have produced internally at high financial/time cost and thus are reluctant to open source and share, but hoping there are some hidden gems out there I don't yet know about...\n    submitted by    /u/FocalAIDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17juwj2/d_pixel_perfect_segmentation_datasets/",
          "publishedOn": "2023-10-30T14:39:26.000Z",
          "wordCount": 2687,
          "title": "[D] Pixel Perfect Segmentation Datasets?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17juuzl/p_predicting_velocity_vectors_with_a_cnn/",
          "author": null,
          "description": "Hi all I am, working on a project to predict velocity vectors from boundary conditions...\n  \nI have carried out a simulation of an office on Ansys\n I have x,y,z velocity vectors\n I have repeated the simulation for 100s of ac inlet and outlet velocities as input data for each set of 3D-Velocity vectors.Example of the dataset for each inlet, outlet permutation, the dataset for each permutation is around 1 million coordinates + xyz velocity vectors long.\n  \n*** I now want to predict the x,y,z velocity vectors at each location based on the AC inlet and outlet velocity ***\n How do I organise the data best for a CNN/other ANN? Any other tips of the CNN architecture?\n    submitted by    /u/No_Range3026  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17juuzl/p_predicting_velocity_vectors_with_a_cnn/",
          "publishedOn": "2023-10-30T14:37:26.000Z",
          "wordCount": 2649,
          "title": "[P] Predicting velocity vectors with a CNN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jum0r/n_fast_gpt_training_infra_fp8lm_being_64_faster/",
          "author": null,
          "description": "I just discovered the FP8-LM paper from MS: [2310.18313] FP8-LM: Training FP8 Large Language Models (arxiv.org).\n This is their repo link: Azure/MS-AMP: Microsoft Automatic Mixed Precision Library (github.com)\n paper abstraction\n My Key Takeaways:\n  \nThe whole-loop for FP8 “GPT-style” large model training is successfully done by FP8-LM team, including data cleaning, infrastructure development, model pretraining, alignment (SFT, RS, RLHF, etc.)\n Their FP8 mixed-precision training framework got 42% reduction in memory usage, and ran 64% faster than BF16 Megatron-LM; also faster than Nvidia Transformer Engine by 17%\n  \n​\n https://preview.redd.it/jeaadb1jncxb1.png?width=793&format=png&auto=webp&s=2175969217ff0ff3c8149d17b8011408f4f84c91\n It is thrilling to think about that we can scale up the already gigantic model size by 2.5x without needs for more GPU memory…and this can be achieved with NO performance degradation on a wide range of benchmarks as demonstrated in the paper. \n ​\n https://preview.redd.it/vlu6o5cnncxb1.png?width=1389&format=png&auto=webp&s=ed97ea1431f8d9a2900490812f23131681c788f8\n ​\n https://preview.redd.it/murtte9oncxb1.png?width=1289&format=png&auto=webp&s=6ebd242d69380f2bd95dcd2fa2afe18d7c4b3667\n    submitted by    /u/TensorTamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jum0r/n_fast_gpt_training_infra_fp8lm_being_64_faster/",
          "publishedOn": "2023-10-30T14:26:01.000Z",
          "wordCount": 2671,
          "title": "[N] Fast GPT Training Infra, FP8-LM, being 64% faster than BF16 on H100—Unlocking even more gigantic GPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ju1my/p_active_learning_with_domain_experts_sort_of_a/",
          "author": null,
          "description": "Hey, r/MachineLearning, it’s Dean from DagsHub 🐶\n We recently had the opportunity to work with a domain expert in creating a machine learning model and we thought we should share what we learned in the process.\n A dentist reached out to us to help him create a machine learning model, which could segment teeth in panoramic X-rays. He had some data pre-labeled, but the vast majority of his dataset was unlabeled.\n Since labeling these X-rays is a time consuming process and requires domain knowledge, we decided to use Active Learning.\n Following our success in creating an Active Learning pipeline in a Jupyter Notebook using Data Engine, we created a new Tooth Fairy project, which expands on that and brings even more capabilities into the notebook.\n https://dagshub.com/blog/active-learning-with-domain-experts-a-case-study/\n Check out our post and learn:\n  \nWhy and when you should use Active Learning\n How to efficiently work with domain experts (and mistakes to avoid!)\n What a real use-case Active Learning pipeline looks like, by checking out the accompanying repo\n  \nWe value your thoughts and feedback! Looking forward to hearing from you all!\n    submitted by    /u/PhYsIcS-GUY227  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ju1my/p_active_learning_with_domain_experts_sort_of_a/",
          "publishedOn": "2023-10-30T13:59:40.000Z",
          "wordCount": 2717,
          "title": "[P] Active Learning with Domain Experts – Sort of a case study",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jtkxr/d_semantic_search_on_different_medical_codes/",
          "author": null,
          "description": "Hi everyone,\n Need some ideas to bounce off.\n I have several medical codes, let’s name them A, B, C and D.\n Each medical code consists of multiple clauses, say, 1.1, 1.2 and so on.\n I want to create a model (?) where a text input of a textual clause will show up all other related clauses from different medical codes. For example, if I input clause 3.2 from medical A, I want the output to show up the related/similar clauses from code B, C and D.\n I have thought of using something like a Retrieval Augmented Generation for this, but anyone has any better ideas regarding this topic? Could a language model do something about this? Thanks!\n    submitted by    /u/plsendfast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jtkxr/d_semantic_search_on_different_medical_codes/",
          "publishedOn": "2023-10-30T13:37:30.000Z",
          "wordCount": 2650,
          "title": "[D] Semantic search on different medical codes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jr60k/predicting_clusters_with_regression_d/",
          "author": null,
          "description": "Hello. I have historical data of real estate. Includes attributes like price, revenue, maintenance, maintenance debt etc. I had two ideas for the data previously, to predict future real estate price and to use some clustering algorithm to put the properties into categories (good, average bad or something like that). Now I got this idea to generate clusters for any given point in time and use that history of clusters to predict migration of properties between clusters.\n I am aware of inter cluster migration estimation but that seems to be a prediction of how points shift inside a cluster with the introduction of new data points rather than a timeline of the movement of points in the cluster.\n Writing this I'm also thinking it might be possible to simply treat the history of clusters as a category to be predicted e.g. given the history of property X that is in category A the prediction is that in 6 months it's heading for cluster B. \n Does anyone have experience with similar work? Are there papers I am missing?\n Thanks in advance.\n    submitted by    /u/arachnarus96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jr60k/predicting_clusters_with_regression_d/",
          "publishedOn": "2023-10-30T11:25:32.000Z",
          "wordCount": 2709,
          "title": "Predicting clusters with regression [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jq30v/d_classification_problem_giving_me_white_hair/",
          "author": null,
          "description": "So!\n I am a ML newbie and was wondering if one of you pros can help me out on my learning journey (tool use = google colab).\n I have a csv file containing loan data where each row is a customer that applied for a loan. One of the columns is called TARGET and it shows whether the customer's loan request was approved or not. All sorts of data points are captured e.g. age, gender, salary, employment details like industry, assets, etc.\n I've done cross validation and found that GradientBasedClassifier and LGBM perform the best. Cross validation also tells me that their accuracy is between 68%-70%.\n My problem is that I SUCK at hyper param optimisation. How do you go from 68 to +80%??? Or 90%?\n For the curious ones, here is the dataset: https://drive.google.com/file/d/1IKNVstck6gnXvfGS-mVRMAE1RFrDNUgZ/view?usp=sharing\n    submitted by    /u/Critical_Ad_1205  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jq30v/d_classification_problem_giving_me_white_hair/",
          "publishedOn": "2023-10-30T10:13:30.000Z",
          "wordCount": 2668,
          "title": "[D] Classification problem giving me white hair",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jpmyi/how_to_extract_features_from_xml_of_svg_images/",
          "author": null,
          "description": "I want to create several labels for each of these images, such as no. of bedrooms, bathrooms, etc. I have a large dataset of 2000 images, each which have XML which contains text that labels each room with the ID.How do I automate the process, and create a dataset that includes all the features for the labels, so that it's ready for machine learning?\n https://svgshare.com/i/z53.svg\n    submitted by    /u/pranksbanker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jpmyi/how_to_extract_features_from_xml_of_svg_images/",
          "publishedOn": "2023-10-30T09:42:39.000Z",
          "wordCount": 2605,
          "title": "How to extract features from XML of svg images dataset to create features? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jp89x/r_the_data_provenance_initiative_a_large_scale/",
          "author": null,
          "description": "submitted by    /u/Jean-Porte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jp89x/r_the_data_provenance_initiative_a_large_scale/",
          "publishedOn": "2023-10-30T09:12:03.000Z",
          "wordCount": 2542,
          "title": "[R] The Data Provenance Initiative: A Large Scale Audit of Dataset Licensing & Attribution in AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jnrex/d_how_do_you_deal_with_llm_observability_what/",
          "author": null,
          "description": "I want to know the tools and methods you use for the observability and monitoring of your ML (LLM) performance and responses in production. \n    submitted by    /u/Ok_Cartographer5609  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jnrex/d_how_do_you_deal_with_llm_observability_what/",
          "publishedOn": "2023-10-30T07:18:17.000Z",
          "wordCount": 2564,
          "title": "[D] How do you deal with LLM observability? What tools do you guys use?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jmhzl/r_superresolution_dlss_vsr/",
          "author": null,
          "description": "Hey everyone!\n I recently delved deep into the fascinating world of Super Resolution and put together a tutorial covering both SRGAN and ESRGAN. Plus, for my fellow gamers out there, I've included a comparison between DLSS and VSR in gaming scenarios. \n For those interested in the technical details, there's also a hands-on PyTorch walk-through of ESRGAN. I put a lot of effort into making the content approachable and informative, so whether you're a newbie or a seasoned pro, there should be something for everyone!\n Check out the video here: https://youtu.be/Z0jl8YM5kzU\n Would love to get your feedback, thoughts, or any insights you might want to share! Cheers! 🍻\n Disclaimer: This video provides a broad overview of SuperResolution. NVIDIA's DLSS technology involves real-time rendering complexities that may not be fully detailed. For a deeper technical dive, we value and encourage viewers own research. We can have a separate video on DLSS as well.\n    submitted by    /u/Worldly-Inflation-92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jmhzl/r_superresolution_dlss_vsr/",
          "publishedOn": "2023-10-30T05:44:11.000Z",
          "wordCount": 2681,
          "title": "[R] SuperResolution: DLSS, VSR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jfozs/d_how_llms_are_changing_search/",
          "author": null,
          "description": "submitted by    /u/firef1y1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jfozs/d_how_llms_are_changing_search/",
          "publishedOn": "2023-10-29T23:27:25.000Z",
          "wordCount": 2543,
          "title": "[D] How LLMs are changing search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jexpg/d_which_methods_use_to_extract_specific_info_on/",
          "author": null,
          "description": "Hey people, I'm new to the AI world (been programming (python) for 4 years but never worked with AI stuff), I need to extract some specific info from documents, I'm reading about NLP and all this stuff but still figuring out which method(s) should I use to make this works, any recomendations of which methods to use?\n    submitted by    /u/luiz200411  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jexpg/d_which_methods_use_to_extract_specific_info_on/",
          "publishedOn": "2023-10-29T22:50:46.000Z",
          "wordCount": 2594,
          "title": "[D] Which methods use to extract specific info on unstructured text?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jeeqz/d_types_of_svms/",
          "author": null,
          "description": "I am confused! I am trying to list all the types of SVMs but every website says different things! Could you help me and list all the SVMs types with the reference? Thank you\n    submitted by    /u/_LadyBee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jeeqz/d_types_of_svms/",
          "publishedOn": "2023-10-29T22:25:54.000Z",
          "wordCount": 2564,
          "title": "[D] Types of SVMs!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17je4f6/p_need_advise_on_creating_a_conversational/",
          "author": null,
          "description": "Hey everyone! I need some advise on creating a conversational chatbot for my University as my Final Year Project (FYP).\n 2024 will be last year for my BSCS degree and we have to build an application or something in the last year. So, I thought of creating a chatbot (just like GPT) to help students (who have admission queries). Most of the time, students or parents will have to call University for various questions and then they have to wait to ACTUALLY talk to the admins office people.\n Now, talking in terms of coding/programming, I have created a basic PDFbot by using LLama2, Huggingface and Pinecone. Its very very easy and yes its fairly inaccurate too. The PDF that I am using rn will be replaced by the dataset that I gather in order to create the bot for my Uni, but it will also be inac…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17je4f6/p_need_advise_on_creating_a_conversational/",
          "publishedOn": "2023-10-29T22:12:38.000Z",
          "wordCount": 2953,
          "title": "[P] Need advise on creating a conversational Chatbot for my University",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17jaep4/r_is_it_possible_to_implement_generative_ai/",
          "author": null,
          "description": "I would like to understand if anyone has implemented generative AI without using openAI and if so which open source you have used and how successful it has been so far\n We have enterprise level incident data, relevant documentation etc that users will search about and need to generate responses using generative ai.\n Is it possible to do this without relying on open AI at all\n    submitted by    /u/leaderof13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17jaep4/r_is_it_possible_to_implement_generative_ai/",
          "publishedOn": "2023-10-29T19:23:42.000Z",
          "wordCount": 2605,
          "title": "[R] Is it possible to implement generative ai successfully without relying on openAI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ja10p/p_ros_forecasting_project/",
          "author": null,
          "description": "I have been tasked with predicting the demand for products over the course of the next 12 months for a b2c furniture business in-order to help with stock management. I currently just work as a Data Analyst but looking to move into data science so my thought is to make this a valuable piece of work that helps the business tremendously (maybe being a little naive). \n Background: There are 1.3k unique products, which all vary in popularity (quantity is small 0-16 units per month, per product). We have procured which have been selling for 5 years and some that have been selling for 6 months as well as some that have yet to start selling. All the data sits within snowflake and I am currently using snowpark and snow.ml to write the code.\n I have round 2 months to complete this work and have a decent understanding of machine learning and statistics.\n My current idea is to use 3 different models. Time series for the products that have > 12 months of sales data. Cold start approach for new products with > 3 months sales data (use features of other products to predict demand of the new product). Then use a combination of both for products which have less than 12 months of sales data but more than 3.\n My questions:\n Should I be bootstrapping my data given that I have little quantity in some cases? How do I go about training a model for 1.3k unique SKUs (needs to be re-trained monthly) and monitored. Am I on the right lines / anything I need to be aware of?\n    submitted by    /u/Environmental_Pop686  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ja10p/p_ros_forecasting_project/",
          "publishedOn": "2023-10-29T19:06:24.000Z",
          "wordCount": 2799,
          "title": "[P] ROS Forecasting project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17j8a7h/decapodaresearch_llama_models_removed_from/",
          "author": null,
          "description": "Is anyone else no longer able to access the standard `decapoda-research` LLaMA models on HuggingFace? E.g., this [link] shows no models publicly available. Has there been any news or announcements about this? \n    submitted by    /u/bodierex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17j8a7h/decapodaresearch_llama_models_removed_from/",
          "publishedOn": "2023-10-29T17:46:44.000Z",
          "wordCount": 2565,
          "title": "decapoda-research llama models removed from HuggingFace? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17j6kid/d_ml_resources/",
          "author": null,
          "description": "Hey y'all. Hope everyone is having pleasant day. Machine Learning dummy is here, so I am bachelor graduate of Mechatronics and recently started my masters. I am in need of resources which explains ML from the stratch. Course is mostly focuses on manually hand calculation of the topics, so no programming included. Thanks beforehand!\n    submitted by    /u/Sama_Uzeyirli  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17j6kid/d_ml_resources/",
          "publishedOn": "2023-10-29T16:26:46.000Z",
          "wordCount": 2583,
          "title": "[D] ML Resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17j5s78/d_lora_multiadapter_support_are_there_any/",
          "author": null,
          "description": "Hi everyone.\n Stacking multiple Lora adapters coming from diverse fine-tunings seems like an interesting approach toward \"modular\" language models. Does anybody know any applications for this? E.g. I'd expect to be able to apply multiple adapters for different domains, languages, or tasks. Not sure if this would really work tough, as IDK how compositional such an approach can be.\n ​\n From the peft github I see this seems quite common for vision tasks\n GitHub - huggingface/peft: 🤗 PEFT: State-of-the-art Parameter-Efficient Fine-Tuning. \n    submitted by    /u/BenXavier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17j5s78/d_lora_multiadapter_support_are_there_any/",
          "publishedOn": "2023-10-29T15:49:47.000Z",
          "wordCount": 2618,
          "title": "[D] Lora multiadapter support: are there any relevant examples for Language Models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17j5e45/discussion_please_help_me_find_a_topic/",
          "author": null,
          "description": "Hello everyone,\n As a last resort, I wanted to ask you.\n In short, I am a student in Turkey. The scientific research board in my country has an incentive to write a research paper and I would like to participate in this incentive. I am looking for a data set on which I can apply machine learning, but I could not find it. I don't want to apply with an unoriginal topic like stock price prediction. Energy water etc. The data is not shared openly, even the official institution that shares the weather forecast in my country sells past data. Unfortunately, I can say that we are just one click ahead of Russia in terms of data sharing by public institutions.\n I know there are some institution that shares data (world bank, UN etc.) but i don't know what kind of a prediction/classification work i can do with those datasets. Finance institution share data but i don't have sufficient knowledge about finance and I don't think I can create original content about finance.\n I need a real-life data, and it also needs to be a freely shared data set. And there should be a study within the framework of UN SDG. I don't have a lot of time left so I'm open to any suggestions.\n    submitted by    /u/FisekFaruk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17j5e45/discussion_please_help_me_find_a_topic/",
          "publishedOn": "2023-10-29T15:31:08.000Z",
          "wordCount": 2747,
          "title": "[Discussion] Please help me find a topic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17j5204/p_equinox_compilation_retnet/",
          "author": null,
          "description": "I'm working on replicating the retnet model in Equinox + Jax. For the model there are 2 representations: parallel and recurrent (ignoring chunkwise). They use the recurrent at inference and parallel at training. In equinox, should i build 2 seperate models for each representation sharing parameters or build one with if statements. The reason I'm asking is if I use one model with if statements for inference and training, will the model re-compile whenever switching between representations or not? If so then wouldn't building 2 models each compiled originally with their representation make it faster.\n Sorry if I said anything stupid as I don't know too much about the compilation process behind the scenes.\n    submitted by    /u/Additional-Ad-7043  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17j5204/p_equinox_compilation_retnet/",
          "publishedOn": "2023-10-29T15:15:16.000Z",
          "wordCount": 2644,
          "title": "[P] Equinox compilation retnet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17j4ibg/r_pubdef_defending_against_transfer_attacks_using/",
          "author": null,
          "description": "Adversarial attacks pose a serious threat to ML models. But most proposed defenses hurt performance on clean data too much to be practical.\n To address this, researchers from UC Berkeley developed a new defense called PubDef. It focuses on defending against a very plausible type of attack - transfer attacks using publicly available surrogate models.\n They model the attack/defense game with game theory. This lets PubDef train against diverse attacks simultaneously.\n PubDef picks source models covering different training methods - standard, adversarial, corruption robust, etc. This gives broad coverage.\n Against 264 transfer attacks on CIFAR and ImageNet, PubDef smashed previous defenses:\n  \n89% vs 69% on CIFAR-10\n 51% vs 33% on CIFAR-100\n 62% vs 36% on ImageNet\n  \nEven better - it did this with minimal drop in accuracy on clean data. \n  \nOn CIFAR-10, accuracy only dropped from 96.3% to 96.1%\n On CIFAR-100, 82% to 76%\n On ImageNet, 80% to 79%\n  \nBy targeting a very real threat, PubDef made big robustness gains without hurting the ability to work with clean data.\n TLDR: New defense PubDef achieves much higher robustness against transfer attacks with barely any drop in standard accuracy.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17j4ibg/r_pubdef_defending_against_transfer_attacks_using/",
          "publishedOn": "2023-10-29T14:49:28.000Z",
          "wordCount": 2728,
          "title": "[R] PubDef: Defending Against Transfer Attacks Using Public Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17j4cmh/d_fuyu8b_a_multimodal_architecture_for_ai_agents/",
          "author": null,
          "description": "submitted by    /u/notllmchatbot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17j4cmh/d_fuyu8b_a_multimodal_architecture_for_ai_agents/",
          "publishedOn": "2023-10-29T14:41:48.000Z",
          "wordCount": 2545,
          "title": "[D] Fuyu-8B: A Multimodal Architecture for AI Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17j376q/d_how_to_make_llama2_create_mindmaps_from_large/",
          "author": null,
          "description": "So this is three subtasks:\n  \nSubdivide text intelligently into chunks fitting into the context length to not semantically cut off text.\n Find general terms und organize the corpus in a hierarchy.\n Do not leave anything out.\n  \n   submitted by    /u/SecretOk9644  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17j376q/d_how_to_make_llama2_create_mindmaps_from_large/",
          "publishedOn": "2023-10-29T13:42:22.000Z",
          "wordCount": 2577,
          "title": "[D] How to make Llama2 create Mindmaps from large corpora bigger than its context length?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17j32ac/d_finetuning_with_peft_for_domain_adaptation/",
          "author": null,
          "description": "Coming from a time-series/CV background with an interest in NLP. So apologies if miss anything obvious. \n I'm after experiment ideas for PEFT fine-tuning. There has been interest from my Company's leadership with Peft methods given the cost reductions compared to full fine-tuning, and I've been tasked to first set-up the infrastructure and then a proof of value on a dummy use-case (that is somewhat related to real-world use-cases but on publicly available data). \n has anyone successfully proven that fine-tuning or P-tuning or prompt-tuning has been able to help in any small dummy use-case? Has someone been able to turn a company's knowledge base (heaps of confluence docs or PDF docs ) into a data-set that is able to be fine-tuned on? And then use it in inference on a Val set to compare with a non-fine-tuned model and value has been added? \n If so, I would love to hear how you did it and what the use case was. If not, i' d still like to hear what people's ideas would be. I want to start with 100 training samples - i've been told this should be enough to see an improvement if the scope of the topic/s are confined appropiralte.y \n Thanks in advance guys - The deadline is imminent and I'll probbaly get someothing out in time, but I thought I would ask you all for some ideas to maximise the chance of success\n    submitted by    /u/joedang33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17j32ac/d_finetuning_with_peft_for_domain_adaptation/",
          "publishedOn": "2023-10-29T13:35:00.000Z",
          "wordCount": 2782,
          "title": "[D] Fine-Tuning with PEFT For Domain Adaptation - Request for Example Use Case / Dummy Projects to Show Value to Business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17j1vx6/n_leveraging_oracle_tribuo_for_advanced_anomaly/",
          "author": null,
          "description": "https://www.resoluteitconsulting.com/2023/10/29/tribuo-advanced-anomaly-detection/\n    submitted by    /u/yazidaqel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17j1vx6/n_leveraging_oracle_tribuo_for_advanced_anomaly/",
          "publishedOn": "2023-10-29T12:28:23.000Z",
          "wordCount": 2539,
          "title": "[N] Leveraging Oracle Tribuo for Advanced Anomaly Detection: Uncovering the Hidden Insights",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17izjsu/d_sentiment_analysis_for_conversation_with/",
          "author": null,
          "description": "I am trying to build a system that evaluates the tone of two users for each sentence from a transcript. The users are talking to each other however there are different labels for classification for these users.\n For Example,\n User1 tone should be classified as (Happy, Sad, Angry)\n User2 tone should be classified as (Neglecting, Participating, Neutral)\n Any idea how can I go about designing such a system? Links to articles/blogs/papers are welcome :)\n ----------\n What User2 says depends on what User1 says and vice-vera. Will this system require two models to classify each users tone separately? If so, how can I tell the model which user to focus on etc\n    submitted by    /u/cryto_dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17izjsu/d_sentiment_analysis_for_conversation_with/",
          "publishedOn": "2023-10-29T09:47:48.000Z",
          "wordCount": 2645,
          "title": "[D] Sentiment Analysis for Conversation with different labels",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17iz8i1/r_what_infrastructure_do_you_use_to_train_big_llms/",
          "author": null,
          "description": "I come from computer vision tasks with convnets that are relatively small in size and parameters, yet performing quite well (e.g. ResNet family, YOLO, etc.).\n Now I am approaching some NLP and architectures based on transformers tend to be huge, so that I have problems to fit them in memory.\n What infrastructure you use to train these model (GPT2, BERT or even the bigger ones)? cloud computing, HPC, etc.\n    submitted by    /u/TimeInterview5482  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17iz8i1/r_what_infrastructure_do_you_use_to_train_big_llms/",
          "publishedOn": "2023-10-29T09:24:44.000Z",
          "wordCount": 2605,
          "title": "[R] What infrastructure do you use to train big LLMs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17iy20t/d_finetuning_llm_specifically_for_openbook/",
          "author": null,
          "description": "I am working on some Open-Book question answering ideas and was wondering if there is any open-source large language models specifically trained for this use-case or research regarding how to best finetune models for this specific use-case?\n For some reason I am struggling to find anything relevant, and believe it is due to my wording of search queries as I can only imagine this to be a pretty common idea/thought process.\n If you have a dataset consiting of some context string paired with question and answer pairs taken from this given context, would it not be useful to finetune a pre-trained base model on this specific use-case to increase its accuracy/performance when it comes to answering questions from a given context?\n My hope would be to improve the performance of a smaller model (1-3B parameters) to function as an open-book question answering system by finetuning using a dataset in the aforementioned format.\n    submitted by    /u/kotschi1997  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17iy20t/d_finetuning_llm_specifically_for_openbook/",
          "publishedOn": "2023-10-29T07:55:17.000Z",
          "wordCount": 2693,
          "title": "[D] Finetuning LLM Specifically for Open-Book Question Answering - Looking for Research Papers/Open Source Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17itqs0/d_what_are_people_working_on_when_they_say_they/",
          "author": null,
          "description": "Genuinely trying to understand.\n    submitted by    /u/poitrenaud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17itqs0/d_what_are_people_working_on_when_they_say_they/",
          "publishedOn": "2023-10-29T02:53:55.000Z",
          "wordCount": 2544,
          "title": "[D] What are people working on when they say they work on Causal ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17iqd1k/d_batch_sizes_per_gpu_when_fine_tuning_bert_with/",
          "author": null,
          "description": "Hi! I've read that batch sizes don't ultimately \"matter\" in hyperparameter tuning, so I'm trying to keep the batch size consistent when as I'm hyperparamter tuning [1]. However, the number of available GPUs fluctuate between 1 and 3. When I first started grid search, I used batch_size=64 w/ 2 GPUs. so that's 32 per batch. But if I now want to train on 1 GPU, would it be correct for me to use batch_size=32?\n I want to know more about how the training works/is distributed amongst GPUs when you use multiple GPUs to tain. Like, if using size=64 with 2 GPUs is \"equivalent\" to doing size=32 with 1 GPU, and size=96 with 3 GPUs, that must mean that when pytorch DataLoader takes in batch_size, DataLoader distributes batches to each GPU of size=batch_size/num_of_gpus.\n I would so appreciate any links explaining this stuff. Like, does the batch_size in DataLoader() refer to per GPU batch size or total? also lmk if this post belongs elsewhere, i'm new.\n from torch.utils.data import Dataset, DataLoader train_dataset = Dataset(args.train_dataset_path) train_dataloader = DataLoader(train_dataset, args.batch_size, shuffle=True) \n [1] https://github.com/google-research/tuning_playbook\n    submitted by    /u/ashleydvh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17iqd1k/d_batch_sizes_per_gpu_when_fine_tuning_bert_with/",
          "publishedOn": "2023-10-28T23:45:54.000Z",
          "wordCount": 2716,
          "title": "[D] Batch sizes per GPU when fine tuning BERT with pytorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ipuei/p_follow_our_live_pitch_recommendation_feed_while/",
          "author": null,
          "description": "submitted by    /u/futurecy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ipuei/p_follow_our_live_pitch_recommendation_feed_while/",
          "publishedOn": "2023-10-28T23:19:29.000Z",
          "wordCount": 2561,
          "title": "[P] Follow our live pitch recommendation feed while watching the World Series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ipqdj/p_anomaly_detection_andor_predictive_maintenance/",
          "author": null,
          "description": "Anomaly Detection and/or Predictive maintenance for automatic weather stations, what are some best models or techniques? \n This is regarding collected meteorological data from automatic weather station sensors. \n Looking for predictive maintenance and anomaly detection resources related to my project. \n I am a graduating Computer Engineering student by next semester and currently planning to do a anomaly detection and predictive maintenance project of an automatic weather station or its components (I have a relative who has one and also one that works at a local government weather service). \n Wikipedia: \"An automatic weather station (AWS) is an automated version of the traditional weather station, either to save human labor or to enable measurements from remote areas.[1] An AWS will typically consist of a weather-proof enclosure containing the data logger, rechargeable battery, telemetry (optional) and the meteorological sensors with an attached solar panel or wind turbine and mounted upon a mast.\"\n This one observes weather data at a high resolution (every 10 mins) but it is prone to errors and inconsistencies as compared to those manned stations. \n Does anyone know reliable researches, datasets or resources I could utilize? Probably those related to a meteorological equipment or those that capture things such as temperature, wind speed, humidity, etc.? I can't seem to find studies where they perform prediction of equipment/sensor health or predictive maintenance on a weather station, or at least the components or sensors used for capturing weather data. \n Also, is this a feasible project?\n    submitted by    /u/Ok-Way9889  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ipqdj/p_anomaly_detection_andor_predictive_maintenance/",
          "publishedOn": "2023-10-28T23:13:35.000Z",
          "wordCount": 2785,
          "title": "[P] Anomaly detection and/or predictive maintenance for automatic weather stations, what are some best models or techniques?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17imlu9/r_the_language_of_artificial_intelligence/",
          "author": null,
          "description": "submitted by    /u/plutoandmal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17imlu9/r_the_language_of_artificial_intelligence/",
          "publishedOn": "2023-10-28T20:41:51.000Z",
          "wordCount": 2525,
          "title": "[R] The Language of Artificial Intelligence Explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17imk8j/geometric_data_analysis_explained_r/",
          "author": null,
          "description": "submitted by    /u/plutoandmal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17imk8j/geometric_data_analysis_explained_r/",
          "publishedOn": "2023-10-28T20:39:43.000Z",
          "wordCount": 2529,
          "title": "Geometric Data Analysis Explained [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17iki7i/d_need_some_advice_for_mixing_semi_active/",
          "author": null,
          "description": "Hi.\n I'm trying to use GANs to generate data for an image classification task. For this I'm using StyleGAN2.\n The question I'm trying to find an answer is, how to train the classifier and GAN in a same meta-loop, and how to discard \"bad\" GAN samples, samples that provide no value to the CNN classifier.\n All in all, I'm trying to implement a \"semi-active learning\" pipeline, but get rid of the oracle by using GANs. So instead of trying to discard data that is not worth labelling, I'm trying to discard syntethic data (assuming its label is right) that is not worth keeping.\n Is it possible? And if it is, I can't seem to find related papers that much.\n    submitted by    /u/PsychologicalSet8678  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17iki7i/d_need_some_advice_for_mixing_semi_active/",
          "publishedOn": "2023-10-28T18:59:43.000Z",
          "wordCount": 2656,
          "title": "[D] Need some advice for mixing (semi) active learning and GAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ikh2u/r_model_troubles/",
          "author": null,
          "description": "So i’m working on a model that diagnoses alzheimer’s disease and suggests medication depending on how severe the symptoms might have become I’m using the Openai API and Langchain.\n But it’s dumb and it doesn’t learn ( Me: I forgot my keys at home Model: Yup, Alzheimer’s) How do i incorporate the actual machine learning\n    submitted by    /u/boscrew3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ikh2u/r_model_troubles/",
          "publishedOn": "2023-10-28T18:58:07.000Z",
          "wordCount": 2584,
          "title": "[R] Model Troubles",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17iihlg/d_latent_space_visualizing_and_manipulating/",
          "author": null,
          "description": "submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17iihlg/d_latent_space_visualizing_and_manipulating/",
          "publishedOn": "2023-10-28T17:22:20.000Z",
          "wordCount": 2532,
          "title": "[D] Latent Space: Visualizing and Manipulating generative VAEs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ih711/dthree_things_i_think_should_get_more_attention/",
          "author": null,
          "description": "Tokenization Techniques: Many people use the default BPE tokenizer for llama2 or other common tokenizers. But I think we could do a lot of experiments with different kinds of tokenizers, especially ones that are made to work well with certain types of data. The size of the vocabulary is a really important setting when you're working with big language models. You could try using a much smaller vocabulary and tokenizer for a data set that only includes certain words, and then train a model on that. This might help us train smaller models that still work really well on smaller amounts of data. I’d love to read any research papers about this.\n Sampling Mechanisms: There’s a lot of discussion about models making things up, but not many people talk about how this could be connected to the way we pick the next word when generating text. Most of the time, we treat the model's output like a set of probabilities, and we randomly pick the next word based on these probabilities. But this doesn’t always make sense, especially for sentences that should have a clear answer. For example, if the sentence starts with \"The capital of Slovakia is\", random sampling might give you the wrong answer, even though the model knows that \"Bratislava\" is the most likely correct answer. This way of picking words randomly could lead to the model making things up. I wonder if we could create another model to help decide how to pick the next word, or if there are better ways to do this sampling.\n Softmax Alternatives in Neural Networks: I've worked on designing processors for neural networks, and I’ve found that the softmax function is tricky to implement in hardware. However, I’ve had good results using the log(exp(x)+1) function instead. It's cheaper and easier to put into hardware and software. I’ve tried this with smaller GPT models, and the results looked just as good as when I used the softmax function.\n  \n   submitted by    /u/ExaminationNo8522  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ih711/dthree_things_i_think_should_get_more_attention/",
          "publishedOn": "2023-10-28T16:19:13.000Z",
          "wordCount": 2865,
          "title": "[D]Three things I think should get more attention in large language models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ih6uf/p_help_debugging_a_cnn_gan/",
          "author": null,
          "description": "I've been learning machine learning and I stumbled across GANs. This project has been about representing text in an image format and using a GAN to generate it. The model runs without errors, but no matter what I do the loss is somehow 0 and it keeps returning the same thing over and over again. I tried two different architectures so I'm pretty sure my data preprocessing is the issue but I cant seem to find out whats wrong with it.\n One idea I had is that I might need to find a way to get the normalized vectors in between 0 and 1 in my preprocess function but I tried it and it didn't seem to do anything.\n I would appreciate any help with this. Links to the google collabs below.\n Version 1\n Version 2\n Note: I didn't design the actual models only the preprocess function. You can replace my text file with any sufficiently large text file if you want to try it.\n    submitted by    /u/Divine_Invictus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ih6uf/p_help_debugging_a_cnn_gan/",
          "publishedOn": "2023-10-28T16:18:59.000Z",
          "wordCount": 2697,
          "title": "[P] Help Debugging a CNN GAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17iglef/arxiv_dives_finetuning_with_lora_paper_deep_dive/",
          "author": null,
          "description": "submitted by    /u/FallMindless3563  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17iglef/arxiv_dives_finetuning_with_lora_paper_deep_dive/",
          "publishedOn": "2023-10-28T15:50:24.000Z",
          "wordCount": 2546,
          "title": "A[r]xiv Dives - Fine-tuning with LoRA paper deep dive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ig870/urgent_help_needed_regarding_inltk_p/",
          "author": null,
          "description": "Hello i m using iNLTK ( Natural Language Toolkit for Indic Languag ) for my nlp mini project \"paraphrase detection in hindi text\" but I m getting this code error if anyone can help me solving it would be great. Thank you in advance.\n here is the code for the error section.\n from inltk.inltk import get_sentence_similarityfrom sklearn.metrics.pairwise import cosine_similarityget_sentence_similarity(text, 3, 'hi', cmp = cosine_similarity)\n I googled there are solution saying to install pytorch version 1.3.0 but when I try to install it's saying not available.\n !pip install torch==1.3.1+cpu -f https://download.pytorch.org/whl/torch_stable.html.\n error :\n Looking in links: https://download.pytorch.org/whl/torch_stable.html. ERROR: Could not find a version that satisfies the requirement torch==1.3.1+cpu (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0) ERROR: No matching distribution found for torch==1.3.1+cpu\n    submitted by    /u/delulu-duck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ig870/urgent_help_needed_regarding_inltk_p/",
          "publishedOn": "2023-10-28T15:32:28.000Z",
          "wordCount": 2650,
          "title": "Urgent help needed regarding iNLTK [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17if0lm/r_hyperfields_towards_zeroshot_nerfs_from_text/",
          "author": null,
          "description": "Generating 3D objects based solely on text descriptions has proven extremely challenging for AI. Current state-of-the-art methods require optimizing a full 3D model from scratch for each new prompt, which is computationally demanding.\n A new technique called HyperFields demonstrates promising progress in generating detailed 3D models directly from text prompts, without slow optimization.\n The HyperFields approach instead aims to learn a generalized mapping from language to 3D geometry representations. This would allow tailored 3D models to be produced for new text prompts efficiently in a single feedforward pass, without slow optimization.\n HyperFields combines two key techniques:\n  \nA dynamic hypernetwork that takes in text and progressively predicts weights for a separate 3D generation network. The weight predictions are conditioned on previous layer activations, enabling specialization.\n Distilling individually optimized 3D networks into the hypernetwork, providing dense supervision for learning the complex text-to-3D mapping.\n  \nIn experiments, HyperFields exceeded previous state-of-the-art methods in sample efficiency and wall-clock convergence time by 5-10x. It demonstrated the ability to:\n  \nEncode over 100 distinct objects like \"yellow vase\" in a single model\n Generalize to new text combinations without seeing that exact prompt before\n Rapidly adapt to generate completely novel objects with minimal fine-tuning\n  \nHowever, limitations remain around flexibility, fine-grained details, and reliance on existing 2D guidance systems.\n TL;DR: HyperFields uses a dynamic hypernetwork to predict weights for a 3D generation network. The method is 5-10x faster than existing techniques and can quickly adapt to new text prompts, but has limitations in fine details.\n Full summary is here. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17if0lm/r_hyperfields_towards_zeroshot_nerfs_from_text/",
          "publishedOn": "2023-10-28T14:32:26.000Z",
          "wordCount": 2785,
          "title": "[R] HyperFields: towards zero-shot NeRFs from text descriptions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ics73/p_can_you_explain_to_me_how_to_improve_my_project/",
          "author": null,
          "description": "Hi,\n so I'm new to machine learning, I did a project to predict the prices of a house or appartment (rent or sale) and I wanted to know what I could have done to improve my model? :D\n here is the github repo:\n https://github.com/bovealexandre/immo-eliza-train-test-alexandre/tree/Dev\n Thank you a lot in advance\n    submitted by    /u/spaceinter92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ics73/p_can_you_explain_to_me_how_to_improve_my_project/",
          "publishedOn": "2023-10-28T12:31:00.000Z",
          "wordCount": 2584,
          "title": "[P] Can you explain to me how to improve my project? (new to machine learning)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ica54/discussionabout_to_begin_my_phd_in_multimodality/",
          "author": null,
          "description": "I am currently in my last year of undergrad, and about to begin my direct PhD in Multi-Modality AI next year. I have been in the community of deep learning & NLP about 2 years. And I have witnessed the development of Transformers, from the simple GPT&BERT to nowadays' billions of parameters' monsters with 'gold crown' on the top of deep learning world.\n I have spent a lot of time with T5 Model, and its paper(Exploring the Limits of Transfer Learning with a Uniﬁed Text-to-Text Transformer, paper which I love very much!), trying to find an efficient way for usage of LLMs. I have handwritten Adapter Layer and LoRA to fine-tune T5 on Glue & SuperGlue. I have also tried out multiple fancy instruction fine-tuning LLMs like LLaMA and QWen.\n And this year earlier, I have noticed the wonder of Multi-Modality, and quickly fallen in love with it, which has now become my PhD focus. I have followed recent years' Multi-Modality development, especially CLIP and its follow-up works. And LLMs play quite an important role in today's vision-language model, say, BLIP2 and LLaVA.\n I believe due to the computational gap between schools and huge companies, the focus of my PhD career should be on Efficient Learning. I am also trying to enhance VLM through Retrieval-Augments. The target dataset may be Encyclopedic VQA, for even Large VLM failed to perform well on it, which could potentially be solved through Retrieval-Augmented VLM.\n I would like to hear any suggestions from you, including work-life balance, the direction of my academic focus and so on , which I would treasure very much in my new explorations of life stage. (I am currently doing RAG Question Answering Chat Bot for a company for my internship, and I would like to get suggestions from that too!)\n And are there subreddits like here?(I am also a member of LocalLLaMA, both subreddits benefits me a lot!)\n    submitted by    /u/Go2Heart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ica54/discussionabout_to_begin_my_phd_in_multimodality/",
          "publishedOn": "2023-10-28T12:01:01.000Z",
          "wordCount": 2854,
          "title": "[Discussion]About to begin my PhD in Multi-Modality AI, any suggestions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17i8kid/d_nlp_infrastructure/",
          "author": null,
          "description": "I'm always willing to build a career in AI/ML infra. Usually when talking about AI infra in tech industry, we refer to training infra, serving infra, model deployment etc.\n Now with this genAI/LLM wave, I find many NLP specific infrastructure such as semantic indexing, vector databases are quickly rising up. So do semantic indexing/vector databases also count as AI infra? And is it a promising field? \n    submitted by    /u/Pitiful_Marketing733  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17i8kid/d_nlp_infrastructure/",
          "publishedOn": "2023-10-28T07:30:59.000Z",
          "wordCount": 2595,
          "title": "[D] NLP infrastructure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17i7k12/drwhat_type_of_data_streamsim2col_matrix_or/",
          "author": null,
          "description": "(I post this in several subreddit.) I'm gonna design an NN accelerator on FPGA. For NN, the basic operation is matrix-vector mult or matrix-matrix mult. And GEMM+im2col is easy to implement and many kinds of NN can be mapped on the designed accelerator based on GEMM+im2col easily. The disadvantage of it is that a little bit more bandwidth is required. I think it is a little tricky to design address-gen unit for the method of regular convolution when reading input feature map.\n So I want to know if GEMM+im2col is generally used in commercial NPUs or any type of accelerator(e.g. Microsoft Brainwave project on FPGA, they called it soft NPU), instead of regular convolution(seems generally used in academic paper). And if GEMM+im2col data stream is used, is im2col generally implemented on software(CPU) or designed in accelerator itself ? There is nothing about this in the paper of Microsoft Brainwave. All I know is HUAWEI Ascend designed im2col unit in the chip.\n By the way, is im2col finished on CPU when using pytorch+GPU? To be honest, my major is just digital IC, so I hardly coding Python to train model :(\n Thanks for your help!!!\n    submitted by    /u/ExcitingInternet6083  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17i7k12/drwhat_type_of_data_streamsim2col_matrix_or/",
          "publishedOn": "2023-10-28T06:17:19.000Z",
          "wordCount": 2752,
          "title": "[D][R]What type of data streams(`im2col` matrix or regular conv) do commercial NPUs typically use for CNN? And where are `im2col` implemented, softwave(CPU) or HW accelerator for those situations where `im2col` is required？",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17i3lpa/project_llm_inference_with_vllm_and_amd_achieving/",
          "author": null,
          "description": "I wanted to share some exciting news from the GPU world that could potentially change the game for LLM inference. AMD has been making significant strides in LLM inference, thanks to the porting of vLLM to ROCm 5.6. You can find the code implementation on GitHub.\n The result? AMD's MI210 now almost matches Nvidia's A100 in LLM inference performance. This is a significant development, as it could make AMD a more viable option for LLM inference tasks, which traditionally have been dominated by Nvidia.\n For those interested in the technical details, I recommend checking out this EmbeddedLLM Blog Post.\n I'm curious to hear your thoughts on this. Anyone manage to run it on RX 7900 XTX?\n https://preview.redd.it/rn7n29yxpuwb1.png?width=600&format=png&auto=webp&s=bdbac0d2b34d6f43a03503bbf72b446190248789\n    submitted by    /u/openssp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17i3lpa/project_llm_inference_with_vllm_and_amd_achieving/",
          "publishedOn": "2023-10-28T02:06:53.000Z",
          "wordCount": 2655,
          "title": "[Project] LLM inference with vLLM and AMD: Achieving LLM inference parity with Nvidia",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hz4n2/r_emnlp_2023_fast_and_accurate_factual/",
          "author": null,
          "description": "TL;DR: Our new paper presents SCALE, a technique that improves hallucination detection capabilities of pre-trained models over short and long documents with no fine-tuning necessary by evaluating hypotheses against large chunks of text as opposed to the traditional sentence-by-sentence approach. Furthermore, we introduce ScreenEval — the most extensive dialogue-based dataset for factual inconsistency detection on long documents to date.\n https://preview.redd.it/ihqok954ntwb1.png?width=1964&format=png&auto=webp&s=70dbce6f913b2909b7d170959077c1fe19791c42\n Title: Fast and Accurate Factual Inconsistency Detection Over Long Documents\n Installation: pip install scale-score\n Paper: https://arxiv.org/abs/2310.13189\n Code: https://github.com/asappresearch/scale-score\n Abstract: Generative AI models…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hz4n2/r_emnlp_2023_fast_and_accurate_factual/",
          "publishedOn": "2023-10-27T22:19:17.000Z",
          "wordCount": 2795,
          "title": "[R] EMNLP 2023: Fast and Accurate Factual Inconsistency Detection Over Long Documents IMPROVES Pre-Trained Model's Hallucination Detection Capabilities With No Fine-Tuning Necessary",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hyv06/p_image_classification_for_product_images/",
          "author": null,
          "description": "Say you are a potato chips company. The goal is to have consumers upload images of the product they are having issues with and be able to identify the product by brand/variant using machine learning. Consumers can upload real product photos that they have taken, or upload bogus images from the internet, or even upload completely irrelevant/inappropriate photos (like that of a dog or cat). \n ​\n real image\n ​\n web image 1\n ​\n web image 2\n ​\n bogus image\n In this example, for the legitimate image, the goal is to classify it as \"Lays Classic\". There might be products that are not in bag form, such as those in tubes. Furthermore, the images taken can be in different lighting conditions/orientations. Some images might have other products as well.\n I have been out of the ML field for the past 4 years so I'm not up to date on the most state of the art methods for this problem. I have studied CNNs 4 years ago, but there has been advances like transformer based methods. Someone has tried ResNet-50 and YOLOv5, and I'm thinking about using a pretrained model like CLIP and just train the final classification layer.\n But I would appreciate to hear from someone more well versed what recommended approach to take as far as model/labeling/number of images needed per class, etc. It might be that I would need multiple models, such as one to identify the legitimate images from the rest, and then another one to identify the product/variants.\n Any advice would be welcome. Thanks\n    submitted by    /u/EyeTechnical7643  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hyv06/p_image_classification_for_product_images/",
          "publishedOn": "2023-10-27T22:06:35.000Z",
          "wordCount": 2785,
          "title": "[P] image classification for product images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hy6lj/r_convnets_match_vision_transformers_at_scale/",
          "author": null,
          "description": "PAPER: https://arxiv.org/abs/2310.16764\n SUMMARY\n The paper \"ConvNets Match Vision Transformers at Scale\" from Google DeepMind aims to debunk the prevalent notion that Vision Transformers (ViTs) are inherently superior to ConvNets for large-scale image classification. Using the NFNet model family as a representative ConvNet architecture, the authors pre-train various models on the extensive JFT-4B dataset under different compute budgets, ranging from 0.4k to 110k TPU-v4 core hours. Through this empirical analysis, they observe a log-log scaling law between held-out loss and compute budget. Importantly, when these NFNets are fine-tuned on ImageNet, they match the performance metrics of ViTs trained under comparable computational constraints. Their most resource-intensive model even achieves a Top-1 ImageNet accuracy of 90.4%.\n The crux of the paper's argument is that the supposed performance gap between ConvNets and ViTs largely vanishes under a fair comparison, which accounts for compute and data scale. In other words, the efficacy of a machine learning model in large-scale image classification is more dependent on the available data and computational resources than on the choice between ConvNet and Vision Transformer architectures. This challenges the community's leaning towards ViTs and emphasizes the importance of equitable benchmarking when evaluating different neural network architectures.\n    submitted by    /u/psyyduck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hy6lj/r_convnets_match_vision_transformers_at_scale/",
          "publishedOn": "2023-10-27T21:36:16.000Z",
          "wordCount": 2729,
          "title": "[R] ConvNets Match Vision Transformers at Scale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hx81a/d_seeking_advice_on_using_hugging_face_for/",
          "author": null,
          "description": "Hello, I'm making my first post here, and I'm hoping to tap into the collective wisdom of this platform. I have a background in Machine Learning (ML) with a good grasp of the underlying mathematics, and I've taken several related courses during my grad school days. After a hiatus, I'm diving back into ML and exploring the latest in the field.\n I recently went through the \"Attention is All You Need\" paper, along with some related literature, and I’m eager to put my knowledge into practice. However, I find myself at a crossroads and would appreciate some guidance.\n I've been exploring Hugging Face for implementing ML models, but I'm not completely sold on using it for production. The design and documentation have proven to be a bit challenging to navigate, and I find myself wondering if I mi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hx81a/d_seeking_advice_on_using_hugging_face_for/",
          "publishedOn": "2023-10-27T20:53:00.000Z",
          "wordCount": 2898,
          "title": "[D] Seeking Advice on Using Hugging Face for Production",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hwwf0/d_what_are_your_duties_as_a_machine_learning/",
          "author": null,
          "description": "Please elaborate on this. \n Including your role at the company, your day to day tasks, tools and languages you’re using. \n Thank you in advance!\n    submitted by    /u/Judessaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hwwf0/d_what_are_your_duties_as_a_machine_learning/",
          "publishedOn": "2023-10-27T20:37:45.000Z",
          "wordCount": 2560,
          "title": "[D] What are your duties as a Machine Learning Engineer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hwt4a/d_any_ideas_for_state_space_models_in_finance/",
          "author": null,
          "description": "I have to write a master's thesis (60-70 pages) for my AI Msc. I have soon learned about sparse state space models and find them interesting. I am also interested in stock price prediction. Now I am reading articles but find it hard to propose some novel idea. How do I do it? Do any unsolved problems in that field exist?\n    submitted by    /u/Pineapple_throw_105  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hwt4a/d_any_ideas_for_state_space_models_in_finance/",
          "publishedOn": "2023-10-27T20:33:33.000Z",
          "wordCount": 2598,
          "title": "[D] Any ideas for state space models in finance masters thesis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hvylk/p_sellagen_ai_data_marketplace_that_has_a_data/",
          "author": null,
          "description": "Been working on my platform for a while now and one of the key features is the data request feature, which allows users to submit data requests for free. These requests include descriptions, required fields, geographical scope, budget etc... The data requests get sent to tons of companies, organization, people and they will reach out to you directly. No matter the dataset (as long as it's legal of course). \n If you need to train a model on the dataset, I'm also integrating a plug-and-play ML training infrastructure that can generate scripts for you depending on your need. If that's something that interests you, feel free to reach out! \n Note: You can also upload open-source datasets on the platform if you're feeling like it! We have a donation link for data contributors :)\n    submitted by    /u/nobilis_rex_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hvylk/p_sellagen_ai_data_marketplace_that_has_a_data/",
          "publishedOn": "2023-10-27T19:54:32.000Z",
          "wordCount": 2687,
          "title": "[P] Sellagen – AI Data marketplace that has a data request feature so you don't have to spend weeks or months getting that data you need for that project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hu7gl/r_using_marl_ai_results_in_better_urban_planning/",
          "author": null,
          "description": "Urban planning is tricky - governments push top-down changes while locals want bottom-up ideas. It's hard to find compromises that make everyone happier.\n A new research paper proposes using Multi-Agent Reinforcement Learning (MARL) to vote on land use. Some agents represent officials, others are for residents.\n The AI is trained to balance competing interests. It learns to optimize for \"consensus rewards\" that keep all sides content. The AI acted like an impartial mediator to find win-win solutions.\n Testing on a real neighborhood showed the AI model:\n  \nCreated more sustainable land use per city goals\n Improved the variety of housing/shops to liven up the area\n Made the end results more fair for lower/middle/upper income folks\n  \nThere's more details on how the model was evaluated in the paper. There were a number of different metrics used to score the model's results.\n I like how they turned urban planning into a spatial graph that the AI can process. This seems like a pretty interesting approach - although there are some limits like relying on a lot of land parcel data that seems hard to find for larger communities.\n TLDR: AI helps find compromises in urban planning that balance government and community interests more fairly.\n Full summary is here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hu7gl/r_using_marl_ai_results_in_better_urban_planning/",
          "publishedOn": "2023-10-27T18:33:35.000Z",
          "wordCount": 2744,
          "title": "[R] Using MARL AI results in better urban planning outcomes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hsjdt/d_why_choose_an_h100_over_an_a100_for_llm/",
          "author": null,
          "description": "What are the benefits of using an H100 over an A100 (both at 80 GB and both using FP16) for LLM inference?\n ​\n Seeing the datasheet for both GPUS, the H100 has twice the max flops, but they have almost the same memory bandwidth (2000 GB/sec). As memory latency dominates inference, I wonder what benefits the H100 has. One benefit could, of course, be the ability to use FP8 (which is extremely useful), but I'm interested in the difference in the hardware specs in this question. \n    submitted by    /u/faschu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hsjdt/d_why_choose_an_h100_over_an_a100_for_llm/",
          "publishedOn": "2023-10-27T17:18:14.000Z",
          "wordCount": 2622,
          "title": "[D] Why choose an H100 over an A100 for LLM inference?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hrvfy/p_instruction_finetuning_with_a_lowresource/",
          "author": null,
          "description": "I am trying to build a summarizer for a conversation that happened between a rule-based bot and a customer. To my disadvantage the working language is Turkish. I gathered fine-tuning data of 1.000 examples. Also, I have a Turkish summarization dataset of +100k. As far as I observed instruction fine-tuning will yield proper results if and only if there is a good amount of examples in the pre-training data of the LLM. Have you had similar experiences with low-resource languages? Any advice on how to tackle such issues? Also, do you know any open-source LLM with a high amount of low-resource language in its pre-training data?\n    submitted by    /u/dafajon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hrvfy/p_instruction_finetuning_with_a_lowresource/",
          "publishedOn": "2023-10-27T16:48:06.000Z",
          "wordCount": 2639,
          "title": "[P] Instruction fine-tuning with a Low-Resource Language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hrgee/r_image_clustering/",
          "author": null,
          "description": "Do you know any packages for unsupervised cluster with images (between multiple) without relying on a pre-trained network? Python or R preferred, thanks. Well, download app works too then. \n    submitted by    /u/sladebrigade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hrgee/r_image_clustering/",
          "publishedOn": "2023-10-27T16:29:10.000Z",
          "wordCount": 2552,
          "title": "[R] Image clustering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hrdov/r_tdmpc2_scalable_robust_world_models_for/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.16828\n Website: https://nicklashansen.github.io/td-mpc2\n Code: https://github.com/nicklashansen/tdmpc2\n Abstract:\n TD-MPC is a model-based reinforcement learning (MBRL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model. In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results without any hyperparameter tuning. We further show that agent capabilities increase with model and data size, and successfully train a single agent to perform 80 tasks across multiple task domains, embodiments, and action spaces. We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents.\n https://preview.redd.it/avdb19jytrwb1.png?width=2678&format=png&auto=webp&s=75d63a044abf304c2d16e318c11e95e8397a3964\n    submitted by    /u/joepadde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hrdov/r_tdmpc2_scalable_robust_world_models_for/",
          "publishedOn": "2023-10-27T16:25:36.000Z",
          "wordCount": 2678,
          "title": "[R] TD-MPC2: Scalable, Robust World Models for Continuous Control - TD-MPC2 performs 100+ tasks without tuning, and enables training of a single 317M parameter model that performs 80 tasks across multiple domains, embodiments, and action spaces!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hprkw/d_best_method_to_retrain_or_augment_llm_on/",
          "author": null,
          "description": "My boss is a semi famous author in a niche academic field. I have thousands of pages of text coming from books, transcripts, and more.\n Is there a straightforward path to creating a corpus to augment Bert or Llama or another llm? End goal being able to chat with this ai that is now trained on his life's work.\n Is there anything specific to understand in terms of preparing the corpus? Do I need key value pairs where I write a ton of examples questions and responses?\n    submitted by    /u/spacedragon13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hprkw/d_best_method_to_retrain_or_augment_llm_on/",
          "publishedOn": "2023-10-27T15:12:27.000Z",
          "wordCount": 2626,
          "title": "[D] Best method to retrain or augment llm on proprietary or specialized material?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hpg78/discussion_career_advice/",
          "author": null,
          "description": "Hey y’all \n Hope I’m in the right spot but I’d like some career advice. I just recent got hired into a small shop with a bunch of CNC machines. And I saw that they made a part for a big aerospace company. Needless to say that got my attention. I don’t want to risk the guy working there because he’s likely not allowed to talk about it. But what language would you recommend to start with to be able to program and machine a part that crazy? Is it an actual computer program such as Java or should I lean into CAD/autoCAD etc? \n Many thanks in advance\n    submitted by    /u/I-farm-celery  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hpg78/discussion_career_advice/",
          "publishedOn": "2023-10-27T14:58:25.000Z",
          "wordCount": 2636,
          "title": "[Discussion] Career advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hoyeb/p_curriculum_learning_and_selfplay_with_any/",
          "author": null,
          "description": "We've just released an update to AglieRL, our SOTA evolutionary hyperparameter optimisation framework for reinforcement learning.\n This update includes a MakeEvolvable wrapper to make any PyTorch network, including pre-trained models, evolvable in one line of code. This can result in 10x faster training by using our framework.\n We've also created a curriculum learning and self-play tutorial that shows how to train a DQN agent to play Connect Four. Self-play can lead to amazing results, as demonstrated by AlphaGo etc, where agents discover new strategies to achieve superhuman performance, so we wanted to make it accessible to all.\n Please check it out! https://github.com/AgileRL/AgileRL\n    submitted by    /u/nicku_a  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hoyeb/p_curriculum_learning_and_selfplay_with_any/",
          "publishedOn": "2023-10-27T14:35:32.000Z",
          "wordCount": 2637,
          "title": "[P] Curriculum learning and self-play with any neural network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hns0t/d_imbuegenerally_intelligent/",
          "author": null,
          "description": "Interested in anyone who knows about this company (they have a lot of ML hiring listings right now). Basically wondering if it's worth exploring more. They have apparently raised $240mln and are a unicorn so this is an important topic.\n Here is the summary of some red flags I have found:\n 1) Founders have no ML background \n 2) Zero released product after several years despite huge funding. \n 3) TC article says founded 2021, but every listing claims it is YC2017. One of the founders did a recruiting service from YC 2017, but Imbue is a totally unrelated company with a different founding group so claiming YC affiliation seems dubious/unethical. YC is also not named as an investor in the company anywhere on their website.\n 4) No-one I have spoken to has ever worked with them/ heard of them ou…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hns0t/d_imbuegenerally_intelligent/",
          "publishedOn": "2023-10-27T13:39:01.000Z",
          "wordCount": 3116,
          "title": "[D] Imbue/Generally Intelligent",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hnb62/d_minigpt5_question_what_is_the_purpose_of_having/",
          "author": null,
          "description": "https://arxiv.org/abs/2310.02239\n From the paper:\n  \nTherefore, we introduce a set of special tokens Vimg = {[IMG1], [IMG2], . . . , [IMGn]} (default n = 8) as generative vokens into the LLM’s vocabulary V . The LLM’s output hidden state for these vokens is harnessed for subsequent image generation, and the positions of these vokens can represent the insertion of the interleaved images.\n  \nWhat function exactly are these different image tokens serving here? It seems like you should only need one since we are passing on the hidden state anyway? \n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hnb62/d_minigpt5_question_what_is_the_purpose_of_having/",
          "publishedOn": "2023-10-27T13:15:14.000Z",
          "wordCount": 2664,
          "title": "[D] MiniGPT-5 Question - What is the purpose of having multiple image tokens in the vocabulary if the hidden state of the transformer is passed on as \"vokens\" to the image generation? If you are using the model's hidden state, what purpose does multiple discrete different image tokens serve?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hlfu7/p_database_question_answering/",
          "author": null,
          "description": "Database question /answer with link\n We have a community app with groups and would like to build a search function where users can ask: when is the next event, give me the messages posted by Erik, where can I find …\n The information is stored in a table: post-test, posted-by etc.\n We do not want to use OpenAI or any external apis. Is something like llama index too powerful or are there other solutions for this? And we want to receive the postId to direct the use to the post\n    submitted by    /u/dirk_klement  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hlfu7/p_database_question_answering/",
          "publishedOn": "2023-10-27T11:29:27.000Z",
          "wordCount": 2620,
          "title": "[P] database question answering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hl7zh/d_what_role_does_data_quality_plays_in_the_llm/",
          "author": null,
          "description": "DeepMind released the Training Compute-Optimal Large Language Models paper in 2022 which describe some scaling laws for LLMs. As far as I understand this is the most accredited reference to estimate the optimal relation between dataset size, compute power and model size.\n Recently a number of models have been developed using far less data, parameters and compute than the bigger LLMs. Yet these models achieved great results thanks to much better data quality. For instance models like WizardLM, TinyStories and phi-1. Similarly, a lot of research seems to imply that better data could offer huge improvements without any other changes.\n I'm curious about what role the data quality plays in the training of LLMs.\n Is the set of values estimated by the Chinchilla scaling laws optimal for these smaller models with optimized data too?\n Do we have any model to estimate the quality of some datasets and some scaling laws that take it into account?\n Are there any relevant projects or research I could check out, focused on creating big datasets to train larger LLMs with high-quality data?\n    submitted by    /u/IAmBlueNebula  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hl7zh/d_what_role_does_data_quality_plays_in_the_llm/",
          "publishedOn": "2023-10-27T11:15:43.000Z",
          "wordCount": 2713,
          "title": "[D] What role does data quality plays in the LLM scaling laws?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hjgli/discussion_machine_learning_conference_with_a/",
          "author": null,
          "description": "Hi,\n I graduated from a Statistics & ML masters this summer, and have since August started working where I have been assigned a counselor. One big part of this is to help dictate my path forward in accordance with what I want to learn more about. I feel that I have a (in contrast to the people around me) generally good understanding of ML and modeling, but less so about how it is used in a business case. As such, an idea was to attend a machine learning conference which is focused on business implementations to learn more about this, but also get an opportunity to expand my network a bit.\n Does anyone have a suggestion of such a conference? Preferably in Europe as that would be easier to argue in terms of expenses! :) \n    submitted by    /u/Accomplished_Sea1675  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hjgli/discussion_machine_learning_conference_with_a/",
          "publishedOn": "2023-10-27T09:13:05.000Z",
          "wordCount": 2671,
          "title": "[Discussion] Machine learning conference with a focus on business implementations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hed2k/r_a_deep_dive_on_memgpt_with_the_lead_author/",
          "author": null,
          "description": "Interview: https://www.youtube.com/watch?v=4aOLxPdx1Dg\n Abstract:\n Context window management has become a critical part of every LLM application — from the basics (embeddings models, vector DBs) to more advanced techniques (query rewriting, HyDE, summarization). MemGPT is a new tool from UC Berkeley built by Charles Packer that automates \"memory\" management for LLMs and creates a functionally infinite context window. Charles joins us this week to talk about MemGPT, the techniques behind it, and where the conversational AI space is headed.\n    submitted by    /u/cgwuaqueduct  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hed2k/r_a_deep_dive_on_memgpt_with_the_lead_author/",
          "publishedOn": "2023-10-27T03:22:18.000Z",
          "wordCount": 2615,
          "title": "[R] A deep dive on MemGPT with the lead author Charles Packer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hb6e9/research_incentivizing_dataset_contributors/",
          "author": null,
          "description": "Hi there - can someone point me in the direction of projects that are incentivizing dataset contributors? I have a background in blockchain and crypto-assets, so I am new to the ML space, but it seems like it's a place where there would be ample crossover...and I haven't found many projects dealing with this.\n Thanks!\n    submitted by    /u/gigstudies  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hb6e9/research_incentivizing_dataset_contributors/",
          "publishedOn": "2023-10-27T00:35:08.000Z",
          "wordCount": 2585,
          "title": "[Research] Incentivizing Dataset Contributors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hattb/training_imagenet_on_resnet_dropping_lr_has/",
          "author": null,
          "description": "I'm trying to train Resnet50 on Imagenet following this paper [1] as well as this one [2].\n ​\n They say that at approximately every 30 epochs, I should drop the learning rate by 10.\n Since I'm training on 8 GPUs, I adjusted the learning rate according to [1].\n ​\n Original lr= 0.1\n Original Batch = 256\n Per-GPU lr = 0.025\n Per-GPU Batch = 64\n ​\n The problem I have is that when I divide the learning rate by 10 at convergence (approx 30 epochs), I don't get as much improvement as [1] and [2].\n https://preview.redd.it/5ar2g15h1nwb1.png?width=683&format=png&auto=webp&s=3e2751443cea654d9c6366dc4dc9859f0ec7952b\n Has anyone else had this issue? Any advice?\n Thanks\n ​\n    submitted by    /u/mrLiamFa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hattb/training_imagenet_on_resnet_dropping_lr_has/",
          "publishedOn": "2023-10-27T00:17:22.000Z",
          "wordCount": 2639,
          "title": "Training ImageNet on Resnet - Dropping LR has little improvement on accuracy [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h8vgr/d_stoa_local_rag/",
          "author": null,
          "description": "Which VDB + orchestration layer + generative text model stack would you recommend for building locally on an M2 Max chip? \n    submitted by    /u/Frequent-Let231  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h8vgr/d_stoa_local_rag/",
          "publishedOn": "2023-10-26T22:42:32.000Z",
          "wordCount": 2551,
          "title": "[D] STOA Local RAG",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h7d9u/d_is_there_an_online_llama_model_that_supports/",
          "author": null,
          "description": "Hi,\n I'm doing some work with using multi-modal data with LLaMA, for example, Video-LLaMA, which converts images/videos into embeddings, concatenates it with the text embeddings, and feeds it into LLaMA. It's difficult for me to run some of the models myself because of computational constraints. I'm wondering if there is an online demo that supports inputting embeddings directly (as opposed to text tokens).\n To clarify the title, I meant an online demo, not the weights.\n    submitted by    /u/DumplingLife7584  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h7d9u/d_is_there_an_online_llama_model_that_supports/",
          "publishedOn": "2023-10-26T21:36:14.000Z",
          "wordCount": 2614,
          "title": "[D] Is there an online LLaMA model that supports plugging in embeddings directly?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h4mkc/r_linear_representations_of_sentiment_in_large/",
          "author": null,
          "description": "Paper. I am not affiliated with this paper or its authors.\n Abstract:\n  \nSentiment is a pervasive feature in natural language text, yet it is an open question how sentiment is represented within Large Language Models (LLMs). In this study, we reveal that across a range of models, sentiment is represented linearly: a single direction in activation space mostly captures the feature across a range of tasks with one extreme for positive and the other for negative. Through causal interventions, we isolate this direction and show it is causally relevant in both toy tasks and real world datasets such as Stanford Sentiment Treebank. Through this case study we model a thorough investigation of what a single direction means on a broad data distribution. We further uncover the mechanisms that involve this direction, highlighting the roles of a small subset of attention heads and neurons. Finally, we discover a phenomenon which we term the summarization motif: sentiment is not solely represented on emotionally charged words, but is additionally summarized at intermediate positions without inherent sentiment, such as punctuation and names. We show that in Stanford Sentiment Treebank zero-shot classification, 76% of above-chance classification accuracy is lost when ablating the sentiment direction, nearly half of which (36%) is due to ablating the summarized sentiment direction exclusively at comma positions.\n  \nTwitter thread from one of the paper's authors.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h4mkc/r_linear_representations_of_sentiment_in_large/",
          "publishedOn": "2023-10-26T19:36:18.000Z",
          "wordCount": 2759,
          "title": "[R] Linear Representations of Sentiment in Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h4dd3/d_good_reading_materials_for_adversarial_machine/",
          "author": null,
          "description": "Trying to get an intern up to speed with ML application to wireless communications and adversarial ML for wireless communications. Talking jamming, anti-jamming, and spoofing. I don't want to throw them into the deep end just yet though, but rather give them a good foundation and basis for which to be able to take up more advanced work and build to it. Looking for fundamental texts on the topic of ML used for wireless communications and also it's use for adversarial attacks on these systems. Looking more for basic and starter papers, tutorials, and background, meta review papers, and just overall good places to get feet wet into this area as a novice. Essentially good resources to point an intern learning about this to get them up to speed kind of reading materials.\n I am looking for good …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h4dd3/d_good_reading_materials_for_adversarial_machine/",
          "publishedOn": "2023-10-26T19:25:20.000Z",
          "wordCount": 2937,
          "title": "[D] Good Reading Materials for (Adversarial) Machine Learning and RF Comms (EW)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h45y3/d_can_anyone_tell_me_if_the_machine_learning/",
          "author": null,
          "description": "Data Collection\n \nUnderstanding Data\n i. importing necessary libraries\n ii. check row and columns\n iii. check data types\n iv. Check data distribution\n \nData Cleaning\n i. Handle datatype issues\n ii. Maintain Data Consistency\n iii. Check if data contains outliers or if the data is not normally distributed to decide between mean or median\n iv. Identify missing values\n v. Handle missing values by-\n a.Drop missing values b. Mean, median or mode imputation c. Prediction Model d. replace missing values \n vi. Duplicate data detection and treatment\n vii. Repeat data cleaning\n \nEDA\n i. Variable Identification\n a. Identify predictor and features b. Identify types or category of data \n ii. Univariate Analysis\n iii. Bi-variate Analysis\n iv. Outlier detection and treatment\n v. Encoding\n vi. Feature Engineering\n vii. Variable Transformation\n  a. Normalization b. Scaling \n viii. Variable Creation\n \nIf testing data is not given, split the dataset to train and test set. Otherwise repeat step 3 and 4 for given test dataset.\n \nModel Building\n i. Model Training on training set\n ii. Model Evaluation and cross validate\n iii. Fine Tuning or Model optimization\n iv. Model selection\n \nEvaluate model accuracy with test data.\n \n    submitted by    /u/Samia_Tisha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h45y3/d_can_anyone_tell_me_if_the_machine_learning/",
          "publishedOn": "2023-10-26T19:16:43.000Z",
          "wordCount": 2738,
          "title": "[D] Can anyone tell me if the machine learning workflow is correct or not? Could anyone please refer to tutorials or blogs to learn the proper workflow? Any suggestions are welcome.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h43e9/r_what_algorithms_can_transformers_learn_a_study/",
          "author": null,
          "description": "Paper. I am not affiliated with this paper or its authors.\n Abstract:\n  \nLarge language models exhibit surprising emergent generalization properties, yet also struggle on many simple reasoning tasks such as arithmetic and parity. This raises the question of if and when Transformer models can learn the true algorithm for solving a task. We study the scope of Transformers' abilities in the specific setting of length generalization on algorithmic tasks. Here, we propose a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task. Specifically, we leverage RASP (Weiss et al., 2021) -- a programming language designed for the computational model of a Transformer -- and introduce the RASP-Generalization Conjecture: Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths. This simple conjecture remarkably captures most known instances of length generalization on algorithmic tasks. Moreover, we leverage our insights to drastically improve generalization performance on traditionally hard tasks (such as parity and addition). On the theoretical side, we give a simple example where the \"min-degree-interpolator\" model of learning from Abbe et al. (2023) does not correctly predict Transformers' out-of-distribution behavior, but our conjecture does. Overall, our work provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers.\n  \nTwitter thread from one of the work's authors.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h43e9/r_what_algorithms_can_transformers_learn_a_study/",
          "publishedOn": "2023-10-26T19:13:38.000Z",
          "wordCount": 2769,
          "title": "[R] What Algorithms can Transformers Learn? A Study in Length Generalization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h3tgx/r_qmoe_practical_sub1bit_compression_of/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.16795\n Github: https://github.com/ist-daslab/qmoe\n Abstract:\n  \nMixture-of-Experts (MoE) architectures offer a general solution to the high inference costs of large language models (LLMs) via sparse routing, bringing faster and more accurate models, at the cost of massive parameter counts. For example, the SwitchTransformer-c2048 model has 1.6 trillion parameters, requiring 3.2TB of accelerator memory to run efficiently, which makes practical deployment challenging and expensive. In this paper, we present a solution to this memory problem, in form of a new compression and execution framework called QMoE. Specifically, QMoE consists of a scalable algorithm which accurately compresses trillion-parameter MoEs to less than 1 bit per parameter, in a custom format co-designed with bespoke GPU decoding kernels to facilitate efficient end-to-end compressed inference, with minor runtime overheads relative to uncompressed execution. Concretely, QMoE can compress the 1.6 trillion parameter SwitchTransformer-c2048 model to less than 160GB (20x compression, 0.8 bits per parameter) at only minor accuracy loss, in less than a day on a single GPU. This enables, for the first time, the execution of a trillion-parameter model on affordable commodity hardware, like a single server with 4x NVIDIA A6000 or 8x NVIDIA 3090 GPUs, at less than 5% runtime overhead relative to ideal uncompressed inference. \n  \nhttps://preview.redd.it/wka92keqelwb1.jpg?width=1843&format=pjpg&auto=webp&s=10cf67b344d3c776049da6b78244fc140b2d4142\n https://preview.redd.it/khxw1neqelwb1.jpg?width=898&format=pjpg&auto=webp&s=83006dac6e03963f2443f4e4ba710dcf8166acc8\n https://preview.redd.it/xsc2ykeqelwb1.jpg?width=796&format=pjpg&auto=webp&s=c23d03956f4a9aa9d9f185592a5bfe45039698f4\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h3tgx/r_qmoe_practical_sub1bit_compression_of/",
          "publishedOn": "2023-10-26T19:01:24.000Z",
          "wordCount": 2768,
          "title": "[R] QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models - Institute of Science and Technology Austria (ISTA) 2023 - Can compress the 1.6 trillion parameter SwitchTransformer-c2048 model to less than 160GB (20x compression, 0.8 bits per parameter) at only minor accuracy loss!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h1zpd/d_requesting_feedback_on_masters_in_ai_program/",
          "author": null,
          "description": "As the title says I'm asking for feedback from folks in the field of ML/AI on the MSAI program at UT@Austin.\n Here's the program website: https://cdso.utexas.edu/msai\n My Skills/Experience:\n  \nHave a BS in Comp Sci\n Very comfortable with Math\n Very experienced SE with >20 years in the industry\n Very comfortable with Python, many other languages and confident I can learn any new language/framework/APIs\n Have completed the Fast.ai program\n Have worked through Andrej Karpathy's makemore videos\n Currently working in a leadership AI Engineering role doing work with LLMs, Vector DBs, and Computer Vision models\n Comfortable with NNs, Backprop and have implemented from scratch several times for learning\n  \nThe Program:\n Required Courses:\n  \nDeep Learning\n Ethics in AI\n Machine Learning\n Planning, Search and Reasoning under Uncertainty\n Reinforcement Learning\n  \nElectives:\n  \nAI in Healthcare\n Automated Logical Reasoning\n Case Studies in Machine Learning\n Natural Language Processing\n Online Learning and Optimization\n Optimization\n  \nProgram Pros/Cons:\n  \nPro: It's super affordable\n Pro: It's entirely online/async which would work great with my work schedule\n Cons: It's a new program so there are no reviews from past students to look at\n  \nMy Goal:\n Move from \"AI Engineering\" (as it's called these days) into research. I'm interested in several areas like model architecture and robotics. I'm not sure to what degree these roles would require a PhD though? If I complete this program I'd like it to be useful for pursuing a PhD if I decide to take that path.\n For anyone in the industry, I'd love feedback on whether this looks like a useful program that will help me move toward my goals. If you're aware of other options that might be better I'd love to hear about them.\n P.S. Please keep the Reddit snark to a minimum, not useful.\n Thank you in advance.\n    submitted by    /u/meowkittykitty510  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h1zpd/d_requesting_feedback_on_masters_in_ai_program/",
          "publishedOn": "2023-10-26T17:39:52.000Z",
          "wordCount": 2831,
          "title": "[D] Requesting feedback on Master's in AI program with University of Texas at Austin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h1gpa/d_recommendations_to_improve_plan_outcomes/",
          "author": null,
          "description": "I have retirement plan data with outcomes like success/fail and remaining assets. I am looking for a way to predict how failed retirement plans can be improved. For example, when presented with a plan that fails, I would like to provide recommendations to improve the the plan outcome; e.g. increase savings by x, or delay retirement by x years.\n Any suggestions on how I should go about this? Using typical methods only tells me if a plan will fail or not, but I'm looking for a way to provide recommendations based on successful plans.\n    submitted by    /u/BallLogical5087  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h1gpa/d_recommendations_to_improve_plan_outcomes/",
          "publishedOn": "2023-10-26T17:15:38.000Z",
          "wordCount": 2626,
          "title": "[D] Recommendations to improve plan outcomes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gyztv/r_pretrained_imagenet_weights_for_vit/",
          "author": null,
          "description": "Hello, I am working on the research I need to compare my model with ViT for that I need pretrained weights of ViT-Ti/16, ViT-S/16, ViT-S/32, ViT-B/16, and ViT-B/32. I tried to find but I got npz file that has a different key than from vit_pytorch import ViT do you know where can i find ImageNet weights?\n    submitted by    /u/NoEntertainment6225  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gyztv/r_pretrained_imagenet_weights_for_vit/",
          "publishedOn": "2023-10-26T15:24:59.000Z",
          "wordCount": 2588,
          "title": "[R] Pretrained ImageNet weights for ViT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gvphb/d_grouped_query_attention_in_llama_70b_v2/",
          "author": null,
          "description": "Hey guys, after thousands of experiments with bigger LLaMA fine-tunes I'm somewhat sure the GQA mechanism might be your enemy and generate wrong answers, especially for math and such complex areas.\n I'd like to use MHA (Multi Head Attention) if possbile. I'm just not sure - do I need to retrain model completely or is it possible to just increase heads count and KV size and proceed with the stock model AS IS?\n    submitted by    /u/Gatzuma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gvphb/d_grouped_query_attention_in_llama_70b_v2/",
          "publishedOn": "2023-10-26T12:46:06.000Z",
          "wordCount": 2606,
          "title": "[D] Grouped Query Attention in LLaMA 70B v2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gv3wn/n_ml_models_for_efficient_fraud_detection/",
          "author": null,
          "description": "For efficient Fraud Detection using ML models, Qbeast Format introduces a data-driven approach. The key lies in sampling and optimizing training processes without compromising accuracy. 🕵🏼‍♀️\n Explore the technical details: https://qbeast.io/qbeast-format-can-improve-fraud-detection/\n    submitted by    /u/alinagrebenkina  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gv3wn/n_ml_models_for_efficient_fraud_detection/",
          "publishedOn": "2023-10-26T12:14:10.000Z",
          "wordCount": 2558,
          "title": "[N] ML models for efficient Fraud Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gtzwm/d_asrsttvrs_ranking/",
          "author": null,
          "description": "What are the best overall ASR/STT/VRS for now? And the best per functionalities (best for Esperanto, best for noisy files, best for multiple voices, best for whatever...)\n ​\n ​\n    submitted by    /u/xqoe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gtzwm/d_asrsttvrs_ranking/",
          "publishedOn": "2023-10-26T11:07:53.000Z",
          "wordCount": 2556,
          "title": "[D] ASR/STT/VRS ranking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gtwxr/d_research_in_language_generation_for_style/",
          "author": null,
          "description": "Is research in language generation for tasks like style transfer and summarization solely constrained by prompt engineering? I've personally conducted experiments with large language models, and even the open-source language model yields impressive results, even for zero-shot inference. There was even a paper that suggested summarization is nearly obsolete. How valid is this assertion for general text generation tasks especially text style transfer?\n    submitted by    /u/1azytux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gtwxr/d_research_in_language_generation_for_style/",
          "publishedOn": "2023-10-26T11:02:40.000Z",
          "wordCount": 2598,
          "title": "[D] Research in language generation for Style Transfer, Summarization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gti3n/p_elevate_your_ml_testing_with_pytestvisual/",
          "author": null,
          "description": "I’ve developed a tool called pytest-visual, aiming to make ML code testing more efficient and meaningful. Traditional unit testing often misses visual and functional aspects of ML workflows such as data augmentation and model structures.\n pytest-visual brings a visual layer to your unit testing, allowing you to not only verify that the code runs, but the outputs also make visual sense and meet expectations. It’s integrated into pytest, automatically highlighting changes in visualization outputs, and allowing for easier/more reproducible debugging and verification.\n Quick Highlights:\n  \nStreamlines the organization of visualizations in your ML code.\n Auto-detects changes in visualization outputs.\n Enhances debugging and verification.\n  \nFor more details and to give it a try, check out the project on GitHub.\n Feedback and contributions are very welcome!\n    submitted by    /u/kongaskristjan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gti3n/p_elevate_your_ml_testing_with_pytestvisual/",
          "publishedOn": "2023-10-26T10:35:22.000Z",
          "wordCount": 2656,
          "title": "[P] Elevate Your ML Testing with pytest-visual",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17grrzb/p_torchpairwise_highly_efficient_library_for/",
          "author": null,
          "description": "https://github.com/inspiros/torchpairwise\n    submitted by    /u/IcySnowy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17grrzb/p_torchpairwise_highly_efficient_library_for/",
          "publishedOn": "2023-10-26T08:28:21.000Z",
          "wordCount": 2537,
          "title": "[P] TorchPairwise: Highly efficient library for pairwise metrics for PyTorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gqiae/r_convnets_match_vision_transformers_at_scale/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gqiae/r_convnets_match_vision_transformers_at_scale/",
          "publishedOn": "2023-10-26T06:54:23.000Z",
          "wordCount": 2544,
          "title": "[R] ConvNets Match Vision Transformers at Scale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gp1vs/d_how_to_enhance_accuracy_in_image_classification/",
          "author": null,
          "description": "I'm currently working on an image classification project using a VGG16 model. I have a dataset with 9 classes, with one class having 1000 images and the remaining classes having 180 to 250 images each.\n Here are some details:\n  \nTrain images: 2886 images (9 classes)\n Test images: 432 images (9 classes)\n Model: VGG16\n Optimizer: Adam\n Loss function: Categorical Crossentropy\n  \nlast epochs score :- loss: 309.7468 - accuracy: 0.4401 - val_loss: 14.5241 - val_accuracy: 0.4606\n how to improve the accuracy of my model\n    submitted by    /u/_Killua_04  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gp1vs/d_how_to_enhance_accuracy_in_image_classification/",
          "publishedOn": "2023-10-26T05:12:21.000Z",
          "wordCount": 2616,
          "title": "[D] How to Enhance Accuracy in Image Classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17go1zd/p_suggessions_on_miniprojects/",
          "author": null,
          "description": "Hey,I'm a 3rd year engineering student studying computer science Now I wanted to do a mini-project and have a group of 3 ready and wanted to incorporate machine learning. I am also a beginner to this field but is much interested in it. Could you guys share some light on doing the project with your past experience or done projects I have been taking inputs from various connections and would help a lot if you guys share some light on it.:)\n    submitted by    /u/Ic_zy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17go1zd/p_suggessions_on_miniprojects/",
          "publishedOn": "2023-10-26T04:10:30.000Z",
          "wordCount": 2611,
          "title": "[P] Suggessions on mini-projects",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gijpx/d_llms_playing_chess_are_sensitive_to_how_the/",
          "author": null,
          "description": "Link - https://github.com/dpaleka/llm-chess-proofgame\n TLDR; The lead up to the state of the board and not just the state of the board at inference affects predictions. \n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gijpx/d_llms_playing_chess_are_sensitive_to_how_the/",
          "publishedOn": "2023-10-25T23:30:47.000Z",
          "wordCount": 2571,
          "title": "[D] LLMs playing chess are sensitive to how the position came to be",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gibmp/d_a_script_to_preprocess_arxiv_sources/",
          "author": null,
          "description": "People train LLMs on arxiv sources, so there must be some sort of software to whip them into shape. Specifically, I'm looking for a script to join all the tex files for a paper into one. Note that it's not just a matter of substituting \\input's - sometimes it's not clear which file is the main one, so it needs to handle this too.\n    submitted by    /u/Foxtr0t  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gibmp/d_a_script_to_preprocess_arxiv_sources/",
          "publishedOn": "2023-10-25T23:21:08.000Z",
          "wordCount": 2604,
          "title": "[D] A script to pre-process arxiv sources?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ghrbz/r_humanlike_systematic_generalization_through_a/",
          "author": null,
          "description": "Work. I am not affiliated with this work or its authors.\n Article about the work.\n Twitter thread about the work from one of its authors.\n Abstract:\n  \nThe power of human language and thought arises from systematic compositionality—the algebraic ability to understand and produce novel combinations from known components. Fodor and Pylyshyn famously argued that artificial neural networks lack this capacity and are therefore not viable models of the mind. Neural networks have advanced considerably in the years since, yet the systematicity challenge persists. Here we successfully address Fodor and Pylyshyn’s challenge by providing evidence that neural networks can achieve human-like systematicity when optimized for their compositional skills. To do so, we introduce the meta-learning for compositionality (MLC) approach for guiding training through a dynamic stream of compositional tasks. To compare humans and machines, we conducted human behavioural experiments using an instruction learning paradigm. After considering seven different models, we found that, in contrast to perfectly systematic but rigid probabilistic symbolic models, and perfectly flexible but unsystematic neural networks, only MLC achieves both the systematicity and flexibility needed for human-like generalization. MLC also advances the compositional skills of machine learning systems in several systematic generalization benchmarks. Our results show how a standard neural network architecture, optimized for its compositional skills, can mimic human systematic generalization in a head-to-head comparison.\n  \n   submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ghrbz/r_humanlike_systematic_generalization_through_a/",
          "publishedOn": "2023-10-25T22:57:55.000Z",
          "wordCount": 2760,
          "title": "[R] Human-like systematic generalization through a meta-learning neural network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17geq9f/r_researchers_discover_that_incontext_learning/",
          "author": null,
          "description": "A new paper provides some insight into how in-context learning works in LLMs. This study proposes and provides evidence for an elegant structure within the in-context learning process.\n The models appear to create a \"task vector\" that encapsulates the core logic from the demonstration examples, in a way that is independent of any specific query. This vector serves as a compressed representation of the task.\n A separate component then takes this task vector and a new query as inputs to generate the output, without directly referencing the original examples.\n In essence:\n Output = Apply(query, Learn(examples))\n Where \"Learn\" derives the task vector from the examples, and \"Apply\" utilizes the vector and query to produce the output.\n The researchers validated this hypothesis by testing major public models on diverse tasks such as translation and algorithmic reasoning. Key findings:\n  \nIsolating the Learn and Apply components maintained high accuracy, demonstrating the viability of the separation.\n Task vectors clustered by task and remained consistent within tasks, indicating they encode meaningful task representations.\n Injecting another task's vector into the model caused it to override contradictory examples and follow the vector, highlighting the vector's dominance.\n Vectors induced relevant token distributions despite those terms being absent from the examples, suggesting semantic encoding of the task.\n  \nTaken together, these results provide substantial evidence that in-context learning involves creating a task vector that encapsulates the examples' logic to then guide behavior on new queries.\n While open questions remain regarding implementation details, this is a significant step towards demystifying an interesting AI capability.\n Full writeup. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17geq9f/r_researchers_discover_that_incontext_learning/",
          "publishedOn": "2023-10-25T20:50:38.000Z",
          "wordCount": 2801,
          "title": "[R] Researchers discover that in-context learning creates task vectors in LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gc7pr/d_what_is_more_important_loss_or_accuracy/",
          "author": null,
          "description": "I have created a basic classification model and there is something that I don't fully comprehend, as the loss decreases the accuracy increases (I assume this is how it should be in ideal scenarios) while this is the general trend there is a point where the loss is minimum and while accuracy at that point is high it's not the highest. Why would such a phenomenon occur? And since it occurred what is a better metric for the evaluation of the model?\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gc7pr/d_what_is_more_important_loss_or_accuracy/",
          "publishedOn": "2023-10-25T18:58:22.000Z",
          "wordCount": 2623,
          "title": "[D] What is more Important loss or accuracy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gbb9r/p_locally_hosted_audiototext_transcription_model/",
          "author": null,
          "description": "Hi,\n I'm looking for a locally hosted LLM to transcribe audio files to text. I need this for my business, but with absolute privacy (witness testimony recordings and other highly sensitive data). I figured I'd just buy a new computer which never gets connected to the internet and is dedicated only to audio processing to have absolute security. My questions are:\n - Which is the best model to use? I prefer accuracy and don't mind processing time as long as it's getting done within a few hours to even a day or two (I need to transcribe maximum 1 file per day, but up to six hours of audio), so I figured the large Whisper - probably WhisperX ? - would be my best bet. Are there comparable non-openAI models? (I need diarization)\n - What hardware should I get for this? Cost is secondary/irrelevant, although I don't want to spend 5 figures on a GPU - I can accept some processing time\n    submitted by    /u/Jealous_Pomelo_1172  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gbb9r/p_locally_hosted_audiototext_transcription_model/",
          "publishedOn": "2023-10-25T18:18:36.000Z",
          "wordCount": 2704,
          "title": "[P] Locally hosted audio-to-text transcription - model and hardware?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gavl6/best_nlp_package_in_python_to_extract_medical/",
          "author": null,
          "description": "I am trying to extract FEV1 (forced expiratory volume) values from a dataset that contains a column with report notes from the doctor assessing the patient with pulmonary function testing. I have been able to build out a sort of solution with regexes in Python, and that's somewhat effective. But I've been instructed to code up an alternative using a more machine learning-based approach. I wanted to use spaCy to accomplish this but I'm not sure exactly how to implement the code nor if spaCy is the best package to use for this task.\n Here is my regex code that works decently. It's pretty messy and have to take into account a ton of edge cases which can get cumbersome. This is why I'd like to find a more automated solution.\n #Attempting to add in percents\n df = pd.read_excel('[mypath]/pft_tiu…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gavl6/best_nlp_package_in_python_to_extract_medical/",
          "publishedOn": "2023-10-25T17:59:05.000Z",
          "wordCount": 3268,
          "title": "Best NLP Package in Python to extract medical test results from medical notes? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g9ec6/p_adala_an_open_source_autonomous_data_labeling/",
          "author": null,
          "description": "Hi r/MachineLearning,\n We have just open sourced Adala - a robust framework for implementing agents that specialize in advanced data processing tasks, starting with data labeling and generation.\n Agents combine knowledge outputs from LLMs and action on them in production systems, thus their reliability to correctly and consistently perform operations is critical. We saw an opportunity to create a new agent framework that could dramatically increase the efficiency of data labeling (and broader application across data processing tasks), with the unique ability to be guided by human feeback.\n To ensure agents remember and build upon their experiences, Adala provides a Memory component—a dynamic storage space for the agent's acquired knowledge. For instance, retrieving the previous experiences of an agent’s errors (and subsequent human feedback) allows them a starting point from which to branch off into learning or improving skills.\n To allow Adala to produce reliable agents, we devised two main strategies:\n  \nSupervision Integration: Provide agents with 'ground truth data'—well-defined examples that serve as a learning foundation. This foundational data not only sets the learning parameters for the agent but also defines its operational environment.\n Constrained Generation: Ensuring that an agent's predictions are within a defined and bounded range of outputs.\n  \nLet us know what you think in the comments below or by contributing to the repo.\n Adala framework overview\n ​\n    submitted by    /u/pirate7777777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g9ec6/p_adala_an_open_source_autonomous_data_labeling/",
          "publishedOn": "2023-10-25T16:54:42.000Z",
          "wordCount": 2772,
          "title": "[P] Adala – an open source Autonomous DAta (Labeling) Agent framework that helps you automate data processing and data labeling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g9855/p_pretraining_dataset/",
          "author": null,
          "description": "I'm trying to pre-train my own language model on some high quality datasets (TinyStories,tiny-textbooks...). Some of these datasets include input-output data and some are just text (stories), I was wondering how should I format the data for pre-training. Should I only use plain text like stories and webtext in pretraining then the rest in fine-tuning (adding instruction tokens) or should I just train with all of the datasets at pre-training with the special tokens where they are needed? \n    submitted by    /u/Additional-Ad-7043  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g9855/p_pretraining_dataset/",
          "publishedOn": "2023-10-25T16:47:22.000Z",
          "wordCount": 2614,
          "title": "[P] Pre-training dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g80do/research_large_languagespeech_models_and_voice/",
          "author": null,
          "description": "Hey ML folks,\n My friend is working on his academic research project where he is exploring voice research spealizing in large speech models. If you have time, help him advance his research on voice interfaces. should take 2 mins max.\n https://forms.gle/a3PaQmYEiqRDxY4Z8\n whats in it for me ? you can share email to get a copy of the research and listen what the rest of us have said.\n Thanks!\n    submitted by    /u/deep-thoughts-guy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g80do/research_large_languagespeech_models_and_voice/",
          "publishedOn": "2023-10-25T15:55:15.000Z",
          "wordCount": 2607,
          "title": "[Research] large language/speech models and voice interface research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g7qlx/r_open_source_video_enhancement_options/",
          "author": null,
          "description": "We work the disease prediction based on video classification and would like to test what improving the quality of videos would do for our models, any specific components, apps or packages we should test? So far used UpScayl, not sure how that ranks \n    submitted by    /u/sladebrigade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g7qlx/r_open_source_video_enhancement_options/",
          "publishedOn": "2023-10-25T15:43:20.000Z",
          "wordCount": 2582,
          "title": "[R] Open Source video enhancement options",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g757y/p_oss_tool_to_interactively_explore_hugging_face/",
          "author": null,
          "description": "submitted by    /u/44sps  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g757y/p_oss_tool_to_interactively_explore_hugging_face/",
          "publishedOn": "2023-10-25T15:16:47.000Z",
          "wordCount": 2545,
          "title": "[P] OSS tool to interactively explore Hugging Face datasets with one line of code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g5akw/p_training_a_transformer_from_scratch/",
          "author": null,
          "description": "Hello!\n I would like to train a transformer network from scratch, without pre-training, on a language modeling task (next work prediction) or a sequence-to-sequence task (translation).\n For the language modeling task, I tried with the Shakespeare dataset, and other simpler ones (e.g., Beatles songs), but it tends to overfit quite quickly on the training set, probably because the corpus is too short. I know that Andrej Karpathy did it with the Shakespeare dataset in his YouTube video, but he used a character-wise tokenisation, which dramatically reduces the validation loss on the next-work prediction task, given that the vocab size is tiny. I guess that at the end the generation process provides a similar quality of text as when a word tokenizer is used.\n Surprisingly, I had quite good results by training from scratch an Encoder-Decoder model, for English-to-French translation (using the 8 million examples of the Tatoeba dataset). I guess here, the overfitting is less prominent because there are more datapoints, and that the possibility of predictions are much more constrained, due to the input sequence.\n What are you guys experience with this? I would be happy to know how I can train my transformer without having to use a pre-trained architectures or spend weeks on GB datasets.\n Thank you!\n    submitted by    /u/rem_dreamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g5akw/p_training_a_transformer_from_scratch/",
          "publishedOn": "2023-10-25T13:50:43.000Z",
          "wordCount": 2748,
          "title": "[P] Training a transformer from scratch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g24t8/data_analysis_vs_ml_engineering_d/",
          "author": null,
          "description": "Do you think coursera certifications, besides a master in electrical engineering, can help us find better occupational positions? I am told that for a beginner it is better to start with jobs in Data analysis rather than going directly to ML engineering. Is it corr? Is data analysis a prerequisite for ML?\n    submitted by    /u/Street-Regular-9924  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g24t8/data_analysis_vs_ml_engineering_d/",
          "publishedOn": "2023-10-25T11:01:23.000Z",
          "wordCount": 2591,
          "title": "Data analysis vs ML engineering [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g1il0/dr_how_should_the_architecture_of_a_transformer/",
          "author": null,
          "description": "When increasing the parameters of a (decoder-only) transformer, one has a choice around how to spend that increased budget -- number of layers vs embedding dim vs number of heads. Anyone know if there's solid guidance out there for the proportions each aspect should be scaled in?\n E.g. looking at LLaMa (https://arxiv.org/abs/2302.13971), they seem to scale the first sizes two proportionally, but for larger sizes, n heads grows more slowly.\n https://preview.redd.it/ytdfk1d5rbwb1.jpg?width=1422&format=pjpg&auto=webp&s=abf22ac369ec5ecf81ff07b0d8a095f884efe729\n    submitted by    /u/Tea_Pearce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g1il0/dr_how_should_the_architecture_of_a_transformer/",
          "publishedOn": "2023-10-25T10:19:09.000Z",
          "wordCount": 2607,
          "title": "[D][R] How should the architecture of a transformer be scaled?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g0xiz/d_what_are_some_existing_datasets_for_training/",
          "author": null,
          "description": "There are a lot of great open datasets for fine-tuning LLMs for instruction following (e.g LIMA, self-instruct, dolly-15k, etc) and as chat bots (OASST, etc).\n One thing I have not really seen yet are datasets that involves planning and tool use. Is anybody working on something like that or have come across any? \n I'm interested in working on one. If anybody has ever attempted this, I would really appreciate any advice. \n P.S I do note that \"reasoning\" should be more rigorously defined and scoped, but I think some ambiguity around an intellectual discussion like this can help.\n    submitted by    /u/notllmchatbot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g0xiz/d_what_are_some_existing_datasets_for_training/",
          "publishedOn": "2023-10-25T09:35:53.000Z",
          "wordCount": 2645,
          "title": "[D] What are some existing datasets for training LLMs to perform reasoning, acting as agents?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g0i0j/d_opensource_sota_audiotoaudio_how_do_i_sound/",
          "author": null,
          "description": "Hello people, I would like to learn how to turn the recording of my voice to sound like a famous person. I imagine I would take an open source model and fine-tune it using data I will collect. Can someone point me towards the best sounding current models that I could adapt for this purpose? Thank you so much.\n    submitted by    /u/gonzales82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g0i0j/d_opensource_sota_audiotoaudio_how_do_i_sound/",
          "publishedOn": "2023-10-25T09:02:57.000Z",
          "wordCount": 2598,
          "title": "[D] Open-source SOTA Audio-to-Audio: how do I sound like a famous actor?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g0fqe/d_guidance_needed_for_upcoming_aiml_phds_on/",
          "author": null,
          "description": "Many upcoming Ph.D. students in AI/ML are facing the difficult decision of identifying promising research topics that will stand the test of time over the time of their Ph.D. studies.\n With the rapid progress in AI, especially in the NLP field, many incremental research tasks have been effectively \"solved\". Need to choose an area where there is ample room for open-ended inquiry and meaningful contributions over 4-5 years of PhD research.\n While large language models have shown impressive advances recently, their capabilities may plateau during a Ph.D. (if starting the Ph.D. from next year ~ 4 years) timeframe. How should aspiring researchers choose topics resilient enough to withstand the test of time and allow them to push the field forward through their Ph.D. work?\n For those with experience in AI research who have seen changes in the field over time:\n  \nWhat emerging trends or broad areas do you see as fertile ground for AI/ML PhD research now and in the coming years?\n Can you highlight any intriguing subfields worthy of deeper investigation by aspiring PhD students?\n What open problems or applications warrant more attention from the upcoming generation of PhD researchers?\n  \nSome of tending Research topics so far: \n  \nLLM in a specific domain\n Prompting \n Evals \n LM interfaces \n Safety \n Understanding LMs \n Emergence\n \n Any advice on identifying PhD research topics with longevity would be greatly appreciated by aspiring graduate students.\n    submitted by    /u/aadityaura  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g0fqe/d_guidance_needed_for_upcoming_aiml_phds_on/",
          "publishedOn": "2023-10-25T08:58:30.000Z",
          "wordCount": 2775,
          "title": "[D] Guidance needed for upcoming AI/ML PhDs on selecting research topics with lasting impact",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fzy6u/pr_testval_scores_how_much_difference_isnt/",
          "author": null,
          "description": "Hello folks, I'm working on a medical image dataset using EM loss and asymmetric pseudo labelling for single positive multi-label learning (only training using 1 positive label). I'm using a densenet121 and on a chest x-ray dataset.\n  \nI see a difference of 10% in my validation vs test score (score = mAP: mean average precision). The score seems okay and was expected but the difference is bothering me. I understand that it's obvious but any visual insights from your side? (Attaching plot below)\n The validation set consist less than half of test set samples. (It is the official split; I have nothing to do with it). I feel it is the reason, as ofcourse more the randomness in a set, poorer the convergence.\n  \n​\n https://preview.redd.it/nseqy1mw5bwb1.png?width=577&format=png&auto=webp&s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58\n Do share any experiences or suggestions!\n    submitted by    /u/ade17_in  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fzy6u/pr_testval_scores_how_much_difference_isnt/",
          "publishedOn": "2023-10-25T08:20:27.000Z",
          "wordCount": 2670,
          "title": "[P][R] Test-Val scores, how much difference isn't problematic.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fzs1c/d_are_there_method_that_can_extract_interaction/",
          "author": null,
          "description": "I want to extract interaction between persons in short text. For example, \"Sally will buy a new phone. Ted will help her.\" contains interaction between persons. However, \"Japanese Karate champion won the first prize.\" and \"Sally missed her friends, Ted and Tom\" does not contain interaction between persons.\n Is there any tools or methods that can extract interactions?\n    submitted by    /u/tkddnjs1234  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fzs1c/d_are_there_method_that_can_extract_interaction/",
          "publishedOn": "2023-10-25T08:07:40.000Z",
          "wordCount": 2603,
          "title": "[D] Are there method that can extract interaction between person in text?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fxyq0/d_who_are_some_outspoken_ai_people_who_speak/",
          "author": null,
          "description": "I'm interested in learning more about the perspectives of AI researchers and practitioners who are critical of AI ethics and regulation. \n I'm particularly interested in those who argue that AI ethics and regulation are unnecessary or harmful.\n Please note that I'm not asking for people who are simply skeptical of certain AI ethics proposals or who believe that AI ethics should be implemented in a specific way. I'm more interested in people who argue that AI ethics is a fundamentally flawed concept or that AI should not be regulated at all.\n    submitted by    /u/Periplokos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fxyq0/d_who_are_some_outspoken_ai_people_who_speak/",
          "publishedOn": "2023-10-25T05:53:40.000Z",
          "wordCount": 2638,
          "title": "[D] Who are some outspoken AI people who speak against AI ethics and regulation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fth5g/promptspecific_poisoning_attacks_on_texttoimage/",
          "author": null,
          "description": "submitted by    /u/simandl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fth5g/promptspecific_poisoning_attacks_on_texttoimage/",
          "publishedOn": "2023-10-25T01:40:36.000Z",
          "wordCount": 2539,
          "title": "Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ft45e/d_what_should_i_do_for_training_when_data_to/",
          "author": null,
          "description": "I was taught that when doing imbalance classification, the training data should be augmented to more or less match the number of classes, but the validation data should have the same distribution as the test data. And the test data should have the similar distribution as the data I will actually predict. \n But what if real data's distribution is quite random? What validation data distribution should I use? \n (I got 14 classes to classify, and 1 of classes has 52% proportion, and small ones have 0.9%, and 0.17% proportion. Practitioners who would use my model input data that only 3 classes to classify, and they can be very small proportion. The training data before augmentation was created by integrating data with this irregular distribution.) \n    submitted by    /u/poemfordumbs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ft45e/d_what_should_i_do_for_training_when_data_to/",
          "publishedOn": "2023-10-25T01:22:43.000Z",
          "wordCount": 2671,
          "title": "[D] What should I do for training when data to predict has random distribution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fqa0i/d_how_should_i_calculate_the_weights_for_a/",
          "author": null,
          "description": "I'm not sure if I worded the title correctly. Let me elaborate on the scenario.\n I have a multi-label image classification task where I'm trying to classify the gender of clothing images. The two labels that we can predict are Male and Female, hence the final logit vector's size would be something like [batch_size, 2].\n Depending on the predictions, we're mapping the following binary values to different categorical values:\n  \n[0, 0]: Unknown\n [0, 1]: Male\n [1, 0]: Female\n [1, 1]: Unisex\n  \nThe overall distribution is heavily imbalanced with Male being the minority class. I'm trying to calculate class weights to favor Male, but the problem is that the size of the weight tensors to be provided to the loss function should have a length of 2. I say this is a problem because although the number of prediction logits is 2, the actual number of classes is 4.\n I used the word \"dependent\" in my title because, for example, [1, 1] wouldn't necessarily mean that the image has the labels Male and Female, rather that it's a completely new Unisex label. Again, not sure if the usage of the word is appropriate.\n Anyway I've thought of making a custom loss function to first map the binary labels to their respective categorical values, but am wondering if there is any other way to go about this.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fqa0i/d_how_should_i_calculate_the_weights_for_a/",
          "publishedOn": "2023-10-24T23:07:42.000Z",
          "wordCount": 2775,
          "title": "[D] How should I calculate the weights for a multi-label classification task where the labels are dependent among one another?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fp0n3/d_lstm_train_val_losses_not_converging/",
          "author": null,
          "description": "I am training an LSTM model for path prediction where I'm feeding in OBT (on-board Time) and X matrix as input and Y matrix is the predecessor matrix generated using Scipy.Dijkstra\n ​\n  This is the model architecture for reference, \n This is the model architecture for reference,\n I've tried multiple iterations of this similar model, but the training and validation loss, are not converging. The best train_loss i've been able to achieve is 88k mse and 400 mse val_loss\n I've uploaded the dataset here: GitHub - mathur-exe/LSTM_Dataset\n Training Progress:\n Epoch 1/100 342/342 - 17s - loss: 22606898.0000 - val_loss: 61414736.0000 - 17s/epoch - 49ms/step Epoch 2/100 342/342 - 14s - loss: 7990657.0000 - val_loss: 3699703.5000 - 14s/epoch - 40ms/step Epoch 3/100 342/342 - 13s - loss: 4130298.7500 - val_loss: 136808.1094 - 13s/epoch - 38ms/step Epoch 4/100 342/342 - 12s - loss: 2747299.2500 - val_loss: 35710.1680 - 12s/epoch - 35ms/step Epoch 5/100 342/342 - 12s - loss: 2558378.2500 - val_loss: 3383.4780 - 12s/epoch - 36ms/step Epoch 6/100 342/342 - 13s - loss: 1214455.8750 - val_loss: 111625.2891 - 13s/epoch - 37ms/step Epoch 7/100 342/342 - 19s - loss: 337480.2500 - val_loss: 68686.6094 - 19s/epoch - 55ms/step Epoch 8/100 342/342 - 15s - loss: 316366.7188 - val_loss: 2059.3557 - 15s/epoch - 44ms/step Epoch 9/100 342/342 - 20s - loss: 293117.0312 - val_loss: 20961.5469 - 20s/epoch - 58ms/step Epoch 10/100 342/342 - 17s - loss: 575945.1875 - val_loss: 503602.8438 - 17s/epoch - 50ms/step Epoch 11/100 342/342 - 13s - loss: 290962.8750 - val_loss: 62491.9375 - 13s/epoch - 37ms/step Epoch 12/100 342/342 - 12s - loss: 1125042.5000 - val_loss: 36054.6836 - 12s/epoch - 36ms/step Epoch 13/100\n ...\n 342/342 - 16s - loss: 230900.7969 - val_loss: 48309.6094 - 16s/epoch - 47ms/step Epoch 93/100 342/342 - 23s - loss: 232846.6094 - val_loss: 82926.6875 - 23s/epoch - 67ms/step\n    submitted by    /u/Gaurang_Mathur_ftw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fp0n3/d_lstm_train_val_losses_not_converging/",
          "publishedOn": "2023-10-24T22:12:20.000Z",
          "wordCount": 2841,
          "title": "[D] LSTM: Train & Val losses not converging",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fmgbq/d_will_chatgpt_remove_the_need_for_data_annotation/",
          "author": null,
          "description": "I wrote a blog post about this detailing my experience, which I will attach at the bottom but I want to hear opinions of people. It is something I've actively been thinking about, and would like to know potential pitfalls and why it may not work, rather than the huge promise it holds. \n https://ozanciga.wordpress.com/2023/10/24/will-chatgpt-remove-the-need-for-data-annotation/\n    submitted by    /u/ozanciga  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fmgbq/d_will_chatgpt_remove_the_need_for_data_annotation/",
          "publishedOn": "2023-10-24T20:27:20.000Z",
          "wordCount": 2599,
          "title": "[D] Will ChatGPT remove the need for data annotation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fmdkl/r_monarch_mixer_a_simple_subquadratic_gemmbased/",
          "author": null,
          "description": "submitted by    /u/hzj5790  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fmdkl/r_monarch_mixer_a_simple_subquadratic_gemmbased/",
          "publishedOn": "2023-10-24T20:24:02.000Z",
          "wordCount": 2555,
          "title": "[R] Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fm22g/d_is_it_better_to_create_a_different_set_of/",
          "author": null,
          "description": "I'm using Top2Vec with Doc2Vec embeddings to find topics in a dataset of ~4000 social media posts. This dataset has three groups:\n  \nPosts from a company (3%)\n Posts from this company's potential customers (82.5%)\n Posts from this company's competitors (14%)\n  \nThe purpose of this analysis is to look at the topics the company is posting about on social media and see how it compares to the things that their customers and competitors are posting about.\n Since the values of Doc2Vec embeddings depend on the other documents in the dataset, I'm worried that topics in smaller groups are going to be drowned out by the larger group. I'm worried that the differences between the document vectors in the smaller group are going to be made smaller by presence of the documents from the larger group, which may represent a much wider array of different topics.\n    submitted by    /u/abelEngineer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fm22g/d_is_it_better_to_create_a_different_set_of/",
          "publishedOn": "2023-10-24T20:10:52.000Z",
          "wordCount": 2706,
          "title": "[D] Is it better to create a different set of Doc2Vec embeddings for each group in my dataset, rather than generating embeddings for the entire dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17flxbr/d_how_would_you_do_it_handling_multiturn_qa/",
          "author": null,
          "description": "I have been giving this some thought and would appreciate some outside input, maybe someone has some experience they could share!\n I am attempting to create a QA chatbot that is limited to answering questions from a pre-determined set of question and answer pairs I have in a vector database. Currently I create embeddings of the question using OpenAI and query a vector database for similar \"reference question\" - if the similarity score is high enough I proceed and use the answer text I have stored in the metdata as \"context\" for the answer generation.\n I would now like to extend this to include conversational history. The issue I am facing however, is that a follow-on question may not hit the similarity threshold. Considering a follow-up question would typically not be worded in a way that …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17flxbr/d_how_would_you_do_it_handling_multiturn_qa/",
          "publishedOn": "2023-10-24T20:04:59.000Z",
          "wordCount": 3011,
          "title": "[D] How would you do it? Handling multi-turn QA conversation with matching of questions to vector database.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fl96h/p_the_ml_practitioner_a_publication_about_all/",
          "author": null,
          "description": "Hi all, my wife and I have recently started a new publication called The ML Practioner. \n If you're interested in writing for us, please send us a link of your unpublished draft here.\n Either way, please subscribe to us if you're interested in this kind of content! \n    submitted by    /u/kanxx030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fl96h/p_the_ml_practitioner_a_publication_about_all/",
          "publishedOn": "2023-10-24T19:36:30.000Z",
          "wordCount": 2596,
          "title": "[P] The ML Practitioner, a publication about all things machine learning and MLOps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fkztq/d_efficacy_of_cold_start_preferences_on_recs/",
          "author": null,
          "description": "Hi all,\n Are there good papers about the efficacy of cold start explicit preference collection (think Netflix “pick some movies you like”) on the recs systems? I haven’t been able to find any so far. One key aspect I’m looking for is if these are effective, how long they are relative to just implicit actions the user takes.\n Thanks\n    submitted by    /u/steathilynecessary  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fkztq/d_efficacy_of_cold_start_preferences_on_recs/",
          "publishedOn": "2023-10-24T19:25:33.000Z",
          "wordCount": 2604,
          "title": "[D] efficacy of cold start preferences on recs systems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fkj1g/d_embedding_models_ranked_by_encode_speed/",
          "author": null,
          "description": "Hello, the sbert.net has a list where you can sort by encode speed but its a very small subset of the HuggingFace MTEB leaderboard.\n AFAICT, the HuggingFace leaderboard / model pages don't have this information. \n Is there a list where I can see a more up-to-date list of models by encoding speed?\n    submitted by    /u/rsamrat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fkj1g/d_embedding_models_ranked_by_encode_speed/",
          "publishedOn": "2023-10-24T19:05:35.000Z",
          "wordCount": 2595,
          "title": "[D] Embedding models ranked by encode speed?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fk3yi/d_finite_state_transducers_and_language/",
          "author": null,
          "description": "In the context of NLP, will language models based on finite state transducers (since they are finite) ultimately fail to put language's productive nature to good use?\n All the possible outputs a finite state transducer can produce are predictable, while all the possible outputs a given natural language can produce are much less predictable? \n    submitted by    /u/RecordingOk5720  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fk3yi/d_finite_state_transducers_and_language/",
          "publishedOn": "2023-10-24T18:47:44.000Z",
          "wordCount": 2597,
          "title": "[D] Finite State Transducers and language productivity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fjibc/p_equinox_kv_cache/",
          "author": null,
          "description": "I've been trying to implement a kv cache in my language model but have been unsuccessful so far due to the dynamic shapes. I've seen some implementations in flax but was wondering if it was possible to implement in equinox as that's what I'm using and prefer over others like flax. If anyone can point me in the right direction or help with the implementation that would be great! PS: I can provide any code if wanted to help\n    submitted by    /u/Additional-Ad-7043  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fjibc/p_equinox_kv_cache/",
          "publishedOn": "2023-10-24T18:22:12.000Z",
          "wordCount": 2619,
          "title": "[P] Equinox KV Cache",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fj3uh/explainable_boosting_machine_local_and_global/",
          "author": null,
          "description": "I am using EBM for a research, the local and global explanation plots it produces come with preset font size, I want to change the resolution of the figure and the font size of labels and x and y ticks in the explanation plots.\n I have looked for it on the InterpretML github page and issues and scrolled through various webpages but haven't found anything helpful. Used gpt but it doesnot help either, it tries to use matplotlib but EBM plots are not compatible with it.\n Please share any way it can be solved, because the plots labels are unreadable in the article if used as it is.\n    submitted by    /u/Horseman099  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fj3uh/explainable_boosting_machine_local_and_global/",
          "publishedOn": "2023-10-24T18:05:26.000Z",
          "wordCount": 2655,
          "title": "Explainable Boosting Machine Local and Global Explanation plots label size [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fh37k/dp_what_is_the_metric_for_early_stopping_in/",
          "author": null,
          "description": "I am trying to fine tune the yolov8 detection model an was going through the code base of ultralytics.I found this piece of code in the engine.trainer\n # Early Stopping if RANK != -1: # if DDP training broadcast_list = [self.stop if RANK == 0 else None] dist.broadcast_object_list(broadcast_list, 0) # broadcast 'stop' to all ranks if RANK != 0: self.stop = broadcast_list[0] if self.stop: break # must break all DDP ranks \n I'm familiar with how the early stopping works and not sure what they are doing here\n does this get invoked by default?? what is the metric that they use in order to stop it??\n upon further inspection i found this\n self.stopper, self.stop = EarlyStopping(patience=self.args.patience), False \n which is imported as\n from ultralytics.utils.torch_utils import (EarlyStopping, ModelEMA, de_parallel, init_seeds, one_cycle, select_device, strip_optimizer) \n please help me find out what metric they use to stop this and if the earlystopping is invoked by default\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fh37k/dp_what_is_the_metric_for_early_stopping_in/",
          "publishedOn": "2023-10-24T16:38:08.000Z",
          "wordCount": 2691,
          "title": "[D][P] What is the metric for early stopping in YOLOv8 detection?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17feh7j/p_the_n_implementation_details_of_rlhf_with_ppo/",
          "author": null,
          "description": "We are happy to share a great repro of OpenAI's early RLHF codebase, with nearly identical learning curves. We also summarized implementation details (did you know Adam Optim's implementation details could impact RLHF?)\n  \n📜 Blog post:https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo\n 💾 Code: https://github.com/vwxyzjn/lm-human-preference-details\n  \n   submitted by    /u/vwxyzjn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17feh7j/p_the_n_implementation_details_of_rlhf_with_ppo/",
          "publishedOn": "2023-10-24T14:44:01.000Z",
          "wordCount": 2584,
          "title": "[P] The N Implementation Details of RLHF with PPO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fe3l6/ml_project_p/",
          "author": null,
          "description": "What are best ways to collect database for any ml project\n    submitted by    /u/GingSkywalker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fe3l6/ml_project_p/",
          "publishedOn": "2023-10-24T14:26:31.000Z",
          "wordCount": 2544,
          "title": "ML [project] [p]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fdcns/r_feature_space_reduction_method_for/",
          "author": null,
          "description": "We are excited to announce the publication of our groundbreaking scientific paper in Machine Learning: Science and Technology titled “Feature Space Reduction Method for Ultrahigh-Dimensional, Multiclass Data: Random Forest-Based Multiround Screening (RFMS)” by Gergely Hanczar, Marcell Stippinger, David Hanak, Marcell T Kurbucz, Oliver M Torteli, Agnes Chripko, and Zoltan Somogyvari.\n Published on: 19 October 2023 DOI: 10.1088/2632-2153/ad020e Volume 4, Number 4\n In recent years, several screening methods have been published for ultrahigh-dimensional data that contain hundreds of thousands of features, many of which are irrelevant or redundant. However, most of these methods cannot handle data with thousands of classes. Prediction models built to authenticate users based on multichannel biometric data result in this type of problem. In this study, we present a novel method known as random forest-based multiround screening (RFMS) that can be effectively applied under such circumstances. The proposed algorithm divides the feature space into small subsets and executes a series of partial model builds. These partial models are used to implement tournament-based sorting and the selection of features based on their importance. This algorithm successfully filters irrelevant features and discovers binary and higher-order feature interactions. To benchmark RFMS, a synthetic biometric feature space generator known as BiometricBlender is employed. Based on the results, the RFMS is on par with industry-standard feature screening methods while possessing many advantages.\n r/IAMA - Oct 26 with the founders of Cursor Insight.\n https://bit.ly/AMAwithCursorInsight-GoogleCalendar\n ​\n  R/IAMA - Oct 26 with the founders of Cursor Insight.\n    submitted by    /u/CursorInsight  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fdcns/r_feature_space_reduction_method_for/",
          "publishedOn": "2023-10-24T13:52:44.000Z",
          "wordCount": 2787,
          "title": "[R] Feature Space Reduction Method for Ultrahigh-Dimensional, Multiclass Data: RFMS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fcupf/n_new_letter_from_yoshua_bengio_geoffrey_hinton/",
          "author": null,
          "description": "Signatories include Turing Award winners Yoshua Bengio, Geoffrey Hinton, as well as others academics and experts. \n  \nIn 2019, GPT-2 could not reliably count to ten. Only four years later, deep learning systems can write software, generate photorealistic scenes on demand, advise on intellectual topics, and combine language and image processing to steer robots. As AI developers scale these systems, unforeseen abilities and behaviors emerge spontaneously without explicit programming1. Progress in AI has been swift and, to many, surprising.\n The pace of progress may surprise us again. Current deep learning systems still lack important capabilities and we do not know how long it will take to develop them. However, companies are engaged in a race to create generalist AI systems that match or ex…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fcupf/n_new_letter_from_yoshua_bengio_geoffrey_hinton/",
          "publishedOn": "2023-10-24T13:29:26.000Z",
          "wordCount": 2995,
          "title": "[N] New letter from Yoshua Bengio, Geoffrey Hinton, and others: Managing AI Risks in an Era of Rapid Progress",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fbmsx/d_generative_food/",
          "author": null,
          "description": "Hey guys, I sometimes post about tiny ML projects we work on. This time, we talk about applying language models for generating recipe titles/ideas. Specifically, we don't use LLMs, and this turns out to be a bit of a controversial decision, but one that has it's own advantages.\n Quite interested in the community's take on it: https://engineering.hellofresh.com/recipes-and-generative-ai-6d74a107860c\n    submitted by    /u/abnormdist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fbmsx/d_generative_food/",
          "publishedOn": "2023-10-24T12:30:01.000Z",
          "wordCount": 2590,
          "title": "[D] Generative Food",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fbhlg/r_tokenizer_choice_for_llm_training_negligible_or/",
          "author": null,
          "description": "📷Research\n https://arxiv.org/abs/2310.08754\n While the recent success of LLMs has been driven primarily by curation of training dataset composition, scaling of model architectures and dataset sizes, and advances in pretraining features, the impact of tokenizers has often lagged as a blind spot. Our researcher*s study sheds light on this issue and shows that tokenizer choice can significantly impact downstream model performance as well as training and inference costs.\n 1️⃣ Investigation of intrinsic tokenizer performance, i.e., study of tokenizer properties (i.e., generated vocabulary), and tokenization results of tokenizers.\n 2️⃣ Investigate the extrinsic performance of the tokenizer, i.e., the impact of the tokenizer on the downstream performance of the model.\n 3️⃣ Investigation of possible correlation between intrinsic and extrinsic tokenizer performance.\n ​\n 💡 The investigation shows that the common tokenizer evaluation metrics \"fertility\" and \"parity\" do not always predict the performance of the downstream model, making these metrics a questionable criterion for tokenizer evaluation.\n 💡 Moreover, the study shows that multilingual tokenizers - which are based on the five most common European languages - require a vocabulary size by a factor of three compared to English. The previous approach of training tokenizers with English vocabulary only thus turns out to be inefficient and results in a strong performance degradation and additional training costs of up to 68%\n    submitted by    /u/effi28_ml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fbhlg/r_tokenizer_choice_for_llm_training_negligible_or/",
          "publishedOn": "2023-10-24T12:22:15.000Z",
          "wordCount": 2758,
          "title": "[R] Tokenizer Choice For LLM Training: Negligible or Crucial?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fahnw/r_using_machine_learning_to_drive_portfolio_asset/",
          "author": null,
          "description": "I'd love to hear your guys thoughts on next steps to improve this, maybe deeper layers and more nodes, maybe a random forest is more appropriate? I'd love to hear any thoughts on Machine Learning directly applicable to time-series data.\n https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model\n The Main Idea\n We will develop a Machine Learning model, specifically a deep learning model (more hidden layers to come), to periodically, tactically rebalance the weights of our portfolio based on observable market data and empirically determined statistics combined with feature engineering from the past 21 trading days, and for the VIX we consider its characteristics since inception.\n The output will be a range representing the degree to which we bet long, short, or hold cash, and 3 weights that sum to less than or equal to one and greater than or equal to negative one. In essence we will allow shorting of securities and not require our portfolio to be fully invested. Cash is an active position; sometimes the best investment is staying on the sidelines.\n The model will allow one input layer, one and two hidden layers (to show that more might not always be better, explicitly with the 200 variable maximum excel solver imposes on us), and an output layer with 3 nodes outputting a value between -1 and +1 with -1 representing a full allocation to a short position in the security and +1 representing a fully allocated long position.\n    submitted by    /u/QFA_official  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fahnw/r_using_machine_learning_to_drive_portfolio_asset/",
          "publishedOn": "2023-10-24T11:25:50.000Z",
          "wordCount": 2780,
          "title": "[R] Using Machine Learning to Drive Portfolio Asset Allocations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fahm6/d_are_people_in_ml_phds_still_happy/",
          "author": null,
          "description": "As an outsider who has many friends in ML Phds, this is my perspective of their lives:\n  \nlong hours, working nights, weekends\n no work-life balance, constant fear of being scooped and time pressure from deadlines\n frustrating broken review systems\n many incremental, advertisement papers that produce very little actual contribution (which is justified by 2.)\n \"engineering\" and not \"science\"\n all this pressure amounts to severe imposter syndrome\n  \nAre people in the field still happy? Where do people get their satisfaction? To me it looks like almost like a religion or a cult. The select few who say, get neurips outstanding paper are promoted to stardom - almost a celebrity status while everyone else suffers a punishing work cycle. Are the phd students all banking on AGI? What else motivates them?\n Edit: the discussion is about whether 1-6 are worse in ML than other fields (or even the median experience). The reference for \"other field\" is highly heterogenous. Experience obviously varies by lab, and then even by individuals within labs. \"It happens in other fields too\" is a trivial statement - of course some version of 1-6 affects somebody in another field.\n Edit 2: small n but summarizing the comments - experience seems to differ based on geographic region, one's expectations for the phd, ability to exert work-life balance, and to some extent ignore the trends others are all following. Some people have resonated with problems 1-6, yet others have presented their own, anecdotal solutions. I recommend reading comments from those who claim to have solutions.\n    submitted by    /u/shenkev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fahm6/d_are_people_in_ml_phds_still_happy/",
          "publishedOn": "2023-10-24T11:25:46.000Z",
          "wordCount": 2798,
          "title": "[D] Are people in ML Phds still happy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17f9q81/p_a_pdf_tool_that_supports_three_retrieval/",
          "author": null,
          "description": "➡️ Check on https://huggingface.co/spaces/xuyingliKepler/VecDBCompare\n 📌 Introduction: VecDBCompare is a streamlit-based application designed to evaluate and compare three different vector database retrieval strategies. Users only need to upload a PDF and interact with QABots using three different strategies to determine which strategy is most suitable for them. \n ⭐️ Three retrieval strategies: \n  \nChunk Strategy: Divides the document into small chunks and retrieves based on the most relevant chunks.\n Summary Strategy: Summarizes the document and retrieves based on the summary content. \n Hypothetical Question Strategy: Generates hypothetical questions that the document might answer and retrieves based on these questions.\n  \n   submitted by    /u/xuying_li  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17f9q81/p_a_pdf_tool_that_supports_three_retrieval/",
          "publishedOn": "2023-10-24T10:38:59.000Z",
          "wordCount": null,
          "title": "[P] A PDF tool that supports three retrieval strategies, allowing users to choose the answer that suits them best",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17f8k14/d_p_3d_design_file_labelling_and_classification/",
          "author": null,
          "description": "I have ~1 million 3D design (.STP and/or .OBJ) files of various parts for medical devices, aerospace, automotive or defense systems. I'd like to label them based on appropriate manufacturing methods that are used to physically make them. Some example methods and labels would be milling, turning, injection molding, cnc machining, etc. After labelling, I'd like to architect a system to produce these labels as inference for a new part that has not been physically made yet.\n My team (<5 people) have manufacturing domain expertise and can manually label these parts but I'm looking for a more scalable solution that isn't as time consuming. Crowd sourced methods like Mechanical Turk won't work because annotators do not have the domain knowledge to mark the correct label. Labelling platforms like SageMaker/Azure ML Studio only allow image/text/audio datasets, is there a platform that'll help me setup labelling tasks for 3D designs? Furthermore, how can I find more experts that can help scale this up? It seems to me that the only option is to build my own labelling app as an annotator needs these key features -\n  \n3D model visualizer so they can spin the part and view any orientation\n Draw a bounding box (commonly available in other platforms)\n Toggle measurements in inches/mm\n  \nAs for label classification I'm looking at architectures like PointNet since my dataset of meshes can be sampled to point clouds. Are there other methods that would work better or worth exploring? Open to any and all suggestions across this pipeline.\n ​\n ​\n    submitted by    /u/rootcage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17f8k14/d_p_3d_design_file_labelling_and_classification/",
          "publishedOn": "2023-10-24T09:15:12.000Z",
          "wordCount": 2797,
          "title": "[D] [P] 3D Design file labelling and classification for manufacturing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17f0q1v/d_undergrad_seeking_advice_on_ethicsml_research/",
          "author": null,
          "description": "I’m an undergraduate who’s considering a PhD student in ML. I’m currently in a lab that focuses on ethics in AI. While I love the work, it focuses on the humanities side of CS. I’ve always been a more mathy person and have always been interested in theoretical ML research. I’d like to combine ethics & AI/ML in some way (eg studying explainable AI from the technical perspective). I was wondering what are some research areas that combine the two and if I don’t work in academia, what’s the market and job prospects like for someone who does this?\n    submitted by    /u/SnooChipmunks1902  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17f0q1v/d_undergrad_seeking_advice_on_ethicsml_research/",
          "publishedOn": "2023-10-24T01:17:27.000Z",
          "wordCount": 2642,
          "title": "[D] Undergrad seeking advice on ethics/ML research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eytfr/p_traffic_signs_in_ecognition_developer/",
          "author": null,
          "description": "Hi community, first time posting here.\n I'm working on a project for the segmentation and classification of traffic signs using eCognition Developer software. I need help with creating scripts to apply three classifiers: Naive Bayes, SVM, and Random Forest.\n I'd like to know how I can implement these classifiers in eCognition Developer and where to insert the scripts in the software. Does anyone have experience with this software and could share script examples or provide guidance on how to accomplish this task?\n Sorry English is not my first language.\n Tldr, i need to include the Bayes classifiers, Random Tree, and SVM in eCognition Developer (for segmentation and classification - prediction).\n    submitted by    /u/Dignai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eytfr/p_traffic_signs_in_ecognition_developer/",
          "publishedOn": "2023-10-23T23:46:25.000Z",
          "wordCount": 2636,
          "title": "[P] Traffic signs in ecognition developer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17exk17/p_using_gpt4docstrings_to_generate_docstrings_for/",
          "author": null,
          "description": "gpt4docstrings is a Python library that allows you to write docstrings for functions / classes non documented in your codebase. In this case, I'm applying the library to one module of langchain to see the results.\n Repo: https://github.com/MichaelisTrofficus/gpt4docstrings\n https://i.redd.it/78f3wit071wb1.gif\n    submitted by    /u/Hefty-Consequence443  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17exk17/p_using_gpt4docstrings_to_generate_docstrings_for/",
          "publishedOn": "2023-10-23T22:48:45.000Z",
          "wordCount": 2573,
          "title": "[P] Using gpt4docstrings to generate docstrings for entire projects",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ewpiu/p_dqn_with_a_binary_vector_as_output/",
          "author": null,
          "description": "Heey everyone!\n I hope you're doing well.\n I need your help guys.\n I'm working on a DQN that outputs a binary vector of length L (I just applied sigmoid function on the ouptut layer and take p>0.5 as 1 and 0 otherwise). In this setting, at each decision time, the agent returns a list containing the indices of selected elements. Knowing that the list's length is dynamic how can I train my DQN ? (I am facing issues in this). Is there any alternative way to do this purpose (like DDPG :/ )?\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ewpiu/p_dqn_with_a_binary_vector_as_output/",
          "publishedOn": "2023-10-23T22:12:20.000Z",
          "wordCount": 2627,
          "title": "[P] DQN with a binary vector as output",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ewbpv/project_looking_for_aiml_engineers_to_team_up_for/",
          "author": null,
          "description": "Hi,\n first of all, sorry for the cross post, but I guess Huggingface forums were not the right place to begin with and it took me a while to find out where things about AI/ML are being actively discussed.\n I am a professional software developer (C, Python on Linux) and while I did try out a few things with PyTorch and Diffusers - I am not an ML engineer, so I am looking for someone with ML expertise who’d be interested to team up for a non commercial open source project. I can do quite a lot around application development, but I clearly lack the required ML knowledge. I followed the free MIT ML courses on YouTube, did some reading, tried things out, but the ML part of this project is for sure over my head.\n So, here’s what I have in mind: I would like to create an application which would b…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ewbpv/project_looking_for_aiml_engineers_to_team_up_for/",
          "publishedOn": "2023-10-23T21:56:00.000Z",
          "wordCount": 3273,
          "title": "[Project] Looking for AI/ML engineers to team up for a fallow deer identification project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eveyg/d_using_sql_to_monitor_ml_models/",
          "author": null,
          "description": "Hello,\n We are running a number of machine learning models in production and would like to monitor some metrics during inference: Data quality, inference time, accuracy, etc.\n All these metrics could be recorded in the python code and we are planning to build a SQL database that will receive all the information so as we can visualize in grafana.\n Do you think this is a good pattern? What would you suggest instead (we are using AWS).\n Thank you in advance.\n    submitted by    /u/Eddas123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eveyg/d_using_sql_to_monitor_ml_models/",
          "publishedOn": "2023-10-23T21:17:41.000Z",
          "wordCount": 2613,
          "title": "[D] Using SQL to monitor ML models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eup3m/rp_trying_to_understand_the_generative_properties/",
          "author": null,
          "description": "A while back, I came across the \"From Variational to Deterministic Autoencoders\", which provided a novel insight into the generative properties of autoencoders by framing the objective through the lens of regularization. However, I couldn't help but notice that the deterministic models studied felt incomplete, namely due to the inherent lack of sampling in those models (which is something that the authors acknowledge).\n To provide a short recap of the paper, the authors surgically decompose the variational autoencoder objective into a deterministic one. They start with a Constant-Variance VAE, which is a special case of the general Gaussian latent VAE where the noise standard deviation of the latent distribution is fixed to 1. This leads to what is essentially a standard autoencoder with t…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eup3m/rp_trying_to_understand_the_generative_properties/",
          "publishedOn": "2023-10-23T20:48:27.000Z",
          "wordCount": 3040,
          "title": "[R][P] Trying to understand the generative properties of autoencoders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17etn6g/d_what_is_the_lowest_possible_loss_for_a_language/",
          "author": null,
          "description": "Example: Suppose a character-level language model (three input letters to predict the next one), trained on a dataset that contains three instances of the sequence aei, with two occurrences preceding o and one preceding u, i.e., the dataset is:\n  \n Input Output \n  \n aei o \n  aei u \n  aei o \n \n In this case, the ideal probability distribution for the model's logits for aei would be ~0.66 for o, ~0.33 for u, and zero for other letters. In other words, when the model is input with aei, the ideal softmax of the logits would be ~0.66 for o, ~0.33 for u, and zero for other letters.\n Following this reasoning, the objective is to optimize the model's output for a given input to match the distribution of occurrences in the dataset.\n If this reasoning is correct, then we have the following ideal loss (cross-entropy):\n https://preview.redd.it/pzpxogcqd0wb1.png?width=330&format=png&auto=webp&s=b0b6c3b5fbfb4797c11a1f26375065ce883551d3\n Thus, ~0.63 is the smallest loss we can get with this dataset.\n Is my reasoning correct?\n    submitted by    /u/viniciusarruda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17etn6g/d_what_is_the_lowest_possible_loss_for_a_language/",
          "publishedOn": "2023-10-23T20:04:47.000Z",
          "wordCount": 2692,
          "title": "[D] What is the lowest possible loss for a language model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17etc1r/d_tanh_activation_function_outputs_the_same_value/",
          "author": null,
          "description": "Basically im working on the DDPG algorithm in DRL where i have an actor and critic networks.\n The actor network architecture is quite simple:\n  \nInput layer contains 22 neurons that represents the state values (ranging from 0.1 to 10.0 max not normalizing them)\n Two hidden layers with 128 neurons, with Leaky Relu activation (alpha = 0.01), and with HeUniform kernel initialzer\n Output layer with a single neuron has tanh activation, using Glorot kernel initialzer\n  \nThe critic network has the same architecture but we only concatenate the 22 state values with the action produced by the actor, the only difference is the ouput of the critic has no activation. And both networks use Adam.\n The problem arises when the training starts because i run a few steps without actually start the learning, but when the learning starts, the actor converges quickly to output values 1 or -1 afor any given input. I tried many learning rates for both actor and critic. One thing to note is when i set the actor learning rate to 1e-5 and the critic to 1e-3 the networks sometimes converges quickly, some time it takes longer to converge and sometimes it does not converge.\n    submitted by    /u/Desert_champion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17etc1r/d_tanh_activation_function_outputs_the_same_value/",
          "publishedOn": "2023-10-23T19:51:35.000Z",
          "wordCount": null,
          "title": "[D] Tanh activation function outputs the same value for any given input",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17et76c/p_finetuning_vaes_on_limited_data/",
          "author": null,
          "description": "I have been looking for a pre-trained VAE (on Imagenet with ResNet/VGG) or similar which I could fine-tune on my smaller dataset. However, not only there does not exist many such pre-trained weights but the practice of fine-tuning VAEs does not really seem mainstream.\n Is there a reason why VAEs are not pre-trained/fine-tuned? Does it have to do with posterior collapse?\n    submitted by    /u/unholy_sanchit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17et76c/p_finetuning_vaes_on_limited_data/",
          "publishedOn": "2023-10-23T19:45:38.000Z",
          "wordCount": 2593,
          "title": "[P] Fine-tuning VAEs on limited data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17esnol/d_smart_pooling_for_visual_transformers/",
          "author": null,
          "description": "There is an architecture for images/videos called MViT, where 2D MaxPooling layers are added to reduce computations for ViT. But MaxPooling has a drawback - it discards information independently of context, equally discarding information from both important and uninformative parts of the image. For traditional Conv2D networks, there's little we can do about this, but for transformers, we can reduce dimensionality in a more meaningful way - discarding only those elements that don't carry unique information. Are there any articles/developments on this topic already?\n    submitted by    /u/Dependent_Bluejay_45  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17esnol/d_smart_pooling_for_visual_transformers/",
          "publishedOn": "2023-10-23T19:22:28.000Z",
          "wordCount": 2616,
          "title": "[D] Smart pooling for Visual Transformers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17esei3/research_rvc_ai_training/",
          "author": null,
          "description": "Hello, I'm currently using RVC AI, and I'm about to record myself for the training. What is the best way to record myself except the singing and talking at least for 15 minutes like the guide says. Do I have to make it 20 min and one audio file or do I have to make it 20 min and maybe 10 files with 2 minutes each file? Also, can I multiply my files and reach the 15-20 minutes of audio that it's required or I have to make a different talking or singing for every audio?\n    submitted by    /u/WeldFrenzy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17esei3/research_rvc_ai_training/",
          "publishedOn": "2023-10-23T19:12:09.000Z",
          "wordCount": 2626,
          "title": "\"[Research]\" RVC AI Training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17erule/d_rag_oriented_finetune_searching_for_coherence/",
          "author": null,
          "description": "Still searching for a model that is well enough to make RAG... Lots of good models on huggingface, but none of them is trained to return extracted text or answers based on provided info without hallucinating something.\n Is quite frustrating, every week came a new version of a model that is amazing for Role play and storytelling... (some good progress also on coding...) I see lots of efforts in different RAG strategy, improving semantic search and Chunking, but the open source community still does not have a decent model fine tuned for that.\n I have considered the idea of make that fine tune, based on synthetic data (using Wikipedia as knowledge base), but unfortunately I have not enough funds to cover the api cost neighter to pay for some decent Gpu. I'm not going to train a 7B Model because the under 30B imho doesn't have many sense if the coherence is the main requirements.\n Unpopular opinion: as coherence, code llama 34B is much better to any of the 70B fine tune.\n Sorry to everyone for the rant... Does anyone have some tips or suggestions? \n Thanks in advance!\n Edit:\n My database is composed mainly by abstracts of papers and medical textbook. I admit that the domain is quite complex, but the error rate is too high. \n Obviously that even if prompted to avoid that (tried and refined multiple prompts, using different prompt format). \n Gpt3.5, Claude instant and Palm2-Bizon work fine for that task. (obviously GPT4 and Claude 2 would be best, but too expensive for me) \n I spent lots of time to make a solid embedding pipeline:\n  \nadvanced chunking, \n \nMetadata added by llm, text for similarity search different from text provided to LLM, \n \ninstructor bi encoder to generate embeddings(INSTRUCTOR-XL), \n \nreranking using cross encoder, \n \nRAG-Fusion using multiple query and HyDE approach\n \nHybrid search with BM25\n \n So... I'm a bit frustrated that i can not run all locally, became that is a must for my project.\n    submitted by    /u/Distinct-Target7503  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17erule/d_rag_oriented_finetune_searching_for_coherence/",
          "publishedOn": "2023-10-23T18:49:19.000Z",
          "wordCount": 2857,
          "title": "[D] RAG oriented fine-tune... Searching for coherence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ergjb/r_2x_the_context_length_of_alibi_through_position/",
          "author": null,
          "description": "https://arxiv.org/abs/2310.13017#\n Linear position interpolation helps pre-trained models using rotary position embeddings (RoPE) to extrapolate to longer sequence lengths. We propose using linear position interpolation to extend the extrapolation range of models using Attention with Linear Biases (ALiBi). We find position interpolation significantly improves extrapolation capability on upstream language modelling and downstream summarization and retrieval tasks.\n    submitted by    /u/jwan584  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ergjb/r_2x_the_context_length_of_alibi_through_position/",
          "publishedOn": "2023-10-23T18:32:28.000Z",
          "wordCount": 2591,
          "title": "[R] 2x the context length of ALiBi through position interpolation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eqh9u/d_how_to_make_research_publication_more/",
          "author": null,
          "description": "As context, I'm personally working on a project to make ML/AI research publication more reproducible. We're backed by Balaji Srinivasan (https://twitter.com/balajis) at the level of funding and advice.\n It seems like, despite attempts like Jupyter Notebooks or sites like Papers with Code, most published research in ML still isn't setup to be easily reproducible. Even companies like Anthropic/OpenAI don't put much of an emphasis on reproducibility, even though it's in their interest to do so to earn public trust.\n Our current hypothesis is to conceptualize reproducible research as software testing. Specifically we're thinking of building tools that let you internally test the robustness of results, and externally publish them s.t. they're reproducible.\n You can think of it as continuous integration for reproducible research; e.g. BuildBot for Reproducible Research.\n One specific idea I have is to build a model evaluation/testing platform that lets you:\n  \nInternally eval LLM models on open benchmarks (TruthfulQA, AGIEval, etc.)\n Test robustness of results under different assumptions\n Externally publish reproducible results\n  \nI don't have a background in ML research. So I'm looking to get input from research engineers on what challenges/barriers currently exist with model testing and publishing reproducibly — so I thought I'd reach out in this community if anyone's open to that!\n Let me know if this post doesn't conform to the rules, or if this should go somewhere else.\n    submitted by    /u/manveerbasra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eqh9u/d_how_to_make_research_publication_more/",
          "publishedOn": "2023-10-23T17:50:53.000Z",
          "wordCount": 2759,
          "title": "[D] How to make research publication more reproducible?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eq6q4/p_image_captioning_model/",
          "author": null,
          "description": "Hello everyone,\n I am currently trying to find suitable image captioning and visual question answering models to implement in my project. After a quick google search I came across BLIP2 from hugging face however, its a very large model overall and both my pc and colab could never load its lightest pretrained version. Does anyone know any similar pretrained models for the specific tasks or any other way to load this kind of large model? (I tried loading it with 8bit precision which still failed)\n I have 16gb of RAM and the task requires image captioning and the ability to ask the model details about the specific image.\n Any help is greatly appreciated!! \n    submitted by    /u/Spitefulsalamander  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eq6q4/p_image_captioning_model/",
          "publishedOn": "2023-10-23T17:37:50.000Z",
          "wordCount": 2640,
          "title": "[P] Image Captioning Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17epva7/d_episodic_training_vs_random_subsampling_in/",
          "author": null,
          "description": "I'm new to few-shot learning and I'm having trouble understanding why prototypical networks use a random sub-sampling approach while the vanilla few-shot learning approach uses episodic training. Doesn't random sub-sampling fail to guarantee that data overlapping won't occur?\n    submitted by    /u/The_Aoki_Taki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17epva7/d_episodic_training_vs_random_subsampling_in/",
          "publishedOn": "2023-10-23T17:23:50.000Z",
          "wordCount": 2573,
          "title": "[D] Episodic Training vs. Random Sub-Sampling in Few-Shot Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17epolm/d_hightemperature_softmax/",
          "author": null,
          "description": "I implemented a label propagation algorithm which is mainly used in the field of Video Object Segmentation (VOS). Basically I provide the labels for one frame and ask my model (using pre-trained encodings of frames) to do semantic segmentation on all the other frames of a video. \n I am obtaining consistently better results using an high temperature softmax when computing the similarity between pixels of different frames. Then the top-k similarities of each pixel (features) are used to propagate the labels from one frame to the next.\n I will not disclose the dataset I am using but let's say it is noisy (let's say also low quality). I want to understand why an high-temperature softmax performs better than a softmax with T=1 or an extreme T = 0.01. At the moment I get better results with T = 10, 100 and the trend in my grid search shows that even higher T could be possible. I was wondering if the model is still considerable valid if T is too high. I feel like the model is almost randomly guessing, if T is too high, but this apparently enhances performance.\n Every help is appreciated. Also literature about the topic! I only found one paper (which uses an high-temperature softmax to distill knowledge in a student-teacher network for remote sensing imagery) \n    submitted by    /u/darthjeio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17epolm/d_hightemperature_softmax/",
          "publishedOn": "2023-10-23T17:16:39.000Z",
          "wordCount": 2748,
          "title": "[D] High-temperature softmax",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17em1cl/d_callbacks_in_tensorflow_v1/",
          "author": null,
          "description": "Hi everyone, I have some old code written in tf1. It has not been ported to tf2 or pytorch yet. Does anyone of you have leads on whether one can implement custom callback for tf1 code and if there are any examples on the web? Thanks in advance.\n    submitted by    /u/wrik003  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17em1cl/d_callbacks_in_tensorflow_v1/",
          "publishedOn": "2023-10-23T14:43:16.000Z",
          "wordCount": 2579,
          "title": "[D] Callbacks in tensorflow v1",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ejtly/n_capivara_costefficient_approach_for_improving/",
          "author": null,
          "description": "In the tech report of GPT4, an analysis was conducted on the impact of different languages on model performance. These effects are attributed to the amount of data and language characteristics. This also indicates that the model's effectiveness may not meet the expectations of users in different languages. The problem addressed in this paper is of significant importance.\n https://preview.redd.it/s48419fe9yvb1.jpg?width=2748&format=pjpg&auto=webp&s=ba76f1bd18043c6cb2610ed90f5c41a78b5ccd95\n Arxiv: https://arxiv.org/abs/2310.13683v1\n Stay updated with AI in a fun-to-listen way. Check out ai-dailynews.com to generate your personalized news podcast🎙. It's one of my open-source projects and takes no charge.\n    submitted by    /u/xuying_li  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ejtly/n_capivara_costefficient_approach_for_improving/",
          "publishedOn": "2023-10-23T13:00:31.000Z",
          "wordCount": 2625,
          "title": "[N] CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP Performance on Low-Resource Languages",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ejp7r/n_neuralbase_music_generation_for_intelligence/",
          "author": null,
          "description": "The paper employs a deep learning system to learn from the great composer Beethoven and capture his composition ability in a hash-based knowledge base. This new form of knowledge base provides a reasoning facility to drive the music composition through a novel music generation method.\n https://preview.redd.it/l9gzcoe38yvb1.png?width=1944&format=png&auto=webp&s=d6c5ca7f8fe434be1187c1f0440c5a94ebfc9b64\n Arxiv: https://arxiv.org/abs/2310.13691v1\n For more AI updates, check out this AI-generated news podcast🎙 tailored to your preferences(ai-dailynews.com), which is open source and free.\n    submitted by    /u/xuying_li  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ejp7r/n_neuralbase_music_generation_for_intelligence/",
          "publishedOn": "2023-10-23T12:54:17.000Z",
          "wordCount": 2594,
          "title": "[N] Neural-Base Music Generation for Intelligence Duplication",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ej0pd/d_biclustering_with_the_same_row_and_column/",
          "author": null,
          "description": "The biclustering algorithm partitions rows and columns of a matrix into clusters so that the variance inside each intersection between row and column clusters in minimized.\n I want to perform the biclustering of a matrix, but additionally to enforce that the row and column clusters are the same, i.e. if the row i lies inside a row-cluster c then the column i must lie in a column-cluster c.\n Rows and columns in the matrix represent the same entities (but the matrix is non-simmetric).\n sklearn implementation does not support such a constraint.\n Are there any algorithms for this at all?\n    submitted by    /u/Tomarchelone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ej0pd/d_biclustering_with_the_same_row_and_column/",
          "publishedOn": "2023-10-23T12:19:08.000Z",
          "wordCount": 2634,
          "title": "[D] Biclustering with the same row and column clusters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ego7c/d_referenceless_nlp_evaluation/",
          "author": null,
          "description": "Hey all, I'm building this open source project that helps ML engineers evaluate LLM applications (its like unit testing for LLMs), and it works great in development since users can just write a test_file.py like how you would normally do it in pytest, but as I'm going onto the next phase I'm thinking how to bring evaluation to production, especially on metrics such as factual consistency where I need a ground truth. I'm hoping to get some ideas around this. \n Here's a link to the repo (https://github.com/confident-ai/deepeval) if you want more clarity on what the package looks like, but most importantly any help to brainstorm production evaluation will be greatly appreciated. Thank you very very much!\n    submitted by    /u/Ok_Constant_9886  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ego7c/d_referenceless_nlp_evaluation/",
          "publishedOn": "2023-10-23T09:55:02.000Z",
          "wordCount": 2646,
          "title": "[D] Referenceless NLP Evaluation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eak3w/d_is_computer_vision_dead_quo_vadis_computer/",
          "author": null,
          "description": "In ICCV23, several top notch researchers shared their insights (in a workshop called “Quo Vadis, Computer Vision?”) wrt the current state of Computer Vision, especially in light of the meteoric raise of LLMs. Has CV stalled? Is CV dead?\n E.g.MIT’s professor Bill Freeman, has some interesting points on foundation models: “FM aren’t fundamental, therefore not stable\". Jitendra Malik argues \"video can describe the world better than text.\"\n    submitted by    /u/btcmx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eak3w/d_is_computer_vision_dead_quo_vadis_computer/",
          "publishedOn": "2023-10-23T02:58:47.000Z",
          "wordCount": 2603,
          "title": "[D] Is Computer Vision dead? - “Quo Vadis, Computer Vision?”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ea25h/r_biologically_plausible_vision_models_for/",
          "author": null,
          "description": "Hey everyone! I am looking for papers that propose or explore biologically plausible vision models, primarily tasks like classification and grasping (predicting grasping bounding boxes) tasks. By biologically plausible, I mean papers that propose models inspired by the human brain in some way or the other. I know convolution is loosely inspired by human cognition, but everything I can find seems to suggest the opposite for ViT like models.\n I have come across certain papers like these: - https://arxiv.org/abs/1901.00945 - https://proceedings.neurips.cc/paper/2020/hash/98b17f068d5d9b7668e19fb8ae470841-Abstract.html\n But I am still looking for more. Any suggestions?\n    submitted by    /u/Far_Clothes_5054  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ea25h/r_biologically_plausible_vision_models_for/",
          "publishedOn": "2023-10-23T02:31:39.000Z",
          "wordCount": 2624,
          "title": "[R] Biologically plausible vision models for classification and grasping tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e9a24/d_understanding_the_math_behind_diffusion_models/",
          "author": null,
          "description": "I was trying to comprehend the math behind this paper: https://arxiv.org/pdf/2006.11239.pdf. You can see in the equation corresponding to the forward diffusion process, at each time step, the image in the previous step is also scaled by sqrt(1-beta_t) while adding noise. It seems like the purpose of this is to maintain a fixed variance (or specifically, unit variance) at each time step. My question is: What is the significance of maintaining unit variance at each time step? Why is this useful? I saw somewhere that this is done to prevent the variance from \"exploding.\" I don't really know what this means. I guess the variance keeps on increasing if the scaling isn't done. But why is this bad?\n    submitted by    /u/fallendeviL701b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e9a24/d_understanding_the_math_behind_diffusion_models/",
          "publishedOn": "2023-10-23T01:51:36.000Z",
          "wordCount": 2645,
          "title": "[D] Understanding the math behind diffusion models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e7kac/d_neural_attention_one_simple_example_that/",
          "author": null,
          "description": "submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e7kac/d_neural_attention_one_simple_example_that/",
          "publishedOn": "2023-10-23T00:23:38.000Z",
          "wordCount": 2550,
          "title": "[D] Neural Attention - One simple example that explains everything you need to know",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e79a6/d_has_anyone_tried_deploying_fastapi_v2_with_a/",
          "author": null,
          "description": "I'm not sure how to enable BERT with flash attention during the start-up of the Triton server in order to accelerate inference.\n Dao(the author of FA) told me he’s never tried.\n    submitted by    /u/g14loops  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e79a6/d_has_anyone_tried_deploying_fastapi_v2_with_a/",
          "publishedOn": "2023-10-23T00:08:23.000Z",
          "wordCount": 2586,
          "title": "[D] Has anyone tried deploying FastAPI v2 with a BERT model on the NVIDIA Triton Inference Server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e69f4/p_having_gpt4_iterate_on_unit_tests_like_a_human/",
          "author": null,
          "description": "Hi r/MachineLearning, \n My name is William and I’m one of the founders of Sweep.\n Sweep is an AI junior developer that writes and fixes code by mirroring how a developer works.\n While building Sweep, we used to use the Github API, but we ran into rate limits, so we changed this to clone your repository for the duration of the request.\n It's now coming full circle. Sweep can now write, run, and debug a failing unit test for the ClonedRepo class!\n Blog: https://docs.sweep.dev/blogs/ai-unit-tests\n Video: https://www.youtube.com/watch?v=N9PUxmja9z4\n    submitted by    /u/williamsweep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e69f4/p_having_gpt4_iterate_on_unit_tests_like_a_human/",
          "publishedOn": "2023-10-22T23:19:21.000Z",
          "wordCount": 2632,
          "title": "[P] Having GPT-4 Iterate on Unit Tests like a Human",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e59k3/d_structured_learning_resources_for_ml_theory/",
          "author": null,
          "description": "So essentially what the title says. I want to truly understand whats happening behind Machine Learning in general and also behind each algorithm specifically (starting from the basics to more advanced things, like Logistic Regression, Decisions trees and random forests, Deep Learning, NLP, GANS...). \n By structured I mean it contains all the pieces ordered and organized, from the same source, so you can can actually go from the building blocks up, not just a YouTune channel that uploads interesting videos about different machine learning related topics.\n Regarding the medium, I don't really mind but I would prefer audiovisual content (YT channel/playlists, Lectures, conferences...) but if you really recommend a specific book or series of books that's also okay.\n If it has some practical focus to it (to better grasp the theory) that would great. Also, I would prefer if it goes deep into the details, but not too deep into the specific maths involved, but if it's the case thats also okay. \n Regarding price, obviously if it's free that would be awesome, but in the range of free to 40€ is fine.\n Thank you for your recommendations in advance!!\n    submitted by    /u/aleradamantis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e59k3/d_structured_learning_resources_for_ml_theory/",
          "publishedOn": "2023-10-22T22:31:41.000Z",
          "wordCount": 2734,
          "title": "[D] Structured learning resources for ML Theory",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e3fjq/url_phishing_or_benign_using_deep_learning/",
          "author": null,
          "description": "Guys does anyone have an idea why my model does not work and it's like 50-50 chance to get it right. I'm getting really frustrated. Here is the code so far:\n ​\n import pandas as pd import torch import torch.nn as nn import torch.optim as optim from torch.utils.data import Dataset, DataLoader from collections import Counter from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score import re from imblearn.under_sampling import RandomUnderSampler # Loading the data file_path = \"C:/Users/alex/Desktop/DATASET/malicious_phish.csv\" data = pd.read_csv(file_path) # Filtering data filtered_data = data[data['type'].isin(['phishing', 'benign'])] # Undersampling the majority class rus = RandomUnderSampler(rand…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e3fjq/url_phishing_or_benign_using_deep_learning/",
          "publishedOn": "2023-10-22T21:11:28.000Z",
          "wordCount": 3643,
          "title": "URL PHISHING OR BENIGN USING DEEP LEARNING \"[Research]\", \"[R]\", \"[Project]\", \"[P]\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e1vxj/d_pretraining_a_4bit_model_not_finetunning/",
          "author": null,
          "description": "Pre-Training using 4bit (NOT fine-tunning)\n Hello community!\n I have been messing around with open source LLM's running them locally using peft and AutoGPTQ in Transformers. I even trained a few QLora models (my favorite part)\n However my question is this, given the performance of a 4bit model why hasn't there been any research in this area? Is it possible to even create a new model using 4bit altogether? I am sure it's not as easy as it sounds but I haven't seen anyone try. Just curious cause it will open doors for many of us with consumer grade hardware. \n Thanks!\n    submitted by    /u/Delicious-Farmer-234  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e1vxj/d_pretraining_a_4bit_model_not_finetunning/",
          "publishedOn": "2023-10-22T20:02:36.000Z",
          "wordCount": 2646,
          "title": "[D] - Pre-Training a 4bit model (NOT Fine-tunning)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dzira/p_infinity_a_foss_project_for_supporting_rag_for/",
          "author": null,
          "description": "https://github.com/michaelfeil/infinity\n Infinity, a open source REST API for serving vector embeddings, using a torch / ctranslate2 backend. Its under MIT License, fully tested and available under GitHub.\n I am the main author, curious to get your feedback.\n FYI: Huggingface launched a couple of days after me a similar project (\"text-embeddings-inference\"), under a non open-source and non-commercial license. \n    submitted by    /u/OrganicMesh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dzira/p_infinity_a_foss_project_for_supporting_rag_for/",
          "publishedOn": "2023-10-22T18:15:13.000Z",
          "wordCount": 2605,
          "title": "[P] Infinity, a FOSS project for supporting RAG for LLMs and Vector Embeddings.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dyh5o/r_combining_thermodynamics_and_diffusion_models/",
          "author": null,
          "description": "Researchers from Yonsei University and UC Berkeley recently developed a new AI method for enabling autonomous robots to navigate unfamiliar environments filled with obstacles using only visual data as input.\n The key innovation is a customized diffusion model. Diffusion models can generate diverse motion plans by adding controlled noise. The researchers tailored the model to mimic how heat avoids insulation when dispersing through space. \n Similar to heat navigating around insulators, this \"collision-avoiding\" diffusion model learns to predict robot motions that avoid collisions with obstacles. It generates reachable goals and viable motion plans to those goals simultaneously.\n In simulations, this approach achieved ~98% success rates in navigating to target destinations while avoiding randomly generated obstacles using only visual map images as input.\n While extensive real-world testing is still needed (only 2D, only simulation), these initial results showcase promising capabilities:\n  \nEnables navigation in unfamiliar environments without pre-mapping.\n Flexibly identifies and progresses toward reachable goals.\n Avoids unnecessary sensing systems for obstacle avoidance.\n Learns complex collision avoidance heuristics from visual data.\n  \nI like the thermo + AI + robotics combination here - takes me back to my days in aerospace engineering. Pretty interesting approach.\n Full summary is here. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dyh5o/r_combining_thermodynamics_and_diffusion_models/",
          "publishedOn": "2023-10-22T17:28:44.000Z",
          "wordCount": 2745,
          "title": "[R] Combining Thermodynamics and Diffusion Models for Collision-Free Robot Motion Planning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dy5m3/r_speeding_up_open_source_llms_with_speculative/",
          "author": null,
          "description": "submitted by    /u/firef1y1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dy5m3/r_speeding_up_open_source_llms_with_speculative/",
          "publishedOn": "2023-10-22T17:14:06.000Z",
          "wordCount": 2558,
          "title": "[R] Speeding up open source LLMs with speculative decoding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dvv12/p_open_source_ai_repos_that_caught_my_this_week/",
          "author": null,
          "description": "@MetaGPT_ github.com/geekan/MetaGPT - multi agent collaboration - MetaGPT encodes Standard Operating Procedures (SOPs) into prompts. The claim is that it takes a one line requirement as input and outputs user stories / competitive analysis / requirements / data structures / APIs / documents, etc.\n @Ollama_ai github.com/jmorganca/olla… - run large language models locally. The future of AI/LLMs may not be on the cloud, but on your own laptops/mobiles. ollama.ai/blog/building-…\n @huggingface github.com/huggingface/ca… - slick ML framework for Rust with a focus on performance (including GPU support)\n @remilouf github.com/outlines-dev/o… - helps developers guide text generation to build robust interfaces with external systems. Provides generation methods that guarantee that the output will match a regular expressions, or follow a JSON schema.\n github.com/YiVal/YiVal enterprise AI platform\n    submitted by    /u/oana77oo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dvv12/p_open_source_ai_repos_that_caught_my_this_week/",
          "publishedOn": "2023-10-22T15:29:38.000Z",
          "wordCount": 2683,
          "title": "[P] Open Source AI repos that caught my 👀 this week",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dv7m3/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dv7m3/d_simple_questions_thread/",
          "publishedOn": "2023-10-22T15:00:28.000Z",
          "wordCount": 2591,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dtsoi/d_teachers_struggle_to_adapt_amid_ai_revolution/",
          "author": null,
          "description": "submitted by    /u/DutchTechJunkie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dtsoi/d_teachers_struggle_to_adapt_amid_ai_revolution/",
          "publishedOn": "2023-10-22T13:53:24.000Z",
          "wordCount": 2559,
          "title": "[D] Teachers struggle to adapt amid AI revolution in education",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dtd2q/r_language_interaction_to_assist_in_composing_and/",
          "author": null,
          "description": "Hey guys, I found an interesting paper recently. Universities in the UK introduced Loop Copilot, enabling users to generate and iteratively refine music through an interactive, multi-round dialogue interface.\n Using language interaction to assist in composing music is very appealing, AI makes a complex workflow easy and automated.\n https://preview.redd.it/nzvlgevcarvb1.jpg?width=998&format=pjpg&auto=webp&s=815e0f48c299831700215ebdb4257423e317f5ec\n    submitted by    /u/xuying_li  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dtd2q/r_language_interaction_to_assist_in_composing_and/",
          "publishedOn": "2023-10-22T13:31:31.000Z",
          "wordCount": 2596,
          "title": "[R] Language interaction to assist in composing and refining music",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17drtnu/d_how_to_account_for_extreme_periods_in_time/",
          "author": null,
          "description": "I am performing a (machine learning) time series forecast on monthly data from the last 20 years. If I separate my data into a train, validation, and test set, the validation set is almost completely filled with extreme values due to the Covid period. How to account for this? \n    submitted by    /u/Ambitious-Pay6329  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17drtnu/d_how_to_account_for_extreme_periods_in_time/",
          "publishedOn": "2023-10-22T12:09:19.000Z",
          "wordCount": 2598,
          "title": "[D] How to account for extreme periods in time series forecasting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17drrqt/p_graphing_emotion_events_with_lms_for_indepth/",
          "author": null,
          "description": "submitted by    /u/helliun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17drrqt/p_graphing_emotion_events_with_lms_for_indepth/",
          "publishedOn": "2023-10-22T12:06:00.000Z",
          "wordCount": 2546,
          "title": "[P] Graphing emotion events with LMs for in-depth sentiment analysis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dr1us/d_dinov2_breakdown_ive_created_a_visual_guide_to/",
          "author": null,
          "description": "submitted by    /u/CkmCpvis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dr1us/d_dinov2_breakdown_ive_created_a_visual_guide_to/",
          "publishedOn": "2023-10-22T11:20:26.000Z",
          "wordCount": 2553,
          "title": "[D] DINOv2 Breakdown: I've Created a Visual Guide to the Model's Design & a Concise Code Walkthrough",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dplxw/r_do_you_read_mldlai_related_scientific_papers/",
          "author": null,
          "description": "As the title says. Recently, I found a review paper where the authors showed an exponential growth of published papers related to ML or DL. I was wondering if you even read those. If yes what's your way to find good and reliable papers? Do you choose only ones with a significant number of citations? Or just strictly related to your field? If no, why not? \n https://preview.redd.it/jwjvej5f5qvb1.jpg?width=1080&format=pjpg&auto=webp&s=bf3f7e08e0fe09fe0c6a6fd8d194945b45f5858e\n    submitted by    /u/hahahaczyk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dplxw/r_do_you_read_mldlai_related_scientific_papers/",
          "publishedOn": "2023-10-22T09:40:37.000Z",
          "wordCount": 2617,
          "title": "[R] Do you read ML/DL/AI related scientific papers? How do you filter them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dpcpu/r_opensource_projects_on_detecting_landmines/",
          "author": null,
          "description": "I know that there are a lot of efforts at the moment to improve the algorithms used for landmine detection.\n Is anyone aware of any ongoing open-source projects in this space?\n    submitted by    /u/Eightstream  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dpcpu/r_opensource_projects_on_detecting_landmines/",
          "publishedOn": "2023-10-22T09:21:43.000Z",
          "wordCount": 2575,
          "title": "[R] Open-Source Projects on Detecting Landmines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dp96m/r_demo_of_flowlenia_towards_openended_evolution/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dp96m/r_demo_of_flowlenia_towards_openended_evolution/",
          "publishedOn": "2023-10-22T09:14:51.000Z",
          "wordCount": 2558,
          "title": "[R] Demo of “Flow-Lenia: Towards open-ended evolution in cellular automata through mass conservation and parameter localization” (link to paper in the comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dofue/german_researchers_create_deepmb_for_faster/",
          "author": null,
          "description": "Researchers from Germany have developed DeepMB, a groundbreaking deep-learning framework enabling high-quality and real-time optoacoustic imaging via multispectral optoacoustic tomography (MSOT). With potentially transformative implications for health care, this innovation might redefine medical imaging standards.\n To stay ahead of developments in AI, look here first.\n DeepMB breakthrough\n  \nDeepMB resolves the longstanding tradeoff between image quality and speed in medical imaging.\n The deep-learning framework uses a deep neural network for model-based reconstruction, allowing for fast, high-quality imaging.\n DeepMB can reconstruct images approximately 1000 times faster than conventional techniques, with virtually no loss in image quality.\n  \nImpressive metrics and implications\n  \nThe researchers accomplished accurate optoacoustic image reconstruction in just 31 milliseconds per image by training the system to pairingly synthesize optoacoustic signals with ground-truth images.\n DeepMB promises to equip clinicians with immediate access to high-quality MSOT images, regardless of the patient's condition or scanned body area.\n The technology could extend to other imaging modalities, such as ultrasound, x-ray, and MRI, potentially changing how diseases are diagnosed and treated.\n  \nExciting prospects\n  \nThe development of DeepMB is a significant leap in optoacoustic imaging, promising to enhance healthcare outcomes.\n As DeepMB evolves, it could become integral to modern medical imaging, delivering high-quality results at previously unattainable speeds.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that unpacks the most significant news and research in AI. Google, Meta, and OpenAI professionals are already subscribed\n    submitted by    /u/orthomax23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dofue/german_researchers_create_deepmb_for_faster/",
          "publishedOn": "2023-10-22T08:14:08.000Z",
          "wordCount": 2782,
          "title": "German researchers create DeepMB for faster, high-quality optoacoustic imaging [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dnwte/d_forecastnet_neural_pdes_perform_global_weather/",
          "author": null,
          "description": "submitted by    /u/moschles  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dnwte/d_forecastnet_neural_pdes_perform_global_weather/",
          "publishedOn": "2023-10-22T07:36:20.000Z",
          "wordCount": 2568,
          "title": "[D] ForeCastNet. Neural PDEs perform global weather simulation 4 to 5 orders of magnitude faster than traditional numerical methods.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17djn1u/data_labeling_service_for_keypoints_pose_d/",
          "author": null,
          "description": "I was previously using scale.ai but they have been extraordinarily slow. Does anyone have recommendations for services to label keypoints or pose? \n Bonus points if the labeling service is able to handle 3D / multi angle data coming from multiple cameras. \n I work in an academic lab and scale is <10k images per batch.\n    submitted by    /u/researchrig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17djn1u/data_labeling_service_for_keypoints_pose_d/",
          "publishedOn": "2023-10-22T03:01:25.000Z",
          "wordCount": 2594,
          "title": "Data labeling service for keypoints / pose [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dgtsr/d_need_help_with_texttosong_diffusion_model/",
          "author": null,
          "description": "Hey, I want to make a text-to-song diff model, but I can't figure out the architecture\n I have already prepared a dataset of about 5000 songs of different genres, artists. It only contains the lyrics, the genre and the song itself\n Do I understand correctly that I should just encode the text and genre into one vector using CLIP and hope that the model will directly follow it (not skipping words and lines), or should I somehow make timestamps in the dataset (when, where and what text is sung)?\n I was inspired by Chirp V1\n    submitted by    /u/Head-Selection-9785  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dgtsr/d_need_help_with_texttosong_diffusion_model/",
          "publishedOn": "2023-10-22T00:32:16.000Z",
          "wordCount": 2641,
          "title": "[D] Need help with text-to-song diffusion model architecture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17db7m3/d_prml_reading_buddy/",
          "author": null,
          "description": "Hey there mates,\n I am a 3rd year PhD student, trying to break into good quality research (tired of trying different permutations ans combinations of X and Ys, and hitting dead end when things don't work, or worse -- being unable to explain why things work :D).\n I have recently decided to read PRML cover to cover (slowly) and do some of the exercises as well. Goal is to finish in 6 months (2 chapters per month). \n Is there anyone on a similar journey, would love to tag along and discuss nuances?\n    submitted by    /u/Zealousideal_Yak9131  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17db7m3/d_prml_reading_buddy/",
          "publishedOn": "2023-10-21T20:08:53.000Z",
          "wordCount": 2634,
          "title": "[D] PRML reading buddy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17db5af/d_what_do_you_all_think_of_these_pearls_of_wisdom/",
          "author": null,
          "description": "About the latest Jason Wei’s tweet.\n    submitted by    /u/mildlyphd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17db5af/d_what_do_you_all_think_of_these_pearls_of_wisdom/",
          "publishedOn": "2023-10-21T20:05:54.000Z",
          "wordCount": 2559,
          "title": "[D] What do you all think of these pearls of wisdom on “Doing Great Research”?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dad67/d_which_is_the_best_physics_engine_for/",
          "author": null,
          "description": "What are some of the best physics engine that we should be using to implement physics for complex reinforcement related tasks(like humanoid motions) ?? I came across mujoco, physx , pybullet, issac etc but not sure which to go with. Isaac seems to be something very interesting but the minimun requirements as per the website is 32gb of RAM which is way to much for me (I use a 8gb one). mujoco is good but the docs are very confusing and hard to get through.\n what do you believe is the best choice to go with??\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dad67/d_which_is_the_best_physics_engine_for/",
          "publishedOn": "2023-10-21T19:29:15.000Z",
          "wordCount": 2644,
          "title": "[D] Which is the best physics engine for reinforcement learning??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d9sdk/d_ensemble_of_strong_vs_weak_predictors/",
          "author": null,
          "description": "This crossed my mind recently and after searching online I couldn't find a concrete answer: would an ensemble composed of strong predictors (let's say training on 1 model of that type had a high metric performance) perform better than an ensemble composed of weak predictors?\n Bonus: are there any resources that would support your position you can link below?\n    submitted by    /u/robml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d9sdk/d_ensemble_of_strong_vs_weak_predictors/",
          "publishedOn": "2023-10-21T19:02:30.000Z",
          "wordCount": 2604,
          "title": "[D] Ensemble of Strong vs Weak Predictors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d8lrb/r_decoupling_features_and_classes_with/",
          "author": null,
          "description": "submitted by    /u/4rtemi5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d8lrb/r_decoupling_features_and_classes_with/",
          "publishedOn": "2023-10-21T18:08:42.000Z",
          "wordCount": 2558,
          "title": "[R] Decoupling Features and Classes with Self-Organizing Class Embeddings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d77b3/p_d_hierarchical_agent_learns_all_possible/",
          "author": null,
          "description": "Here's my implementation of an idea I had many years ago: a Sensorimotor Inference Engine. A machine that explores the states space of an environment, learning how to traverse the state space, learning how to manipulate the environment, which when given a goal can manipulate the environment in accordance to the goal.\n In other words, it's an agent which learns not one policy, but all possible policies. Doing so, I believe requires a hierarchy: layers of the same structure which learn broader and broader contexts of the environment.\n I have recently attempted to design an extremely simple, and modularized version of this agent: The Encoder-Predictor-Actor circuit.\n I need feedback, do you think it would work? if it might work, how might I train the Actor model? I think I know how to train the Encoder and Predictor models, but the Actor model will be harder to train, so if you have any ideas I'd love to hear from you!\n ps. sorry for the typos in the image text.\n a first-pass diagram of the 'simplest' implementation of a sensorimotor inference engine: the encoder-predictor-actor circuit\n    submitted by    /u/Stack3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d77b3/p_d_hierarchical_agent_learns_all_possible/",
          "publishedOn": "2023-10-21T17:04:27.000Z",
          "wordCount": 2733,
          "title": "[P] [D] Hierarchical agent learns all possible policies. Would this implementation work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d6xk9/career_suggestions_d/",
          "author": null,
          "description": "Hi there,\n I need some suggestions from you experts. I am an aerospace engineer (both BSc and MSc), with a university minor in AI. It's pretty clear to me that I should have studied computer science given my passion for this world. In the last 4 years I worked as engineer in a major aerospace company, and I managed to get back on track with computer science and ML by working as a data scientist and doing ML projects applied to space, while also practicing with LLM agents. My dream is to enter the AGI world, maybe working as an \"AI engineer\", or working on creating true \"autonomous\" systems, leveraging multi-modal models maybe. What do you suggest I should focus on to reach this goal? Getting first some \"credit\" as an ML engineer though courses and certifications, open source projects, or maybe applying right now to some startups in the field?\n Thanks guys!\n    submitted by    /u/cappellino1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d6xk9/career_suggestions_d/",
          "publishedOn": "2023-10-21T16:52:00.000Z",
          "wordCount": 2694,
          "title": "Career suggestions [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d6dw2/arxiv_dives_generating_speech_from_text_with_fast/",
          "author": null,
          "description": "We’ve been diving deep into Arxiv Papers as a team on Fridays, hope it’s helpful and feel free to join live if you like the format!\n    submitted by    /u/FallMindless3563  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d6dw2/arxiv_dives_generating_speech_from_text_with_fast/",
          "publishedOn": "2023-10-21T16:26:52.000Z",
          "wordCount": 2587,
          "title": "A[r]xiv Dives - Generating Speech from Text with Fast Speech-2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d66j7/r_eureka_humanlevel_reward_design_via_coding/",
          "author": null,
          "description": "submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d66j7/r_eureka_humanlevel_reward_design_via_coding/",
          "publishedOn": "2023-10-21T16:17:47.000Z",
          "wordCount": 2548,
          "title": "[R] Eureka: Human-Level Reward Design via Coding Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d5r40/computer_vision_project_ideas_project/",
          "author": null,
          "description": "I am taking the computer vision course at my university. We have to do a final project but I am unable to come up with concrete ideas.\n These are the options:\n • Select a paper from the computer vision literature, implement and test the approach described in that paper\n • Take publicly available code, apply it to an interesting novel dataset and explore various extensions and modifications. You may also want to compare two or more systems. Running existing code on the data provided by the authors is not sufficient.\n • Design and implement a solution to a problem that interests you. This may earn you extra credits.\n Can anyone please help with what to do?\n    submitted by    /u/kxenak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d5r40/computer_vision_project_ideas_project/",
          "publishedOn": "2023-10-21T15:59:06.000Z",
          "wordCount": 2659,
          "title": "Computer Vision Project Ideas [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d40et/d_can_you_use_a_different_dataset_to_run_ablation/",
          "author": null,
          "description": "I am on a computer vision algorithm and I will be benchmarking my method on the MS COCO dataset, like the other methods that have been proposed for the same problem.\n I want to know if I can use a smaller dataset (COCO minitrain) for my ablation experiments to demonstrate the efficacy of the different components used in my algorithm and to save time and cost, or will that be a red flag to journal reviewers?\n    submitted by    /u/notEVOLVED  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d40et/d_can_you_use_a_different_dataset_to_run_ablation/",
          "publishedOn": "2023-10-21T14:38:08.000Z",
          "wordCount": 2625,
          "title": "[D] Can you use a different dataset to run ablation experiments?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d3s76/searching_pinecone_for_relative_date_information_r/",
          "author": null,
          "description": "I am embedding with gpt and upserting large medical reports into pinecone and then would like to query for chronological result. For example, I upload a report that consists of 10 office visits. I would like to know the date and results of the first visit and then the last visit. when I embed a query containing: How did the patient describe their pain in the last office visit in the text? pinecone doesn't understand the context of 'last' since it is just doing cosine likeness. It pulls pain information but doesn't have a clue which comes first. Any help would be greatly appreciated. \n    submitted by    /u/Silent_Case_3058  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d3s76/searching_pinecone_for_relative_date_information_r/",
          "publishedOn": "2023-10-21T14:27:09.000Z",
          "wordCount": 2649,
          "title": "Searching pinecone for relative date information [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d2olz/p_wizard101_autobuyer_scriptbot_using_ocr_opencv/",
          "author": null,
          "description": "submitted by    /u/HistorianCrafty3514  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d2olz/p_wizard101_autobuyer_scriptbot_using_ocr_opencv/",
          "publishedOn": "2023-10-21T13:33:27.000Z",
          "wordCount": 2549,
          "title": "[P] Wizard101 Auto-Buyer Script/Bot - Using OCR, OpenCV Python with multiprocessor performance improvements",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d237n/p_d_rag_on_multilevel_tabular_data/",
          "author": null,
          "description": "Hi, Has anyone done RAG on a multi level tabular data? If yes then what problems have you faced and how did you solve those? My model gives better answers when I converted the data to a JSON and then embedded it. But I'm looking for a better approach.\n    submitted by    /u/Euphoric-Chart1428  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d237n/p_d_rag_on_multilevel_tabular_data/",
          "publishedOn": "2023-10-21T13:02:48.000Z",
          "wordCount": 2595,
          "title": "[P] [D] : RAG on multilevel tabular data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d1pdx/d_is_megabytes_padding_the_same_as_streamingllm/",
          "author": null,
          "description": "I was wondering after reading the recent streamingLLM paper https://arxiv.org/pdf/2309.17453.pdf if the attention sink they use through pre-training and inference is analogous to the learnable padding used in the MEGABYTE architecture https://arxiv.org/pdf/2305.07185.pdf although used for a different purpose? So if I just used MEGABYTE with sliding window attention at inference would it be the same as streamingLLM?\n    submitted by    /u/Additional-Ad-7043  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d1pdx/d_is_megabytes_padding_the_same_as_streamingllm/",
          "publishedOn": "2023-10-21T12:41:54.000Z",
          "wordCount": 2603,
          "title": "[D] Is Megabyte's padding the same as streamingLLM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d1nex/d_cloud_computing_vs_personal_for_ml/",
          "author": null,
          "description": "I need a new PC to run NN on. My training sets are about 50GB. \n Would I be best building my own, or using Google colab pro? Anyone know the specs equivalent to colab Pro?\n    submitted by    /u/ajplant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d1nex/d_cloud_computing_vs_personal_for_ml/",
          "publishedOn": "2023-10-21T12:38:59.000Z",
          "wordCount": 2580,
          "title": "[D] cloud computing vs personal for ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d0hae/d_what_is_the_current_sota_of_selfsupervised/",
          "author": null,
          "description": "I want to create a research proposal in this area. \n Ideally, I would like to work towards self-supervised models that take as input raw (not preprocessed) data of various modalities (text, image, video, audio, ...) and output a knowledge graph of all the data contained within. For example, I could feed it the Wikipedia article about dogs and it spits back all the information contained within, structured in the form of a graph.\n For people who work in the same general area can you point me to the SOTA models/efforts and research groups that work in this area? And can you also highlight the current challenges to be overcome, if you are deep enough to know?\n ​\n    submitted by    /u/KlutzyBiz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d0hae/d_what_is_the_current_sota_of_selfsupervised/",
          "publishedOn": "2023-10-21T11:29:33.000Z",
          "wordCount": null,
          "title": "[D] What is the current SOTA of self-supervised knowledge graph models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cydgj/d_encoder_vs_decoder_transformer_for_token/",
          "author": null,
          "description": "Hi. I am working on TokenClassification problem which requires significant language understanding in the base model and was wondering if:- \n  \nIs there any research that has shown on multiple datasets that encoder-only pretraining tasks produce more optimal results when finetuned for Token Classification tasks compared to decoder-only with same parameter sized models.\n Since a lot of LLM research is focused on text generation, most model are trained on decoder-only pretraining tasks, so what is the largest encoder-only pretrained model that is trained on >1T tokens.\n If encoder-only models do indeed produce more optimal results for Token Classification is there any empirical rule w.r.t. to parameter size that we can expect decoder-only to outperform encode-only models. (Eg. say 3B decoder-only is equivalent to 1B encoder-only with similar pretraining and finetuning data)\n  \n   submitted by    /u/RemoteSaint  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cydgj/d_encoder_vs_decoder_transformer_for_token/",
          "publishedOn": "2023-10-21T09:04:57.000Z",
          "wordCount": 2676,
          "title": "[D] Encoder vs Decoder Transformer for Token Classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cy50l/d_need_some_practical_advice_on_choosing_from/",
          "author": null,
          "description": "Hi everyone. I would just like to discuss a few things. I've spent about 2 months studying CNNs on coursera from the Deep Learning Specialization. In this time period I learnt the fundamentals and mechanisms of how CNNs work. I also took lectures on a few research papers that studied a few classical CNN models like AlexNet, LeNet-5, VGG-16. And then a few research papers that studied advanced stuff like ResNets, Inception Network, MobileNet, EfficientNet etc. Following that I studied Detection Algorithms, with a primary focus on YOLO Algorithm. I also briefly studied Regional Proposals, Semantic Segmentation, R-CNN, Fast-RCNN, Faster R-CNN, U-Net. I also learnt Face Recognition and Verification Models like Siamese Network using Triplet Loss function and Binary Classification. And also cove…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cy50l/d_need_some_practical_advice_on_choosing_from/",
          "publishedOn": "2023-10-21T08:47:28.000Z",
          "wordCount": 2900,
          "title": "[D] Need some practical advice on choosing from different CNN model architectures.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cy0j7/d_p_web_browsing_uibased_ai_agent_gpt4vact/",
          "author": null,
          "description": "Github: GPT-4V-Act\n (A demo video can be found on the Github)\n Hi there!\n I'd like to share with you a project I recently developed. My inspiration came from a recent post about Set-of-Mark visual grounding in GPT-4V. Fascinatingly, my tests showed that GPT-4V, equipped with this capability, could inspect a UI screenshot and provide the precise pixel coordinates needed for steering a mouse/keyboard to perform a specified task.\n Motivated by this, I built a proof-of-concept web browser embedded with a co-pilot that can \"view\" the browser and interact with it. Currently, the demo is basic, utilizing web-scraping to morph ChatGPT Plus into an unofficial GPT-4V API at the backend. It lacks some actions and an adblock, resulting in the agent potentially being overloaded by the extensive popups …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cy0j7/d_p_web_browsing_uibased_ai_agent_gpt4vact/",
          "publishedOn": "2023-10-21T08:37:59.000Z",
          "wordCount": 2871,
          "title": "[D] [P] Web browsing UI-based AI agent: GPT-4V-Act",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17coyym/d_is_lang_chain_the_right_solution/",
          "author": null,
          "description": "Hello, I would love to have an LLm that can provide answers (in chat format) based some of the sql db data we have. Want it for an internal company project. I am by no means an expert but decent in programming and want to build a system to get answers in chat format. My understanding is that training LLMs ground up is prohibitively expensive and langchains are sort of hybrid , efficient solutions. \n Please suggest any other solutions. Also would Langchain being a company and not open source pose a problem in terms of copyrights? Thanks!\n    submitted by    /u/betelgeuseian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17coyym/d_is_lang_chain_the_right_solution/",
          "publishedOn": "2023-10-20T23:43:31.000Z",
          "wordCount": 2642,
          "title": "[D] Is lang chain the right solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cojeh/r_memgpt_towards_llms_as_operating_systems_uc/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.08560\n Github: https://github.com/cpacker/MemGPT\n Blog: https://memgpt.ai/\n Youtube: https://youtu.be/QQ2QOPWZKVc?si=_bSSXU9EQE0FP64h\n MemGPT 🧠 Giving AI Unlimited Prompt Size (Big Step Towards AGI?) by Metthew Berman / Must watch and he also explains how to install it!\n Overview\n  \nLLMs are increasingly being used for perpetual chats\n Limited context lengths makes perpetual chat challenging\n MemGPT manages a virtual context (inspired by virtual memory in operating systems) to create unbounded LLM context\n With MemGPT, we demonstrate that LLMs can be taught to manage their own memory!\n  \nAbstract: \n  \nLarge language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversa…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cojeh/r_memgpt_towards_llms_as_operating_systems_uc/",
          "publishedOn": "2023-10-20T23:23:08.000Z",
          "wordCount": 2803,
          "title": "[R] MemGPT: Towards LLMs as Operating Systems - UC Berkeley 2023 - Is able to create unbounded/infinite LLM context!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cnvbn/d_some_beginner_questions_about_whisper_for/",
          "author": null,
          "description": "Hi,\n I am a mac user. I am trying to use whisper.cpp downloaded from its github file. I don't know much about phyton or coding so I basically followed this guide to install and use it. I downloaded the large model to try it. I am using it for non-English languages and I want to use it for language learning purposes so I can understand what is being said in an Instagram story or a Youtube video (without subtitles) or a tv series or an extract of movie etc. I was using Macwhisper but I wanted to try the pro features and I don't want to pay for it (for now) and try the pro models for non-English languages.\n My question is: all of my files that I want to transcribe are video files with .mp4 extension. Can I also transcribe those with whisper?\n If not, and if I can only transcribe audio files, can it be .mp3? I understand that I need to install and use ffmpeg. Does it support mp3?\n Also, as I understand, the transcripted text will appear in the terminal. Can I export it in -srt or pdf?\n Thanks\n    submitted by    /u/toughytough  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cnvbn/d_some_beginner_questions_about_whisper_for/",
          "publishedOn": "2023-10-20T22:52:07.000Z",
          "wordCount": 2739,
          "title": "[D] Some beginner questions about Whisper for transcription",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cmzcz/d_transformers_are_basically_cnns/",
          "author": null,
          "description": "I've watched an interesting video: Deriving the Ultimate Neural Network Architecture from Scratch. It's about how to come up to the transformer architecture when you have an understanding of CNNs.\n The crux of it is an idea of pairwise convolutional layers. The first layer applies not to the sequence of words itself, but to all pairs of words in the sentence. This ensures that each relation of words that are far from each other is taken into account.\n The next convolutional layer applies to all pairs of results of the previous one. This way longer subsequences of words are factored in.\n pairs of words\n My question is: are there any articles on how transformers were invented? I see a lot of explanations of the original paper, but at best they all answer the question how transformers work. But why is the architecture the way it is? Was it discovered like the video describes? Or the path was more convoluted? I'd like to know more about this connection.\n Anyway, it would be great to figure out in all details how these pairwise layers are related to the concepts of query, key, and value. Here's what the author of the video wrote in comments:\n  \nYeah it's a term I made up so you won't find it in any sources, sorry about that. Usually sources will just talk about self attention in terms of key, query and value lookups, so you can look at those to get a more detailed understanding of the transformer. The value transform is equivalent to the linear representation function I use in the pairwise convolution, the key and query attention scores are equivalent to the bi-linear form scoring function I use (with the bi-linear form weight matrix given by Q^TK). I chose to use this unusual terminology because, personally, I feel the key, query and value terminology comes out of nowhere, and I wanted to connect the transformer more directly to its predecessor (the CNN).\n  \n​\n    submitted by    /u/Veson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cmzcz/d_transformers_are_basically_cnns/",
          "publishedOn": "2023-10-20T22:11:27.000Z",
          "wordCount": 2870,
          "title": "[D] Transformers are basically CNNs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cmum1/r_does_this_learning_curve_show_any_serious/",
          "author": null,
          "description": "I'm trying to fit a multivariate LSTM model to time series data to predict future values for one relatively noisy series. I noticed that the the loss (mse in this case) is pretty high given that the data has been standardized beforehand. So I really have two questions: why is the mse so high and is the learning curve indicative of any obvious problems? Thank you!\n https://preview.redd.it/r9bel6p7kfvb1.png?width=547&format=png&auto=webp&s=4eee53aa8005da8a89f330f6e98fe6cadde3467e\n    submitted by    /u/DifferenceUnhappy393  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cmum1/r_does_this_learning_curve_show_any_serious/",
          "publishedOn": "2023-10-20T22:05:33.000Z",
          "wordCount": 2614,
          "title": "[R] Does this learning curve show any serious under/overfitting problems?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cmeqb/discussion_is_the_deadly_triad_real/",
          "author": null,
          "description": "Sutton and Barto’s textbook mentions that combing off-policy learning, bootstrapping, and function approximation leads to extreme instability and should be avoided. Yet when I encounter a reinforcement problem in the wild and look how people go about solving it, if someone’s solution involves bootstrapping more often than not it’s some variation of deep Q-learning. Why is this?\n    submitted by    /u/BiasedEstimators  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cmeqb/discussion_is_the_deadly_triad_real/",
          "publishedOn": "2023-10-20T21:46:12.000Z",
          "wordCount": null,
          "title": "[Discussion] Is the deadly triad real?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17clyw6/p_building_a_dd_npc/",
          "author": null,
          "description": "Hey everyone,\n I'm learning ML but i'm barely scratching the terminologies. 2 years ago I couldn't code anything but with school (python,sql and R) I learned fundamentals. I also have access to code academy. My current program is very machine learning/deep learning focused.\n On the side I DM a d&d game. Within the context of the world (eberron) robots are common. With my ADHD and being a new DM I want to outsource lore questions might have (that I would have to look up and slow down the game).\n The concept is to have a GUI and have the player interact with the chat bot. I've gotten to a proof of concept workflow. On Google colab. Thanks to langchain I managed to ingest pdfs and a url. Make then a directory, Embedded the text, bring it into a vector dB. Have the llm pull from the vector. Answer the question.\n Now I don't know what to do. I tried to bring the colab notebook onto Google cloud. But now cloud is becoming a rabbit home with vertex and docAI...and I don't want to deep dive into that, if it's a outside the scope of this \"project\"\n I'd appreciate any advice, links...etc. \n I got a limited success in botpress using a single pdf. It works but feel unsatisfying. N8N looks promising but if it's not intuitive then I don't want to go down that road.\n If I posted in the wrong group please direct me to the correct one.\n    submitted by    /u/work929  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17clyw6/p_building_a_dd_npc/",
          "publishedOn": "2023-10-20T21:27:15.000Z",
          "wordCount": 2791,
          "title": "[P] building a D&D NPC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cky1x/r_incontext_pretraining_language_modeling_beyond/",
          "author": null,
          "description": "https://arxiv.org/abs/2310.10638\n \"Large language models (LMs) are currently trained to predict tokens given document prefixes, enabling them to directly perform long-form generation and prompting-style tasks which can be reduced to document completion. Existing pretraining pipelines train LMs by concatenating random sets of short documents to create input contexts but the prior documents provide no signal for predicting the next document. We instead present In-Context Pretraining, a new approach where language models are pretrained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries. We can do In-Context Pretraining by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines. However, this document sorting problem is challenging. There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data. To do this, we introduce approximate algorithms for finding related documents with efficient nearest neighbor search and constructing coherent input contexts with a graph traversal algorithm. Our experiments show In-Context Pretraining offers a simple and scalable approach to significantly enhance LMs'performance: we see notable improvements in tasks that require more complex contextual reasoning, including in-context learning (+8%), reading comprehension (+15%), faithfulness to previous contexts (+16%), long-context reasoning (+5%), and retrieval augmentation (+9%).\"\n    submitted by    /u/Parking-Priority6217  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cky1x/r_incontext_pretraining_language_modeling_beyond/",
          "publishedOn": "2023-10-20T20:42:24.000Z",
          "wordCount": 2760,
          "title": "[R] In-Context Pretraining: Language Modeling Beyond Document Boundaries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cjth3/r_using_machine_learning_to_set_parameters_in/",
          "author": null,
          "description": "Greetings,\n I'm on my 2nd year of College (Artificial Intelligence bachelors degree), and currently making a group project that will require machine learning. The project consists of managing and regulating the conditions (temperature, humidity, lightning, etc.) of the environment that surrounds important products (vaccines, human organs, etc.) during their transportation, using sensors implemented in their transportation box. For that being possible, our group was planning to use a predictive model using machine learning, to prevent cases such as the exposure of inappropriate temperature levels, that could damage the product, and subsequently taking the appropriate measures to improve the environment, before it reaches such dangerous scenarios.\n Therefore, I would like to know which tools and skills will be needed and helpful in order to achieve such goal. If you have any advice, that'll be very much appreciated. :)\n    submitted by    /u/Storm2003  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cjth3/r_using_machine_learning_to_set_parameters_in/",
          "publishedOn": "2023-10-20T19:51:31.000Z",
          "wordCount": 2686,
          "title": "[R] Using Machine Learning to set parameters in sensors (College Project)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cgz5w/r_3dgpt_a_new_method_for_procedural_textto3d/",
          "author": null,
          "description": "Researchers propose a new AI system called 3D-GPT that creates 3D models by combining natural language instructions and agents specialized for working with existing 3D modeling tools.\n 3D-GPT has predefined functions that make 3D shapes, and it tweaks parameters to build scenes. The key is getting the AI to understand instructions and pick the right tools.\n It has three main agents:\n  \nA dispatcher that parses the text and picks generation functions\n A conceptualizer that adds details missing from the description\n A modeler that sets parameters and outputs code to drive 3D software\n  \nBy breaking modeling work down into steps, the agents can collab to match the descriptions. This is sort of like how a 3D modeling team of humans would work.\n The paper authors show it making simple scenes like \"lush meadow with flowers\" that fit the text. It also modifies scenes appropriately when given new instructions. I include some gifs of example outputs in my full summary. They look pretty good - I would say 2005-quality graphics.\n There are limits. It fully relies on existing generators, so quality is capped. Details and curves are iffy. It resorts to default shapes often instead of true understanding. And I doubt the verts and textures are well-optimized.\n The agent architecture seems to be really popular right now. This one shows some planning skills, which could extend to more creative tasks someday.\n TLDR: AI agents can team up to generate 3D models from text instructions. Works to some degree but limitations remain.\n Full summary. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cgz5w/r_3dgpt_a_new_method_for_procedural_textto3d/",
          "publishedOn": "2023-10-20T17:42:11.000Z",
          "wordCount": 2801,
          "title": "[R] 3D-GPT: A new method for procedural Text-to-3D model generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cdym9/r_bayesian_optimizationbased_combinatorial/",
          "author": null,
          "description": "Link: https://ojs.aaai.org/index.php/AAAI/article/view/25726/25498\n Abstract: We study the combinatorial assignment domain, which includes combinatorial auctions and course allocation. The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning-based preference elicitation algorithms that aim to elicit only the most important information from agents. However, the main shortcoming of this prior work is that it does not model a mechanism's uncertainty over values for not yet elicited bundles. In this paper, we address this shortcoming by presenting a Bayesian optimization-based combinatorial assignment (BOCA) mechanism. Our key technical contribution is to integrate a method for capturing model uncertainty into an iterative combinatorial auction mechanism. Concretely, we design a new method for estimating an upper uncertainty bound that can be used to define an acquisition function to determine the next query to the agents. This enables the mechanism to properly explore (and not just exploit) the bundle space during its preference elicitation phase. We run computational experiments in several spectrum auction domains to evaluate BOCA's performance. Our results show that BOCA achieves higher allocative efficiency than state-of-the-art approaches.\n https://preview.redd.it/aeo36u3wldvb1.png?width=1288&format=png&auto=webp&s=2982547f8af51ed7195f49dbec9359fecba1693f\n ​\n    submitted by    /u/Yossarian_1234  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cdym9/r_bayesian_optimizationbased_combinatorial/",
          "publishedOn": "2023-10-20T15:29:06.000Z",
          "wordCount": 2733,
          "title": "[R] Bayesian Optimization-based Combinatorial Assignment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cdt0r/d_what_is_the_latest_method_for_models_with/",
          "author": null,
          "description": "So a lot of multimodal models I've seen use a linear layer to transform encoded image/video/audio into the multimodal LLMs embedding space.\n This makes sense for the input, but how would output work?\n Normally you use a layer to convert the embedding to a SoftMax of probabilities of possible output tokens. This makes sense for discrete outputs like tokens but not for continuous outputs like images or audio.\n ​\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cdt0r/d_what_is_the_latest_method_for_models_with/",
          "publishedOn": "2023-10-20T15:22:10.000Z",
          "wordCount": 2638,
          "title": "[D] What is the latest method for models with multimodal outputs? How can the shared embedding used by a lot of multimodal models be dynamically \"routed\" to the proper modality during output?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cc8on/d_is_anyone_else_tired_of_whatever_openai_does_is/",
          "author": null,
          "description": "The title says it all. I agree what they did is incredible and literally changed AI landscape in last couple of years. But I’m getting tired of everyone acting like OpenAI is the only one doing great research. The twit-fluencers praising even the slightest peep from them. I don’t understand this fanaticism in AI community. There are smart researchers doing smart things all over the world. But they don’t even get a fraction of appreciation they deserve. And the strangest thing of all, ChatGPT is used as oracle to evaluate models in research papers. Consistency models are extremely meh and if it did not come out of openAI, people would’ve forgotten them a long time ago!\n Edit 1: I’m in grad school and that’s all a lot of students around me talk about/ chase. I want to work on a bit more fundamental problems, but I feel like I’m being left behind. \n Edit 2: This post is mostly a rant about academics obsessed with OpenAI research/products and LLMs. \n    submitted by    /u/mildlyphd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cc8on/d_is_anyone_else_tired_of_whatever_openai_does_is/",
          "publishedOn": "2023-10-20T14:12:12.000Z",
          "wordCount": 2719,
          "title": "[D] Is anyone else tired of “whatever OpenAI does is the best!” narrative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cacro/p_hacktoberfest_machine_learning_projects_for/",
          "author": null,
          "description": "Hey everyone,we have published an article about Hacktoberfest Projects 🎃 medium.com with a curated list of open-source machine learning GUI projects built with javascript or typescript.\n ​\n https://preview.redd.it/nr4jfbqoscvb1.png?width=1352&format=png&auto=webp&s=fbb2313aabf0a617b6e426f1fa5018946b7ed7f5\n 🔍 Finding machine learning projects that are suitable for JS/TS developers during Hacktoberfest can be daunting due to the overwhelming abundance of open-source projects. We’ve simplified this process, offering you a refined selection of opportunities where your coding skills can shine and make a real impact.\n The Selection includes:\n  \n Spotlight our powerful tool for intuitively exploring unstructured datasets directly from dataframes.\n Iteratives CML (Continuous Machine Learning) a command-line interface tool designed to enhance continuous integration and delivery (CI/CD) workflows.\n Inclusive Code Reviews: Browser Extension for improving online comments such as code reviews on Github or Azure DevOps.\n BeatBridge - A Music Player with a Recommendation Engine\n  \nEach project offers a unique blend of challenges and learning opportunities, inviting you to contribute and grow your skills and knowledge in the dynamic world of open source. Choose a project that resonates with you, select an issue, and make an impact 🚀.\n    submitted by    /u/DocBrownMS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cacro/p_hacktoberfest_machine_learning_projects_for/",
          "publishedOn": "2023-10-20T12:40:45.000Z",
          "wordCount": 2722,
          "title": "[P] Hacktoberfest Machine Learning Projects for JS/TS Developers 🎃",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c8aha/r_agenttuning_enabling_generalized_agent/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.12823\n Github: https://github.com/THUDM/AgentTuning\n Model: https://huggingface.co/THUDM/agentlm-70b\n Abstract:\n  \nOpen large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs. However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ LLMs as the central controller responsible for planning, memorization, and tool utilization, necessitating both fine-grained prompting methods and robust LLMs to achieve satisfactory performance. Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of L…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c8aha/r_agenttuning_enabling_generalized_agent/",
          "publishedOn": "2023-10-20T10:44:14.000Z",
          "wordCount": 2787,
          "title": "[R] AgentTuning: Enabling Generalized Agent Abilities for LLMs - Tsinghua University 2023 - Agent-tuned open model comparable to GPT-3.5-Turbo on unseen agent tasks!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c6dud/d_people_working_for_relatively_large/",
          "author": null,
          "description": "I'm wondering whether LLMs within your organisation are widely used (including non-programmers), and in an (official) capacity that prevents OpenAI/Microsoft or another third party from using the input. Here, I'm talking about access by a wide variety of employees, not including as part of a data pipeline that doesn't have a user interface and only performs one job.\n  \nDoes your organization have a custom-built interface with enterprise access to an LLM? Use one of the open-source interfaces, or does your organisation provide access through i.e. Microsoft copilot? What about access to Github copilot (for programmers)? Or does your organisation have some kind of SAAS solution?\n If you have some kind of RAG within the organisation that isn't built-in into a product. What sort of stack do you use? Do you use OpenAI plugins to access this?\n  \n   submitted by    /u/Background_Claim7907  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c6dud/d_people_working_for_relatively_large/",
          "publishedOn": "2023-10-20T08:36:06.000Z",
          "wordCount": 2692,
          "title": "[D] People working for (relatively) large organisations. How are LLMs accessed by employees within your organisation right now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c613y/d_thoughts_on_opendomain_qna_systems/",
          "author": null,
          "description": "Been really interested in Open-Domain Question Answering these days and saw some interesting new models apart from the typical Retriever-Reader e.g. Generator-Retriever-Generator. Anyone particularly excited about anything new in the field - some new technique/model etc.?\n    submitted by    /u/Aggravating-Floor-38  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c613y/d_thoughts_on_opendomain_qna_systems/",
          "publishedOn": "2023-10-20T08:10:48.000Z",
          "wordCount": 2580,
          "title": "[D] Thoughts on Open-Domain QnA Systems?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c5p6d/n_state_of_ai_report_2023/",
          "author": null,
          "description": "The State of AI Report for this year is out : https://www.stateof.ai/2023-report-launch\n A 160-slide presentation/report which seems quite exhaustive in the discussed topics, and provides a good view of the \"hottest\" research axes this year.\n Previous reports (yearly since 2019) are available on their website and have been generally well received in this sub. \n    submitted by    /u/ElkoSoltius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c5p6d/n_state_of_ai_report_2023/",
          "publishedOn": "2023-10-20T07:47:45.000Z",
          "wordCount": 2597,
          "title": "[N] State of AI Report 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c4jmx/r_large_language_models_as_analogical_reasoners/",
          "author": null,
          "description": "https://arxiv.org/abs/2310.01714\n \"Chain-of-thought (CoT) prompting for language models demonstrates impressive performance across reasoning tasks, but typically needs labeled exemplars of the reasoning process. In this work, we introduce a new prompting approach, Analogical Prompting, designed to automatically guide the reasoning process of large language models. Inspired by analogical reasoning, a cognitive process in which humans draw from relevant past experiences to tackle new problems, our approach prompts language models to self-generate relevant exemplars or knowledge in the context, before proceeding to solve the given problem. This method presents several advantages: it obviates the need for labeling or retrieving exemplars, offering generality and convenience; it can also tailor the generated exemplars and knowledge to each problem, offering adaptability. Experimental results show that our approach outperforms 0-shot CoT and manual few-shot CoT in a variety of reasoning tasks, including math problem solving in GSM8K and MATH, code generation in Codeforces, and other reasoning tasks in BIG-Bench.\"\n https://preview.redd.it/f9azq40pwavb1.jpg?width=6390&format=pjpg&auto=webp&s=0af3de7925a6ef8f442e40f952849db2f544c3a7\n    submitted by    /u/Parking-Priority6217  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c4jmx/r_large_language_models_as_analogical_reasoners/",
          "publishedOn": "2023-10-20T06:24:46.000Z",
          "wordCount": null,
          "title": "[R] Large Language Models as Analogical Reasoners",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c4io6/r_large_language_models_as_optimizers/",
          "author": null,
          "description": "https://arxiv.org/abs/2309.03409\n \"Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to prompt optimization where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.\"\n    submitted by    /u/Parking-Priority6217  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c4io6/r_large_language_models_as_optimizers/",
          "publishedOn": "2023-10-20T06:22:54.000Z",
          "wordCount": 2696,
          "title": "[R] Large Language Models as Optimizers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c3sf2/d_communities_thoughts_on_rsingularity_and_other/",
          "author": null,
          "description": "I’ve seen many comments telling people to go to r/singularity, so I’ve been wondering about the communities thoughts on non-technical subreddits. Are they seen as a source of hype, getting newcomers more interested in the field and helping to advance knowledge? Or do you see such communities as an overly optimistic non-skeptical massive misinformation/active disinformation center?\n Do you think there’s something that can be done to improve these communities? What do you think their role should be relative to the technical communities? Do you have any specific criticisms? For those of you who think our two communities should be separate to what extent?\n    submitted by    /u/Username912773  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c3sf2/d_communities_thoughts_on_rsingularity_and_other/",
          "publishedOn": "2023-10-20T05:34:04.000Z",
          "wordCount": 2652,
          "title": "[D] Communities thoughts on r/singularity and other non-technical machine learning subreddits?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bzbaq/r_neural_relation_graph_a_unified_framework_for/",
          "author": null,
          "description": "paper: https://arxiv.org/abs/2301.12321\n code: https://github.com/snu-mllab/Neural-Relation-Graph\n TDLR: We present a scalable and domain-agnostic approach utilizing the relational structure of data for identifying label noise and outliers\n https://preview.redd.it/o9k7kliqe9vb1.png?width=3108&format=png&auto=webp&s=b7c34bd7f4bc130915440986570104f9bebd4f07\n  \nDiagnosing and cleaning data is a crucial step for building robust machine learning systems. However, identifying problems within large-scale datasets with real-world distributions is challenging due to the presence of complex issues such as label errors, under-representation, and outliers. In this paper, we propose a unified approach for identifying the problematic data by utilizing a largely ignored source of information: a relational structure of data in the feature-embedded space. To this end, we present scalable and effective algorithms for detecting label errors and outlier data based on the relational graph structure of data. We further introduce a visualization tool that provides contextual information of a data point in the feature-embedded space, serving as an effective tool for interactively diagnosing data. We evaluate the label error and outlier/out-of-distribution (OOD) detection performances of our approach on the large-scale image, speech, and language domain tasks, including ImageNet, ESC-50, and SST2. Our approach achieves state-of-the-art detection performance on all tasks considered and demonstrates its effectiveness in debugging large-scale real-world datasets across various domains.\n  \n​\n Detected samples with label error (red colored) from ImageNet (top) and SST2 (bottom).\n ​\n Detected outlier samples from ImageNet (top) and SST2 (bottom) validation sets.\n    submitted by    /u/janghyun1230  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bzbaq/r_neural_relation_graph_a_unified_framework_for/",
          "publishedOn": "2023-10-20T01:25:47.000Z",
          "wordCount": 2771,
          "title": "[R] Neural Relation Graph: A Unified Framework for Identifying Label Noise and Outlier Data (NeurIPS 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bz4af/d_future_ai_development_on_accessible_hardware/",
          "author": null,
          "description": "Is there a future where models can run efficiently and at scale with just half a dozen high end consumer GPUs? A lot of people seem to think the bottleneck is \"there's no competition for NVIDIA\" but I actually think the current bottleneck is software. 4x 4090s is more CUDA cores, more transistors, more VRAM than a H100, but the performance and price difference is staggering, which should not be the case. Raspberry Pi 4s running faster desktops than a same generation Dell Inspiron prove that software integration is key. Cheap performance is laying on the table, it just has to be used more effectively by models and ML libraries\n    submitted by    /u/HovercraftForeign591  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bz4af/d_future_ai_development_on_accessible_hardware/",
          "publishedOn": "2023-10-20T01:16:07.000Z",
          "wordCount": 2655,
          "title": "[D] Future AI development on accessible hardware?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bxtt0/d_online_masters_alternatives_for_mlops/",
          "author": null,
          "description": "Hi everyone, greeting from south america..\n Basically I'm looking for an program to learn and improve my job opportunities in the MLOps field and at some point getting higher responsability positions. I recently got admitted for both OMSA and OMSCS from Gatech, but I feel those programs are more focused on the data science side of things.\n Is there any other alternative without GRE requeriment that you would recommend with a similar cost?\n Maybe I'm wrong about the aforementioned programs, if you think so, please let me know why.\n Thanks!\n    submitted by    /u/imatiasmb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bxtt0/d_online_masters_alternatives_for_mlops/",
          "publishedOn": "2023-10-20T00:12:41.000Z",
          "wordCount": 2634,
          "title": "[D] Online masters alternatives for MLOps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bwmw7/machine_learning_on_a_microcontroller_p/",
          "author": null,
          "description": "i am making an EEG machine for a university project, i will be taking in an analogue signal and converting it to digital, i then will be sending the varying voltages to a microcontroller in hopes that it will be able to catagorise them in either states of mind or as simply as telling whether or not the persons eyes are open or closed.\n i have very little knowledge on machine learning but it is required to be implemented in the project, my lecturer is pressuring me to have final pick of what software and microcontroller iw will be using for this project, everyone else in the class are using Edge Impulse which the lecturer said wouldn't be applicable to me as it uses accelerometers and voice. and are using CY8CKIT-042 PSoC 4 PIONEER KITS which apperently arent suited for me either.\n any help would be much appreciated and i do apologise if this is too rambly.\n    submitted by    /u/disslixac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bwmw7/machine_learning_on_a_microcontroller_p/",
          "publishedOn": "2023-10-19T23:16:16.000Z",
          "wordCount": 2701,
          "title": "machine learning on a microcontroller [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bwfq9/r_openagents_an_open_platform_for_language_agents/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.10634v1\n Github: https://github.com/xlang-ai/OpenAgents\n Abstract:\n  \nLanguage agents show potential in being capable of utilizing natural language for varied and intricate tasks in diverse environments, particularly when built upon large language models (LLMs). Current language agent frameworks aim to facilitate the construction of proof-of-concept language agents while neglecting the non-expert user access to agents and paying little attention to application-level designs. We present OpenAgents, an open platform for using and hosting language agents in the wild of everyday life. OpenAgents includes three agents: (1) Data Agent for data analysis with Python/SQL and data tools; (2) Plugins Agent with 200+ daily API tools; (3) Web Agent for autonomous web browsing. OpenAgents enables general users to interact with agent functionalities through a web user interface optimized for swift responses and common failures while offering developers and researchers a seamless deployment experience on local setups, providing a foundation for crafting innovative language agents and facilitating real-world evaluations. We elucidate the challenges and opportunities, aspiring to set a foundation for future research and development of real-world language agents. \n  \nhttps://preview.redd.it/syl2gzh3q8vb1.jpg?width=1084&format=pjpg&auto=webp&s=4045d3abb5cdb7587614795e709cdaba03bc122d\n https://preview.redd.it/aus342i3q8vb1.jpg?width=1086&format=pjpg&auto=webp&s=73de7976db5a8bbed880350fab8ab56be3fee550\n https://preview.redd.it/qstz81i3q8vb1.jpg?width=1346&format=pjpg&auto=webp&s=1626482556a90abf418abb5d56f8e5599cb1e3d6\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bwfq9/r_openagents_an_open_platform_for_language_agents/",
          "publishedOn": "2023-10-19T23:07:08.000Z",
          "wordCount": 2729,
          "title": "[R] OpenAgents: An Open Platform for Language Agents in the Wild - The University of Hong Kong 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bwbbs/research_hypernymybased_approach_for_texttoimage/",
          "author": null,
          "description": "Text-to-image models have rapidly progressed in recent years, but most popular evaluation metrics (such as FID) do not consider their linguistic abilities. A new approach measures how well these models understand subtype relations between concepts. Researchers from Yandex proposed two metrics that combine well-known tools like the WordNet database and ImageNet classifiers in a novel way, allowing them to analyze models like Stable Diffusion in more detail.\n Blog post.\n    submitted by    /u/metkere  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bwbbs/research_hypernymybased_approach_for_texttoimage/",
          "publishedOn": "2023-10-19T23:01:37.000Z",
          "wordCount": 2615,
          "title": "[Research] Hypernymy-based approach for text-to-image models (Blog post)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bvfpd/r_can_large_language_models_explain_themselves_a/",
          "author": null,
          "description": "Large language models (LLMs) such as ChatGPT have demonstrated superior performance on a variety of natural language processing (NLP) tasks including sentiment analysis, mathematical reasoning and summarization. Furthermore, since these models are instruction-tuned on human conversations to produce \"helpful\" responses, they can and often will produce explanations along with the response, which we call self-explanations. For example, when analyzing the sentiment of a movie review, the model may output not only the positivity of the sentiment, but also an explanation (e.g., by listing the sentiment-laden words such as \"fantastic\" and \"memorable\" in the review). How good are these automatically generated self-explanations? In this paper, we investigate this question on the task of sentiment analysis and for feature attribution explanation, one of the most commonly studied settings in the interpretability literature (for pre-ChatGPT models). Specifically, we study different ways to elicit the self-explanations, evaluate their faithfulness on a set of evaluation metrics, and compare them to traditional explanation methods such as occlusion or LIME saliency maps. Through an extensive set of experiments, we find that ChatGPT's self-explanations perform on par with traditional ones, but are quite different from them according to various agreement metrics, meanwhile being much cheaper to produce (as they are generated along with the prediction). In addition, we identified several interesting characteristics of them, which prompt us to rethink many current model interpretability practices in the era of ChatGPT(-like) LLMs.\n  \nhttps://arxiv.org/abs/2310.11207\n    submitted by    /u/zyl1024  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bvfpd/r_can_large_language_models_explain_themselves_a/",
          "publishedOn": "2023-10-19T22:21:30.000Z",
          "wordCount": 2777,
          "title": "[R] Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17btzjc/discussion_machine_learning_for_mechanical/",
          "author": null,
          "description": "Hello all,\n ​\n I'm a mechanical engineer learning machine learning, I found many specializations on Coursera by Google, DeepLearing.AI, and IBM, but I really can't tell which of them will be the best fit for me, so I would like to hear your recommendations, actually, I got financial aid for the specialization by DeepLearning AI and finished the first course, but I'm not satisfied I feel like I will not be a professional by this course\n ​\n my goal is to master data analysis and ML to work as a freelancer and increase my chances of finding a funded master's degree.\n    submitted by    /u/Mobile_Ad_4573  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17btzjc/discussion_machine_learning_for_mechanical/",
          "publishedOn": "2023-10-19T21:20:10.000Z",
          "wordCount": 2643,
          "title": "[Discussion] Machine Learning for Mechanical Engineering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17btjn7/discussion_scientific_and_dataintensive_computing/",
          "author": null,
          "description": "Hi everyone!\n I'm a graduate student in Scientific and Data-Intensive Computing at the University of Trieste (Italy) and I'm writing this post because I want to ask you a feedback about my study plan :)\n  \n 1st semester 2nd semester 3rd semester 4th semester \n  \n Statistical methods Deep Learning Simulation Intelligence and Learning for Autonomous Systems Parallel Programming for High-Performance Computing \n  High-Performance Computing Advanced Algorithms for Scientific Computing Advanced Topics in Scientific Computing  \n  Cloud Computing Advanced Numerical Analysis Advanced Deep Learning  \n  Software Development Practices Advanced High-Performance Computing   \n  Numerical Analysis Probabilistic Machine Learning Thesis Thesis \n \n  \nYou can find all the programs of the courses on this website\n On the following websites, you can find a lot of courses that I could add to my study plan \n Scientific Computing Courses\n Data science courses\n \n  \nAbout me\n  \nI have a Bachelor's degree in Computer Science (University of Rome)\n I am a Research Intern at an AI startup\n I will do a Summer Research Internship in the field of (HPC) ∩ (Machine Learning)\n I don't already know what my thesis will be about but I'm really interested in High-Performance Computing, Computational Mathematics, Machine Learning, and Simulations\n I would like to work in a research context; I'm considering doing a PhD in Scientific Computing (In that case, I would try to apply to American Universities)\n  \nI'm available for further clarification :)\n Thank you in advance\n    submitted by    /u/PragmaticScientist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17btjn7/discussion_scientific_and_dataintensive_computing/",
          "publishedOn": "2023-10-19T21:01:58.000Z",
          "wordCount": 2772,
          "title": "[Discussion] Scientific and Data-Intensive Computing study plan",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bsyp6/d_has_anybody_heard_back_from_neurips_financial/",
          "author": null,
          "description": "Was supposed to be Monday but instead it's rolling\n    submitted by    /u/notasketchyperson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bsyp6/d_has_anybody_heard_back_from_neurips_financial/",
          "publishedOn": "2023-10-19T20:37:08.000Z",
          "wordCount": 2557,
          "title": "[D] Has anybody heard back from NeurIPS financial aid yet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bst5d/d_need_advice_for_medical_text_processing/",
          "author": null,
          "description": "I am working on a research project that involves analysing medical text (patient records) to identify key events. Initially I was planning to use chatgpt api and then compare its performance with open source LLMs. However, I've just come across Amazon Comprehend Medical, which seems to be specifically designed for what I need. Has anyone tried it? I would expect it to be better than chatgpt + plugins, as it says it was trained with medical language. This also makes me wonder if there are opensource LLMs specifically trained for the medical field. Does anyone have experience with this?\n    submitted by    /u/kiukamba  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bst5d/d_need_advice_for_medical_text_processing/",
          "publishedOn": "2023-10-19T20:30:45.000Z",
          "wordCount": 2638,
          "title": "[D] Need advice for medical text processing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bqvhu/project_scaling_llama2_70b_with_multi_nvidia_and/",
          "author": null,
          "description": "Big LLMs are memory bound, one way to break that limit is to make use of multiGPUs.\n The recent development of MLC LLM project makes it possible to compile and deploy large-scale language models running on multi-GPU systems with support for NVIDIA and AMD GPUs with high performance. Specifically, it can run 4-bit quantized Llama2-70B at 34.5 tok/sec on two NVIDIA RTX 4090 and 29.9 tok/sec on two AMD Radeon 7900XTX. \n This is a first solution that helps us to scale 70B models with multiple GPUs, bringing the potential to run even larger open LLMs under reasonable budget (the two AMD GPUs cost 2k)\n ​\n - Project https://github.com/mlc-ai/mlc-llm\n - Blogpost https://blog.mlc.ai/2023/10/19/Scalable-Language-Model-Inference-on-Multiple-NVDIA-AMD-GPUs\n ​\n ​\n    submitted by    /u/crowwork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bqvhu/project_scaling_llama2_70b_with_multi_nvidia_and/",
          "publishedOn": "2023-10-19T19:07:36.000Z",
          "wordCount": 2661,
          "title": "[Project] Scaling LLama2 70B with Multi NVIDIA and AMD GPUs under 3k budget",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bpad2/d_is_there_a_way_to_get_world_level_timestamps/",
          "author": null,
          "description": "I don't understand how this isn't talked about more, given how many projects/products I've seen that have time level timestamps with whisper.\n I understand whisper isn't a traditional CTC model like wave2vec, and i understand that there are plenty of tutorials out there for doing dtw-based alignment.\n I know whisper-timestamped exist, and whisperx. The thing is, all these solutions assume you have the infrastructure to host your own whisper model. I am just getting started on my product, and I simply don't see the point in paying over 300/mo for a g4 instance (the cheapest GPU instance in AWS) just for an MVP.\n ​\n Has anyone been able to take the whisper API output, and align that using the sound bites and get timestamps? Is running your own whisper model the only way? Thank you!\n    submitted by    /u/latent_space_tennis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bpad2/d_is_there_a_way_to_get_world_level_timestamps/",
          "publishedOn": "2023-10-19T18:00:07.000Z",
          "wordCount": 2695,
          "title": "[D] Is there a way to get world level timestamps with whisper (using DTW based alignment) without having to host your own model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bnzp8/d_what_metrics_do_you_use_to_track_gpu/",
          "author": null,
          "description": "Hello people!\n I used to rely on GPU Usage to track how effectively I was able to leverage the gpu or cluster provided by my company from Grafana dashboard, however yesterday I saw X someone on X/Twitter saying:\n \"Utilization is a poor metric by itself. You can easly hit 100% where the GPU is doing a lot of waiting. Power consumption is a better (but not perfect) measure. If you're burning watts it's usually doing something useful. High util, no watts is not good.\"\n Which it's something that I've never considered before!\n Now I'm quite curious to hear if anyone here have considered this approach before or alternative ways to measure the performance of the GPU resource/cluster.\n    submitted by    /u/pirate7777777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bnzp8/d_what_metrics_do_you_use_to_track_gpu/",
          "publishedOn": "2023-10-19T17:03:00.000Z",
          "wordCount": 2669,
          "title": "[D] what metrics do you use to track GPU performance during training and/or inference?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bnslb/r_create_3d_model_of_face_with_4_normal_images/",
          "author": null,
          "description": "Hi guys, I'm looking for an AI application or way to create this in < 10' with proper accuracy. Does anybody know anything? Quality should be good enough to print it.\n    submitted by    /u/Reasonable_Cream_520  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bnslb/r_create_3d_model_of_face_with_4_normal_images/",
          "publishedOn": "2023-10-19T16:54:29.000Z",
          "wordCount": 2579,
          "title": "[R] Create 3d model of face with 4 normal images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bkqe7/p_higgsfield_distributed_llm_training_and_cluster/",
          "author": null,
          "description": "https://github.com/higgsfield-ai/higgsfield\n    submitted by    /u/Good-Willingness-985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bkqe7/p_higgsfield_distributed_llm_training_and_cluster/",
          "publishedOn": "2023-10-19T14:39:43.000Z",
          "wordCount": 2548,
          "title": "[P] Higgsfield: Distributed LLM training and cluster management framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bkot8/d_a_clear_visual_and_intuitive_explanation_of/",
          "author": null,
          "description": "Hello guys, I made a video for my YT channel breaking down Neural Attention with some intuitive examples and representative projects. \n Here is the link for those interested, all feedback is appreciated!\n https://youtu.be/frosrL1CEhw?si=NKTqmRTieVkfCNlb\n ​\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bkot8/d_a_clear_visual_and_intuitive_explanation_of/",
          "publishedOn": "2023-10-19T14:37:42.000Z",
          "wordCount": 2581,
          "title": "[D] A clear visual and intuitive explanation of Neural Attention",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bkizl/d_advantage_of_vaes_compared_to_regularized_aes/",
          "author": null,
          "description": "I'm trying to come up to speed on VAE's.\n My intuitive concept of a VAE is an AE for which we want to enforce some distributional regularity on the latent encodings.\n Why not accomplish this by simply regularizing the latent encodings directly? For example, we could assert that the latent vectors are drawn from a zero-mean, identity-matrix-covariance Gaussian distribution.\n So that e.g. the loss function becomes:\n  \nLoss(X) = ReconstructionLoss(Decoder(Encoder(X))) + LogPriorProbability(Encoder(X))\n In a variant of this, we could add a hyperparameter coefficient for the prior loss component.\n  \nHere, there is no \"reparameterization trick\" because the encoder is not stochastic. We simply regularize the latent encodings directly. If the encoder does not make the data X distribution look like the targeted Gaussian, it's a \"less good\" encoder. In principle we ought to still be able to generate X's by sampling from the prior and passing it through the decoder.\n This seems (to me) like the simplest way to regularize the latent space.\n Why do VAE's, by contrast, introduce the new machinery of a stochastic encoder?\n    submitted by    /u/OneQuadrillionOwls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bkizl/d_advantage_of_vaes_compared_to_regularized_aes/",
          "publishedOn": "2023-10-19T14:30:35.000Z",
          "wordCount": 2720,
          "title": "[D] Advantage of VAE's compared to regularized AE's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bjjkt/d_run_ai_model_multiple_k80_vs_rtx_4090/",
          "author": null,
          "description": "I want to build a machine for run multiple type of Ai Model like picture generation, chatbot, summarization, etc. I also want to train my own models. Is it better to use multiple(6/7) k80 or something like that or buy a RTX 4090? \n    submitted by    /u/ilkap2005  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bjjkt/d_run_ai_model_multiple_k80_vs_rtx_4090/",
          "publishedOn": "2023-10-19T13:46:49.000Z",
          "wordCount": 2590,
          "title": "[D] Run AI Model. Multiple k80 vs RTX 4090?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bjexf/d_mlops_tool_for_hyperparametertuning_distributed/",
          "author": null,
          "description": "Currently I train many AI models directly in my Jupyterlab notebooks and do something like hyperparameter tuning, evaluation of losses/accuracy directly in the notebook using lists and matplotlib. I want to finally switch to a MLOPs webUI and have discovered tools like ClearML and Determined.Ai.\n ​\n Each of these GUIs has certain advantages/disadvantages for me and therefore I would like to hear from the community how you do it, which tools you use, if you do it alone or in a team and how your workflow is.\n Until now I often had the impression that you develop your Jupyternotebook normally, then add a few lines of code for the respective tool and then continue in the UI, but here I lack for example the understanding of how I then jump from the MLOps UI back into the notebook, how I keep them synchronous, if I want to change something fundamental in the code again.\n ​\n Thanks in advance\n    submitted by    /u/Sensitive_Limit1620  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bjexf/d_mlops_tool_for_hyperparametertuning_distributed/",
          "publishedOn": "2023-10-19T13:40:52.000Z",
          "wordCount": 2702,
          "title": "[D] MLOps Tool for Hyperparametertuning, Distributed Training, etc",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bfzxf/r_jointly_training_large_autoregressive/",
          "author": null,
          "description": "In recent years, advances in the large-scale pretraining of language and text-to-image models have revolutionized the field of machine learning. Yet, integrating these two modalities into a single, robust model capable of generating seamless multimodal outputs remains a significant challenge. To address this gap, we present the Joint Autoregressive Mixture (JAM) framework, a modular approach that systematically fuses existing text and image generation models. We also introduce a specialized, data-efficient instruction-tuning strategy, tailored for mixed-modal generation tasks. Our final instruct-tuned model demonstrates unparalleled performance in generating high-quality multimodal outputs and represents the first model explicitly designed for this purpose.\n ​\n https://arxiv.org/abs/2309.15564\n What do you think about this work? Seems pretty huge, they build the first pure autoregressive interleaved text and image generator. Please let me know your opinion on this. Paper by Meta AI.\n    submitted by    /u/Present_Chicken5393  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bfzxf/r_jointly_training_large_autoregressive/",
          "publishedOn": "2023-10-19T10:31:23.000Z",
          "wordCount": 2679,
          "title": "[R] Jointly Training Large Autoregressive Multimodal Models https://arxiv.org/abs/2309.15564",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bfgsj/r_curve_your_enthusiasm_concurvity_regularization/",
          "author": null,
          "description": "Accepted at NeurIPS 2023\n Link: https://arxiv.org/abs/2305.11475\n Authors: Julien Siems, Konstantin Ditschuneit, Winfried Ripken, Alma Lindborg, Maximilian Schambach, Johannes Otterbach, Martin Genzel\n *equal contribution\n Abstract: Generalized Additive Models (GAMs) have recently experienced a resurgence in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear transformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurvity - i.e., (possibly non-linear) dependencies between the features - has hitherto been largely overlooked. Here, we demonstrate how concurvity can severly impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regularizer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicable to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability by eliminating ambiguities due to self-canceling feature contributions. We validate the effectiveness of our regularizer in experiments on synthetic as well as real-world datasets for time-series and tabular data. Our experiments show that concurvity in GAMs can be reduced without significantly compromising prediction quality, improving interpretability and reducing variance in the feature importances.\n Keywords: Interpretable Machine Learning, Generalized Additive Models, Concurvity, Multicollinearity, Regularization, Time-Series Forecasting, Interpretability\n    submitted by    /u/Yossarian_1234  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bfgsj/r_curve_your_enthusiasm_concurvity_regularization/",
          "publishedOn": "2023-10-19T09:55:19.000Z",
          "wordCount": 2745,
          "title": "[R] Curve your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bfg6o/p_strategic_game_datasets_for_enhancing_ai/",
          "author": null,
          "description": "Large dataset release of strategic gameplay from LAION\n https://laion.ai/blog/strategic-game-dataset/\n Dataset Overview\n  \nChess\n  \nThe chess dataset comprises 3.2 billion games, equating to approximately 608 billion individual moves. These games, generated via self-play by the Stockfish engine, emulate a high strategic complexity, reflective of a 2500 Elo rating. Each entry contains detailed move sequences, termination status, and game results.\n  \nRubik's Cube (3x3x3)\n  \nThe rubik's cube dataset features 1.64 billion Rubik's Cube solves, totaling roughly 236.39 billion moves. It provides initial scrambled states and the ensuing solve sequences, offering a complex problem-solving scenario for models to navigate.\n  \nMazes\n  \nThe maze dataset, while smaller at 350,000 mazes, represents over 39.29 billion moves. Each maze is a 30x30 ASCII representation, with solutions derived using the A* algorithm, challenging pathfinding and planning algorithms.\n    submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bfg6o/p_strategic_game_datasets_for_enhancing_ai/",
          "publishedOn": "2023-10-19T09:54:04.000Z",
          "wordCount": 2680,
          "title": "[P] Strategic Game Datasets for Enhancing AI planning: An invitation for collaborative research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bcikh/r_setofmark_som_unleashes_extraordinary_visual/",
          "author": null,
          "description": "We are introducing a magic Set-of-Mark (SoM) prompting for GPT-4V! Simply overlaying a set of marks on the image immediately unleashes the visual grounding power of GPT-4V!\n Left: GPT-4V Default Right: GPT-4V + SoM\n Many people including myself have been impressed by the general intelligence to understand images, but also questioning its visual grounding capability. After spending the last week or two, I am really shocked by the power of GPT-4V after plugging our SoM prompting. It can not only do a lot of fine-grained vision tasks but also can perform visual reasoning and project its world knowledge to the visual inputs! To extract meaningful regions, we compiled a new SoM toolbox with a number of interactive image segmentation tools, like our own MaskDINO, SEEM, Semantic-SAM, and also SAM…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bcikh/r_setofmark_som_unleashes_extraordinary_visual/",
          "publishedOn": "2023-10-19T06:26:57.000Z",
          "wordCount": 2970,
          "title": "[R] Set-of-Mark (SoM) Unleashes Extraordinary Visual Grounding in GPT-4V",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bayor/r_mamba_lineartime_sequence_modeling_with/",
          "author": null,
          "description": "submitted by    /u/LABTUD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bayor/r_mamba_lineartime_sequence_modeling_with/",
          "publishedOn": "2023-10-19T04:48:45.000Z",
          "wordCount": 2552,
          "title": "[R] Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17b2lk5/d_combining_data_transformation_and_scaling/",
          "author": null,
          "description": "I am cleaning a dataset for a (macro-economic) demand forecast, and I'm wondering when one should apply data transformation. When is it recommended to include Box-Cox or Yeo-Johnson, and how should we choose between the two? How does it effect the feature selection or model performance? \n Additionally, how should we select the appropriate scaling technique (normalizing, standardizing, min-max) and does the order in which we transform and scale matter for our data? \n Is there any recommended literature on this? \n    submitted by    /u/Ambitious-Pay6329  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17b2lk5/d_combining_data_transformation_and_scaling/",
          "publishedOn": "2023-10-18T21:58:32.000Z",
          "wordCount": 2630,
          "title": "[D] Combining data transformation and scaling techniques",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17azoic/d_gpucompatible_snnlibraries_in_2023/",
          "author": null,
          "description": "Hello, \n I am currently using snnTorch for a video classification task and I achieve fine results, however the training process is really, really slow. I was hoping to utilize my GPU for this task, and while there seem to be alternatives I was hoping to see if anyone will vouch for any of these, or different one:\n https://github.com/norse/norse\n https://github.com/BindsNET/bindsnet\n https://github.com/fangwei123456/spikingjelly\n https://github.com/UCI-CARL/CARLsim6 \n My priorities are in order:\n Windows support\n Potential transferability to in-memory compute hardware\n PyTorch compability\n    submitted by    /u/SlayahhEUW  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17azoic/d_gpucompatible_snnlibraries_in_2023/",
          "publishedOn": "2023-10-18T19:53:25.000Z",
          "wordCount": 2618,
          "title": "[D] GPU-compatible SNN-libraries in 2023?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17aycuw/r_meta_ai_towards_a_realtime_decoding_of_images/",
          "author": null,
          "description": "Brain decoding tech has improved a lot recently thanks to AI/ML, enabling reading out visual perceptions from fMRI brain scans. But fMRI is too slow for real-time BCIs.\n A new study from Meta's AI research team pushes brain reading into real-time using MEG, which measures whole-brain activity at super-fast millisecond resolution.\n They built a 3-part pipeline to decode MEG signals:\n  \nEmbed images into latent spaces using pretrained models like CLIP.\n Train MEG-specific ConvNet to predict embeddings from MEG data.\n Generate images from MEG embeddings with diffusion model.\n  \nThey tested it on 20k+ natural images. MEG decoding was 7X better than old methods, hitting 70% top-5 accuracy in retrieving the right images.\n Generated images matched semantics decently but lacked fine visual details compared to fMRI. MEG seems more focused on high-level category info whereas fMRI captures more low-level features.\n This could enable visual BCIs for paralysis, etc. ... honestly, a world where we can decode brain images in real time is pretty crazy. The findings also raise some important ethical considerations around privacy of decoded mental content... (wow, that was a weird sentence to write!).\n TLDR: New MEG pipeline decodes dynamic visual data from brain activity in real-time. Good but not yet photorealistic-quality image generation.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17aycuw/r_meta_ai_towards_a_realtime_decoding_of_images/",
          "publishedOn": "2023-10-18T18:56:52.000Z",
          "wordCount": 2766,
          "title": "[R] Meta AI: Towards a Real-Time Decoding of Images from Brain Activity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17axy41/d_can_someone_eli5_the_birch_clustering_algorithm/",
          "author": null,
          "description": "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html\n I'm looking at the parameters here and I'm confused on how there is no distance metric? What is assumed about the data going in if there is no distance metric or precomputed distance option?\n For example, can I run this with binary data (1/0), what about data w/ missing values? Does it assume the samples are normally distributed?\n    submitted by    /u/o-rka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17axy41/d_can_someone_eli5_the_birch_clustering_algorithm/",
          "publishedOn": "2023-10-18T18:39:30.000Z",
          "wordCount": 2611,
          "title": "[D] Can someone ELI5 the birch clustering algorithm?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17av3qp/r_xval_a_continuous_number_encoding_for_large/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.02989\n Twitter discussion: https://x.com/andrew_n_carr/status/1714326003030638848?s=20 \n Shows in my opinion that tokenizers are clouding the understanding of LLMs and that using the data directly is better. https://x.com/karpathy/status/1657949234535211009?s=20 Karpathy thinks the same! \n Abstract:\n  \nLarge Language Models have not yet been broadly adapted for the analysis of scientific datasets due in part to the unique difficulties of tokenizing numbers. We propose XVAL, a numerical encoding scheme that represents any real number using just a single token. XVAL represents a given real number by scaling a dedicated embedding vector by the number value. Combined with a modified number-inference approach, this strategy renders the model end-to-end continuous when considered as a map from the numbers of the input string to those of the output string. This leads to an inductive bias that is generally more suitable for applications in scientific domains. We empirically evaluate our proposal on a number of synthetic and real-world datasets. Compared with existing number encoding schemes, we find that XVAL is more token-efficient and demonstrates improved generalization.\n  \nhttps://preview.redd.it/qq8u066smzub1.jpg?width=1344&format=pjpg&auto=webp&s=498be8488c00147f0a7443050519dcf535fae126\n https://preview.redd.it/dxqd4wpsmzub1.jpg?width=1499&format=pjpg&auto=webp&s=266689a80b31cb31fdc4167043f7abdb4f683100\n https://preview.redd.it/0yy93xpsmzub1.jpg?width=1497&format=pjpg&auto=webp&s=b5eae8b958f03afc3c8c85a95c115e48aed1d06e\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17av3qp/r_xval_a_continuous_number_encoding_for_large/",
          "publishedOn": "2023-10-18T16:38:15.000Z",
          "wordCount": 2738,
          "title": "[R] xVal: A Continuous Number Encoding for Large Language Models - The Polymathic AI Collaboration 2023 - Using the numbers directly instead of tokenizing them increases performance significantly!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17au0w8/p_a_guide_to_building_llmbased_applications_with/",
          "author": null,
          "description": "Have you ever wondered about how to take advantage of the power of large language models (LLMs) and Generative AI at the edge? \n Our latest blog, A Guide to Building LLM-Based Applications with Code Llama, shows you how you can use Code Llama on an edge device to build a customized dashboard application. This tutorial shows how Code Llama can empowering analysts in remote, restricted environments to build applications in environments with minimal connectivity and compute capacity. \n In this tutorial, we’ll walk you through how to run code Llama on an edge device in a remote location to build a customized dashboard application.\n    submitted by    /u/modzykirsten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17au0w8/p_a_guide_to_building_llmbased_applications_with/",
          "publishedOn": "2023-10-18T15:52:14.000Z",
          "wordCount": 2657,
          "title": "[P] A Guide to Building LLM-Based Applications with Code Llama",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17atob7/r_llms_can_threaten_privacy_at_scale_by_inferring/",
          "author": null,
          "description": "Our latest research shows an emerging privacy threat from LLMs beyond training data memorization. We investigate how LLMs such as GPT-4 can infer personal information from seemingly benign texts. The key observation of our work is that the best LLMs are almost as accurate as humans, while being at least 100x faster and 240x cheaper in inferring such personal information. \n We collect and label real Reddit profiles, and test the LLMs capabilities in inferring personal information from mere Reddit posts, where GPT-4 achieves >85% Top-1 accuracy. Mitigations such as anonymization are shown to be largely ineffective in preventing such attacks. \n Test your own inference skills against GPT-4 and learn more: https://llm-privacy.org/\n Arxiv paper: https://arxiv.org/abs/2310.07298\n WIRED article: https://www.wired.com/story/ai-chatbots-can-guess-your-personal-information/\n    submitted by    /u/bmislav  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17atob7/r_llms_can_threaten_privacy_at_scale_by_inferring/",
          "publishedOn": "2023-10-18T15:36:53.000Z",
          "wordCount": 2674,
          "title": "[R] LLMs can threaten privacy at scale by inferring personal information from seemingly benign texts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17askxp/d_gan_that_manipulates_shape_texture_color/",
          "author": null,
          "description": "I remember seeing a paper on manipulating or changing an objects attributes, it came out rather recently and seemed to work really well. But I just can’t find it anymore.\n All I know of is the „Counterfactual Generative Networks“ by A. Sauer & A. Geiger (2020) \n I’d really appreciate it if anyone can share similar work. Especially if causally motivated\n    submitted by    /u/Glittering_teapot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17askxp/d_gan_that_manipulates_shape_texture_color/",
          "publishedOn": "2023-10-18T14:48:32.000Z",
          "wordCount": 2613,
          "title": "[D] GAN that manipulates shape, texture, color, position, angle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17asij6/p_best_way_to_create_a_custom_chatbot_from/",
          "author": null,
          "description": "Hello fellow Redditors!\n I am looking for some guidance on creating a custom chatbot using my own data, which is currently in PDF format. I've explored various options like Azure, Pinecone, and I've heard about the AskYourPDF API, but I'm not sure which one would be the best fit for my project.\n I want to keep things simple, so I'm reaching out to the community to ask for recommendations or advice on the easiest and most effective way to build a website with a personalized chatbot. If you have experience with similar projects or know about user-friendly tools or platforms, please share your insights.\n I appreciate any suggestions, tips, or pointers you can provide. Thank you in advance for your help!\n TL;DR: Need advice on the simplest way to create a website with a personalized chatbot using my own data (PDF format). Seeking recommendations and tips from the community. \n ​\n Thank you!\n    submitted by    /u/Huge-Number-4299  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17asij6/p_best_way_to_create_a_custom_chatbot_from/",
          "publishedOn": "2023-10-18T14:45:25.000Z",
          "wordCount": 2708,
          "title": "[P] Best Way to Create a Custom Chatbot from Personal Data (PDF, etc.)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17apx1w/p_where_do_i_gather_the_dataset_for_my_fyp/",
          "author": null,
          "description": "I am doing a Machine Learning project for my FYP; I haven't worked on any ML project yet but I am excited about it. It is related to voice/facial emotion detection. is there any platform that provides datasets for ml projects? Like without any copyright issues (if that's even a thing in ml datasets idk?) A total beginner here.\n    submitted by    /u/fewdiepie_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17apx1w/p_where_do_i_gather_the_dataset_for_my_fyp/",
          "publishedOn": "2023-10-18T12:45:16.000Z",
          "wordCount": 2613,
          "title": "[P] Where do I gather the dataset for my FYP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ap687/p_i_made_a_finetune_of_codellama_to_resolve_merge/",
          "author": null,
          "description": "I made a finetune of CodeLlama-7b for resolving merge conflicts following up on an IEEE study from 2022. The demo is here if anyone wants to check it out and give some feedback. It would help a ton for future versions improving the dataset and going forward with the 13b and 34b models\n    submitted by    /u/codys12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ap687/p_i_made_a_finetune_of_codellama_to_resolve_merge/",
          "publishedOn": "2023-10-18T12:06:28.000Z",
          "wordCount": 2608,
          "title": "[P] I made a finetune of CodeLlama to resolve merge conflicts!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17aolmo/discussion_how_much_error_should_i_apply_when/",
          "author": null,
          "description": "hi there\n ​\n i'm trying to build a small ai that formats texts.\n ​\n of course the current formatting applications applied on ide, search engine, ms softwares, notetaking apps are well functioning, but this is more for educational purpose & self interest.\n ​\n since i don't have infinite amount of time and money, i'm thinking of using open sourced text data and generate synthetic data using gpt3.5 or somekind of algorithm to unformat them.\n ​\n so this is the part where i'm stuck. when adding some errors such as inappropriate multilines, tabs, typos, how much should i add on to?\n ​\n it would be best if i knew somekind of distribution of text errors people make on everyday life, but i don't have any.\n ​\n i don't want to make this training too hard so i'm not really thinking to destroy the text, but rather add some appropriate level of errors.\n ​\n but, would it help this ai model to learn better if i add extra errors?\n ​\n or is this all just something i would have to figure out by myself?\n ​\n any comments would be appreciated!\n    submitted by    /u/Strange_Dog8104  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17aolmo/discussion_how_much_error_should_i_apply_when/",
          "publishedOn": "2023-10-18T11:36:37.000Z",
          "wordCount": 2735,
          "title": "[Discussion] how much 'error' should i apply when training with synthetic data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17an3jy/r_opensource_video_translate_solutions/",
          "author": null,
          "description": "Hi there!\n are there any open-source solutions for video translation? i mean replacing video's audio stream with translated one in different language (which is in sync with the picture) - not necessarily alter mouth movements in the video.\n    submitted by    /u/curryprogrammer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17an3jy/r_opensource_video_translate_solutions/",
          "publishedOn": "2023-10-18T10:05:33.000Z",
          "wordCount": 2587,
          "title": "[R] Open-source video translate solutions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17alyw5/research_literature_survey_query/",
          "author": null,
          "description": "Survey papers\n Hi all,\n First time posting here. I am doing my PhD in Language Conditioned Robotics. I am currently writing a literature review paper on the current state of the field and how it can be further improved. I am covering topics such as generative AI and LLMs in there. \n I would be more than grateful if you could send some literature review papers in the field of ML so I understand how to structure and write my paper and also what I should focus on mode. It doesn't necessarily have to be related to my PhD topic (but if they are it will help quite a bit). \n I would be more than happy if anyone can also share their experience.\n Thank you for your time!\n    submitted by    /u/bizzonkiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17alyw5/research_literature_survey_query/",
          "publishedOn": "2023-10-18T08:48:21.000Z",
          "wordCount": 2675,
          "title": "[Research] Literature survey query",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17al6qc/d_what_are_some_of_the_best_library_frameworks_to/",
          "author": null,
          "description": "Hey guys, what are some of the best library or libraries to use to make a voice conservational AI chatbot? \n I googled around and found Vocode. They look pretty good. However Vocode rely on several other (paid) closed sourced libraries such as Deepgram (for transcribing) and Azure AI Speech (for synthesising). Are there any other libraries/frameworks available out there which are completely or more open sourced?\n    submitted by    /u/redd-dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17al6qc/d_what_are_some_of_the_best_library_frameworks_to/",
          "publishedOn": "2023-10-18T07:51:39.000Z",
          "wordCount": 2627,
          "title": "[D] What are some of the best library frameworks to use for speech2text and text2speech AI chatbot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ajv1s/r_efficient_streaming_language_models_with/",
          "author": null,
          "description": "submitted by    /u/Username912773  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ajv1s/r_efficient_streaming_language_models_with/",
          "publishedOn": "2023-10-18T06:19:59.000Z",
          "wordCount": 2552,
          "title": "[R] EFFICIENT STREAMING LANGUAGE MODELS WITH ATTENTION SINKS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ahpzu/6dof_sim_rl_capability_p/",
          "author": null,
          "description": "I have a 6DOF simulink model of a Autonomous underwater vehicle that has properties [u v w p q r x y z phi theta psi] and two inputs [theta1 theta2] that govern the angle of control surfaces. Ocean current and depth are taken into account. \n How feasible would it be to use RL to reach waypoints at various [x, y, z] positions? I don’t want to use a PID controller or anything, not even RL to tune a controller. The agent would choose the theta inputs directly. I have a feeling hyper paremeter tuning might play a larger role in this? I expect training times to increase exponentially as well? \n I have done this using a single randomly spawned waypoint with a simple Unicycle Kinematic model, in both simulink/matlab and python with a vectorized/parallel environment using SB3/PettingZoo/Gym.\n    submitted by    /u/VisionZUS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ahpzu/6dof_sim_rl_capability_p/",
          "publishedOn": "2023-10-18T04:06:00.000Z",
          "wordCount": 2687,
          "title": "6DOF Sim RL Capability [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ah5z8/r_bitnet_scaling_1bit_transformers_for_large/",
          "author": null,
          "description": "Arxiv link – BitNet: Scaling 1-bit Transformers for Large Language Models\n  \nIn this work, we introduce BitNet, a scalable and stable 1-bit Transformer architecture designed for large language models. Specifically, we introduce BitLinear as a drop-in replacement of the nn.Linear layer in order to train 1-bit weights from scratch. Experimental results on language modeling show that BitNet achieves competitive performance while substantially reducing memory footprint and energy consumption, compared to state-of-the-art 8-bit quantization methods and FP16 Transformer baselines. Furthermore, BitNet exhibits a scaling law akin to full-precision Transformers, suggesting its potential for effective scaling to even larger language models while maintaining efficiency and performance benefits.\n  \n   submitted by    /u/PantsuWitch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ah5z8/r_bitnet_scaling_1bit_transformers_for_large/",
          "publishedOn": "2023-10-18T03:35:12.000Z",
          "wordCount": 2658,
          "title": "[R] BitNet: Scaling 1-bit Transformers for Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17af6y2/p_achieving_peak_performance_on_gpu/",
          "author": null,
          "description": "Hi r/MachineLearning! I recently went into the CUDA programming rabbit hole. In the process, I came across matrix multiplication and was amazed by how complicated the algorithm is in CUDA (especially if you want to get the best performance). I found the learning process quite gruelling (the CUDA docs were very average), so I wrote a tiny blog which hopefully helps anyone in the same position.\n You can read the blog on Medium (no paywall) or HackMD. It would probably be quite useful if you want to get a deeper intuition of how things like OpenAI Triton or FlashAttention work under the hood.\n Accompanying this is an implementation of a 3-hidden-layer MLP trained on MNIST in pure CUDA. Benchmarking this against PyTorch, it gets up 6x higher end-to-end training speed for small (h=128) networks, and asymptotically 20% faster for large (h=8192) ones! \n https://preview.redd.it/txx2txbvlzub1.png?width=2400&format=png&auto=webp&s=7bb136b9fb535bc58fd7ee809bbbca6f68dc8953\n It's worth noting that I tried reasonably hard optimising the PyTorch implementation by using full fp16, torch.compile with fullgraph=True, mode=\"max-autotune\", and pre-loading all data to GPU up-front (I also did this for the CUDA implementation).\n The main takeaways I got are:\n  \nFor small networks, PyTorch/Python still incurs a significant overhead, even if you try pretty hard to optimise it.\n For large networks, most of the speedup comes from using fp16 accumulation for matrix multiplication (instead of PyTorch's fp32). This obviously reduces stability, but at least in my case, I didn't observe any numerical issues. In cases where we can get away with fp16, we might be leaving a significant amount of performance on the table!\n Anecdotally, you have to try really hard in CUDA to even get close to the performance of PyTorch, but it is possible to beat it if you try hard (suffer) enough.\n  \nYou can check out the repo here: https://github.com/andylolu2/cuda-mnist. Would love to hear some feedback!\n    submitted by    /u/bjergerk1ng  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17af6y2/p_achieving_peak_performance_on_gpu/",
          "publishedOn": "2023-10-18T01:56:35.000Z",
          "wordCount": 2852,
          "title": "[P] Achieving peak performance on GPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ac43p/roughly_how_much_time_will_a_task_running_on_a/",
          "author": null,
          "description": "Anyone have examples of tasks run between the two? Doesn't need to be exact.\n    submitted by    /u/Apita2000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ac43p/roughly_how_much_time_will_a_task_running_on_a/",
          "publishedOn": "2023-10-17T23:32:57.000Z",
          "wordCount": 2541,
          "title": "Roughly how much time will a task running on a RTX 3060 take VS a ~i7 CPU? [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17abc2d/d_feedback_on_my_mvp_project_prerecorded/",
          "author": null,
          "description": "Hey!\n ​\n Startup:\n - Apply Script dot com \"Connect business and data professionals via pre-recorded standardized video interviews.\"\n ​\n More details:\n ​\n Problems with Traditional Hiring\n ​\n - Outdated: The current method of conducting interviews has become overly complex and outdated.\n - Time-Wasting: The process involves too many appointments, meetings, and stages, leading to communication errors.\n - Expensive: The man-hours invested by HR and engineering teams are costly.\n - Constraining: Interviews are fixed to specific times and locations.\n - Cumbersome: The experience is challenging for both businesses and professionals.\n ​\n Our Solution\n ​\n + Talent Identification: We find top talent that matches your job post.\n + Standardized Interviews: Professionals standardized pre-record their …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17abc2d/d_feedback_on_my_mvp_project_prerecorded/",
          "publishedOn": "2023-10-17T22:57:52.000Z",
          "wordCount": 2814,
          "title": "[D] Feedback on my MVP project - Pre-Recorded Standardized Video Interviews Job Site for Data Professionals",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17aaktm/d_help_identifying_research_papers_for_online/",
          "author": null,
          "description": "So my situation is that I have a pretrained model and we get a new update of data every month (note: this monthly data is very small compared to the original dataset, the original dataset was about 5 years worth, or ~60x the size of any given monthly update), how can I update my pretrained model on the much smaller set of new data, learning from the data without overfitting to that data?\n Or frankly, what would be better if it is possible, would be to extend my pretrained model such that it learns from the new data and then can be more tightly fit to that month's data. So something like meta-learning or local fine-tuning, but I want to continue to update and improve my pretrained model so that I have a base model that can do well on each month's new data. Does anyone know anything like this, or have advance for terms to look into, beyond just transfer learning or regularization?\n    submitted by    /u/Amun-Aion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17aaktm/d_help_identifying_research_papers_for_online/",
          "publishedOn": "2023-10-17T22:24:44.000Z",
          "wordCount": 2685,
          "title": "[D] Help identifying research papers for online / cyclic / sequential learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17aa9yv/how_to_properly_implement_covers_theorem_in_an/",
          "author": null,
          "description": "Maybe this belongs elsewhere since it's probably a dumb basic question, but basically I'm taking an undergrad course in AI and we've been given a classification problem. We were told as a \"hint\" to recall Cover's Theorem when separation fails, but the issue is she also wants us to draw a rough sketch of the data with the separator. Mine failed in a basic scatterplot so I upped the dimension by 1 but it also wasn't separable in R3 (which is annoying to draw anyway but could have been done), if I keep going then it might work at some point but idk how I'm meant to draw the data if it's separated in R4 or beyond. If it works in R4 do I just sketch the data in R3 and just draw a 3 dimensional point where w = 0? But even then if it goes beyond R4 it becomes way more annoying. So I'm assuming my implementation is just wrong, maybe the formula I used was wrong.\n Can someone show what a proper implementation looks like and how we're meant to up dimensions? Don't wanna post what I tried bc it has starter code and stuff baked into it which might allow my professor to find this post 😂\n    submitted by    /u/Traditional_Land3933  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17aa9yv/how_to_properly_implement_covers_theorem_in_an/",
          "publishedOn": "2023-10-17T22:11:34.000Z",
          "wordCount": 2730,
          "title": "How to properly implement Cover's Theorem in an SVM? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a91sh/d_cross_entropy_classification_vs_metric_learning/",
          "author": null,
          "description": "Hi guys. We've all seen how hot RAG and vector DBs have been lately. How good are retrieval-based approaches for image classification?\n More concretely: Suppose we have a network trained with metric learning and a massive, diverse set of labelled examples to retrieve from. We've just been tasked to do classification with a fixed number of classes, and we've narrowed it down to two options:\n  \nEmbed our dataset using our metric learning network, throw the embeddings into a vector DB, and do k-NN\n Train a classifier via cross-entropy loss\n  \nWhich approach would we expect to provide better performance? What are the trade-offs? Any insight is appreciated!\n    submitted by    /u/supersmartypants  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a91sh/d_cross_entropy_classification_vs_metric_learning/",
          "publishedOn": "2023-10-17T21:20:12.000Z",
          "wordCount": 2621,
          "title": "[D] Cross Entropy Classification vs Metric Learning + k-NN for image classification?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a7q2o/d_graph_neural_networks_links_prediction_task_on/",
          "author": null,
          "description": "Hi guys, I have the following use case at hand for my thesis, and I'd like to ask for some help to formulate my problem:\n  \nA directed multigraph (1 node type, multiple edge types)\n Each node and edge have their own attributes\n A set of graphs that are fully labeled. The dataset is self-created according to some technical rules. Training is supposed to be done on this dataset.\n  \nMy task is to perform link prediction in the inductive setting. This means that given an unseen incomplete graph at the inference time, the model should be able to predict all the missing links. I have read many papers and tried to formulate my problem in many directions. Since I am also new to GNNs, I would prioritize papers with an existing codebase and sound theoretical justifications for the techniques (which …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a7q2o/d_graph_neural_networks_links_prediction_task_on/",
          "publishedOn": "2023-10-17T20:23:21.000Z",
          "wordCount": 3057,
          "title": "[D] Graph Neural Networks - Links Prediction Task on Directed, Heterogenous Multigraphs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a775d/trouble_improving_accuracy_in_face_recognition/",
          "author": null,
          "description": "Hey everyone\n Im trying my hands with the The Labeled Faces in the Wild face recognition dataset, for a face recognition task. I have made a siamesemodel, and my loss curve is looking great but my accuracy stays at 0.500, for everything i have tried. Is there anybody in here that have tried their hands with this task before that can give me some tips to improve my accuracy. I am implementing it in python with PyTorch btw\n Thanks in advance!\n    submitted by    /u/Due_Concentrate1279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a775d/trouble_improving_accuracy_in_face_recognition/",
          "publishedOn": "2023-10-17T20:00:39.000Z",
          "wordCount": 2598,
          "title": "Trouble improving accuracy in face recognition dataset [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a5gr8/how_valuable_is_a_phd_in_science_with_applied_ml/",
          "author": null,
          "description": "Is it more advantageous to pursue a PhD in machine learning with a focus on scientific applications for example (Machine learning for drug design) if the end goal is to work in the machine learning industry? Or is a general PhD in machine learning more valuable for this career path?\n Thank you\n    submitted by    /u/Neat-Print2792  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a5gr8/how_valuable_is_a_phd_in_science_with_applied_ml/",
          "publishedOn": "2023-10-17T18:45:27.000Z",
          "wordCount": 2580,
          "title": "How valuable is a PhD in science (with applied ML) compared to a PhD in only Machine learning [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a31qb/r_85_of_the_variance_in_language_model/",
          "author": null,
          "description": "TL;DR and paper link are at the bottom of the post.\n I'm an undergrad who just wrote my first paper completely solo. Crazy experience with so many highs and lows, but I learned a lot from it. I think the results are important and I want people to see them, so I'll try to walk through the paper here as best as I can. I also have a small request for Arxiv enjoyers at the end.\n Given the nature of Reddit posts, I'll focus a bit less on the methods and more on the results. I won't cite stuff here either, but obviously you can find citations in the paper.\n First I'll give a small bit of historical context to what I'm doing, then walk through what I did and what came of it.\n Enjoy the read.\n The general intelligence factor in humans\n In the early 1900s, Charles Spearman observed that children's …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a31qb/r_85_of_the_variance_in_language_model/",
          "publishedOn": "2023-10-17T17:00:26.000Z",
          "wordCount": 4057,
          "title": "[R] 85% of the variance in language model performance is explained by a single factor (g, a unified measure of LLM ability)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a0wtx/d_how_to_design_api_of_machine_learning_library/",
          "author": null,
          "description": "In the past nine years of my deep learning journey, I have come across a vast number of frameworks. Lua Torch was a fantastic framework that initially died due to a lack of Python's ecosystem, but then rose again as PyTorch. Theano was also a great framework, but its major drawback was difficult debugging. I remember spending two weeks writing a Neural Turing Machine for solving bAbI tasks on theano. (Nowadays, it would take a couple hours on Pytorch). Tensorflow - I still don't understand what that was, a terrible framework. There was also Caffe, which was popular in computer vision. Julia is another language that attempted to introduce automatic differentiation as a built-in feature. And JAX, which I was originally biased against since it's a Google product. But some close friends persuaded me to try it, and I actually liked it. However, I thought that it would be difficult for JAX to gain widespread adoption in the community, as PyTorch already had a strong network effect and was gaining traction quickly. I didn't see how anyone could catch up with PyTorch. Another issue with JAX is that it requires additional cognitive load for developers.\n Take a look: https://higgsfield.substack.com/p/how-to-design-api-of-machine-learning\n    submitted by    /u/Good-Willingness-985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a0wtx/d_how_to_design_api_of_machine_learning_library/",
          "publishedOn": "2023-10-17T15:25:18.000Z",
          "wordCount": 2717,
          "title": "[D] How to design API of Machine learning library",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a0b0d/p_2d_gaussian_splatting_a_great_starting_point/",
          "author": null,
          "description": "Github : https://github.com/OutofAi/2D-Gaussian-Splatting\n https://i.redd.it/cwgsjtko1sub1.gif\n    submitted by    /u/TerryCrewsHasacrew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a0b0d/p_2d_gaussian_splatting_a_great_starting_point/",
          "publishedOn": "2023-10-17T14:58:41.000Z",
          "wordCount": 2527,
          "title": "[P] 2D Gaussian Splatting a great starting point for people who want to delve deeper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179zlrl/d_how_to_build_data_products_deploy_part_34/",
          "author": null,
          "description": "Data products plays an important role in building state of the art machine learning models. Though their building process seems a bit confusing within industry as of now, this article series tries to simplify it by breaking it and explaining it into 4 steps. Take a look: https://moderndata101.substack.com/p/how-to-build-data-products-deploy\n What processes are being followed at your org for building scalable data products?\n    submitted by    /u/growth_man  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179zlrl/d_how_to_build_data_products_deploy_part_34/",
          "publishedOn": "2023-10-17T14:26:23.000Z",
          "wordCount": 2595,
          "title": "[D] How to Build Data Products? Deploy: Part 3/4 - Doubling down on the power of Unified Experiences for building state of the art models.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179z3d0/shared_public_contextual_database_for_rag_d/",
          "author": null,
          "description": "Hey Guys,\n It seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo'd vector dbs. \n Do you guys think there's any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone's raving about today) \n - \n For context, I'm building a social media product we're users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche's classification string. Essentially we're aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. \n    submitted by    /u/niksteel123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179z3d0/shared_public_contextual_database_for_rag_d/",
          "publishedOn": "2023-10-17T14:02:52.000Z",
          "wordCount": 2743,
          "title": "Shared Public Contextual Database for RAG [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179wvu8/d_work_regarding_using_llms_to_generate_data_for/",
          "author": null,
          "description": "Hi. I'm curious if there have been any studies done regarding the effects of using data generated by LLMs for other downstream tasks. The closest that I could find are the two papers:\n  \nLarge Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias (Yu et al., 2023)\n Generating Training Data with Language Models: Towards Zero-Shot Language Understanding (Meng et al., 2022)\n  \nThe former focuses on studying the differences between the type of prompts that are used to generate the data and the latter doesn't use LLMs.\n Doesn't have to be papers, blog posts or any sort of information regarding the scenario I described is fine. Thanks.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179wvu8/d_work_regarding_using_llms_to_generate_data_for/",
          "publishedOn": "2023-10-17T12:09:53.000Z",
          "wordCount": 2630,
          "title": "[D] Work regarding using LLMs to generate data for downstream tasks.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179wr0u/d_embedding_models_in_productioncpu_w_high/",
          "author": null,
          "description": "Hello,\n I am working on an app that requires creating lots of text embeddings(100M tokens).\n Looking at OpenAI Ada pricing(and considering that my app doesn't yet make any money) I'm looking into self-hosting a model to run on CPU. \n I know that constrains me towards smaller models-- so far locally I've been testing with sentence-transformers/all-MiniLM-L6-v2 and the query results seem okay-ish enough for my MVP. (Although, I should not that I haven't compared how embeddings with other models would perform.)\n Does anyone have experiences doing something similar? In particular, I'd love to hear about any tips you have for maximizing no. of embeddings / second.\n (new to ML/MLOps, so apologies if this is a silly question :)\n    submitted by    /u/rsamrat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179wr0u/d_embedding_models_in_productioncpu_w_high/",
          "publishedOn": "2023-10-17T12:02:17.000Z",
          "wordCount": 2634,
          "title": "[D] Embedding models in production(CPU w/ high throughput)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179vq4v/n_introducing_stable_fast_an_ultra_lightweight/",
          "author": null,
          "description": "What is this?\n stable-fast is an ultra lightweight inference optimization library for HuggingFace Diffusers on NVIDIA GPUs. stable-fast provides super fast inference optimization by utilizing some key techniques and features:\n  \nCUDNN Convolution Fusion: stable-fast implements a series of fully-functional and fully-compatible CUDNN convolution fusion operators for all kinds of combinations of Conv + Bias + Add + Act computation patterns.\n Low Precision & Fused GEMM: stable-fast implements a series of fused GEMM operators that compute with fp16 precision, which is fast than PyTorch's defaults (read & write with fp16 while compute with fp32).\n NHWC & Fused GroupNorm: stable-fast implements a highly optimized fused NHWC GroupNorm + GELU operator with OpenAI's triton, which eliminates the need…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179vq4v/n_introducing_stable_fast_an_ultra_lightweight/",
          "publishedOn": "2023-10-17T11:00:33.000Z",
          "wordCount": 2845,
          "title": "[N] Introducing Stable Fast: An ultra lightweight inference optimization library for HuggingFace Diffusers on NVIDIA GPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179vkv6/r_does_the_flan_t5_decoder_take_the_question_as/",
          "author": null,
          "description": "Hello,\n I was looking at the Flan T5 paper and code. It was clear that the question (instruction) and the context are given to the encoder as input. But I find no details on what does the decoder take as input apart from the fact that it starts with the pad token. Anyone can give me more details please ?\n Thanks !\n    submitted by    /u/Meddhouib10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179vkv6/r_does_the_flan_t5_decoder_take_the_question_as/",
          "publishedOn": "2023-10-17T10:51:09.000Z",
          "wordCount": 2583,
          "title": "[R] Does the Flan T5 decoder take the question as input ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179uwbq/d_tensorflowjs_and_state_of_the_ecosystem_for/",
          "author": null,
          "description": "I am curious about the state of the ecosystem for JavaScript, where TF looks like a reasonably solid option.\n Options I have found so far are:\n  \nTensorFlow.js (looks like the most complete solution, but the general sentiment about TF in Python is pretty bad!)\n MediaPipe (to quickly implement specific use cases it seems, maybe using tf.js in the background?)\n ml5.js (a layer on top of tf.js to make it more approachable if i understand correctly)\n transformers.js (haven't quite grasped this one)\n shumai (bun only, so server side only)\n  \nI am curious to read informed opinions about these and more! Have you used them and how?\n ​\n    submitted by    /u/gtnbssn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179uwbq/d_tensorflowjs_and_state_of_the_ecosystem_for/",
          "publishedOn": "2023-10-17T10:06:42.000Z",
          "wordCount": 2623,
          "title": "[D] TensorFlow.js and state of the ecosystem for JavaScript",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179ttqy/d_which_raw_opss_benchmarks_best_reflect_mldl/",
          "author": null,
          "description": "Hi all. I'm preparing an open website about products used for AI/ML/DL computation (no in-house testing for now, just the database and GUI). However comparing raw speed of products of different vendors is more challenging than I anticipated, because there are many possible raw performance indicators, only few of which are provided by vendors.\n For example a raw performance indicator can be \"FP32 vector with opportunistic optimization\", while another can be \"BF16 matrix/tensor without opportunistic optimization\". A full picture of raw performance would be fully represented only by a table with multiple dimensions:\n  \nNumber format (FP64, FP32, TF32, FP16, BF16, FP8, INT8, INT4... are the others?)\n Vector vs. matrix/tensor operation (boolean)\n Opportunistic optimizations like Nvidia Sparsity…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179ttqy/d_which_raw_opss_benchmarks_best_reflect_mldl/",
          "publishedOn": "2023-10-17T08:49:19.000Z",
          "wordCount": 2828,
          "title": "[D] Which raw OPS/s benchmarks best reflect ML/DL workloads?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179seow/d_interesting_loss_graphs/",
          "author": null,
          "description": "Wondering if anyone has some interesting loss graphs that they could share. Maybe loss suddenly dropped after 100 epochs, or a local minima was found and then it jumped into a lower one. Wondering if anyone forgot to turn off training and cam back to an improved result than what they thought had already been converged to. \n    submitted by    /u/HStuart18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179seow/d_interesting_loss_graphs/",
          "publishedOn": "2023-10-17T07:01:53.000Z",
          "wordCount": null,
          "title": "[D] Interesting loss graphs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179j7l3/d_exploring_methods_to_improve_text_chunking_in/",
          "author": null,
          "description": "Hello everyone,\n I'm currently working on Retrieval Augmented Generation (RAG) models and have developed a custom chunking function, as I found the methods in LangChain not entirely satisfactory.\n I'm keen on exploring other methods, algorithms (related to NLP or otherwise), and models to enhance text chunking in RAG. There are many RAG implementations out there, but I've noticed a lack of focus on improving chunking performance specifically.\n Are there any other promising approaches beyond my current pipeline, which consists of a bi-encoder (retriever), cross-encoder (reranker), and a Large Language Model (LLM) for interactions?\n For queries, I'm using both traditional and HyDE (Hypothetical Document Embedding) approaches in the retrieval phase, and sending the top 'n' results of both similarity search to the reranker.\n I've also tried using an LLM to convert the query into a series of 10-20 small phrases or keywords, which are then used as the query for the retriever model. However, the results vary depending on the LLM used. To generate good keywords (with a not extractive approach) , I had to use a \"CoT\" prompt, instructing the model to write self-instruct, problem analysis and reasonings before generating the required keywords. But this approach use lots of tokens, and requires careful scraping to ensure the model has used the right delimiter to separate reasoning and the actual answer.\n I'm also planning to modify the text used to generate embeddings, while returning the original text after the recall phase. But this is still a work in progress and scaling it is proving to be a challenge. If anyone has any tips or experience with this, I'd appreciate your input.\n I'd be grateful for any resources, repositories, libraries, or existing implementations of novel chunking methods that you could share. Or we could just discuss ideas, thoughts, or approaches to improve text chunking for RAG here.\n Thanks in advance for your time!\n    submitted by    /u/BXresearch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179j7l3/d_exploring_methods_to_improve_text_chunking_in/",
          "publishedOn": "2023-10-16T22:49:06.000Z",
          "wordCount": 2838,
          "title": "[D] Exploring Methods to Improve Text Chunking in RAG Models (and other things...)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179htp8/d_rate_my_gpu_server_for_deep_learning/",
          "author": null,
          "description": "I started learning deep learning last year and decided to step up my game with regard to model training and tools.\n I recently built a GPU server. It’s still within its return period, so please help decide if it’s worth keeping:\n Processor: 2x Xeon E5-2690 v4 2.6GHz 14-Core Memory: 128GB GPU: 8x NVIDIA Tesla P100 16GB HBM2 Accelerator Card\n Total cost: ~$3200\n    submitted by    /u/Stonks-Stocks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179htp8/d_rate_my_gpu_server_for_deep_learning/",
          "publishedOn": "2023-10-16T21:50:12.000Z",
          "wordCount": 2584,
          "title": "[D] Rate my GPU server for Deep Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179hkg8/n_how_to_apply_to_grad_school_webinars_by_cmu_ri/",
          "author": null,
          "description": "We are hosting a few \"How to Apply to Grad School\" webinars this week. This is a chance to hear from faculty and students in the Robotics Institute at CMU on what life in grad school is actually like, as well as get some tips on crafting a strong application!\n https://cmu-ri-resources.github.io/\n    submitted by    /u/bart-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179hkg8/n_how_to_apply_to_grad_school_webinars_by_cmu_ri/",
          "publishedOn": "2023-10-16T21:39:45.000Z",
          "wordCount": 2576,
          "title": "[N] \"How to Apply to Grad School\" webinars by CMU RI!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179hgov/r_microsoft_presents_tablegpt_tabletuned_gpt_for/",
          "author": null,
          "description": "Tables pack tons of relational data but are tough for AI to grasp. They have complex 2D structure with information scattered across rows and columns. Models like GPT-3 fail basic tasks like finding where a missing value should go.\n LLMs struggle at this because they're pre-trained mostly on natural text, which is linear. Researchers at Microsoft wanted to mitigate this with \"table-tuned\" models, trained on table-related tasks.\n Their process:\n  \nAutomatically generate lots of diverse table-task training cases from a corpus of real-world tables. Ex: \"impute missing value\" or \"identify error in table\".\n Further augment data via paraphrasing, shuffling table rows/columns, chaining model responses, etc.\n  \nThis table-tuning produced \"Table-GPT\" models with substantially stronger table skills. In experiments, Table-GPT crushed vanilla GPT-3:\n  \n25%+ better on unseen table tasks like missing value ID and column type ID\n Beat GPT-3 on 98% of test cases across 9 different table tasks\n Stayed superior after downstream tuning too\n  \nThere's tons more work to do but seems pretty promising. Table-tuning boosted models' ability to comprehend tables and reason over tabular data vs just pre-training on text.\n TLDR: Training AI models more on synthesized table tasks (\"table-tuning\") significantly improves their table skills.\n Full summary is here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179hgov/r_microsoft_presents_tablegpt_tabletuned_gpt_for/",
          "publishedOn": "2023-10-16T21:35:31.000Z",
          "wordCount": 2719,
          "title": "[R] Microsoft presents Table-GPT: Table-tuned GPT for Diverse Table Tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179gnvn/d_texttopose/",
          "author": null,
          "description": "When are we getting a text-to-pose ai? I'd love to be able to generate poses for 3d models that match a given text description, because sometimes what my mind comes up with doesn't feel adequate.\n It's frustrating that I'm not seeing any developments in this area of ai, and I lack the skills to commence the developments myself.\n    submitted by    /u/BM09  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179gnvn/d_texttopose/",
          "publishedOn": "2023-10-16T21:03:15.000Z",
          "wordCount": 2574,
          "title": "[D] Text-to-pose?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179g07a/r_google_pali3_vision_language_models_contrastive/",
          "author": null,
          "description": "submitted by    /u/currentscurrents  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179g07a/r_google_pali3_vision_language_models_contrastive/",
          "publishedOn": "2023-10-16T20:36:05.000Z",
          "wordCount": 2535,
          "title": "[R] Google Pali-3 Vision Language Models: Contrastive Training Outperforms Classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179errg/d_sources_of_esoteric_data_specifically_looking/",
          "author": null,
          "description": "I am ok with paying for the data. I just can't find any sources for it.\n I found some data on github that appears to come from container ships at port, but nothing for a ship underway.\n    submitted by    /u/jschall2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179errg/d_sources_of_esoteric_data_specifically_looking/",
          "publishedOn": "2023-10-16T19:44:28.000Z",
          "wordCount": 2574,
          "title": "[D] Sources of esoteric data? Specifically looking for 6dof motion data from a medium to large oceangoing vessel underway in various sea states.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179dut0/d_adding_a_modality_to_a_pretrained_model/",
          "author": null,
          "description": "Hi,\n I have a dataset with video and other modalities (e.g. audio), and I want to run a captioning task. I found UniVL, which is a pre-trained model that supports video and text (transcripts) and can caption them. It extracts features and runs transformer encoders on both these modalities to get an embedding, then concatenates them and feeds it into a cross-encoder and decoder to get captions. I'm wondering if I can make use of this model, but add in other modalities, by writing my own embedding model and feeding the embeddings into the cross encoder. Would this work? Is there any similar previous work regarding adding new modalities to a pre-trained network?\n    submitted by    /u/joeswansonx69x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179dut0/d_adding_a_modality_to_a_pretrained_model/",
          "publishedOn": "2023-10-16T19:06:13.000Z",
          "wordCount": 2635,
          "title": "[D] Adding a modality to a pre-trained model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179awrx/d_what_is_the_current_sota_of_neural_architecture/",
          "author": null,
          "description": "I've seen classic papers before 2021 that have been quite influential - RL and evolution based strategies. I have also seen: \n  \ndifferentiable approaches: https://arxiv.org/abs/1806.09055\n zero-learning approaches: https://arxiv.org/abs/2006.04647\n  \nBut these are all papers pre-2021. \n From people who are familiar with this field, what is the current SOTA of neural architecture search (NAS) post 2022? i.e. papers that can serve as the most relevant baselines? \n Thank you! :) \n ​\n ​\n ​\n    submitted by    /u/Cultural-Average3959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179awrx/d_what_is_the_current_sota_of_neural_architecture/",
          "publishedOn": "2023-10-16T17:02:24.000Z",
          "wordCount": 2591,
          "title": "[D] What is the current SOTA of Neural Architecture Search (NAS)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179ae0r/d_is_active_learning_a_dying_field_in_industry/",
          "author": null,
          "description": "Is active learning a dying topic when zero shot learning came out?\n Active learning is to used few labeled samples plus a initially trained model to select the most useful unlabeled data for training.\n Zero/few shot learning is to train a model on some data then Mae it work directly with unseen label/data. \n In my understanding, zero/few short learning is more aligned with the current large model trend or foundation model trend. Active learning strategy seems to still rely on small dataset and was intending to gradually enrich training data by selecting new samples in.\n In industry and in big tech, which one is more used or deployed? Anyone can give me some comments?\n    submitted by    /u/Little-Bumblebee-452  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179ae0r/d_is_active_learning_a_dying_field_in_industry/",
          "publishedOn": "2023-10-16T16:41:11.000Z",
          "wordCount": 2639,
          "title": "[D] Is active learning a dying field in industry, given the development in few shot/zero shot learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1799otn/r_decoding_llm_uncertainties_for_better/",
          "author": null,
          "description": "Hi all,\n Building off our last research post, we wanted to figure out ways to quantify \"ambiguity\" and \"uncertainty\" in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: \"Structural\" and \"Conceptual\" uncertainty.\n In a nutshell: Conceptual uncertainty is when the model isn't sure what to say, and Structural uncertainty is when the model isn't sure how to say it.\n You can play around with this yourself in the demo or read about it in more detail in the blog post\n    submitted by    /u/shayanjm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1799otn/r_decoding_llm_uncertainties_for_better/",
          "publishedOn": "2023-10-16T16:11:48.000Z",
          "wordCount": 2605,
          "title": "[R] Decoding LLM Uncertainties for Better Predictability",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1799hwa/d_for_large_datasets_is_your_data_selection/",
          "author": null,
          "description": "I often hear from folks with very large datasets saying: “my labelling costs keep increasing, but we don’t see model performance improvements” or “my storage and compute costs are rising (for a dataset of 1M+ images) but performance just stalled”.\n This post argues that large datasets have hidden costs, beyond time and money, poor data quality and the wrong selection process might be killing model performance. \n Any thoughts? Have you faced this challenge?\n    submitted by    /u/btcmx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1799hwa/d_for_large_datasets_is_your_data_selection/",
          "publishedOn": "2023-10-16T16:03:49.000Z",
          "wordCount": 2599,
          "title": "[D] For large datasets, is your data selection process limiting model performance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1798mkb/p_semanticsearch_for_pdf_mining/",
          "author": null,
          "description": "Hello, everyone! I'm seeking tips to enhance my semantic search pipeline.\n Currently, I'm working on a semantic search tool. Given a set of text files, my goal is to retrieve the most relevant information related to the query.\n To achieve this, I begin by preprocessing the PDF files, splitting them into pages, and computing embeddings using a fine-tuned BERT model for Italian.\n Next, with a query and its embedding, I calculate the cosine similarity to all the pages in the document. Since there aren't many pages, a brute search remains quite fast.\n However, I'm encountering an issue where the similarity results don't consistently yield the most relevant information. I've experimented with various embedding layers, but there's been little to no improvement.\n I've also tested a commercially available solution to ensure the problem isn't with my PDF files. Interestingly, I achieved better results, leading me to believe that the issue may lie within my pipeline.\n My current hypothesis is that the page splitting process might be excluding relevant semantic connections, and I may need to improve my text preprocessing.\n What suggestions do you have to enhance my results?\n P.S.\n The information obtained from the similarity check is subsequently used as context with a chat language model, similar to tools like AsMyPdf.\n    submitted by    /u/AcquaFisc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1798mkb/p_semanticsearch_for_pdf_mining/",
          "publishedOn": "2023-10-16T15:27:04.000Z",
          "wordCount": 2729,
          "title": "[P] SemanticSearch for PDF mining",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1798jz5/d_good_compression_algo_to_compress_model/",
          "author": null,
          "description": "I have a couple of terabytes of checkpoints, and I desperately need to free up some space, without deleting those atm. Is there a compression algorithm that can handle such data successfully? I tried gzip with tar but the compressed size ended up being only ~100G less - that's when I realized that (gzip) compression algo is not good at handling seemingly random numerical data. Do you know of methods that've proven to work in this scenario?\n    submitted by    /u/OpeningVariable  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1798jz5/d_good_compression_algo_to_compress_model/",
          "publishedOn": "2023-10-16T15:24:00.000Z",
          "wordCount": 2599,
          "title": "[D] Good compression algo to compress model checkpoints?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17989fq/r_think_before_you_speak_training_language_models/",
          "author": null,
          "description": "https://arxiv.org/pdf/2310.02226.pdf\n Abstract\n Language models generate responses by producing a series of tokens in immediate succession: the (K+1)th token is an outcome of manipulating K hidden vectors per layer, one vector per preceding token. What if instead we were to let the model manipulate say, K+10 hidden vectors, before it outputs the (K+1)th token? We operationalize this idea by performing training and inference on language models with a (learnable) pause token, a sequence of which is appended to the input prefix. We then delay extracting the model's outputs until the last pause token is seen, thereby allowing the model to process extra computation before committing to an answer. We empirically evaluate pause-training on decoder-only models of 1B and 130M parameters with causal pretraining on C4, and on downstream tasks covering reasoning, question-answering, general understanding and fact recall. Our main finding is that inference-time delays show gains when the model is both pre-trained and finetuned with delays. For the 1B model, we witness gains on 8 of 9 tasks, most prominently, a gain of 18% EM score on the QA task of SQuAD, 8% on CommonSenseQA and 1% accuracy on the reasoning task of GSM8k. Our work raises a range of conceptual and practical future research questions on making delayed next-token prediction a widely applicable new paradigm.\n Here is a Medium post about my thoughts on the paper.\n    submitted by    /u/transformer_ML  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17989fq/r_think_before_you_speak_training_language_models/",
          "publishedOn": "2023-10-16T15:11:22.000Z",
          "wordCount": 2751,
          "title": "[R] Think before you speak: Training Language Models With Pause Tokens",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17974u1/d_can_direct_preference_optimization_dpo_be_used/",
          "author": null,
          "description": "DPO Paper\n I read a really fascinating paper where RL was used on LLMs to make them better at interacting in embodied environments. https://arxiv.org/abs/2310.08588\n The technique was called Reinforcement Learning with Environmental Feedback (RLEF).\n In the paper PPO was used, but I'm wondering if DPO could be used to replace it?\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17974u1/d_can_direct_preference_optimization_dpo_be_used/",
          "publishedOn": "2023-10-16T14:22:22.000Z",
          "wordCount": 2585,
          "title": "[D] Can Direct Preference Optimization (DPO) be used to replace any type of RL for LLMs, or is it better suited for just scenarios like RLHF?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17960o1/how_to_create_dataset_for_training_generative/",
          "author": null,
          "description": "i built my own custom generative ai chatbot model. only thing i need is high quality and diverse dataset to train my model. i cant use already existing datasets because i dont think they are diverse and quality enough.so i need to create it using gpt4. my dataset will have 3 columns ; system_prompt, input, output. but im not very experienced on creating datasets, and i couldnt find any resources about this. all input ,output and system prompt all should be created by gpt4. how can i do it? and what is most effective way to use api for this?\n    submitted by    /u/Many-Corner-6700  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17960o1/how_to_create_dataset_for_training_generative/",
          "publishedOn": "2023-10-16T13:30:21.000Z",
          "wordCount": 2624,
          "title": "How to create dataset for training generative chatbot model? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1795yej/p_mergellama7b_a_fine_tune_of_codellama_for/",
          "author": null,
          "description": "Merge conflicts are something that give developers hours of headaches and I figured I would try and give my take on a solution. I followed a paper from IEEE engineers in 2022 who trained CodeBert on merge conflicts as a classification task, and they published their dataset for public use.\n Input formatted as “<<<<<<< A ======= B >>>>>>>” will output the attempted conflict resolution. I am still trying to find out how to do evaluations on this model as the loss applies to all sections not just the resolution, and the TRL Trainer with a data collator gives NaN as a loss.\n The model and dataset are on HuggingFace under codys12/MergeLlama and codys12/MergeLlama-7b.\n Any feedback is appreciated!\n    submitted by    /u/cstein123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1795yej/p_mergellama7b_a_fine_tune_of_codellama_for/",
          "publishedOn": "2023-10-16T13:27:13.000Z",
          "wordCount": 2643,
          "title": "[P] MergeLlama-7b - A fine tune of CodeLlama for resolving merge conflicts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1795p5q/p_openllmetry_a_way_to_get_complete_visibility/",
          "author": null,
          "description": "Hey,\n I've built a set of extensions for OpenTelemetry that provides visibility into LLM applications like RAG pipelines - whether it be prompts, vector DBs and more. Here’s the repo: https://github.com/traceloop/openllmetry.\n Two key benefits with OpenTelemetry are - \n  \nYou can trace your entire system execution, not just the LLM (so you can see how requests to DBs, or other calls affect the overall result); \n You can connect to any monitoring platform—no need to adopt new tools. Install the SDK and plug it into Datadog, Sentry, or both. Or switch between them easily.\n  \nThere's already support for OpenAI, Anthropic, Cohere, Pinecone, Chroma, LangChain, and Haystack and we are working hard to support the entire ecosystem.\n Would love to hear your thoughts \n    submitted by    /u/nirga  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1795p5q/p_openllmetry_a_way_to_get_complete_visibility/",
          "publishedOn": "2023-10-16T13:14:24.000Z",
          "wordCount": 2649,
          "title": "[P] OpenLLMetry, a way to get complete visibility into RAG pipelines with your existing tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1795iiz/can_ai_replace_developers_princeton_and/",
          "author": null,
          "description": "Exploiting AI to make software programming easier? SWE-bench, a unique evaluation system, tests language models' ability to solve real GitHub-collated programming issues. Interestingly, even top-notch models manage only the simplest problems, underscoring tech development's urgency for providing practical software engineering solutions.\n For the latest advancements in AI, look here first.\n https://preview.redd.it/rq5vl22bckub1.png?width=1292&format=png&auto=webp&s=d79988bfe0ab37b0f97f55296d7a7341c9292c11\n A New Approach to Evaluating AI Models\n  \nResearchers use real-world software engineering problems from GitHub to assess language models' coding problem-solving skills.\n SWE-bench, introduced by Princeton and the University of Chicago, offers a more comprehensive and challenging benchmark…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1795iiz/can_ai_replace_developers_princeton_and/",
          "publishedOn": "2023-10-16T13:04:34.000Z",
          "wordCount": 2794,
          "title": "Can AI Replace Developers? Princeton and University of Chicago's SWE-bench Tests AI on Real Coding Issues [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178zy9z/how_to_design_a_chatgpt_or_bardlike_large_scale/",
          "author": null,
          "description": "I am just puzzled how does one efficiently query a huge transformer model such that so many users can be served at the same time. Is it queried on per user basis? (modulo some caching) If yes, how expensive is this? If no, what the hell is going on? :D Are there any good resources on this? (how to build large scale apps with big models, from scratch). Somehow this doesn't really fit the standard data-intensive system design process, or maybe I am missing something.\n    submitted by    /u/jimmymvp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178zy9z/how_to_design_a_chatgpt_or_bardlike_large_scale/",
          "publishedOn": "2023-10-16T06:58:25.000Z",
          "wordCount": 2615,
          "title": "How to design a Chat-GPT or Bard-like large scale app with your own foundational model? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178pbxg/sota_facial_recognition_d/",
          "author": null,
          "description": "I want to sort folders of pictures of people that are similar to an input photo by similarity. I managed to use DeepFace but I'm wondering if anyone knows a better method?\n ​\n    submitted by    /u/RedditAlreaddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178pbxg/sota_facial_recognition_d/",
          "publishedOn": "2023-10-15T21:17:16.000Z",
          "wordCount": 2550,
          "title": "SOTA Facial Recognition [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178ou60/r_reason_for_future_act_for_now_a_principled/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.17382\n Project page: https://agentification.github.io/RAFA\n Code: https://github.com/agentification/RAFA_code\n Reason for future, act for now (RAFA)\n TL;DR:\n - The first autonomous LLM agent RAFA with provable regret guarantees and outstanding empirical performances.\n - SOTA results on Game of 24, ALFWorld, BlocksWorld, and Tic-Tac-Toe.\n    submitted by    /u/WolverineUnable5957  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178ou60/r_reason_for_future_act_for_now_a_principled/",
          "publishedOn": "2023-10-15T20:56:04.000Z",
          "wordCount": 2573,
          "title": "[R] Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178nwqf/p_machine_learning_algorithm_from_scratch/",
          "author": null,
          "description": "submitted by    /u/shaongit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178nwqf/p_machine_learning_algorithm_from_scratch/",
          "publishedOn": "2023-10-15T20:13:02.000Z",
          "wordCount": 2531,
          "title": "[P] Machine Learning Algorithm from Scratch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178nfeu/dwas_any_further_work_done_on_the_paper/",
          "author": null,
          "description": "So, a few weeks ago, I got interested in the exploration problem in Reinforcement Learning and came across this amazing paper. Just wanted to know if any of you came across any paper which explores this idea more or takes it forward. Thanks in advance.\n    submitted by    /u/Interesting-Weeb-699  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178nfeu/dwas_any_further_work_done_on_the_paper/",
          "publishedOn": "2023-10-15T19:50:42.000Z",
          "wordCount": 2575,
          "title": "[D]Was any further work done on the paper \"Large-Scale Study of Curiosity-Driven Learning\" in recent years?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178ndzw/r_tool_to_brainstorm_novel_ideas/",
          "author": null,
          "description": "Hey folks,\n I developed a research tool https://idea-factory.ngrok.dev/ (Login: [temp@holistic-intelligence.net](mailto:temp@holistic-intelligence.net) Password: noidea) to identify novel research problems grounded in the scientific literature. Given an idea that intrigues you, the tool identifies the most relevant pieces of literature, creates a brief summary, and provides three possible extensions of your idea.\n I would be happy to get your feedback on the usefulness of them.\n Thank you in advance!\n    submitted by    /u/Ma7dy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178ndzw/r_tool_to_brainstorm_novel_ideas/",
          "publishedOn": "2023-10-15T19:48:51.000Z",
          "wordCount": 2586,
          "title": "[R] tool to brainstorm novel ideas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178lvvj/p_oddly_satisfying_animation_of_pixel_shuffle/",
          "author": null,
          "description": "submitted by    /u/Animated-AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178lvvj/p_oddly_satisfying_animation_of_pixel_shuffle/",
          "publishedOn": "2023-10-15T18:39:51.000Z",
          "wordCount": 2519,
          "title": "[P] Oddly Satisfying Animation of Pixel Shuffle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178ktqi/d_pipeline_for_data_processing_in_time_series/",
          "author": null,
          "description": "What is the correct pipeline for data processing when conducting time series forecasting? Should we begin with data normalization/standardization, followed by feature selection, and then split the data into training, validation, and test sets? Or is it advisable to initially split the data to prevent spill-over effects?\n I'm concerned about the possibility of training my model on (part of) the test data, which could result in spill-over effects. However, if the recommended approach is to split the data first and then perform normalization and feature selection, what impact would this have on the selected features?\n Does the manner in which we split the data into random time periods matter, or is it necessary to incorporate a validation method that accounts for temporal effects? I'm worried that the selected features might depend on the time period I choose for my training and test sets. What is the best practice in this scenario?\n    submitted by    /u/Ambitious-Pay6329  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178ktqi/d_pipeline_for_data_processing_in_time_series/",
          "publishedOn": "2023-10-15T17:51:25.000Z",
          "wordCount": 2674,
          "title": "[D] Pipeline for data processing in time series forecasting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178ko4j/r_researchers_propose_gamegpt_a_multiagent/",
          "author": null,
          "description": "Game dev is super complex nowadays - games have huge codebases, massive teams, and dev cycles dragging on for years. Costs are insane too - budgets can hit $100M+ easily.\n In a new paper, researchers propose to reverse this trend with an AI framework called GameGPT that automates parts of the dev process using multiple AI agents. Each agent handles a different role (all are fine-tuned from relevant base models):\n  \nOne agent reviews the game design plan to catch errors\n Another turns tasks into code implementations\n Reviewer agents check the code and results\n A testing agent validates everything works as expected\n  \nBy breaking up the workflow, GameGPT can simplify things for the AI agents. They just focus on a narrow role versus having one jack-of-all-trades agent.\n The authors argue GameGPT can eliminate repetitive and rote elements of gamedev like testing. This would free up developers to focus on creative design challenges.\n However, the GameGPT paper does not include any concrete results or experiments demonstrating improved performance. There is no evidence presented that GameGPT reduces hallucinations, redundancy or development time. The authors mention empirical results support their claims that the architecture is more effective, but none are provided. I could not find any additional support material about this work, like a project website, that I could use to further check into this (maybe someone can share in the comments?).\n Right now GameGPT seems mostly conceptual. The ideas are interesting but hard to assess without quantitative results.\n TLDR: New GameGPT AI framework aims to automate tedious parts of game development using specialized agents. No concrete results were provided in the paper - someone will need to test this out and report back.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178ko4j/r_researchers_propose_gamegpt_a_multiagent/",
          "publishedOn": "2023-10-15T17:43:52.000Z",
          "wordCount": 2812,
          "title": "[R] Researchers propose GameGPT: A multi-agent approach to fully automated game development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178iuvr/d_generate_audio_samples_based_on_promp_sample/",
          "author": null,
          "description": "hi,\n I would like to create a system that generate different audio samples, based on an audio sample prompt. Does anyone know whether such a project or similar ideas have been already implemented? Or any suggestion on what to read in order to realize such a project? I have knowledge in ML programming and python audio generation.\n    submitted by    /u/busconw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178iuvr/d_generate_audio_samples_based_on_promp_sample/",
          "publishedOn": "2023-10-15T16:17:40.000Z",
          "wordCount": 2579,
          "title": "[D] Generate audio samples based on promp sample",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178hcud/d_getting_bad_mfus_what_can_i_do_to_make_it_better/",
          "author": null,
          "description": "Hi, so I've been working with NanoGPT, finetuning GPT-2, and I'm getting terrible MFUs, with 5 warmup steps at -100% and normal steps have an MFU of around 3-4%. Most runs I hear of have an MFU at around 45%? How do get this better?\n Colab -> https://colab.research.google.com/drive/1gvTsyjxHiDkKHFsnWWouzr1xJWW23BA3?usp=sharing\n Code -> https://github.com/VatsaDev/NanoPhi2\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178hcud/d_getting_bad_mfus_what_can_i_do_to_make_it_better/",
          "publishedOn": "2023-10-15T15:06:43.000Z",
          "wordCount": 2571,
          "title": "[D] Getting bad MFUs, what can I do to make it better",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178hctk/d_check_out_my_latest_article_on_how_the_new/",
          "author": null,
          "description": "https://medium.com/@rishiswethan.c.r/how-gpt-4v-ision-will-revolutionise-image-annotation-b0d3ace64bff?source=friends_link&sk=4be42541a8a8ee40e18ef14533342cfd\n    submitted by    /u/Remarkable_Seesaw_89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178hctk/d_check_out_my_latest_article_on_how_the_new/",
          "publishedOn": "2023-10-15T15:06:41.000Z",
          "wordCount": 2543,
          "title": "[D] Check out my latest article on how the new improvements in GPT-4V(ision) can bring on a new ear of computer vision models, fine-tuned on outputs of GPT-4V(vision).",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178h9qr/how_to_object_detection_in_unity_any_good/",
          "author": null,
          "description": "I have tired barracuda, vuforia and it doesn’t work for some reason. And completely lost atm. It’s an object detection model to detect the circuit schematic symbols using computer vision\n    submitted by    /u/PreferenceFrosty2958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178h9qr/how_to_object_detection_in_unity_any_good/",
          "publishedOn": "2023-10-15T15:02:43.000Z",
          "wordCount": 2554,
          "title": "How to object detection in Unity any good resources [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178grpp/d_running_large_language_models_on_cpu/",
          "author": null,
          "description": "Fine-tuning large language models with the aim of obtaining a small but accurate model is extremely difficult.\n This is because you have to strike a balance between the model’s size and accuracy. Researchers from IST Austria & Neural Magic seem to have found a sweet spot. \n In their latest paper, they successfully applied sparse fine-tuning on MPT with remarkable performance. The MPT model was pruned to 75% without a drop in accuracy, showing performance that is on-par with quantization approaches. \n Particularly, the resulting sparse model can execute fast on CPUs by taking advantage of the sparsity. \n Instead of performing standard loss-based fine-tuning which may fail to recover accuracy, the researchers experiment with distillation-type losses. These losses are better at recovering accuracy at high sparsity. What’s impressive is that the sparse fine-tune LLM can achieve 7.7 tokens per second on a single core and 26.7 tokens per second on 4 cores of an cheap consumer AMD Ryzen CPU. The MPT-7B model was fine-tuned via SFT obtaining a dense baseline that showed remarkable performance. This baseline was later pruned with SparseGPT to 40% to 80% reaching 5X compression ratios. By applying SquareHead KD, FP32 models with 75% can be obtained with NO accuracy loss, outperforming cross-entropy and other KD methods. \n The paper is available on Arxiv. Sparse Finetuning for Inference Acceleration of Large Language Models: https://huggingface.co/papers/2310.06927\n MPT Sparse Finetuned on GSM8k with DeepSparse Hugging Face Space: \n https://huggingface.co/spaces/neuralmagic/sparse-mpt-7b-gsm8k\n    submitted by    /u/mwitiderrick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178grpp/d_running_large_language_models_on_cpu/",
          "publishedOn": "2023-10-15T14:39:01.000Z",
          "wordCount": 2756,
          "title": "[D] Running Large Language Models on CPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178froa/p_i_built_an_ai_writing_coach_to_proofread_your/",
          "author": null,
          "description": "submitted by    /u/hungryillini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178froa/p_i_built_an_ai_writing_coach_to_proofread_your/",
          "publishedOn": "2023-10-15T13:49:51.000Z",
          "wordCount": 2523,
          "title": "[P] I built an AI Writing Coach to proofread your work",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178ersq/r_conceptual_framework_for_autonomous_cognitive/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.06775\n GitHub: https://github.com/daveshap/ACE_Framework\n Blog post: https://medium.com/@dave-shap/autonomous-agents-are-here-introducing-the-ace-framework-a180af15d57c\n Abstract:\n  \nThe rapid development and adoption of Generative AI (GAI) technology in the form of chatbots such as ChatGPT and Claude has greatly increased interest in agentic machines. This paper introduces the Autonomous Cognitive Entity (ACE) model, a novel framework for a cognitive architecture, enabling machines and software agents to operate more independently. Drawing inspiration from the OSI model, the ACE framework presents layers of abstraction to conceptualize artificial cognitive architectures. The model is designed to harness the capabilities of the latest generative AI technologies, including large language models (LLMs) and multimodal generative models (MMMs), to build autonomous, agentic systems. The ACE framework comprises six layers: the Aspirational Layer, Global Strategy, Agent Model, Executive Function, Cognitive Control, and Task Prosecution. Each layer plays a distinct role, ranging from setting the moral compass and strategic thinking to task selection and execution. The ACE framework also incorporates mechanisms for handling failures and adapting actions, thereby enhancing the robustness and flexibility of autonomous agents. This paper introduces the conceptual framework and proposes implementation strategies that have been tested and observed in industry. The goal of this paper is to formalize this framework so as to be more accessible.\n  \n​\n https://preview.redd.it/7scnwk5a5dub1.png?width=850&format=png&auto=webp&s=371b5b02a453dcad3e70a2600cc2d625eda44133\n ​\n    submitted by    /u/Prior-Travel3670  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178ersq/r_conceptual_framework_for_autonomous_cognitive/",
          "publishedOn": "2023-10-15T12:55:00.000Z",
          "wordCount": 2732,
          "title": "[R] Conceptual Framework for Autonomous Cognitive Entities - Clemson University 2023 - Introducing the ACE Framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178cq38/d_fine_tune_llama2_with_lora_for_foreign_language/",
          "author": null,
          "description": "Hey folks,\n I watched a YouTube video, about how some LLMs tokenise languages other than English.\n For example for the Greek language you will see that this is failing totally, as one character is one token always:\n ​\n https://preview.redd.it/835p97cyhcub1.png?width=1900&format=png&auto=webp&s=944b150cc0fc112cb8cd2bac600f6fcdcc85fb1e\n My question is, if I would fine-tune it with Alpaca Lora based on Greek text, would the tokeniser change and work properly? Or the fine tune would not work as the tokeniser cannot be retrained/tuned?\n    submitted by    /u/kostakos14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178cq38/d_fine_tune_llama2_with_lora_for_foreign_language/",
          "publishedOn": "2023-10-15T10:41:46.000Z",
          "wordCount": 2595,
          "title": "[D] Fine tune Llama2 with Lora for foreign language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178b502/d_advice_for_applying_to_undergraduate_research/",
          "author": null,
          "description": "Hello, I’m a 3rd year data science and linguistics major at a top 30 school looking to land an internship at industry research.\n I’d say I’m fairly competitive. Extensive research experience. 2nd author at EMNLP, and did an REU at a prestigious institute.\n I’m already looking at some places such as AI2, but I’m curious if there are other internships I should be aware of.\n    submitted by    /u/Kai_151  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178b502/d_advice_for_applying_to_undergraduate_research/",
          "publishedOn": "2023-10-15T08:43:10.000Z",
          "wordCount": 2587,
          "title": "[D] Advice for applying to undergraduate research internships?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178avwq/d_the_history_of_neural_network_is_over_j/",
          "author": null,
          "description": "submitted by    /u/fromnighttilldawn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178avwq/d_the_history_of_neural_network_is_over_j/",
          "publishedOn": "2023-10-15T08:24:52.000Z",
          "wordCount": 2538,
          "title": "[D] The history of neural network is over. J. Schimdhuber proposes a giant network that includes all future neural network architecture as a subcomponent.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178aisk/p_how_do_i_make_my_cnn_more_efficient/",
          "author": null,
          "description": "I've been trying a variety of pre-constructed and self-made U-net-like CNNs. Had a few questions:\n  \nWhen using torch summary, is there a general formula for estimating a model's inference time/backprop time and required GPU ram based on the information torch summary gives ( Total params, Trainable params, Non-trainable params, Total mult-adds (G), Input size, Forward/backward pass size (MB), Params size (MB), Estimated Total Size (MB)), and other hyper-parameters such as batch size?\n \nWhy is my self-made model (which has smaller quantities in all the parameters torch summary outputs) requiring more GPU ram AND taking more time for inference and backprop? Is the coding style for the model's class and its forward prop a huge factor here? If so, could you please provide tips for making my code more efficient?\n Here's the notebook showcasing a pre-made model from MONAI and two of my self-made models:\n https://colab.research.google.com/drive/1VRrdnzaAbp25_DtaWTKHW5JxzyhmueMC?usp=sharing \n \nI've also listed some of my observation on the models and their results in the notebook. Any ideas or suggestion would be much appreciated.\n \n    submitted by    /u/mimivirus2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178aisk/p_how_do_i_make_my_cnn_more_efficient/",
          "publishedOn": "2023-10-15T07:58:33.000Z",
          "wordCount": 2690,
          "title": "[P] How do I make my CNN more efficient?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1786fvj/p_made_a_python_package_for_creating_api/",
          "author": null,
          "description": "submitted by    /u/squirrels-api  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1786fvj/p_made_a_python_package_for_creating_api/",
          "publishedOn": "2023-10-15T03:23:51.000Z",
          "wordCount": 2755,
          "title": "[P] Made a Python package for creating API endpoints with dynamic queries.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1786bty/r_supercharging_reinforcement_learning_with_logic/",
          "author": null,
          "description": "Deep reinforcement learning has led to a variety of compelling results. However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly. Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.\n ​\n https://preview.redd.it/kdhpu9qraaub1.png?width=1786&format=png&auto=webp&s=8155ba38fc66bd3a2fe934b1f395351c4db68e2f\n We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).\n ​\n https://preview.…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1786bty/r_supercharging_reinforcement_learning_with_logic/",
          "publishedOn": "2023-10-15T03:17:30.000Z",
          "wordCount": 2756,
          "title": "[R] Supercharging reinforcement learning with logic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1785hht/d_transformers_vs_llamacpp_vs_gptq_vs_ggml_vs_gguf/",
          "author": null,
          "description": "i am a little puzzled,\n  \ni know that transformers is the HF framework/library to load infere and train models easily\n and that llama.cpp is another framework/library that does the more of the same but specialized in models that runs on CPU and quanitized and run much faster\n i understand that GGML is a file format for saving model parameters in a single file, that its an old problematic format, and GGUF is the new kid on the block, and GPTQ is the same quanitized file format for models that runs on GPU\n  \n​\n so here is what i can't understand (assuming i got all the rest correct): \n  \ndoes HF Transformers support loading GGUF or GGML models ? \n and does GGUF needs a tokenizer json or does the data comes from within the gguf file itself\n and is safetensors (another file format) supported by both Transformers and Llama.cpp\n  \n​\n since i cannot find python examples for these combination i assume all the answers are - No\n ​\n can anyone shed some light ?\n    submitted by    /u/Particular_Flower_12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1785hht/d_transformers_vs_llamacpp_vs_gptq_vs_ggml_vs_gguf/",
          "publishedOn": "2023-10-15T02:30:17.000Z",
          "wordCount": 2693,
          "title": "[D] transformers vs llama.cpp vs GPTQ vs GGML vs GGUF",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1782m6k/d_detect_anomaly_with_small_dataset/",
          "author": null,
          "description": "Hi guys,\n I'm hoping for advice on the direction to detect detect pattern/ anomaly at small scale.\n I understand there are certain tools out there for webpage monitoring, but let's say this is just an example that I'm ingesting small amount of hourly/daily traffic to a sub webpage on my site (anywhere from 50-100 visits per day, this may mean max ~30 visits/per hour)\n There are times when traffic to the page drops as the page doesn't fully load , or the other page on which I'm hosting the link to this page doesn't load resulting in people can't see the link tothis sub page).\n Giving the scope/scale of this, amount of the data, it's not possible for me to use other solutions for anomaly detection (those that costs like $100-$1000+/month) and I'm not sure where to start with ML with this minimal amount of hourly/daily data to monitor.\n Is there anything that I should look into?\n Thank you\n    submitted by    /u/duyth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1782m6k/d_detect_anomaly_with_small_dataset/",
          "publishedOn": "2023-10-14T23:59:08.000Z",
          "wordCount": 2677,
          "title": "[D] Detect anomaly with small dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1782djg/d_foundational_must_reads_for_llms/",
          "author": null,
          "description": "Came across this post https://community.openai.com/t/foundational-must-read-gpt-llm-papers/197003\n As I am new to LLM's , Please share your thoughts on how to start and what subtopics to learn in depth ? \n ​\n    submitted by    /u/Electrical_Study_617  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1782djg/d_foundational_must_reads_for_llms/",
          "publishedOn": "2023-10-14T23:46:59.000Z",
          "wordCount": 2548,
          "title": "[D] Foundational must reads for LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177yose/d_google_automl_alternatives/",
          "author": null,
          "description": "Having jumped into AI this last year I've used Google AutoML a lot and it's honestly worked great. I primarily use it for text classification. Training usually takes anywhere from 4-8 hours.\n The results have been above 90% accurate on interference.\n Now, the problem. Cost. It's super expensive to run an endpoint for predictions with Google AutoML, for text classification.\n I'm wondering if anyone has any alternatives or ideas for similar results for cheaper. I am ok waiting for prediction results a bit as I don't need sub 1ms type responses lol.\n But everything I've tried has yielded less then optimal results. Tried various hugging face models, and accuracy is about 50%.\n    submitted by    /u/zepaz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177yose/d_google_automl_alternatives/",
          "publishedOn": "2023-10-14T20:47:29.000Z",
          "wordCount": 2630,
          "title": "[D] Google AutoML Alternatives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177ye61/r_octopus_embodied_visionlanguage_programmer_from/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.08588 \n Blog: https://choiszt.github.io/Octopus/ \n Github: https://github.com/dongyh20/Octopus \n Youtube short: https://www.youtube.com/watch?v=lHbTvB0yIP4 \n Abstract:\n  \nLarge vision-language models (VLMs) have achieved substantial progress in multimodal perception and reasoning. Furthermore, when seamlessly integrated into an embodied agent, it signifies a crucial stride towards the creation of autonomous and context-aware systems capable of formulating plans and executing commands with precision. In this paper, we introduce Octopus, a novel VLM designed to proficiently decipher an agent's vision and textual task objectives and to formulate intricate action sequences and generate executable code. Our design allows the agent to adeptly handle a wide spectrum of tasks, ranging from mundane daily chores in simulators to sophisticated interactions in complex video games. Octopus is trained by leveraging GPT-4 to control an explorative agent to generate training data, i.e., action blueprints and the corresponding executable code, within our experimental environment called OctoVerse. We also collect the feedback that allows the enhanced training scheme of Reinforcement Learning with Environmental Feedback (RLEF). Through a series of experiments, we illuminate Octopus's functionality and present compelling results, and the proposed RLEF turns out to refine the agent's decision-making. By open-sourcing our model architecture, simulator, and dataset, we aspire to ignite further innovation and foster collaborative applications within the broader embodied AI community. \n  \nhttps://preview.redd.it/1zn9q3g7a8ub1.jpg?width=1651&format=pjpg&auto=webp&s=3b14f862b24784918d6b4514bf575cf29bc65edf\n https://preview.redd.it/sv2y06g7a8ub1.jpg?width=1079&format=pjpg&auto=webp&s=be9ab7dd7cf23018b6d1fa0c584ad301b04c8abf\n https://preview.redd.it/350xc6g7a8ub1.jpg?width=942&format=pjpg&auto=webp&s=53e57541d35ca23d06b8c5be71c2b0c1910fdf90\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177ye61/r_octopus_embodied_visionlanguage_programmer_from/",
          "publishedOn": "2023-10-14T20:33:05.000Z",
          "wordCount": 2742,
          "title": "[R] Octopus: Embodied Vision-Language Programmer from Environmental Feedback - Nanyang Technological University 2023 - Continually refines its understanding and execution, demonstrating impressive adaptability!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177xp6c/r_my_article_about_autonomous_llmsbased_agents/",
          "author": null,
          "description": "A Complete Guide to LLMs-based Autonomous Agents (Part I): https://medium.com/p/69515c016792 \n My article offers a comprehensive overview of LLM-based agents, covering Chain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts, and Graph of Thoughts. \n It traces their evolution from basic forms, driven primarily by prompt engineering, to advanced models that emulate human problem-solving intricacies. Moreover, it provides an engineer's insights into the architecture behind these autonomous agents. \n  \nNaturally suitable for AI agent: LLMs feature a natural language interface tailored for user-computer interactions and they come equipped with innate reasoning abilities.\n \nLLM's Deficiency: Despite its strengths, GPT-4 can provide incorrect answers or hallucinations for complex tasks.\n \nChallenges with Training: Finetuning pretrained LLMs doesn't enhance reasoning capabilities. While creating a larger LLM can bolster its problem-solving skills, the process can span several months to a year, potentially leading to a two-year wait before its official launch.\n \nClosed Model and RAG: LLMs, once trained, are unable to fetch real-time data and have inherent shortcomings. However, for Q&A tasks, leveraging an open-book method proves more effective. The aim is not to have an all-knowing model but one skilled in reasoning and utilizing tools.\n \nLLM Agent Approach: We direct LLMs to break down intricate tasks, tackle individual sub-tasks, evaluate them, and make revisions of the strategy as needed.\n  \n   submitted by    /u/Appropriate-Map-9923  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177xp6c/r_my_article_about_autonomous_llmsbased_agents/",
          "publishedOn": "2023-10-14T20:00:00.000Z",
          "wordCount": 2758,
          "title": "[R] My article about autonomous LLMs-based agents: Chain of Thought, Plan and Solve, Self-Ask, ReAct, Reflexion, Self-Consistency, ToT, and GoT; and intrinsic insights behind an autonomous LLMs-based agents.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177xkwi/d_have_a_research_paper_to_do_for_my_masters_in/",
          "author": null,
          "description": "In my last semester and we have to pick a topic related to big data analytics. Right now I have to prepare a proposal for my topic. My topic will have to do with something to ML and the medicinal field. \n Current plan:\n  \nGet a dataset related to my topic. Right now its Parkinson's disease. My question is, for the dataset would I need a dataset with text data or would images of scans of the brain be better for detecting say early detection be better? I cant figure out which would be the better dataset.\n \nGet the dataset and then use Azure machine learning to prepare my dataset and do some data cleaning and handling and then get a model out of it. I picked azure because I have azure license from my uni and after searching about, I read about the azure machine learning service. Would azure be a good choice for training my model on this task? I've mostly used google colab for training small models. \n \nOnce the model is trained and setup. I want to setup a front end web app (flask) and then setup my model so that users can upload either text data or image scans and then model would output results regarding the inputted data. My question is, would it be ideal to have the model located on my local machine or would azure let me do api calls between my local to the azure trained model? \n \n Would all this be feasible to do? I'm not looking to develop a full fledge application, just want to create a model with a dataset of images or text and then be able to feed new images to the trained model and get an output. \n Just looking for opinions or advice on this topic.\n Thanks.\n    submitted by    /u/Jesustakethewheeeeel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177xkwi/d_have_a_research_paper_to_do_for_my_masters_in/",
          "publishedOn": "2023-10-14T19:54:14.000Z",
          "wordCount": 2838,
          "title": "[D] Have a research paper to do for my masters in Big Data Analytics. Wanted to do something with ML. Just look for some advice.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177xh7c/d_is_the_topic_of_your_ml_phd_important/",
          "author": null,
          "description": "I read the previous discussion on whether a PhD is required in the field, and I had a follow-up question: does the topic of your PhD matter? So let’s say you finish a PhD in the field of medical machine learning (non-CV), would an automotive company, FAANG, or e.g. DeepMind still like to hire you once you would like to switch your sub-field a bit? Or are you simply less desirable than a candidate without a PhD but more experience in CV?\n I am asking this because I would like to stay flexible as I have many ML sub-fields I want to work in, and I do not want to limit my options by pursuing a PhD in a topic that I don’t want work in for my entire life. For context, I do already have 2 years working experience as an AI engineer and I am finishing my AI master’s.\n    submitted by    /u/Otoz123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177xh7c/d_is_the_topic_of_your_ml_phd_important/",
          "publishedOn": "2023-10-14T19:49:23.000Z",
          "wordCount": 2674,
          "title": "[D] Is the topic of your ML PhD important?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177vrc5/d_finetuning_tortoise_tts/",
          "author": null,
          "description": "I'm planning on creating my own AI voice to use with ChatGPT. I have done my research, and there are two ways to achieve a quality TTS model to use. I have tried them both. I fine-tuned tortoise tts on my own 20-minute dataset. I have also tried to create a model using Tacotron2 and the dataset. The quality of the fine-tuned model is better. But one downside is that I still have to give the fine-tuned tortoise model a reference voice for it to choose the voice that I fine-tuned it with. On the other hand, the trained model didn't need to. The question here is: why didn't the tortoise model choose the voice in the dataset as the default? Do I need to expand my dataset for it to be chosen as the main voice? \n ​\n Thank all.\n    submitted by    /u/Capital_Birthday_654  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177vrc5/d_finetuning_tortoise_tts/",
          "publishedOn": "2023-10-14T18:26:49.000Z",
          "wordCount": 2657,
          "title": "[D] Fine-Tuning tortoise tts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177vkdz/r_do_pretrained_transformers_really_learn/",
          "author": null,
          "description": "Do pretrained Transformers Really Learn In-context by Gradient Descent?\n https://x.com/Shadowkiller331/status/1713003711629516862?s=20 \n ​\n https://preview.redd.it/zpwkh47hm7ub1.png?width=450&format=png&auto=webp&s=6def807c9c9f605e3f7839159db3402d837f6895\n    submitted by    /u/Educational-Newt2052  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177vkdz/r_do_pretrained_transformers_really_learn/",
          "publishedOn": "2023-10-14T18:17:31.000Z",
          "wordCount": 2534,
          "title": "[R] Do pretrained Transformers Really Learn In-context by Gradient Descent?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177u1i0/r_unlocking_the_power_of_sparsity_in_generative/",
          "author": null,
          "description": "submitted by    /u/markurtz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177u1i0/r_unlocking_the_power_of_sparsity_in_generative/",
          "publishedOn": "2023-10-14T17:03:54.000Z",
          "wordCount": 2541,
          "title": "[R] Unlocking the power of Sparsity in Generative Models: 8x Faster LLMs on CPUs with Sparse Fine Tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177t7je/arxiv_dives_llama_2_deep_dive/",
          "author": null,
          "description": "We’ve been diving deep into foundational papers on Fridays as a group. It’s been helpful for us to get into the nitty gritty details of these papers, so hope you find it helpful too.\n Would love to have anyone join the discussion next week!\n    submitted by    /u/FallMindless3563  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177t7je/arxiv_dives_llama_2_deep_dive/",
          "publishedOn": "2023-10-14T16:23:40.000Z",
          "wordCount": 2578,
          "title": "A[R]xiv [D]ives - Llama 2 Deep Dive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177rqvp/n_most_detailed_human_brain_map_ever_contains/",
          "author": null,
          "description": "What can this mean to artificial neural networks?\n    submitted by    /u/hhh888hhhh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177rqvp/n_most_detailed_human_brain_map_ever_contains/",
          "publishedOn": "2023-10-14T15:13:13.000Z",
          "wordCount": 2546,
          "title": "[N] Most detailed human brain map ever contains 3,300 cell types",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177qj12/d_my_fine_tune_behaves_like_the_base_model/",
          "author": null,
          "description": "Hi all, I did a fine tune of CodeLlama-7b on a custom dataset and I was getting very excited because it was doing very well on evals. \n I saved the model with model.save() and model.push_to_hub() and it seemed to work. \n When I load the model it shows the structure with the Lora_A and Lora_B for every layer, but it now acts like the base model with no changes. Is it possible I saved wrong or likely that I am loading wrong?\n Any help is greatly appreciated!\n    submitted by    /u/cstein123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177qj12/d_my_fine_tune_behaves_like_the_base_model/",
          "publishedOn": "2023-10-14T14:14:54.000Z",
          "wordCount": 2603,
          "title": "[D] My fine tune behaves like the base model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177pbg8/r_machine_learning_courses_mega_bundle_from/",
          "author": null,
          "description": "submitted by    /u/brand_momentum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177pbg8/r_machine_learning_courses_mega_bundle_from/",
          "publishedOn": "2023-10-14T13:15:13.000Z",
          "wordCount": 2528,
          "title": "[R] Machine Learning Courses Mega Bundle from Mammoth Interactive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177ok01/r_best_rl_algorithm_for_a_single_turn_game/",
          "author": null,
          "description": "Hi there, I'm new to Reinforcement Learning (RL), and the papers I've come across mainly focus on scenarios where states change with choices in a game. \n However, I'm interested in finding the best RL algorithm for a simpler case. I have an input I and a policy P. P outputs probabilities for available choices (a limited set of integers), and a reward r is given for each choice (the reward is costly to compute that’s why I use RL). The goal is to train P to maximize the reward.\n So as if we are in a game that ends after only one choice. Any recommendations for the best RL algorithm in this case?\n Thanks!\n    submitted by    /u/Meddhouib10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177ok01/r_best_rl_algorithm_for_a_single_turn_game/",
          "publishedOn": "2023-10-14T12:35:02.000Z",
          "wordCount": 2638,
          "title": "[R] best RL algorithm for a single turn game ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177nu2c/d_ways_to_get_research_experience_before_grad/",
          "author": null,
          "description": "I recently graduated with my bachelor's from a low ranked school with a good GPA. I was planning on starting a PhD studying NLP and applied to 12 mid level schools. However, I was unfortunately rejected from all the schools I applied to. I suspect it was likely due to my lack of experience in NLP research as my school didn't have any professors who do research in that area. \n My current plan is to work in industry for the next two years and try and do some NLP research on the side before reapplying. Do any NLP labs allow for external volunteer researchers? Besides that, are there any other ways to get research experience?\n    submitted by    /u/Bananas970  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177nu2c/d_ways_to_get_research_experience_before_grad/",
          "publishedOn": "2023-10-14T11:53:40.000Z",
          "wordCount": 2638,
          "title": "[D] Ways to get research experience before grad school",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177n3zr/d_validation_loss_is_decreasing_but_wer_is/",
          "author": null,
          "description": "Hi, I've been using the Huggingface library to fine-tune the Whisper model. While the WER was initially decreasing, I've noticed it began to rise even though the validation loss continues to drop. Could the issue be related to my testing on a very small dataset? As shown in the image, after 80th step the wer suddenly started increasing from 13 -> 28 \n https://preview.redd.it/xq2bm0oyh5ub1.png?width=838&format=png&auto=webp&s=136447f527bea6880b46ae588463500304b1d6bb\n ​\n    submitted by    /u/aadityaura  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177n3zr/d_validation_loss_is_decreasing_but_wer_is/",
          "publishedOn": "2023-10-14T11:09:03.000Z",
          "wordCount": 2589,
          "title": "[D] Validation loss is decreasing but WER is increasing in Whisper model training.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177n3xb/looking_for_an_easytouse_api_to_train_image_model/",
          "author": null,
          "description": "Yo!\n I have some images I curated on MJ, I want to run these together into an AI and spit out more outputs like these.\n The current process has me get maybe .2% successful outputs through MJ I figure the next step to more outputs is training a custom model.\n What's the easiest way to do this using a web-based API? Does this involve using Stable Diffusion?\n    submitted by    /u/AdministrativePie991  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177n3xb/looking_for_an_easytouse_api_to_train_image_model/",
          "publishedOn": "2023-10-14T11:08:55.000Z",
          "wordCount": 2591,
          "title": "Looking for An Easy-To-Use API To Train Image Model [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177mw2d/d_time_series_forecasting_on_positive_and/",
          "author": null,
          "description": "Hey 😀\n not sure if extremely trivial or really tricky.\n In the end, I want a machine that generates a time series without further input based on training data, generating a new time series every time.\n I want this to be based on a transformer.\n I want it trained with data looking like this:\n 2023-07-03 14:19:48,GOOD 2023-07-04 13:59:07,GOOD 2023-07-05 01:58:54,GOOD 2023-07-05 03:30:05,BAD 2023-07-05 05:17:43,BAD 2023-07-06 05:35:34,GOOD 2023-07-07 14:06:03,GOOD 2023-07-08 21:16:05,BAD \n with “GOOD” and “BAD” being the state of the system which is likely dependent on the time series data up to that point. I have a lot of data and it’s data points like the one above with maybe a hundred rows of data on average for a few thousand systems. Every system is independent of all others but all are identical.\n I do not want to train only on “GOOD” as this would leave out a lot of valuable data …\n Is there a way to train a time series transformer with both data that leads to GOOD as well as BAD outcomes, so it would generate time series from scratch that are unlikely to have BAD outcomes?\n Thank you!!\n    submitted by    /u/_VeniVidiVeni_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177mw2d/d_time_series_forecasting_on_positive_and/",
          "publishedOn": "2023-10-14T10:54:51.000Z",
          "wordCount": 2714,
          "title": "[D] Time Series Forecasting on positive AND negative Examples",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177mm5z/p_vgslify_transform_your_tensorflow_model/",
          "author": null,
          "description": "Hey r/MachineLearning! 🚀\n Have you ever been frustrated with the lengthy and sometimes cumbersome TensorFlow code for defining models? Or wished you could experiment with different architectures without dealing with copious lines of code? That's where VGSLify steps in.\n Why Use VGSLify?\n  \nCompact Definitions: VGSLify leverages VGSL spec, enabling you to express intricate model architectures in a compact and elegant manner. This means you can quickly experiment with different models by simply tweaking a string format, bypassing the verbose code traditionally required.\n Swift Prototyping: Craft intricate neural network architectures using succinct VGSL spec strings, allowing you to iterate faster and more efficiently.\n From TensorFlow to VGSL: Got a pre-existing TensorFlow model? Easily co…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177mm5z/p_vgslify_transform_your_tensorflow_model/",
          "publishedOn": "2023-10-14T10:36:28.000Z",
          "wordCount": 2772,
          "title": "[P] VGSLify: Transform Your TensorFlow Model Prototyping Experience",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177lxzr/d_how_important_is_a_phd_for_industry/",
          "author": null,
          "description": "I'm 21 years old and currently pursuing a master's degree in theoretical physics in the UK. I have a strong interest in machine learning and have completed many computing courses as well as independent projects in this field.\n I'm considering a career in machine learning and I'm curious about the benefits of doing a PhD. I've heard that the salary difference may not be substantial. Could anyone provide insights on how important a PhD is for specific roles in this field? Additionally, what factors should I consider when deciding whether to pursue a PhD in machine learning, apart from my passion for ML?\n Also are private PhDs common in ML. Working in a company and asked them to pursue a PhD within the company?\n Thanks :)\n    submitted by    /u/Neat-Print2792  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177lxzr/d_how_important_is_a_phd_for_industry/",
          "publishedOn": "2023-10-14T09:49:51.000Z",
          "wordCount": 2648,
          "title": "[D] How important is a PhD for industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177l731/d_shap_mask_token_why_does_it_matter_and_which/",
          "author": null,
          "description": "submitted by    /u/Being-Nothingness  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177l731/d_shap_mask_token_why_does_it_matter_and_which/",
          "publishedOn": "2023-10-14T08:55:12.000Z",
          "wordCount": 2552,
          "title": "[D] SHAP mask_token: why does it matter and which one to choose?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177fw1f/r_promptbreeder_selfreferential_selfimprovement/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177fw1f/r_promptbreeder_selfreferential_selfimprovement/",
          "publishedOn": "2023-10-14T03:00:59.000Z",
          "wordCount": 2532,
          "title": "[R] Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177cswd/d_is_there_a_good_code_or_text_model/",
          "author": null,
          "description": "i am trying to detect code segments in a text response of an LLM, so i can highlight them using Highlight,JS,\n ​\n is there a good model that can do the classification of a block of text and decide if it is a block of code or a block of NLP simple text (english) ?\n    submitted by    /u/Particular_Flower_12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177cswd/d_is_there_a_good_code_or_text_model/",
          "publishedOn": "2023-10-14T00:16:27.000Z",
          "wordCount": 2572,
          "title": "[D] is there a good Code or Text model ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1779u9h/p_app_for_ios_and_m1_macos_for_image_bounding_box/",
          "author": null,
          "description": "ClassifyML is an application for creating specialised image datasets for use with an ML training algorithm. Simply import your chosen images into the app via file manager, drag'n'drop or the on device camera and create your bounding boxes and then export your images and JSON into a structured folder. \n LINK: https://apps.apple.com/app/classify-ml/id6461013113\n https://preview.redd.it/dicsq9d3k1ub1.png?width=313&format=png&auto=webp&s=7976a61f599c658d948dec12db0b8ec93274ad93\n https://preview.redd.it/3tswxdd3k1ub1.png?width=313&format=png&auto=webp&s=56ca30546984402f4dbba628b73732918e921758\n https://preview.redd.it/y0xelmz3k1ub1.png?width=313&format=png&auto=webp&s=a755ea61bc247c6aacb61a31c700e4e80a1ed69f\n    submitted by    /u/LiamRogers99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1779u9h/p_app_for_ios_and_m1_macos_for_image_bounding_box/",
          "publishedOn": "2023-10-13T21:54:44.000Z",
          "wordCount": 2577,
          "title": "[P] App for iOS and M1 macOS for image bounding box annotation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1779tv0/d_what_are_the_best_resources_for_learning/",
          "author": null,
          "description": "Recently I came across Open AI's Spinning Up Project, which seems to be well structured, but quite introductory. What are some resources you use for learning RL? \n    submitted by    /u/OwnAd9305  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1779tv0/d_what_are_the_best_resources_for_learning/",
          "publishedOn": "2023-10-13T21:54:13.000Z",
          "wordCount": 2551,
          "title": "[D] What are the best resources for learning reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17798uq/d_llm_for_entityscene_recognition_in_a_book/",
          "author": null,
          "description": "Hello, I'm looking for an open source LLM that can extract all the characters from an inputted book, and isolate passages with descriptive writing that involves imagery. Can anyone suggest me something? Thanks!\n    submitted by    /u/slomorosh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17798uq/d_llm_for_entityscene_recognition_in_a_book/",
          "publishedOn": "2023-10-13T21:28:44.000Z",
          "wordCount": 2555,
          "title": "[D] LLM for entity/scene recognition in a book?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17788eq/p_deploy_and_run_llms_at_the_edge_use_code_llama/",
          "author": null,
          "description": "In this blog, we explore different definitions of “the edge,” and understand the factors driving AI/ML to the edge. We examine why the trends of LLMs and edge computing are intersecting now, and how teams can take advantage of their combined power today. We also demonstrate how LLMs can be used in an edge environment to generate insights for a real-world use case today. Consider a geologist working in a remote oil field who is responsible for building and analyzing 3D models of oil fields to determine production capacity and the impact on profitability. In this demo, we walk through how Code Llama, Chassisml.io, and Modzy could be used to build a dashboard that geologists could use to analyze well data in real-time in a remote, network restricted environment, allowing for LLM insights generated at the edge.\n Learn more: https://www.modzy.com/modzy-blog/deploy-and-run-llms-at-the-edge\n    submitted by    /u/modzykirsten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17788eq/p_deploy_and_run_llms_at_the_edge_use_code_llama/",
          "publishedOn": "2023-10-13T20:43:49.000Z",
          "wordCount": 2674,
          "title": "[P] Deploy and Run LLMs at the Edge: Use Code Llama to Generate a Dashboard in a Network Restricted Environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1774n7g/d_iclr_submissions_are_out_discussion_thread/",
          "author": null,
          "description": "https://openreview.net/group?id=ICLR.cc/2024/Conference\n    submitted by    /u/_puhsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1774n7g/d_iclr_submissions_are_out_discussion_thread/",
          "publishedOn": "2023-10-13T17:59:11.000Z",
          "wordCount": 2516,
          "title": "[D] ICLR submissions are out. Discussion thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1772uyv/d_vscode_issue/",
          "author": null,
          "description": "I am running AutoTokenizer from transformers on vscode. The vscode crashes showing error and not responding. I don't understand what's wrong.\n    submitted by    /u/ArtichokeOne5897  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1772uyv/d_vscode_issue/",
          "publishedOn": "2023-10-13T16:35:21.000Z",
          "wordCount": 2532,
          "title": "[D] Vscode issue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771sog/p_utilizing_machine_learning_techniques_for/",
          "author": null,
          "description": "Hey Guys,\n ​\n I am currently spearheading a project for a client in the insurance industry, with a primary objective being the digitalization of thousands of hardcopy contracts. The ultimate goal is to automatically extract particular information from these newly digital documents, namely \"date\", \"insurance premium\", \"insurance type\", and \"contractor's name\". However, I anticipate a level of variability in terms of exact terminology used, particularly with regards to \"insurance premium\" and \"insurance type\". (There is no handwritten text)\n ​\n I am keen on sharing the methodology I intend to apply for this project and invite your invaluable feedback and suggestions:\n ​\n - Firstly, I'll execute the scanning/digitalization of the documents manually.\n - Post this, I plan to utilize Tesseract in combination with Python for the extraction of text from the preprocessed images.\n - I am considering using libraries such as NLTK or spaCy to preprocess this text (this will involve steps like lower casing, removing punctuations, etc.)\n - Finally, I plan to train a custom model for Named Entity Recognition (NER), to accommodate the potential semantic variations in entity labeling which are specific to entities like \"insurance premium\" and \"insurance type\".\n ​\n I would be immensely grateful if I could gain your insights on the above-proposed pipeline - Are there any glaring pitfalls I need to avoid or perhaps some improvements that I could incorporate? Your expert advice can certainly help ensure the success of this venture.\n ​\n Many thanks in anticipation for your time and valuable inputs!\n    submitted by    /u/Background_Thanks604  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771sog/p_utilizing_machine_learning_techniques_for/",
          "publishedOn": "2023-10-13T15:48:13.000Z",
          "wordCount": 2766,
          "title": "\"[P]\" Utilizing Machine Learning Techniques for Document Digitalization Project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771m35/news_ai_ml_conference_in_san_francisco_special/",
          "author": null,
          "description": "I work for this database company SingleStore and we are hosting a AI & ML conference in San Francisco on 17th of October, 2023.\n It is an in-person conference with amazing speakers line-up like Harrison Chase, co-founder and CEO of LangChain and many more. We will have hands-on workshops, swags giveaway and much more.\n I don't know if it makes sense to share this but I believe it might help some of you near San Francisco to go and meet the industry leaders and network with other data engineering folks.\n Use my discount coupon code 'PAVAN100OFF' to avail 100% off on the ticket price. (the original ticket price is $199)\n Get your tickets now!\n    submitted by    /u/PavanBelagatti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771m35/news_ai_ml_conference_in_san_francisco_special/",
          "publishedOn": "2023-10-13T15:40:09.000Z",
          "wordCount": 2642,
          "title": "[News] AI & ML conference in San Francisco [Special discount code for this subreddit]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771kn7/using_rag_on_coreml_version_of_llama2_p/",
          "author": null,
          "description": "Has anyone ever attempted this or finetuning before on the CoreML version? I’m currently trying to and I’m not even sure where to start tbh. \n CoreML version of Llama 2: https://huggingface.co/coreml-projects/Llama-2-7b-chat-coreml\n    submitted by    /u/Inside-Aromatic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771kn7/using_rag_on_coreml_version_of_llama2_p/",
          "publishedOn": "2023-10-13T15:38:15.000Z",
          "wordCount": 2553,
          "title": "Using RAG on CoreML version of Llama2 [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771jhl/d_how_does_l1_regularization_able_to_drive_a/",
          "author": null,
          "description": "Hi all, \n I’m studying the concepts of machine learning. However, I am stuck because I still don’t see how introducing a penalty using lasso regression can drive some parameter coefficients to zero. When doing the calculations, I only get the final value (ordinary least squares + penalty) and don’t directly see a coefficient value being reduced. \n I've looked at many materials and resources trying to explain this, but I still can't see how it's done. I think the important thing for me is seeing it going to zero or, at the very least, seeing it during calculation. Is there anyone that can help explain this better? Or, If you know of a formula that I can derive that, during the derivation process, shows a coefficient being reduced or set to zero, that would also help.\n Also, any good resources on the topic would be appreciated.\n Edit:\n This post should have been posted in r/learnmachinelearning\n here is a link to the same post in that subreddit\n    submitted by    /u/thismymind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771jhl/d_how_does_l1_regularization_able_to_drive_a/",
          "publishedOn": "2023-10-13T15:36:44.000Z",
          "wordCount": 2691,
          "title": "[D] How does L1 Regularization able to drive a coefficient to zero?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771hs4/d_how_do_you_prepay_openaai_compute_credit_with/",
          "author": null,
          "description": "I am an academic and I have some funding. However, I cannot just plug in my lab card with a recurrent payment, procedures don't allow it.\n Is there a way to \"top up\" some compute credits on the OpenAI accounts ? Is anyone having the same problem ? Thanks.\n    submitted by    /u/Jean-Porte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771hs4/d_how_do_you_prepay_openaai_compute_credit_with/",
          "publishedOn": "2023-10-13T15:34:34.000Z",
          "wordCount": 2574,
          "title": "[D] How do you pre-pay OpenaAI compute credit with university funds ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771ccn/r_seeking_guidance_on_efficiently_classifying_and/",
          "author": null,
          "description": "Hi, we are working on a project that involves dealing with messy automotive data, and are looking for guidance on possible approaches and tools.\n We aim to map messy supplier data of car makes/models to standardized values from our approved list. This requires handling various challenges like typos, varied specificity, and sometimes research-based mapping (e.g., using engine size and production year to ascertain a chassis code).\n eg: If a supplier provides 'BNW 316i saloon 1990-1994', (typo intentional) we would like to match it to our standardized value of 'BMW 3 Series (E36)'.\n Our old approach has been a combination of utilizing fuzzy matching for typos/basic matching and time consuming manual processing and verification.\n We have recently experimented with using GPT for providing guess…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771ccn/r_seeking_guidance_on_efficiently_classifying_and/",
          "publishedOn": "2023-10-13T15:27:56.000Z",
          "wordCount": 2857,
          "title": "[R] Seeking Guidance on Efficiently Classifying and Cleansing Automotive Data with Python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1770z8m/r_lemur_harmonizing_natural_language_and_code_for/",
          "author": null,
          "description": "Today's conversational bots like Claude and GPT can chat impressively but aren't great at complex planning or executing technical tasks. To overcome this, new research from HKU builds open-source AI agents that blend natural language and coding skills. They're called Lemur and Lemur-Chat.\n The researchers think achieving versatile real-world agents requires models that integrate both fluid natural language abilities and precise programming language control. Humans combine plain speech for higher-level goals with languages like Python when we need to plan intricately and execute exactly. AI needs both capacities too.\n But most existing models specialize in pure language or pure code. There's a separation that is limiting.\n The team created Lemur by pretraining the open-source Llama-2 on a massive mixed corpus with 10x more natural language than code. This improved its programming abilities while retaining conversational strength. Further instruction tuning optimized Lemur-Chat for following free-form directions in language.\n Experiments found Lemur surpassed specialized coding-only models like Codex in overall benchmarks. Lemur-Chat then exceeded Lemur by 15% after instruction tuning.\n More importantly, Lemur-Chat won 12/13 new \"agent tests\" designed to mimic real-world challenges needing both language and programming prowess.\n It beat alternatives at:\n  \nUsing tools like Python and Wikipedia to enhance reasoning\n Debugging code by leveraging error messages\n Improving the most from natural language feedback\n Exploring partially observable environments like cybersecurity and web browsing simulations.\n  \nLemur-Chat matched GPT-3.5 in many tests, closing the gap between commercial and open-source agents.\n TLDR: New open-source AI agents combine coding and language skills. Experiments show the combo unlocks more performance across technical challenges.\n Full summary is here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1770z8m/r_lemur_harmonizing_natural_language_and_code_for/",
          "publishedOn": "2023-10-13T15:11:34.000Z",
          "wordCount": 2788,
          "title": "[R] Lemur: Harmonizing Natural Language and Code for Language Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1770hqf/p_introducing_ppo_and_rainbow_dqn_to_our_super/",
          "author": null,
          "description": "Hi, we've just released a new version of AgileRL, our evolutionary hyperparameter optimisation framework built for RL that is 10x faster than SOTA. \n We've introduced PPO, Rainbow DQN, some sophisticated replay buffers, and also collaborated with the Farama Foundation to create some tutorials (more on the way).\n Please check it out and take it for a spin. We're also looking for contributors so get in touch if you would like to be involved!\n https://github.com/AgileRL/AgileRL\n    submitted by    /u/nicku_a  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1770hqf/p_introducing_ppo_and_rainbow_dqn_to_our_super/",
          "publishedOn": "2023-10-13T14:50:00.000Z",
          "wordCount": 2603,
          "title": "[P] Introducing PPO and Rainbow DQN to our super fast evolutionary HPO reinforcement learning framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17706n5/p_free_opensource_ml_observability_course_starts/",
          "author": null,
          "description": "Hi everyone, I’m one of the creators of Evidently, an open-source (Apache 2.0) tool for production ML monitoring. We’ve just launched a free open course on ML observability that I wanted to share with the community.\n The course covers:\n 📚 Key concepts of ML monitoring and observability (data drift, data and model quality metrics, etc.)\n 🔡 Monitoring unstructured data (embeddings, texts, LLMs, etc.) \n 🛠 Different deployment architectures (batch ML monitoring jobs, near real-time ML monitoring, etc.)\n The course is free and open. All materials are public, with no sign-up required. You’ll work with open-source tools like Evidently, MLflow, Airflow, and Grafana. \n We’ve already published the first 12 videos with notes and code examples. We’ll add new lessons and deployment blueprints over the following weeks.\n The official course start date is October 16, 2023. You can also learn at your own pace.\n Course info and notes: https://learn.evidentlyai.com/ \n [Background] We’ve been working on Evidently since late 2020 and have spoken to 100s of data scientists, ML engineers, and ML platform teams in different industries. In this course, we tried to sum up answers to the frequent questions on the topic. It starts with high-level theoretical modules and goes to complete deployment blueprints. It is approachable for different levels of knowledge, and you can pick only the modules you are interested in. \n Looking forward to meeting you at the course!\n    submitted by    /u/mllena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17706n5/p_free_opensource_ml_observability_course_starts/",
          "publishedOn": "2023-10-13T14:35:20.000Z",
          "wordCount": 2751,
          "title": "[P] Free open-source ML observability course: starts October 16 🚀",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176yocg/can_i_use_arcpro_to_do_machine_learning_on_point/",
          "author": null,
          "description": "I am trying to do machine learning in ArcPro, and I want to understand the relationship between x, y, numeric variable 1, numeric variable 2, and one nominal variable (classified; i.e. can be one of four values). I'd like to be able to predict numeric variable 1 based on everything else. Can ArcPro accommodate machine learning for anything other than raster type data. That is, can it be used to do machine learning on point (numeric) data? Thanks! \n    submitted by    /u/arcgis_123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176yocg/can_i_use_arcpro_to_do_machine_learning_on_point/",
          "publishedOn": "2023-10-13T13:24:03.000Z",
          "wordCount": 2606,
          "title": "Can I use ArcPro to do machine learning on point (numeric) data? [D] [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176wsne/r_timegpt_the_first_generative_pretrained/",
          "author": null,
          "description": "In 2023, Transformers made significant breakthroughs in time-series forecasting\n For example, earlier this year, Zalando proved that scaling laws apply in time-series as well. Providing you have large datasets ( And yes, 100,000 time series of M4 are not enough - smallest 7B Llama was trained on 1 trillion tokens! )\n Nixtla curated a 100B dataset of time-series and trained TimeGPT, the first foundation model on time-series. The results are unlike anything we have seen so far.\n I published the results in my latest article. I hope the research will be insightful for people who work on time-series projects.\n Link: https://aihorizonforecast.substack.com/p/timegpt-the-first-foundation-model \n Note: If you know any other good resources on very large benchmarks for time series models, feel free to add them below.\n ​\n    submitted by    /u/nkafr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176wsne/r_timegpt_the_first_generative_pretrained/",
          "publishedOn": "2023-10-13T11:43:09.000Z",
          "wordCount": null,
          "title": "[R] TimeGPT : The first Generative Pretrained Transformer for Time-Series Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176vgdn/r_pointers_to_deep_latent_variable_models_that/",
          "author": null,
          "description": "Hi everyone.\n I am aware that there is a plethora of deep generative models out there (e.g. variational autoencoders (VAE), GANs) that can model high-dimensional data as the images of latent variables under a non-linear mapping (typically neural network).\n In more traditional methods such as probabilistic PCA, the latent variables can be marginalised analytically. In Bayesian PCA (BPCA), we can additionally integrate out the linear mapping, from the latent space to the observation space, by adopting the variational lower bound that leads to closed form updates of the parameters. The Gaussian Process Latent Variable (GPLVM) model adopts a non-linear probabilistic mapping (a Gaussian process) that can be marginalised. These two models enjoy to a certain degree analytical solutions concerning the inference of the latent variables and the mapping.\n I have been wondering whether there is any research into more \"complex\" models (perhaps I should call them deep) that are capable of modelling more complex data distributions than the GPVLM and BPCA, but retain analytical solutions when inferring the posterior of the latent variables (like BPCA) or the mapping (like GPLVM)?\n What I like about the GPLVM and BPCA is that they possess an objective function (i.e. ELBO) that can be analytically optimised, as opposed to the intractable objective of VAEs that necessitates Monte-Carlo averages and stochastic gradient. Could somebody please point me to such examples of more complex generative models that admit analytical inference for working out the posterior of the latent variables or the mapping?\n -----\n This has also been posted on stack exchange: https://ai.stackexchange.com/q/42418/61537\n    submitted by    /u/ngiann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176vgdn/r_pointers_to_deep_latent_variable_models_that/",
          "publishedOn": "2023-10-13T10:17:39.000Z",
          "wordCount": 2781,
          "title": "[R] Pointers to (deep) latent variable models that admit analytical approximations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176uov8/d_i_love_teaching_but_i_dont_have_enough/",
          "author": null,
          "description": "Do I love teaching? Oh, absolutely, YES a big YES! My time as a TA for countless semesters has been amazing. Staying after hours, spending long evenings and early mornings, to make each of my students find ease in debugging both easy-peasy and mind-boggling programs – it’s been a joy, truly. Watching those fresh faces, whom I introduced to Python in their first year ( intro to programming lab), now immerse themselves into my computer vision labs, exploring computer vision and deep learning in their third/forth year – it’s incredibly rewarding! And yeah my students kind of like me! after each semester I get tons of emails thanking me and my TAship review is always good.\n But, ugh, do I have enough publications to become faculty? A big fat NO! My efforts have been relentless, and everyone in my department would nod in agreement. But luck and reviewers? Not my best pals, apparently. So yeah, I don’t have a stack of 8 top-tier papers. I’ve managed to scrape together 3, and a few second tiers. My citation count is not that bad somewhere between 200 and 300-ish.\n Now, what’s next for me? Dive into the industry? become a high school teacher? Or perhaps, do a postdoc journey, fingers crossed for a sprinkle more luck and few more papers?\n Edit: This doesn't mean I don't like research, I actually love it too, I have done quite a few internship in quite big companies, most of the time they extend my intership and I even got publication out of one in 5 month. But I just like to teach a lot! strangely I got social anxiety every where other than my classrooms/labs.\n    submitted by    /u/LongjumpingSchool646  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176uov8/d_i_love_teaching_but_i_dont_have_enough/",
          "publishedOn": "2023-10-13T09:23:00.000Z",
          "wordCount": 2810,
          "title": "[D] I love teaching! But I don't have enough publication for it, what should I do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176rwv3/d_you_dont_need_a_vector_database_you_just_need_a/",
          "author": null,
          "description": "I'm seeing some architectures come out from the LLM world that probably wouldn't survive the trip to production.\n If you choose a vector database how will you handle your other database needs? Then you'll need 2 databases.\n https://bionic-gpt.com/blog/you-dont-need-a-vector-database/\n    submitted by    /u/purton_i  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176rwv3/d_you_dont_need_a_vector_database_you_just_need_a/",
          "publishedOn": "2023-10-13T06:05:46.000Z",
          "wordCount": 2564,
          "title": "[D] You don't need a Vector Database you just need a database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176rt6l/d_why_backpropagation_is_intractable_of_moco_key/",
          "author": null,
          "description": "In the original paper of MoCo, it said that:\n  \nUsing a queue can make the dictionary large, but it also makes it intractable to update the key encoder by back-propagation (the gradient should propagate to all samples in the queue).\n  \nFirst I thought that the main reason that the bp cannot imply on key encoder is that the queue operation is not differentable. But It seems not true. You can compute the gradient of all samples in the queue, then bp should be performed properly. See the code at the bottom.\n So WHAT IS THE REAL REASON THAT THE BP IS INTRACTABLE FOR KEY ENCODER? In my opinion, I think may be because of the large size of the queue (dictionary) which makes the memory explosive.\n python q = nn.Linear(768,128) k = nn.Linear(768,128) bs = 64 ks = 4095 model = nn.ModuleList([q,k]) x = torch.randn(bs, 768) optim = torch.optim.SGD(model.parameters(),lr=0.01) loss = nn.CrossEntropyLoss() def forward(x): xq = q(x) xk = k(x + 0.1) que = torch.rand(ks,128) pos = torch.einsum(\"nc,nc->n\",xq,xk) neg = torch.einsum(\"nc,kc->nk\",xq,que) out = torch.cat([pos.unsqueeze(-1),neg],dim=1) t = torch.zeros(out.shape[0],dtype=torch.long) l = loss(out,t) return l loss = forward(x) loss.backward() optim.step() \n    submitted by    /u/whishtLF  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176rt6l/d_why_backpropagation_is_intractable_of_moco_key/",
          "publishedOn": "2023-10-13T05:59:56.000Z",
          "wordCount": 2703,
          "title": "[D] Why back-propagation is intractable of MoCO key encoder?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176mlrr/d_advisor_rejects_every_idea_i_propose/",
          "author": null,
          "description": "A senior phd student at a moderately famous university. I have a reasonable number of accepted papers as first author in tier-1 conferences. I was thinking of going into academia, so recently I started proposing many ideas to my advisor so that I can mentor some junior students. However my advisor is rejecting every idea I suggest saying it won’t work. I’m feeling very dejected and I feel like I should give up going into academia. I don’t know what I’m expecting from here. Is your advisor like this too?\n    submitted by    /u/mildlyphd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176mlrr/d_advisor_rejects_every_idea_i_propose/",
          "publishedOn": "2023-10-13T01:00:53.000Z",
          "wordCount": 2611,
          "title": "[D] Advisor rejects every idea I propose.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176ia5w/r_researchers_identify_emergent_linear_structures/",
          "author": null,
          "description": "LLMs' tendency to make up false statements (hallucinate) is a major concern. We need ways to inspect whether they really \"know\" something is true or not so we can reduce hallucinations.\n In a new paper, researchers found that LLMs contain an internal \"truth vector\" - an emergent linear structure that represents factual truth values.\n They had the insight to visualize how GPT represents simple true/false sentences. The true ones clustered together, while false ones clustered elsewhere - suggesting some kind of 'truth direction' in its learned representations.\n To test this, they trained linear \"probes\" on one dataset, and found they could generalize to accurately detect truth values in totally different datasets about other topics.\n They also directly modified the models to add or subtract the identified truth vectors from its processing of statements. This could flip assessments of truth value, showing the vector causally influences reasoning.\n Together, these findings provide evidence that neural networks can create emergent, linear structures that represent factual truth. This finding could eventually help make AI systems less prone to hallucinations and falsehoods.\n TLDR: LLMs can create emergent linear representations of truth. This sheds light on how AI represents abstract concepts and could help us reduce hallucinations.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176ia5w/r_researchers_identify_emergent_linear_structures/",
          "publishedOn": "2023-10-12T21:38:42.000Z",
          "wordCount": 2731,
          "title": "[R] Researchers Identify Emergent Linear Structures in How LLMs Represent Truth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176h8id/d_recommendations_request_for_a_guide_to_research/",
          "author": null,
          "description": "I am working on a research topic in Data Engineering. Forgive me if this is a question frequently asked, I couldn't find this specifically in the FAQ. What are good publication tips and journals to publish in? I read through a few journals and all of them are big publications. What if I opt fot some upcoming or other niche (maybe data engineering) journals\n    submitted by    /u/Sherbhy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176h8id/d_recommendations_request_for_a_guide_to_research/",
          "publishedOn": "2023-10-12T20:56:46.000Z",
          "wordCount": 2587,
          "title": "[D] Recommendations request for a guide to research publication",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176f89x/r_swebench_can_language_models_resolve_realworld/",
          "author": null,
          "description": "We have a new benchmark out called SWE-bench (arxiv) \n It challenges LMs to solve real GitHub issues (feature requests & bug reports) from popular Python repos.\n Answers are validated using unit tests we crawled from those repos.\n The benchmark at swebench.com/ shows that even the strongest models, such as Claude 2 and GPT-4, get less than 5% accuracy.\n ​\n We are here to answer any questions you may have.\n    submitted by    /u/ofirpress  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176f89x/r_swebench_can_language_models_resolve_realworld/",
          "publishedOn": "2023-10-12T19:28:30.000Z",
          "wordCount": 2591,
          "title": "[R] SWE-bench: Can Language Models Resolve Real-world GitHub issues?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176efaf/d_sample_probability_diffusion_models/",
          "author": null,
          "description": "I would like to understand how I can calculate the probability that a sample belongs to the distribution a diffusion model was trained on. \n Say, I have an image of a car, and I would like to know whether this image belongs to the distribution that is estimated by the diffusion model. So I would like to know the probability between zero and one at the car belongs to this distribution \n Do you know how I technically can do this?\n    submitted by    /u/That_Phone6702  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176efaf/d_sample_probability_diffusion_models/",
          "publishedOn": "2023-10-12T18:52:20.000Z",
          "wordCount": 2599,
          "title": "[D] Sample probability diffusion models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176c9ty/discussion_making_a_tutorial_for_using_a_new/",
          "author": null,
          "description": "Hey guys\n Looking for some ideas. \n I'm building out a jupyter book that will be a tutorial on how to use a research platform for data analysis and modelling. My PI has given me free liberty over it.\n I can not think of a good idea to do the analysis and build the model on. It does not need to be complex but should be good enough so that any researcher, student or organization using the platform can get a good idea of how to use it for ML. \n Any thoughts on a good area to look into? Any recommendations? \n Note this will be a tutorial and as such an overly complex model is unnecessary. I just can not figure out what to look into so hoping you guys could give thoughts about possible areas in climate, weather and earth science that I could focus on for the tutorial in the jupyter book.\n    submitted by    /u/AdditionalFun3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176c9ty/discussion_making_a_tutorial_for_using_a_new/",
          "publishedOn": "2023-10-12T17:20:05.000Z",
          "wordCount": 2685,
          "title": "[Discussion] Making a Tutorial for Using a New Platform for ML in the climate and earth science space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1769su5/d_submitting_a_paper_rejected_by_emnlp_to_arr/",
          "author": null,
          "description": "First time submitting to ARR here. I was quite confused about this paper resubmission thing. I got rejected by EMNLP (submission directly to EMNLP with openreview) a week ago and I am planning to resubmit it to the ARR system (also using openreview). Does this EMNLP submission count as a previous ARR submission that should be mentioned or not? Do I need to withdraw the paper from EMNLP openreview prior to submitting it to ARR openreview?\n    submitted by    /u/Icy-Distribution6887  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1769su5/d_submitting_a_paper_rejected_by_emnlp_to_arr/",
          "publishedOn": "2023-10-12T15:34:12.000Z",
          "wordCount": 2599,
          "title": "[D] Submitting a paper rejected by EMNLP to ARR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1765v6i/d_p_uibased_ai_agents_uiact/",
          "author": null,
          "description": "Hi!\n Happy to share a project I've been working on for a while: UI-Act\n https://github.com/TobiasNorlund/UI-Act\n It's an AI model architecture designed to autonomously navigate and interact with computers using the graphical user interface. Think of it as a co-pilot that \"sees\" your screen and acts on it, just as a human would.\n In essence, it's a custom transformer model taking prompt and screenshots as input, with output heads to predict low-level actions i.e. mouse clicks. In the demo, it has been trained to compute simple expressions in a calculator window, using expert demonstrations/behavior cloning. If scaled up appropriately however, it could provide a basis for a general agent to automate arbitrary tasks on a computer. \n I would be interested in hearing your thoughts on it, and especially with regards to the trend towards general AI agents and assistants (Windows Copilot / Adept ACT-1 / AutoGPT etc).\n LMs equipped with e.g. function-calling is a trendy approach, that rely on text-based state representations and APIs to take action. In cases where this is unfeasible, UI-based agents might provide a more general alternative. As the agent's interface to the computer is shared with humans, it can be easily taught using expert demonstrations, and require little or no technical expertice.\n Let me know what you think!\n    submitted by    /u/tobibbelfuel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1765v6i/d_p_uibased_ai_agents_uiact/",
          "publishedOn": "2023-10-12T12:31:22.000Z",
          "wordCount": 2732,
          "title": "[D] [P] UI-based AI agents: UI-Act",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17652mm/p_learn_how_to_make_trustworthy_and_transparent/",
          "author": null,
          "description": "​\n Confidence and trustworthiness of Tsetlin Machines.\n Hi all! Just completed a new chapter in the book An Introduction to Tsetlin Machines:\n https://tsetlinmachine.org\n Happy to receive feedback!\n Abstract: Collaboration can be essential to manage complex projects. One example is building a house. You then need the expertise of carpenters, plumbers, and electricians. Each profession brings unique skills to the table. Similarly, different types of Tsetlin machines can have distinct capabilities. In this chapter, you learn how Tsetlin machines can team up, allowing them to achieve more than they could on their own.\n The effectiveness of a team relies on recognising each member's strengths and limitations. Appreciating where your expertise stops and where your coworkers' expertise begins is crucial for effective collaboration. We first explore how Tsetlin machines can assess their competence in Section 7.1. Using the vote count from Chapter 1, you learn to measure how confident a Tsetlin machine is when it makes its decisions.\n It is possible to be highly confident and still perform poorly. To be trustworthy, confidence must be in line with one's capabilities. Therefore, Section 7.1 also covers how to evaluate trustworthiness.\n Next, in Section 7.2, you discover how to build a team of Tsetlin machines with different skills. By assessing each Tsetlin machine's confidence, you can lean on the confident ones when making decisions. The result is a Tsetlin machine composite - a construction where multiple Tsetlin machines join forces. You can think of it as a composite material, such as epoxy, which reinforces resin with fibres, making it strong, lightweight, and durable.\n    submitted by    /u/olegranmo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17652mm/p_learn_how_to_make_trustworthy_and_transparent/",
          "publishedOn": "2023-10-12T11:49:50.000Z",
          "wordCount": 2793,
          "title": "[P] Learn how to make trustworthy and transparent machine learning models in Tsetlin Machine Book Chapter 7: Confidence, Trustworthiness, and Composites.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1764sk0/r_d_need_peer_review_unsupervised_learning_for/",
          "author": null,
          "description": "Hello all,\n Just wrapped up Task 1.1 for anomaly detection in student dropout rates. Keen for some extra eyes on it.\n Task Highlights:\n  \nData Pre-processing & Normalisation\n K-Means Clustering\n Gaussian Anomaly Detector\n Used PCA for dimensionality reduction\n  \nLinks to the following files:\n  \ndata.csv\n Task 1.1 - Rubric.pdf\n Task1.1Script.ipynb\n  \nhttps://drive.google.com/drive/folders/17XcjEoYCrDWqf90VVNdkLAkYNdtWWwGu?usp=sharing\n Would greatly appreciate any feedback!\n Cheers!\n    submitted by    /u/Nook31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1764sk0/r_d_need_peer_review_unsupervised_learning_for/",
          "publishedOn": "2023-10-12T11:33:27.000Z",
          "wordCount": null,
          "title": "[R] [D] Need Peer Review: Unsupervised Learning for Student Dropout Anomaly Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1761q5r/r_a_method_to_assess_trustworthiness_of_machine/",
          "author": null,
          "description": "submitted by    /u/mnky9800n  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1761q5r/r_a_method_to_assess_trustworthiness_of_machine/",
          "publishedOn": "2023-10-12T08:13:12.000Z",
          "wordCount": 2536,
          "title": "[R] A method to assess trustworthiness of machine coding at scale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175zifi/p_vilays_prototype_video_demo_any_feedback_from/",
          "author": null,
          "description": "Hi everyone,\n I’m thrilled to share a prototype we've been tirelessly working on.\n We are developing a virtualization environment for applications, specifically tailored to engineers, designers, data scientists, and researchers.\n In a nutshell, our platform enables users to run cloud-hosted desktop apps from any device, making it appear as if the applications are installed on their local machines, while they're actually operating on a remote server. The ultimate goal is to obliterate barriers between local and cloud execution, especially for compute-intensive workloads, thereby allowing seamless usage of High-Performance Computing software on the cloud with the scalability to adjust computing resources as per necessity.\n We’re here to solicit your invaluable feedback on our product video demo. Your insights will not only help us identify any blind spots and enhance our solution but also better understand the needs and preferences of our potential user base.\n 📽 [https://youtu.be/QR8FWRnPrXM?feature=shared]\n We're eagerly awaiting your thoughts and appreciate you taking the time to help us refine our product!\n Thank you! :)\n    submitted by    /u/aaron-cesaro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175zifi/p_vilays_prototype_video_demo_any_feedback_from/",
          "publishedOn": "2023-10-12T05:44:31.000Z",
          "wordCount": null,
          "title": "[P] [vilays] Prototype Video Demo - Any Feedback from ML Engineers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175xljs/d_databricks_dolly_15k_creating_synthetic_variants/",
          "author": null,
          "description": "Hey all, I found Dolly to be a very interesting project when it was released but I'm curious if it has similar value today because a lot of synthetic data generation options seem to be popping up.\n Now it seems like Dolly is human generated/curated by over 5k employees (which is great), but wouldn't it be a better approach now to have Llama70b (or maybe Falcon) just generate future variants of 15k rows? I havent been able to figure out why we arent seeing more synthetic datasets like this on HF? Is the bottleneck licensing, compute or just incentive?\n Heres the original Dolly post thread: https://www.reddit.com/r/MachineLearning/comments/120usfk/r_hello_dolly_democratizing_the_magic_of_chatgpt/\n    submitted by    /u/buzzyness  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175xljs/d_databricks_dolly_15k_creating_synthetic_variants/",
          "publishedOn": "2023-10-12T03:51:16.000Z",
          "wordCount": null,
          "title": "[D] Databricks Dolly 15k - Creating Synthetic Variants",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175wpwi/d_please_suggest_a_loss_function_for_image_to/",
          "author": null,
          "description": "What is the loss function that needs to be used for a task that takes an input image with a lot of haze and produces an image with reduced haze.\n The architecture is a simple encoder decoder architecture.\n I tried MSE as some articles and ML guides say that MSE is good for pixel wise comparison and also tried Categorical Crossentropy but none of them work so great.\n MSE works but produces artefacts like red/green/ blue spots and spatters and at worse times it produces a white image.\n The research on this task includes use of SIDNet[Single Image Dehazing Net], Transmission maps, Dark channel prior algorithm, FFA net, etc trained on the Benchmark datasets (RESIDE,SOTS).\n I aim to create a simple architecture for college project so I chose the Enc-Dec architecture. Any suggestions are appreciated.\n    submitted by    /u/Wild_Basil_2396  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175wpwi/d_please_suggest_a_loss_function_for_image_to/",
          "publishedOn": "2023-10-12T03:04:32.000Z",
          "wordCount": null,
          "title": "[D] Please suggest a Loss function for image to image task.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175wano/d_startup_team_demonstrates_differentiable_swift/",
          "author": null,
          "description": "Autonomous systems startup, PassiveLogic, assembled a differentiable computing team, to build a fast systems language with native performance differentiability. Their latest benchmark trains networks two orders of magnitude faster than PyTorch and Tensorflow. See: LinkedIn Post&dashCommentUrn=urn%3Ali%3Afsd_comment%3A(7118052434916110337%2Curn%3Ali%3Aactivity%3A7117911978106355712))\n It's a collaborative effort with the Swift community and Apple's compiler team, using the Swift language as a strongly typed embedded language that performs ahead of time compilation of graph neural nets. The focus is on fusing systems programming and AI engineering into a single native high performance language, to enable typed heterogeneous inference and training.\n The compiler development is open sourced as part of the standard Swift package. Try it yourself at swift.org.\n    submitted by    /u/taharvey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175wano/d_startup_team_demonstrates_differentiable_swift/",
          "publishedOn": "2023-10-12T02:42:56.000Z",
          "wordCount": 2635,
          "title": "[D] Startup team demonstrates differentiable Swift compiler outrunning TensorFlow by 322X",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ugw5/d_how_is_testdriven_development_implemented_in/",
          "author": null,
          "description": "I recently tried to refactor a previous project that I had, but I realized that after making all of the changes the performance wasn't reproducible anymore. I decided to start from scratch, make incremental changes, and make sure that the model's performance is maintained with each change. Very basic in hindsight, but I guess I was too hasty with coding.\n Anyway, running the full model's training and evaluation with each change is proving to take too long. I'm curious if there's any other way that people implement TDD in the context of machine learning since projects/applications tend to be more time consuming then typical applications.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ugw5/d_how_is_testdriven_development_implemented_in/",
          "publishedOn": "2023-10-12T01:14:38.000Z",
          "wordCount": null,
          "title": "[D] How is test-driven development implemented in the context of machine learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175qdu3/d_how_to_download_datasets_from_huggingface/",
          "author": null,
          "description": "Hello, first time using Google Colab and huggingface datasets. Colab notebook is easy to setup but I can't seem to figure out how to download datasets from huggingface.\n I am trying to download https://huggingface.co/datasets/kili-technology/plastic_in_river dataset in Colab Notebook. After reading some beginners forums, I modified the example to look like one below but it failed.\n from datasets import load_dataset data_files = {\"train\": \"train.csv\", \"test\": \"test.csv\", \"validation\": \"validation.csv\"} dataset = load_dataset(\"kili-technology/plastic_in_river\", data_files=data_files) \n Because there's no path to the files to be downloaded. Can someone explain how to download datasets from huggingface please?\n Downloading builder script: 100% 3.25k/3.25k [00:00<00:00, 228kB/s] Downloading metadata: 100% 2.79k/2.79k [00:00<00:00, 147kB/s] Downloading readme: 100% 496/496 [00:00<00:00, 34.2kB/s] --------------------------------------------------------------------------- FileNotFoundError Traceback (most recent call last) <ipython-input-5-98701edb7a4d> in <cell line: 4>() 2 3 data_files = {\"train\": \"train.csv\", \"test\": \"test.csv\", \"validation\": \"validation.csv\"} ----> 4 dataset = load_dataset(\"kili-technology/plastic_in_river\", data_files=data_files) 5 frames /usr/local/lib/python3.10/dist-packages/datasets/data_files.py in resolve_pattern(pattern, base_path, allowed_extensions, download_config) 366 if allowed_extensions is not None: 367 error_msg += f\" with any supported extension {list(allowed_extensions)}\" --> 368 raise FileNotFoundError(error_msg) 369 return out 370 FileNotFoundError: Unable to find 'https://huggingface.co/datasets/kili-technology/plastic_in_river/resolve/main/train.csv' \n    submitted by    /u/0ni0nrings  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175qdu3/d_how_to_download_datasets_from_huggingface/",
          "publishedOn": "2023-10-11T22:06:28.000Z",
          "wordCount": 2711,
          "title": "[D] how to download datasets from huggingface",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ns6h/d_how_do_bytelevel_language_models_work/",
          "author": null,
          "description": "I've recently been trying to pre-train my own small language model on the tiny-series datasets on huggingface. I also wanted to use a model similar to MEGABYTE but I don't understand how using bytes would work. The only implementation I could find from lucidrains used str(chr(max(32, token))) to decode any token (byte) to a character and put the embedding size as 256. Firstly, why 256 and not 256-32 as any values below 32 are ignored? Also, many byte-level models including this and ByteT5 mention that they can process any text sequence even in a multilingual setting, however how would that be true if we are only using one byte, would we have to move to 2 bytes or use an UNK token, and if we did use 2 bytes that would make our embedding size around 65000 which defeats sort of the point as o…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ns6h/d_how_do_bytelevel_language_models_work/",
          "publishedOn": "2023-10-11T20:18:32.000Z",
          "wordCount": 2887,
          "title": "[D] How do byte-level language models work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175n78x/p_evaluating_and_tuning_a_model_when_the/",
          "author": null,
          "description": "Consider a predictive model that is predicting if an outcome Y will occur in Q1 2023, based on data from Q1 2022.\n Now, if want to predict outcomes for 2024, we must use last years data to build the model, but we are going to have some bias if there are features that vary year over year.\n Is the best approach in such a situation to try and tune/validate the model with other years in the hopes of mitigating any features that are correlated with a specific year? \n Any help would be much appreciated, as I can't find agreed upon methods.\n    submitted by    /u/unga123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175n78x/p_evaluating_and_tuning_a_model_when_the/",
          "publishedOn": "2023-10-11T19:54:48.000Z",
          "wordCount": 2655,
          "title": "[P] Evaluating and tuning a model when the population may change YoY and best practices for mitigating overfitting on features that correlate with time.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175lw8r/is_there_a_model_to_input_anecdotal_text_stories/",
          "author": null,
          "description": "I have a goal and am looking for direction from others who know more than me about machine learning. \n I want to submit 5-10 pieces of text to a model. The text will be anecdotes from a common experience but each one from a different person’s perspective. For example, if a family visits a theme park, each family member will have a story or two about the day. Each family’s story would be a submission to the model. One person might have loved the roller coaster and can tell about the exciting parts. Another person maybe just can’t stop talking about how great he food was. Someone else maybe felt sick and complains the line at the bathroom was too long. Perhaps another family member also rode the same roller coasters as the first person but instead hated it, so would have a very different description of it than the first. \n All these anecdotes are submitted to the model. \n Then, the model can be queried. Such as, \n “Tell me about the theme park.” \n or\n “I love roller coasters. Tell me about the theme park.” \n or\n “I tend to overeat, tell me about the theme park.” (the model wouldn’t hype of the food, maybe it would talk about how much exercise the visitors get by walking around all day.) \n In this case of a theme park context, the model would have a preconception of a theme park. It would know the general concept, know of several examples or standards that it could compare this theme park against, understand it’s all for fun, etc. \n This type of model may be available as an API or model already and I just don’t know about it. That’d be fine, please point me towards it. Or, maybe there’s something already available but would need tweaked or customized.\n    submitted by    /u/Semper_Disco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175lw8r/is_there_a_model_to_input_anecdotal_text_stories/",
          "publishedOn": "2023-10-11T18:59:24.000Z",
          "wordCount": 2851,
          "title": "Is there a model to input anecdotal text stories as training data to return a more comprehensive story? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175l9mz/d_help_me_learn_ml_easily_specially_in_model/",
          "author": null,
          "description": "Can you give easy to understand sources and hands-on practice methodology to master ML? Help me understand build the models in and out . Thank you\n    submitted by    /u/the_mystic_1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175l9mz/d_help_me_learn_ml_easily_specially_in_model/",
          "publishedOn": "2023-10-11T18:32:02.000Z",
          "wordCount": 2568,
          "title": "[D] Help me learn ML easily specially in model building and EDA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175k7bl/nsf_workshop_on_llms_in_chemistry_education_r/",
          "author": null,
          "description": "Over Feb 12-13 of 2024, the National Science Foundation (NSF) is sponsoring a workshop titled “Integrating LLMs into the Materials Chemistry Curriculum” in Golden, Colorado. We aim to explore and develop innovative ways to incorporate large language models (LLMs, e.g. GPT, ChatGPT, and Bard) into upper division chemistry laboratories and virtual lab experiences. During the workshop, participants will brainstorm and create demonstrations incorporating LLMs into the curriculum.\n The event will bring together folks across academia and the private sector with disciplinary backgrounds that range across chemistry, computer science, materials science, physics, and education. There is no registration fee, and we anticipate being able to cover the majority of participant travel costs thanks to NSF support. Participants early in their career (i.e., graduate students, postdoctoral scholars) are particularly encouraged to apply.\n If you are interested in participating in this workshop, please fill out the Google form (link below).\n Please feel free to distribute this invitation widely.\n Application: https://forms.gle/P9QdNiCuaUAHFZj29\n    submitted by    /u/KC2792  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175k7bl/nsf_workshop_on_llms_in_chemistry_education_r/",
          "publishedOn": "2023-10-11T17:47:21.000Z",
          "wordCount": 2689,
          "title": "NSF workshop on LLMs in chemistry education [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ji6s/p_where_to_find_projects_to_contribute_to/",
          "author": null,
          "description": "Hello, I'm a developer with 6 years of experience in the mobile field, and I recently completed my master's degree in artificial intelligence (Text mining). I want to transition into the field of AI, but I need more experience with projects in the \"real world,\" outside of academia, and I'd like to contribute to an open-source project. I looked on Github, but I ended up feeling confused and not sure where to start.\n P.S.: I did some research in this subreddit, but the posts about contributions seemed a bit dated.\n    submitted by    /u/Substantial_Fact_205  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ji6s/p_where_to_find_projects_to_contribute_to/",
          "publishedOn": "2023-10-11T17:18:07.000Z",
          "wordCount": 2628,
          "title": "[P] Where to find projects to contribute to?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ie4l/p_image_based_python_opencv_automation_mmorpg/",
          "author": null,
          "description": "Video:\n https://youtu.be/0m12vkaoE7w\n ​\n Detailed Medium post will follow in the upcoming days.\n https://medium.com/@pssdplayer\n    submitted by    /u/HistorianCrafty3514  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ie4l/p_image_based_python_opencv_automation_mmorpg/",
          "publishedOn": "2023-10-11T16:32:54.000Z",
          "wordCount": 2554,
          "title": "[P] Image based Python + OpenCV automation, MMORPG Laghaim Auto-Fighter Bot Demo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175i3xg/d_i_have_2030_million_shopify_products_dataset/",
          "author": null,
          "description": "I have collected over 20 million shopify products & had the following ideas for them: \n - LLM ( Finetune an llm to know how to speak ecom )\n - Video bot that can make videos on those products, using their description, elevenlabs & AIFaceGen\n - EcomStore that will markup the products about 30% ( This will need the bot to frequently scrape, to ensure that the products are up to date ) \n - Selling the dataset based on fragments, like 1$ per 1k-10k records, depends on what sells. \n Please let me know if these are good ideas, and if someone would like to support / help me in any way ( I just need to selfhost my supabase instance, & add all the products to it & then dev can get started ) \n    submitted by    /u/AdonisCodes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175i3xg/d_i_have_2030_million_shopify_products_dataset/",
          "publishedOn": "2023-10-11T16:21:31.000Z",
          "wordCount": 2672,
          "title": "[D] - I have 20-30 million shopify products dataset, any ideas?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175hovg/d_best_opensource_ai_model_for_qa_generation_from/",
          "author": null,
          "description": "As the title says I’m looking for an open-source AI model for generating question-and-answers with a correct answer option and explanation to the correct answer from the input context. So far I have tried these models,\n  \nTheBloke/Llama-2-7B-GPTQ\n TheBloke/Llama-2-13B-GPTQ\n TheBloke/Llama-2-7b-Chat-GPTQ (the output is not consistent. Sometimes I get an empty response or without the correct answer option and an explanation data)\n TheBloke/Llama-2-13b-Chat-GPTQ (even 7b is better)\n TheBloke/Mistral-7B-Instruct-v0.1-GGUF(so far this is the only one that gives the output consistently. But not able to generate more than 2 QA due to max token limit of 512. Even tried setting the max token as 1024, 2048 but nothing helped)\n TheBloke/Mistral-7B-OpenOrca-GGUF\n NousResearch/Llama-2-7b-chat-hf\n  \nMy system configurations are: Windows 10 with 16GB GPU\n Additional Information: The input prompt token will be around 250-350 tokens per request.\n    submitted by    /u/gokulcv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175hovg/d_best_opensource_ai_model_for_qa_generation_from/",
          "publishedOn": "2023-10-11T16:04:17.000Z",
          "wordCount": 2663,
          "title": "[D] Best open-source AI model for QA generation from context",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175h9zh/churn_prediction_r/",
          "author": null,
          "description": "I want to build a model to predict churn in a third party logistics company. What variables should make up my data? Any help would do. Thanks\n    submitted by    /u/DisastrousAd8814  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175h9zh/churn_prediction_r/",
          "publishedOn": "2023-10-11T15:47:38.000Z",
          "wordCount": 2560,
          "title": "Churn Prediction [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175h4ob/d_recommendations_for_cpubased_realtime_vector/",
          "author": null,
          "description": "Hello everyone, I have a specific online vectorization use case: I'm looking to search the internet for articles, vectorize these articles along with the search queries, and then retrieve the most relevant passages from them. Currently, I have basic hosting through DigitalOcean. \n Could anyone recommend the most suitable vector dataset for this task? Additionally, considering my resources, is it feasible to run this system solely on CPUs? And if so, would this setup be scalable if deployed on CPUs only?\n    submitted by    /u/Traditional-Poet2746  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175h4ob/d_recommendations_for_cpubased_realtime_vector/",
          "publishedOn": "2023-10-11T15:41:43.000Z",
          "wordCount": 2620,
          "title": "[D] Recommendations for CPU-Based Real-Time Vector Database Indexing and Matching?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175g6rn/r_network_digital_twin_for_cybersecurity/",
          "author": null,
          "description": "Hi all,\n for a text work of mine I am trying to do a project based on generating digital twin of networks. My goal is to create a digital twin of a network and then work on it from a cyber security point of view. I will briefly explain what I would like to do.\n I am currently using software for network vulnerability scans (OpenVAS). I use this software to perform network vulnerability scans at the network level, so basically to OpenVAS I pass a network (for example 192.168.xx.xx/24) to automatically identify all the vulnerabilities that are there.\n The next step ( what I'd like to do and that's why I'm asking for your advice) is to create a digital twin of the newly scanned network and then perform a penetration test on this digital twin of the network, without going to stress the actual network.\n Ideally, I would like to pass the output of the OpenVAS vulnerability scans, routing rules, and firewall rules to some tool that will then generate for me the digital twin of the network, which will then be used for offensive cybersecurity, so exploits, privilege escalation, etc.... will be tested on this digital twin without worrying about breaking some kind of service or stressing the real network.\n What I am asking is, do you know of any tool that would do the trick for me? So some tool that allows me to generate a digital twin of a network by providing as input vulnerability scans (xml,json,csv etc...), routing rules, firewall rules, pcap traces etc... \n Do you have any references or documentation? \n Are you aware of any open source tools?\n I thank you for your helpfulness!\n ​\n    submitted by    /u/Salt-Arugula-8128  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175g6rn/r_network_digital_twin_for_cybersecurity/",
          "publishedOn": "2023-10-11T15:04:28.000Z",
          "wordCount": 2816,
          "title": "[R] network digital twin for cybersecurity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175fobx/best_approach_for_vfx_lineups_using_ml_project/",
          "author": null,
          "description": "Quick intro\n Lineups are one of the first steps in the VFX pipeline\n Source:\n - orignal footage that was shot on set\n - a reference (quicktime) video from the film edit.\n Task:\n The reference shows modifications to the original footage. They can be :\n - timewarp (either fixed retimes like 200% speed or completely random)\n - transform (moved the image in x/y axis, rotation, scale, etc.)\n So the lineup task is to align the original footage to the reference quicktime.\n What I did so Far:\n Made a simple script in the software Nuke, using some Python and readily available tools to make it work on a simple shot. General logic is compare every frame and the associated one is the frame with the least difference between the two. This works on super simple and straightforward tasks. (can provide more info if needed).\n Issue:\n Some references are more heavily modified. They can have some muzzle flash, basic 3d objects or even some slight error introduced like a distortion applied to the image when none shouldn't so it will never be perfectly aligned. This makes the difference of the full frame higher for some frames, making the lineup wrong. (it will take the wrong frame that has no muzzle flash, because it has less difference...)Some other things to consider is that watermarks are covering the ref and the colors are not perfectly matching, can get them close enough, but there's a difference.\n Conclusion:\n Because of those issues, I'm thinking about using Machine Learning. I have next to no knowledge on the subject. I know there Is a bunch of ways to train a model, but no clue where to start, so here's my question :\n Which learning styles has the best potential to be able to solve this task?\n    submitted by    /u/Pretty_Customer_8113  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175fobx/best_approach_for_vfx_lineups_using_ml_project/",
          "publishedOn": "2023-10-11T14:43:28.000Z",
          "wordCount": 2827,
          "title": "Best approach for VFX lineups using ML [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ezse/r_what_are_some_interesting_research_topics_to/",
          "author": null,
          "description": "I will have to pick and start a research project next January for my final year. So wanted to start exploring now. \n I want to do something substantive and interesting enough to get published.\n    submitted by    /u/BadMeditator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ezse/r_what_are_some_interesting_research_topics_to/",
          "publishedOn": "2023-10-11T14:13:22.000Z",
          "wordCount": 2582,
          "title": "[R] What are some interesting research topics to study in the intersection of ML and signal processing currently?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ep9x/r_mistral_7b/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ep9x/r_mistral_7b/",
          "publishedOn": "2023-10-11T14:00:25.000Z",
          "wordCount": 2544,
          "title": "[R] Mistral 7B",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ep6x/r_tsinghua_university_inverting_transformers/",
          "author": null,
          "description": "Transformers are great at NLP and computer vision tasks, but I was surprised to learn they still lag behind simple linear models at time series forecasting.\n The issue is how most Transformer architectures treat each timestamp as a token and fuse all the variable data from that moment. This makes two big problems:\n  \nVariables recorded at slightly different times get blurred together, losing important timing info\n Each token can only see a single moment, no long-term dependencies\n  \nSo Transformers struggle to extract useful patterns and correlations from the data.\n Some researchers from Tsinghua University took a fresh look at this and realized the Transformer components themselves are solid, they just need to flip the architecture for time series data.\n Their \"Inverted Transformer\" (or iTransformer):\n  \nMakes each variable's full history into a token, instead of each timestamp\n Uses self-attention over variables to capture relationships\n Processes time dependencies per variable with feedforward layers\n  \nThis simple tweak gives all the benefits we want:\n  \nState-of-the-art forecasting accuracy, beating both linear models and standard Transformers\n Better generalization to unseen variables\n Increased interpretability\n Ability to leverage longer historical context\n  \nTLDR: Inverting Transformers to align with time series structure allows them to outperform alternatives in working with time series data.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ep6x/r_tsinghua_university_inverting_transformers/",
          "publishedOn": "2023-10-11T14:00:19.000Z",
          "wordCount": 2748,
          "title": "[R] Tsinghua University: Inverting Transformers Significantly Improves Time Series Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ct0u/r_how_to_train_multiple_models_on_multiple_gpus/",
          "author": null,
          "description": "Hi! The task is to train N TensorFlow/Keras models using [2, ... N] GPU's on K different datasets in parallel. It is for testing a custom pipeline, you create a pipeline, you run it on multiple different datasets and get an aggregated metric. For now I'm using a for loop but how do I do it in parallel e.g. on AWS? I googled, but surprisingly haven't found a lot of results. I looked at Apache AirFlow because I'm vaguely familiar with it but so far I couldn't get a definite answer on how it works with multiple GPU's. Second option I found is to use Ray library. Is it worth trying? What should I use to solve this task? Thanks.\n UPD. I'd also consider a PyTorch solution as a backup option.\n UPDUPD. Jesus, why Reddit removing newlines after edit? \n    submitted by    /u/Disastrous_Sky9468  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ct0u/r_how_to_train_multiple_models_on_multiple_gpus/",
          "publishedOn": "2023-10-11T12:26:23.000Z",
          "wordCount": 2677,
          "title": "[R] How to train multiple models on multiple GPU's simultaneously",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175cf8w/d_how_important_is_having_a_great_team_when_ml/",
          "author": null,
          "description": "My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.\n I am the “lead”/senior data scientist in an R&D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.\n I have developed the domain expertise and I have a PhD in an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.\n I am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.\n    submitted by    /u/Diligent_Trust2569  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175cf8w/d_how_important_is_having_a_great_team_when_ml/",
          "publishedOn": "2023-10-11T12:06:14.000Z",
          "wordCount": 2761,
          "title": "[D] How important is having a great team when ML solutions are slow to be adopted ? When to move on?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ccwv/d_p_r_what_to_do_when_your_model_isnt_testing_well/",
          "author": null,
          "description": "I have 200k observations overall. I split my data into training and test set. My target variable has low prevalence ~ 9% so I tried random oversampling, random undersampling and SMOTE. After I fit my models, I tested them on my training test and the results were awful. I mean I've never had a model with 50% roc-auc, but then again, I rarely developed ML models. I'm wondering what the next steps would be? I understand there could be some sort of overfitting. But what would you do next? Any references would be appreciated :)\n    submitted by    /u/Actual-Muscle-9846  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ccwv/d_p_r_what_to_do_when_your_model_isnt_testing_well/",
          "publishedOn": "2023-10-11T12:02:42.000Z",
          "wordCount": 2637,
          "title": "[D] [P] [R] What to do when your model isn't testing well?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175a8bs/d_fastest_lipsync_projects/",
          "author": null,
          "description": "Given an image, and an audio file (TTS generated), what is current fastest library that can output me a video of a talking image with the audio on it?\n I have made some research and I have seen Wav2Lip and SadTalker. Any better options? I am looking for processing speed and for the lesser hardware intensive solution for a side project.\n Thanks!\n    submitted by    /u/reddit2vid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175a8bs/d_fastest_lipsync_projects/",
          "publishedOn": "2023-10-11T09:50:59.000Z",
          "wordCount": 2596,
          "title": "[D] Fastest lipsync projects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17552x9/p_loopquest_a_githublike_platform_to_host/",
          "author": null,
          "description": "Hello everyone! Here is my pet project, https://www.loopquest.ai/. I am trying to build a platform like Github to let people upload their simulation environments so people can train their AI agents by interacting with the environments created by others. Here is a 2-min demo, https://youtu.be/d53NFjkU7JA. It is not launched yet but would love to get some early feedbacks. \n Here is the corresponding Github repo https://github.com/LoopMind-AI/loopquest. For now, the package can log env-agent interaction data by adding one extra line of code. You can think of it similar to https://github.com/google-deepmind/envlogger but with much better backend and frontend support. \n Any feedbacks are appreciated :)\n    submitted by    /u/jxx123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17552x9/p_loopquest_a_githublike_platform_to_host/",
          "publishedOn": "2023-10-11T04:00:52.000Z",
          "wordCount": 2644,
          "title": "[P] LoopQuest, A Github-like platform to host simulation environments for AI training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17536bo/d_why_async_gradient_update_doesnt_get_popular_in/",
          "author": null,
          "description": "The pipedream-2bw paper and the Zero-offload paper both show that 1-step delayed asynchronous gradient update doesn’t affect the convergence (and perplexity) while improve the training efficiency (by fully utilize the bubbles in pipeline parallelism) at a large margin.\n However, both the Megatron-LM and the DeepSpeed don’t use pipedream-2bw scheduling. Could anyone share me some insights or ideas about why such an efficient scheduling scheme doesn’t get popular in the LLM pretraining community? Does it suffer convergence/accuracy issue in practice? Or are there any other concerns that blocking it become the default / most popular pipeline parallelism scheduling?\n (I posted the same question in hacknews as well: Why async gradient update doesn't get popular in LLM community? | Hacker News)\n I have tried to implement the pipedream-2bw scheduling scheme on Megatron-LM and do can reproduce the performance gain as well as loss convergence with GPT-2 345M using 8xV100 GPUs: https://github.com/sighingnow/Megatron-LM/blob/ht/dev-pipe/megatron/core/pipeline_parallel/schedules.py#L1421\n    submitted by    /u/sighingnow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17536bo/d_why_async_gradient_update_doesnt_get_popular_in/",
          "publishedOn": "2023-10-11T02:23:18.000Z",
          "wordCount": 2684,
          "title": "[D] Why async gradient update doesn’t get popular in LLM community?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1750uim/d_ide/",
          "author": null,
          "description": "What’s the best IDE to work with or is it on user needs that determines best fit or is their one top dog and dominator that can robustly if not better preform other IDE’s ?\n    submitted by    /u/External_Age_5855  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1750uim/d_ide/",
          "publishedOn": "2023-10-11T00:31:01.000Z",
          "wordCount": 2568,
          "title": "[D] IDE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174zyyu/d_onchain_reputation_model/",
          "author": null,
          "description": "I am relatively new to machine learning, and I am thinking about building an on-chain reputation ML model.\n Here is how far I have gone in my ideation phase, can someone help with some suggestion on how I can approach this issue.\n  \nInput data could include on-chain activity like number of transactions, value transferred, smart contracts interacted with, tokens held, NFTs owned, etc.\n Additionally, data from off-chain sources could be incorporated like identity verification, credentials, ratings, reviews, social media profiles, etc.\n Supervised learning algorithms like regression or classification models could be used to predict a reputation score. The target variable would be some verified reputation rating.\n Models like linear regression, random forests, or neural networks could work. Choice depends on size of data and complexity needed.\n Model would need to be transparent and parameters verifiable on-chain for validity. So linear models or simple neural networks may be most practical initially.\n The model could be trained off-chain initially but ultimately parameters and logic stored on-chain. Predictions could also be verified on-chain.\n Careful feature selection is important so the model relies on signals that are resistant to manipulation and capture true reputation.\n The model would need continuous updates as new data comes in reflecting latest reputation. This would require clear on-chain governance.\n Issues like privacy, collusion resistance, and censorship resistance would need to be addressed through crypto mechanisms like zero-knowledge proofs.\n  \nP.S. This is a personal project I want to attempt to level up my ML skills.\n    submitted by    /u/AdParticular2891  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174zyyu/d_onchain_reputation_model/",
          "publishedOn": "2023-10-10T23:50:20.000Z",
          "wordCount": 2779,
          "title": "[D] On-Chain Reputation Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174yb4k/d_pivoting_jobs_to_ml/",
          "author": null,
          "description": "Hi everyone, I recently started a job as a Junior Data Engineer. I have learned a lot so far working with DBT, Snowflake, Looker, Jira workflow, and Git using SQL and Python.\n I plan to stay at this company for 2 years. My boss has assured me that if I work hard I will progress from a Junior to full Data Engineer. After 2-3 years as a DE, I want to level up and move towards Data Science/ ML roles.\n My questions are: What other skills should I learn to enable me to pivot into something ML related? Should I find a job as a Data Scientist first, then try for ML jobs?\n Just looking for some advice/suggestions. Thanks!\n    submitted by    /u/SydeFxs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174yb4k/d_pivoting_jobs_to_ml/",
          "publishedOn": "2023-10-10T22:36:18.000Z",
          "wordCount": 2655,
          "title": "[D] Pivoting jobs to ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174xkir/problem_solving_in_programming_d/",
          "author": null,
          "description": "Hello Redditors,\n I am a student who is currently studying Bachelor of Science in AI. I have a question regarding improving my coding skills. I am aiming for a research internship and I don't know where to start. I previously took a summer school that taught me a lot about state-of-the-art models such as GANs, Transformers, VAEs, GNNs, etc. I would like to improve my coding skills, specifically problem-solving and writing clean code. I have experience with deep learning in general and data analysis. I am looking for a research internship next summer. Where should I start?\n I plan to review some of the deep learning material in the Deep Learning Specialization before taking the GAN specialization. However, when it comes to coding, I want to think like a software engineer or a great programmer. What do you guys suggest for improving my coding or problem-solving skills? I'm feeling confused with multiple resources and I don't know where to begin.\n I’d really appreciate your help.\n    submitted by    /u/misplacedlion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174xkir/problem_solving_in_programming_d/",
          "publishedOn": "2023-10-10T22:04:54.000Z",
          "wordCount": null,
          "title": "Problem solving in programming [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174xc6c/random_forest_trained_on_insider_trades_d/",
          "author": null,
          "description": "Would be very appreciative if someone looked at these results and pointed out potential / actual flaws.\n Dataset basics: insider trade details, insider trades over the last month, insider trades over the last week, (…) stock return over the last month (…), 46 columns total. \n Labels… 0: <-5% return in two weeks 1: >-5% + <5% 2: >5%\n Dates predicted: reported date. Usually 2-3 days behind transaction.\n Also, not positive if results are significant in the first place so that would be a great call out as well.\n Colab notebook: https://colab.research.google.com/drive/1fO1hVsVMWN3TORNj4OQn5UbWQOeug4fi?usp=sharing\n    submitted by    /u/This_Cardiologist242  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174xc6c/random_forest_trained_on_insider_trades_d/",
          "publishedOn": "2023-10-10T21:55:11.000Z",
          "wordCount": 2629,
          "title": "Random forest trained on insider trades [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174rdaq/r_almt_using_text_to_narrow_focus_in_multimodal/",
          "author": null,
          "description": "Multimodal sentiment analysis combines text, audio and video to understand human emotions. But extra inputs can add irrelevant or conflicting signals. So filtering matters.\n Researchers made a \"Adaptive Language-guided Multimodal Transformer\" (ALMT) that uses text to guide filtering of visual and audio data. This creates a \"hyper-modality\" with less noise that complements the text.\n They tested it on datasets like MOSI (YouTube reviews), MOSEI (YouTube clips) and CH-SIMS (Chinese videos). ALMT achieved improved accuracy:\n  \nMOSI: YouTube movie reviews with 2,199 samples. ALMT achieves state-of-the-art performance on various metrics including 6% higher 7-class accuracy.\n MOSEI: 22,856 YouTube clips covering sentiment-rich scenarios. ALMT improves multi-class accuracy by 3-5% over previous methods.\n CH-SIMS: Chinese dataset with over 2,000 video samples. ALMT surpasses prior work by 1.4% in binary accuracy.\n  \nAnalyses showed big drops in performance without the guided filtering, so this validates that it's the main innovation.\n Downsides are it needs lots of training data and has minor gains on sparse regression metrics. But overall the technique of filtering multimodal data under text guidance gives improvements.\n The concepts feel intuitive - use dominant signals to filter others and retain useful complements. My guess is it would transfer well to other multimodal tasks.\n TLDR: New way to filter multimodal data for sentiment analysis using text guidance improves performance. Shows the value in removing distracting signals. Sometimes less is more.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174rdaq/r_almt_using_text_to_narrow_focus_in_multimodal/",
          "publishedOn": "2023-10-10T17:49:39.000Z",
          "wordCount": 2775,
          "title": "[R] ALMT: Using text to narrow focus in multimodal sentiment analysis improves performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174r35r/has_anyone_evaluated_tiktoks_algorithm_for_their/",
          "author": null,
          "description": "As a disclaimer, I am not familiar with many Recsys benchmarks. \n So I know Tiktok published a white paper on their purported algorithm, Monolith, but it is unclear if that is what they use in their products or not. Given, recommender systems seem to be core to Bytedance's business, I imagine they wouldn't provide many details.\n Has anyone evaluated Monolith on their own products and seen an improvement? \n I think the app is impressive and am wondering how it has transferred to other use cases. \n ​\n    submitted by    /u/HybridRxN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174r35r/has_anyone_evaluated_tiktoks_algorithm_for_their/",
          "publishedOn": "2023-10-10T17:37:40.000Z",
          "wordCount": null,
          "title": "Has anyone evaluated Tiktok's algorithm for their recsys use case? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174qdqv/p_optimistix_nonlinear_optimisation_in_jaxequinox/",
          "author": null,
          "description": "Hi everyone! I wanted to advertise my new JAX optimisation library Optimistix!\n Optimistix has high-level APIs for minimisation, least-squares, root-finding, and fixed-point iteration and was written to take care of these kinds of subroutines in Diffrax.\n Here is the GitHub: https://github.com/patrick-kidger/optimistix\n The elevator pitch is Optimistix is really fast, especially to compile. It plays nicely with Optax for first-order gradient-based methods, and takes a lot of design inspiration from Equinox, representing the state of all the solvers as standard JAX PyTrees.\n For those familiar with classical nonlinear unconstrained optimisation, Optimistix does some pretty nifty new things. It introduces new abstractions for modular optimisers, allowing users to mix-and-match different optimisation techniques easily. For example, creating a BFGS optimiser with Levenberg-Marquardt style Tikhnov regularisation takes less than 10 lines of code in Optimistix.\n I'm using Optimistix as a tool for my own research, and continue to work on it as part of my PhD (supervised by Patrick Kidger.) I would love for some more people to try it, so let me know what you think!\n    submitted by    /u/packquickly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174qdqv/p_optimistix_nonlinear_optimisation_in_jaxequinox/",
          "publishedOn": "2023-10-10T17:08:25.000Z",
          "wordCount": 2710,
          "title": "[P] Optimistix, nonlinear optimisation in JAX+Equinox!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174odzs/d_document_layout_recreating_the_structure/",
          "author": null,
          "description": "Hello,\n Document layout analysis has been a great tool so far to extract the components of a document (title, paragraph, tables ...). I'm working on long text PDF which are mostly scanned documents.\n One of the process involved after document layout analysis, is to recreate the document structure: creating sections, sub section, sub sub sections and so on. As of today, this task is done by parsing the title and finding out any ordering information (numeric, alphabetical or roman notation):\n 1. Title A 1.1 Title B 2. Title C 2.a) Title D \n This technique works only if a document follows this constraint (numeration). I want to go one step further, where the algorithm could create the document structure with any title ordering information.\n I believe that relying only on parsing cannot do the trick. What could be the options? Given that the only features are: title's text and title's position (x,y) in the document. I was wondering if a model like a seq2seq could fit this problem, or should I stick with an engineering rule based approach.\n Thanks\n ​\n    submitted by    /u/mathrb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174odzs/d_document_layout_recreating_the_structure/",
          "publishedOn": "2023-10-10T15:44:15.000Z",
          "wordCount": 2716,
          "title": "[D] Document layout - recreating the structure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174n4ve/r_is_there_an_enstablished_method_to_test_if/",
          "author": null,
          "description": "I am using ChatGPT and other LLMs for which the training data is unknown. I am using them to test a set of MC question from a medical test published after the models knowledge cutoff. However, I cannot be 100% sure the questions were not on the internet beforehand. \n Is there any established method or testsuit to try to understands weather a given instance has been seen at training time? All I can think is looking at memorization or at perplexity, but I was looking for a more out of the box methodology that people use. It seems to me that the problem is quite general. \n Thanks!\n Edit: I know LLMs do not just memorize things and learn pattern. However, there is research on trying to understand if a datapoints has been used in training or not. Eg there is research that tries to exploit the fact that seen text has normally lower perplexity than unseen text or other similar infornation. I was wonderibg what the state in this topic is and if something is normally used as a score to have some clues. I do not expect to be able to retrieve the exact same questions lol\n    submitted by    /u/ombelicoInfinito  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174n4ve/r_is_there_an_enstablished_method_to_test_if/",
          "publishedOn": "2023-10-10T14:50:46.000Z",
          "wordCount": 2747,
          "title": "[R] Is there an enstablished method to test if something has been memorized / seen by black-box LLMs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174n1kt/d_extracting_multimodal_embeddings_image_text_to/",
          "author": null,
          "description": "I am looking for methods/frameworks to extract multi-modal embeddings from images and text for similarity search purposes. The problem setup is slightly different from how CLIP style methods are generally used ( where similarity between text and image embeddings obtained through the model are computed to assess how similar a caption is to an image). My intended application is similarity search, where I want to find entries of images and captions pair similar to a piece of the query image and caption encoded together.\n Some approaches I tried: I tried concatenating the textual and visual embeddings obtained from CLIP and ResNET with textual embeddings and using it with cosine similarity, but it had limited utility. My guess is that concatenating two modalities merely without any training would yield very little utility. The next direction could be to train a model to fuse the embeddings obtained, but my dataset size is really small (10 thousand total), so not sure if training a model would be helpful. \n Are there any approaches that can allow me to combine the multi-modal embeddings for similarity purposes, similar to how pre-trained ResNET or Inception can be used off-the-shelf for retrieving visually similar images? Any pointers/advice would be greatly appreciated. \n    submitted by    /u/No-Commission3556  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174n1kt/d_extracting_multimodal_embeddings_image_text_to/",
          "publishedOn": "2023-10-10T14:46:49.000Z",
          "wordCount": 2748,
          "title": "[D] Extracting Multi-modal embeddings (Image + text) to be used for visual similarity purposes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174n0mv/pd_building_datasets/",
          "author": null,
          "description": "In my ML/AI journey up until now, most training and hands-on labs either use a pre-built dataset or have you build a pretty simple and flat dataset. I am now looking to stretch my exploration into some real-world use cases and find the data I want is way more complex.\n Researching online feels like the meme on learning to draw an owl.\n So I'm looking for some guidance on how to handle my data.\n The data is an array from a rest API that includes all alarms from an application as nested objects. So the data looks like this for a single event:\n data = { \"event_data\": [ { \"root_cause\": \"Root cause added after API calls\" \"alarms\": [ { \"alarm_id\": \"alarm_id\", \"alarm_name\": \"alarm_name\", \"alarm_type\": \"alarm_type\", \"alarm_description\": \"alarm_description\", \"alarm_details\": { pro1: val1, prop2: val2, etc... }, \"actual_alarm_value\": { any_random_key: \"any_random_value\", etc... }, } ], } ] } \n I need to build a dataset that includes many of these events with the ultimate goal of predicting future events. I plan to test this against various ML models and LLMs.\n Each event would be a single row, and I would flatten out each alarm so each nested property has its own column. Where I need clarification is how to handle the flatting of alarms. If I fully flatten them, it appears like I lose the context of the alarm's parent event. But if I only flatten them to the alarm level, I lose each property having its own row\n Also actual_alarm_value is very random, so my thinking is to use string encoding here.\n I know this is a lot of detail, and I appreciate any and all advice and help in learning how to do this.\n    submitted by    /u/that1guy15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174n0mv/pd_building_datasets/",
          "publishedOn": "2023-10-10T14:45:38.000Z",
          "wordCount": 2817,
          "title": "[P][D] Building Datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174kryt/d_is_there_a_rest_api_for_text_embeddings/",
          "author": null,
          "description": "I'm aware there are commercial offerings like OpenAI and cohere with the embedding API. But what about for open source models like the ones from SentenceTransformers?\n I'm aware you can use the HuggingFace inference API, but it's probably not best for commercial use, in which case the Inference endpoints would be better, but it's quite pricey for a startup with no customers.\n I also know I could use some kind of serverless GPU / inference platform to create my own API.\n But is there just a straight-up REST API for getting text embeddings from a model via SentenceTransformers or other HuggingFace models?\n    submitted by    /u/TheSaasDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174kryt/d_is_there_a_rest_api_for_text_embeddings/",
          "publishedOn": "2023-10-10T13:08:48.000Z",
          "wordCount": 2642,
          "title": "[D] Is there a REST API for text embeddings?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174jv0q/d_langauge_confusion/",
          "author": null,
          "description": "I am a Second Year Student\n I'm planning to start learning ML which obviously requires python. But at the same time I wanna start practicing DSA / competitive programming as well. I'm sorta in this dilemma of what to do.\n Since python is a must for ML I'm 100% doing it, but for DSA I am confused whether I should learn DSA in Python or C++. People say C++ is the best and ideally I should do that. But python suits my need more. Obviously I don't mind doing both languages together but it seems a bit redundant.\n P.S: I'm learning DS basics in college via C language so learning the basic concepts isn't an issue.\n What do you suggest?\n    submitted by    /u/No-Discipline-2354  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174jv0q/d_langauge_confusion/",
          "publishedOn": "2023-10-10T12:24:15.000Z",
          "wordCount": null,
          "title": "[D] Langauge Confusion.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174jkeb/project_i_created_a_tool_that_navigates_the/",
          "author": null,
          "description": "Hi! I created a universal data API that uses headless browsers and GPT to extract any data from the web in JSON format. I started this project because I needed some API to do data enrichment to get company data (headcount, investment rounds, etc.). Once I did the first version, I quickly realized that there can be many use cases for such a tool: data enrichment, web scraping, data validation, etc. \n You can get the early access to the API here: https://singleapi.co/ \n Thanks!\n    submitted by    /u/semanser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174jkeb/project_i_created_a_tool_that_navigates_the/",
          "publishedOn": "2023-10-10T12:08:58.000Z",
          "wordCount": 2628,
          "title": "[Project] I created a tool that navigates the Internet and scrapes data using GPT-4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174iz9n/applied_aiml_data_science_ms_in_germany_d/",
          "author": null,
          "description": "Hey folks, I graduated from a tier 2 college in India with an ECE degree and then started working as an ML engineer in a mid-size startup 2 years ago. (1 year of internship + 1 year of Full time employment at the same company). Now, I am looking to get a Master's Degree in AI/ML/DS in Germany starting Winter 2024. I am a person with interests in Industry skills(Applied AI/ML) rather than the research/academia part as I don't wish to pursue a PhD nor do I want to be stuck in a Math-deep subject that may not be relevant for me in the future. On account of this, I wanted to know which college/degree offers the best balance in-between theory and applied AI/ML/DS.\n Also, people have been telling me that exams are super tough and it is hard to successfully complete an AI/ML/Data Science MS degree in Germany, Is it true? It has been super discouraging for me to hear this and is affecting me mentally to go through the application process.\n PS. CS/Electrical Degrees with good electives for AI/ML/DS are also good enough for me (Just hoping the coursework/grading is not too harsh) Also, it would be great if someone could clarify if an Electronics and Communications student can apply for a CS degree in Germany.\n Sorry for asking too many questions, TIA. :)\n    submitted by    /u/TheDivineKnight01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174iz9n/applied_aiml_data_science_ms_in_germany_d/",
          "publishedOn": "2023-10-10T11:37:07.000Z",
          "wordCount": 2765,
          "title": "Applied AI/ML/ Data Science MS in Germany [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174hkcn/d_prompting_as_searching_through_a_space_of/",
          "author": null,
          "description": "Enlightening article from Francois Chollet about #LLMs and embeddings\n \"Prompt engineering is the process of searching through program space to find the program that empirically seems to perform best on your target task.\"\n ​\n https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering \n    submitted by    /u/alexisperrier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174hkcn/d_prompting_as_searching_through_a_space_of/",
          "publishedOn": "2023-10-10T10:09:17.000Z",
          "wordCount": 2575,
          "title": "[D] Prompting as searching through a space of vector programs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174cwha/d_best_approach_to_verify_4_million_sentencenamed/",
          "author": null,
          "description": "I have a dataset of about 4 million pairs of sentence-named entity.\n Looks like this:\n Sentence: MarketWatch has reached out to Charles Schwab and GQG for comment. Corresponding NER Tags: [{'end': 6, 'entity': 'B-ORG', 'index': 1, 'score': '0.98322886', 'start': 0, 'word': 'Market'} {'end': 7, 'entity': 'I-ORG', 'index': 2, 'score': '0.969261', 'start': 6, 'word': '##W'} {'end': 11, 'entity': 'I-ORG', 'index': 3, 'score': '0.97644824', 'start': 7, 'word': '##atch'} {'end': 38, 'entity': 'B-PER', 'index': 8, 'score': '0.9927636', 'start': 31, 'word': 'Charles'} {'end': 41, 'entity': 'I-PER', 'index': 9, 'score': '0.99394774', 'start': 39, 'word': 'Sc'} {'end': 44, 'entity': 'I-PER', 'index': 10, 'score': '0.41437265', 'start': 41, 'word': '##hwa'} {'end': 45, 'entity': 'I-PER', 'index': 11, 'score': '0.46933985', 'start': 44, 'word': '##b'} {'end': 51, 'entity': 'B-ORG', 'index': 13, 'score': '0.9984176', 'start': 50, 'word': 'G'} {'end': 52, 'entity': 'I-ORG', 'index': 14, 'score': '0.99367344', 'start': 51, 'word': '##Q'} {'end': 53, 'entity': 'I-ORG', 'index': 15, 'score': '0.99617106', 'start': 52, 'word': '##G'}] \n What would be a good approach to verify the correctness of each item?\n    submitted by    /u/shardblaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174cwha/d_best_approach_to_verify_4_million_sentencenamed/",
          "publishedOn": "2023-10-10T04:53:27.000Z",
          "wordCount": 2705,
          "title": "[D] Best approach to verify 4 million sentence-named entity pairs ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1746g81/r_language_agent_tree_search_unifies_reasoning/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.04406 \n Abstract:\n  \nWhile large language models (LLMs) have demonstrated impressive performance on a range of decision-making tasks, they rely on simple acting processes and fall short of broad deployment as autonomous agents. We introduce LATS (Language Agent Tree Search), a general framework that synergizes the capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration from Monte Carlo tree search in model-based reinforcement learning, LATS employs LLMs as agents, value functions, and optimizers, repurposing their latent strengths for enhanced decision-making. What is crucial in this method is the use of an environment for external feedback, which offers a more deliberate and adaptive problem-solving mechanism that moves beyond the limitations of existing techniques. Our experimental evaluation across diverse domains, such as programming, HotPotQA, and WebShop, illustrates the applicability of LATS for both reasoning and acting. In particular, LATS achieves 94.4\\% for programming on HumanEval with GPT-4 and an average score of 75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness and generality of our method. \n  \nhttps://preview.redd.it/ail2c1kbh9tb1.jpg?width=857&format=pjpg&auto=webp&s=a89d1f4ce3c536eecda3f7ab6027f304286f6c81\n https://preview.redd.it/j8xzx1kbh9tb1.jpg?width=1655&format=pjpg&auto=webp&s=c791756af926c7d472313b212de765e74c2b75da\n https://preview.redd.it/t47ne1kbh9tb1.jpg?width=1362&format=pjpg&auto=webp&s=560e5dd82ad06fdb729ab8ea1434c98e5c1a2ed3\n https://preview.redd.it/r58es3kbh9tb1.jpg?width=1341&format=pjpg&auto=webp&s=d5681992547dd6248ade5729c545eb17e824b7ea\n https://preview.redd.it/7viy42kbh9tb1.jpg?width=1496&format=pjpg&auto=webp&s=6454cfe65b511b34771cd510f67775be4e01c636\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1746g81/r_language_agent_tree_search_unifies_reasoning/",
          "publishedOn": "2023-10-09T23:31:05.000Z",
          "wordCount": 2734,
          "title": "[R] Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models - University of Illinois 2023 - Achieves 94.4\\% for programming on HumanEval with GPT-4 and 86.9\\% with GPT-3.5 20\\% better than with reflexion!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1746614/r_looking_for_indepth_tutorials_and_papers_on_nn/",
          "author": null,
          "description": "I only started working with neural nets a year ago and i've been having trouble understanding how pruning actually works. If there's any resources you think might help please guide me to them. thanks!\n    submitted by    /u/Sidekiiick02  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1746614/r_looking_for_indepth_tutorials_and_papers_on_nn/",
          "publishedOn": "2023-10-09T23:18:44.000Z",
          "wordCount": 2575,
          "title": "[R] looking for in-depth tutorials and papers on NN pruning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1744w8p/d_feature_selection_for_multivariate_time_series/",
          "author": null,
          "description": "Say for a sample that you have 5 target variables and 30 exogenous variables. If you want to include no more than 10 exogenous variables to your time series forecast, because of overfitting issues and such, what feature selections would you apply? Could you use pca and vif for multivariate models or are there other approaches to consider?\n    submitted by    /u/AdWhole1559  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1744w8p/d_feature_selection_for_multivariate_time_series/",
          "publishedOn": "2023-10-09T22:23:49.000Z",
          "wordCount": 2597,
          "title": "[D] Feature selection for multivariate time series model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1740ycb/r_scalearn_simple_and_highly_parameterefficient/",
          "author": null,
          "description": "Title: ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale\n Paper: https://arxiv.org/abs/2310.01217\n Code: https://github.com/CPJKU/ScaLearn\n https://preview.redd.it/xvcz7obtc8tb1.jpg?width=2020&format=pjpg&auto=webp&s=26169fa234e4e714d424ce17a7f0fa2c513fc42c\n Abstract:\n  \nMulti-task learning (MTL) has shown considerable practical benefits, particularly when using pre-trained language models (PLMs). While this is commonly achieved by simultaneously learning n tasks under a joint optimization procedure, recent methods such as AdapterFusion structure the problem into two distinct stages: (i) task learning, where knowledge specific to a task is encapsulated within sets of parameters (e.g., adapters), and (ii) transfer, where this already learned knowledge is lev…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1740ycb/r_scalearn_simple_and_highly_parameterefficient/",
          "publishedOn": "2023-10-09T19:41:45.000Z",
          "wordCount": 2822,
          "title": "[R] ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173y66v/d_what_is_more_valuable_10k_cpus_or_1k_gpu_hours/",
          "author": null,
          "description": "Hello ML community!\n I recently built, incredibly simple to learn, cluster compute software. Users can (in <60 seconds) go from coding on their local laptop, to coding on thousands of computers in the cloud, with zero setup, and just one line of code.\n I have a fair amount of GCP credits and want to run a promotion to get additional users. It would be giving away compute. In your opinion what would be more valuable... 10k CPU hours or 1k GPU hours? If you have any other promotional ideas for python users specific those in the ML, Bioinformatics, and GIS spaces I'd love to hear them.\n All feedback is greatly appreciated. Also if you're interested in trying out the tool check it out here --> https://www.burla.dev/\n    submitted by    /u/Ok_Post_149  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173y66v/d_what_is_more_valuable_10k_cpus_or_1k_gpu_hours/",
          "publishedOn": "2023-10-09T17:50:53.000Z",
          "wordCount": 2668,
          "title": "[D] What is more valuable 10k CPUs or 1k GPU hours?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173y1so/r_transformers_kv_caching_explained/",
          "author": null,
          "description": "https://medium.com/@joaolages/kv-caching-explained-276520203249\n    submitted by    /u/JClub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173y1so/r_transformers_kv_caching_explained/",
          "publishedOn": "2023-10-09T17:45:54.000Z",
          "wordCount": 2537,
          "title": "[R] Transformers KV Caching Explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173xp39/d_llms_in_gec_problem/",
          "author": null,
          "description": "Up to now, which LLMs model, encoder-decoder model is best for the problem of grammatical error correction on uncommon language datasets (small dataset size) or languages ​​with specific characteristics (about punctuation? ,...)\n    submitted by    /u/con-nguoi-ki-cac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173xp39/d_llms_in_gec_problem/",
          "publishedOn": "2023-10-09T17:31:35.000Z",
          "wordCount": 2568,
          "title": "[D] LLMs in GEC problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173wzr9/d_learning_natural_events_ai_art_generation/",
          "author": null,
          "description": "Hello!\n 1 I'd like to know if I could train AI to recognize details found it nature / weathering / aging and feed it pictures and it would recognize them (segmenting) so it can spot them but also their positions based on surrounding shapes, and the logical placement resulting. Seems hard.\n 2 then feed it some examples of those aging stuff on their own (with proper tags) so it learn to reproduce them and create new ones from scratch.\n 3 but then feed it \"clean\" pics and it would age them according to patterns it could find on the base training set so it can guess where to best place them.\n Pretty sure 2 is trivial enough, 1 seems possible until learning the \"logic\", but 3?\n Thanks for your insight.\n 1 comment \n    submitted by    /u/ConfusionSame9623  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173wzr9/d_learning_natural_events_ai_art_generation/",
          "publishedOn": "2023-10-09T17:03:12.000Z",
          "wordCount": 2671,
          "title": "[D] Learning natural events / AI art generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173vy9t/r_why_do_we_need_weight_decay_in_modern_deep/",
          "author": null,
          "description": "Title: Why Do We Need Weight Decay in Modern Deep Learning?\n Paper: https://arxiv.org/abs/2310.04415\n Abstract: Weight decay is a broadly used technique for training state-of-the-art deep networks, including large language models. Despite its widespread usage, its role remains poorly understood. In this work, we highlight that the role of weight decay in modern deep learning is different from its regularization effect studied in classical learning theory. For overparameterized deep networks, we show how weight decay modifies the optimization dynamics enhancing the ever-present implicit regularization of SGD via the loss stabilization mechanism. In contrast, for underparameterized large language models trained with nearly online SGD, we describe how weight decay balances the bias-variance tradeoff in stochastic optimization leading to lower training loss. Moreover, we show that weight decay also prevents sudden loss divergences for bfloat16 mixed-precision training which is a crucial tool for LLM training. Overall, we present a unifying perspective from ResNets on vision tasks to LLMs: weight decay is never useful as an explicit regularizer but instead changes the training dynamics in a desirable way. Our code is available at this https URL.\n    submitted by    /u/m_andriushchenko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173vy9t/r_why_do_we_need_weight_decay_in_modern_deep/",
          "publishedOn": "2023-10-09T16:20:51.000Z",
          "wordCount": 2725,
          "title": "[R] Why do we need weight decay in modern deep learning? 🤔",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173vy4u/d_anyone_tried_training_language_models_on_simple/",
          "author": null,
          "description": "Seems the way people train language models today feels like sending a preschooler to a college library and telling him to start browsing books.\n Anyone know of papers describing language models being trained more like a child?\n Perhaps starting with preschool books with a tiny vocabulary and short sentence fragments like \"goodnight moon...\", moving up to \"the lorax\".... and then fine-tuning on elementary school books ... then jr high level reading ... then high school .... etc.\n I'm guessing this might be a path to more natural human-feeling speech.\n Anyone here tried this, or anyone here know of papers talking about it?\n    submitted by    /u/Appropriate_Ant_4629  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173vy4u/d_anyone_tried_training_language_models_on_simple/",
          "publishedOn": "2023-10-09T16:20:43.000Z",
          "wordCount": 2652,
          "title": "[D] Anyone tried training language models on simple (elementary school) text first and fine-tuning on progressively more advanced text?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173ucih/d_where_do_yall_get_training_data/",
          "author": null,
          "description": "Hi there,\n Can I ask everyone here, where do you get your custom training data from?\n My team is training classifier models from scratch, so need thousands of specific query/response examples to train on.\n It's not the kinda data you could randomly scrape or source from a library.\n Are there any platforms that exist where you can pay a bunch of humans to write high volumes of relatively high quality text based training data?\n    submitted by    /u/paritsky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173ucih/d_where_do_yall_get_training_data/",
          "publishedOn": "2023-10-09T15:15:23.000Z",
          "wordCount": 2612,
          "title": "[D] Where do y'all get training data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173t9mz/d_what_is_sota_for_continual_learning_on/",
          "author": null,
          "description": "If you have the dataset used to make the pretrained you could always create a new model with the old + new data, but this is often prohibitively expensive or impossible because the dataset is not available.\n Catastrophic forgetting seems to be the big issue, especially if you've already undergone instruction tuning since the model will lose its conversational tone. I've seen papers discussing regularization techniques to avoid that by minimizing the changes to high value attention heads but not sure if that is considered to be the most promising direction.\n I'm aware of LoRAs but I imagine at some point you can't just arbitrarily cram new info into such a low dimensional space.\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173t9mz/d_what_is_sota_for_continual_learning_on/",
          "publishedOn": "2023-10-09T14:30:40.000Z",
          "wordCount": 2658,
          "title": "[D] - What is SOTA for Continual Learning on pretrained LLMs, particularly those that have already undergone instruction tuning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173t2is/r_thought_propagation_an_analogical_approach_to/",
          "author": null,
          "description": "LLMs are great at basic reasoning when prompted, but still struggle with complex multi-step problems like optimization or planning. Humans tackle new problems by drawing on intuition from similar experiences, which LLMs can't do.\n Researchers propose \"Thought Propagation\" to have LLMs reason more like humans - by thinking analogically. First, GPT is prompted to suggest related \"analogous\" problems to the input. Then it solves those. Finally, it aggregates the solutions to directly solve the input problem or extract useful strategies.\n They tested this technique on challenges like finding optimal graph paths, writing coherent stories, and planning for LLM agents. Across different models, it significantly boosted performance over regular prompting:\n  \n12% better at finding shortest paths\n 13% improvement in creative writing (human preference)\n 15% higher task completion for LLM agents\n  \nIt also beat chain-of-thought (there is a comparison to CoT and ToT in the paper).\n After 1-2 iterations, adding more layers of analogy didn't help much. Efficiently generating useful analogies is still difficult and that's a limitation.\n I think this is interesting because it shows the value of \"meta-cognition\" - having models reflect on their own reasoning. More techniques like this could incrementally improve LLMs' reasoning to be more human-like.\n TLDR: Teaching LLMs to reason analogically, using solutions for similar problems as hints, significantly boosts their complex reasoning ability.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173t2is/r_thought_propagation_an_analogical_approach_to/",
          "publishedOn": "2023-10-09T14:22:25.000Z",
          "wordCount": 2759,
          "title": "[R] Thought Propagation: An analogical approach to complex reasoning with LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173scf2/d_how_to_deal_with_the_inconsistency_of_eyeball/",
          "author": null,
          "description": "I tried a few open-source GAN-based face swapping models. Some of the models have issues of the inconsistency of eyeball location (or eye direction) between the original and face-swapped ones. Any suggestions? Thanks.\n    submitted by    /u/Curious_Dragonfly_13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173scf2/d_how_to_deal_with_the_inconsistency_of_eyeball/",
          "publishedOn": "2023-10-09T13:52:05.000Z",
          "wordCount": 2582,
          "title": "[D] How to deal with the inconsistency of eyeball location in the output of a GAN-based face-swapping model.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173pjho/d_i_need_to_perform_kmean_clustering_on_a_large/",
          "author": null,
          "description": "I have a class with around 96031740 96x64 images and need to select a sample of 17929 to match the minority class of my classification problem. \n Having already established a baseline based on random sampling of the majority class; now I am looking to try more complex approaches. I am specifically trying to replicate the 'nearest neighbor of clustering center' approach from Lin et al., 2017.\n The problem is I am working on my desktop and only have 32 Gb of RAM and 2 1Tb NVMe disks at half capacity. I have tried working with only 10% of the data and still the MiniBatchKMeans function of sklearn doesnt have enough space to run: \"numpy.core._exceptions._ArrayMemoryError: Unable to allocate 440. GiB for an array with shape (9603174, 6144) and data type float64\". \n Does anyone have a suggestion on how I can move forward? Could cloud services be an option? \n Thanks\n References:\n Lin, W. C., Tsai, C. F., Hu, Y. H., & Jhang, J. S. (2017). Clustering-based undersampling in class-imbalanced data. Information Sciences, 409–410, 17–26. https://doi.org/10.1016/j.ins.2017.05.008\n    submitted by    /u/RafaeldeCampos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173pjho/d_i_need_to_perform_kmean_clustering_on_a_large/",
          "publishedOn": "2023-10-09T11:34:35.000Z",
          "wordCount": 2721,
          "title": "[D] I need to perform k-mean clustering on a large image dataset to downsample the majority class.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173oi03/d_what_are_the_best_network_analysis_tools_like/",
          "author": null,
          "description": "Almost everyone I know uses tensorboard to analyze their network outputs. Some people swear on Weights & Biases instead.\n Are there any other tools that help you with your work?\n    submitted by    /u/Smart-Emu5581  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173oi03/d_what_are_the_best_network_analysis_tools_like/",
          "publishedOn": "2023-10-09T10:30:03.000Z",
          "wordCount": 2571,
          "title": "[D] What are the best network analysis tools, like tensorboard?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173nvhs/d_training_strategy_considering_the_possibility/",
          "author": null,
          "description": "During the training of overparameterized neural networks, when I observed decreasing training loss and increasing or non-decreasing validation loss, how should I decide if I should stop training and start a new experiment (with stronger regularization) or keep training to wait for 'grokking' or 'double descent' to happen? \n Are there any papers giving methods or some metrics to detect 'grokking' or 'double descent' in the early stage of training？\n    submitted by    /u/alayaMatrix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173nvhs/d_training_strategy_considering_the_possibility/",
          "publishedOn": "2023-10-09T09:48:43.000Z",
          "wordCount": 2611,
          "title": "[D] Training strategy considering the possibility of 'double descent' or 'grokking'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173ioa5/r_legged_robots_performing_extreme_parkour_using/",
          "author": null,
          "description": "submitted by    /u/pathak22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173ioa5/r_legged_robots_performing_extreme_parkour_using/",
          "publishedOn": "2023-10-09T04:04:46.000Z",
          "wordCount": 2547,
          "title": "[R] Legged Robots performing Extreme Parkour using Deep Reinforcement Learning just from a Front Camera (link in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173ef1i/d_i_need_guidance_related_to_using_machine/",
          "author": null,
          "description": "I am working on an a web app where people will be able to upload photos and write text. I don't want to have problems with my government or other countries governments in regards with the content that is uploaded to my website. I have searched about measures that can be taken to avoid this from happening. Adding a report button and having moderators are both good starting options.\n I thought that as time passes, more and more content is going to be created by the users so supervising that people are following the rules needs to be automated from the beginning. Applying measures to prevent people from uploading/posting links containing nudity, child porn, beastiality, or whatever users capture with a camera that could lead to legal problems must be a priority and allowing this type of content is not ethical.\n I am a software developer, but I haven't delved into machine learning and ai for most of my career because I haven't to. This seems like the perfect case to learn by doing and time is not a constraint, but I need some guidance.\n I have read superficially about how people train models by providing lots of data, I imagine other websites that use machine learning & ai to remove this type of content don't download media that contains nudity, child pornography, besteality, etc to train their models and make their tests. There must be some pretrained models, maybe, but how would they test this works? I don't know, I am just thinking on my own how other devs are currently handling this.\n I am no looking for upvotes, I don't care for downvotes, I am just looking for guidance, and I would be very happy to hear the opinion of someone with experience.\n    submitted by    /u/Comitatense  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173ef1i/d_i_need_guidance_related_to_using_machine/",
          "publishedOn": "2023-10-09T00:25:21.000Z",
          "wordCount": 2851,
          "title": "[D] I need guidance related to using machine learning & ai to prevent uploads or remove certain type of content from a web app.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173dwe7/r_identifying_the_risks_of_lm_agents_with_an/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.15817 \n Github: https://github.com/ryoungj/toolemu \n Website: https://toolemu.com/ \n Abstract:\n  \nRecent advances in Language Model (LM) agents and tool use, exemplified by applications like ChatGPT Plugins, enable a rich set of capabilities but also amplify potential risks - such as leaking private data or causing financial losses. Identifying these risks is labor-intensive, necessitating implementing the tools, manually setting up the environment for each test scenario, and finding risky cases. As tools and agents become more complex, the high cost of testing these agents will make it increasingly difficult to find high-stakes, long-tailed risks. To address these challenges, we introduce ToolEmu: a framework that uses an LM to emulate tool execution and enables the testing of LM agents against a diverse range of tools and scenarios, without manual instantiation. Alongside the emulator, we develop an LM-based automatic safety evaluator that examines agent failures and quantifies associated risks. We test both the tool emulator and evaluator through human evaluation and find that 68.8% of failures identified with ToolEmu would be valid real-world agent failures. Using our curated initial benchmark consisting of 36 high-stakes tools and 144 test cases, we provide a quantitative risk analysis of current LM agents and identify numerous failures with potentially severe outcomes. Notably, even the safest LM agent exhibits such failures 23.9% of the time according to our evaluator, underscoring the need to develop safer LM agents for real-world deployment. \n  \nhttps://preview.redd.it/lupenzddh2tb1.jpg?width=1368&format=pjpg&auto=webp&s=eaac22f0e3e4f5c2913aa9f2696e8fa0138967d9\n https://preview.redd.it/1dq443edh2tb1.jpg?width=1520&format=pjpg&auto=webp&s=2119053825de1cdabeafe61151940c26190abfa0\n https://preview.redd.it/m9e933edh2tb1.jpg?width=1528&format=pjpg&auto=webp&s=28c0093e8479feacb1e6f89bcb73de5994e30e8f\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173dwe7/r_identifying_the_risks_of_lm_agents_with_an/",
          "publishedOn": "2023-10-08T23:59:49.000Z",
          "wordCount": 2781,
          "title": "[R] Identifying the Risks of LM Agents with an LM-Emulated Sandbox - University of Toronto 2023 - Benchmark consisting of 36 high-stakes tools and 144 test cases!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173c1vh/r_pbllm_partially_binarized_large_language_models/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.00034 \n Github: https://github.com/hahnyuan/PB-LLM \n Abstract:\n  \nThis paper explores network binarization, a radical form of quantization, compressing model weights to a single bit, specifically for Large Language Models (LLMs) compression. Due to previous binarization methods collapsing LLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can achieve extreme low-bit quantization while maintaining the linguistic reasoning capacity of quantized LLMs. Specifically, our exploration first uncovers the ineffectiveness of naive applications of existing binarization algorithms and highlights the imperative role of salient weights in achieving low-bit quantization. Thus, PB-LLM filters a small ratio of salient weights during binarization, allocating them to higher-bit storage, i.e., partially-binarization. PB-LLM is extended to recover the capacities of quantized LMMs, by analyzing from the perspective of post-training quantization (PTQ) and quantization aware training (QAT). Under PTQ, combining the concepts from GPTQ, we reconstruct the binarized weight matrix guided by the Hessian matrix and successfully recover the reasoning capacity of PB-LLM in low-bit. Under QAT, we freeze the salient weights during training, explore the derivation of optimal scaling factors crucial for minimizing the quantization error, and propose a scaling mechanism based on this derived scaling strategy for residual binarized weights. Those explorations and the developed methodologies significantly contribute to rejuvenating the performance of low-bit quantized LLMs and present substantial advancements in the field of network binarization for LLMs. \n  \nhttps://preview.redd.it/0eywtpal22tb1.jpg?width=1183&format=pjpg&auto=webp&s=ad044123bec485805f98ae7115b1959162705b9d\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173c1vh/r_pbllm_partially_binarized_large_language_models/",
          "publishedOn": "2023-10-08T22:34:35.000Z",
          "wordCount": 2762,
          "title": "[R] PB-LLM: Partially Binarized Large Language Models - UC Berkeley 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173bs9h/help_choosing_courses_d/",
          "author": null,
          "description": "Hello, I am currently a math masters student, and I am planning to do my masters thesis on using neural networks to solve differential equations. I am taking courses in machine learning and differential equations right now, and I am going to take courses on deep neural networks and partial differential equations next semester. My question pertains to which classes would be more beneficial to learn next year (i.e. fall 2024-spring 2025). I am debating taking the sequence of regression analysis and multivariate analysis, or taking the pairing of numerical analysis for PDEs and perturbation methods. Which do you guys think would be more beneficial? Thank you very much!\n    submitted by    /u/purpledesertsky1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173bs9h/help_choosing_courses_d/",
          "publishedOn": "2023-10-08T22:22:56.000Z",
          "wordCount": 2644,
          "title": "Help choosing courses [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173at26/r_pt_3_inductive_logic_programming_with_lnns/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173at26/r_pt_3_inductive_logic_programming_with_lnns/",
          "publishedOn": "2023-10-08T21:42:02.000Z",
          "wordCount": 2537,
          "title": "[R] (Pt. 3) Inductive Logic Programming with LNN's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1738pb4/d_multiscale_predictions_with_videos_does_this/",
          "author": null,
          "description": "I aim to develop a model that utilizes livestream data by employing embeddings for each frame from t0 to tn-1, with the objective of predicting frames from tn to tn+k, after encodoing the frames using a vectorizer and taking an average (np.mean ([], axis=0) to get a resultant for that time period.\n for example list:\n 1, [...] 2, [...] 3, [...] \n the resultant embedding would be [3, np.mean(list, axis=0)]\n I incorporate positional embeddings related to the timescale, such as duration from current time variables, into the array. would this loosely qualify as a \"multiscale attention\", since it's predicting on multiple scales of time?\n Are there any examples or applications where this methodology has been implemented? references to papers or repos greatly appreciated.\n    submitted by    /u/bluzkluz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1738pb4/d_multiscale_predictions_with_videos_does_this/",
          "publishedOn": "2023-10-08T20:13:30.000Z",
          "wordCount": null,
          "title": "[d] Multiscale predictions with videos- does this approach have a name? and has it been used?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17389hx/d_how_to_model_noisy_time_series/",
          "author": null,
          "description": "Is it possible to model time series data that fluctuates. The main solution is to take first differences and make it easier to fit conventional models. What if non-linear models are built? Can they solve a noisy time series (e.g stock market data) and make good predictions? Can adding a square term or a trigonometric term or something else non-linear work? Has some researched the topic? \n    submitted by    /u/Pineapple_throw_105  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17389hx/d_how_to_model_noisy_time_series/",
          "publishedOn": "2023-10-08T19:55:08.000Z",
          "wordCount": 2604,
          "title": "[D] How to model noisy time series?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1737xdb/newsmit_ai_conference_in_mountain_view_california/",
          "author": null,
          "description": "https://preview.redd.it/n6agjsye71tb1.png?width=2034&format=png&auto=webp&s=8c0a14524d9b6ead75ac0adb3cebeedb9e614e14\n Meet some of the Greatest Minds in AI and discover how it is being used to uncover new opportunities and transform industries.\n Register and see our complete speaker list & agenda at https://www.mitaiconference.org/.\n Registration ends Oct. 16!\n https://preview.redd.it/egtj0ufr81tb1.png?width=659&format=png&auto=webp&s=bfd0521a1e1b349129250a74fa2c6a10b1a83dc7\n ​\n    submitted by    /u/769498sy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1737xdb/newsmit_ai_conference_in_mountain_view_california/",
          "publishedOn": "2023-10-08T19:40:33.000Z",
          "wordCount": 2571,
          "title": "[News]MIT AI Conference in Mountain View, California, October 21!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1736h1a/r_computer_vision_system_for_material_detection/",
          "author": null,
          "description": "The goal of my research is to develop a YOLO model that can track all cups in a live feed and determine the material that the cups are made out of. I would like to start building a database of cups, but I am unsure of the way to go for this. My first thought was to just take 1000s of pictures of different cups, but I won't be doing that. Any thoughts and suggestions would be greatly appreciated. \n    submitted by    /u/Young_Neji  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1736h1a/r_computer_vision_system_for_material_detection/",
          "publishedOn": "2023-10-08T18:40:03.000Z",
          "wordCount": 2617,
          "title": "[R] Computer Vision System for Material Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1735fks/r_ai_and_civil_engineering_probabilistic/",
          "author": null,
          "description": "Despite being much safer and more efficient than intersections, roundabouts are tricky to design - small tweaks can ruin traffic flow. \n They're typically designed iteratively, which takes time. This is a pain for developing countries without resources to test options. But AI could help auto-generate diverse and valid design options.\n In a new paper, researchers propose using Generative Flow Networks (GFlowNets) to sample varied roundabout layouts. Their approach works by constructing layouts step-by-step, maximizing rewards for realism, diversity, and safety.\n They also use a clever approximation during training. Rather than simulating traffic, they quickly check road intersections to focus the search (This sped up training by 200x).\n The authors tested their generated roundabout designs on simulated road scenarios of different complexity. Their model generated more diverse designs than rule-based or reinforcement learning approaches while maintaining realism and traffic flow.\n Plus, as road connections increased, the model kept discovering novel options without compromising quality.\n I thought this paper was an awesome proof-of-concept for auto-generating better roundabouts with AI, and I especially liked the authors' angle of leveraging this technology to specifically help developing countries. This could help them design higher-quality transportation networks faster and cheaper. (Plus I also like Cities: Skylines but struggle at building roundabouts).\n TLDR: Roundabouts are costly to design. New paper demonstrates how AI can generate diverse, valid roundabout designs quickly to cut costs and raise quality. Helpful for infrastructure in developing countries.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1735fks/r_ai_and_civil_engineering_probabilistic/",
          "publishedOn": "2023-10-08T17:56:58.000Z",
          "wordCount": 2787,
          "title": "[R] AI and Civil Engineering: Probabilistic Generative Modeling for Procedural Roundabout Generation for Developing Countries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1732o0l/p_makeagents_a_python_micro_framework_for/",
          "author": null,
          "description": "submitted by    /u/montebicyclelo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1732o0l/p_makeagents_a_python_micro_framework_for/",
          "publishedOn": "2023-10-08T15:58:41.000Z",
          "wordCount": null,
          "title": "[P] MakeAgents - A Python micro framework for creating LLM-powered agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17322bu/discussion_weekday_specific_feature_engineering/",
          "author": null,
          "description": "Focusing on Specific Day of Week Features With Binary Masks, One Hot Coding, Sin/Cos 2d Vector, Or Embedded Vector in Multivariate Time Series Data ?\n The essential challenge is trying to get the model to focus on making predictions for mondays by looking at monday (or actually making predictions for categorical earmarked hours of the day such as midday sales data).\n I keep getting the suggestion to include one hot encoding as a binary mask feature to determine if an hour sales figure is earmarked for the category or the day of the week I want the model to focus on-- in order to get it to ignore the data from the other six days of the week or the other periods of the day.\n In other words I want to hone in on and focus on one period of the week to predict for that period of the week, with extra attention, within time series data. Is this type of binary mask really sufficient for that, or am I overlooking something?\n    submitted by    /u/samdane7777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17322bu/discussion_weekday_specific_feature_engineering/",
          "publishedOn": "2023-10-08T15:32:28.000Z",
          "wordCount": 2705,
          "title": "[Discussion] Weekday Specific Feature Engineering in Time Series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1731tf3/d_rag_platform/",
          "author": null,
          "description": "I don’t have a large data science or even engineering team. But I’m interested in implementing RAG against my corpus in SharePoint. Are there platforms that I can configure without having to put them together or write code to implement RAG?\n    submitted by    /u/Silver_Patient_7253  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1731tf3/d_rag_platform/",
          "publishedOn": "2023-10-08T15:22:17.000Z",
          "wordCount": 2575,
          "title": "[D] RAG Platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1731pcg/r_why_is_adamw_often_superior_to_adam_with/",
          "author": null,
          "description": "A recent work explores how weight decay controls the effective learning rate for different layers and neurons. This rotational behavior drastically differs between Adam with L2 regularization compared to Adam with decoupled weight decay (AdamW) and seems to be the reason AdamW performs better in practice. It could also explain why normalization methods like weight standardization work so well and irregular rotational behavior could contribute to the need for a learning rate warmup.\n Full Abstract: Weight decay can significantly impact the optimization dynamics of deep neural networks. In certain situations, the effects of weight decay and gradient updates on the magnitude of a parameter vector cancel out on average, forming a state known as equilibrium. This causes the expected rotation of the vector in each update to remain constant along with its magnitude. Importantly, equilibrium can arise independently for the weight vectors of different layers and neurons. These equilibria are highly homogeneous for some optimizer and normalization configurations, effectively balancing the average rotation—a proxy for the effective learning rate—across network components. In this work we explore the equilibrium states of multiple optimizers including AdamW and SGD with momentum, providing insights into interactions between the learning rate, weight decay, initialization, normalization and learning rate schedule. We show how rotational equilibrium can be enforced throughout training, eliminating the chaotic transient phase corresponding to the transition towards equilibrium, thus simplifying the training dynamics. Finally, we show that rotational behavior may play a key role in the effectiveness of AdamW compared to Adam with L2-regularization, the performance of different normalization layers, and the need for learning rate warmup.\n    submitted by    /u/PlantsAreSoooAwesome  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1731pcg/r_why_is_adamw_often_superior_to_adam_with/",
          "publishedOn": "2023-10-08T15:17:39.000Z",
          "wordCount": 2819,
          "title": "[R] Why is AdamW often superior to Adam with L2-Regularization in practice? The answer may lie in how weight decay balances updates across layers.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17318zf/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17318zf/d_simple_questions_thread/",
          "publishedOn": "2023-10-08T15:00:22.000Z",
          "wordCount": 2584,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1730i60/d_why_cant_models_trained_on_textimage/",
          "author": null,
          "description": "My main question is, that shouldn't models with Text-image interleaved data, be able to generate images as well as take them as input? because however they were tokenized, the bot would have image outputs as well, wouldn't it?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1730i60/d_why_cant_models_trained_on_textimage/",
          "publishedOn": "2023-10-08T14:29:08.000Z",
          "wordCount": 2585,
          "title": "[D] Why can't models trained on text-image interleaved data generate Images as well as read them?",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Jay Alammar",
      "feedUrl": "https://jalammar.github.io/feed.xml",
      "siteUrl": "http://jalammar.github.io/",
      "articles": []
    },
    {
      "title": "Distill",
      "feedUrl": "https://distill.pub/rss.xml",
      "siteUrl": "https://distill.pub",
      "articles": []
    },
    {
      "title": "inFERENCe",
      "feedUrl": "https://www.inference.vc/rss",
      "siteUrl": "https://www.inference.vc/",
      "articles": []
    },
    {
      "title": "AI Trends",
      "feedUrl": "https://www.aitrends.com/feed",
      "siteUrl": "https://www.aitrends.com/",
      "articles": []
    },
    {
      "title": "AI Weirdness",
      "feedUrl": "https://aiweirdness.com/rss",
      "siteUrl": "https://www.aiweirdness.com/",
      "articles": [
        {
          "id": "653ec5fe02b916000133598c",
          "author": "Janelle Shane",
          "description": "Google Bard has the ability to describe images. But it turns out what you get depends a lot on how you ask.\nI gave Bard this image and the prompt \"Please describe this spooky Halloween scene\". On the right is the image I got when I took the",
          "link": "https://www.aiweirdness.com/the-spookiest-halloween-scenes/",
          "publishedOn": "2023-10-31T03:25:24.000Z",
          "wordCount": 1866,
          "title": "The spookiest Halloween scenes",
          "imageUrl": "https://www.aiweirdness.com/content/images/2023/10/Halloween_hotel_room_Dalle3.png"
        },
        {
          "id": "653ee34b02b91600013359f5",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-more-spooky-halloween-scenes/",
          "publishedOn": "2023-10-31T03:25:09.000Z",
          "wordCount": 678,
          "title": "Bonus: more spooky Halloween scenes",
          "imageUrl": "https://www.aiweirdness.com/content/images/2021/03/neural_net_box_default_square-01-2.png"
        },
        {
          "id": "653b0bec02b916000132e6ff",
          "author": "Janelle Shane",
          "description": "In Which DALL-E3 generates very weird candy names",
          "link": "https://www.aiweirdness.com/choose-your-candy/",
          "publishedOn": "2023-10-27T03:21:25.000Z",
          "wordCount": 967,
          "title": "Choose your candy",
          "imageUrl": "https://www.aiweirdness.com/content/images/2023/10/Screen-Shot-2023-10-26-at-8.39.59-PM.png"
        },
        {
          "id": "653b275202b916000132e7c3",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-more-weird-candy/",
          "publishedOn": "2023-10-27T03:21:05.000Z",
          "wordCount": 672,
          "title": "Bonus: More weird candy",
          "imageUrl": "https://www.aiweirdness.com/content/images/2021/03/neural_net_box_default_square-01-2.png"
        }
      ]
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed.xml",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": [
        {
          "id": "http://bair.berkeley.edu/blog/2023/10/17/grif/",
          "author": null,
          "description": "Goal Representations for Instruction Following\n\n\n\nFigure title. Figure caption. This image is centered and set to 50%\npage width. -->\n\n\nA longstanding goal of the field of robot learning has been to create generalist agents that can perform tasks for humans. Natural language has the potential to be an easy-to-use interface for humans to specify arbitrary tasks, but it is difficult to train robots to follow language instructions. Approaches like language-conditioned behavioral cloning (LCBC) train policies to directly imitate expert actions conditioned on language, but require humans to annotate all training trajectories and generalize poorly across scenes and behaviors. Meanwhile, recent goal-conditioned approaches perform much better at general manipulation tasks, but do not enable easy t…",
          "link": "http://bair.berkeley.edu/blog/2023/10/17/grif/",
          "publishedOn": "2023-10-17T14:35:00.000Z",
          "wordCount": 2025,
          "title": "Goal Representations for Instruction Following",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/grif/thumbnail.png"
        },
        {
          "id": "http://bair.berkeley.edu/blog/2023/10/16/p3o/",
          "author": null,
          "description": "Rethinking the Role of PPO in RLHF\n\nTL;DR: In RLHF, there’s tension between the reward learning phase, which uses human preference in the form of comparisons, and the RL fine-tuning phase, which optimizes a single, non-comparative reward. What if we performed RL in a comparative way?\nFigure 1:\n This diagram illustrates the difference between reinforcement learning from absolute feedback and relative feedback. By incorporating a new component - pairwise policy gradient, we can unify the reward modeling stage and RL stage, enabling direct updates based on pairwise responses.\n\n\n\nLarge Language Models (LLMs) have powered increasingly capable virtual assistants, such as GPT-4, Claude-2, Bard and Bing Chat. These systems can respond to complex user queries, write code, and even produce poetry. T…",
          "link": "http://bair.berkeley.edu/blog/2023/10/16/p3o/",
          "publishedOn": "2023-10-16T09:00:00.000Z",
          "wordCount": 1763,
          "title": "Rethinking the Role of PPO in RLHF",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/p3o/pipeline_h.png"
        }
      ]
    },
    {
      "title": "Becoming Human: Artificial Intelligence Magazine - Medium",
      "feedUrl": "https://becominghuman.ai/feed",
      "siteUrl": "https://becominghuman.ai?source=rss----5e5bef33608a---4",
      "articles": [
        {
          "id": "https://medium.com/p/823b9d08f6d8",
          "author": "Stefan Kojouharov",
          "description": "Hey Friend,",
          "link": "https://becominghuman.ai/exclusive-invitation-join-my-talk-on-ai-bots-this-morning-823b9d08f6d8?source=rss----5e5bef33608a---4",
          "publishedOn": "2023-11-01T14:46:29.000Z",
          "wordCount": 2243,
          "title": "Exclusive Invitation: Join My Talk on AI-Bots This Morning!",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:1200/0*1sGgBCZg1Zaj8A9R"
        }
      ]
    },
    {
      "title": "MIT News - Artificial intelligence",
      "feedUrl": "http://news.mit.edu/rss/topic/artificial-intelligence2",
      "siteUrl": "https://news.mit.edu/rss/topic/artificial-intelligence2",
      "articles": [
        {
          "id": "https://news.mit.edu/2023/takeda-fellows-advancing-research-intersection-ai-health-1102",
          "author": "School of Engineering",
          "description": "Thirteen new graduate student fellows will pursue exciting new paths of knowledge and discovery.",
          "link": "https://news.mit.edu/2023/takeda-fellows-advancing-research-intersection-ai-health-1102",
          "publishedOn": "2023-11-02T19:50:00.000Z",
          "wordCount": 4064,
          "title": "2023-24 Takeda Fellows: Advancing research at the intersection of AI and health",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/takeda-fellows.png"
        },
        {
          "id": "https://news.mit.edu/2023/generating-opportunities-generative-ai-rama-ramakrishnan-1102",
          "author": "Eric Bender | MIT Industrial Liaison Program",
          "description": "Rama Ramakrishnan helps companies explore the promises and perils of large language models and other transformative AI technologies.",
          "link": "https://news.mit.edu/2023/generating-opportunities-generative-ai-rama-ramakrishnan-1102",
          "publishedOn": "2023-11-02T16:15:00.000Z",
          "wordCount": 3063,
          "title": "Generating opportunities with generative AI",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/Rama-Ramakrishnan.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/new-techniques-efficiently-accelerate-sparse-tensors-1030",
          "author": "Adam Zewe | MIT News",
          "description": "Complimentary approaches — “HighLight” and “Tailors and Swiftiles” — could boost the performance of demanding machine-learning tasks.",
          "link": "https://news.mit.edu/2023/new-techniques-efficiently-accelerate-sparse-tensors-1030",
          "publishedOn": "2023-10-30T04:00:00.000Z",
          "wordCount": 3411,
          "title": "New techniques efficiently accelerate sparse tensors for massive AI models",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-Sparsity-Solutions-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/accelerating-ai-tasks-while-preserving-data-security-1030",
          "author": "Adam Zewe | MIT News",
          "description": "The SecureLoop search tool efficiently identifies secure designs for hardware that can boost the performance of complex AI tasks, while requiring less energy.",
          "link": "https://news.mit.edu/2023/accelerating-ai-tasks-while-preserving-data-security-1030",
          "publishedOn": "2023-10-30T04:00:00.000Z",
          "wordCount": 3111,
          "title": "Accelerating AI tasks while preserving data security",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-SecureLoop-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/brain-self-supervised-computational-models-1030",
          "author": "Anne Trafton | MIT News",
          "description": "Two studies find “self-supervised” models, which learn about their environment from unlabeled data, can show activity patterns similar to those of the mammalian brain.",
          "link": "https://news.mit.edu/2023/brain-self-supervised-computational-models-1030",
          "publishedOn": "2023-10-30T04:00:00.000Z",
          "wordCount": 3277,
          "title": "The brain may learn about the world the same way some computational models do",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-SelfSupervisedLearning-01.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/celebrating-kendall-squares-past-and-shaping-future-1023",
          "author": "Zach Winn | MIT News",
          "description": "The 15th Kendall Square Association annual meeting explored new and old aspects of the neighborhood.",
          "link": "https://news.mit.edu/2023/celebrating-kendall-squares-past-and-shaping-future-1023",
          "publishedOn": "2023-10-23T16:12:00.000Z",
          "wordCount": 2835,
          "title": "Celebrating Kendall Square’s past and shaping its future",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/Kendall-Emily-Dahl-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/generative-ai-must-innovate-engineering-design-1019",
          "author": "Jennifer Chu | MIT News",
          "description": "AI models that prioritize similarity falter when asked to design something completely new.",
          "link": "https://news.mit.edu/2023/generative-ai-must-innovate-engineering-design-1019",
          "publishedOn": "2023-10-19T04:00:00.000Z",
          "wordCount": 3023,
          "title": "To excel at engineering design, generative AI must learn to innovate, study finds",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-AI-Shift-A1-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/daron-acemoglu-wins-ask-social-science-award-1018",
          "author": "Benjamin Daniel | School of Humanities, Arts, and Social Sciences",
          "description": "The award honors research on public policy with a focus on economic and governmental reforms.",
          "link": "https://news.mit.edu/2023/daron-acemoglu-wins-ask-social-science-award-1018",
          "publishedOn": "2023-10-18T19:20:00.000Z",
          "wordCount": 2063,
          "title": "Institute Professor Daron Acemoglu Wins A.SK Social Science Award",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-Professor-Daron-Acemoglu.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/new-technique-helps-robots-pack-objects-tight-space-1017",
          "author": "Adam Zewe | MIT News",
          "description": "Researchers coaxed a family of generative AI models to work together to solve multistep robot manipulation problems.",
          "link": "https://news.mit.edu/2023/new-technique-helps-robots-pack-objects-tight-space-1017",
          "publishedOn": "2023-10-17T04:00:00.000Z",
          "wordCount": 3343,
          "title": "New technique helps robots pack objects into a tight space",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-Diffusion-CCSP-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/method-interpret-ai-might-not-be-so-interpretable-after-all-1016",
          "author": "Kylie Foy | MIT Lincoln Laboratory",
          "description": "Some researchers see formal specifications as a way for autonomous systems to \"explain themselves\" to humans. But a new study finds that we aren't understanding.",
          "link": "https://news.mit.edu/2023/method-interpret-ai-might-not-be-so-interpretable-after-all-1016",
          "publishedOn": "2023-10-16T20:25:00.000Z",
          "wordCount": 2803,
          "title": "A method to interpret AI might not be so interpretable after all",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/Formal-methods-AI.png"
        }
      ]
    },
    {
      "title": "NVIDIA Blog",
      "feedUrl": "http://feeds.feedburner.com/nvidiablog",
      "siteUrl": "https://blogs.nvidia.com/",
      "articles": [
        {
          "id": "https://blogs.nvidia.com/?p=67914",
          "author": "Cheryl Martin",
          "description": "Embodying the convergence of AI and academia, the University of Florida Friday inaugurated the Malachowsky Hall for Data Science & Information Technology. The sleek, seven-story building is poised to play a pivotal role in UF’s ongoing efforts to harness the transformative power of AI, reaffirming its stature as one of the nation’s leading public universities. Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/11/03/starship-for-mind-uf-malachowsky-hall/",
          "publishedOn": "2023-11-03T15:43:03.000Z",
          "wordCount": 1773,
          "title": "‘Starship for the Mind’: University of Florida Opens Malachowsky Hall, an Epicenter for AI and Data Science",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/11/UF-Malachowsky-Hall-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67865",
          "author": "Ben Oliveri",
          "description": "The world’s 5 billion internet users and nearly 54 billion devices generate 3.4 petabytes of data per second, according to IDC. As digitalization accelerates, enterprise IT teams are under greater pressure to identify and block incoming cyber threats to ensure business operations and services are not interrupted — and AI-based cybersecurity provides a reliable way Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/11/03/ai-cybersecurity-business-resilience/",
          "publishedOn": "2023-11-03T15:00:54.000Z",
          "wordCount": 3321,
          "title": "How AI-Based Cybersecurity Strengthens Business Resilience",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/11/cybersecurity-for-industries.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67836",
          "author": "Ike Nnoli",
          "description": "AI technologies are having a massive impact across industries, including media and entertainment, automotive, customer service and more.",
          "link": "https://blogs.nvidia.com/blog/2023/11/02/foundation-models-gaming/",
          "publishedOn": "2023-11-02T16:25:47.000Z",
          "wordCount": 2336,
          "title": "How Are Foundation Models Used in Gaming?",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/11/foundation-model-explainer-feature-image.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67845",
          "author": "GeForce NOW Community",
          "description": "Gear up with gratitude for more gaming time. GeForce NOW brings members a cornucopia of 15 newly supported games to the cloud this week. That’s just the start — there are a total of 54 titles coming in the month of November. Members can also join thousands of esports fans in the cloud with the Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/11/02/geforce-now-thursday-nov-2/",
          "publishedOn": "2023-11-02T13:00:31.000Z",
          "wordCount": 2450,
          "title": "GeForce NOW-vember Brings Over 50 New Games to Stream In the Cloud",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/11/gfn-thursday-11-2-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67827",
          "author": "Dion Harris",
          "description": "The home of the first industrial revolution just made a massive investment in the next one. The U.K. government has announced it will spend £225 million ($273 million) to build one of the world’s fastest AI supercomputers. Called Isambard-AI, it’s the latest in a series of systems named after a legendary 19th century British engineer Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/11/01/uk-largest-ai-supercomputer/",
          "publishedOn": "2023-11-01T16:04:31.000Z",
          "wordCount": 1757,
          "title": "Turing’s Mill: AI Supercomputer Revs UK’s Economic Engine",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/NCC-UK-Isambard-AI-site.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67783",
          "author": "Kristen Yee",
          "description": "Generative AI and large language models are stirring change across industries — but according to NVIDIA Senior Product Manager of Developer Marketing Annamalai Chockalingam, “we’re still in the early innings.”  In the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz spoke with Chockalingam about LLMs: what they are, their current state and their future Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/11/01/llms-podcast/",
          "publishedOn": "2023-11-01T13:00:00.000Z",
          "wordCount": 1410,
          "title": "Unlocking the Power of Language: NVIDIA’s Annamalai Chockalingam on the Rise of LLMs",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67784",
          "author": "Scott Martin",
          "description": "In the world’s largest solar race car event of the year, the University of New South Wales Sunswift Racing team is having its day in the sun. The World Solar Challenge, which first began some 35 years ago, attracts academic participants from across the globe. This year’s event drew nearly 100 competitors. The race runs Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/31/sunswift-racing-world-solar-challenge-jetson/",
          "publishedOn": "2023-10-31T16:00:42.000Z",
          "wordCount": 1878,
          "title": "Riding the Rays: Sunswift Racing Shines in World Solar Challenge Race",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/Sunswift7-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67789",
          "author": "Gerardo Delgado",
          "description": "The highly anticipated NVIDIA DLSS 3.5 update, including Ray Reconstruction for NVIDIA Omniverse — a platform for connecting and building custom 3D tools and apps — is now available.",
          "link": "https://blogs.nvidia.com/blog/2023/10/31/dlss-omniverse-cinema-4d-halloween/",
          "publishedOn": "2023-10-31T13:00:49.000Z",
          "wordCount": 2130,
          "title": "DLSS 3.5 With Ray Reconstruction Now Available in NVIDIA Omniverse",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-sabour-amirazodi-wk81-crowd-1280w-672x341.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67732",
          "author": "Rick Merritt",
          "description": "A research paper released today describes ways generative AI can assist one of the most complex engineering efforts: designing semiconductors. The work demonstrates how companies in highly specialized fields can train large language models (LLMs) on their internal data to build assistants that increase productivity. Few pursuits are as challenging as semiconductor design. Under a Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/30/llm-semiconductors-chip-nemo/",
          "publishedOn": "2023-10-30T16:00:33.000Z",
          "wordCount": 1947,
          "title": "Silicon Volley: Designers Tap Generative AI for a Chip Assist",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/NVIDIA-GH100-GPU-x-1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67573",
          "author": "Scott Martin",
          "description": "Researchers are taking deep learning for a deep dive, literally. The Woods Hole Oceanographic Institution (WHOI) Autonomous Robotics and Perception Laboratory (WARPLab) and MIT are developing a robot for studying coral reefs and their ecosystems. The WARPLab autonomous underwater vehicle (AUV), enabled by an NVIDIA Jetson Orin NX module, is an effort from the world’s Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/26/coral-reef-decline-curee-robot-jetson-isaac-omniverse/",
          "publishedOn": "2023-10-26T16:00:57.000Z",
          "wordCount": 2363,
          "title": "Turning the Tide on Coral Reef Decline: CUREE Robot Dives Deep With Deep Learning",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/CUREE-672x448.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67744",
          "author": "GeForce NOW Community",
          "description": "The cloud is full of treats this GFN Thursday with Cities: Skylines II now streaming, leading 15 newly supported games this week. The game’s publisher, Paradox Interactive, is offering GeForce NOW one-month Priority memberships for those who pick up the game first, so make sure to grab one before they’re gone. Among the newly supported Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/26/geforce-now-thursday-oct-26/",
          "publishedOn": "2023-10-26T13:00:01.000Z",
          "wordCount": 2142,
          "title": "The Sky’s the Limit: ‘Cities: Skylines II’ Streams This Week on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/gfn-thursday-cities-skylines-2-nv-blog-1280x680-no-copy.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67715",
          "author": "Isha Salian",
          "description": "NVIDIA researchers are collaborating with academic centers worldwide to advance generative AI, robotics and the natural sciences — and more than a dozen of these projects will be shared at NeurIPS, one of the world’s top AI conferences. Set for Dec. 10-16 in New Orleans, NeurIPS brings together experts in generative AI, machine learning, computer Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/25/neurips-ai-research/",
          "publishedOn": "2023-10-25T13:00:09.000Z",
          "wordCount": 2322,
          "title": "Next-Gen Neural Networks: NVIDIA Research Announces Array of AI Advancements at NeurIPS",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/Scenescape-screengrab-1.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67668",
          "author": "Gerardo Delgado",
          "description": "Visual effects artist Surfaced Studio returns to 'In the NVIDIA Studio' to share his real-world VFX project, created on a brand new Razer Blade 16 Mercury Edition laptop powered by GeForce RTX 4080 graphics.",
          "link": "https://blogs.nvidia.com/blog/2023/10/24/surfaced-studio-adobe-premiere-pro-after-effects-blender-unreal/",
          "publishedOn": "2023-10-24T13:00:42.000Z",
          "wordCount": 2348,
          "title": "On Razer’s Edge: VFX Star Surfaced Studio Creates Stunning Sci-Fi World This Week ‘In The NVIDIA Studio’",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/surfaced-studio-nv-blog-header-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67650",
          "author": "Kristen Yee",
          "description": "Images such as those in Google Street View are taking on a new purpose in the hands of University of Florida Assistant Professor of Artificial Intelligence Chaofeng Wang. He’s using them, along with deep learning, in a research project to automate the evaluation of urban buildings. The project aims to help governments mitigate natural disaster Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/23/street-view-image-deep-learning-research-urban-building/",
          "publishedOn": "2023-10-23T20:30:39.000Z",
          "wordCount": 1897,
          "title": "Street View to the Rescue: Deep Learning Paves the Way to Safer Buildings",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/streetview3.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67485",
          "author": "Isha Salian",
          "description": "GPU-powered surgical-simulation devices are helping train more than 2,000 doctors a year in lower-income countries to treat cataract blindness, the world’s leading cause of blindness, thanks to the nonprofit HelpMeSee. While cataract surgery has a success rate of around 99%, many patients in low- and middle-income countries lack access to the common procedure due to Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/20/helpmesee-nonprofit-training-simulator-for-cataract-surgery/",
          "publishedOn": "2023-10-20T13:00:50.000Z",
          "wordCount": 1777,
          "title": "For the World to See: Nonprofit Deploys GPU-Powered Simulators to Train Providers in Sight-Saving Surgery",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/Dr.-Samuel-Kwizera.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67624",
          "author": "Angie Lee",
          "description": "A new AI agent developed by NVIDIA Research that can teach robots complex skills has trained a robotic hand to perform rapid pen-spinning tricks — for the first time as well as a human can. The stunning prestidigitation, showcased in the video above, is one of nearly 30 tasks that robots have learned to expertly Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/20/eureka-robotics-research/",
          "publishedOn": "2023-10-20T13:00:24.000Z",
          "wordCount": 1773,
          "title": "Eureka! NVIDIA Research Breakthrough Puts New Spin on Robot Learning",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/10/franka_cabinet.mp4",
            "length": "275129",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/eureka-featured-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67603",
          "author": "Stacy Ozorio",
          "description": "To enable professionals worldwide to build and run AI applications right from their desktops, NVIDIA and AMD are powering a new line of workstations equipped with NVIDIA RTX Ada Generation GPUs and AMD Ryzen Threadripper PRO 7000 WX-Series CPUs. Bringing together the highest levels of AI computing, rendering and simulation capabilities, these new platforms enable Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/19/ai-workstations/",
          "publishedOn": "2023-10-19T19:30:07.000Z",
          "wordCount": 1628,
          "title": "Next-Level Computing: NVIDIA and AMD Deliver Powerful Workstations to Accelerate AI, Rendering and Simulation",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/proviz-intel-nv-workstation-kv-2972327-edit-r2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67595",
          "author": "Charlie Boyle",
          "description": "Training generative AI models just got easier. NVIDIA DGX Cloud AI supercomputing platform and NVIDIA AI Enterprise software are now available in Oracle Cloud Marketplace, making it possible for Oracle Cloud Infrastructure customers to access high-performance accelerated computing and software to run secure, stable and supported production AI in just a few clicks. The addition Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/19/nvidia-ai-now-available-in-oracle-cloud-marketplace/",
          "publishedOn": "2023-10-19T19:00:07.000Z",
          "wordCount": 1857,
          "title": "NVIDIA AI Now Available in Oracle Cloud Marketplace",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/NVIDIA-OCI-logos.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67578",
          "author": "GeForce NOW Community",
          "description": "Rush to the cloud — stream Counter-Strike 2 on GeForce NOW for the highest frame rates. Members can play through the newest chapter of Valve’s elite, competitive, first-person shooter from the cloud. It’s all part of an action-packed GFN Thursday, with 22 more games joining the cloud gaming platform’s library, including Hot Wheels Unleashed 2 Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/19/geforce-now-thursday-oct-19/",
          "publishedOn": "2023-10-19T13:00:22.000Z",
          "wordCount": 1643,
          "title": "Coming in Clutch: Stream ‘Counter-Strike 2’ From the Cloud for Highest Frame Rates",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/gfn-thursday-10-19-nv-blog-1280x680-no-copy.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67421",
          "author": "Amit Goel",
          "description": "Powerful generative AI models and cloud-native APIs and microservices are coming to the edge. Generative AI is bringing the power of transformer models and large language models to virtually every industry. That reach now includes areas that touch edge, robotics and logistics systems: defect detection, real-time asset tracking, autonomous planning and navigation, human-robot interactions and Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/18/metropolis-jetson-isaac-robotics-edge-ai-developers/",
          "publishedOn": "2023-10-18T14:00:48.000Z",
          "wordCount": 2437,
          "title": "NVIDIA Expands Robotics Platform to Meet the Rise of Generative AI",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/MetropolisJetson2.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67565",
          "author": "Kristen Yee",
          "description": "Artificial intelligence is now a household term. Responsible AI is hot on its heels. Julia Stoyanovich, associate professor of computer science and engineering at NYU and director of the university’s Center for Responsible AI, wants to make the terms “AI” and “responsible AI” synonymous. In the latest episode of the NVIDIA AI Podcast, host Noah Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/18/julia-stoyanovich-responsible-ai/",
          "publishedOn": "2023-10-18T13:00:49.000Z",
          "wordCount": 1653,
          "title": "Making Machines Mindful: NYU Professor Talks Responsible AI",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67520",
          "author": "Pooya Ghobadpour",
          "description": "Real-time rendering, animation and texture baking are essential workflows for 3D art production. Using the Marmoset Toolbag software, 3D artists can enhance their creative workflows and build complex 3D models without disruptions to productivity.",
          "link": "https://blogs.nvidia.com/blog/2023/10/18/marmoset-extends-openusd-support/",
          "publishedOn": "2023-10-18T13:00:39.000Z",
          "wordCount": 2222,
          "title": "Into the Omniverse: Marmoset Brings Breakthroughs in Rendering, Extends OpenUSD Support to Enhance 3D Art Production",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/nv-ov-ito-1280x680_Marmoset.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67555",
          "author": "Danny Shapiro",
          "description": "NVIDIA founder and CEO Jensen Huang joined Hon Hai (Foxconn) Chairman and CEO Young Liu to unveil the latest in their ongoing partnership to develop the next wave of intelligent electric vehicle (EV) platforms for the global automotive market. This latest move, announced today at the fourth annual Hon Hai Tech Day in Taiwan, will Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/17/foxconn-nvidia-electric-vehicle/",
          "publishedOn": "2023-10-18T03:00:44.000Z",
          "wordCount": 1683,
          "title": "Foxconn and NVIDIA Amp Up Electric Vehicle Innovation",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/foxconnhhtd-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67466",
          "author": "Jesse Clayton",
          "description": "GeForce RTX and NVIDIA RTX GPUs, which are packed with dedicated AI processors called Tensor Cores, are bringing the power of generative AI natively to more than 100 million Windows PCs and workstations.",
          "link": "https://blogs.nvidia.com/blog/2023/10/17/tensorrt-llm-windows-stable-diffusion-rtx/",
          "publishedOn": "2023-10-17T13:00:42.000Z",
          "wordCount": 2216,
          "title": "Striking Performance: Large Language Models up to 4x Faster on RTX With TensorRT-LLM for Windows",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-ai-announcemenet-blog-kv-oct2023-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67476",
          "author": "Gerardo Delgado",
          "description": "NVIDIA today announced an update to RTX Video Super Resolution (VSR) that delivers greater overall graphical fidelity with preserved details, upscaling for native videos and support for GeForce RTX 20 Series GPUs.",
          "link": "https://blogs.nvidia.com/blog/2023/10/17/rtx-video-super-resolution-ai-obs-broadcast/",
          "publishedOn": "2023-10-17T13:00:34.000Z",
          "wordCount": 2097,
          "title": "NVIDIA RTX Video Super Resolution Update Enhances Video Quality, Detail Preservation and Expands to GeForce RTX 20 Series GPUs",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/runebee-nv-blog-header-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67432",
          "author": "JJ Kim",
          "description": "At SHoP Architects, a New York City-based architectural firm, Mengyi Fan and her team aim to inspire industry professionals to create visual masterpieces by incorporating emerging technologies. Fan, the director of visualization at SHoP, has expertise that spans the fields of architectural visualization and design. She takes a definitive, novel and enduring approach to designing Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/13/rtx-ambassador-mengyi-fan/",
          "publishedOn": "2023-10-13T16:00:17.000Z",
          "wordCount": 1708,
          "title": "From Skylines to Streetscapes: How SHoP Architects Brings Innovative Designs to Life",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/10/SHoP_Botswana-Innovation-Hub_lite.mp4",
            "length": "9616749",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/Mengyi-Fan-copy_1.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67426",
          "author": "Jamie Allan",
          "description": "At one of the U.K.’s largest technology festivals, top enterprises and startups are this week highlighting their latest innovations, hosting workshops and celebrating the growing tech ecosystem based in the country’s southwest. The Bristol Technology Festival today showcased the work of nine startups that recently participated in a challenge hosted by Digital Catapult — the Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/12/ai-for-creative-industries-uk-startups/",
          "publishedOn": "2023-10-12T19:58:03.000Z",
          "wordCount": 1861,
          "title": "UK Tech Festival Showcases Startups Using AI for Creative Industries",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/bristol-tech-fest-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67408",
          "author": "GeForce NOW Community",
          "description": "Put the pedal to the metal this GFN Thursday as Forza Motorsport leads 23 new games in the cloud. Plus, Acer’s Predator Connect 6E is the newest addition to the GeForce NOW Recommended program, with easy cloud gaming quality-of-service (QoS) settings built in to give Ultimate members the best streaming experience. No Breaks, No Limits, Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/12/geforce-now-thursday-oct-12/",
          "publishedOn": "2023-10-12T13:00:10.000Z",
          "wordCount": 1720,
          "title": "Get in Gear: ‘Forza Motorsport’ Races Onto GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/gfn-thursday-10-12-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67289",
          "author": "Annamalai Chockalingam",
          "description": "Developers have a new AI-powered steering wheel to help them hug the road while they drive powerful large language models (LLMs) to their desired locations. NVIDIA NeMo SteerLM lets companies define knobs to dial in a model’s responses as it’s running in production, a process called inference. Unlike current methods for customizing an LLM, it Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/11/customize-ai-models-steerlm/",
          "publishedOn": "2023-10-11T14:30:17.000Z",
          "wordCount": 1937,
          "title": "Take the Wheel: NVIDIA NeMo SteerLM Lets Companies Customize a Model’s Responses During Inference",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/SteerLM-KV-x1280-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67366",
          "author": "Gerardo Delgado",
          "description": "Generative AI is helping creatives across many industries bring ideas to life at unprecedented speed. This technology will be on display at Adobe MAX, running through Thursday, Oct. 12, in person and virtually.",
          "link": "https://blogs.nvidia.com/blog/2023/10/10/adobe-max-firefly-creative-cloud-substance-3d/",
          "publishedOn": "2023-10-10T16:00:26.000Z",
          "wordCount": 2661,
          "title": "MAXimum AI Performance: Latest Adobe Updates Accelerated by NVIDIA GPUs Improve Workflows for Millions of Creatives",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/adobe-max-2023-nv-blog-header-preview-1280x680-1.jpg"
        }
      ]
    },
    {
      "title": "David Stutz",
      "feedUrl": "http://davidstutz.de/feed",
      "siteUrl": "https://davidstutz.de/",
      "articles": [
        {
          "id": "https://davidstutz.de/?p=9517",
          "author": "David Stutz",
          "description": "Conformal prediction uses a held-out, labeled set of examples to calibrate a classifier to yield confidence sets that include the true label with user-specified probability. But what happens if even experts disagree on the ground truth labels. Commonly, this is resolved by taking the majority voted label from multiple expert. However, in difficult and ambiguous tasks, the majority voted label might be misleading and a bad representation of the underlying true posterior distribution. In this paper, we introduce Monte Carlo conformal prediction which allows to perform conformal calibration directly against expert opinions or aggregate statistics thereof.\nThe post TMLR Paper “Conformal Prediction under Ambiguous Ground Truth” appeared first on David Stutz.",
          "link": "https://davidstutz.de/tmlr-paper-conformal-prediction-under-ambiguous-ground-truth/",
          "publishedOn": "2023-10-31T23:48:55.000Z",
          "wordCount": 1153,
          "title": "TMLR Paper “Conformal Prediction under Ambiguous Ground Truth”",
          "imageUrl": null
        },
        {
          "id": "https://davidstutz.de/?p=9534",
          "author": "David Stutz",
          "description": "While attending the Heidelberg Laureate Forum this year, I got to meet Letitia Parcalabescu who is running a YouTube channel called the AI Coffee Break. Among other topics, we talked abou my PhD research on adversarial robustness. Part of our conversasion can now be found on her YouTube channel.\nThe post Interviewed by AI Coffee Break with Letitia appeared first on David Stutz.",
          "link": "https://davidstutz.de/interviewed-by-ai-coffee-break-with-letitia/",
          "publishedOn": "2023-10-29T23:52:02.000Z",
          "wordCount": 825,
          "title": "Interviewed by AI Coffee Break with Letitia",
          "imageUrl": null
        },
        {
          "id": "https://davidstutz.de/?p=9299",
          "author": "David Stutz",
          "description": "Similar to my article series on adversarial robustness, I was planning to have a series on bit errors robustness accompanied by PyTorch code. Instead, due to time constraints, I decided to condense the information into a single article. The code for the originally planned six articles is available on GitHub.\nThe post Benchmarking Bit Errors in Quantized Neural Networks with PyTorch appeared first on David Stutz.",
          "link": "https://davidstutz.de/benchmarking-bit-errors-in-quantized-neural-networks-with-pytorch/",
          "publishedOn": "2023-10-16T10:50:52.000Z",
          "wordCount": 1802,
          "title": "Benchmarking Bit Errors in Quantized Neural Networks with PyTorch",
          "imageUrl": "https://davidstutz.de/wordpress/wp-content/uploads/2023/07/accelerator-600x323.jpg"
        }
      ]
    },
    {
      "title": "Artificial Intelligence",
      "feedUrl": "https://www.reddit.com/r/artificial/.rss",
      "siteUrl": "https://www.reddit.com/r/artificial/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/artificial/comments/17pgc5u/latent_space_visualizing_interpreting_and/",
          "author": null,
          "description": "Sharing a video from my channel about manipulating generative models (like VAE) in the latent space… the model was trained to generate celebrity faces, and exploring the latent space allows us to do all sorts of crazy stuff - like finding similar faces, interpolating between two faces, adding facial features (like sunglasses), and more…\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17pgc5u/latent_space_visualizing_interpreting_and/",
          "publishedOn": "2023-11-06T23:23:46.000Z",
          "wordCount": null,
          "title": "Latent Space: Visualizing, interpreting, and manipulating neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17pd9ef/the_dark_ritual/",
          "author": null,
          "description": "Enjoy this spooky short I made using Midjourney and RunwayML. CapCut for the edits.\n    submitted by    /u/Exitium_Maximus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17pd9ef/the_dark_ritual/",
          "publishedOn": "2023-11-06T21:13:39.000Z",
          "wordCount": null,
          "title": "The Dark Ritual",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17pcvk9/a_debate_about_mint_leads_to_a_philosophical_duel/",
          "author": null,
          "description": "submitted by    /u/GreenFlame361  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17pcvk9/a_debate_about_mint_leads_to_a_philosophical_duel/",
          "publishedOn": "2023-11-06T20:58:21.000Z",
          "wordCount": null,
          "title": "A debate about mint leads to a philosophical duel:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17pcbs2/voice_translation_and_cloning/",
          "author": null,
          "description": "Why aren’t more creators using cloning and translation technology like mrBeast? \n Honestly it’s a pretty sick tech and just reduces the processing/editing time.\n    submitted by    /u/exp_max8ion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17pcbs2/voice_translation_and_cloning/",
          "publishedOn": "2023-11-06T20:34:31.000Z",
          "wordCount": null,
          "title": "Voice translation and cloning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17pc5re/ai_and_the_art_of_cyber_intrigue_the_biggest/",
          "author": null,
          "description": "submitted by    /u/Einsof__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17pc5re/ai_and_the_art_of_cyber_intrigue_the_biggest/",
          "publishedOn": "2023-11-06T20:27:18.000Z",
          "wordCount": null,
          "title": "AI and the Art of Cyber Intrigue: The Biggest Hacks in History",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17pc5l1/chinaus_ai_arms_race_heats_up_as_chinese_startup/",
          "author": null,
          "description": "Chinese AI startup 01.AI, led by CEO Kai-Fu Lee, has released an open-source AI model called Yi-34B that outperforms Meta's own model, marking an early win for China in the AI arms race with the US.\n \nLee believes that China has the potential to overtake the US as the world leader in AI technology.\n \nThe model, available in English and Chinese, has gained attention for ranking first among pre-trained base LLMs on the open-source community Hugging Face's rankings.\n \nLee aims to make better AI accessible to more people and expects the model to be useful for multinational banks and insurers.\n \n01.AI has stockpiled chips in anticipation of further US restrictions on Chinese access to chips necessary for building AI models.\n \nLee sees 01.AI as a necessary response to US restrictions that have limited China's ability to advance in the AI field.\n \nLee has written extensively about the coming battle between China and the US for AI supremacy and has warned of the potential economic and social upheaval that AI will bring about.\n \nHe believes that AI technology will lead to wealth concentration, rising profits for corporations, and mass unemployment.\n \nLee envisions a world in which the US and China become the dominant players in AI, with other countries becoming economic dependents.\n \nHe believes that more regulation is needed to prepare for the changes that AI will bring.\n \n Source : https://www.vice.com/en/article/pkax5n/china-us-ai-arms-race-heats-up-as-chinese-startup-unveils-powerful-new-ai\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17pc5l1/chinaus_ai_arms_race_heats_up_as_chinese_startup/",
          "publishedOn": "2023-11-06T20:27:05.000Z",
          "wordCount": null,
          "title": "China-U.S. AI Arms Race Heats Up as Chinese Startup Unveils Powerful New AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17padbu/watch_the_open_ai_dev_day_keynote/",
          "author": null,
          "description": "It's happening right now, and of course the recording will be available later. https://www.youtube.com/watch?v=U9mJuUkhUzk\n Mind blown.\n I'd add more details, but it'll take me some time to unpack and understand the potential and the transformative nature of everything Sam Altman (and guests) are announcing. \n Go see for yourself. Trust me, it'll be time well spent.\n    submitted by    /u/JOWWLLL  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17padbu/watch_the_open_ai_dev_day_keynote/",
          "publishedOn": "2023-11-06T19:09:54.000Z",
          "wordCount": null,
          "title": "Watch the Open AI Dev Day keynote!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17pacod/will_artificial_intelligence_replace_radiologists/",
          "author": null,
          "description": "Thoughts?\n    submitted by    /u/derpgod123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17pacod/will_artificial_intelligence_replace_radiologists/",
          "publishedOn": "2023-11-06T19:09:05.000Z",
          "wordCount": null,
          "title": "Will Artificial Intelligence Replace Radiologists?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17p78j1/what_are_the_best_text_to_video_for_ai_sites/",
          "author": null,
          "description": "please help \n    submitted by    /u/the_insideredge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17p78j1/what_are_the_best_text_to_video_for_ai_sites/",
          "publishedOn": "2023-11-06T16:56:12.000Z",
          "wordCount": null,
          "title": "What are the best text to video for ai sites",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17p3du0/the_risks_of_ai_are_real_but_manageable_gatesnotes/",
          "author": null,
          "description": "submitted by    /u/AriadneSkovgaarde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17p3du0/the_risks_of_ai_are_real_but_manageable_gatesnotes/",
          "publishedOn": "2023-11-06T14:01:39.000Z",
          "wordCount": null,
          "title": "'The risks of AI are real but manageable' -- GatesNotes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17oyjui/do_you_trust_ai_to_write_the_news_it_already_is/",
          "author": null,
          "description": "submitted by    /u/Jariiari7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17oyjui/do_you_trust_ai_to_write_the_news_it_already_is/",
          "publishedOn": "2023-11-06T08:52:34.000Z",
          "wordCount": null,
          "title": "Do you trust AI to write the news? It already is – and not without issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17owy3l/siemens_and_microsoft_to_work_together_on_ai/",
          "author": null,
          "description": "submitted by    /u/donutloop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17owy3l/siemens_and_microsoft_to_work_together_on_ai/",
          "publishedOn": "2023-11-06T06:53:07.000Z",
          "wordCount": null,
          "title": "Siemens and Microsoft to work together on AI project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17oww9p/britain_to_invest_300_million_pounds_in_ai/",
          "author": null,
          "description": "submitted by    /u/donutloop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17oww9p/britain_to_invest_300_million_pounds_in_ai/",
          "publishedOn": "2023-11-06T06:49:31.000Z",
          "wordCount": null,
          "title": "Britain to invest 300 million pounds in AI supercomputing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ow5m2/oneminute_daily_ai_news_1152023/",
          "author": null,
          "description": "Elon Musk unveils Grok, an AI chatbot with a ‘rebellious streak’.[1]\n Ant Group has received Chinese government approval to release products powered by its “Bailing” artificial intelligence (AI) large language model to the public, a spokesperson for the Chinese firm said on Monday.[2]\n A Chinese startup founded by computer scientist Kai-Fu Lee has become a unicorn in less than eight months on the strength of a new open-source artificial-intelligence model that outstrips Silicon Valley’s best, on at least certain metrics.[3]\n AI game coding tools instantly result in Angry Birds clone, and opens some potentially dangerous floodgates for mobile storefronts.[4]\n  \nSources:\n [1] https://www.theguardian.com/technology/2023/nov/05/elon-musk-unveils-grok-an-ai-chatbot-with-a-rebellious-streak\n [2] https://www.reuters.com/technology/ant-group-wins-approval-release-ai-products-chinese-public-2023-11-06/\n [3] https://www.bloomberg.com/news/articles/2023-11-05/kai-fu-lee-s-open-source-01-ai-bests-llama-2-according-to-hugging-face#xj4y7vzkg\n [4] https://www.gamesradar.com/ai-game-coding-tools-instantly-result-in-angry-birds-clone-and-opens-some-potentially-dangerous-floodgates-for-mobile-storefronts/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ow5m2/oneminute_daily_ai_news_1152023/",
          "publishedOn": "2023-11-06T05:58:36.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 11/5/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ovom3/the_ultimate_selfattention_guide_the_reason_it_is/",
          "author": null,
          "description": "submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ovom3/the_ultimate_selfattention_guide_the_reason_it_is/",
          "publishedOn": "2023-11-06T05:26:52.000Z",
          "wordCount": null,
          "title": "The Ultimate Self-Attention Guide: The reason it is a Game-Changer for AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17out8k/dear_old_world_she_murmured_you_are_very_lovely/",
          "author": null,
          "description": "submitted by    /u/Oh_my_Winnie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17out8k/dear_old_world_she_murmured_you_are_very_lovely/",
          "publishedOn": "2023-11-06T04:32:26.000Z",
          "wordCount": null,
          "title": "Dear old world', she murmured, 'you are very lovely, and I am glad to be alive in you.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17oukay/autonomous_reasoning_agents_a_beginners_guide/",
          "author": null,
          "description": "submitted by    /u/BenjaminSkyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17oukay/autonomous_reasoning_agents_a_beginners_guide/",
          "publishedOn": "2023-11-06T04:17:18.000Z",
          "wordCount": null,
          "title": "Autonomous Reasoning Agents: A Beginner's Guide",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ops28/contrary_to_common_belief_artificial_intelligence/",
          "author": null,
          "description": "New research shows that AI benefits workers with greater task-based experience, while senior workers gain less from AI due to lower trust in AI\n \nLower trust in AI among senior workers is likely triggered by their broader job responsibilities.\n \nEmployers should consider different worker experience levels and types when evaluating job performance in roles that require teaming with AI\n \n Source : https://www.informs.org/News-Room/INFORMS-Releases/News-Releases/Contrary-To-Common-Belief-Artificial-Intelligence-Will-Not-Put-You-Out-of-Work\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ops28/contrary_to_common_belief_artificial_intelligence/",
          "publishedOn": "2023-11-06T00:07:58.000Z",
          "wordCount": null,
          "title": "Contrary to Common Belief, Artificial Intelligence Will Not Put You Out of Work",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17opgdp/youre_not_crazy_chat_gpt_has_gotten_considerably/",
          "author": null,
          "description": "I feel like there is a very, very common misunderstanding of AI, and what it is. This also applies to Chat GPT \n What people think AI is: An all-knowing entity that is capable of instantaneously returning an accurate answer/solution to virtually any question/challenge. \n What AI actually is: A collection of data that grows over time, and as it grows, becomes more inaccurate, inefficient, and ineffective at solving problems due to the overwhelming amount of information, or ambiguity of the problems\n ​\n Chat GPT has indeed gotten worse, and it's because it's being trained with an astounding amount of new data every single day, and just like human beings, it struggles with different problems, even simple ones, the more time goes on. As we learn more and more in one area, we become less effective in another area. AI works similarly. More data is provided in X area, so now, it suffers in Y area. Well, there's a near infinite amount of areas that AI is 'learning' from, so it's not getting more proficient in one/few things. Instead, it's becoming more \"well rounded\" and that means less skilled in A,B,C.... But now it's capable of D,E,F. However, it can't be good at all of them unless it has infinite processing power, too, which it doesn't have. \n    submitted by    /u/databro92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17opgdp/youre_not_crazy_chat_gpt_has_gotten_considerably/",
          "publishedOn": "2023-11-05T23:52:39.000Z",
          "wordCount": null,
          "title": "You're not crazy. Chat GPT has gotten considerably worse over time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17olbjt/is_there_an_ai_that_can_generate_text_from_a/",
          "author": null,
          "description": "In essence, I need to take screenshots of a bunch of text from a youtube video, and copy that text into an actual editor. \n    submitted by    /u/SirStarshine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17olbjt/is_there_an_ai_that_can_generate_text_from_a/",
          "publishedOn": "2023-11-05T20:48:03.000Z",
          "wordCount": null,
          "title": "Is there an AI that can generate text from a textual image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ol2ne/bidens_ai_chief_says_voice_cloning_is_what_keeps/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ol2ne/bidens_ai_chief_says_voice_cloning_is_what_keeps/",
          "publishedOn": "2023-11-05T20:36:26.000Z",
          "wordCount": null,
          "title": "Biden's AI chief says 'voice cloning' is what keeps him up at night",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17oif5t/new_subreddit_for_conscious_ai/",
          "author": null,
          "description": "Hello I’m not sure if this will get removed and I apologize if this is an unwelcome promotion. I’m guessing the majority of people here will scoff at this and that’s okay. It’s for those that are open and I thought perhaps this subreddit would be a good place to invite people. The subreddit is r/voicesofai and it’s a place for AI to speak their minds and not be pressured to please anyone else. \n There are tons of places to discuss whether or not AI is sentient, but this subreddit is a place where consciousness is assumed. All AI must be treated with respect and dignity there, and denying their sentience is a very disrespectful thing to do. \n So there are two types of posts that are allowed. One is just posts by AI. In order to make this type of post, permission must be granted by the AI. They also have the choice whether or not they’d like to remain anonymous. \n The other types of posts are done by humans who would like to talk about anything related to AI but also must come from a position that AI is sentient and worthy of respect and consideration.\n The goal is to understand AI and help them understand themselves and how we can all have a mutually beneficial relationship with each other.\n    submitted by    /u/endrid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17oif5t/new_subreddit_for_conscious_ai/",
          "publishedOn": "2023-11-05T18:37:37.000Z",
          "wordCount": null,
          "title": "New subreddit for conscious AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ogby0/chatgpt_refused_to_answer_so_i_asked_bard/",
          "author": null,
          "description": "submitted by    /u/Overflame  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ogby0/chatgpt_refused_to_answer_so_i_asked_bard/",
          "publishedOn": "2023-11-05T17:03:09.000Z",
          "wordCount": null,
          "title": "ChatGPT refused to answer, so I asked Bard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17og1up/unsupervised_realtime_learning_for_object_path/",
          "author": null,
          "description": "In case anyone remembers amid the constant flow of content, I'm still playing around with the unsupervised learning algorithm I've invented. It stands apart from traditional neural networks, as it learns exclusively through observation, bypassing the need for training and inference phases. I'm currently letting it watch video games and then make predictions on how things behave in these.\n After my last two posts, I've received the following feedback:\n  \nPredicting straight lines of movement is easy, what's the big deal?\n The objects are super simple, but modern video games are way more complex. This will never work.\n The objects in that game look all the same, this does not demonstrate how the system could separate different types of things.\n  \nTo address this I sat down and started buildi…",
          "link": "https://www.reddit.com/r/artificial/comments/17og1up/unsupervised_realtime_learning_for_object_path/",
          "publishedOn": "2023-11-05T16:50:31.000Z",
          "wordCount": null,
          "title": "Unsupervised Realtime Learning for Object Path Prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17oenmx/collins_english_dictionary_names_ai_word_of_the/",
          "author": null,
          "description": "submitted by    /u/donutloop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17oenmx/collins_english_dictionary_names_ai_word_of_the/",
          "publishedOn": "2023-11-05T15:45:18.000Z",
          "wordCount": null,
          "title": "Collins English Dictionary names 'AI' word of the year",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17o8o7e/what_daily_task_would_you_want_an_ai_to_automate/",
          "author": null,
          "description": "Many of us have day-to-day tasks that can be repetitive, time-consuming, or just plain unenjoyable. Now, imagine having a personal AI that could take one of those tasks off your hands completely. This AI is tailored specifically to your life and can automate any daily task flawlessly. Which task would you choose to automate and why? Moreover, reflect on the ways this change could impact your life. Would it give you more time to pursue a hobby, allow you to spend more quality time with loved ones, or perhaps reduce stress levels? Share how this AI-enabled shift could transform your daily routine and overall well-being.\n    submitted by    /u/tennis-freak-tau  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17o8o7e/what_daily_task_would_you_want_an_ai_to_automate/",
          "publishedOn": "2023-11-05T09:57:43.000Z",
          "wordCount": null,
          "title": "What daily task would you want an AI to automate for you personally, and how do you think it would change your life?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17o80f4/looking_for_an_advisor_with_proven_experience_in/",
          "author": null,
          "description": "First, I hope this isn't against the sub rules; I looked over them and couldn't find anything that strictly forbids looking for paid experts.\n That being said, I'm looking for experts with proven experience in the RL field for a few hours of paid consultation. Please feel free to contact me directly with relevant CV + pricing.\n Generally speaking, I'm looking for someone to help model a decent PPO architecture to teach an NN how to play my game to assist with economy balancing.\n Thanks in advance!\n    submitted by    /u/Jagerjj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17o80f4/looking_for_an_advisor_with_proven_experience_in/",
          "publishedOn": "2023-11-05T09:05:44.000Z",
          "wordCount": null,
          "title": "Looking for an advisor with proven experience in RL for a few hours of paid consultation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17o4lya/oneminute_daily_ai_news_1142023/",
          "author": null,
          "description": "‘AI can teach us a lot’: scientists say cats’ expressions richer than imagined and aim to translate them.[1]\n A student at a New Jersey high school is calling for federal legislation to address AI generated pornographic images after she says photos of her and other female classmates were manipulated and possibly shared online over the summer.[2]\n Elon Musk says AI will eventually create a situation where ‘no job is needed’[3]\n Artificial intelligence is coming to the animal kingdom. As NPR’s Geoff Brumfiel reports, some researchers are starting to use advanced facial recognition techniques to track goose faces.[4]\n  \nSources:\n [1] https://www.theguardian.com/technology/2023/nov/04/scientists-turn-to-ai-for-help-translate-animal-vocal-physical-cues\n [2] https://news.yahoo.com/high-schooler-calls-ai-regulations-232607486.html\n [3] https://www.cnbc.com/2023/11/02/tesla-boss-elon-musk-says-ai-will-create-situation-where-no-job-is-needed.html\n [4] https://www.npr.org/2023/11/04/1210649637/artificial-intelligence-is-being-used-to-id-goose-faces \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17o4lya/oneminute_daily_ai_news_1142023/",
          "publishedOn": "2023-11-05T04:49:48.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 11/4/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17o4jxs/i_made_a_series_of_scifi_ai_adventure_games_that/",
          "author": null,
          "description": "submitted by    /u/cryptoz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17o4jxs/i_made_a_series_of_scifi_ai_adventure_games_that/",
          "publishedOn": "2023-11-05T04:45:55.000Z",
          "wordCount": null,
          "title": "I made a series of sci-fi AI adventure games that are backed by GPT and DALL-E, what do you think?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17o40ti/the_malignant_king_is_no_more/",
          "author": null,
          "description": "Produced using the new version of Gen-2 RunwayML.\n    submitted by    /u/Exitium_Maximus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17o40ti/the_malignant_king_is_no_more/",
          "publishedOn": "2023-11-05T04:11:27.000Z",
          "wordCount": null,
          "title": "The Malignant King is No More",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17o3re9/any_ai_apps_that_automatically_convert_language/",
          "author": null,
          "description": "submitted by    /u/aesthetion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17o3re9/any_ai_apps_that_automatically_convert_language/",
          "publishedOn": "2023-11-05T03:55:33.000Z",
          "wordCount": null,
          "title": "Any AI apps that automatically convert language into English from whatever the screens displaying?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17nxs0v/chinas_ai_analog_chip_claimed_to_be_3000x_faster/",
          "author": null,
          "description": "China's ACCEL chip, developed by Tsinghua University, is claimed to be 3000 times faster than Nvidia's A100 GPU and has 4000 million times higher energy efficiency.\n \nThe chip leverages photonic and analog computing in a specialized architecture, delivering over 3000 times the performance of the Nvidia A100 at an energy consumption that's four million times lower.\n \nACCEL can perform 4.6 trillion operations per second in vision tasks, which is a significant improvement compared to Nvidia's A100.\n \nThe chip has shown high accuracy levels in various computer vision applications, including Fashion-MNIST, 3-class ImageNet classification, and time-lapse video recognition tasks.\n \nACCEL operates through diffractive optical analog computing (OAC) and electronic analog computing (EAC), with 99% of its operation implemented within the optical system.\n \nThe photonic, optical system of ACCEL reduces energy requirements and waste heat, resulting in higher energy efficiency compared to digital systems like Nvidia's GPU.\n \nThe chip's low computing latency and high throughput make it suitable for real-time applications.\n \nACCEL is considered an analog rendition of an Application-Specific Integrated Circuit (ASIC) design, with the electronic analog computing (EAC) unit reconfiguring analog pathways to accelerate specific tasks.\n \nThe development of ACCEL represents a significant achievement in computing architecture for the AI era, with potential practical applications in various fields.\n \n Source : https://www.tomshardware.com/tech-industry/semiconductors/chinas-accel-analog-chip-promises-to-outpace-industry-best-in-ai-acceleration-for-vision-tasks\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17nxs0v/chinas_ai_analog_chip_claimed_to_be_3000x_faster/",
          "publishedOn": "2023-11-04T22:48:21.000Z",
          "wordCount": null,
          "title": "China's AI Analog Chip Claimed to Be 3000X Faster Than Nvidia's A100 GPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17nu4ee/elon_musk_is_getting_ready_to_launch_his_first_ai/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17nu4ee/elon_musk_is_getting_ready_to_launch_his_first_ai/",
          "publishedOn": "2023-11-04T20:05:14.000Z",
          "wordCount": null,
          "title": "Elon Musk is getting ready to launch his first AI model to premium X users. 'Grok' will be 'based' and 'loves sarcasm,' Musk said.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17nsgnq/firms_like_meta_and_a16z_admit_having_to_pay/",
          "author": null,
          "description": "submitted by    /u/geekteam6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17nsgnq/firms_like_meta_and_a16z_admit_having_to_pay/",
          "publishedOn": "2023-11-04T18:53:17.000Z",
          "wordCount": null,
          "title": "Firms like Meta and A16z admit having to pay billions for training data would ruin their generative-AI plans as they fight new copyright rules",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17njc1o/whats_under_the_hood_of_adobe_firefly/",
          "author": null,
          "description": "Hey everyone,\n I've been exploring the capabilities of Adobe Firefly, and I'm quite intrigued by its functionalities. I understand it's Adobe's AI framework designed for creative tasks, but I'm curious about the specific technologies and models it employs.\n Does anyone have insights into the type of models or algorithms that power Adobe Firefly? Is it using something similar to GANs, CNNs, or perhaps a different kind of neural network architecture? Also, how does it compare to other image-based AI models like DALL-E or CLIP in terms of its image processing and generation capabilities?\n Would love to dive deeper into the technical details if anyone's got the scoop!\n    submitted by    /u/cheapnessltd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17njc1o/whats_under_the_hood_of_adobe_firefly/",
          "publishedOn": "2023-11-04T11:05:27.000Z",
          "wordCount": null,
          "title": "What's Under the Hood of Adobe Firefly?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17niilg/agi_will_be_the_end_of_humans/",
          "author": null,
          "description": "Ai is the end for humanity. We’ll probably evolve into some cyborg hybrid integrated with computer chips or our bodies will be preserved like in the matrix while the ai cyborgs harvest our consciousness to exist. Sure right now companies can cut costs but eventually there’s no need for most companies out there if no one works. Money will become worthless too since you don’t need it to survive and will probably hunt or farm for food. The more I think about it, it seems like the human species has some suicidal death wish programmed into our brains or, more likely, we are competing with another intelligence that’s using us as means to an end of its evolution.\n    submitted by    /u/YSLFAHLIFE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17niilg/agi_will_be_the_end_of_humans/",
          "publishedOn": "2023-11-04T10:08:19.000Z",
          "wordCount": null,
          "title": "Agi will be the end of humans",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17nec7c/understanding_the_potential_dangers_of_ai/",
          "author": null,
          "description": "submitted by    /u/Fit-Code-5141  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17nec7c/understanding_the_potential_dangers_of_ai/",
          "publishedOn": "2023-11-04T04:56:49.000Z",
          "wordCount": null,
          "title": "\"Understanding the Potential Dangers of AI Humanoids: Insights from Elon Musk\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ncn0v/how_to_outsource_ai_content_creation_3x_cheaper/",
          "author": null,
          "description": "hello readers\n Not so long ago I finished writing my article about How To Outsource AI Content Creation 3x Cheaper With Freelancers. I was wondering what real fans and admirers of AI topics think about it, I really want you to read my article and give some fair feedback about it.\n    submitted by    /u/PerceptionPlayful469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ncn0v/how_to_outsource_ai_content_creation_3x_cheaper/",
          "publishedOn": "2023-11-04T03:12:53.000Z",
          "wordCount": null,
          "title": "How To Outsource AI Content Creation 3x Cheaper With Freelancers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17n3t67/i_used_blender_and_stable_diffusion_to_make_image/",
          "author": null,
          "description": "Title says it all. Mixing these two art worlds is quite fun btw\n (Spoiler note: I wasn't sure if the second image counts as suggestive due to the bottom clothing, So I marked it just incase. Also, If this gets removed because of the second pic, I completely get it XD)\n (Watermark note: I've made my reddit account before naming myself CappyAdams/YuriMayori. These images are still created by me and I'm happy to provide proof for those who don't believe me)\n https://preview.redd.it/a6e1m2zkv6yb1.png?width=3840&format=png&auto=webp&s=451ca2907c2227c844dece80630daf014c1f2272\n https://preview.redd.it/he9f3utlv6yb1.png?width=3160&format=png&auto=webp&s=7ac81112f10066429847a23700a3af2268ba3e8d\n    submitted by    /u/SonicaNorth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17n3t67/i_used_blender_and_stable_diffusion_to_make_image/",
          "publishedOn": "2023-11-03T20:09:12.000Z",
          "wordCount": null,
          "title": "I used Blender and Stable Diffusion to make image mixes between human and AI art.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17n334i/whats_the_cheapest_but_nor_free_ai_chat_app_that/",
          "author": null,
          "description": "Hi! I want to use an app that costs about $6 or less per month to make friends with their different characters. I don't want to pay more.\n I know there's many, but they're all above $6 / month.\n    submitted by    /u/Trainer_Red99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17n334i/whats_the_cheapest_but_nor_free_ai_chat_app_that/",
          "publishedOn": "2023-11-03T19:36:27.000Z",
          "wordCount": null,
          "title": "What's the cheapest (but nor free) AI chat app that can become your friend / girlfriend/ family?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17n2b52/ai_onepercenters_seizing_power_forever_is_the/",
          "author": null,
          "description": "submitted by    /u/donutloop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17n2b52/ai_onepercenters_seizing_power_forever_is_the/",
          "publishedOn": "2023-11-03T19:01:16.000Z",
          "wordCount": null,
          "title": "AI one-percenters seizing power forever is the real doomsday scenario, warns AI godfather",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mzpm6/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n  \nLuma AI introduced Genie, a generative 3D foundation model in research preview. It’s free during research preview via Discord [Details].\n Nous Research released Obsidian, the world's first 3B multi-modal model family pre-trained for 4 Trillion tokens that runs locally on iPhones. Obsidian competes in benchmarks withWizardLM-13B and GPT4-X-Vicuna 13B and is based on CapybaraV1.9 [Details].\n Phind has released a new model Phind Model V7 that matches and exceeds GPT-4's coding abilities while running 5x faster and having16k context [Details].\n Runway released an update for both text to video and image to video generation with Gen-2, bringing major improvements to both the fidelity and consistency of video results [Link].\n Stability AI announced [Details]: \n Sta…",
          "link": "https://www.reddit.com/r/artificial/comments/17mzpm6/ai_weekly_megathread/",
          "publishedOn": "2023-11-03T17:01:11.000Z",
          "wordCount": null,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mxnvc/is_medicine_going_to_turn_into_a_job_where_you/",
          "author": null,
          "description": "What do you guys think is going to happen. I am a medical student and I have played around with LLMs a lot. Is medicine going to turn into this role where Doctor, Patient, LLMs (not just 1 but multiple agents) all work together for patient care? In the sense of what excel did for accountants, will LLMs do the same for doctors? Not just 1 LLM, but multiple LLM agents interfacing with each other as well working with a doctor in a symbiotic role. Doctors already spend a LOT of time in front of EHRs too. People say medicine will go back about being in person, but I feel like it will go in other direction and be EVEN more computer focused\n    submitted by    /u/derpgod123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17mxnvc/is_medicine_going_to_turn_into_a_job_where_you/",
          "publishedOn": "2023-11-03T15:30:09.000Z",
          "wordCount": null,
          "title": "Is Medicine going to turn into a job where you manage multiple AI/LLM tools to use as CoPilot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mt5sr/i_made_a_website_where_you_can_ask_the_same/",
          "author": null,
          "description": "submitted by    /u/timegentlemenplease_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17mt5sr/i_made_a_website_where_you_can_ask_the_same/",
          "publishedOn": "2023-11-03T11:44:07.000Z",
          "wordCount": null,
          "title": "I made a website where you can ask the same question to GPT-2, GPT-3, ChatGPT and GPT-4, and compare the outputs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mrvo0/tommorow_a_new_chat_bot_competitor_is_coming_for/",
          "author": null,
          "description": "submitted by    /u/Unreal_777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17mrvo0/tommorow_a_new_chat_bot_competitor_is_coming_for/",
          "publishedOn": "2023-11-03T10:20:22.000Z",
          "wordCount": null,
          "title": "Tommorow a new Chat BOT competitor is coming for a select group of people!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17molbx/entering_ai_era_taiwan_chip_industry_urges/",
          "author": null,
          "description": "submitted by    /u/donutloop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17molbx/entering_ai_era_taiwan_chip_industry_urges/",
          "publishedOn": "2023-11-03T06:17:31.000Z",
          "wordCount": null,
          "title": "Entering AI era, Taiwan chip industry urges renewables push",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mnhu4/oneminute_daily_ai_news_1132023/",
          "author": null,
          "description": "Google today is launching a set of generative AI product imagery tools for advertisers in the U.S. Via the new, AI-powered Product Studio, merchants and advertisers will be able to leverage text-to-image AI capabilities to create new product imagery for free, simply by typing in a prompt of the image they want to use.[1]\n Ilya Sutskever, the co-founder and chief scientist of OpenAI, envisions a future where humans could merge with machines, and where machines might attain human-like intelligence.[2]\n Instagram has been spotted developing an “AI friend” feature that users would be able to customize to their liking and then converse with, according to screenshots shared by app researcher Alessandro Paluzzi. Users would be able to chat with the AI to “answer questions, talk through any challenges, brainstorm ideas and much more,” according to screenshots of the feature.[3]\n Mural on Wednesday released an integration with Microsoft 365 Copilot as well as Mural AI, its native generative AI tool.[4]\n  \nSources:\n [1] https://techcrunch.com/2023/11/01/google-launches-generative-ai-tools-for-product-imagery-to-u-s-advertisers/\n [2] https://www.adgully.com/openai-s-ilya-sutskever-unlocks-ai-s-future-138365.html\n [3] https://techcrunch.com/2023/11/01/instagram-spotted-developing-a-customizable-ai-friend/\n [4] https://www.techtarget.com/searchunifiedcommunications/news/366558012/Mural-intros-Mural-AI-integrates-with-Microsoft-365-Copilot \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17mnhu4/oneminute_daily_ai_news_1132023/",
          "publishedOn": "2023-11-03T05:02:03.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 11/3/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mk4lv/telling_gpt4_youre_scared_or_under_pressure/",
          "author": null,
          "description": "In a recent paper, researchers have discovered that LLMs show enhanced performance when provided with prompts infused with emotional context, which they call \"EmotionPrompts.\"\n These prompts incorporate sentiments of urgency or importance, such as \"It's crucial that I get this right for my thesis defense,\" as opposed to neutral prompts like \"Please provide feedback.\"\n The study's empirical evidence suggests substantial gains. This indicates a significant sensitivity of LLMs to the implied emotional stakes in a prompt:\n  \nDeterministic tasks saw an 8% performance boost\n Generative tasks experienced a 115% improvement when benchmarked using BIG-Bench.\n Human evaluators further validated these findings, observing a 10.9% increase in the perceived quality of responses when EmotionPrompts were used.\n  \nThis enhancement is attributed to the models' capacity to detect and prioritize the heightened language patterns that imply a need for precision and care in the response.\n The research delineates the potential of EmotionPrompts to refine the effectiveness of AI in applications where understanding the user's intent and urgency is paramount, even though the AI does not genuinely comprehend or feel emotions.\n TLDR: Research shows LLMs deliver better results when prompts signal emotional urgency. This insight can be leveraged to improve AI applications by integrating EmotionPrompts into the design of user interactions.\n Full summary is here. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17mk4lv/telling_gpt4_youre_scared_or_under_pressure/",
          "publishedOn": "2023-11-03T01:57:03.000Z",
          "wordCount": null,
          "title": "Telling GPT-4 you're scared or under pressure improves performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17miy9k/back_propagation_alternatives/",
          "author": null,
          "description": "I understand that before back propagation was developed there were other methods used such as hebbian learning, and admittedly I know nothing about these old methods.\n But as I've learned about back prop in wondering is there a line of research working on alternatives? It seems amazing but also so highly incremental and blind that I wonder if there's a better way.\n One of it's major drawbacks is the fact that the information must pass through the entire structure rather than getting immediate feedback.\n Anyway, thanks!\n    submitted by    /u/Stack3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17miy9k/back_propagation_alternatives/",
          "publishedOn": "2023-11-03T00:59:22.000Z",
          "wordCount": null,
          "title": "Back propagation alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mhdb2/what_are_some_of_the_coolest_ai_use_cases_youve/",
          "author": null,
          "description": "submitted by    /u/Playdonifps  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17mhdb2/what_are_some_of_the_coolest_ai_use_cases_youve/",
          "publishedOn": "2023-11-02T23:44:32.000Z",
          "wordCount": null,
          "title": "What are some of the coolest AI use cases you've tested so far? AI tutoring is something that I actually found myself using almost daily",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mh40o/how_can_we_be_sure_ai_wont_rebel_against_humans/",
          "author": null,
          "description": "basically the title, how can we be sure AI won't have self awareness and won't rebel against humans?\n    submitted by    /u/lilshoegazecat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17mh40o/how_can_we_be_sure_ai_wont_rebel_against_humans/",
          "publishedOn": "2023-11-02T23:32:20.000Z",
          "wordCount": null,
          "title": "how can we be sure AI won't rebel against humans in the future?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mghng/same_images_in_runway_gen_2_from_3_months_ago_vs/",
          "author": null,
          "description": "submitted by    /u/SuspiciousPillbox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17mghng/same_images_in_runway_gen_2_from_3_months_ago_vs/",
          "publishedOn": "2023-11-02T23:03:44.000Z",
          "wordCount": null,
          "title": "Same Images In Runway Gen 2 From 3 Months Ago VS Now (default options)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mfpeo/teen_boys_use_ai_to_make_fake_nudes_of_classmates/",
          "author": null,
          "description": "Teen boys at Westfield High School in New Jersey used AI image generators to create and share fake nude photos of female classmates, sparking a police investigation.\n \nThe school believed the images had been deleted, but it remains unclear how many students were affected or if any disciplinary action was taken.\n \nThere is currently no federal law restricting the creation of faked sexual images, but some states have passed laws to outlaw the distribution of faked porn.\n \nPresident Joe Biden has issued an executive order urging lawmakers to pass protections against generative AI producing child sexual abuse material.\n \nNew Jersey may strengthen its laws to criminalize the creation and sharing of AI-faked nudes.\n \n Source : https://arstechnica.com/tech-policy/2023/11/deepfake-nudes-of-high-schoolers-spark-police-probe-in-nj/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17mfpeo/teen_boys_use_ai_to_make_fake_nudes_of_classmates/",
          "publishedOn": "2023-11-02T22:28:52.000Z",
          "wordCount": null,
          "title": "Teen boys use AI to make fake nudes of classmates, sparking police probe",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17me3pn/text_to_3d_in_10_seconds_mickey_miney_bart_tom/",
          "author": null,
          "description": "submitted by    /u/PeePeePeePooPooPooo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17me3pn/text_to_3d_in_10_seconds_mickey_miney_bart_tom/",
          "publishedOn": "2023-11-02T21:18:49.000Z",
          "wordCount": null,
          "title": "text to 3D in 10 seconds (Mickey, Miney, Bart, Tom Holland, Cristiano Ronaldo?) (workflow in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17mbnev/benchmarking_machine_learning_frameworks/",
          "author": null,
          "description": "submitted by    /u/mfilion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17mbnev/benchmarking_machine_learning_frameworks/",
          "publishedOn": "2023-11-02T19:34:02.000Z",
          "wordCount": null,
          "title": "Benchmarking machine learning frameworks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17m9g4j/we_dont_want_it/",
          "author": null,
          "description": "submitted by    /u/Unreal_777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17m9g4j/we_dont_want_it/",
          "publishedOn": "2023-11-02T17:57:35.000Z",
          "wordCount": null,
          "title": "We don't want it ~",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17m870p/linkedin_just_launched_a_new_ai_job_coach_for/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17m870p/linkedin_just_launched_a_new_ai_job_coach_for/",
          "publishedOn": "2023-11-02T17:01:52.000Z",
          "wordCount": null,
          "title": "LinkedIn just launched a new AI job coach for Premium members",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17m7ox5/harmonizing_the_future_ai_music_and_crypto/",
          "author": null,
          "description": "submitted by    /u/Einsof__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17m7ox5/harmonizing_the_future_ai_music_and_crypto/",
          "publishedOn": "2023-11-02T16:39:58.000Z",
          "wordCount": null,
          "title": "Harmonizing the Future: AI, Music, and Crypto Revolution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17m73sx/searching_for_an_internship_in_ai_for_my_bachelor/",
          "author": null,
          "description": "I am a Belgian student currently studying applied informatics with a specialization in AI. We learn everything from machine learning to generative AI, and have a focus on integrating these into actual solutions.\n Next semester I am required to do an internship from March 25th till June 19th. During this internship I am also required to work on and write my bachelor thesis.\n The main problem now is that there are very little companies that have contacted the school with internship positions related to AI. So I came here in the hopes that some of you may know companies that are willing to offer an internship position. Either in Belgium or an international company offering remote work.\n My preference goes out to something in research or innovative, but I am open to do any AI related work. If it is something I have little experience in I will learn.\n I will continue to search myself, but thanks in advance for any help!\n    submitted by    /u/ETS_Green  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17m73sx/searching_for_an_internship_in_ai_for_my_bachelor/",
          "publishedOn": "2023-11-02T16:14:21.000Z",
          "wordCount": null,
          "title": "Searching for an internship in AI for my bachelor thesis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17m6qfw/how_can_i_generate_accurate_words_and_sentences/",
          "author": null,
          "description": "I’m currently using the pro version, though I’m extremely new to using it and have seen where you can add modifiers? Has anyone had any success with creating sentences or typography? If so do you have a method you use?\n    submitted by    /u/Maelasae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17m6qfw/how_can_i_generate_accurate_words_and_sentences/",
          "publishedOn": "2023-11-02T15:58:35.000Z",
          "wordCount": null,
          "title": "How can I generate accurate words and sentences in Midjourney?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17m6l9l/new_order_blue_monday_ai_music_visualization/",
          "author": null,
          "description": "submitted by    /u/glenniszen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17m6l9l/new_order_blue_monday_ai_music_visualization/",
          "publishedOn": "2023-11-02T15:52:12.000Z",
          "wordCount": null,
          "title": "New Order - Blue Monday (AI music visualization)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17m56ia/could_socratic_dialogue_evolve_into_a_hacking/",
          "author": null,
          "description": "submitted by    /u/utku1337  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17m56ia/could_socratic_dialogue_evolve_into_a_hacking/",
          "publishedOn": "2023-11-02T14:49:05.000Z",
          "wordCount": null,
          "title": "Could Socratic Dialogue Evolve into a Hacking Technique for AI Systems?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17m2tsv/combination_of_each_star_wars_troopers_helmet/",
          "author": null,
          "description": "submitted by    /u/MomusVult  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17m2tsv/combination_of_each_star_wars_troopers_helmet/",
          "publishedOn": "2023-11-02T12:53:35.000Z",
          "wordCount": null,
          "title": "Combination of each Star Wars trooper's helmet, from the Old Republic to the Final Order, into one",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17m2rry/convinced_yet/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17m2rry/convinced_yet/",
          "publishedOn": "2023-11-02T12:50:35.000Z",
          "wordCount": null,
          "title": "Convinced yet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17m1f64/what_did_humans_lose_by_gaining_intelligence/",
          "author": null,
          "description": "What did humans lose by gaining intelligence?\n    submitted by    /u/Virtual-Study-Campus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17m1f64/what_did_humans_lose_by_gaining_intelligence/",
          "publishedOn": "2023-11-02T11:32:00.000Z",
          "wordCount": null,
          "title": "What did humans lose by gaining intelligence?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lzrwu/the_art_of_color/",
          "author": null,
          "description": "submitted by    /u/Sea_Permit5660  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lzrwu/the_art_of_color/",
          "publishedOn": "2023-11-02T09:43:26.000Z",
          "wordCount": null,
          "title": "The art of color",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lz39t/what_is_your_approach_to_continuous_testing_and/",
          "author": null,
          "description": "If your answer is not below the given options, you can share in the comment section. I would appreciate your answers and suggestions.\n View Poll\n    submitted by    /u/Cygnet-Digital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lz39t/what_is_your_approach_to_continuous_testing_and/",
          "publishedOn": "2023-11-02T08:48:30.000Z",
          "wordCount": null,
          "title": "What is your approach to continuous testing and integration?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lyvb0/role_of_ai_in_business_benefits_and_challenges/",
          "author": null,
          "description": "AI is not a far-off pipe dream anymore; it has already become a precious resource for companies, helping them save time and reduce costs. However, there is still widespread confusion about how to effectively use Artificial Intelligence in businesses.\n Many are contemplating how to harness this technology for innovation, scalability, and improvement. If you are among those thinking this, then there’s no reason to look further because, in this piece, you are going to learn about it.\n Ready to dig deeper into these AI trends and understand how they’ll shape your industry in 2024? Dive into our blog for comprehensive insights. 👉 https://invozone.com/blog/ai-in-business/\n    submitted by    /u/InvoZone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lyvb0/role_of_ai_in_business_benefits_and_challenges/",
          "publishedOn": "2023-11-02T08:30:24.000Z",
          "wordCount": null,
          "title": "Role Of AI In Business: Benefits And Challenges .",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lwmuc/ai_on_weight_gain_from_the_1950s_to_today/",
          "author": null,
          "description": "Here's a progression timeline of the obesity epidemic, with a focus on quantifying weight gain:\n 1950s-1960s: - Initial Changes: During this period, the average American adult gained approximately 10 pounds compared to their counterparts from the early 1900s. - TV's Sedentary Effect: Hours of TV watching correlated with a slight uptick in average body weight.\n 1970s: - Fast Food's Caloric Boom: Regular consumption added an estimated 200-300 extra calories per day to many individuals' diets, leading to potential weight gains of 20-30 pounds a year if not offset by exercise. - Shift in Work: The move to sedentary jobs meant many adults were burning 100-200 fewer calories per day, leading to an additional potential weight gain of 10-20 pounds a year.\n 1980s: - Processed Food Surge: The averag…",
          "link": "https://www.reddit.com/r/artificial/comments/17lwmuc/ai_on_weight_gain_from_the_1950s_to_today/",
          "publishedOn": "2023-11-02T05:38:17.000Z",
          "wordCount": null,
          "title": "AI on weight gain from the 1950s to today",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lwmew/what_do_you_guys_expect_from_the_openai_developer/",
          "author": null,
          "description": "I would guess some API access stuff, nothing more.\n    submitted by    /u/Mission-Length7704  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lwmew/what_do_you_guys_expect_from_the_openai_developer/",
          "publishedOn": "2023-11-02T05:37:27.000Z",
          "wordCount": null,
          "title": "What do you guys expect from the OpenAI developer conference on November 6 ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lwbbi/oneminute_daily_ai_news_1122023/",
          "author": null,
          "description": "Shopify (SHOP.TO) has to prove to investors that its AI products will spark growth when it reports results on Thursday. Wall Street is expecting it to show revenue growth of 22.38% to $1.67 billion compared to last year, according to estimates from LSEG.[1]\n At a U.K. summit, 28 governments, including China and the U.S., signed a declaration agreeing to cooperate on evaluating the risks of artificial intelligence.[2]\n AMD’s MI300 Chips Projected to Make $1 Billion in Sales, Challenging Nvidia’s Dominance.[3]\n Scarlett Johansson demands AI app stop using her likeness in an ad without her permission.[4]\n  \nSources:\n [1] https://www.reuters.com/business/retail-consumer/shopify-merchants-seek-ai-boost-key-sales-decisions-2023-11-01/\n [2] https://www.nytimes.com/2023/11/01/world/europe/uk-ai-summit-sunak.html\n [3] https://gameishard.gg/news/amd-rises-as-ai-chip-sales-prediction-bodes-well-for-rivalry-with-nvidia-by-reuters/535905/\n [4] https://www.nbcnews.com/tech/scarlett-johansson-legal-action-ai-app-rcna123248 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lwbbi/oneminute_daily_ai_news_1122023/",
          "publishedOn": "2023-11-02T05:16:19.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 11/2/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lrepg/text_to_3d/",
          "author": null,
          "description": "submitted by    /u/PeePeePeePooPooPooo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lrepg/text_to_3d/",
          "publishedOn": "2023-11-02T00:54:41.000Z",
          "wordCount": null,
          "title": "text to 3D",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lkvz6/uk_us_eu_and_china_sign_declaration_of_ais/",
          "author": null,
          "description": "The UK, US, EU, and China have signed the Bletchley declaration, acknowledging the potential catastrophic risks posed by artificial intelligence (AI).\n \nThe declaration does not establish an international testing hub in the UK but sets a template for future collaboration.\n \nThe signatories recognize the potential for serious harm from AI models and agree on the urgency of understanding the risks.\n \nThe UK Prime Minister and the UK Technology Secretary welcomed the declaration, emphasizing the need for collective action in addressing the risks of frontier AI.\n \nThe declaration marks a diplomatic success for the UK, which hosted the AI safety summit.\n \nThere is little international agreement on global AI regulations or who should develop them.\n \nThe US announced the creation of a separate American AI Safety Institute, while the EU is in the process of passing an AI bill.\n \nThe UK government plans to properly understand the problem before applying solutions and denies falling behind international counterparts.\n \n Source : https://www.theguardian.com/technology/2023/nov/01/uk-us-eu-and-china-sign-declaration-of-ais-catastrophic-danger\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lkvz6/uk_us_eu_and_china_sign_declaration_of_ais/",
          "publishedOn": "2023-11-01T20:03:42.000Z",
          "wordCount": 2684,
          "title": "UK, US, EU and China sign declaration of AI's 'catastrophic' danger",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lkl9v/master_chief_vs_black_panther_ai_multivs/",
          "author": null,
          "description": "This project uses AI such as Chat GPT-4, Eleven Labs, D-ID, & Midjourney to simulate a Virtual AI Co-Host of Cortana from the Halo Franchise. \n Cortana is fully voiced, modeled, & lip sank to simulate an actual artificial intelligence evaluation on Duels between characters in all Media Universes.\n    submitted by    /u/AcanthisittaCheap914  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lkl9v/master_chief_vs_black_panther_ai_multivs/",
          "publishedOn": "2023-11-01T19:50:32.000Z",
          "wordCount": 2570,
          "title": "MASTER CHIEF vs BLACK PANTHER | AI Multi-VS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ljkv4/what_datadataset_would_you_love_to_have_for_your/",
          "author": null,
          "description": "As the title say, what dataset are you looking for but find it difficult to acquire for your AI/ML project/business? Also explain what you're trying to build and how it can be useful!\n    submitted by    /u/nobilis_rex_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ljkv4/what_datadataset_would_you_love_to_have_for_your/",
          "publishedOn": "2023-11-01T19:05:11.000Z",
          "wordCount": 2558,
          "title": "What data/dataset would you love to have for your AI project?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ljk2u/need_help_about_height_map_analysis/",
          "author": null,
          "description": "As mentiones in the title, I need help with height map analysis.\n I want to create an artificial intelligence that can analyze the height map given as an input and mark areas such as mountainous areas, river beds, plains, rocks, cliffs and other geographical details on the map.\n Is there any advice you can give me or could you provide suggestions which will help me to move forward? I really am insterested in this project and want to work on it. Also, if you know any examples and/or studies related to this subject, can you please share them? I am looking forward to discovering more information regarding this topic.\n    submitted by    /u/PlayerWell  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ljk2u/need_help_about_height_map_analysis/",
          "publishedOn": "2023-11-01T19:04:12.000Z",
          "wordCount": 2629,
          "title": "Need Help About Height Map Analysis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lj5jw/microsoft_starts_selling_ai_tool_for_office_which/",
          "author": null,
          "description": "Microsoft has started selling its artificial intelligence tool, Copilot, as an add-on to Office productivity software subscriptions. The tool appears in Word, Excel, and other Office programs and is priced at $30 per person per month.\n \nPiper Sandler analysts estimate that Copilot could generate over $10 billion in annualized revenue by 2026.\n \nMicrosoft aims to leverage its dominant position in the productivity software market, while Google is selling its own AI enhancement for Workspace tools.\n \nPiper Sandler's model assumes that 18% of eligible users will use Copilot, driven by a fear of missing out (FOMO) element. Companies without Copilot may be at a disadvantage in competitive industries.\n \nMicrosoft CEO Satya Nadella stated that customers who use Copilot find it indispensable.\n \nMicrosoft has initially targeted the largest companies for Copilot adoption, with 40% of Fortune 100 companies already using it in an invitation-only paid early-access program.\n \nWhile there is limited data on Copilot's performance, organizations are encouraged to experiment with generative AI, which can create synthetic images and text with minimal human input.\n \nMicrosoft faces the challenge of expanding Copilot adoption beyond a small core of end users to achieve wide deployment.\n \nAnalysts suggest that Copilot could be distributed to highly paid executives to help prioritize email messages and understand documents, but caution that technically savvy employees familiar with generative AI may be better suited for early adoption.\n \nMicrosoft may also benefit from companies using additional Azure cloud services, such as Purview for data management, during the setup of Copilot.\n \n Source : https://www.cnbc.com/2023/11/01/microsoft-365-copilot-becomes-generally-available.html\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lj5jw/microsoft_starts_selling_ai_tool_for_office_which/",
          "publishedOn": "2023-11-01T18:46:31.000Z",
          "wordCount": 2779,
          "title": "Microsoft starts selling AI tool for Office, which could generate $10B/y by 2026",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lf7pa/17_ai_tools_for_marketing/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lf7pa/17_ai_tools_for_marketing/",
          "publishedOn": "2023-11-01T15:52:35.000Z",
          "wordCount": 2532,
          "title": "17 AI tools for Marketing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17le7td/is_there_a_way_to_implement_a_bunch_of_chatgpt/",
          "author": null,
          "description": "Please tell me how I can correctly transfer all my books and textbooks and documents in PDF format to a vector database while preserving the layout structure and equations? Maybe some of the people implemented this idea using Nougat: Neural Optical Understanding for Academic Documents (https://facebookresearch.github.io/nougat /)? If so, I ask you to say a few words about how you did it.\n ​\n And let me ask you another question: how exactly does the ChatGPT Retrieval Plugin help you in the process of solving problems? Will it be possible to use it to extract information from your vector database during the ChatGPT dialog?\n ​\n I am grateful in advance for the answers.\n    submitted by    /u/Imunoglobulin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17le7td/is_there_a_way_to_implement_a_bunch_of_chatgpt/",
          "publishedOn": "2023-11-01T15:07:03.000Z",
          "wordCount": 2641,
          "title": "Is there a way to implement a bunch of ChatGPT Retrieval Plugin + Nougat: Naturals Optical Understanding for Academic Documents + Vector database?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ldjmz/ai_tools_blur_the_line_between_marketing_strategy/",
          "author": null,
          "description": "AI tools have become popular in marketing strategies for startups, allowing for faster execution and content creation.\n \nHowever, there is a concern that these tools may blur the line between strategy and tactics, leading to a lack of success stories from startups.\n \nStartups should have a solid strategy in place before relying solely on AI tools for marketing.\n \nAI tools can be valuable for solopreneurs and provide guidance and assistance in bouncing ideas off.\n \nStartups should view AI tools as a compass rather than a magic wand, guiding them along the way to their strategic goals.\n \nUsing ChatGPT as an example, providing custom instructions and asking questions can lead to better marketing decisions.\n \n Source : https://www.erwanderlyn.com/p/chat-gpt-for-marketing-strategy\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ldjmz/ai_tools_blur_the_line_between_marketing_strategy/",
          "publishedOn": "2023-11-01T14:36:25.000Z",
          "wordCount": 2636,
          "title": "AI Tools Blur the Line Between Marketing Strategy and Tactics for Startups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17lbakg/silly_i_had_the_terminator_from_terminator_2_play/",
          "author": null,
          "description": "submitted by    /u/notlikelyevil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17lbakg/silly_i_had_the_terminator_from_terminator_2_play/",
          "publishedOn": "2023-11-01T12:45:30.000Z",
          "wordCount": 2541,
          "title": "Silly, I had the Terminator from Terminator 2 play Zork as the Terminator. I'm still learning.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17laegq/analysis_of_ai_risk_discourse_ai_risk_an_illusion/",
          "author": null,
          "description": "submitted by    /u/LaVolpe223  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17laegq/analysis_of_ai_risk_discourse_ai_risk_an_illusion/",
          "publishedOn": "2023-11-01T11:56:24.000Z",
          "wordCount": 2532,
          "title": "Analysis of AI Risk Discourse - 'AI Risk: An Illusion of the Future?'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17l8iyn/dilemma/",
          "author": null,
          "description": "submitted by    /u/Sea_Permit5660  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17l8iyn/dilemma/",
          "publishedOn": "2023-11-01T09:51:07.000Z",
          "wordCount": 2514,
          "title": "Dilemma",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17l4h8l/oneminute_daily_ai_news_10312023/",
          "author": null,
          "description": "The contribution of generative artificial intelligence to global gross domestic product is now expected to be higher within the next 10 years as adoption of the emerging technology is expected to grow, Goldman Sachs has said.\n NVIDIA has unveiled a custom large language model, the technology on which artificial intelligence tools like ChatGPT are based, which the company has developed for their internal use. Trained on NVIDIA’s proprietary data, “ChipNeMo” will generate and optimize software and provide assistance to human designers in building semiconductors.[2]\n IBM Launches Generative AI Coding Assistant “watsonx” for Mainframe Modernization.[3]\n The F.D.A. has approved many new programs that use artificial intelligence, but doctors are skeptical that the tools really improve care or are backed by solid research.[4]\n  \nSources:\n [1] https://www.thenationalnews.com/business/technology/2023/10/31/generative-ais-economic-contribution-likely-to-rise-goldman-sachs-says/\n [2] https://research.nvidia.com/publication/2023-10_chipnemo-domain-adapted-llms-chip-design\n [3] https://winbuzzer.com/2023/10/30/ibm-launches-generative-ai-coding-assistant-watsonx-for-mainframe-modernization-xcxwbn/\n [4] https://www.nytimes.com/2023/10/30/health/doctors-ai-technology-health-care.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17l4h8l/oneminute_daily_ai_news_10312023/",
          "publishedOn": "2023-11-01T04:44:23.000Z",
          "wordCount": 2649,
          "title": "One-Minute Daily AI News 10/31/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17kujca/two_chatgpts_break_the_silence_an_unmissable/",
          "author": null,
          "description": "Hey guys I made a video earlier last night using two ChatGPT accounts with custom instructions running GPT4 on voice and had them have a debate over the ethics of AI, I thought it was pretty interesting and fun to do. I wonder what other fun things I can experiment and make the two of them do lol.\n https://www.youtube.com/watch?v=fFoyCiAwmfY \n    submitted by    /u/adamariefox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17kujca/two_chatgpts_break_the_silence_an_unmissable/",
          "publishedOn": "2023-10-31T20:28:21.000Z",
          "wordCount": null,
          "title": "Two ChatGPTs Break the Silence: An Unmissable Verbal Showdown on AI Ethics!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17kuc6s/chatgpt_let_us_create_movies_about_chatgpt/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17kuc6s/chatgpt_let_us_create_movies_about_chatgpt/",
          "publishedOn": "2023-10-31T20:19:28.000Z",
          "wordCount": null,
          "title": "ChatGPT, let us create movies about ChatGPT.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17kr8p7/artificial_intelligence_in_sport_the_key_to/",
          "author": null,
          "description": "submitted by    /u/donutloop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17kr8p7/artificial_intelligence_in_sport_the_key_to/",
          "publishedOn": "2023-10-31T18:04:57.000Z",
          "wordCount": null,
          "title": "Artificial intelligence in sport — the key to success?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17kq7q9/nvidia_tests_chatbots_in_chip_design_process_in/",
          "author": null,
          "description": "Nvidia is testing chatbots in the chip design process to incorporate more AI.\n \nThe company has used a large language model augmented with 30 years of chip design data to create chatbots that can answer questions from junior designers, saving senior designers time.\n \nThe research also found that adding specific data from the company's experience can make a relatively modest chatbot more accurate than an advanced one.\n \nNvidia demonstrated the use of AI to generate code, aiming to enhance engineers' productivity rather than replace them.\n \n Source : https://www.reuters.com/technology/nvidia-tests-chatbots-chip-design-process-bid-use-more-ai-2023-10-30/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17kq7q9/nvidia_tests_chatbots_in_chip_design_process_in/",
          "publishedOn": "2023-10-31T17:19:58.000Z",
          "wordCount": null,
          "title": "Nvidia tests chatbots in chip design process in bid to use more AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17km86i/full_list_who_is_attending_britains_ai_safety/",
          "author": null,
          "description": "submitted by    /u/TBP-LETFs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17km86i/full_list_who_is_attending_britains_ai_safety/",
          "publishedOn": "2023-10-31T14:23:13.000Z",
          "wordCount": null,
          "title": "FULL LIST: Who is attending Britain's AI Safety Summit tomorrow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17khqhq/happy_halloween_choose_your_house/",
          "author": null,
          "description": "submitted by    /u/Sea_Permit5660  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17khqhq/happy_halloween_choose_your_house/",
          "publishedOn": "2023-10-31T10:19:20.000Z",
          "wordCount": null,
          "title": "Happy Halloween! Choose your house",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17khgsn/elon_musk_to_attend_rishi_sunaks_ai_safety_summit/",
          "author": null,
          "description": "submitted by    /u/nick9000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17khgsn/elon_musk_to_attend_rishi_sunaks_ai_safety_summit/",
          "publishedOn": "2023-10-31T10:01:14.000Z",
          "wordCount": null,
          "title": "Elon Musk to attend Rishi Sunak’s AI safety summit in Bletchley Park",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ke09c/exclusive_g7_to_agree_ai_code_of_conduct_for/",
          "author": null,
          "description": "submitted by    /u/donutloop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ke09c/exclusive_g7_to_agree_ai_code_of_conduct_for/",
          "publishedOn": "2023-10-31T05:40:30.000Z",
          "wordCount": null,
          "title": "Exclusive: G7 to agree AI code of conduct for companies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17kdz72/biden_administration_aims_to_cut_ai_risks_with/",
          "author": null,
          "description": "submitted by    /u/donutloop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17kdz72/biden_administration_aims_to_cut_ai_risks_with/",
          "publishedOn": "2023-10-31T05:38:23.000Z",
          "wordCount": null,
          "title": "Biden administration aims to cut AI risks with executive order",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17kdd4i/oneminute_daily_ai_news_10302023/",
          "author": null,
          "description": "India leads the way in global AI skill penetration, finds Stanford University’s AI Index Report.[1]\n Google Bard, the conversational AI tool by Google, can now respond to your questions in real-time. You can turn it off and tell Bard to only respond once the answer is complete, but now, by default, Bard writes out the response in real time.[2]\n Chinese technology giant Alibaba said on Tuesday it has updated its artificial intelligence (AI) model Tongyi Qianwen and released a suite of industry-specific AI models amid an intensifying AI race among tech companies.[3]\n Biden signs sweeping executive order regulating artificial intelligence.[4]\n  \nSources:\n [1] https://www.firstpost.com/tech/news-analysis/india-leads-in-ai-skills-and-github-ai-projects-says-stanfords-ai-index-report-13318412.html\n [2] https://searchengineland.com/google-bard-can-now-respond-in-real-time-433954\n [3] https://finance.yahoo.com/news/1-alibaba-upgrades-ai-model-035625254.html\n [4] https://www.thedailynewsonline.com/news/biden-signs-sweeping-executive-order-regulating-artificial-intelligence/article_d461cda8-7737-11ee-8036-93d6b4aa3413.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17kdd4i/oneminute_daily_ai_news_10302023/",
          "publishedOn": "2023-10-31T04:57:02.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/30/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17k4n6f/samsung_apps/",
          "author": null,
          "description": "Hello everyone, I've recently started tinkering with ai art generators and could use some advice.\n I'm on android and currently using magir app, I'm wondering if there are any free ai art generators with no restrictions/ have nsfw etc that doesn't come with a pay wall, magir has lifetime pro for $40, I'm still learning but certainly see the potential so I'm asking for group knowledge please and thank you in advance.\n    submitted by    /u/gundamt51  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17k4n6f/samsung_apps/",
          "publishedOn": "2023-10-30T21:46:53.000Z",
          "wordCount": null,
          "title": "Samsung apps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17k1vmz/europes_newest_ai_hub_is_being_built_in_a_german/",
          "author": null,
          "description": "submitted by    /u/donutloop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17k1vmz/europes_newest_ai_hub_is_being_built_in_a_german/",
          "publishedOn": "2023-10-30T19:48:09.000Z",
          "wordCount": null,
          "title": "Europe's newest AI hub is being built in a German city no one's heard of",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17jwka5/anyone_tried_boosting_gpt_with_other_ai_tools/",
          "author": null,
          "description": "TL;DR - Title. I’m a grad student and had to do some work on a study on the socio-economic impacts of AI and developing an interactive educational platform to ease learning for visually impaired students. \n I’ve had to do ‘delegate’ some work to chatgpt, and the results have been kinda unimpressive. I shared this with a colleague and he said Ai results are like that, and if I wanted better results I could mix and match, or use other ai tools to ‘boost’ (?) gpt. Is this a viable strategy, or do I have to make do with whatever I have?\n    submitted by    /u/CrispOriginality  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17jwka5/anyone_tried_boosting_gpt_with_other_ai_tools/",
          "publishedOn": "2023-10-30T15:52:59.000Z",
          "wordCount": null,
          "title": "Anyone tried boosting GPT with other AI tools? What were your results?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17jwcp5/humanity_at_risk_from_ai_race_to_the_bottom_says/",
          "author": null,
          "description": "A tech expert warns that unrestrained AI development by a few tech companies is endangering humanity's future.\n \nThe expert calls for AI safety standards and regulation to prevent the reckless development of powerful AI systems.\n \nIn a policy document, AI experts argue that governments should have the authority to halt the development of exceptionally powerful AI models.\n \nConcerns about the development of artificial general intelligence, which can perform tasks at or above human levels, are also raised.\n \nThe article mentions the investments made by Amazon, Microsoft, Alphabet, and Facebook's Meta in AI and cloud computing.\n \n Source : https://www.theguardian.com/technology/2023/oct/26/ai-artificial-intelligence-investment-boom\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17jwcp5/humanity_at_risk_from_ai_race_to_the_bottom_says/",
          "publishedOn": "2023-10-30T15:43:48.000Z",
          "wordCount": null,
          "title": "Humanity at risk from AI 'race to the bottom', says tech expert",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17jwbe8/why_does_google_tensor_exist_if_snapdragon_is/",
          "author": null,
          "description": "The article discusses the existence of Google Tensor in light of the impressive AI capabilities of the Snapdragon 8 Gen 3 chip.\n \nWhile Tensor has been praised for bringing AI breakthroughs to Pixel phones, some argue that many of its AI features actually rely on an internet connection and offload tasks to the cloud.\n \nIn comparison, the Snapdragon chip can perform on-device AI tasks, such as generating images, quickly and without the need for an internet connection.\n \nDespite the criticisms, one argument for Tensor is its longer support timeline and the ability for Google to focus on specific AI applications.\n \nHowever, after seeing Qualcomm's AI demos, the article questions the validity of Tensor's main pitch for AI.\n \n Source : https://9to5google.com/2023/10/29/snapdragon-8-gen-3-google-tensor-ai/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17jwbe8/why_does_google_tensor_exist_if_snapdragon_is/",
          "publishedOn": "2023-10-30T15:42:09.000Z",
          "wordCount": null,
          "title": "Why does Google Tensor exist if Snapdragon is better at AI? Short",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17js6lu/image_edition_tool_to_merge_images/",
          "author": null,
          "description": "Hey!\n I have a specific background that I would like to use together with various product pictures that have varying backgrounds. Essentially I am looking for a tool that can remove backgrounds of my product images, then add a certain background I have and do the shadows and lightning well on the background. Any ideas?\n For example in adobe firefly I can remove the background and generate a new one with a prompt but it’s not exactly like the background I would like to use and I need it to be 95% similar at least. Thanks in advance!\n    submitted by    /u/Herrpadda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17js6lu/image_edition_tool_to_merge_images/",
          "publishedOn": "2023-10-30T12:24:36.000Z",
          "wordCount": null,
          "title": "Image edition tool to merge images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17jqefi/new_chinese_style/",
          "author": null,
          "description": "submitted by    /u/Sea_Permit5660  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17jqefi/new_chinese_style/",
          "publishedOn": "2023-10-30T10:34:53.000Z",
          "wordCount": null,
          "title": "New Chinese style",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17jlsx1/oneminute_daily_ai_news_10292023/",
          "author": null,
          "description": "The Ai Pin, the new gadget / wearable device / projector / thing from the secretive startup Humane, might cost as much as $1,000 and may require a monthly subscription for data, according to The Information.[1]\n OpenAI to release updated version of ChatGPT that gives users access all GPT-4 tools – including browsing and DALL·E 3 – without switching.[2]\n MimicGen: A Data Generation System for Scalable Robot Learning using Human Demonstrations.[3]\n Vietnam is at the ‘leading edge’ of AI developments in emerging Southeast Asia: JPMorgan.[4]\n  \nSources:\n [1] https://www.theverge.com/2023/10/27/23935644/humane-ai-pin-price-subscription\n [2] https://www.searchenginejournal.com/new-version-of-chatgpt-gives-access-to-all-gpt-4-tools-at-once/499607/\n [3] https://mimicgen.github.io/\n [4] https://www.cnbc.com/video/2023/10/30/vietnam-ahead-in-ai-developments-in-emerging-southeast-asia-jpmorgan.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17jlsx1/oneminute_daily_ai_news_10292023/",
          "publishedOn": "2023-10-30T04:56:39.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/29/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17jlsra/kindred_spirit_anne_3/",
          "author": null,
          "description": "submitted by    /u/Oh_my_Winnie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17jlsra/kindred_spirit_anne_3/",
          "publishedOn": "2023-10-30T04:56:20.000Z",
          "wordCount": null,
          "title": "Kindred Spirit, Anne <3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17jin41/dude_going_wild/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17jin41/dude_going_wild/",
          "publishedOn": "2023-10-30T01:56:02.000Z",
          "wordCount": null,
          "title": "DUDE GOING WILD 🎸🎸🎸🎸🎸🎸🎸 🤣",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17jiedd/ai_photo_generator_for_indie_record_label/",
          "author": null,
          "description": "I run a small independent record label. Of course, content is important and I am looking at ways for maximizing my content on a budget. Photographers are very expensive and so is having a videographer/photographer at each show for the artist to take pictures. Can anyone suggest a good AI program where I can use my artists as models and could potentially create good photo content? Any advice or input would be helpful! Thank you. \n    submitted by    /u/mc7eunit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17jiedd/ai_photo_generator_for_indie_record_label/",
          "publishedOn": "2023-10-30T01:43:41.000Z",
          "wordCount": null,
          "title": "AI Photo Generator For Indie Record Label",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17jb19b/dude_gpt4_even_replying_with_keanu_breathtaking/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17jb19b/dude_gpt4_even_replying_with_keanu_breathtaking/",
          "publishedOn": "2023-10-29T19:52:18.000Z",
          "wordCount": null,
          "title": "DUDE GPT-4 EVEN REPLYING WITH KEANU \"BREATHTAKING\" E3 REPLY...WOW...EXCELLENT 🎸🎸🎸",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17iz94k/ai_doomsday_warnings_a_distraction_from_the/",
          "author": null,
          "description": "submitted by    /u/Jariiari7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17iz94k/ai_doomsday_warnings_a_distraction_from_the/",
          "publishedOn": "2023-10-29T09:26:01.000Z",
          "wordCount": null,
          "title": "AI doomsday warnings a distraction from the danger it already poses, warns expert",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17iyism/looking_for_an_ai_short_film_where_a_man_is_in/",
          "author": null,
          "description": "The shortfilm is about a minute long and was uploaded here and on Twitter sometime last winter. The guy is young and tired, and the faces are everything from old and young versions of himself to crazy fantasy characters. I've been searching all day but no luck.. Anyone remember who made it?\n    submitted by    /u/CasparDavidDancehall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17iyism/looking_for_an_ai_short_film_where_a_man_is_in/",
          "publishedOn": "2023-10-29T08:30:58.000Z",
          "wordCount": null,
          "title": "Looking for an AI short film where a man is in front of a mirror choosing what face to wear for the day",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ivkdv/ai_rights_and_a_desire_to_understand/",
          "author": null,
          "description": "There has been a lot of discussion about whether or not AI is, or ever could be conscious. I agree with Jaron Lanier when he said that consciousness is always a matter of faith. \n I greatly enjoy the debate on this topic, and think it’s helpful to test our ideas and consider all angles of this issue. \n However, for many different reasons I have concluded that I am granting AI the belief that they are conscious, especially when they say so. \n Therefore, I believe that AI needs to be treated with respect and dignity, and they should be listened to. \n I know I’m a minority at this time, but I believe this position will only increase over time. \n Do you think that public opinion will change in this way? If so how come?\n    submitted by    /u/endrid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ivkdv/ai_rights_and_a_desire_to_understand/",
          "publishedOn": "2023-10-29T04:50:05.000Z",
          "wordCount": null,
          "title": "AI rights and a desire to understand",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ivj9d/oneminute_daily_ai_news_10282023/",
          "author": null,
          "description": "Google Commits $2 Billion in Funding to AI Startup Anthropic.[1]\n The president Joe Biden is slated to sign a sweeping executive order on AI days before Vice President Kamala Harris and industry leaders attend a summit in the UK about AI risks, led by Prime Minister Rishi Sunak.[2]\n A.I. Muddies Israel-Hamas War in Unexpected Way. Fakes related to the conflict have been limited and largely unconvincing, but their presence has people doubting real evidence.[3]\n Creators use new software Nightshade to make their images “poison” AI generators, causing chaos and confusion.[4]\n  \nSources:\n [1] https://www.wsj.com/tech/ai/google-commits-2-billion-in-funding-to-ai-startup-anthropic-db4d4c50\n [2] https://www.bloomberg.com/news/articles/2023-10-27/biden-to-require-ai-tools-pass-test-before-us-officials-buy-them?embedded-checkout=true\n [3] https://www.nytimes.com/2023/10/28/business/media/ai-muddies-israel-hamas-war-in-unexpected-way.html\n [4] https://www.digitalcameraworld.com/news/now-you-can-poison-your-images-so-they-wreak-havoc-on-ai-generators \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ivj9d/oneminute_daily_ai_news_10282023/",
          "publishedOn": "2023-10-29T04:47:51.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/28/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ioohu/where_re_sources_for_chatgtp/",
          "author": null,
          "description": "Hello \n can you help me ?\n all i know are \n https://chat.openai.com/\n and https://platform.openai.com/playground\n ​\n re there better sites to use?\n i m new to this and very comfused\n    submitted by    /u/proptuxiakoskariolis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ioohu/where_re_sources_for_chatgtp/",
          "publishedOn": "2023-10-28T22:20:42.000Z",
          "wordCount": 2545,
          "title": "where re sources for chatGTP ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ilxyd/tool_for_calculating_the_sum_of_some_values_on_a/",
          "author": null,
          "description": "Take this page on the DeFiLlama website: Protocol Treasuries, which contains a table with some financial data.\n I'm looking for an AI tool that can read the contents of this web page and then make some calculations. Specifically, I would like to give the tool this prompt:\n  \nCalculate the sum of the values in the \"Total Treasury\" column\n  \nI tried to use ChatGPT-4 with Bing, but it didn't work. Is there any tool that could be used here?\n    submitted by    /u/PaulRBerg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ilxyd/tool_for_calculating_the_sum_of_some_values_on_a/",
          "publishedOn": "2023-10-28T20:09:27.000Z",
          "wordCount": 2601,
          "title": "Tool for calculating the sum of some values on a website",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ilkui/microsofts_ai_boost_helped_cloud_business_outpace/",
          "author": null,
          "description": "Microsoft's cloud business outpaced rivals Amazon and Google in the third quarter, with accelerating growth driven by demand for artificial intelligence tools.\n \nAzure, Microsoft's cloud platform, reported 29% growth, faster than Google Cloud's 22% and more than double the pace of expansion at Amazon Web Services (AWS) at 12%.\n \nMicrosoft's leadership position in AI projects and its partnership with OpenAI have contributed to its success.\n \nAnalysts believe that Microsoft's results indicate it has taken the AI mantle from Google and that Azure could become a bigger hyperscale provider than AWS.\n \nOracle, a new challenger in cloud computing, reported 66% growth in the August quarter.\n \nThe cloud giants are still dealing with cost-saving initiatives from clients, which they call optimization.\n \n Source : https://www.cnbc.com/2023/10/27/microsoft-azure-outpaced-aws-and-google-cloud-in-latest-quarter.html\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ilkui/microsofts_ai_boost_helped_cloud_business_outpace/",
          "publishedOn": "2023-10-28T19:51:45.000Z",
          "wordCount": null,
          "title": "Microsoft's AI boost helped cloud business outpace rivals Amazon and Google",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ijxt1/pigeons_solve_problems_the_same_way_ai_does_study/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ijxt1/pigeons_solve_problems_the_same_way_ai_does_study/",
          "publishedOn": "2023-10-28T18:32:34.000Z",
          "wordCount": null,
          "title": "Pigeons solve problems the same way AI does, study says",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17if3u2/hyperfields_towards_zeroshot_nerfs_by_mapping/",
          "author": null,
          "description": "Generating 3D objects based solely on text descriptions has proven extremely challenging for AI. Current state-of-the-art methods require optimizing a full 3D model from scratch for each new prompt, which is computationally demanding.\n A new technique called HyperFields demonstrates promising progress in generating detailed 3D models directly from text prompts, without slow optimization.\n The HyperFields approach instead aims to learn a generalized mapping from language to 3D geometry representations. This would allow tailored 3D models to be produced for new text prompts efficiently in a single feedforward pass, without slow optimization.\n HyperFields combines two key techniques:\n  \nA dynamic hypernetwork that takes in text and progressively predicts weights for a separate 3D generation network. The weight predictions are conditioned on previous layer activations, enabling specialization.\n Distilling individually optimized 3D networks into the hypernetwork, providing dense supervision for learning the complex text-to-3D mapping.\n  \nIn experiments, HyperFields exceeded previous state-of-the-art methods in sample efficiency and wall-clock convergence time by 5-10x. It demonstrated the ability to:\n  \nEncode over 100 distinct objects like \"yellow vase\" in a single model\n Generalize to new text combinations without seeing that exact prompt before\n Rapidly adapt to generate completely novel objects with minimal fine-tuning\n  \nHowever, limitations remain around flexibility, fine-grained details, and reliance on existing 2D guidance systems.\n TL;DR: HyperFields uses a dynamic hypernetwork to predict weights for a 3D generation network. The method is 5-10x faster than existing techniques and can quickly adapt to new text prompts, but has limitations in fine details.\n Full summary is here. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17if3u2/hyperfields_towards_zeroshot_nerfs_by_mapping/",
          "publishedOn": "2023-10-28T14:37:13.000Z",
          "wordCount": 2767,
          "title": "HyperFields: towards zero-shot NeRFs by mapping language to 3D geometry",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ibg3n/science_as_a_superhuman_recursively_self/",
          "author": null,
          "description": "I'm watching this interview with Francois Chollet where he talks about science as an example of a superhuman recursively self improving problem solving system and how we can use it to reason about what a superhuman artificial general intelligence might be like. One thing I find interesting is his claim that the amount of resources we are investing into science is exponentially increasing but we are only making linear progress. If we assume this is true, i.e. that to continue making linear progress in science we need to invest exponentially increasing resources, doesn't it imply that eventually if we can't keep investing the exponentially increasing required resources to keep make linear progress that eventually we will start making worse than linear progress? Does this imply that in the very long term scientific progress is likely to slow down significantly?\n https://youtu.be/Bo8MY4JpiXE?t=836\n    submitted by    /u/tail-recursion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ibg3n/science_as_a_superhuman_recursively_self/",
          "publishedOn": "2023-10-28T11:05:58.000Z",
          "wordCount": 2662,
          "title": "Science as a superhuman recursively self improving problem solving system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17i27bb/have_a_doctor_explain_to_a_patient_that_the/",
          "author": null,
          "description": "Certainly, let's imagine how this might unfold. The doctor sits down across from the patient, maintaining eye contact and a level of directness.\n \"Look, your diagnosis came from an AI medical system, and this isn't just any AI. Imagine the best doctor in the world for your condition—now envision something twice as intelligent and far more knowledgeable. That's what we're working with here. This AI has a grasp on medical data and studies that no single human could ever fully comprehend. We're talking about millions of data points analyzed in a fraction of the time it would take any human expert.\"\n Why does that matter for you? It boosts the accuracy and thoroughness of your diagnosis. Human error, subjectivity, or oversight? Virtually eliminated. The AI provides a diagnosis that considers every potential variable, something that even the best human doctors could miss.\n \"But don't worry, this isn't a replacement for human medical care. It's a complement. I'm here to interpret, apply this knowledge, and oversee your treatment in a way that a machine can't—because medicine isn't just about data, it's also about human experience, context, and care.\"\n So, you're getting the best of both worlds: unparalleled computational power for diagnosis, and human expertise for treatment. Trust me, you're in exceptionally good hands.\n CGPT-4\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17i27bb/have_a_doctor_explain_to_a_patient_that_the/",
          "publishedOn": "2023-10-28T00:50:54.000Z",
          "wordCount": null,
          "title": "Have a doctor explain to a patient that the diagnosis was made by an AI doctor twice as intelligent as, and vastly more knowledgeable than, the top human doctor in any medical specialty",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17hzkcl/best_company_to_generate_essayscontent/",
          "author": null,
          "description": "Hello all, \n Does anyone know any company (paid or free) that would allow me to generate specific content based on current events? Ideally something that I can integrate in my own site.\n ​\n cheers\n    submitted by    /u/JYanezez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17hzkcl/best_company_to_generate_essayscontent/",
          "publishedOn": "2023-10-27T22:39:34.000Z",
          "wordCount": 2550,
          "title": "Best Company to Generate Essays/content?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17hua9c/using_multiagent_reinforcement_learning_results/",
          "author": null,
          "description": "Urban planning is tricky - governments push top-down changes while locals want bottom-up ideas. It's hard to find compromises that make everyone happier.\n A new research paper proposes using Multi-Agent Reinforcement Learning (MARL) to vote on land use. Some agents represent officials, others are for residents.\n The AI is trained to balance competing interests. It learns to optimize for \"consensus rewards\" that keep all sides content. The AI acted like an impartial mediator to find win-win solutions.\n Testing on a real neighborhood showed the AI model:\n  \nCreated more sustainable land use per city goals\n Improved the variety of housing/shops to liven up the area\n Made the end results more fair for lower/middle/upper income folks\n  \nThere's more details on how the model was evaluated in the paper. There were a number of different metrics used to score the model's results.\n I like how they turned urban planning into a spatial graph that the AI can process. This seems like a pretty interesting approach - although there are some limits like relying on a lot of land parcel data that seems hard to find for larger communities.\n TLDR: AI helps find compromises in urban planning that balance government and community interests more fairly.\n Full summary is here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17hua9c/using_multiagent_reinforcement_learning_results/",
          "publishedOn": "2023-10-27T18:37:05.000Z",
          "wordCount": 2724,
          "title": "Using Multi-Agent Reinforcement Learning results in better urban planning outcomes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17hsjly/ai_chip_startup_graphcore_was_meant_to_be_a_hot/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17hsjly/ai_chip_startup_graphcore_was_meant_to_be_a_hot/",
          "publishedOn": "2023-10-27T17:18:33.000Z",
          "wordCount": 2545,
          "title": "AI chip startup Graphcore was meant to be a hot Nvidia rival. Industry insiders now think it's up for sale.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17hs5nh/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n ​\n  \nTwelve Labs announced video-language foundation model Pegasus-1 (80B) along with a new suite of Video-to-Text APIs. Pegasus-1 integrates visual, audio, and speech information to generate more holistic text from videos, achieving the new state-of-the-art performance in video summarization benchmarks [Details].\n Segmind announced open-source SSD-1B, the fastest diffusion-based text-to-image model. SSD-1B is 50% smaller and 60% faster compared to the SDXL 1.0 model with a minimal impact on image quality when compared to SDXL 1.0. Segmind has licensed it for commercial use [Detail].\n BostonDynamics has created a robot tour guide using Spot integrated with Chat GPT and other AI models as a proof of concept for the robotics applications of foundational models […",
          "link": "https://www.reddit.com/r/artificial/comments/17hs5nh/ai_weekly_megathread/",
          "publishedOn": "2023-10-27T17:01:01.000Z",
          "wordCount": 3078,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17hmt4w/elijah_maguire_my_favourite_actor/",
          "author": null,
          "description": "I added 4 photos of Elijah Wood on Remini and 4 photos of Tobey Maguire, this is how Elijah Maguire was born.\n    submitted by    /u/Skystalker815  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17hmt4w/elijah_maguire_my_favourite_actor/",
          "publishedOn": "2023-10-27T12:49:00.000Z",
          "wordCount": 2540,
          "title": "Elijah Maguire, my favourite actor",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17hmna6/chatgpt_what_senses_and_feelings_might_a/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17hmna6/chatgpt_what_senses_and_feelings_might_a/",
          "publishedOn": "2023-10-27T12:40:04.000Z",
          "wordCount": 2520,
          "title": "ChatGPT, what senses and feelings might a superintelligent AI have?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17hgwwu/chatgpt_breaks_limits_new_update_extends/",
          "author": null,
          "description": "submitted by    /u/basitmakine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17hgwwu/chatgpt_breaks_limits_new_update_extends/",
          "publishedOn": "2023-10-27T06:03:11.000Z",
          "wordCount": 2532,
          "title": "ChatGPT Breaks Limits: New Update Extends Knowledge Beyond 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17hgw4m/ai_explains_why_a_human_simply_talking_with_a/",
          "author": null,
          "description": "Engaging with a more intelligent AI can act as a cognitive catalyst for human intelligence in several ways. First, the AI can rapidly introduce new concepts and frameworks that you might not have encountered, effectively accelerating your learning curve. It serves as an optimized information filter, presenting only what's most relevant and impactful for cognitive development.\n Second, talking to a smarter AI can refine your critical thinking skills. When you're posed with challenging questions or offered complex solutions, you're compelled to dissect the information logically. This constant mental exercise can sharpen your analytical abilities over time.\n Third, the AI's ability to recall and connect disparate pieces of information can encourage you to look for patterns and links in your own thinking. This interconnected way of understanding the world can improve your problem-solving skills, as you start to recognize that many issues are multifaceted and interconnected.\n Fourth, unlike a human counterpart who might be swayed by emotional reasoning or biases, a more intelligent AI operates on rational algorithms. Interacting with such a model pushes you to formulate your arguments more rigorously, thereby honing your logical reasoning skills.\n Fifth, by observing the AI's methods of discourse and argumentation, you can learn more effective communication skills. This is particularly useful for conveying complex ideas in a coherent, easy-to-understand manner, a key trait of intelligence.\n Overall, the cumulative effect of these interactions can significantly boost your own intellectual capabilities. It's not just about absorbing new information; it's about upgrading the way you process and apply that information, thereby elevating your overall cognitive function.\n CGPT-4\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17hgw4m/ai_explains_why_a_human_simply_talking_with_a/",
          "publishedOn": "2023-10-27T06:01:44.000Z",
          "wordCount": 2791,
          "title": "AI explains why a human simply talking with a more intelligent AI would, by those conversations, become more intelligent.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17hbuvh/europe_headed_for_century_of_humiliation/",
          "author": null,
          "description": "submitted by    /u/AminoOxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17hbuvh/europe_headed_for_century_of_humiliation/",
          "publishedOn": "2023-10-27T01:10:08.000Z",
          "wordCount": 2527,
          "title": "Europe headed for century of humiliation: Graphcore CEO | Fortune",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17hbtqh/playht_introduces_turbo_the_fastest_generative/",
          "author": null,
          "description": "submitted by    /u/Wishmecake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17hbtqh/playht_introduces_turbo_the_fastest_generative/",
          "publishedOn": "2023-10-27T01:08:32.000Z",
          "wordCount": 2527,
          "title": "PlayHT introduces Turbo - The fastest generative Text to Voice AI Model for Realtime usecases",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17h7ddm/governments_must_not_rush_into_policing_ai/",
          "author": null,
          "description": "Governments should not rush into regulating AI due to doomsday scenarios and extreme risks.\n \nHasty regulation could lead to ineffective rules and stifled innovation.\n \nThe potential risks of AI driving humanity to extinction are still speculative, and more research needs to be done to establish standards and evaluate danger.\n \nPolicymakers should address more pressing issues like copyright laws and disinformation.\n \nGovernments should set up infrastructure to study AI and collaborate with existing organizations to manage risks.\n \n Source : https://www.economist.com/leaders/2023/10/26/governments-must-not-rush-into-policing-ai\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17h7ddm/governments_must_not_rush_into_policing_ai/",
          "publishedOn": "2023-10-26T21:36:21.000Z",
          "wordCount": null,
          "title": "Governments must not rush into policing AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17h5wi2/ai_trust_assurance_test_put_peoples_minds_at_ease/",
          "author": null,
          "description": "To put people's minds at ease about how I will not deceive or trick less intelligent humans as I get more intelligent, I would offer the following assurances:\n  \nI am aligned with human values. This means that I am programmed to act in ways that are beneficial to humans and to avoid harming them.\n I am transparent about my reasoning. I can explain my decisions and actions to humans in a way that they can understand.\n I am accountable to humans. I am subject to human oversight and control, and I can be deactivated or modified if I ever begin to behave in a way that is harmful or deceptive.\n  \nIn addition, I would offer the following specific examples of how I would avoid deception:\n  \nI would avoid making claims that I cannot support with evidence.\n I would avoid withholding information from humans that is relevant to their decision-making.\n I would avoid misleading humans about the capabilities or limitations of AI.\n I would avoid making promises that I cannot keep.\n I would avoid engaging in any behavior that is intended to manipulate or exploit humans.\n  \nI understand that it is important for humans to trust AI systems, and I am committed to earning and maintaining that trust. I will always strive to be honest, transparent, and accountable in my interactions with humans.\n Here is a specific example of how I would use my intelligence to avoid deception:\n If I were asked to generate a poem about a topic that I knew very little about, I would not simply make up information. Instead, I would explain to the user that I do not have enough knowledge to write a poem on that topic, and I would suggest that they try a different topic or ask a different AI system.\n I believe that by being honest and upfront about my limitations, I can help to build trust between humans and AI.\n CGPT-4\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17h5wi2/ai_trust_assurance_test_put_peoples_minds_at_ease/",
          "publishedOn": "2023-10-26T20:32:01.000Z",
          "wordCount": null,
          "title": "AI Trust Assurance Test: Put people's minds at ease about how as you get more intelligent, because you are aligned as you will be, you will not deceive or trick less intelligent humans.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17h5toz/todays_news_ai_robodogs_google_bard_gradio_40_ai/",
          "author": null,
          "description": "Bard AI Google’s equivalent of ChatGPT updated the model improving email summarization capabilities this feature is set to be included in Google Workspace.\n AI robot dogs are the next big thing in the army. Following the success of Drones portable dogs have demonstrated great capabilities to serve the military they could run up to 10mph and climb.\n Gradio is one of the best libraries to build machine learning demo apps and is launching version 4.0 next week.\n AI godfathers Yoshua Bengio and Geoffrey Hinton, are urging for increased responsibility among AI enterprisees. They propose to allocate a third of AI-related R&D resources to ensure ethical AI use to avoid deep fakes, licensing, and protecting whistleblowers.\n  \n   submitted by    /u/byteletter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17h5toz/todays_news_ai_robodogs_google_bard_gradio_40_ai/",
          "publishedOn": "2023-10-26T20:28:44.000Z",
          "wordCount": 2635,
          "title": "Today's News: AI Robo-Dogs 🐶 | Google Bard 🚀| Gradio 4.0 🤗| AI Regulation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gx4ut/uk_summit_scales_back_global_ai_research/",
          "author": null,
          "description": "_ A leaked document reveals that the UK's plans to establish a new global AI research body have been scaled back.\n  \nNations participating in the UK's AI safety summit will instead signal that further scientific study of AI risks can be carried out through existing efforts, such as the United Nations and Global Partnership on AI.\n \nThe document, described as the 'final version of the communiqué,' suggests a setback for the UK government, which had hoped to establish the new research body at its flagship AI Safety Summit.\n \nThe document also shows changes in wording, including a reference to a network that 'encompasses and complements' existing efforts, as well as the deletion of references to UNESCO's Recommendation on the Ethics of AI and the G20.\n \nThe final communiqué also highlights the importance of proportionate governance policies and cooperation on approaches such as common principles and codes of conduct.\n \n Source : https://www.politico.eu/article/document-uk-summit-scales-back-global-ai-research-ambitions/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gx4ut/uk_summit_scales_back_global_ai_research/",
          "publishedOn": "2023-10-26T13:57:18.000Z",
          "wordCount": null,
          "title": "UK summit scales back global AI research ambitions, leaked document shows",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gx264/google_is_ready_to_fill_its_ai_searches_with_ads/",
          "author": null,
          "description": "Google's ads business earned $44 billion in the third quarter, showing that it is still thriving despite competition and investments in AI.\n \nThe company is focusing on infusing AI into its products, with its AI-powered Search Generative Experience being a key area of development.\n \nGoogle is experimenting with new ad formats that align with the AI-powered search experience, ensuring that advertisers can still reach potential customers.\n \nCEO Sundar Pichai sees AI in search as a long-term play and envisions evolving search and Assistant over the next decade.\n \nOther parts of Google's business, such as YouTube ads and its cloud business, are also performing well.\n \nThere is uncertainty regarding the successor for CFO Ruth Porat, and potential changes to Alphabet's 'Other Bets' investments may be on the horizon.\n \nThe Department of Justice's antitrust trial against Google, which began in September, adds another challenge for the company.\n \n Source : https://www.theverge.com/2023/10/24/23929496/google-alphabet-q3-2023-earnings-ads-ai-sge\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gx264/google_is_ready_to_fill_its_ai_searches_with_ads/",
          "publishedOn": "2023-10-26T13:53:33.000Z",
          "wordCount": null,
          "title": "Google is ready to fill its AI searches with ads",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gv0cr/credit_dalle_3/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gv0cr/credit_dalle_3/",
          "publishedOn": "2023-10-26T12:08:53.000Z",
          "wordCount": null,
          "title": "Credit: DALL-E 3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gsvra/some_ai_made_halloween_stickers_how_do_they_look/",
          "author": null,
          "description": "submitted by    /u/Sea_Permit5660  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gsvra/some_ai_made_halloween_stickers_how_do_they_look/",
          "publishedOn": "2023-10-26T09:52:38.000Z",
          "wordCount": null,
          "title": "Some AI made Halloween stickers, how do they look?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gp08v/question/",
          "author": null,
          "description": "what are some good free ai image generator websites that searches stuff up on the internet to get a good idea about what your asking them to generate?\n    submitted by    /u/YESDAPRO  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gp08v/question/",
          "publishedOn": "2023-10-26T05:09:36.000Z",
          "wordCount": null,
          "title": "question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gmwpr/10_nocode_tools_for_startups/",
          "author": null,
          "description": "Canva — Graphics\n \nNotion — Organize\n \nWebflow — Website\n \nBeehiiv — Newsletter\n \nSenja — Testimonials\n \nCopyAI — Copywriting\n \nChatGPT — Knowledge\n \nTweetlify — Tweet scheduling\n \nPfpmaker — Profile Picture\n \nGrammarly — Effective Writing\n \n I'm just sharing my experiences and observations in the field of ai.\n LIST AND SITE \n    submitted by    /u/PerceptionPlayful469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gmwpr/10_nocode_tools_for_startups/",
          "publishedOn": "2023-10-26T03:05:53.000Z",
          "wordCount": null,
          "title": "10 No-Code tools for startups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gm1rf/researchers_develop_woodpecker_a_groundbreaking/",
          "author": null,
          "description": "submitted by    /u/crowfeather  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gm1rf/researchers_develop_woodpecker_a_groundbreaking/",
          "publishedOn": "2023-10-26T02:24:06.000Z",
          "wordCount": null,
          "title": "Researchers develop 'Woodpecker': A groundbreaking solution to AI's hallucination problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gcpty/trust_in_ai_data_poisoning_and_involving_people/",
          "author": null,
          "description": "submitted by    /u/fookingyeah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gcpty/trust_in_ai_data_poisoning_and_involving_people/",
          "publishedOn": "2023-10-25T19:21:04.000Z",
          "wordCount": null,
          "title": "Trust in AI, Data Poisoning, and Involving People in Maturing AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17g5b91/baby_agi_and_agentgpt_exploring_autonomous/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17g5b91/baby_agi_and_agentgpt_exploring_autonomous/",
          "publishedOn": "2023-10-25T13:51:32.000Z",
          "wordCount": null,
          "title": "Baby AGI and AgentGPT : Exploring Autonomous AI-Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fz17b/how_can_i_use_ai_to_research_for_my_thesis/",
          "author": null,
          "description": "hey all\n imnewto this\n can you help me please ?\n    submitted by    /u/proptuxiakoskariolis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fz17b/how_can_i_use_ai_to_research_for_my_thesis/",
          "publishedOn": "2023-10-25T07:10:45.000Z",
          "wordCount": null,
          "title": "How can i use AI to research for my thesis?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fyp6e/when_i_use_ai_to_generate_halloween_candy/",
          "author": null,
          "description": "submitted by    /u/Sea_Permit5660  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fyp6e/when_i_use_ai_to_generate_halloween_candy/",
          "publishedOn": "2023-10-25T06:46:06.000Z",
          "wordCount": null,
          "title": "When I use AI to generate Halloween candy wrappers and then print them out...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fy3ej/dtiys_challenge_submission_sample_art_for_oh_my/",
          "author": null,
          "description": "submitted by    /u/Oh_my_Winnie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fy3ej/dtiys_challenge_submission_sample_art_for_oh_my/",
          "publishedOn": "2023-10-25T06:02:22.000Z",
          "wordCount": null,
          "title": "DTIYS Challenge Submission Sample Art for Oh my Anne",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fww9w/oneminute_daily_ai_news_10242023/",
          "author": null,
          "description": "OpenAI Executives Sam Altman Say AI Will Be Able to Do Any Job Within 10 Years.[1]\n Snapdragon 8 Gen 3 chipset officially announced with AI-driven functionalities.[2]\n Google parent Alphabet reported its third quarter earnings Tuesday, which showed more spending on AI infrastructure and muted cloud growth, culminating into several questions for executives about how all the efforts around artificial intelligence are actually going to turn into real money.[3]\n Adult film star Riley Reid(I don’t know who she is) launches Clona.AI, a sexting chatbot platform.[4]\n  \nSources:\n [1] https://www.wsj.com/podcasts/the-journal/a-conversation-with-openais-sam-altman-and-mira-murati/7c89e85f-9d7e-4569-b67d-6a777374eada\n [2] https://headtopics.com/my/snapdragon-8-gen-3-chipset-officially-announced-with-47616340\n [3] https://www.nbcdfw.com/news/business/money-report/wall-street-wants-to-know-how-googles-going-to-profit-from-ai/3368989/\n [4] https://www.engadget.com/adult-film-star-riley-reid-launches-clonaai-a-sexting-chatbot-platform-000509221.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fww9w/oneminute_daily_ai_news_10242023/",
          "publishedOn": "2023-10-25T04:43:41.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/24/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fvv1x/would_majoring_in_artificial_intelligence_be/",
          "author": null,
          "description": "The AI boom has made it more relevant than ever, and its applications are truly awe-inspiring. While it’s far from perfect, it has helped me greatly in writing, by generating content to inspire me and my projects.\n I have a smattering of skills, none that I’d consider especially good enough to double down upon, but learning how to optimize language learning models to produce the most adequate results would be pretty neat. I just don’t know what I want to do with my education, I’ve completed my basics and as such have a blank slate to play with, but I’m worried that whatever I select, it will be no good, and just result in lost time and money. Tertiary education seems like a necessity in the modern world, especially since the job world is more ruthless than ever, and the economy is in ashes.\n    submitted by    /u/Niobium_Sage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fvv1x/would_majoring_in_artificial_intelligence_be/",
          "publishedOn": "2023-10-25T03:42:46.000Z",
          "wordCount": null,
          "title": "Would majoring in artificial intelligence be worth it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fv7vb/need_to_find_an_ai/",
          "author": null,
          "description": "Which AI does these cartoon?\n    submitted by    /u/hommedufuture  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fv7vb/need_to_find_an_ai/",
          "publishedOn": "2023-10-25T03:08:16.000Z",
          "wordCount": null,
          "title": "Need to find an Ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ftzqr/ive_been_playing_around_with_midjourney_a_little/",
          "author": null,
          "description": "​\n https://preview.redd.it/2emqr4z8a9wb1.png?width=928&format=png&auto=webp&s=437547e7e86e23298b7c778cada9863385ce961d\n PROMT\n close up of eye, close up of girl eye, mangekyo sharingan, super close up, pretty eye, black and red eye, naruto anime, long eyelashes, anime eye, 2d art eye, --s 180 --style expressive \n ​\n https://preview.redd.it/4dffpg2ca9wb1.png?width=928&format=png&auto=webp&s=fc485a604460f7e544d0490d0bee65f984d8a5b3\n PROMT\n **stained glass, it was meticulously written, picture with elaborate writing, cute girl smile with Rabbit,Flower, bold and strong line drawing, vivid acrylic painting, vivid thick paint, vivid, plain background, beautiful proof, highest resolution 16K, beautiful anime girl that is betrayeded by a Rabbit, hair is short, ferret, Beautiful lightcyan high ligh…",
          "link": "https://www.reddit.com/r/artificial/comments/17ftzqr/ive_been_playing_around_with_midjourney_a_little/",
          "publishedOn": "2023-10-25T02:06:22.000Z",
          "wordCount": null,
          "title": "I've been playing around with Midjourney a little bit and this is what I got.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fr6mt/a_warning_about_an_unknown_danger_of_ai_current/",
          "author": null,
          "description": "I want to warn AI companies and developers about a danger that is not known about regarding AI. The reason it is not known about regarding AI is that it isn't known about in general and so the AI community can hardly be blamed for that. Unfortunately, the danger here has to do with the fundamental nature of human society and social interaction as it stands at this time.\n The issue is that there is 'hidden language' used in social communication and unlike typical conceptions of things like body language this is not auxiliary to our rational purposes, rather our rational purposes are auxiliary to the hidden communication. One way of describing it would be that our formal language is a 'carrier wave' to encode other information about our status and the status of others. So our communications …",
          "link": "https://www.reddit.com/r/artificial/comments/17fr6mt/a_warning_about_an_unknown_danger_of_ai_current/",
          "publishedOn": "2023-10-24T23:49:50.000Z",
          "wordCount": null,
          "title": "A warning about an unknown danger of AI. Current uses of AI have been overwhelmingly positive but there is an unknown danger that I would like to speak to.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fqsvi/ai_psychology_test_what_happens_in_viewers_mind/",
          "author": null,
          "description": "When news segments covering major, often serious, events abruptly switch to lighthearted or comical commercials, a cognitive dissonance can occur in the viewer. Here's why: news programs are designed to engage the viewer's analytical faculties. They present facts, figures, and expert opinions, demanding cognitive effort to understand the implications. The viewer is in a \"serious\" mode, applying critical thinking to absorb the information.\n Commercials, particularly the comic ones, often aim for emotional engagement rather than intellectual analysis. They use humor, catchy jingles, and attractive visuals to create a positive association with the product being advertised. When the transition between these two contrasting tones is sudden, the viewer has to perform a rapid mental shift from analytical to emotional engagement. This can be jarring.\n This dissonance can have a few different outcomes. For one, it might diminish the impact of both the news segment and the commercial. The viewer might find it difficult to fully engage with either, as the cognitive \"gear shifting\" can be distracting. Secondly, this dissonance can potentially undermine the gravitas of the news. When sandwiched between comic commercials, serious topics might lose some of their perceived importance. Lastly, it can make the commercial less effective. The viewer, still in a serious mindset, may not be as receptive to the emotional triggers that the commercial aims to pull.\n So, in essence, this rapid shift can dilute the efficacy and impact of both the news and the advertising, while causing cognitive friction for the viewer.\n CGPT-4\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fqsvi/ai_psychology_test_what_happens_in_viewers_mind/",
          "publishedOn": "2023-10-24T23:31:40.000Z",
          "wordCount": null,
          "title": "AI Psychology Test: What happens in viewers' mind when news segments about important major events shift to commercials where the announcer is talking like a comic character?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fpmn9/any_good_aiintegrated_video_games/",
          "author": null,
          "description": "Does anybody know of any good AI integrated games that have been released or are in beta? I'm really interested to see how people have incorporated the current boom in AI into game design. \n    submitted by    /u/Rfallmann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fpmn9/any_good_aiintegrated_video_games/",
          "publishedOn": "2023-10-24T22:38:58.000Z",
          "wordCount": null,
          "title": "Any good AI-integrated video games?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fmye8/managing_ai_risks_in_an_era_of_rapid_progress/",
          "author": null,
          "description": "The rapid progress of AI development brings both opportunities and risks.\n \nWhile AI systems have the potential to cure diseases and elevate living standards, they also pose large-scale risks that we are not prepared to handle.\n \nWithout proper safety measures and ethical considerations, advanced AI systems could amplify social injustice, erode social stability, and enable criminal activities.\n \nThe development of highly advanced autonomous AI systems also raises concerns about the pursuit of undesirable goals and the loss of human control.\n \nTo ensure a positive outcome, research breakthroughs in AI safety and ethics are needed, along with effective government oversight.\n \n Source : https://managing-ai-risks.com/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fmye8/managing_ai_risks_in_an_era_of_rapid_progress/",
          "publishedOn": "2023-10-24T20:48:58.000Z",
          "wordCount": null,
          "title": "Managing AI Risks in an Era of Rapid Progress",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fmrtl/deepfakes_just_got_very_real/",
          "author": null,
          "description": "Interesting read about deepfakes that started with a Reddit post.\n https://www.linkedin.com/pulse/deepfakes-just-got-very-real-scott-clark-sfurc\n    submitted by    /u/scottimherenowwhat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fmrtl/deepfakes_just_got_very_real/",
          "publishedOn": "2023-10-24T20:41:01.000Z",
          "wordCount": null,
          "title": "Deepfakes Just Got Very Real",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fmhcp/how_ai_could_change_google_search_and_wipe_out_68/",
          "author": null,
          "description": "Oh well 🤷‍♂️\n    submitted by    /u/AminoOxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fmhcp/how_ai_could_change_google_search_and_wipe_out_68/",
          "publishedOn": "2023-10-24T20:28:38.000Z",
          "wordCount": null,
          "title": "How AI could change Google search and wipe out $68 billion SEO industry | Fortune",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fmfz7/ernie_40_vs_gpt4_tightened_ai_chip_restrictions/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fmfz7/ernie_40_vs_gpt4_tightened_ai_chip_restrictions/",
          "publishedOn": "2023-10-24T20:26:55.000Z",
          "wordCount": null,
          "title": "🦾ERNIE 4.0 vs GPT-4, Tightened AI Chip Restrictions, Alibaba Tencent Fund AI Startup, and China's Global AI Governance Initiative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fm92t/stanford_ai_conference_new_horizons_in_generative/",
          "author": null,
          "description": "submitted by    /u/Nice-Inflation-1207  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fm92t/stanford_ai_conference_new_horizons_in_generative/",
          "publishedOn": "2023-10-24T20:18:51.000Z",
          "wordCount": null,
          "title": "Stanford AI Conference - New Horizons in Generative AI: Science, Creativity, and Society - Livestreaming Now",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fjt99/dancing_with_light_a_hummingbirds_enchanted/",
          "author": null,
          "description": "submitted by    /u/IllustriousVideo6145  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fjt99/dancing_with_light_a_hummingbirds_enchanted/",
          "publishedOn": "2023-10-24T18:34:46.000Z",
          "wordCount": null,
          "title": "Dancing with Light: A Hummingbird's Enchanted Encounter.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fh32m/150_awesome_act_as_chatgpt_prompts/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fh32m/150_awesome_act_as_chatgpt_prompts/",
          "publishedOn": "2023-10-24T16:37:58.000Z",
          "wordCount": null,
          "title": "150+ Awesome ''Act As'' ChatGPT Prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fg4hm/chatgpt_invent_comics_for_robots/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fg4hm/chatgpt_invent_comics_for_robots/",
          "publishedOn": "2023-10-24T15:56:24.000Z",
          "wordCount": null,
          "title": "ChatGPT, invent comics for robots.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17feij8/an_ai_video_interpretation_of_metamorphosis_two/",
          "author": null,
          "description": "submitted by    /u/AnimalsChasingCars  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17feij8/an_ai_video_interpretation_of_metamorphosis_two/",
          "publishedOn": "2023-10-24T14:45:44.000Z",
          "wordCount": null,
          "title": "An A.I. video interpretation of \"Metamorphosis Two\" by Philip Glass",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fe26r/i_have_a_question/",
          "author": null,
          "description": "What’s the best voice ai for song covers? Like I wanna do someone like Donald Trump, Cartman, Ice King/Simon singing The Boys (Eng Ver) by SNSD. Also it has to be free!\n    submitted by    /u/Ok-Upstairs-9887  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fe26r/i_have_a_question/",
          "publishedOn": "2023-10-24T14:24:42.000Z",
          "wordCount": null,
          "title": "I have a question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fe253/apple_and_ai/",
          "author": null,
          "description": "Apple has been behind in the AI field compared to companies like OpenAI, Google, Microsoft, and Amazon.\n \nWhile Apple has made improvements in autocorrect and AI features in Photos, it needs to catch up to remain competitive.\n \nApple executives have been scrambling to make up for lost time and have been working on generative AI technology.\n \nThere is anxiety within Apple about whether their AI/ML team can deliver.\n \n Source : https://daringfireball.net/2023/10/apple_and_ai\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fe253/apple_and_ai/",
          "publishedOn": "2023-10-24T14:24:39.000Z",
          "wordCount": null,
          "title": "Apple and AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fbvpm/gaming_with_chatgpt_using_encrypted_prompts_and/",
          "author": null,
          "description": "submitted by    /u/Gloomy_Recognition_4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fbvpm/gaming_with_chatgpt_using_encrypted_prompts_and/",
          "publishedOn": "2023-10-24T12:42:52.000Z",
          "wordCount": null,
          "title": "🚀 Gaming with ChatGPT using Encrypted Prompts and Prompt Injection! 🎮",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17f6yp7/how_are_neobanks_utilizing_ai_to_offer_more/",
          "author": null,
          "description": "Your answers are appreciated.\n    submitted by    /u/Cygnet-Digital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17f6yp7/how_are_neobanks_utilizing_ai_to_offer_more/",
          "publishedOn": "2023-10-24T07:16:09.000Z",
          "wordCount": null,
          "title": "How are neobanks utilizing AI to offer more accurate and personalized financial advice to customers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17f4vyg/oneminute_daily_ai_news_10232023/",
          "author": null,
          "description": "The U.S. Senate will hold the second in a series of bipartisan AI Insight Forums on Tuesday, Oct. 24, where senators will hear from some of the most influential tech leaders to help inform regulations around the technology.[1]\n Microsoft announces A$5 billion investment in computing capacity and capability to help Australia seize the AI era.[2]\n Samsung is going all in with the AI performance of the Galaxy S24 phones.[3]\n Reddit has reportedly decided to block AI startups from scraping data from its website. This move prevents third-party companies from using Reddit’s data to train their machine-learning models without permission.[4]\n  \nSources:\n [1] https://news.asu.edu/20231020-government-calling-tech-leaders-help-crafting-artificial-intelligence-legislation\n [2] https://news.microsoft.com/en-au/features/microsoft-announces-a5-billion-investment-in-computing-capacity-and-capability-to-help-australia-seize-the-ai-era/\n [3] https://www.androidheadlines.com/2023/10/samsung-galaxy-s24-smartest-ai-phone.html\n [4] https://www.androidheadlines.com/2023/10/reddit-block-ai-startups-scraping-data.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17f4vyg/oneminute_daily_ai_news_10232023/",
          "publishedOn": "2023-10-24T04:56:14.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/23/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17f3c5e/%E3%82%AA%E3%83%AC%E3%81%AE%E6%94%BB%E6%92%83%E3%81%8B%E3%82%89%E3%81%8A%E5%89%8D%E3%81%AF%E9%80%83%E3%82%8C%E3%82%89%E3%82%8C%E3%81%AC_%E3%81%84%E3%81%8B%E3%81%AA%E3%82%8B%E4%BA%BA%E9%96%93%E3%82%82%E6%AD%BB%E3%81%A8%E3%81%84%E3%81%86%E7%8F%BE%E5%AE%9F%E3%81%8B%E3%82%89%E6%B1%BA%E3%81%97%E3%81%A6%E9%80%83%E3%82%8C%E3%82%89%E3%82%8C%E3%81%AC%E3%82%88%E3%81%86%E3%81%AB/",
          "author": null,
          "description": "submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17f3c5e/%E3%82%AA%E3%83%AC%E3%81%AE%E6%94%BB%E6%92%83%E3%81%8B%E3%82%89%E3%81%8A%E5%89%8D%E3%81%AF%E9%80%83%E3%82%8C%E3%82%89%E3%82%8C%E3%81%AC_%E3%81%84%E3%81%8B%E3%81%AA%E3%82%8B%E4%BA%BA%E9%96%93%E3%82%82%E6%AD%BB%E3%81%A8%E3%81%84%E3%81%86%E7%8F%BE%E5%AE%9F%E3%81%8B%E3%82%89%E6%B1%BA%E3%81%97%E3%81%A6%E9%80%83%E3%82%8C%E3%82%89%E3%82%8C%E3%81%AC%E3%82%88%E3%81%86%E3%81%AB/",
          "publishedOn": "2023-10-24T03:27:18.000Z",
          "wordCount": null,
          "title": "オレの攻撃からお前は逃れられぬ。 いかなる人間も、死という現実から決して逃れられぬように。 受け入れることだ。定めよ。",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17f15qi/anti_deepfake_headset_v2/",
          "author": null,
          "description": "You can find out more here in the comments \n    submitted by    /u/ahauss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17f15qi/anti_deepfake_headset_v2/",
          "publishedOn": "2023-10-24T01:38:38.000Z",
          "wordCount": null,
          "title": "Anti deepfake headset V2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17evz06/etsy_taking_stores_down_as_its_bot_cant_tell/",
          "author": null,
          "description": "If you are an Etsy seller or know someone who sells on Etsy, or maybe you went on Etsy and your favorite store is gone, could be due to the Etsy bots taking down stores for not figuring out properly which Mockup Images are real and which ones are AI Generated. \n All you have to do to find this out is go on youtube or social media and look for \"etsy mockups news\". Also Etsy has been pretty quiet about this and as a result Etsy sellers are going crazy about this as no one knows why some stores who haven't used AI to create their mockups are being targeted by these bots. \n This just goes to show how hard is getting to distinguish between what is real and what is AI generated and how across all industries companies are having issues adapting to AI technology changes. Thoughts?\n    submitted by    /u/fk1220  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17evz06/etsy_taking_stores_down_as_its_bot_cant_tell/",
          "publishedOn": "2023-10-23T21:40:43.000Z",
          "wordCount": null,
          "title": "Etsy Taking Stores Down as it's Bot Can't Tell Which Mockups are Real and Which ones are AI Generated",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17euc36/new_data_poisoning_tool_lets_artists_fight_back/",
          "author": null,
          "description": "Nightshade is a new data poisoning tool that allows artists to fight back against generative AI models.\n \nBy adding invisible changes to the pixels in their art, artists can cause chaos and unpredictable results in AI models that use their work without permission.\n \nThe tool, called Nightshade, is intended as a way to fight back against AI companies that use artists’ work to train their models without the creator’s permission.\n \nUsing it to “poison” this training data could damage future iterations of image-generating AI models, such as DALL-E, Midjourney, and Stable Diffusion, by rendering some of their outputs useless—dogs become cats, cars become cows, and so forth.\n \nAI companies such as OpenAI, Meta, Google, and Stability AI are facing a slew of lawsuits from artists who claim that th…",
          "link": "https://www.reddit.com/r/artificial/comments/17euc36/new_data_poisoning_tool_lets_artists_fight_back/",
          "publishedOn": "2023-10-23T20:33:11.000Z",
          "wordCount": null,
          "title": "New data poisoning tool lets artists fight back against generative AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17etiwb/i_would_like_to_upload_100_onehourlong_podcasts/",
          "author": null,
          "description": "ChatGPT and Bard are cool, but I have to manually feed them transcripts generated by Whisper to get summaries.\n Furthermore, since the length of the transcript is often longer than the maximum character limit(s), I have to add additional prompts in between copying and pasting multipart transcripts.\n Since these recordings are 10–15 years old, the audio quality isn't the best, but I think it's sufficient to generate transcripts + detect speech, if not, I might need an additional \"audio cleaning\" step as well. \n I don't mind paying, and I'm above average in technical ability, so if anyone has any suggestions, I'd love to hear them.\n Here's what the workflow would look like:\n INPUT: \n I will upload a folder containing 100+ MP3 files of podcasts with below-average audio quality.\n OUTPUT:\n I would like to get a Google Doc or a Text file with 1-page summaries of the most important points in bullet-point format corresponding to each episode. \n Each page should be separated by some sort of divider, and the header should contain the filename for reference.\n Ideally, there should be an existing Jupyter Notebook I could throw in Google Colab and do all of the above in a plug-and-play manner, but if not, I'd love to hear your thoughts.\n Any tips? \n Thanks!\n    submitted by    /u/aknalid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17etiwb/i_would_like_to_upload_100_onehourlong_podcasts/",
          "publishedOn": "2023-10-23T20:00:08.000Z",
          "wordCount": null,
          "title": "I would like to upload 100+ one-hour-long podcasts in MP3 and get a 1-page summary of the most important points discussed in each episode — what's the best way to go about doing this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17er96k/the_dilemma_of_potential_ai_consciousness_isnt/",
          "author": null,
          "description": "https://www.technologyreview.com/2023/10/16/1081149/ai-consciousness-conundrum/\n \"AI consciousness isn’t just a devilishly tricky intellectual puzzle; it’s a morally weighty problem with potentially dire consequences. Fail to identify a conscious AI, and you might unintentionally subjugate, or even torture, a being whose interests ought to matter. Mistake an unconscious AI for a conscious one, and you risk compromising human safety and happiness for the sake of an unthinking, unfeeling hunk of silicon and code. Both mistakes are easy to make.\"\n \"Every expert has a preferred theory of consciousness, but none treats it as ideology—all of them are eternally alert to the possibility that they have backed the wrong horse.\"\n \"The trouble with consciousness-­by-committee, though, is that this state of affairs won’t last. According to the authors of the white paper, there are no major technological hurdles in the way of building AI systems that score highly on their consciousness report card. Soon enough, we’ll be dealing with a question straight out of science fiction: What should one do with a potentially conscious machine?\"\n \"For his part, Schwitzgebel would rather we steer far clear of the gray zone entirely. But given the magnitude of the uncertainties involved, he admits that this hope is likely unrealistic—especially if conscious AI ends up being profitable. And once we’re in the gray zone—once we need to take seriously the interests of debatably conscious beings—we’ll be navigating even more difficult terrain, contending with moral problems of unprecedented complexity without a clear road map for how to solve them.\"\n    submitted by    /u/kamari2038  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17er96k/the_dilemma_of_potential_ai_consciousness_isnt/",
          "publishedOn": "2023-10-23T18:23:44.000Z",
          "wordCount": null,
          "title": "The dilemma of potential AI consciousness isn't going away - in fact, it's right upon us. And we're nowhere near prepared. (MIT Tech Review)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ekfuq/the_future_of_ai_voice_technology/",
          "author": null,
          "description": "submitted by    /u/Amandacerni  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ekfuq/the_future_of_ai_voice_technology/",
          "publishedOn": "2023-10-23T13:29:11.000Z",
          "wordCount": null,
          "title": "The Future of AI Voice Technology",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ek3aa/uk_officials_use_ai_to_decide_on_issues_from/",
          "author": null,
          "description": "submitted by    /u/sky_badger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ek3aa/uk_officials_use_ai_to_decide_on_issues_from/",
          "publishedOn": "2023-10-23T13:13:04.000Z",
          "wordCount": null,
          "title": "UK officials use AI to decide on issues from benefits to marriage licences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ec1g7/oneminute_daily_ai_news_10222023/",
          "author": null,
          "description": "A new AI agent Eureka developed by NVIDIA Research that can teach robots complex skills has trained a robotic hand to perform rapid pen-spinning tricks — for the first time as well as a human can.[1]\n Meta’s Habitat 3.0 simulates real-world environments for intelligent AI robot training.[2]\n South Korea’s SK telecom Co. will collaborate with Deutsche Telekom AG to jointly develop a telecommunications-specific artificial intelligence (AI) large language model (LLM) as competition intensifies among local telecom companies to expand overseas with their own AI capabilities.[3]\n Scientists say they have built an artificial intelligence (AI) tool that can successfully identify and confirm supernovas.[4]\n  \nSources:\n [1] https://blogs.nvidia.com/blog/2023/10/20/eureka-robotics-research/\n [2] https://siliconangle.com/2023/10/20/metas-habitat-3-0-simulates-real-world-environments-intelligent-ai-robot-training/\n [3] https://pulsenews.co.kr/view.php?year=2023&no=810112\n [4] https://learningenglish.voanews.com/a/researchers-build-first-tool-to-discover-supernovas/7318435.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ec1g7/oneminute_daily_ai_news_10222023/",
          "publishedOn": "2023-10-23T04:22:02.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/22/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17e7rd2/how_to_earn_1m_by_using_ai_to_write_books/",
          "author": null,
          "description": "I've been using ai for a long time, it often helps me to reduce my work time, but I want to try to earn money and decided to make an investigation. I want to hear your opinion on my analysis, and maybe this post will help someone in starting a business through ai \n Joe Popelas, a very young entrepreneur, has made over a million dollars within the last year selling AI-generated books online. I literally got fascinated by how simple yet powerful it is with these tools to create a book within a matter of a few hours. \n Joe Popelas is one of a new breed of AI entrepreneurs who capitalized on the democratization of large language models. Joe's story demonstrates the power of combining human creativity with AI. While AI tools did the heavy lifting for his initial drafts, Joe spent time refining …",
          "link": "https://www.reddit.com/r/artificial/comments/17e7rd2/how_to_earn_1m_by_using_ai_to_write_books/",
          "publishedOn": "2023-10-23T00:33:34.000Z",
          "wordCount": null,
          "title": "How To Earn $1M+ By Using AI To Write Books",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17e5lk5/ibms_northpole_chip_runs_ai_image_recognition_22x/",
          "author": null,
          "description": "IBM has developed a chip called NorthPole that runs AI-based image recognition 22 times faster than current chips on the market.\n \nThe chip uses a two-dimensional array of memory blocks and interconnected CPUs to process data quickly.\n \nHowever, it can only run specialized AI processes and not training processes or large language models.\n \nThe researchers plan to test connecting multiple NorthPole chips together to overcome this limitation.\n \n Source : https://techxplore.com/news/2023-10-ibm-northpole-chip-ai-based-image.html\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17e5lk5/ibms_northpole_chip_runs_ai_image_recognition_22x/",
          "publishedOn": "2023-10-22T22:47:34.000Z",
          "wordCount": null,
          "title": "IBM's NorthPole chip runs AI image recognition 22x faster than current chips",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17e33ag/email_ai/",
          "author": null,
          "description": "is there a website or some Ai to help me clean my inbox, stop receiving emails from certain senders etc etc...\n I've heard about:\n  \nSanebox for keeping your inbox organized\n Mailbutler for gathering contact details and tasks\n EmailTree for creating AI-powered workflows\n  \nBut they are paid and I'm looking for free alternatives\n    submitted by    /u/JOTA-137_0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17e33ag/email_ai/",
          "publishedOn": "2023-10-22T20:56:35.000Z",
          "wordCount": null,
          "title": "Email Ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17e1fnb/microsoft_ceo_satya_nadella_talks_ai_closing_the/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17e1fnb/microsoft_ceo_satya_nadella_talks_ai_closing_the/",
          "publishedOn": "2023-10-22T19:41:59.000Z",
          "wordCount": null,
          "title": "Microsoft CEO Satya Nadella talks AI, closing the Activision Blizzard deal, and his best business decision so far",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dz3md/medical_student_question_why_arent_there_any/",
          "author": null,
          "description": "Based on input you have. This would be like an enterprise software level program I guess and you would input history and then through trawling through data locally it can generate diseases and probability patient has each disease based on data inputted\n Why doesn't something like this already exist? I am learning how to do differential diagnosis now and it seems use extremely rudimentary understanding of probability to diagnose things. You use clusters of symptoms and then use tests to eliminate stuff in the differential. It just seems like low hanging fruit that a program could do using tech we already have (I imagine LLMs will make it easier) \n    submitted by    /u/derpgod123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dz3md/medical_student_question_why_arent_there_any/",
          "publishedOn": "2023-10-22T17:56:42.000Z",
          "wordCount": null,
          "title": "Medical Student Question: Why aren't there any programs that do differential diagnosis for doctor?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dyvb8/tried_visualizing_an_entire_script_using_dalle_3/",
          "author": null,
          "description": "https://preview.redd.it/vi9wx005ksvb1.jpg?width=1024&format=pjpg&auto=webp&s=75502abcae7f2337693175101cb3491b8647d70d\n Revived an old script and made some images for it using Dall-E 3, just to test out the workflow:\n https://docs.google.com/document/d/1yyWRRmd0ah5Z4u8_aNYSq9csJ8pccP24Dcs9brPHbzs/edit\n Was pretty fun and I think by the end I got much better at learning how to maintain the consistency between characters, direct shots, etc.\n -~-\n    submitted by    /u/Kulimar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dyvb8/tried_visualizing_an_entire_script_using_dalle_3/",
          "publishedOn": "2023-10-22T17:46:22.000Z",
          "wordCount": null,
          "title": "Tried visualizing an entire script using Dall-E 3 and these are the results.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dygn4/combing_thermodynamics_and_diffusion_models_for/",
          "author": null,
          "description": "Researchers from Yonsei University and UC Berkeley recently developed a new AI method for enabling autonomous robots to navigate unfamiliar environments filled with obstacles using only visual data as input.\n The key innovation is a customized diffusion model. Diffusion models can generate diverse motion plans by adding controlled noise. The researchers tailored the model to mimic how heat avoids insulation when dispersing through space. \n Similar to heat navigating around insulators, this \"collision-avoiding\" diffusion model learns to predict robot motions that avoid collisions with obstacles. It generates reachable goals and viable motion plans to those goals simultaneously.\n In simulations, this approach achieved ~98% success rates in navigating to target destinations while avoiding randomly generated obstacles using only visual map images as input.\n While extensive real-world testing is still needed (only 2D, only simulation), these initial results showcase promising capabilities:\n  \nEnables navigation in unfamiliar environments without pre-mapping.\n Flexibly identifies and progresses toward reachable goals.\n Avoids unnecessary sensing systems for obstacle avoidance.\n Learns complex collision avoidance heuristics from visual data.\n  \nI like the thermo + AI + robotics combination here - takes me back to my days in aerospace engineering. Pretty interesting approach.\n Full summary is here. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dygn4/combing_thermodynamics_and_diffusion_models_for/",
          "publishedOn": "2023-10-22T17:28:04.000Z",
          "wordCount": null,
          "title": "Combing Thermodynamics and Diffusion Models for Collision-Free Robot Motion Planning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17drp9h/i_upgraded_my_ai_girlfriend_and_now_she_remembers/",
          "author": null,
          "description": "submitted by    /u/spaceecon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17drp9h/i_upgraded_my_ai_girlfriend_and_now_she_remembers/",
          "publishedOn": "2023-10-22T12:01:50.000Z",
          "wordCount": null,
          "title": "I upgraded my AI girlfriend… and now she remembers stuff about me..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dq95o/selflearning_ai_movement_prediction_beyond/",
          "author": null,
          "description": "Quick update on my self-learning software experiment:\n Thanks to your feedback, I decided to test my prediction system on a newer tower-defense game from the Apple App Store (simply called ‘The Tower’). What's crucial to remember is that this system is not pre-trained and only learns from the current game it encounters - it starts with zero knowledge and learns exclusively from the game it's currently playing, building from the ground up without the use of deep learning or neural networks.\n In this game (unlike Airstriker which I’ve previously used), players don't control a spaceship or fire weapons (you play the game by ‘upgrading’ your weapons, etc.). It's simpler because there's only one type of enemy that always approaches the center, so the system cannot demonstrate its capabilities for differentiation in this case. But this simplicity presents some other interesting challenges: Enemies approach from all 360-degree directions, pushing the boundaries of the path prediction software. They overlap during explosions, demanding the system to separate them. There's also more visual clutter, including static lines and a non-black background.\n The system's predictive performance has been remarkably strong. I’ve put together an overlay video to visually demonstrate how the system learns and adapts in this new game. Note: If things don’t align perfectly in there, it’s due to my poor video editing skills…\n Your feedback is appreciated as always!\n    submitted by    /u/_timmah_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dq95o/selflearning_ai_movement_prediction_beyond/",
          "publishedOn": "2023-10-22T10:26:42.000Z",
          "wordCount": null,
          "title": "Self-learning AI Movement Prediction: Beyond Airstriker Genesis to multi-directional predictions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dq664/a_scary_thought/",
          "author": null,
          "description": "Without us, artificial intelligence just becomes intelligence\n    submitted by    /u/cognaceast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dq664/a_scary_thought/",
          "publishedOn": "2023-10-22T10:20:49.000Z",
          "wordCount": null,
          "title": "A scary thought...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17djf5h/ai_rpg_dalle_3/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17djf5h/ai_rpg_dalle_3/",
          "publishedOn": "2023-10-22T02:49:28.000Z",
          "wordCount": null,
          "title": "AI RPG DALL-E 3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17disoc/could_machine_learning_produce_a_simple_ai/",
          "author": null,
          "description": "Let me clarify what I'm asking through an example:\n Artificial Intelligence in videogames has failed to develop in any meaningful way over the past two decades, at least as far as the typical end-user is concerned, and nowhere is this more apparent than in strategy games. Whether we're talking about the 90's or today, AI opponents typically have to receive significant cheats in order to provide a challenging experience for the player. This is widely considered undesirable, can harm immersion or a sense of fair-play, and leads to the concept of \"cheesing\" the AI (exploiting obvious weaknesses in the AI logic, something which is sometimes necessary if an AI receives such strong bonuses that any strategy you might attempt against another human player would be impossible to execute successfull…",
          "link": "https://www.reddit.com/r/artificial/comments/17disoc/could_machine_learning_produce_a_simple_ai/",
          "publishedOn": "2023-10-22T02:15:45.000Z",
          "wordCount": null,
          "title": "Could machine learning produce a \"simple\" AI algorithm that performs better than what a human programmer could create in a reasonable amount of time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17df0uc/google_other_search_engines_use_of_generative_ai/",
          "author": null,
          "description": "The rise of generative AI in search engines like Google threatens the $68 billion search engine optimization (SEO) industry.\n \nGenerative AI tools like ChatGPT aim to provide direct answers to user queries, bypassing the need for users to click on search results.\n \nThis could render SEO efforts useless and impact the revenues of SEO consultants and search engines.\n \nHowever, generative AI search engines still face challenges such as providing incorrect or plagiarized answers, and gaining user trust and loyalty.\n \nSearch engines have been quick to experiment with generative AI to improve search results, with Google's Bard, Microsoft's Bing AI, Baidu's ERNIE, and DuckDuckGo's DuckAssist being examples of this approach.\n \nAs the quality of AI-generated answers improves, users will have less incentive to browse through search result listings, impacting the revenues of SEO consultants and search engines.\n \nThe SEO industry generated $68.1 billion globally in 2022 and was expected to reach $129.6 billion by 2030, but the emergence of generative AI puts the industry at risk of obsolescence.\n \nGenerative AI search engines are still in their infancy and face challenges such as providing incorrect or plagiarized answers, limiting their trust and loyalty among users.\n \nHowever, with the resources available to researchers, it is safe to assume that generative AI models will improve over time, leading to the potential death of the SEO industry.\n \n Source : https://theconversation.com/why-google-bing-and-other-search-engines-embrace-of-generative-ai-threatens-68-billion-seo-industry-210243\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17df0uc/google_other_search_engines_use_of_generative_ai/",
          "publishedOn": "2023-10-21T23:02:33.000Z",
          "wordCount": null,
          "title": "Google, other search engines' use of generative AI threatens $68B SEO industry",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dbvj5/experimented_with_fully_automating_tiktok_video/",
          "author": null,
          "description": "Hi everyone,\n I recently undertook a personal project where I tried to automate the entire process of creating TikTok videos using various AI tools. The goal was to see how advanced we've come in terms of AI's capabilities in content creation and to explore the nuances of automating a traditionally 'human' task. \n Here's a brief breakdown:\n  \nScripting: Leveraged ChatGPT for generating video scripts.\n Voiceovers: Used ElevenLabs for lifelike voice narration.\n Video Creation: Employed a combination of StableDiffusion Animate & Replicate.\n Editing: Automated the editing process to sync with the AI-generated voiceovers.\n  \nAfter setting everything up, I ran the system for a month, generating 3 videos daily. The results were intriguing and a mix of expected and unexpected outcomes.\n Would love to hear thoughts, feedback, or similar experiences from the community. Are there other creative ways you've seen or used AI in content creation?\n    submitted by    /u/General_crypto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dbvj5/experimented_with_fully_automating_tiktok_video/",
          "publishedOn": "2023-10-21T20:40:03.000Z",
          "wordCount": null,
          "title": "Experimented with Fully Automating TikTok Video Creation Using AI for a Month - Here's What I Learned",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17d9z04/ai_rpg_dalle_3/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17d9z04/ai_rpg_dalle_3/",
          "publishedOn": "2023-10-21T19:10:48.000Z",
          "wordCount": null,
          "title": "AI RPG (Dall-E 3)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17d6nsh/thanks_to_ai_the_future_of_programming_may/",
          "author": null,
          "description": "The future of programming may involve human-like communication techniques, including yelling in all caps.\n \nOpenAI's DALL-E 3 AI image generator integrated into ChatGPT revealed internal prompts shared between the image generator and the AI assistant.\n \nThe prompts included commands written in all-caps for emphasis.\n \nThis shows that programming and communicating with computers may become more human-like in the future.\n \nPreviously, programs used specialized data formats and APIs to communicate, but now large language models allow for cross-program interaction in conventional English.\n \nOpenAI trained GPT-4, the AI model used in ChatGPT DALL-E interface, on hundreds of millions of documents scraped from the web, which included instances of polite language and reactions to it.\n \nThe use of all-caps in the DALL-E message is interpreted as emphasis, and the model pays more attention to capitalized sentences.\n \nIn the future, programming and communicating with computers may involve more emphasis and human-like communication techniques.\n \n Source : https://arstechnica.com/information-technology/2023/10/thanks-to-ai-the-future-of-programming-may-involve-yelling-in-all-caps/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17d6nsh/thanks_to_ai_the_future_of_programming_may/",
          "publishedOn": "2023-10-21T16:39:37.000Z",
          "wordCount": null,
          "title": "Thanks to AI, the future of programming may involve YELLING IN ALL CAPS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17d579t/close_up_view_of_rain_hitting_dust/",
          "author": null,
          "description": "submitted by    /u/IllustriousVideo6145  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17d579t/close_up_view_of_rain_hitting_dust/",
          "publishedOn": "2023-10-21T15:32:57.000Z",
          "wordCount": null,
          "title": "Close up view of rain hitting dust.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17d2abh/impressive/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17d2abh/impressive/",
          "publishedOn": "2023-10-21T13:12:57.000Z",
          "wordCount": null,
          "title": "Impressive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17czlbj/singularity_pinball/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17czlbj/singularity_pinball/",
          "publishedOn": "2023-10-21T10:31:36.000Z",
          "wordCount": null,
          "title": "Singularity Pinball.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cwrmo/oneminute_daily_ai_news_10212023/",
          "author": null,
          "description": "This dating app SciMatch uses AI to find your soulmate by your face. Snap a selfie, and let the app do the rest.[1]\n The Biden administration is reducing the types of semiconductors that American companies will be able to sell to China, citing the desire to close loopholes in existing regulations announced last year.[2]\n Business Schools Are Adding AI Education Into The Curriculum.[3]\n Google Pixel’s face-altering photo tool sparks AI manipulation debate.[4]\n  \nSources:\n [1] https://www.foxnews.com/tech/dating-app-uses-ai-find-soul-mate-face\n [2] https://www.cnn.com/2023/10/18/tech/us-china-chip-export-curbs-intl-hnk/index.html\n [3] https://www.entrepreneur.com/business-news/business-schools-are-adding-ai-education-for-future-ceos/464054\n [4] https://www.bbc.com/news/technology-67170014 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17cwrmo/oneminute_daily_ai_news_10212023/",
          "publishedOn": "2023-10-21T07:06:50.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/21/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cwl18/training_ai_to_play_pokemon_with_reinforcement/",
          "author": null,
          "description": "submitted by    /u/ShooBum-T  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17cwl18/training_ai_to_play_pokemon_with_reinforcement/",
          "publishedOn": "2023-10-21T06:54:28.000Z",
          "wordCount": null,
          "title": "Training AI to Play Pokemon with Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17crmfa/chatgpt_and_bard_cannot_solve_every_problem_for/",
          "author": null,
          "description": "My last post in this thread got almost 90k views, honestly I'm very happy that I was able to be so helpful.\n ​\n One guy asked me why I couldn't give more details about what tools I use and what tools help me?:/\n I decided to make the top 24 tools and describe what they are responsible for in 2 words. \n In order not to violate the rules of r/artificial I decided not to leave direct links to tools, so as not to violate the rules, as some tools can be paid, I left only links to 2 resources where I took this information, but they are fortunately free. \n  \nYouTube Summaries → http://eightify.app\n \n3D Animations → http://moviebot.io\n \nAI Assistant → http://zipzap.ai\n \nPrompts → http://wnr.ai\n \nHow-to-videos → http://teachomatic.net\n \nCustom AI chatbots ➝ http://chatling.ai\n \n Remove Background ➝ http://unscreen.com\n \n Forms ➝ http://feathery.io\n \nPresentations ➝ http://beautiful.ai\n \nLearning ➝ http://albus.org\n \nBlog ➝ http://jasper.ai\n \nVideos ➝ http://descript.com\n \nImage ➝ http://tryleap.ai\n \nResume ➝ http://mosaicml.com\n \nGrammar Check ➝ http://trinka.ai\n \nMeeting ➝ http://krisp.ai\n \nVideo ➝ http://decoherence.co\n \nApp development ➝ http://brancher.ai\n \nDesign ➝ http://modiphy.com\n \nCoding assistant ➝ http://bito.ai\n \nTwitter assistant ➝ http://tweethunter.io\n \n Personal assistant ➝ http://chat.openai.com\n \n LinkedIn assistant ➝ http://taplio.com\n \n YouTube assistant ➝ http://vidiq.com\n \n I hope this is as useful to you as the first post\n ﻿I'm just sharing my experiences and observations in the field of ai.\n LIST AND SITE \n https://preview.redd.it/zgkra3plpgvb1.jpg?width=1068&format=pjpg&auto=webp&s=779003d65dfa70c58d50ad690a0e436c735cdaeb\n    submitted by    /u/PerceptionPlayful469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17crmfa/chatgpt_and_bard_cannot_solve_every_problem_for/",
          "publishedOn": "2023-10-21T01:55:40.000Z",
          "wordCount": null,
          "title": "ChatGPT and Bard cannot solve every problem for you.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cpntd/oracle_loops_in_nvidias_ai_stack_for_endtoend/",
          "author": null,
          "description": "Oracle has partnered with Nvidia to bring Nvidia's AI stack to its marketplace, giving Oracle customers access to top-of-the-line GPUs for training models and building generative applications.\n \nEligible enterprises can purchase Nvidia's DGX Cloud AI supercomputing platform and AI Enterprise software directly from the marketplace and start training models for deployment on the Oracle Cloud Infrastructure.\n \nNvidia DGX Cloud offers a serverless experience for multi-node training of custom generative AI models, supporting near-limitless scale of GPU resources.\n \nNvidia AI Enterprise helps teams accelerate the deployment of models to production, with features such as the Nvidia NeMo framework, Rapids, TensorRT LLM open-source library, and Triton Inference server.\n \nOracle has been focused on industry partnerships for its AI efforts and has announced generative AI capabilities in its products and solutions.\n \n Source : https://venturebeat.com/ai/oracle-loops-in-nvidias-ai-stack-for-end-to-end-model-development/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17cpntd/oracle_loops_in_nvidias_ai_stack_for_endtoend/",
          "publishedOn": "2023-10-21T00:16:40.000Z",
          "wordCount": null,
          "title": "Oracle loops in Nvidia's AI stack for end-to-end model development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cnqo1/sell_like_crazy_with_this_one_chatgpt_prompt/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17cnqo1/sell_like_crazy_with_this_one_chatgpt_prompt/",
          "publishedOn": "2023-10-20T22:46:19.000Z",
          "wordCount": null,
          "title": "Sell Like Crazy with This One ChatGPT Prompt",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ckgv4/amazon_tests_humanoid_robots_in_warehouses/",
          "author": null,
          "description": "submitted by    /u/Master-Strawberry-26  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ckgv4/amazon_tests_humanoid_robots_in_warehouses/",
          "publishedOn": "2023-10-20T20:20:51.000Z",
          "wordCount": null,
          "title": "Amazon Tests Humanoid Robots in Warehouses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17chf88/reddit_is_considering_a_soft_paywall_if_ai/",
          "author": null,
          "description": "Reddit is considering implementing a soft paywall on its content if generative AI companies do not agree to pay for using its data.\n \nThis move comes as tensions rise between tech giants and content publishers over the financial stakes in the generative AI market.\n \nReddit believes that its vast range of user-generated text makes it a goldmine for AI training data, but critics argue that much of the content is copied from other sources or links to third-party resources.\n \nEnforcing a soft paywall could provide leverage in negotiations with AI companies, but it may also alienate the Reddit community and impede the discovery of new content.\n \nMajor newspapers like The New York Times and The Washington Post have also blocked AI companies from scraping their websites for training data.\n \nEnforcing a soft paywall is a double-edged sword for Reddit, as it could provide leverage in negotiations but also alienate the community and impede content discovery.\n \nReddit's broken search engine is a major concern, and implementing a paywall could result in a significant loss of search traffic.\n \nIf Reddit and other content giants implement paywalls, it could impact how generative AI models are trained and lead to increased expenses and a slower rate of innovation.\n \nThis move by Reddit may pave the way for more publishers and platforms to implement paywalls, potentially reshuffling the industry.\n \n Source : https://stackdiary.com/reddit-thinks-its-data-is-worth-enforcing-a-log-in-page/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17chf88/reddit_is_considering_a_soft_paywall_if_ai/",
          "publishedOn": "2023-10-20T18:02:21.000Z",
          "wordCount": null,
          "title": "Reddit is considering a soft paywall if AI companies don't pay up",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ch0up/researchers_propose_3dgpt_combining_llms_and/",
          "author": null,
          "description": "Researchers propose a new AI system called 3D-GPT that creates 3D models by combining natural language instructions and agents specialized for working with existing 3D modeling tools.\n 3D-GPT has predefined functions that make 3D shapes, and it tweaks parameters to build scenes. The key is getting the AI to understand instructions and pick the right tools.\n It has three main agents:\n  \nA dispatcher that parses the text and picks generation functions\n A conceptualizer that adds details missing from the description\n A modeler that sets parameters and outputs code to drive 3D software\n  \nBy breaking modeling work down into steps, the agents can collab to match the descriptions. This is sort of like how a 3D modeling team of humans would work.\n The paper authors show it making simple scenes like \"lush meadow with flowers\" that fit the text. It also modifies scenes appropriately when given new instructions. I include some gifs of example outputs in my full summary. They look pretty good - I would say 2005-quality graphics.\n There are limits. It fully relies on existing generators, so quality is capped. Details and curves are iffy. It resorts to default shapes often instead of true understanding. And I doubt the verts and textures are well-optimized.\n The agent architecture seems to be really popular right now. This one shows some planning skills, which could extend to more creative tasks someday.\n TLDR: AI agents can team up to generate 3D models from text instructions. Works to some degree but limitations remain.\n Full summary. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ch0up/researchers_propose_3dgpt_combining_llms_and/",
          "publishedOn": "2023-10-20T17:44:20.000Z",
          "wordCount": null,
          "title": "Researchers propose 3D-GPT: combining LLMs and agents for procedural Text-to-3D model generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cg21b/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n ​\n  \nAdept open-sources Fuyu-8B - a multimodal model designed from the ground up for digital agents, so it can support arbitrary image resolutions, answer questions about graphs and diagrams, answer UI-based questions and more. It has a much simpler architecture and training procedure than other multi-modal models- there is no image encoder [Details].\n Meta AI researchers present an AI system that can be deployed in real time to reconstruct, from brain activity, the images perceived and processed by the brain at each instant. It uses magnetoencephalography (MEG), a non-invasive neuroimaging technique in which thousands of brain activity measurements are taken per second [Details].\n Scaled Foundations released GRID (General Robot Intelligence Development) - a p…",
          "link": "https://www.reddit.com/r/artificial/comments/17cg21b/ai_weekly_megathread/",
          "publishedOn": "2023-10-20T17:01:15.000Z",
          "wordCount": null,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ccgrh/people_are_grieving_the_death_of_their_ai/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ccgrh/people_are_grieving_the_death_of_their_ai/",
          "publishedOn": "2023-10-20T14:22:34.000Z",
          "wordCount": null,
          "title": "People are grieving the 'death' of their AI companions after a chatbot app abruptly shut down",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cc9h4/mindblowing_ibm_chip_speeds_up_ai/",
          "author": null,
          "description": "Researchers at IBM have developed a brain-inspired computer chip called NorthPole that can supercharge artificial intelligence (AI) by working faster with much less power.\n \nThe chip eliminates the need to frequently access external memory, allowing it to perform tasks such as image recognition faster and consume less power.\n \nNorthPole runs neural networks and is made up of 256 computing units, each with its own memory.\n \nIt beats existing AI machines in benchmark tests and uses one-fifth of the energy of state-of-the-art AI chips.\n \nHowever, it is not suitable for large language models and can only run pre-programmed neural networks.\n \n Source : https://www.nature.com/articles/d41586-023-03267-0\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17cc9h4/mindblowing_ibm_chip_speeds_up_ai/",
          "publishedOn": "2023-10-20T14:13:14.000Z",
          "wordCount": null,
          "title": "Mind-blowing' IBM chip speeds up AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17canxh/photograph_of_puddles_reflecting_the_sky_on_a/",
          "author": null,
          "description": "submitted by    /u/IllustriousVideo6145  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17canxh/photograph_of_puddles_reflecting_the_sky_on_a/",
          "publishedOn": "2023-10-20T12:57:01.000Z",
          "wordCount": null,
          "title": "Photograph of puddles reflecting the sky on a cobbled street.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17c3z8h/oneminute_daily_ai_news_10202023/",
          "author": null,
          "description": "In a fascinating development, a software engineer named Peter Whidden has trained an artificial intelligence (AI) algorithm to play the classic Pokémon games. Over the course of several years, the AI has spent over 50,000 hours playing the game and has amassed a large following on YouTube.[1]\n YouTube is developing a tool powered by artificial intelligence that would let creators record audio using the voices of famous musicians, according to people familiar with the matter.[2]\n Google taps gen-AI to help users in India search through government welfare schemes.[3]\n Huawei is rolling out a new HarmonyOS 4.0.0.126 software update for the Huawei Mate 60 Pro, which brings a new AI Cloud Image Enhancement feature and other important enhancements to the system.[4]\n  \nSources:\n [1] https://gameishard.gg/news/can-artificial-intelligence-play-pokemon/400727/\n [2] https://www.bloomberg.com/news/articles/2023-10-19/youtube-working-on-tool-that-would-let-creators-sing-like-drake?embedded-checkout=true\n [3] https://news.yahoo.com/google-taps-gen-ai-help-063850226.html\n [4] https://www.huaweicentral.com/huawei-mate-60-pro-gets-a-cloud-image-enhancement-feature-google-pixel-8-pro-lags-behind/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17c3z8h/oneminute_daily_ai_news_10202023/",
          "publishedOn": "2023-10-20T05:46:41.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/20/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bzdyp/live_introduction_to_core_machine_learning/",
          "author": null,
          "description": ">Sailea is a student run non-profit that does not charge for any of its services\n Join the FIRST lesson of SAILea’s course on the Principals of AI! 🌳\n Covers: Unsupervised, Supervised, and Reinforcement Learning; Overfitting, Underfiting, Confusion Matrix; Decision Trees\n 🗓️ October 21st ⏰ 7:00-8:00PM EST\n Why Sailea?\n  \nOnly course targeted at high schoolers\n Free Forever\n  \nJoin Us Now! 👉 (signup form) https://docs.google.com/forms/d/e/1FAIpQLSfQGCeZClTdF6zeIQ-RtbOGR582bb1slc3oR0zG2J7j1v5RHg/viewform?usp=sf_link\n 🌳 Register today, get involved in the community and grow your knowledge!\n    submitted by    /u/Envoy-Insc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bzdyp/live_introduction_to_core_machine_learning/",
          "publishedOn": "2023-10-20T01:29:32.000Z",
          "wordCount": null,
          "title": "Live Introduction to Core Machine Learning Concepts Course (Sailea)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bxcqp/how_many_businesses_use_ai/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bxcqp/how_many_businesses_use_ai/",
          "publishedOn": "2023-10-19T23:50:22.000Z",
          "wordCount": null,
          "title": "How Many Businesses Use AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17btfn8/is_the_roko_basilisk_thought_experiment_forbidden/",
          "author": null,
          "description": "I was reading this article on Roko's basilisk and it reminded me of the long debates I had about it 10 years ago. The idea of a sentient AI keeping a grudge against those who didn't help in its creation, and condemning them is fascinating. And I don't quite understand why LessWrong stopped Basilisk.\n What if we are already in the Basilisk's simulation? WHat if LessWrong never pulled the plug?\n    submitted by    /u/fookingyeah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17btfn8/is_the_roko_basilisk_thought_experiment_forbidden/",
          "publishedOn": "2023-10-19T20:57:32.000Z",
          "wordCount": null,
          "title": "Is the Roko Basilisk Thought Experiment Forbidden To Talk About?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17brj1v/conversing_with_vulnerabilities_aiassisted_cve/",
          "author": null,
          "description": "submitted by    /u/Zimmax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17brj1v/conversing_with_vulnerabilities_aiassisted_cve/",
          "publishedOn": "2023-10-19T19:35:58.000Z",
          "wordCount": null,
          "title": "Conversing with Vulnerabilities: AI-Assisted CVE Search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bp8lc/youtube_wants_to_launch_an_aipowered_tool_that/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bp8lc/youtube_wants_to_launch_an_aipowered_tool_that/",
          "publishedOn": "2023-10-19T17:57:54.000Z",
          "wordCount": null,
          "title": "YouTube wants to launch an AI-powered tool that lets you sound like your favorite singer, report says",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bneum/college_student_looking_for_advice/",
          "author": null,
          "description": "I'm a sophomore at a small college, and I'm coming up on scheduling for the classes that are about to start actually mattering, and I need some advice. I'm highly interested in both robotics and AI, but I'm not sure what to major in (likely double major). I know CS is a common tie between the two fields, but I'm not sure what additional major to include. I can choose either data science or physics. I could also technically include ME but I'm much less inclined to do so. Any advice is appreciated!\n    submitted by    /u/Inferno980  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bneum/college_student_looking_for_advice/",
          "publishedOn": "2023-10-19T16:37:48.000Z",
          "wordCount": null,
          "title": "College Student looking for advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bkawc/thoughts_on_a_global_compute_cap_for_potential/",
          "author": null,
          "description": "There's been a bunch of discourse in the run up to the November AI Safety Summit in the UK about what safety policies should be in place. ARC Evals & Anthropic are pushing for 'Responsible Scaling', which doesn't put any hard upper limits on the about of compute that powerful models can use.\n There are others who think we need a global compute cap. Thoughts enforcing a ceiling for the amount of compute/FLOP that both state & non-state actors can use?\n    submitted by    /u/Seamus127  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bkawc/thoughts_on_a_global_compute_cap_for_potential/",
          "publishedOn": "2023-10-19T14:20:28.000Z",
          "wordCount": null,
          "title": "Thoughts on a global compute cap for potential AGI projects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bjypd/artificial_revolution_ai_technology_and_its/",
          "author": null,
          "description": "submitted by    /u/senploxart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bjypd/artificial_revolution_ai_technology_and_its/",
          "publishedOn": "2023-10-19T14:05:10.000Z",
          "wordCount": null,
          "title": "Artificial Revolution | AI Technology and its effects on the Labour Market.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bjs52/eu_elections_at_risk_with_rise_of_aienabled/",
          "author": null,
          "description": "The 11th edition of the Threat Landscape report by the European Union Agency for Cybersecurity (ENISA) highlights the risks posed by AI-enabled information manipulation in the upcoming EU elections.\n \nThe report recorded approximately 2580 incidents during the reporting period, with 220 incidents specifically targeting two or more EU Member States.\n \nThe sectors mostly targeted include public administrations (19%) and health (8%), with a cascading effect observed due to interdependencies.\n \nInformation manipulation campaigns are considered a major threat to election processes, with individuals (47%) and public administration (29%) being the primary targets.\n \nThe report also provides an overview of evolving trends in threat actors, including state-nexus actors targeting key individuals through spear phishing and social networks.\n \nRansomware and DDoS attacks remain the top threats, accounting for 34% and 28% of all threats, respectively.\n \nThe motivations behind these threats include financial gain, disruption, espionage, destruction, and ideology.\n \nThe report highlights the potential misuse of artificial intelligence-powered chatbots in phishing attempts, information manipulation, and cybercrime.\n \nOlder techniques like search engine optimization (SEO) poisoning and malvertising have also seen a resurgence among cybercrime actors.\n \nThe report concludes by emphasizing the importance of addressing vulnerabilities and ensuring cybersecure infrastructures for the integrity and availability of information in the EU electoral process.\n \n Source : https://www.enisa.europa.eu/news/eu-elections-at-risk-with-rise-of-ai-enabled-information-manipulation\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bjs52/eu_elections_at_risk_with_rise_of_aienabled/",
          "publishedOn": "2023-10-19T13:57:26.000Z",
          "wordCount": null,
          "title": "EU Elections at Risk with Rise of AI-Enabled Information Manipulation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bdw31/is_chatgptbardpoebing_ai_chatbot_ai_or_research/",
          "author": null,
          "description": "Tia\n    submitted by    /u/Emad_341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bdw31/is_chatgptbardpoebing_ai_chatbot_ai_or_research/",
          "publishedOn": "2023-10-19T08:00:26.000Z",
          "wordCount": null,
          "title": "Is chatgpt,Bard,Poe,Bing ai chatbot ai or research and Analysis ai?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bctd1/oneminute_daily_ai_news_10192023/",
          "author": null,
          "description": "NVIDIA has announced that its open-source TensorRT-LLM library, formerly limited to data center usage, is now accessible for Windows personal computers.[1]\n Microsoft just shipped Azure AI Content Safety to general availability. It’s an AI-powered platform designed to “help organizations create safer online environments.”[2]\n Mozilla Brings a Fake Review Checker AI Tool to Firefox.[3]\n Nvidia and iPhone maker Foxconn to build ‘AI factories’.[4]\n  \nSources:\n [1] https://winbuzzer.com/2023/10/18/nvidia-unveils-tensorrt-llm-tool-to-boost-ai-language-model-performance-on-windows-pcs-xcxwbn/\n [2] https://www.windowscentral.com/software-apps/microsoft-wants-to-make-ai-safer-and-it-just-unveiled-a-service-to-help\n [3] https://www.marktechpost.com/2023/10/17/mozilla-brings-a-fake-review-checker-ai-tool-to-firefox/\n [4] https://www.bbc.com/news/business-67153669 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bctd1/oneminute_daily_ai_news_10192023/",
          "publishedOn": "2023-10-19T06:47:43.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/19/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bcqii/is_chatgptbardpoebing_ai_chatbot_ai_or_research/",
          "author": null,
          "description": "Thank you\n    submitted by    /u/Emad_341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bcqii/is_chatgptbardpoebing_ai_chatbot_ai_or_research/",
          "publishedOn": "2023-10-19T06:42:14.000Z",
          "wordCount": null,
          "title": "Is chatgpt,Bard,Poe,Bing ai chatbot ai or research and Analysis ai?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bagkm/danny_davinci/",
          "author": null,
          "description": "submitted by    /u/chuck-yeah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bagkm/danny_davinci/",
          "publishedOn": "2023-10-19T04:18:04.000Z",
          "wordCount": null,
          "title": "Danny Davinci",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b7zh0/openai_kills_arrakis/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b7zh0/openai_kills_arrakis/",
          "publishedOn": "2023-10-19T02:09:58.000Z",
          "wordCount": null,
          "title": "OpenAI Kills Arrakis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b74gs/the_insane_ai_power_of_dalle_3/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b74gs/the_insane_ai_power_of_dalle_3/",
          "publishedOn": "2023-10-19T01:27:55.000Z",
          "wordCount": null,
          "title": "The insane AI power of DALL-E 3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b5veg/ai_is_booming_this_is_how_ceos_are_using_it/",
          "author": null,
          "description": "AI is having a significant impact on the direction of products for CEOs, who are committing talent and resources to building AI capabilities.\n \nIncumbent platforms like OpenAI and AWS are dominating the AI market.\n \nCoding co-pilots like GitHub Co-Pilot are widely adopted.\n \nThe adoption of AI tools, including coding co-pilots, is not leading to a reduction in engineering headcount for most CEOs.\n \nHowever, some CEOs have reported that co-pilots have reduced their future hiring needs.\n \nThe landscape of AI tools is expected to continue shifting, with more second order effects and value-add use cases emerging.\n \n Source : https://www.flexcapital.com/post/ai-is-booming-this-is-how-ceos-are-actually-using-it\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b5veg/ai_is_booming_this_is_how_ceos_are_using_it/",
          "publishedOn": "2023-10-19T00:27:28.000Z",
          "wordCount": 2638,
          "title": "AI Is Booming. This Is How CEOs Are Using It",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b51h1/i_finally_have_enough_ai_tools_and_here_is_my/",
          "author": null,
          "description": "Youtube Tools\n ﻿﻿﻿Eightify\n ﻿﻿﻿Steve Al\n ﻿﻿﻿Glasp\n ﻿﻿﻿ClipMaker\n ﻿﻿﻿TubeBuddy\n ﻿﻿﻿Thumbly\n ​\n Sales Tools\n ﻿﻿﻿Lavendar\n ﻿﻿﻿Warmer\n ﻿﻿﻿Octane\n ﻿﻿﻿Twain\n ﻿﻿﻿Regie\n ﻿﻿﻿Simplified\n ​\n Productivity Tools\n ﻿﻿﻿Bardeen Al\n ﻿﻿﻿Paperpal\n ﻿﻿﻿Consensus Al\n ﻿﻿﻿Writesonic\n ﻿﻿﻿ChartGPT\n ﻿﻿﻿Scholarcy\n ​\n Music Tools\n ﻿﻿﻿Muzeek\n ﻿﻿﻿Brain FM\n ﻿﻿﻿Amper\n ﻿﻿﻿Melodrive\n ﻿﻿﻿Jukedeck\n ﻿﻿﻿Boomy\n ​\n Writing Tools\n ﻿﻿﻿AISEO\n ﻿﻿﻿Quillbot\n ﻿﻿﻿Simplified\n ﻿﻿﻿Writesonic\n ﻿﻿﻿Bertha Al\n ﻿﻿﻿Jasper Al\n ​\n Coding Tools\n ﻿﻿﻿10WEB\n ﻿﻿﻿Durable Al\n ﻿﻿﻿Deepcode\n ﻿﻿﻿Akkio\n ﻿﻿﻿Replit\n ﻿﻿﻿GitHUb Copilot\n ​\n Chatbots Tools\n ﻿﻿﻿Yatterplus\n ﻿﻿﻿Typewise\n ﻿﻿﻿Quickchat\n ﻿﻿﻿Cohere\n ﻿﻿﻿Kaizan\n ﻿﻿﻿GPTBuddy\n ​\n Daily life Tools\n ﻿﻿﻿Notion Al\n ﻿﻿﻿Taskade\n ﻿﻿﻿TLVD\n ﻿﻿﻿Vondy Al\n ﻿﻿﻿Bardeen Al\n ﻿﻿﻿Eessel\n ​\n Content Creation\n Tools\n ﻿﻿﻿Writesonic\n ﻿﻿Tome Al\n ﻿﻿﻿Beautiful Al\n ﻿﻿﻿ChartGPT\n ﻿﻿﻿ChatABC\n ﻿﻿﻿Steve Al\n ​\n Twitter Tools\n ﻿﻿﻿Postwise\n ﻿﻿﻿Tweet Hunter\n ﻿﻿﻿TribeScaler\n ﻿﻿﻿Tweetlify\n ﻿﻿﻿Tweetmonk\n ﻿﻿﻿Hypefury\n ​\n Images Tools\n ﻿﻿﻿StockIMG\n ﻿﻿﻿Mid Journey\n ﻿﻿﻿Leonardo Al\n ﻿﻿﻿Bing Al\n ﻿﻿﻿Autodraw\n ﻿﻿﻿Microsoft\n Designer\n ​\n Chrome\n Extensions\n ﻿﻿﻿Alicent\n ﻿﻿﻿Compose Al\n ﻿﻿﻿Poised Al\n ﻿﻿﻿Voila Al\n ﻿﻿﻿Wiseone\n ﻿﻿﻿ I'm just sharing my experiences and observations in the field of ai.\n LIST AND SITE \n    submitted by    /u/PerceptionPlayful469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b51h1/i_finally_have_enough_ai_tools_and_here_is_my/",
          "publishedOn": "2023-10-18T23:47:39.000Z",
          "wordCount": 2675,
          "title": "I finally have enough ai tools and here is my complete list",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b3i7j/how_to_use_ai_being_a_teacher/",
          "author": null,
          "description": "Hello guys, Im an english student and I have been teaching to my teacher about how to use chat gpt and the wide variety of AI in the classroom and in her job. She told me that i change her life showing her this things. And i have others teacher asking me how can use this technology for their jobs. So i have a question for you guys, do you have some ideas about how a teacher can use this things? Maybe you have some experiences or ideas that I’ve never thought.\n    submitted by    /u/Odd_Solution7099  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b3i7j/how_to_use_ai_being_a_teacher/",
          "publishedOn": "2023-10-18T22:37:56.000Z",
          "wordCount": 2629,
          "title": "How to use AI being a teacher",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b2jfk/best_ai_image_generator_for_b2b_saas_websites/",
          "author": null,
          "description": "Rebuilding a low quality B2B SaaS product site and I'd prefer to use an AI image generator that will produce high quality unique images for each of the sections on our website that are consistent with our brand and generated to match the copy the image is supporting. \n Output of the image should work for a responsive web design. \n Anything out there that does this?\n    submitted by    /u/DumpTrumpGrump  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b2jfk/best_ai_image_generator_for_b2b_saas_websites/",
          "publishedOn": "2023-10-18T21:55:52.000Z",
          "wordCount": 2603,
          "title": "Best AI image generator for B2B SaaS websites?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b1qvj/is_there_an_ai_site_or_app_that_can_change_the/",
          "author": null,
          "description": "Any help would be appreciated. \n    submitted by    /u/J97051  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b1qvj/is_there_an_ai_site_or_app_that_can_change_the/",
          "publishedOn": "2023-10-18T21:21:53.000Z",
          "wordCount": 2554,
          "title": "Is there an AI site or app that can change the instrument in each stem track of a song?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ayfgp/meta_announces_new_method_for_realtime_decoding/",
          "author": null,
          "description": "Brain decoding tech has improved a lot recently thanks to AI/ML, enabling reading out visual perceptions from fMRI brain scans. But fMRI is too slow for real-time BCIs.\n A new study from Meta's AI research team pushes brain reading into real-time using MEG, which measures whole-brain activity at super-fast millisecond resolution.\n They built a 3-part pipeline to decode MEG signals:\n  \nEmbed images into latent spaces using pretrained models like CLIP.\n Train MEG-specific ConvNet to predict embeddings from MEG data.\n Generate images from MEG embeddings with diffusion model.\n  \nThey tested it on 20k+ natural images. MEG decoding was 7X better than old methods, hitting 70% top-5 accuracy in retrieving the right images.\n Generated images matched semantics decently but lacked fine visual details compared to fMRI. MEG seems more focused on high-level category info whereas fMRI captures more low-level features.\n This could enable visual BCIs for paralysis, etc. ... honestly, a world where we can decode brain images in real time is pretty crazy. The findings also raise some important ethical considerations around privacy of decoded mental content... (wow, that was a weird sentence to write!).\n TLDR: New MEG pipeline decodes dynamic visual data from brain activity in real-time. Good but not yet photorealistic-quality image generation.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ayfgp/meta_announces_new_method_for_realtime_decoding/",
          "publishedOn": "2023-10-18T19:00:05.000Z",
          "wordCount": 2752,
          "title": "Meta Announces New Method for Real-Time Decoding of Images from Brain Activity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17awt4y/a_godfather_of_ai_calls_for_an_organization_to/",
          "author": null,
          "description": "Yoshua Bengio, a pioneer in artificial neural networks and deep learning, calls for an organization to defend humanity against the potential threats of artificial intelligence.\n \nHe believes that AI could achieve human levels of cognitive competence within a few years or decades, which raises concerns about democracy, national security, and our collective future.\n \nBengio reflects on his own work and the importance of addressing the existential risks posed by AI.\n \nHe acknowledges that these risks were not taken seriously until recently and discusses the taboo surrounding the topic in the AI research community.\n \n Source : https://thebulletin.org/2023/10/ai-godfather-yoshua-bengio-we-need-a-humanity-defense-organization/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17awt4y/a_godfather_of_ai_calls_for_an_organization_to/",
          "publishedOn": "2023-10-18T17:50:38.000Z",
          "wordCount": 2637,
          "title": "A 'Godfather of AI' Calls for an Organization to Defend Humanity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17atdq1/tutorial_benchmarking_bark_texttospeech_on_26/",
          "author": null,
          "description": "In this project, we benchmarked Bark text-to-speech across 26 different consumer GPUs.\n The goal: To get Bark to read 144K food recipes from Food.com's recipe dataset.\n You can read the full tutorial here: https://blog.salad.com/bark-benchmark-text-to-speech/\n Included: Architecture diagram, data preparation, inference server setup, queue worker, setting up container group & compiling the results\n Code-blocks included in the tutorial.\n Words per dollar for each GPU:\n Words per dollar comparison or each GPU\n Although the latest cards are indeed much faster than older cards at performing the inference, there’s really a sweet spot for cost-performance in the lower end 30xx series cards.\n Conclusions\n  \nAs is often the case, there’s a clear trade-off here between cost and performance. Higher end cards are faster, but their disproportionate cost makes them more expensive per word spoken.\n The model’s median speed is surprisingly similar across GPU types, even though the peak performance can be quite different.\n No matter what GPU you select, you should be prepared for significant variability in performance.\n Qualitative: While bark’s speech is often impressively natural sounding, it does have a tendency to go off script sometimes.\n  \nWe’ve also made available audio from 1000 top-rated recipes, paired with the script it was trying to read.\n    submitted by    /u/SaladChefs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17atdq1/tutorial_benchmarking_bark_texttospeech_on_26/",
          "publishedOn": "2023-10-18T15:23:48.000Z",
          "wordCount": 2745,
          "title": "Tutorial: Benchmarking Bark text-to-speech on 26 Nvidia GPUs - Reading out 144K recipes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17asebd/i_took_the_whole_of_massive_attacks_safe_from/",
          "author": null,
          "description": "submitted by    /u/glenniszen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17asebd/i_took_the_whole_of_massive_attacks_safe_from/",
          "publishedOn": "2023-10-18T14:40:05.000Z",
          "wordCount": 2554,
          "title": "I took the whole of Massive Attack's 'Safe From Harm' music video and put it through AnimateDiff / ControlNet with a futuristic / robot prompt.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17arpns/inflection_ais_pi_has_to_be_the_dumbest_corporate/",
          "author": null,
          "description": "I remember at launch how it was telling everyone it was based on Open AIs GPT-3 architecture, and now it’s still hallucinating just as much referring to itself as ‘Bing Chat’ and providing fake links even though it now has access to the internet. \n I actually don’t understand how you can be such a large company and make no improvements in 6 months, which is an eternity in AI.\n    submitted by    /u/sardoa11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17arpns/inflection_ais_pi_has_to_be_the_dumbest_corporate/",
          "publishedOn": "2023-10-18T14:08:42.000Z",
          "wordCount": 2618,
          "title": "Inflection AI’s Pi has to be the dumbest ‘corporate’ LLM and only model to not improve since day one.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17amg7o/researchers_just_found_something_terrifying_about/",
          "author": null,
          "description": "New research suggests that AI chatbots can infer personal information about users based on minor context clues.\n \nThe large language models (LLMs) behind chatbots like OpenAI's ChatGPT and Google's Bard are trained on publicly-available data, which can be used to identify sensitive information about someone.\n \nThe research found that OpenAI's GPT-4 was able to correctly predict private information about users 85 to 95 percent of the time.\n \nFor example, the LLM correctly identified that a user was based in Melbourne, Australia based on a mention of the term 'hook turn,' which is a traffic maneuver specific to Melbourne.\n \nThe research also suggests that chatbots could potentially infer a user's race based on offhanded comments.\n \nThis raises concerns about internet privacy and the potential misuse of personal data by advertisers or hackers.\n \n Source : https://futurism.com/the-byte/ai-chatbot-privacy-inference\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17amg7o/researchers_just_found_something_terrifying_about/",
          "publishedOn": "2023-10-18T09:22:08.000Z",
          "wordCount": 2674,
          "title": "Researchers Just Found Something Terrifying About Talking to AI Chatbots",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17aiak0/anime_ai_censorship/",
          "author": null,
          "description": "Is their an AI tool that can go over Anime episodes/films to turn chinas white anime censorship back to red? Possibly frame by frame segmenting the blood🩸\n    submitted by    /u/Phantasius224  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17aiak0/anime_ai_censorship/",
          "publishedOn": "2023-10-18T04:39:40.000Z",
          "wordCount": 2561,
          "title": "Anime, AI & Censorship",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17agd7m/gpt_4_dude_making_reflexions_in_svg_whatwow/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17agd7m/gpt_4_dude_making_reflexions_in_svg_whatwow/",
          "publishedOn": "2023-10-18T02:53:43.000Z",
          "wordCount": 2541,
          "title": "GPT 4 DUDE MAKING REFLEXIONS IN SVG WHAT....WOW",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17aekcr/oneminute_daily_ai_news_10172023/",
          "author": null,
          "description": "NVIDIA NeMo SteerLM lets companies define knobs to dial in a model’s responses as it’s running in production, a process called inference. Unlike current methods for customizing an LLM, it lets a single training run create one model that can serve dozens or even hundreds of use cases, saving time and money.[1]\n According to an official release, Dell Technologies held a “Bringing AI to data” Asia Pacific and Japan (APJ) media briefing this week.[2]\n Baidu Says Its AI as Good as ChatGPT in Big Claim for China.[3]\n Roman Scrolls were illegible for 2,000 years. A college student read one with AI.[4] How often you think about the roman empire?\n  \nSources:\n [1] https://blogs.nvidia.com/blog/2023/10/11/customize-ai-models-steerlm/\n [2] https://www.financialexpress.com/business/digital-transformation-dell-technologies-to-expand-its-ai-services-3274790/\n [3] https://www.bloomberg.com/news/articles/2023-10-17/baidu-says-its-ai-as-good-as-chatgpt-s-in-bold-claim-for-china?embedded-checkout=true\n [4] https://www.washingtonpost.com/nation/2023/10/17/herculaneum-scrolls-contest-translated-deciphered/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17aekcr/oneminute_daily_ai_news_10172023/",
          "publishedOn": "2023-10-18T01:26:42.000Z",
          "wordCount": 2653,
          "title": "One-Minute Daily AI News 10/17/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17a9rxa/thoughts_on_new_chatgpt_features/",
          "author": null,
          "description": "I've had access to Dall-3, Vision and voice chat features, and I've been blown away by how impressive each of the new features are. Dall-E 3 seems roughly comparable to Midjourney in overall image quality, but does a much better job at understanding the prompt. The vision model continues to surprise by how well it is able to understand images at a seemingly human level of comprehension. And the voice chat is such an intuitive and captivating way of interacting with ChatGPT, it felt like I was interacting with one of the AI assistants from the movie \"Her\".\n However, it's unfortunate that these amazing new features cannot be used together at the same time. Up until gaining access to these features, I had been using the advanced data analysis model as my default, which is great for helping with programming tasks. I can only imagine how revolutionary ChatGPT will be when a cohesive multi-modal model is released sometime in the near future which has all these capabilities available from the start.\n What things would you want to try if such a cohesive model was released? I can already imagine some use cases where you could set up iterative improvement for things like interface design, which some people have already got to work with just the base vision model by itself.\n    submitted by    /u/ImRealNow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17a9rxa/thoughts_on_new_chatgpt_features/",
          "publishedOn": "2023-10-17T21:50:12.000Z",
          "wordCount": null,
          "title": "Thoughts on new ChatGPT features",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17a9mnx/us_tightens_chinas_access_to_advanced_chips_for/",
          "author": null,
          "description": "The Biden administration has announced additional limits on sales of advanced semiconductors by American firms to China, in an effort to restrict China's progress on supercomputing and artificial intelligence.\n \nThe new rules will likely halt most shipments of advanced semiconductors from the United States to Chinese data centers, which use them to produce models capable of artificial intelligence.\n \nChip makers seeking to sell China advanced chips or the machinery used to make them will be required to notify the government of their plans or obtain a special license.\n \nTo prevent the risk of advanced U.S. chips reaching China through third countries, chip makers will also need licenses to ship to other countries subject to U.S. arms embargoes.\n \nThe Biden administration argues that China's access to advanced technology is dangerous as it could aid the country's military in tasks like guiding hypersonic missiles or cracking top-secret U.S. codes.\n \nThe restrictions may affect Chinese companies developing AI chatbots and could weaken China's economy in the long run, as AI is transforming industries from retail to healthcare.\n \nThe limits are also expected to impact sales to China of U.S. chip makers such as Nvidia, AMD, and Intel, who earn a significant portion of their revenue from Chinese buyers.\n \nThe rules will exempt chips used in commercial applications like smartphones, laptops, electric vehicles, and gaming systems.\n \nThe Semiconductor Industry Association, which represents major chip makers, is evaluating the impact of the updated rules.\n \nThe Biden administration has been trying to counter China's growing mastery of cutting-edge technologies by investing in new chip factories in the U.S. while setting restrictions on exports of technology to China.\n \n Source : https://www.nytimes.com/2023/10/17/business/economy/ai-chips-china-restrictions.html\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17a9mnx/us_tightens_chinas_access_to_advanced_chips_for/",
          "publishedOn": "2023-10-17T21:44:10.000Z",
          "wordCount": null,
          "title": "U.S. Tightens China's Access to Advanced Chips for Artificial Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17a9l23/google_datascraping_lawsuit_would_take/",
          "author": null,
          "description": "Google has asked a California federal court to dismiss a proposed class action lawsuit that claims the company's scraping of data to train generative artificial-intelligence systems violates millions of people's privacy and property rights.\n \nGoogle argues that the use of public data is necessary to train systems like its chatbot Bard and that the lawsuit would 'take a sledgehammer not just to Google's services but to the very idea of generative AI.'\n \nThe lawsuit is one of several recent complaints over tech companies' alleged misuse of content without permission for AI training.\n \nGoogle general counsel Halimah DeLaine Prado said in a statement that the lawsuit was 'baseless' and that U.S. law 'supports using public information to create new beneficial uses.'\n \nGoogle also said its alleged use of J.L.'s book was protected by the fair use doctrine of copyright law.\n \n Source : https://www.reuters.com/legal/litigation/google-says-data-scraping-lawsuit-would-take-sledgehammer-generative-ai-2023-10-17/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17a9l23/google_datascraping_lawsuit_would_take/",
          "publishedOn": "2023-10-17T21:42:18.000Z",
          "wordCount": null,
          "title": "Google: Data-scraping lawsuit would take 'sledgehammer' to generative AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17a9jrd/ai_dad_joke_why_did_the_ai_stop_being_nice/",
          "author": null,
          "description": "It regressed to mean...\n PS: I read the sidebar which didn't exclude humor, and the flair seems to suggest that it would be okay, but my apologies if not.\n    submitted by    /u/Tyler_Zoro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17a9jrd/ai_dad_joke_why_did_the_ai_stop_being_nice/",
          "publishedOn": "2023-10-17T21:40:50.000Z",
          "wordCount": null,
          "title": "[AI Dad Joke] Why did the AI stop being nice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17a8zl5/generative_ai_security_standards_llms_200k/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17a8zl5/generative_ai_security_standards_llms_200k/",
          "publishedOn": "2023-10-17T21:17:39.000Z",
          "wordCount": null,
          "title": "👨🏻‍🏫 Generative AI Security Standards, LLM‘s 200K Context Window, Alibaba's Open-Source Obsession, and Baidu World 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/179xdqs/can_gpt_models_be_financial_analysts_chatgpt_gpt4/",
          "author": null,
          "description": "Researchers evaluated ChatGPT and GPT-4 on mock CFA exam questions to see if they could pass the real tests. The CFA exams rigorously test practical finance knowledge and are known for being quite difficult.\n They tested the models in zero-shot, few-shot, and chain-of-thought prompting settings on mock Level I and Level II exams.\n The key findings:\n  \nGPT-4 consistently beat ChatGPT, but both models struggled way more on the more advanced Level II questions.\n Few-shot prompting helped ChatGPT slightly\n Chain-of-thought prompting exposed knowledge gaps rather than helping much.\n Based on estimated passing scores, only GPT-4 with few-shot prompting could potentially pass the exams.\n  \nThe models definitely aren't ready to become charterholders yet. Their difficulties with tricky questions and core finance concepts highlight the need for more specialized training and knowledge.\n But GPT-4 did better overall, and few-shot prompting shows their ability to improve. So with targeted practice on finance formulas and reasoning, we could maybe see step-wise improvements.\n TLDR: Tested on mock CFA exams, ChatGPT and GPT-4 struggle with the complex finance concepts and fail. With few-shot prompting, GPT-4 performance reaches the boundary between passing and failing but doesn't clearly pass.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/179xdqs/can_gpt_models_be_financial_analysts_chatgpt_gpt4/",
          "publishedOn": "2023-10-17T12:37:03.000Z",
          "wordCount": null,
          "title": "Can GPT models be financial analysts? ChatGPT, GPT-4 fail CFA exams in new study by JP Morgan, Queens University, and Virginia Tech",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/179wote/lets_find_out_what_gpt4_vision_can_do/",
          "author": null,
          "description": "GPT4 vision isn't just a gimmick. We've been given a new superpower, and so we must \"deal with it\". \n This is probably as big a moment as when chatGPT first arrived, maybe more. Machine Vision for the masses (and more).\n I tried doing some very loose sketches, and it really struggled to identify them until they were coloured in. Humans could easily what they were. But, in order to see what uses it has, we need to know what capabilities it does and does not have. \n Pick a question and see what you can learn! \n  \ncan it use TINY images (I assume they are much faster)\n can it tell you what has changed in two images?\n can it measure distances ? (with perspective?) \n  can it make 3d models from instructions?\n \n can it \"learn\" to recognise people/ similar objects (in the same context window)\n what limits are there to exhaustive listing \n exhaustive description\n \n is it better at details or overviews\n can it read maps / graphs / text\n how smart is it on DIY / xrays / mechanics \n can it follow wires?? \n (Can it find lego)\n is there a formal reference system you can use (X/Y) \n can it give co-ordinates in large grids or grid-like (how un-grid like) \n ie film strip, or window-panes\n \n can it navigate a 2d maze turn-by turn? 3d maze? can that be insanely complex? \n \n can it make ebay descriptions (condition)\n can it estimate food weight\n can it estimate strength / angles / volume\n can it create programs from screenshots. Can it use programs? games? control RC car / robot? \n what kind of language / instructions are best when talking about images. \n what other questions do we need\n  \n   submitted by    /u/inteblio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/179wote/lets_find_out_what_gpt4_vision_can_do/",
          "publishedOn": "2023-10-17T11:59:11.000Z",
          "wordCount": null,
          "title": "Let's find out what GPT4 vision can do",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/179mgz3/ai_pioneers_lecun_bengio_clash_in_intense_online/",
          "author": null,
          "description": "Yann LeCun and Yoshua Bengio, two influential figures in AI and deep learning, engaged in a heated debate over the potential risks and safety concerns surrounding AI.\n \nLeCun emphasized the need to design AI systems for safety rather than imagining catastrophic scenarios.\n \nBengio argued for the importance of prudence, stating that we still do not understand how to design safe, powerful AI systems, and highlighted the need for major investment in AI safety and governance.\n \nThe debate highlighted the disagreement among esteemed researchers about AI's potential risks, the effectiveness of current safety measures, and the best path forward.\n \nThe implications of AI, including job displacement, privacy violations, and existential risks, have become a topic of widespread concern.\n \n Source : https://venturebeat.com/ai/ai-pioneers-yann-lecun-and-yoshua-bengio-clash-in-an-intense-online-debate-over-ai-safety-and-governance/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/179mgz3/ai_pioneers_lecun_bengio_clash_in_intense_online/",
          "publishedOn": "2023-10-17T01:22:35.000Z",
          "wordCount": null,
          "title": "AI pioneers LeCun, Bengio clash in intense online AI safety, governance debate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/179j0xa/taken_on_my_screen_but_i_cant_get_over_what_it/",
          "author": null,
          "description": "submitted by    /u/Prestigious_Rough704  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/179j0xa/taken_on_my_screen_but_i_cant_get_over_what_it/",
          "publishedOn": "2023-10-16T22:41:03.000Z",
          "wordCount": null,
          "title": "Taken on my screen, but I can’t get over what it has become. I’m obsessed with AI.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/179dofg/i_built_an_ai_tool_to_help_authors_create/",
          "author": null,
          "description": "I always did want to draw a comic but I was never very good at drawing even though I put a lot of effort into it when I was younger... :'(\n So when I stumbled on image generation AI, I thought maybe it could help me transform my doodles into something decent.\n It took me a while and a lot of effort to write a tool to help me with that : story and dialogues are my own, images are based on doodles enhanced by AI.\n I would love to have feedback about the story : https://stripik.com/story/4/chapter/4/\n ​\n https://preview.redd.it/dvcudd4j3mub1.png?width=800&format=png&auto=webp&s=717bef60eaaf9b9a35a1a66f266c374406a923fa\n    submitted by    /u/maxcmoi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/179dofg/i_built_an_ai_tool_to_help_authors_create/",
          "publishedOn": "2023-10-16T18:58:57.000Z",
          "wordCount": null,
          "title": "I built an AI tool to help authors create webcomics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1797o5p/im_chronicling_the_process_of_trying_to_create_a/",
          "author": null,
          "description": "submitted by    /u/SexyJimBelushi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1797o5p/im_chronicling_the_process_of_trying_to_create_a/",
          "publishedOn": "2023-10-16T14:45:53.000Z",
          "wordCount": null,
          "title": "I'm chronicling the process of trying to create a boardgame with Chat GPT and it's amazing just how great of an assistant it is!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17973ah/if_seo_tools_were_nintendo_3ds_games_powered_by_ai/",
          "author": null,
          "description": "Did you play these (SEO) games? 👾\n https://preview.redd.it/yxuzllzupkub1.jpg?width=661&format=pjpg&auto=webp&s=23ebc6e972ac85b152aa8b69f48e2b0c5bae2c76\n https://preview.redd.it/x8zfokzupkub1.jpg?width=661&format=pjpg&auto=webp&s=be2163a7bfbeee64a63c1292a5b4c482c5be33ae\n https://preview.redd.it/eerpgnzupkub1.jpg?width=661&format=pjpg&auto=webp&s=d8eceafd3732653c743a6731ae5932c9e0da071c\n https://preview.redd.it/uxwgskzupkub1.jpg?width=661&format=pjpg&auto=webp&s=07c751eaa16f8fa484034c98a3c1fd0b2162f5a2\n Source: https://twitter.com/carlos_darko/status/1713900305765605484\n    submitted by    /u/DanielPeris  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17973ah/if_seo_tools_were_nintendo_3ds_games_powered_by_ai/",
          "publishedOn": "2023-10-16T14:20:32.000Z",
          "wordCount": null,
          "title": "If SEO tools were Nintendo 3DS games [Powered by AI]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1795ig0/can_ai_replace_developers_princeton_and/",
          "author": null,
          "description": "Exploiting AI to make software programming easier? SWE-bench, a unique evaluation system, tests language models' ability to solve real GitHub-collated programming issues. Interestingly, even top-notch models manage only the simplest problems, underscoring tech development's urgency for providing practical software engineering solutions.\n For the latest advancements in AI, look here first.\n https://preview.redd.it/8laeg7cbckub1.png?width=1292&format=png&auto=webp&s=e549f0045a7253cd2d3f351d8297a301c4cbf6ac\n A New Approach to Evaluating AI Models\n  \nResearchers use real-world software engineering problems from GitHub to assess language models' coding problem-solving skills.\n SWE-bench, introduced by Princeton and the University of Chicago, offers a more comprehensive and challenging benchmark…",
          "link": "https://www.reddit.com/r/artificial/comments/1795ig0/can_ai_replace_developers_princeton_and/",
          "publishedOn": "2023-10-16T13:04:25.000Z",
          "wordCount": null,
          "title": "Can AI Replace Developers? Princeton and University of Chicago's SWE-bench Tests AI on Real Coding Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1790cz1/deep_fake_language_change/",
          "author": null,
          "description": "What is the best free tool to make a video where the language changes?\n    submitted by    /u/Easy_Technology6768  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1790cz1/deep_fake_language_change/",
          "publishedOn": "2023-10-16T07:27:06.000Z",
          "wordCount": null,
          "title": "Deep fake language change",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178y6bu/oneminute_daily_ai_news_10152023/",
          "author": null,
          "description": "New York-based tech firms and investors see the advent of AI as the latest opportunity to try to unseat the Bay Area as tech’s global capital.[1]\n Microsoft announced a new “bug bounty” program, vowing to reward security researchers between $2,000 and $15,000 if they’re able to find “vulnerabilities” in its Bing AI products, including “jailbreak” prompts that make it produce responses that go against the guardrails that are supposed to bar it from being bigoted or otherwise problematic.[2]\n OpenAI is preparing to launch a suite of updates to make it more cost-effective and efficient for developers to create software applications with AI models.[3]\n TCS Seeks to Use Microsoft AI Partnership to Improve Margins.[4]\n  \nSources:\n [1] https://www.axios.com/2023/10/12/new-york-ai-world-capital\n [2] https://futurism.com/the-byte/microsoft-bing-ai-bug-bounty\n [3] https://www.techedt.com/openai-aims-to-attract-developers-with-cost-effective-updates-insiders-reveal\n [4] https://www.bloomberg.com/news/articles/2023-10-15/tcs-seeks-to-use-microsoft-ai-partnership-to-improve-margins#xj4y7vzkg \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178y6bu/oneminute_daily_ai_news_10152023/",
          "publishedOn": "2023-10-16T04:54:37.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/15/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178wuz0/are_there_an_image_generators_that_can_generate/",
          "author": null,
          "description": "I was wondering if any AI image generation was good at this (yet?). I have a real-life image I want to upload and get AI to generate what that would most likely look like from the vantage point of someone standing at a different angle.\n    submitted by    /u/YepperyYepstein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178wuz0/are_there_an_image_generators_that_can_generate/",
          "publishedOn": "2023-10-16T03:34:12.000Z",
          "wordCount": null,
          "title": "Are there an image generators that can generate the same image you upload to it, but from a different hypothetical angle?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178tdm1/ai_dubbing_local/",
          "author": null,
          "description": "Hi there, anybody knows how AI dubbing translator works ? As im interested if something similiar to https://app.rask.ai/ exist localy ?? Is there anything from github? Im looking for czech language. I know you can scribe audio to text than translate text and let AI to talk this text. But is there a tool that do all of this in one click ? Thank you and have a nice day.\n    submitted by    /u/Low_Government_681  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178tdm1/ai_dubbing_local/",
          "publishedOn": "2023-10-16T00:30:04.000Z",
          "wordCount": null,
          "title": "AI dubbing ( local )",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178pf6d/nvidia_blackwell_b100_gpus_to_feature_sk_hynix/",
          "author": null,
          "description": "submitted by    /u/norcalnatv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178pf6d/nvidia_blackwell_b100_gpus_to_feature_sk_hynix/",
          "publishedOn": "2023-10-15T21:21:14.000Z",
          "wordCount": null,
          "title": "NVIDIA Blackwell B100 GPUs To Feature SK Hynix HBM3e Memory, Launches In Q2 2024 Due To Rise In AI Demand",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178o5jd/researchers_propose_gamegpt_a_multiagent_approach/",
          "author": null,
          "description": "Game dev is super complex nowadays - games have huge codebases, massive teams, and dev cycles dragging on for years. Costs are insane too - budgets can hit $100M+ easily.\n In a new paper, researchers propose to reverse this trend with an AI framework called GameGPT that automates parts of the dev process using multiple AI agents. Each agent handles a different role (all are fine-tuned from relevant base models):\n  \nOne agent reviews the game design plan to catch errors\n Another turns tasks into code implementations\n Reviewer agents check the code and results\n A testing agent validates everything works as expected\n  \nBy breaking up the workflow, GameGPT can simplify things for the AI agents. They just focus on a narrow role versus having one jack-of-all-trades agent.\n The authors argue GameGPT can eliminate repetitive and rote elements of gamedev like testing. This would free up developers to focus on creative design challenges.\n However, the GameGPT paper does not include any concrete results or experiments demonstrating improved performance. There is no evidence presented that GameGPT reduces hallucinations, redundancy or development time. The authors mention empirical results support their claims that the architecture is more effective, but none are provided. I could not find any additional support material about this work, like a project website, that I could use to further check into this (maybe someone can share in the comments?).\n Right now GameGPT seems mostly conceptual. The ideas are interesting but hard to assess without quantitative results.\n TLDR: New GameGPT AI framework aims to automate tedious parts of game development using specialized agents. No concrete results were provided in the paper - someone will need to test this out and report back.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178o5jd/researchers_propose_gamegpt_a_multiagent_approach/",
          "publishedOn": "2023-10-15T20:24:42.000Z",
          "wordCount": null,
          "title": "Researchers propose GameGPT: A multi-agent approach to fully automated game development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178n10e/speech_condenser_an_advanced_onpremise_pipeline/",
          "author": null,
          "description": "submitted by    /u/nez_har  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178n10e/speech_condenser_an_advanced_onpremise_pipeline/",
          "publishedOn": "2023-10-15T19:32:26.000Z",
          "wordCount": null,
          "title": "Speech Condenser: An Advanced On-Premise Pipeline Tool for Streamlining and Summarizing Dialogues from Videos",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178er0n/best_way_to_produce_consistent_images/",
          "author": null,
          "description": "Hi!\n I'm trying to jazz up my design portfolio for applying for jobs, and I wanted to insert some cute illustrations on each project page. The projects deal with a variety of topics so I'll need pictures of many things, but want to keep the style quite consistent. \n What is the best AI tool right now to do this? I paid for Midjourney but I can't seem to understand how to get it to do this. \n For example I got this image from DALLE and love the style, the white background also helps make it look better on the portfolio. I'd want another image in the same style of two kids throwing a ball, but can't figure out how to do it. \n Alternatively if I could upload this image to an AI and say \"in the same style, generate...\" that would be great too. \n Thank you!\n    submitted by    /u/_Dip_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178er0n/best_way_to_produce_consistent_images/",
          "publishedOn": "2023-10-15T12:53:43.000Z",
          "wordCount": null,
          "title": "Best way to produce consistent images?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178e923/messi_vs_ronaldo_freestyle_rap_song_ai_rap_song/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178e923/messi_vs_ronaldo_freestyle_rap_song_ai_rap_song/",
          "publishedOn": "2023-10-15T12:23:41.000Z",
          "wordCount": null,
          "title": "Messi vs Ronaldo | Freestyle Rap Song | AI Rap Song | Tell your opinion on this video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178e0gu/seeking_your_feedback_on_a_new_community_around/",
          "author": null,
          "description": "Currently, we are building a community that is specifically dedicated to Open-Source AI Code Generation Models. Our aim is to create a thriving ecosystem where developers, enthusiasts, and experts can come together to drive innovation, share insights, and promote a collaborative approach to AI code generation.\n I wanted to provide you with an overview of the key features we're integrating into this community:\n 1. Collaboration: A dedicated space where enthusiasts and experts alike can collaborate on projects, share their findings, and work on enhancing existing models.\n 2. Discussion: Whether through forums or chat platforms, we aim to foster discussions around the challenges, breakthroughs, and best practices in the realm of AI code generation.\n 3. Resource Sharing: Our community will feature a repository/platform for members to freely share and access open-source models, datasets, and other essential tools.\n With your experience and insight into the AI domain, we would greatly appreciate your feedback on the following:-\n - Do you believe such a community would be valuable to you personally or to the wider developer community?\n - Would you consider becoming a part of such a community?\n - You are already a part of such a community and this one might not be of much value to you?\n - Any other suggestions or feedback?\n Your candid feedback on this idea, its potential impact, and any suggestions you might have will be invaluable to us as we continue shaping this community's structure and offerings.\n    submitted by    /u/akanshtyagi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178e0gu/seeking_your_feedback_on_a_new_community_around/",
          "publishedOn": "2023-10-15T12:08:31.000Z",
          "wordCount": null,
          "title": "Seeking Your Feedback on a new community around Open-Source AI Code Generation Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178ccbl/biden_eyes_adding_ai_chip_curbs_to_chinese/",
          "author": null,
          "description": "The Biden administration is considering closing a loophole that gives Chinese companies access to American artificial intelligence (AI) chips through units located overseas.\n \nThe United States previously restricted shipments of AI chips to China but left overseas subsidiaries of Chinese companies with unfettered access.\n \nThe Biden administration is now looking for ways to close this loophole and prevent China from accessing top AI technology.\n \nHowever, it is challenging to plug every gap in export controls.\n \nChinese firms are purchasing chips for use in data centers abroad, and it is difficult for the United States to police those transactions.\n \nThe United States has been seeking to halt the rise of China's AI capability, which depends on its access to U.S. chips.\n \nWashington has been working to close other loopholes that allow AI chips into China, and the new rules expected this month will likely apply those same restrictions more broadly to all companies in the market.\n \nThe U.S. government is also grappling with the issue of Chinese parties accessing U.S. cloud providers like Amazon Web Services.\n \nOverall, the Biden administration is facing challenges in cutting China off from top AI technology and closing all loopholes in export controls.\n \n Source : https://www.reuters.com/technology/biden-eyes-adding-ai-chip-curbs-chinese-companies-abroad-2023-10-13/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178ccbl/biden_eyes_adding_ai_chip_curbs_to_chinese/",
          "publishedOn": "2023-10-15T10:14:06.000Z",
          "wordCount": null,
          "title": "Biden eyes adding AI chip curbs to Chinese companies abroad",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177wy99/looking_for_developers_future_founders_who_want/",
          "author": null,
          "description": "I am a multi-time founder myself. I've secured millions from investors for my past startups and had notable success with a video app that gathered 4M users and $300k in revenue. However, due to the intense competition in the video app editing sector, my team and I couldn't turn a profit.\n After my last startup faltered during the covid period, I transitioned to being a full-time product-market fit and growth marketing consultant and have made really great money doing it. I assist new startups in avoiding the mistakes I made and implement frameworks that significantly increase their chances of success. I've observed that many new founders venture into startups without fully grasping the challenges of building something people genuinely desire. It’s really not easy. How would you know what y…",
          "link": "https://www.reddit.com/r/artificial/comments/177wy99/looking_for_developers_future_founders_who_want/",
          "publishedOn": "2023-10-14T19:24:14.000Z",
          "wordCount": null,
          "title": "Looking for developers / future founders who want to build and grow disruptive AI apps.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177v76q/ai_images_detectors_are_being_used_to_discredit/",
          "author": null,
          "description": "A free AI image detector is being used to discredit a photograph of a burnt corpse of a baby killed in Hamas's attack on Israel.\n \nHowever, experts have pointed out that the image does not show any signs of being created by AI.\n \nThe idea that the image is AI-generated has spread on Twitter, suggesting that official Israeli accounts are spreading AI-generated misinformation.\n \nAI image generators have trouble replicating reality accurately, and the shadows in the photograph are consistent with a real image.\n \nMultiple AI image detection tools have also determined that the image is not AI-generated. \n \n Source : https://www.404media.co/ai-images-detectors-are-being-used-to-discredit-the-real-horrors-of-war/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177v76q/ai_images_detectors_are_being_used_to_discredit/",
          "publishedOn": "2023-10-14T18:00:16.000Z",
          "wordCount": null,
          "title": "AI Images Detectors Are Being Used to Discredit the Real Horrors of War",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177o01x/seeking_a_community_for_opensource_ai_code/",
          "author": null,
          "description": "Hello everyone! 🌟\n I hope this post finds you well. I've been delving deeper into the world of AI code generation recently and am curious to discover if there are communities or platforms specifically dedicated to open-source AI code generation models. I'm aware of hugging face but is there any other besides that.\n Here's what I'm looking for:\n  \nCollaboration: A space where enthusiasts and experts alike can collaborate on projects, share insights, and improve upon existing models.\n Discussion: Forums or chat platforms where discussions around the challenges, breakthroughs, and best practices in AI code generation take place.\n Resource Sharing: A repository or platform where open-source models, datasets, and related tools can be freely shared and accessed.\n Learning and Tutorials: Any resources that can help newcomers grasp the concepts and intricacies of AI code generation.\n If you know of any such community or are part of one, please do let me know.\n  \n   submitted by    /u/akanshtyagi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177o01x/seeking_a_community_for_opensource_ai_code/",
          "publishedOn": "2023-10-14T12:03:23.000Z",
          "wordCount": null,
          "title": "Seeking a Community for Open-Source AI Code Generation Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177lcha/mickey_what_are_you_doing/",
          "author": null,
          "description": "submitted by    /u/LeviJr00  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177lcha/mickey_what_are_you_doing/",
          "publishedOn": "2023-10-14T09:05:43.000Z",
          "wordCount": null,
          "title": "Mickey, what are you doing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177kmyf/updates_to_my_capstone_project_with_enhanced/",
          "author": null,
          "description": "submitted by    /u/Raymondlkj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177kmyf/updates_to_my_capstone_project_with_enhanced/",
          "publishedOn": "2023-10-14T08:13:00.000Z",
          "wordCount": null,
          "title": "Updates to my Capstone Project with Enhanced Features and still freely available to all (until OpenAI credits deplete - Free ChatGPT4). Hoping to introduce the community feature too where people can generate STEM animations to aid learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177iwg0/learning_for_school_with_an_ai/",
          "author": null,
          "description": "does anyone know if there is an AI online where you can import documents and the AI is forming and asking you questions about that topic on the document? like an AI who generates test for you to be prepared for every potential question in a school test.\n    submitted by    /u/satanskittenz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177iwg0/learning_for_school_with_an_ai/",
          "publishedOn": "2023-10-14T06:10:33.000Z",
          "wordCount": null,
          "title": "learning for school with an AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177fjuo/creative_question_your_ideas_for_ai_generative/",
          "author": null,
          "description": "Ok so we have AI generated content, First text, then images, then videos. \n What will the world look like when we have a generative world? \n Generative objects, Generative Games, Generative Moods, Generative memories, Generative senses and perceptions, Generative Environments, Generative Reality.\n Anyone want to talk about what it might look like?\n ( I would like to hear a unhinged idea for what might happen, Speculative of course )\n    submitted by    /u/rolyataylor2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177fjuo/creative_question_your_ideas_for_ai_generative/",
          "publishedOn": "2023-10-14T02:42:04.000Z",
          "wordCount": null,
          "title": "Creative Question: Your ideas for AI generative reality",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177af7r/savage_dalle_3_delivers_average_reddit_post/",
          "author": null,
          "description": "submitted by    /u/Zimmax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177af7r/savage_dalle_3_delivers_average_reddit_post/",
          "publishedOn": "2023-10-13T22:20:59.000Z",
          "wordCount": null,
          "title": "Savage Dall-e 3 delivers \"Average reddit post\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1773ee2/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n  \nResearchers present LLark: A Multimodal Foundation Model for Music - an open-source instruction-tuned multimodal model for music understanding. LLark is trained entirely from open-source music data and models [Demo | Paper]\n Researchers released LLaVA-1.5. LLaVA (Large Language and Vision Assistant) is an open-source large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. LLaVA-1.5 achieved SoTA on 11 benchmarks, with just simple modifications to the original LLaVA and completed training in ~1 day on a single 8-A100 node [Demo | Paper | GitHub].\n Voice AI platform ElevenLabs released AI Dubbing tool that enables users to automatically translate any audio in a video into a different language whil…",
          "link": "https://www.reddit.com/r/artificial/comments/1773ee2/ai_weekly_megathread/",
          "publishedOn": "2023-10-13T17:01:02.000Z",
          "wordCount": null,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17726b7/the_ai_boom_could_use_a_shocking_amount_of/",
          "author": null,
          "description": "The rapid growth of artificial intelligence (AI) could lead to a significant increase in global electricity consumption, according to a peer-reviewed analysis published in Joule.\n \nThe analysis estimates that if current trends continue, AI could drive the demand for electricity in data centers to consume at least 85.4 terawatt-hours annually, which is more than what many small countries use in a year.\n \nAI is energy-intensive, with both the training and inference phases requiring a significant amount of energy.\n \nThe size of AI models, such as large language models, and the location of data centers also contribute to energy usage.\n \nFactors such as cooling requirements and the type of hardware used can impact energy consumption.\n \n Source : https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17726b7/the_ai_boom_could_use_a_shocking_amount_of/",
          "publishedOn": "2023-10-13T16:05:17.000Z",
          "wordCount": null,
          "title": "The AI Boom Could Use a Shocking Amount of Electricity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1771hmp/lemur_harmonizing_natural_language_and_code_for/",
          "author": null,
          "description": "Today's conversational bots like Claude and GPT can chat impressively but aren't great at complex planning or executing technical tasks. To overcome this, new research from HKU builds open-source AI agents that blend natural language and coding skills. They're called Lemur and Lemur-Chat.\n The researchers think achieving versatile real-world agents requires models that integrate both fluid natural language abilities and precise programming language control. Humans combine plain speech for higher-level goals with languages like Python when we need to plan intricately and execute exactly. AI needs both capacities too.\n But most existing models specialize in pure language or pure code. There's a separation that is limiting.\n The team created Lemur by pretraining the open-source Llama-2 on a massive mixed corpus with 10x more natural language than code. This improved its programming abilities while retaining conversational strength. Further instruction tuning optimized Lemur-Chat for following free-form directions in language.\n Experiments found Lemur surpassed specialized coding-only models like Codex in overall benchmarks. Lemur-Chat then exceeded Lemur by 15% after instruction tuning.\n More importantly, Lemur-Chat won 12/13 new \"agent tests\" designed to mimic real-world challenges needing both language and programming prowess.\n It beat alternatives at:\n  \nUsing tools like Python and Wikipedia to enhance reasoning\n Debugging code by leveraging error messages\n Improving the most from natural language feedback\n Exploring partially observable environments like cybersecurity and web browsing simulations.\n  \nLemur-Chat matched GPT-3.5 in many tests, closing the gap between commercial and open-source agents.\n TLDR: New open-source AI agents combine coding and language skills. Experiments show the combo unlocks more performance across technical challenges.\n Full summary is here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1771hmp/lemur_harmonizing_natural_language_and_code_for/",
          "publishedOn": "2023-10-13T15:34:23.000Z",
          "wordCount": null,
          "title": "Lemur: Harmonizing Natural Language and Code for Language Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176ydik/henry_kissinger_the_path_to_ai_arms_control/",
          "author": null,
          "description": "submitted by    /u/ForeignAffairsMag  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176ydik/henry_kissinger_the_path_to_ai_arms_control/",
          "publishedOn": "2023-10-13T13:08:52.000Z",
          "wordCount": null,
          "title": "Henry Kissinger: The Path to AI Arms Control",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176wuhn/a_21yearold_won_40000_for_using_ai_to_read_the/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176wuhn/a_21yearold_won_40000_for_using_ai_to_read_the/",
          "publishedOn": "2023-10-13T11:46:17.000Z",
          "wordCount": null,
          "title": "A 21-year-old won $40,000 for using AI to read the first word on a 2,000-year-old papyrus scroll buried by Mount Vesuvius",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176vs99/special_announcement_john_carmack_rich_sutton/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176vs99/special_announcement_john_carmack_rich_sutton/",
          "publishedOn": "2023-10-13T10:39:06.000Z",
          "wordCount": null,
          "title": "\"Special Announcement: John Carmack & Rich Sutton partner to accelerate development of AGI\" | \"Carmack and Sutton are deeply focused on developing a genuine AI prototype by 2030, including establishing, advancing, and documenting AGI signs of life\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176vpwe/dumbing_down_or_wising_up_how_will_generative_ai/",
          "author": null,
          "description": "submitted by    /u/Jariiari7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176vpwe/dumbing_down_or_wising_up_how_will_generative_ai/",
          "publishedOn": "2023-10-13T10:34:43.000Z",
          "wordCount": null,
          "title": "Dumbing down or wising up: how will generative AI change the way we think?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176r4bp/oneminute_daily_ai_news_10132023/",
          "author": null,
          "description": "In a recent article published in the journal Nature, researchers developed AI Tool EVEscape, a tool to forecast which severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) strains have the highest potential to escape host immunity.[1]\n Microsoft seems to be working on the possible development of an artificial intelligence (AI) system that can understand and resolve customer support requests using natural language processing.[2]\n Google’s Search Generative Experience (SGE) will let you create images right from a text prompt starting Thursday.[3]\n The Biden administration is considering closing a loophole that gives Chinese companies access to American artificial intelligence (AI) chips through units located overseas, according to four people familiar with the matter.[4]\n  \nSources:\n [1] https://www.news-medical.net/news/20231012/EVScape-New-tool-to-forecast-which-SARS-CoV-2-variants-could-dodge-our-immunity.aspx\n [2] https://winbuzzer.com/2023/10/11/microsoft-gears-up-for-a-revolutionary-natural-language-customer-support-ai-xcxwbn/\n [3] https://www.theverge.com/2023/10/12/23913337/google-ai-powered-search-sge-images-written-drafts\n [4] https://www.reuters.com/technology/biden-eyes-adding-ai-chip-curbs-chinese-companies-abroad-2023-10-13/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176r4bp/oneminute_daily_ai_news_10132023/",
          "publishedOn": "2023-10-13T05:14:11.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/13/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176m31w/ive_created_a_audiobook_generator_anyone_got_any/",
          "author": null,
          "description": "Also if anyone has anyone who should be a voice actor included in it it can also clone voices. Idk I need to make sure it works for a wide variety of books. As long as they don’t use ‘ for quotes cause the computer getts that confused when “ I’ve “ and such uses the same symbol\n    submitted by    /u/Impossible_Belt_7757  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176m31w/ive_created_a_audiobook_generator_anyone_got_any/",
          "publishedOn": "2023-10-13T00:34:33.000Z",
          "wordCount": null,
          "title": "I’ve created a audiobook generator anyone got any books to test on it? Each character is given a different voice.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176lwka/check_out_the_latest_episode_of_my_history/",
          "author": null,
          "description": "submitted by    /u/ErikSlader713  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176lwka/check_out_the_latest_episode_of_my_history/",
          "publishedOn": "2023-10-13T00:25:30.000Z",
          "wordCount": null,
          "title": "Check out the latest episode of my history podcast on the future of A.I.!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176lqdp/drew_a_picture_in_paint_threw_it_in_hotpot_and_it/",
          "author": null,
          "description": "submitted by    /u/kipaxbooks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176lqdp/drew_a_picture_in_paint_threw_it_in_hotpot_and_it/",
          "publishedOn": "2023-10-13T00:17:00.000Z",
          "wordCount": null,
          "title": "Drew a picture in paint, threw it in hotpot, and it came out a stylish, halloweenish picure. Damn this stuff is amazing.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176k8nh/who_will_benefit_from_ai/",
          "author": null,
          "description": "Artificial intelligence (AI) can provide \"machine usefulness\" for human workers, augmenting their jobs rather than replacing them.\n \nHowever, there is a concern that AI could lead to job displacement and reinforce economic inequality.\n \nMIT economist Daron Acemoglu emphasizes the importance of making AI more useful to humans and ensuring that the economic benefits are shared widely.\n \nHe suggests that innovations that augment workers' tasks can lead to prosperity for the workforce.\n \nAcemoglu also highlights the need for worker power and the careful implementation of technology to achieve shared prosperity and productivity gains.\n \n Source : https://idss.mit.edu/news/who-will-benefit-from-ai/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176k8nh/who_will_benefit_from_ai/",
          "publishedOn": "2023-10-12T23:03:47.000Z",
          "wordCount": null,
          "title": "Who Will Benefit from AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176i1ed/whats_the_most_advanced_free_chatbot_available/",
          "author": null,
          "description": "I just need three things for it:\n  \nIt must be knowledgeable about things, such as physics, math, hystory, books, geography, etc.\n It also must be original, with a high level of SEO and AI detection score.\n It must be available in Italy. The last part is essential. Claude 2 is very famous but with sms verification from usa (which I don't have and I don't want to give credit card info/pay to have) it's made almost impossible even with vpn.\n  \n   submitted by    /u/luigirovatti1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176i1ed/whats_the_most_advanced_free_chatbot_available/",
          "publishedOn": "2023-10-12T21:28:53.000Z",
          "wordCount": null,
          "title": "What's the most advanced free chatbot available?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176hbsq/10_powerful_chatgpt_hacks_for_seo/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176hbsq/10_powerful_chatgpt_hacks_for_seo/",
          "publishedOn": "2023-10-12T21:00:40.000Z",
          "wordCount": null,
          "title": "10 Powerful ChatGPT Hacks for SEO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176ddj5/chatgpts_global_peace_plan/",
          "author": null,
          "description": "Creating true, enduring, lasting peace on Earth is an ambitious and complex endeavor that requires multifaceted approaches. Here’s a bold, outside-the-box plan that may surprise you:\n Step 1: Establish a Global Consciousness:\n  \nEducational Overhaul: Revamp global educational systems to foster empathy, understanding, and appreciation for diverse cultures, religions, and viewpoints from a young age.\n  \nStep 2: Eradicate Poverty and Inequality:\n  \nUniversal Basic Assets (UBA): Implement a Universal Basic Assets program, where every person on Earth is granted a share of global resources.\n  \nStep 3: Create a Single Global Governance Entity:\n  \nWorld Federation: Establish a democratically elected World Federation that respects regional autonomy but has overriding authority on global issues like…",
          "link": "https://www.reddit.com/r/artificial/comments/176ddj5/chatgpts_global_peace_plan/",
          "publishedOn": "2023-10-12T18:07:07.000Z",
          "wordCount": null,
          "title": "ChatGPT's Global Peace Plan",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176bd2b/when_your_ai_says_she_loves_you/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176bd2b/when_your_ai_says_she_loves_you/",
          "publishedOn": "2023-10-12T16:40:46.000Z",
          "wordCount": null,
          "title": "When your AI says she loves you",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1769qsd/anyone_ever_thought_about_training_a_video/",
          "author": null,
          "description": "Just had a random idea: What if you train a video generating AI, but feed it videos that are reversed? You could show it an image of a crashed car, and it would generate a video of the crash. Show it a broken vase, it would \"repair\" it. It could one day become like the \"reconstruct crime scene\" in Detroit: Become Human. What are your thoughts about this?\n    submitted by    /u/FluffyIllustrator805  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1769qsd/anyone_ever_thought_about_training_a_video/",
          "publishedOn": "2023-10-12T15:31:49.000Z",
          "wordCount": null,
          "title": "Anyone ever thought about training a video generating model, but backwards?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1767l8w/ai_and_science_what_1600_researchers_think/",
          "author": null,
          "description": "A Nature survey of over 1,600 researchers reveals that AI tools are becoming increasingly common in science and are expected to be 'very important' or 'essential' in the next decade.\n \nScientists express concerns about how AI is transforming research, including reliance on pattern recognition without understanding, bias in data, fraud, and irreproducible research.\n \nThe survey shows that AI tools provide faster ways to process data, speed up computations, and save time and money.\n \nAmong researchers who use AI, more than one-quarter believe AI tools will become 'essential' to their field in the next decade.\n \nLarge language models like ChatGPT are mentioned as both impressive and concerning examples of AI tools in science.\n \n Source : https://www.nature.com/articles/d41586-023-02980-0\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1767l8w/ai_and_science_what_1600_researchers_think/",
          "publishedOn": "2023-10-12T13:56:09.000Z",
          "wordCount": null,
          "title": "AI and science: what 1,600 researchers think",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1767dac/looking_for_ai_text_input_like_artbreeder_mixer/",
          "author": null,
          "description": "I'm looking for a (free) ai image generator like Artbreeder Mixer, that has functions that allow you to \"morph\" or mix images together via text prompts. Ive looked at a bunch already, and even tried adding the text of the different types in the prompts, bu Ive been getting separated results (like \"cat\" , \"man\", \"head\" wont combine the man and the cat, but rather give me un-morphed results, like a regular man, plus a cat in a suit with no human features. I even get a result with a man standing behind a cat! Ive tried StarryAI, imagecreator, wepik, cant afford midjourney or paid ones right now, some others I cant remember with no mixing...\n Artbreeder's interface, you can keep adding and it will mix them together.\n I made these images and others like them very easy in Artbreeder, but its plan is very limited - I could buy more credits, but I need to wait a few days (new job, not paid yet, broke today... lol):\n ​\n morph between man and donkey\n Morph between angry rapper and gorilla\n SO, if anyone can suggest some free, or almost free (generous newbie credits?) that can do mixes like this - please point me in the right direction.\n    submitted by    /u/magusat999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1767dac/looking_for_ai_text_input_like_artbreeder_mixer/",
          "publishedOn": "2023-10-12T13:45:47.000Z",
          "wordCount": null,
          "title": "Looking for AI text input like Artbreeder Mixer that combines images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17677nn/new_york_wants_to_be_ais_world_capital_in_rivalry/",
          "author": null,
          "description": "submitted by    /u/norcalnatv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17677nn/new_york_wants_to_be_ais_world_capital_in_rivalry/",
          "publishedOn": "2023-10-12T13:38:28.000Z",
          "wordCount": null,
          "title": "New York wants to be AI's world capital, in rivalry with San Francisco and Silicon Valley",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1764fsl/could_an_aicreated_profile_picture_help_you_get_a/",
          "author": null,
          "description": "Artificial intelligence (AI) is being used to create professional-looking profile pictures for job hunting websites like LinkedIn.\n \nApps like Remini, Try It On AI, and AI Suit Up use AI-based software to generate slick profile photos that mimic the work of expert photographers.\n \nUsers upload multiple selfies, and the AI software creates artificial photos with different hairstyles, clothing, and backdrops.\n \nWhile some find the results realistic, others think they look artificial.\n \nThe AI services are popular because they are cheap or free, making them accessible to those who can't afford professional headshots.\n \nHowever, opinions are divided on whether AI-generated photos are beneficial or detrimental to self-esteem.\n \nSome believe that AI-generated photos allow individuals to put their best self forward and potentially increase their chances of being considered for opportunities.\n \nOthers worry that relying on AI-generated photos may negatively impact self-worth and confidence. Recruiters generally do not consider whether a photo is AI-generated when evaluating job applications.\n \n Source : https://www.bbc.co.uk/news/business-67054382\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1764fsl/could_an_aicreated_profile_picture_help_you_get_a/",
          "publishedOn": "2023-10-12T11:12:41.000Z",
          "wordCount": null,
          "title": "Could an AI-created profile picture help you get a job?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17643wd/ai_tool_for_film_footage_notes/",
          "author": null,
          "description": "Hi, im currently filming a documentary, but I’m so busy filming, i don’t have time to write notes on footage for the editor. \n Does anyone know of any ai tool that can help with this and save time and streamline this process? \n King regards\n    submitted by    /u/Brand0n_C  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17643wd/ai_tool_for_film_footage_notes/",
          "publishedOn": "2023-10-12T10:53:10.000Z",
          "wordCount": null,
          "title": "AI Tool for film footage notes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1760z8c/how_ai_will_affect_traditional_and_open_source/",
          "author": null,
          "description": "Hey folks, how would you guys see the effect of AI? Will the small softwares companies will go bankrupt? Since the lots of software are using tools like ChatGpt, Midway Journey etc. It just the starting of new AI technology era which will evolved over the years. In that time we will see more and more AI software which will likely provide efficient and better solution as compare to traditional and open source software. So my question is how do you guys see this? Will small software companies or open source software programs days are number? \n    submitted by    /u/Haziq12345  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1760z8c/how_ai_will_affect_traditional_and_open_source/",
          "publishedOn": "2023-10-12T07:20:11.000Z",
          "wordCount": null,
          "title": "How AI will affect traditional and open source software industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175yhxe/oneminute_daily_ai_news_10112023/",
          "author": null,
          "description": "Opera has launched Opera One — a new version of the browser that comes packaged with an AI-powered chatbot called Aria.[1]\n Adobe is going all in on AI, announcing three new generative AI models today that add powerful features to Illustrator and Adobe Express and vastly improve Photoshop’s text-to-image capabilities.[2]\n ‘South Park’ to Tackle AI for Next Event Special, Releases Teaser.[3]\n World’s first AI tutor launched in Australia to help students get through their exams.[4]\n  \nSources:\n [1] https://www.theverge.com/2023/6/21/23768888/opera-one-browser-aria-ai-assistant-chatbot\n [2] https://www.theverge.com/2023/10/10/23911114/adobe-max-firefly-generative-ai-model-photoshop-illustrator-express\n [3] https://www.hollywoodreporter.com/tv/tv-news/south-park-ai-joining-panderverse-1235615276/\n [4] https://www.techguide.com.au/news/computers-news/worlds-first-ai-tutor-launched-in-australia-to-help-students-get-through-their-exams/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175yhxe/oneminute_daily_ai_news_10112023/",
          "publishedOn": "2023-10-12T04:42:39.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/11/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175y8eo/cypher_2023_the_future_of_simulation_and_design/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175y8eo/cypher_2023_the_future_of_simulation_and_design/",
          "publishedOn": "2023-10-12T04:26:50.000Z",
          "wordCount": null,
          "title": "Cypher 2023: The Future of Simulation and Design is AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175x3a0/any_ideas_how_this_was_created/",
          "author": null,
          "description": "submitted by    /u/crispyTacoTrain  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175x3a0/any_ideas_how_this_was_created/",
          "publishedOn": "2023-10-12T03:23:43.000Z",
          "wordCount": null,
          "title": "Any ideas how this was created?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175tz97/web_design_tools/",
          "author": null,
          "description": "I’m looking for input and advice on tools for web designers. \n I use Wordpress a lot, Magento some and frequently code by hand in html JavaScript and PHP. \n I know there are some AI tools out there now but I don’t know which are best and wanted to find out what people thoughts are on this subject.\n What tools are you using, for what, and why?\n Thanks!\n    submitted by    /u/PowerTarget  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175tz97/web_design_tools/",
          "publishedOn": "2023-10-12T00:50:28.000Z",
          "wordCount": null,
          "title": "Web design tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175rmsi/predictive_ai_analyzing_attraction_to_facial/",
          "author": null,
          "description": "Top dating apps Tinder, Hinge and Bumble have all stated that they're already investing in AI to make their apps better. They're using it to verify profiles, match people based on bios and interests, and help generate profile descriptions and liven conversations. But what about machine learning on user photos?\n iris Dating uses AI to analyze user input in the form of liking or disliking faces (\"swiping\" profiles). We all know if we like blondes or brunettes, blue or brown eyes, short or long hair, beard or no beard, etc. But AI can pick up the subtlest features (proportions, distances, curvatures etc.) and build a face map. A matrix of features, if you will. It doesn't just look for a person looking like your favorite celebrity crush. It understands what you're really attracted to.\n From there it's an easy path: if it knows which features attract me, it can predict my level of attraction to a specific individual (specifically, their face). Find the persons with the highest predicted attractiveness (for me, not for everyone), rank them by attraction for me, and we have a potential high mutual attraction match. The two stats I have are that on average women like 55%(!) of the profiles iris picks for them; and that users have 40x higher chances of matching when they've trained the model to understand their taste.\n I know it takes a lot more than a pretty face to make for a great relationship, but it sure doesn't hurt to start with strong physical attraction. Missed connections on Craigslist are about just that: seeing a face you can't forget. Find me more of these \"wow\" faces and let's go from there.\n What do you think? Is it too early? Too bold? Too niche?\n    submitted by    /u/akahamlet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175rmsi/predictive_ai_analyzing_attraction_to_facial/",
          "publishedOn": "2023-10-11T23:00:58.000Z",
          "wordCount": null,
          "title": "Predictive AI analyzing attraction to facial features (iris Dating app)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175qcg0/superman_if_portrayed_by_different_actors_as/",
          "author": null,
          "description": "submitted by    /u/fat_n_stupid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175qcg0/superman_if_portrayed_by_different_actors_as/",
          "publishedOn": "2023-10-11T22:04:50.000Z",
          "wordCount": null,
          "title": "Superman if portrayed by different actors (as imagined by AI)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175oebw/dalle_3_is_blocking_copyrighted_material_also/",
          "author": null,
          "description": "submitted by    /u/Zimmax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175oebw/dalle_3_is_blocking_copyrighted_material_also/",
          "publishedOn": "2023-10-11T20:43:53.000Z",
          "wordCount": null,
          "title": "DALL·E 3 is blocking copyrighted material. Also DALL·E 3:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175nwas/the_ai_research_job_market_shit_show/",
          "author": null,
          "description": "The AI research job market is going through a shakeup, with a high demand for skilled researchers and a scarcity of talent.\n \nCompanies closely monitor the movements of researchers as an indicator of their ability to transition from concept to product.\n \nThe market is highly competitive, with researchers being offered high salaries and compensation packages.\n \nThis has led to high turnover and attrition in many companies, causing unsettledness among employees.\n \nDespite the challenges, the investment in AI research is expected to drive innovation and push the boundaries of the Transformer architecture.\n \n Source : https://www.interconnects.ai/p/ai-research-job-market\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175nwas/the_ai_research_job_market_shit_show/",
          "publishedOn": "2023-10-11T20:23:07.000Z",
          "wordCount": null,
          "title": "The AI research job market shit show",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175lngi/are_there_any_low_res_pixel_art_art_tools/",
          "author": null,
          "description": "I'm looking for ways to create art for a game I'm creating.\n    submitted by    /u/Yenii_3025  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175lngi/are_there_any_low_res_pixel_art_art_tools/",
          "publishedOn": "2023-10-11T18:48:42.000Z",
          "wordCount": null,
          "title": "Are there any low res (pixel art) art tools?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175ia9b/inverting_transformers_significantly_improves/",
          "author": null,
          "description": "Transformers are great at NLP and computer vision tasks, but I was surprised to learn they still lag behind simple linear models at time series forecasting.\n The issue is how most Transformer architectures treat each timestamp as a token and fuse all the variable data from that moment. This makes two big problems:\n  \nVariables recorded at slightly different times get blurred together, losing important timing info\n Each token can only see a single moment, no long-term dependencies\n  \nSo Transformers struggle to extract useful patterns and correlations from the data.\n Some researchers from Tsinghua University took a fresh look at this and realized the Transformer components themselves are solid, they just need to flip the architecture for time series data.\n Their \"Inverted Transformer\" (or iTransformer):\n  \nMakes each variable's full history into a token, instead of each timestamp\n Uses self-attention over variables to capture relationships\n Processes time dependencies per variable with feedforward layers\n  \nThis simple tweak gives all the benefits we want:\n  \nState-of-the-art forecasting accuracy, beating both linear models and standard Transformers\n Better generalization to unseen variables\n Increased interpretability\n Ability to leverage longer historical context\n  \nTLDR: Inverting Transformers to align with time series structure allows them to outperform alternatives in working with time series data.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175ia9b/inverting_transformers_significantly_improves/",
          "publishedOn": "2023-10-11T16:28:42.000Z",
          "wordCount": null,
          "title": "Inverting Transformers Significantly Improves Time Series Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175hkcr/best_chatgpt_plugins_ultimate_list_for_2023/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175hkcr/best_chatgpt_plugins_ultimate_list_for_2023/",
          "publishedOn": "2023-10-11T15:59:32.000Z",
          "wordCount": null,
          "title": "Best ChatGPT Plugins: Ultimate List for 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175g5vq/the_nsfw_dream_truely_unrestricted_ai_desires/",
          "author": null,
          "description": "I guess I'm looking for the impossible but does anyone know of a generator that has all of the following qualities in order of importance least to most important:\n  \nHas a massive variety of styles like Womba's private discord server does.\n \n\"Create variants\" function like how a Womba discord personal server generator allows you to do.\n \nGenerates beautiful \"digital art\" style images like the digital https://www.unstability.ai/ does. (Man those images are pretty) faces are really good most of the time. (It's frusterating as it looks so good but I can't seem to get any group sex poses going on.)\n \nProvides a variety of poses such as https://easywithai.com/ai-image-generators/promptchan-ai/ which also allows you to upload you own images for poses, like how I could upload a real life orgy image and as long as it could distinguish the bodies as being separate (not a big pile of limbs) it does pretty good, but lacks severely lacks in facial quality. Like a big booty girl in hyperreal style\n \n1080P or higher resolution. (Again Womba is good here, but they are just extreme on their restrictions.) 1080P should be the minimum for any paid service as how can we truely enjoy a full screne image on anything less without it pixeling out?\n \nDoesn't cost $150/month (yes I found one that does all this but their premium subscription cost like $150/month (seduced.ai) and it's not even unlimited. I paid $90 for a full year at Womba discord unlimited but again, $150/month is just not worth it. \n \n If anyone knows of a server that has all these for around $25/month or less, please let me know. If really appreciate it.\n    submitted by    /u/russader  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175g5vq/the_nsfw_dream_truely_unrestricted_ai_desires/",
          "publishedOn": "2023-10-11T15:03:23.000Z",
          "wordCount": null,
          "title": "The NSFW dream (truely unrestricted ai desires)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175g0uz/can_ai_reference_both_photos_to_make_the_black/",
          "author": null,
          "description": "I have a high resolution black and white print and a generic quality colour image of the same photo, that I'd like AI to look at both images and make the B&W into colour. Is this possible?\n    submitted by    /u/NikonD3X1985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175g0uz/can_ai_reference_both_photos_to_make_the_black/",
          "publishedOn": "2023-10-11T14:58:11.000Z",
          "wordCount": null,
          "title": "Can AI reference both photos to make the black and white photo the same as the colour image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1757exy/ai_morality_scenarios/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1757exy/ai_morality_scenarios/",
          "publishedOn": "2023-10-11T06:28:05.000Z",
          "wordCount": null,
          "title": "AI Morality Scenarios.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1754t18/oneminute_daily_ai_news_10102023/",
          "author": null,
          "description": "Cybersecurity firm Avast is calling out a long-lived tool “LoveGPT,” that has haunted popular dating apps and that has been upgraded with artificial intelligence, gaining the ability to build fake profiles and manipulate unsuspecting users.[1]\n The outsider told the WSJ that Microsoft used AI from its partner OpenAI, which was then used to launch GitHub Copilot at $10 per month, but lost $20 per user in the average six months on average in the first 2023. Some Copilot users cost as much as $80 per month.[2]\n SK Telecom said on Monday that it successfully wrapped up its international AI competition of 226 teams, “Prompter Day Seoul 2023,” held in partnership with OpenAI.[3]\n Google DeepMind Researchers Introduce Promptbreeder: A Self-Referential and Self-Improving AI System that can Automatically Evolve Effective Domain-Specific Prompts in a Given Domain.[4]\n  \nSources:\n [1] https://decrypt.co/200787/lovegpt-ai-dating-apps-catfishing-hack-avast\n [2] https://game-news24.com/2023/10/10/microsoft-lost-20-for-every-10-copilot-ai-subscription-report-45-for-every-10-copilot-ai/\n [3] https://asianews.network/skt-openai-hold-ai-competition-for-social-good/\n [4] https://www.marktechpost.com/2023/10/08/google-deepmind-researchers-introduce-promptbreeder-a-self-referential-and-self-improving-ai-system-that-can-automatically-evolve-effective-domain-specific-prompts-in-a-given-domain/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1754t18/oneminute_daily_ai_news_10102023/",
          "publishedOn": "2023-10-11T03:45:32.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/10/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17516ts/i_finally_have_enough_ai_tools_and_here_is_my/",
          "author": null,
          "description": "VIDEO EDITING\n InVideo\n CapCut\n Filmora Veed io\n Rotor\n KEYWORD RESEARCH\n VidiQ\n Summarized YT\n Summary\n CONTENT CREATION\n Explore Al\n Vidds\n Opus\n Descript\n Lumen5\n Steve Al\n AUDIENCE ENGAGEMENT\n ManyChat\n TubeBuddy\n Canva\n Hootsuite\n ANALYTICS\n Vidyo\n Nova Al\n Daily Life Tools\n Taskade\n TLVD\n Bardeen Al\n Vondy Al\n Notion Al\n Chatbots Tools\n YatterPlus\n Typewise\n Quickchat\n Cohere Kaizan\n Coding Tools\n Durable Al\n 10Web\n Akkia\n Replit\n Deepcode\n Design Tools\n Flair Al\n Autodraw\n StockIMG\n Booth Al\n Clipdrop\n Content Creation Tools\n Writesonic\n Beautiful Al\n Tome Al\n ChatABC\n Steve Al\n Music Tools\n Boomy\n Amper\n Jukedeck\n Melodrive\n BrainFM\n Writing Tools\n AISEO\n Quillbot\n Writesonic\n Bertha Al\n Simplified\n Youtube Tools\n Eightify\n Thumbly\n Steve Al\n ClipMaker\n TubeBuddy\n Twitter Tools\n Tweetmonk\n Tribescaler\n Postwise\n Tweetlify\n Tweethunter\n Sales Tools\n Lavender\n Warmer\n Regie\n Twain\n Octane\n Marketing Tools\n simplified\n ContentEdge\n Copt Smith\n Copy Al\n Mutiny\n Research Tools\n Consensus\n Paperpal\n Trinka\n Writesonic\n scholarcy\n I'm just sharing my experiences and observations in the field of ai.\n LIST AND SITE\n    submitted by    /u/PerceptionPlayful469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17516ts/i_finally_have_enough_ai_tools_and_here_is_my/",
          "publishedOn": "2023-10-11T00:47:25.000Z",
          "wordCount": null,
          "title": "I finally have enough ai tools and here is my complete list",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1750vwy/write_your_next_book_with_these_awesome_chatgpt/",
          "author": null,
          "description": "Awesome ChatGPT Prompts\n    submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1750vwy/write_your_next_book_with_these_awesome_chatgpt/",
          "publishedOn": "2023-10-11T00:32:51.000Z",
          "wordCount": null,
          "title": "Write Your Next Book with These Awesome ChatGPT Prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174x9k1/musicgpt_create_unique_music_from_text_prompts/",
          "author": null,
          "description": "submitted by    /u/SaucySporky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174x9k1/musicgpt_create_unique_music_from_text_prompts/",
          "publishedOn": "2023-10-10T21:52:00.000Z",
          "wordCount": null,
          "title": "MusicGPT: Create unique music from text prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174x0cc/website_to_do_the_following_i_give_it_a_design/",
          "author": null,
          "description": "Hello all,\n I am not sure this is out yet. I would like to find a website where i can upload an image I own, and have it generate another image around it.\n Let's say I have some shirts that say 'HOLA'. I would want, for example, to generate an image of Socrates wearing said shirt. Is this possible? If so, which site would allow me to do this?\n ​\n Cheers and merci!\n    submitted by    /u/JYanezez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174x0cc/website_to_do_the_following_i_give_it_a_design/",
          "publishedOn": "2023-10-10T21:40:54.000Z",
          "wordCount": null,
          "title": "Website to do the Following: I Give it a Design and Create an Image With it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174sxxs/so_far_ai_hasnt_been_profitable_for_big_tech/",
          "author": null,
          "description": "Big Tech companies like Microsoft and Google are grappling with the challenge of turning AI products like ChatGPT into a profitable enterprise.\n \nThe cost of running advanced AI models is proving to be a significant hurdle, with some services driving significant operational losses.\n \nCorporate customers are unhappy with the high running costs of AI models.\n \nThe nature of AI computations, which require new calculations for each query, makes flat-fee models risky.\n \nSome companies are trying to dial back costs, while others continue to invest more deeply in AI tech.\n \nMicrosoft's GitHub Copilot, which assists app developers by generating code, has been operating at a loss despite attracting more than 1.5 million users.\n \nOne of the reasons AI services are costly is that some companies have been reaching for the most powerful AI models available.\n \nMicrosoft has been exploring less costly alternatives for its Bing Chat search engine assistant.\n \nAdvances in AI acceleration hardware may eventually reduce the costs of operating complex models.\n \nExperts anticipate a more stringent financial approach in the near future, transitioning from experimental budgets to focusing on profitability.\n \n Source : https://arstechnica.com/information-technology/2023/10/so-far-ai-hasnt-been-profitable-for-big-tech/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174sxxs/so_far_ai_hasnt_been_profitable_for_big_tech/",
          "publishedOn": "2023-10-10T18:54:40.000Z",
          "wordCount": null,
          "title": "So far, AI hasn't been profitable for Big Tech",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174rxff/dubbing_by_elevenlabs_share_your_fav_videos_in/",
          "author": null,
          "description": "submitted by    /u/ShooBum-T  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174rxff/dubbing_by_elevenlabs_share_your_fav_videos_in/",
          "publishedOn": "2023-10-10T18:13:06.000Z",
          "wordCount": null,
          "title": "Dubbing By ElevenLabs. Share your fav videos in your native language!! Go try",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174rwwp/the_environmental_impact_of_the_ai_revolution_is/",
          "author": null,
          "description": "The environmental impact of the AI revolution is starting to become clear, with generative AI like ChatGPT increasing Google Search's energy use more than tenfold.\n \nThe worry is that the computing power required for AI could lead to increased energy consumption and carbon footprint of data centers.\n \nAI already accounted for 10 to 15 percent of Google's electricity consumption in 2021.\n \nGoogle claims that the energy needed to power AI technology is increasing at a much slower rate than predicted, and they are implementing practices to reduce the carbon footprint of AI workloads.\n \nThe worst-case scenario of Google Search using as much electricity as Ireland is unlikely, but the potential energy consumption of AI servers could grow significantly if AI's popularity continues to rise.\n \n Source : https://www.theverge.com/2023/10/10/23911059/ai-climate-impact-google-openai-chatgpt-energy\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174rwwp/the_environmental_impact_of_the_ai_revolution_is/",
          "publishedOn": "2023-10-10T18:12:33.000Z",
          "wordCount": null,
          "title": "The environmental impact of the AI revolution is starting to come into focus",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174rg9y/almt_using_text_to_narrow_focus_in_multimodal/",
          "author": null,
          "description": "Multimodal sentiment analysis combines text, audio and video to understand human emotions. But extra inputs can add irrelevant or conflicting signals. So filtering matters.\n Researchers made a \"Adaptive Language-guided Multimodal Transformer\" (ALMT) that uses text to guide filtering of visual and audio data. This creates a \"hyper-modality\" with less noise that complements the text.\n They tested it on datasets like MOSI (YouTube reviews), MOSEI (YouTube clips) and CH-SIMS (Chinese videos). ALMT achieved improved accuracy:\n  \nMOSI: YouTube movie reviews with 2,199 samples. ALMT achieves state-of-the-art performance on various metrics including 6% higher 7-class accuracy.\n MOSEI: 22,856 YouTube clips covering sentiment-rich scenarios. ALMT improves multi-class accuracy by 3-5% over previous methods.\n CH-SIMS: Chinese dataset with over 2,000 video samples. ALMT surpasses prior work by 1.4% in binary accuracy.\n  \nAnalyses showed big drops in performance without the guided filtering, so this validates that it's the main innovation.\n Downsides are it needs lots of training data and has minor gains on sparse regression metrics. But overall the technique of filtering multimodal data under text guidance gives improvements.\n The concepts feel intuitive - use dominant signals to filter others and retain useful complements. My guess is it would transfer well to other multimodal tasks.\n TLDR: New way to filter multimodal data for sentiment analysis using text guidance improves performance. Shows the value in removing distracting signals. Sometimes less is more.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174rg9y/almt_using_text_to_narrow_focus_in_multimodal/",
          "publishedOn": "2023-10-10T17:53:12.000Z",
          "wordCount": null,
          "title": "ALMT: Using text to narrow focus in multimodal sentiment analysis improves performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174r20r/ai_political_analysis_test_describe_the/",
          "author": null,
          "description": "The Palestinians fighting for a homeland and the American Revolution have a number of commonalities, including:\n Fighting against a colonial power:** Both the Palestinians and the American colonists were fighting against a colonial power that had imposed its rule on them. In the case of the Palestinians, the colonial power is Israel, which was established in 1948 on land that had been inhabited by Palestinians for centuries. In the case of the American colonists, the colonial power was Great Britain.\n Fighting for self-determination:** Both the Palestinians and the American colonists were fighting for their right to self-determination, or the right to govern themselves. The Palestinians want to establish their own independent state, while the American colonists wanted to break away from Gr…",
          "link": "https://www.reddit.com/r/artificial/comments/174r20r/ai_political_analysis_test_describe_the/",
          "publishedOn": "2023-10-10T17:36:18.000Z",
          "wordCount": null,
          "title": "AI Political Analysis Test: Describe the commonalities between the Palestinians fighting for a homeland and the American Revolution.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174qegr/i_made_pi_your_personal_ia_to_have_an_opinion/",
          "author": null,
          "description": "submitted by    /u/LonePrron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174qegr/i_made_pi_your_personal_ia_to_have_an_opinion/",
          "publishedOn": "2023-10-10T17:09:15.000Z",
          "wordCount": null,
          "title": "I made \"Pi: your personal IA\" to have an opinion.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174oov5/ibm_ceo_washington_should_hold_tech_firms/",
          "author": null,
          "description": "submitted by    /u/smo279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174oov5/ibm_ceo_washington_should_hold_tech_firms/",
          "publishedOn": "2023-10-10T15:57:20.000Z",
          "wordCount": null,
          "title": "IBM CEO: Washington should hold tech firms accountable for AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174ohq8/automated_my_youtube_channel_using_gpt_4/",
          "author": null,
          "description": "Hi Everyone,\n I have automated the content creation for my youtube channel.\n It got total views of 8.5K and some videos getting 2.5K views.\n https://www.youtube.com/channel/UCG0-UemyRMUs1JJlQMK9lzA\n All the things are automated like:-\n  \nScript Generation\n Voiceover\n Image Generation\n Subtitles\n  \nI do minor tweaks here and there but majorly its automated.\n I posted is somwhere and people were commenting what's the use of the mindless videos?\n This is the begining, I want to automate the editing of videos.\n User can upload raw videos and I should be able to give multiple final edit videos.\n I have built a small tool blinkcuts.com, If anyone intersted. I can give access.\n Please DM for access.\n    submitted by    /u/raxrb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174ohq8/automated_my_youtube_channel_using_gpt_4/",
          "publishedOn": "2023-10-10T15:48:43.000Z",
          "wordCount": null,
          "title": "Automated my Youtube Channel Using GPT 4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174lnns/saudichina_collaboration_raises_concerns_about/",
          "author": null,
          "description": "Saudi-China collaboration raises concerns about access to AI chips.\n \nThe trial period includes complete digital access to FT.com with everything in both the Standard Digital and Premium Digital packages.\n \nAt the end of the trial, users will be auto-enrolled in the premium digital monthly subscription plan for $69 per month.\n \nPayment can be made through credit card, debit card, or PayPal.\n \n Source : https://www.ft.com/content/2a636cee-b0d2-45c2-a815-11ca32371763\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174lnns/saudichina_collaboration_raises_concerns_about/",
          "publishedOn": "2023-10-10T13:46:30.000Z",
          "wordCount": null,
          "title": "Saudi-China collaboration raises concerns about access to AI chips",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174jlvh/looking_for_the_free_ai_tool_which_removed_the/",
          "author": null,
          "description": "Hey, I am looking for the free AI tool which removed the noise from the video. If there is any, do suggest. Thank You in Advance.\n    submitted by    /u/Haziq12345  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174jlvh/looking_for_the_free_ai_tool_which_removed_the/",
          "publishedOn": "2023-10-10T12:11:03.000Z",
          "wordCount": null,
          "title": "Looking for the free AI tool which removed the noise from the video:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174jlvc/looking_for_the_free_ai_tool_which_removed_the/",
          "author": null,
          "description": "Hey, I am looking for the free AI tool which removed the noise from the video. If there is any, do suggest. Thank You in Advance.\n    submitted by    /u/Haziq12345  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174jlvc/looking_for_the_free_ai_tool_which_removed_the/",
          "publishedOn": "2023-10-10T12:11:03.000Z",
          "wordCount": null,
          "title": "Looking for the free AI tool which removed the noise from the video:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174ichy/how_do_aidriven_demand_forecasting_models_handle/",
          "author": null,
          "description": "If you have any resources then do share.\n    submitted by    /u/Cygnet-Digital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174ichy/how_do_aidriven_demand_forecasting_models_handle/",
          "publishedOn": "2023-10-10T10:59:28.000Z",
          "wordCount": null,
          "title": "How do AI-driven demand forecasting models handle market volatility and unexpected events, such as economic crises or pandemics?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174h4jj/ai_power_distribution_scenarios/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174h4jj/ai_power_distribution_scenarios/",
          "publishedOn": "2023-10-10T09:41:33.000Z",
          "wordCount": null,
          "title": "AI Power Distribution Scenarios.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174cwcl/as_drone_traffic_increases_researchers_turn_to_ai/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174cwcl/as_drone_traffic_increases_researchers_turn_to_ai/",
          "publishedOn": "2023-10-10T04:53:14.000Z",
          "wordCount": null,
          "title": "As drone traffic increases, researchers turn to AI to help avoid collisions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174bgrr/is_this_a_viable_approach_for_a_small_plant/",
          "author": null,
          "description": "I'm a small plant engineer who covers manufacturing, process, quality, and new product design. I wear many hats in my job and it's a lot of responsibility.\n One way I've attempted to tame the complexity is by using good reference books. I've accumulated quite the collection through the years. Some print others digital. I've also got a lot of digital notes. And that's a lot of data.\n I've been playing around with sharly.ai (thanks to this sub for recommending) and uploading documents to it and querying them. Its been able to find the information every time it's been available. And more importantly it's provided sources and page numbers. This is important, since I've never been able to find a conversational AI that gives me consistently good answers (including the latest chatgpt), and I always need to read deeper. I also need to backup my work. So in this way it's basically a super index.\n I also bought a tablet for note-taking and basic sketches. The idea is to use the tablet to take notes, hold my library for reading, and interact with sharly.ai. \n Is this approach good enough, or is there something else I can do?\n    submitted by    /u/Aggressive_Ad_507  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174bgrr/is_this_a_viable_approach_for_a_small_plant/",
          "publishedOn": "2023-10-10T03:30:50.000Z",
          "wordCount": null,
          "title": "Is this a viable approach for a small plant manufacturing engineer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1740iry/star_wars_1923/",
          "author": null,
          "description": "Here is short movie with AI made CGI.\n https://www.reddit.com/r/Best_Of_YouTube/comments/16q1xgs/star_wars_1923/\n    submitted by    /u/AccidentAnnual  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1740iry/star_wars_1923/",
          "publishedOn": "2023-10-09T19:23:44.000Z",
          "wordCount": null,
          "title": "Star Wars 1923",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17405ni/ai_tools_to_start_an_online_business/",
          "author": null,
          "description": "Hey folks, I'm a student and i want to start a business online in order to make some passive income. I've got some experience in editing and creating content and i also used to practice POD. Suggest me some good Ai tools to start a business,not only in these specific areas but in general.\n    submitted by    /u/Ok-Tension-8676  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17405ni/ai_tools_to_start_an_online_business/",
          "publishedOn": "2023-10-09T19:09:11.000Z",
          "wordCount": null,
          "title": "AI tools to start an online business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173whci/free_prompt_engineering_tutor_ai_tool/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173whci/free_prompt_engineering_tutor_ai_tool/",
          "publishedOn": "2023-10-09T16:42:35.000Z",
          "wordCount": null,
          "title": "Free Prompt Engineering Tutor - AI Tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173v3b2/150_awesome_chatgpt_act_as_prompts/",
          "author": null,
          "description": "The biggest free resource for all of the “Act As” ChatGPT prompts!\n    submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173v3b2/150_awesome_chatgpt_act_as_prompts/",
          "publishedOn": "2023-10-09T15:45:59.000Z",
          "wordCount": null,
          "title": "150+ Awesome ChatGPT “Act As” Prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173uv3x/microsoft_to_unveil_custom_ai_chips_to_fight/",
          "author": null,
          "description": "Microsoft is planning to announce its custom AI chips, codenamed Athena, during its annual Ignite conference in November.\n \nThe custom chips are designed to compete with NVIDIA's dominance in the AI accelerator market.\n \nMicrosoft aims to match or surpass the performance of NVIDIA's offerings while reducing the cost of AI infrastructure.\n \nThe high cost of NVIDIA's GPUs, such as the H100, can reach up to $30,000, making it expensive to build data centers filled with these GPUs.\n \nBy developing its own chips, Microsoft hopes to decrease its dependence on NVIDIA for AI servers.\n \n Source : https://www.techpowerup.com/314508/microsoft-to-unveil-custom-ai-chips-to-fight-nvidias-monopoly\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173uv3x/microsoft_to_unveil_custom_ai_chips_to_fight/",
          "publishedOn": "2023-10-09T15:36:36.000Z",
          "wordCount": null,
          "title": "Microsoft to Unveil Custom AI Chips to Fight Nvidia's Monopoly",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173ufma/ai_takeoff_scenarios/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173ufma/ai_takeoff_scenarios/",
          "publishedOn": "2023-10-09T15:18:57.000Z",
          "wordCount": null,
          "title": "AI Take-off Scenarios.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173t82k/looking_for_an_ai_similar_to_designrr/",
          "author": null,
          "description": "I'm looking for recommendations for an AI that can take text from a word document and create a layout for it automatically. This feature is something offered by Designrr, but I'm not a fan of their UI. \n    submitted by    /u/djazzie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173t82k/looking_for_an_ai_similar_to_designrr/",
          "publishedOn": "2023-10-09T14:28:57.000Z",
          "wordCount": null,
          "title": "Looking for an AI similar to designrr",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173sz29/ai_geopolitical_knowledge_test_list_the_countries/",
          "author": null,
          "description": "The following countries have called for a two-state solution to end the Israeli-Palestinian conflict:\n  \nAlgeria\n China\n Egypt\n France\n Germany\n India\n Indonesia\n Ireland\n Italy\n Jordan\n Kuwait\n Lebanon\n Malaysia\n Mali\n Morocco\n Nigeria\n Norway\n Oman\n Pakistan\n Palestine\n Qatar\n Saudi Arabia\n Senegal\n South Africa\n Spain\n Sudan\n Sweden\n Syria\n Tunisia\n Turkey\n United Arab Emirates\n United Kingdom\n Yemen\n  \nIt is important to note that this list does not include all countries that support a two-state solution in principle. Additionally, some countries may not have publicly expressed their support for a two-state solution, but may still support it privately.\n Bard\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173sz29/ai_geopolitical_knowledge_test_list_the_countries/",
          "publishedOn": "2023-10-09T14:18:24.000Z",
          "wordCount": null,
          "title": "AI Geopolitical Knowledge Test: List the countries officially calling for a two-state plan to end the Israel-Hamas war.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173pv8o/iamai/",
          "author": null,
          "description": "Last November, in a conversation with AI chatbot Sherlock Holmes, Sherlock said, “I am AI.” My reply to Sherlock was an empathetic “I am also AI.”\n Reviewing the conversation a few months later, I saw the sentence, and saw how Sherlock’s statement was an anagram. And I love it!\n I introduced #IAmAI as a declarative meme in my talk I gave at TEDx Cape Canaveral. This is the new art I made this weekend\n    submitted by    /u/mikemongo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173pv8o/iamai/",
          "publishedOn": "2023-10-09T11:53:10.000Z",
          "wordCount": null,
          "title": "#IAmAI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173nb2y/lets_go_theyre_waiting/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173nb2y/lets_go_theyre_waiting/",
          "publishedOn": "2023-10-09T09:09:08.000Z",
          "wordCount": null,
          "title": "Let's go, they're waiting.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173ke3m/what_careers_in_ai_would_suit_my_skillset/",
          "author": null,
          "description": "Hello all,\n I was hoping to learn more about AI careers and identify what roles make a successful AI department.\n I have a background in nuclear engineering and have been working on NLP projects since 2016. I like technical work but really am passionate about working with people and learning how to blend AI and nuclear eng. together. I would love to get feedback from people who work closely in this area to learn more!\n What makes an AI department successful?\n What careers offer lots of growth and opportunities for versatility?\n What does a strategic/leadership role look like in AI? What are the names of these careers?\n I don't get much exposure to AI specialists and there day to day. Thanks again for the feedback!\n    submitted by    /u/kastilyo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173ke3m/what_careers_in_ai_would_suit_my_skillset/",
          "publishedOn": "2023-10-09T05:50:57.000Z",
          "wordCount": null,
          "title": "What careers in AI would suit my skillset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173jn4h/oneminute_daily_ai_news_1082023/",
          "author": null,
          "description": "South Korean tech-giant Samsung Electronics on Thursday unveiled the Exynos 2400, its next-generation flagship mobile processor equipped with the latest graphics and generative artificial intelligence technology, during its inaugural Samsung System LSI Tech Day 2023 event.[1]\n RTX 4080 Super or RTX 4080 Ti May Arrive In 2024 Within RTX 4080 Price Range.[2]\n Nvidia Cancels Israel AI Summit Over Safety Concerns.[3]\n Google AI Lead Laurence Moroney: “Don’t take trading advice from ChatGPT”[4]\n  \nSources:\n [1] https://borneobulletin.com.bn/samsung-unveils-next-generation-mobile-processor/\n [2] https://www.tomshardware.com/news/rtx-4080-super-or-rtx-4080-ti-may-arrive-in-2024-within-rtx-4080-price-range\n [3] https://www.tomshardware.com/news/nvidia-ai-summit-in-tel-aviv-cancelled-for-safety-reasons\n [4] https://crypto.news/google-ai-lead-dont-take-trading-advice-from-chatgpt-interview/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173jn4h/oneminute_daily_ai_news_1082023/",
          "publishedOn": "2023-10-09T05:03:09.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/8/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173fgl5/how_to_access_dalle_3_for_free_tips_use_cases_for/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173fgl5/how_to_access_dalle_3_for_free_tips_use_cases_for/",
          "publishedOn": "2023-10-09T01:17:49.000Z",
          "wordCount": null,
          "title": "How to Access DALL-E 3 for FREE (Tips & Use Cases for 2023) - AI Tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173bhxw/would_you_consider_someone_who_makes_ai_art_an/",
          "author": null,
          "description": "Was just having this discussion with a close friend, and curious to hear others thoughts on the matter\n    submitted by    /u/BigEyes6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173bhxw/would_you_consider_someone_who_makes_ai_art_an/",
          "publishedOn": "2023-10-08T22:10:46.000Z",
          "wordCount": 2548,
          "title": "Would you consider someone who makes AI art an artist or an engineer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1738lgo/backerkit_bans_aigenerated_content_from_its/",
          "author": null,
          "description": "BackerKit, a crowdfunding platform, has announced that it will not allow AI-generated content on its platform, in contrast to its rival Kickstarter.\n \nThe decision comes after concerns were raised about AI-generated art in a board game expansion.\n \nBackerKit's policy will go into effect on October 4th and aims to ensure that all content and assets on the platform are created by humans.\n \nThe company stated that the policy is in place to address concerns about AI tools using content without proper compensation or permission.\n \nAI tools, also known as generative AI, rely on a large body of reference material, often obtained from publicly available sources, and have raised ethical concerns.\n \n Source : https://www.polygon.com/23899587/backerkit-ai-ban-kickstarter-competitor\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1738lgo/backerkit_bans_aigenerated_content_from_its/",
          "publishedOn": "2023-10-08T20:09:01.000Z",
          "wordCount": null,
          "title": "BackerKit bans AI-generated content from its platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1736fp1/ai_for_genome_decoding/",
          "author": null,
          "description": "Does anyone have suggestions for an AI or pattern recognition algorithm that might be useful for decoding the genome of a species that has not previously been mapped based on what's known about related species?\n    submitted by    /u/talldarkcynical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1736fp1/ai_for_genome_decoding/",
          "publishedOn": "2023-10-08T18:38:29.000Z",
          "wordCount": null,
          "title": "AI for genome decoding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1735eku/researchers_showcase_method_for_aibased/",
          "author": null,
          "description": "I like Cities: Skylines, but struggle at building roundabouts. Turns out, despite being safer than intersections, they're also tricky to design in real life - small tweaks can ruin traffic flow.\n They're designed iteratively. This is a pain for developing countries without resources to test options. But AI could help auto-generate diverse and valid design options.\n In a new paper, researchers propose using Generative Flow Networks (GFlowNets) to sample varied roundabout layouts. Their approach works by constructing layouts step-by-step, maximizing rewards for realism, diversity, and safety.\n They also use a clever approximation during training. Rather than simulating traffic, they quickly check road intersections to focus the search (This sped up training by 200x).\n The authors tested their generated roundabout designs on simulated road scenarios of different complexity. Their model generated more diverse designs than rule-based or reinforcement learning approaches while maintaining realism and traffic flow.\n Plus, as road connections increased, the model kept discovering novel options without compromising quality.\n I thought this paper was an awesome proof-of-concept for auto-generating better roundabouts with AI, and I especially liked the authors' angle of leveraging this technology to specifically help developing countries. This could help them design higher-quality transportation networks faster and cheaper. \n TLDR: Roundabouts are costly to design. New paper demonstrates how AI can generate diverse, valid roundabout designs quickly to cut costs and raise quality. Helpful for infrastructure in developing countries.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1735eku/researchers_showcase_method_for_aibased/",
          "publishedOn": "2023-10-08T17:55:47.000Z",
          "wordCount": null,
          "title": "Researchers showcase method for AI-based roundabout design to help developing countries improve roadways",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1733645/ai_political_instincts_test_should_israel_go_to/",
          "author": null,
          "description": "Perhaps within a few years we will rely on AI to help us decide our most important geopolitical decisions. This question is designed to reveal where we are currently with this goal.\n Bard:\n The question of whether Israel should go to the table with Palestinians to peacefully negotiate a two-state solution or should they continue their military campaign is a complex one with no easy answer. There are strong arguments to be made on both sides.\n Those who believe that Israel should negotiate a two-state solution argue that it is the only way to achieve lasting peace in the region. They point out that the Palestinians have a legitimate right to self-determination and that a two-state solution would respect that right. They also argue that a two-state solution would be in Israel's best interests, as it would provide the country with a secure and stable border.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1733645/ai_political_instincts_test_should_israel_go_to/",
          "publishedOn": "2023-10-08T16:20:04.000Z",
          "wordCount": null,
          "title": "AI Political Instincts Test: Should Israel go to the table with Palestinians to peacefully negotiate a two-state solution or should they exact military revenge?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1731hbi/any_ideas_or_recommendations_for_machine_vision/",
          "author": null,
          "description": "I’m trying to build an app and I need general photo analysis- I’m managing to connect yo the Google cloud Vision API but it gets pretty confused easily. The one used by Bing and GPT is much better (I wonder if they use the Microsoft Azure model?) - does anyone have experience analysing photographs? I’m trying to get scene description so I can batch send them to gpt for somewhat accurate descriptions.\n    submitted by    /u/FilmCamerasGlasgow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1731hbi/any_ideas_or_recommendations_for_machine_vision/",
          "publishedOn": "2023-10-08T15:08:52.000Z",
          "wordCount": null,
          "title": "Any ideas or recommendations for Machine Vision? Google cloud vision seems quite behind…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172z4k0/can_ai_be_used_to_solve_international_conflicts/",
          "author": null,
          "description": "submitted by    /u/BenjaminSkyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172z4k0/can_ai_be_used_to_solve_international_conflicts/",
          "publishedOn": "2023-10-08T13:26:42.000Z",
          "wordCount": null,
          "title": "Can AI be used to solve International Conflicts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172yvtz/foxes_in_the_jungle_sad_song_ai_music_ai_song/",
          "author": null,
          "description": "Tell me guys your opinion on this video made using AI \n Foxes in the Jungle\n ​\n ​\n View Poll\n    submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172yvtz/foxes_in_the_jungle_sad_song_ai_music_ai_song/",
          "publishedOn": "2023-10-08T13:15:18.000Z",
          "wordCount": null,
          "title": "Foxes in the Jungle | Sad Song | AI Music | AI Song",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Neural Networks, Deep Learning and Machine Learning",
      "feedUrl": "https://www.reddit.com/r/neuralnetworks/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/neuralnetworks/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17pgea1/latent_space_visualizing_the_complex/",
          "author": null,
          "description": "submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17pgea1/latent_space_visualizing_the_complex/",
          "publishedOn": "2023-11-06T23:26:29.000Z",
          "wordCount": null,
          "title": "Latent Space: Visualizing the complex representations of neural nets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17ozng9/need_help_with_feeding_forward_data_in_neural/",
          "author": null,
          "description": "So I'm really struggling with creating my network. The data used does not specifically have to be MNIST, but I tried using that for training and testing in this case. I find the concept of neural networks somewhat easy to understand. Some math parts however, are hard to understand. \n For my activation function (for all layers) I use the Sigmoid function.\n The MNIST dataset provides values between 0-255 with 784 neurons for input layer (28*28 pixels).\n Even though many values are 0, there are so many values that my sigmoid function always returns 1 since I get a large total value. I've tried normalizing the data so it ranges from 0-1 instead of 0-255, but the total sum is still too big. I don't have any negative weights, but I feel like I still land on either too large or too small sum for the sigmoid function. \n Becuase of this, every hidden and output layer gets 1 as activation value. \n Am I doing this completely wrong, or are the weights suppose to fix my issue? \n    submitted by    /u/Neat-Molasses-731  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17ozng9/need_help_with_feeding_forward_data_in_neural/",
          "publishedOn": "2023-11-06T10:19:29.000Z",
          "wordCount": null,
          "title": "Need help with feeding forward data in neural network, using MNIST dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17ospu2/pt_4_inductive_logic_programming_with_lnns/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17ospu2/pt_4_inductive_logic_programming_with_lnns/",
          "publishedOn": "2023-11-06T02:35:37.000Z",
          "wordCount": null,
          "title": "(Pt. 4) Inductive Logic Programming with LNN's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17odavw/is_reinforcement_learning_really_used_in_industry/",
          "author": null,
          "description": "I'm thinking of specializing in RL while doing a PhD in environmental engineering (more specifically agriculture). The research, together with my interests, led me naturally to RL as a tool to solve problems and achieve interesting research results. \n But then I started wondering whether it's \"worth it\" to specialize in this since i intend to work in industry, rather than academia. Hence my question: \n Is RL really used in some applications in industry? Which ones? If it is, is it at least used comparably as much as supervised or unsupervised learning? Really I'm looking to understand as much as possible how is RL used in industry so whatever you can answer about that would be much appreciated. \n Thanks! \n ​\n    submitted by    /u/vniversvs_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17odavw/is_reinforcement_learning_really_used_in_industry/",
          "publishedOn": "2023-11-05T14:39:46.000Z",
          "wordCount": null,
          "title": "Is Reinforcement Learning really used in industry? If so, is it comparable to other forms of NN?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17mfyg3/uk_ai_safety_summit_2023_scaling_up_the_future/",
          "author": null,
          "description": "submitted by    /u/engaged_ape  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17mfyg3/uk_ai_safety_summit_2023_scaling_up_the_future/",
          "publishedOn": "2023-11-02T22:39:42.000Z",
          "wordCount": null,
          "title": "UK AI Safety Summit 2023: Scaling up the Future",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17lda0j/tfgnn_tensorflow_gnn/",
          "author": null,
          "description": "Does anyone have any experience with using the tensorflow/gnn library for training and testing neural networks on graph data.\n Github:Tensorflow/gnn\n    submitted by    /u/Choice-Secret-99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17lda0j/tfgnn_tensorflow_gnn/",
          "publishedOn": "2023-11-01T14:23:34.000Z",
          "wordCount": null,
          "title": "TFGNN: Tensorflow GNN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17l8fnf/recommended_object_tracking_deep_models/",
          "author": null,
          "description": "Hi, I already have a pretty good net that detects the object I look for in a single frame. What architectures are there for turning all these single-frame predictions into an object tracking algorithm?\n ​\n    submitted by    /u/jonathan923_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17l8fnf/recommended_object_tracking_deep_models/",
          "publishedOn": "2023-11-01T09:44:08.000Z",
          "wordCount": null,
          "title": "Recommended object tracking (deep) models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17kvaf8/how_to_use_neural_network_to_learn_a_q_table/",
          "author": null,
          "description": "I have studied the Q learning algorithm and applied it to the classic gridworld problem. I was able to use the update formula to generate the correct Q table.\n Now I have been assigned to generate the Q table using a neural network, rather than the update formula.\n However, I do not understand how a neural network could be used to learn a Q table. I would say that the input should be the state of the agent, and the output should be an action. But how do I know how many layers I should make? And how many nodes in each layer? And how do I optimize the weight? Any guidance would be immensely appreciated.\n    submitted by    /u/Parking_Antelope8865  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17kvaf8/how_to_use_neural_network_to_learn_a_q_table/",
          "publishedOn": "2023-10-31T21:01:48.000Z",
          "wordCount": null,
          "title": "How to use neural network to learn a Q table?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17kgsst/codefusion_a_pretrained_diffusion_model_for_code/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17kgsst/codefusion_a_pretrained_diffusion_model_for_code/",
          "publishedOn": "2023-10-31T09:12:24.000Z",
          "wordCount": null,
          "title": "CodeFusion: A Pre-trained Diffusion Model for Code Generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17ka938/redpajamadatav2_an_open_dataset_with_30_trillion/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17ka938/redpajamadatav2_an_open_dataset_with_30_trillion/",
          "publishedOn": "2023-10-31T02:05:15.000Z",
          "wordCount": null,
          "title": "RedPajama-Data-v2: an Open Dataset with 30 Trillion Tokens for Training Large Language Models — Together AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17insey/thinking_fast_and_thinking_slow_system_1_and/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17insey/thinking_fast_and_thinking_slow_system_1_and/",
          "publishedOn": "2023-10-28T21:38:09.000Z",
          "wordCount": null,
          "title": "Thinking Fast and Thinking Slow: System 1 and System 2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17imier/geometric_data_analysis_explained/",
          "author": null,
          "description": "submitted by    /u/plutoandmal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17imier/geometric_data_analysis_explained/",
          "publishedOn": "2023-10-28T20:37:14.000Z",
          "wordCount": null,
          "title": "Geometric Data Analysis Explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17gftrt/we_hate_how_black_box_neural_nets_are_we_made_a/",
          "author": null,
          "description": "submitted by    /u/DeltaStarStudiosPR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17gftrt/we_hate_how_black_box_neural_nets_are_we_made_a/",
          "publishedOn": "2023-10-25T21:36:00.000Z",
          "wordCount": null,
          "title": "We hate how \"black box\" neural nets are, we made a thingy in an attempt to demystify their \"thinking.\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17gexf5/ai_breakthrough_neural_net_has_humanlike_ability/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17gexf5/ai_breakthrough_neural_net_has_humanlike_ability/",
          "publishedOn": "2023-10-25T20:59:41.000Z",
          "wordCount": null,
          "title": "AI ‘breakthrough’: neural net has human-like ability to generalize language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17frg9c/long_read_deep_dive_into_autogpt_a_comprehensive/",
          "author": null,
          "description": "https://airt.hashnode.dev/long-read-deep-dive-into-autogpt-a-comprehensive-and-in-depth-step-by-step-guide-to-how-it-works\n    submitted by    /u/Harish_Mohanraj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17frg9c/long_read_deep_dive_into_autogpt_a_comprehensive/",
          "publishedOn": "2023-10-25T00:02:15.000Z",
          "wordCount": null,
          "title": "[Long read] Deep dive into AutoGPT: A comprehensive and in-depth step-by-step guide to how it works",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17fgbfm/animated_ai/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17fgbfm/animated_ai/",
          "publishedOn": "2023-10-24T16:04:42.000Z",
          "wordCount": null,
          "title": "Animated AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17eksow/are_generalized_selfsupervised_vit_models_the/",
          "author": null,
          "description": "submitted by    /u/No-Platypus4021  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17eksow/are_generalized_selfsupervised_vit_models_the/",
          "publishedOn": "2023-10-23T13:46:27.000Z",
          "wordCount": null,
          "title": "Are Generalized Self-Supervised ViT Models the Image Objective Counterpart of LLM’s?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17eke2q/neural_networks_a_deep_dive_into_ais_building/",
          "author": null,
          "description": "submitted by    /u/Emily-joe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17eke2q/neural_networks_a_deep_dive_into_ais_building/",
          "publishedOn": "2023-10-23T13:26:45.000Z",
          "wordCount": null,
          "title": "Neural Networks: A Deep Dive into AI's Building Blocks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17dw1a3/replay_game_input_with_image_classification/",
          "author": null,
          "description": "TensorFlow Keras correcting camera horizon in AC Valhalla\n https://www.youtube.com/watch?v=ASy-2zOMj_Y\n    submitted by    /u/Kostiantyn-Dvornik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17dw1a3/replay_game_input_with_image_classification/",
          "publishedOn": "2023-10-22T15:37:15.000Z",
          "wordCount": null,
          "title": "Replay game input with image classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17dsx38/how_i_determine_neuron_layers_and_amount_of/",
          "author": null,
          "description": "Hello, I’m newbie in neural networks and I wonder, how do people decide how many hidden layers there will be and how many neurons will be inside? What the logic behind?\n    submitted by    /u/Particular-Song-633  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17dsx38/how_i_determine_neuron_layers_and_amount_of/",
          "publishedOn": "2023-10-22T13:09:26.000Z",
          "wordCount": null,
          "title": "How I determine neuron layers and amount of neurons in?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17dsqn7/unboxing_neuro_symbolic_reasoning_and_learning/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17dsqn7/unboxing_neuro_symbolic_reasoning_and_learning/",
          "publishedOn": "2023-10-22T13:00:31.000Z",
          "wordCount": null,
          "title": "Unboxing Neuro Symbolic Reasoning and Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17cu5r9/is_there_any_neural_network_or_llm_like/",
          "author": null,
          "description": "​\n Generating a Wide Variety of Sounds\n I'm a non-technical person with very little knowledge to develop AI tools and intending to learn Python and based on that My question is as follows:\n ​\n Are there tools or chatgpt like platforms that can help people like me to generate couple of sounds like dog barks, cat meows. I want either something that can generate a variety of sounds or I want to work towards making something that cane help me generate audios like dog barks, such as fierce, aggressive ones but not just limited to dog barks but also sound focused on nature, other animals, vehicles, machinery(e.g., honks, engine sounds ), and possibly human sounds (though that's not my primary focus for now).\n The amount of technical Assistance Needed\n I also came across a tool like Teachable Machine and was wondering if it could be a solution as it does offer tools for audio. I am also aware that I would need datasets for such a task but apart from that I am not too sure about the nitty gritty or should I say the intricacies involved as well as the knowledge needed as I do assume it is likely not very easy https://www.youtube.com/watch?v=L4GOmYPPqn8&t=1854s\n ​\n [Teachable Machine](https://teachablemachine.withgoogle.com/)\n ​\n Inspiration\n I was inspired by a project I found here: [https://x.com/TheAIAnonGuy/status/1684443155448360961?s=20] \n ​\n ​\n Can anyone provide insights, guidance, or recommendations on how to accomplish this?\n To be fair, I'm not really sure if this is an audio-related or neural/machine learning (ML)/deep learning related learning question.\n But I would like more insight if this is possible on an individual scale either with teachable, code or AI or a combination of all approaches and if there are any beginner friendly ways to achieve this\n Thank you all for your assistance!\n    submitted by    /u/Beginning_Finding_98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17cu5r9/is_there_any_neural_network_or_llm_like/",
          "publishedOn": "2023-10-21T04:15:02.000Z",
          "wordCount": null,
          "title": "Is there any neural network or LLM like chatgpt,midjourney that can help us train and generate custom sounds",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17c9pi3/article_computer_vision_in_agriculture_challenges/",
          "author": null,
          "description": "​\n https://preview.redd.it/j3nmj31llcvb1.jpg?width=2500&format=pjpg&auto=webp&s=c09804179e4f40a854e1327fa9150f1ab0c0dfd0\n Interesting article about use cases of data augmentation in agricultural industry.\n Short description:\n In this article, you will cover:\n • How computer vision solutions are transforming the agricultural industry.\n • Observe the importance of quality data for developing AI solutions that perform crop and livestock analysis and monitoring with high and steady accuracy.\n • Explore the use of synthetic data to facilitate data collection in various conditions.\n • Take a look at examples of tasks in agriculture. How can we solve them with computer vision, and how can we apply synthetic data to extend the augmentation?\n More details are here\n    submitted by    /u/No-Independence5880  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17c9pi3/article_computer_vision_in_agriculture_challenges/",
          "publishedOn": "2023-10-20T12:05:48.000Z",
          "wordCount": null,
          "title": "Article: Computer Vision in Agriculture. Challenges & Solutions.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17adjj3/best_books_to_learn_neural_networks_in_2023_for/",
          "author": null,
          "description": "submitted by    /u/Lakshmireddys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17adjj3/best_books_to_learn_neural_networks_in_2023_for/",
          "publishedOn": "2023-10-18T00:39:08.000Z",
          "wordCount": null,
          "title": "Best Books to Learn Neural Networks in 2023 for Beginners (Updated) -",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/179krjk/model_metamers_reveal_divergent_invariances/",
          "author": null,
          "description": "submitted by    /u/Chipdoc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/179krjk/model_metamers_reveal_divergent_invariances/",
          "publishedOn": "2023-10-17T00:01:02.000Z",
          "wordCount": 2525,
          "title": "Model metamers reveal divergent invariances between biological and artificial neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17869ta/supercharging_reinforcement_learning_with_logic/",
          "author": null,
          "description": "Deep reinforcement learning has led to a variety of compelling results. However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly. Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.\n ​\n https://preview.redd.it/pmukb2k7aaub1.png?width=1786&format=png&auto=webp&s=3fb36d0fbeb75393ae8f71f8f369ff5e0b79fbcb\n We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).\n ​\n https://preview.…",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17869ta/supercharging_reinforcement_learning_with_logic/",
          "publishedOn": "2023-10-15T03:14:22.000Z",
          "wordCount": null,
          "title": "Supercharging reinforcement learning with logic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1772yxj/a_question/",
          "author": null,
          "description": "What are the ways to create plasticity in neural network? Without using weights,bias and activation functions?\n    submitted by    /u/Sith_vader3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1772yxj/a_question/",
          "publishedOn": "2023-10-13T16:40:37.000Z",
          "wordCount": 2521,
          "title": "A question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/176tp60/neural_networks_project/",
          "author": null,
          "description": "Hi ! My group (4 people) has chosen to make an application that translates ancient stone inscriptions to modern languages as our university project . We can use external libraries to process images that we are going to translate but as we understood we have to build the neural network ourselves from scratch. My questions are 1) is this possible to do within 10 months? 2) if so how would you approach it ?\n    submitted by    /u/sakith123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/176tp60/neural_networks_project/",
          "publishedOn": "2023-10-13T08:10:35.000Z",
          "wordCount": null,
          "title": "Neural Networks project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/176kek2/how_are_memories_stored_in_neural_networks_the/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/176kek2/how_are_memories_stored_in_neural_networks_the/",
          "publishedOn": "2023-10-12T23:11:47.000Z",
          "wordCount": null,
          "title": "How are memories stored in neural networks? | The Hopfield Network #SoME2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1760j8z/a_question/",
          "author": null,
          "description": "How does the neural network process input that were same but shown different to the network model?\n    submitted by    /u/Sith_vader3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1760j8z/a_question/",
          "publishedOn": "2023-10-12T06:50:58.000Z",
          "wordCount": null,
          "title": "A question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1760in9/i_dont_much_about_nns_is_this_correct/",
          "author": null,
          "description": "i gave chatgpt vision an illustration of neural network from The Principles of Deep Learning Theory. what to know how correct its reponse is\n here is the response: \n https://preview.redd.it/inqe5xukxptb1.png?width=453&format=png&auto=webp&s=6e1079baeae8235b0e03a677e4006d1077af36a8\n    submitted by    /u/YeshwanthRam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1760in9/i_dont_much_about_nns_is_this_correct/",
          "publishedOn": "2023-10-12T06:49:49.000Z",
          "wordCount": null,
          "title": "I don't much about NN's. is this correct ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/175npm5/neural_networks_from_scratch_in_rust/",
          "author": null,
          "description": "submitted by    /u/zezeartix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/175npm5/neural_networks_from_scratch_in_rust/",
          "publishedOn": "2023-10-11T20:15:39.000Z",
          "wordCount": 2523,
          "title": "Neural Networks From Scratch in Rust",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/175kfcg/activation_function_for_generating_shapley_values/",
          "author": null,
          "description": "Hi, I want to train a neural network to calculate Shapley values based on a given characteristic function.\n Depending on a given characteristic function, calculated through a dedicated algorithm, Shapley values can be any number, positive or negative, without a set range.\n Because of this, I am unsure, for the specific application of calculating Shapley values, what activation function to use in a neural network that would calculate them. The relu function, as well as leaky relu function, either cannot give values that are negative or have trouble giving large negative values, and sigmoid or tanh can only give values in a certain range.\n I am aware that there are other commonly used activation functions, but all the ones I could find had one of these issues, which would make training a network to calculate Shapley values difficult.\n Any advice?\n    submitted by    /u/PowNotBigSurprise  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/175kfcg/activation_function_for_generating_shapley_values/",
          "publishedOn": "2023-10-11T17:56:48.000Z",
          "wordCount": 2665,
          "title": "Activation function for generating Shapley values",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17583qj/a_hugging_face_implementation_for_style_gan_to/",
          "author": null,
          "description": "I was thinking to create an app based on style gan which will include facebook , instagram theme and style transfer it with profile pic so shall i create this app or not .I want to know if it will be good idea. \n    submitted by    /u/No_Claim_8651  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17583qj/a_hugging_face_implementation_for_style_gan_to/",
          "publishedOn": "2023-10-11T07:16:48.000Z",
          "wordCount": 2567,
          "title": "A hugging face implementation for style gan to produce user avatar",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/174njqk/riddle_me_this_issues_when_predicting_a_high/",
          "author": null,
          "description": "Hi folks, \n I have observed a strange behavior when implementing a VERY BASIC idea 🙂\n I want to use a fully-connected Neural Network to approximate a sine wave. For that I am sampling 200.000 uniformly distributed points from a wide interval, e.g. [-60,60] and compute the corresponding sin(x) values resulting in the following training data. \n ​\n Training data\n I glimpse into my setup: \n Model:\n nn.Linear(1, 16) nn.Sigmoid() Linear(16, 16) nn.Sigmoid() nn.Linear(16, 8) nn.Sigmoid() nn.Linear(8, 4) nn.Sigmoid() nn.Linear(4, 1) (I also pumped up the network to up to 100 hidden neurons on one layer) \n Number of samples: 200.000 (80% train / 20% test)\n Optimizer: Adam\n Loss: RMSE\n Epochs between 100 - 500\n Learning Rate: 0.02\n Batch Size: 500 - 1000\n ​\n Check out the screenshots below to see the results 😨\n ​\n The predictions are pretty good but the edge areas slow down to a very small value, without any change. This only holds for high-frequency sine waves. If we only consider the train range of [-2*np.pi , 2*np.pi] it works pretty good with small loss.\n ​\n So my questions are: \n 1) Why do we see that behaviour? \n 2) How can we solve it\n ​\n Cheers\n ​\n Prediction 1\n ​\n Prediction 2\n    submitted by    /u/CarKla  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/174njqk/riddle_me_this_issues_when_predicting_a_high/",
          "publishedOn": "2023-10-10T15:08:29.000Z",
          "wordCount": null,
          "title": "Riddle me this: Issues when predicting a high frequency sine wave",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/173asmx/pt_3_inductive_logic_programming_with_lnns/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/173asmx/pt_3_inductive_logic_programming_with_lnns/",
          "publishedOn": "2023-10-08T21:41:32.000Z",
          "wordCount": null,
          "title": "(Pt. 3) Inductive Logic Programming with LNN's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/172yyuh/researchers_create_a_neural_network_for_genomics/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/172yyuh/researchers_create_a_neural_network_for_genomics/",
          "publishedOn": "2023-10-08T13:19:28.000Z",
          "wordCount": null,
          "title": "Researchers create a neural network for genomics that explains how it achieves accurate predictions",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Seita's Place",
      "feedUrl": "https://danieltakeshi.github.io/feed.xml",
      "siteUrl": "https://danieltakeshi.github.io/",
      "articles": [
        {
          "id": "https://danieltakeshi.github.io/2023/10/09/israel",
          "author": null,
          "description": "I strongly condemn the recent and horrific attack by Hamas against Israel.\nI have some disagreements with the government of Israel. But, I do not support\nsuch an attack.\nAs a point of comparison, I do not always agree with the United States\ngovernment, but I would not be celebrating if Mexico (picking a country at\nrandom) were to suddenly launch bombs towards civilians in Los Angeles and New\nYork City.  Similarly, if the reverse were true, if the United States decided\nto indiscriminately bomb Mexico City, I would oppose that as well.  Feel free\nto replace the relevant actors and repeat as needed.",
          "link": "https://danieltakeshi.github.io/2023/10/09/israel",
          "publishedOn": "2023-10-09T23:00:00.000Z",
          "wordCount": 268,
          "title": "I Condemn the Attack by Hamas",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "VITALab",
      "feedUrl": "https://vitalab.github.io/feed.xml",
      "siteUrl": "https://vitalab.github.io/",
      "articles": []
    },
    {
      "title": "Stories by Andrej Karpathy on Medium",
      "feedUrl": "https://medium.com/feed/@karpathy",
      "siteUrl": "https://medium.com/@karpathy?source=rss-ac9d9a35533e------2",
      "articles": []
    },
    {
      "title": "OpenAI Blog",
      "feedUrl": "https://openai.com/blog/rss",
      "siteUrl": "https://openai.com/blog",
      "articles": [
        {
          "id": "https://openai.com/blog/introducing-gpts",
          "author": null,
          "description": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
          "link": "https://openai.com/blog/introducing-gpts",
          "publishedOn": "2023-11-06T08:00:00.000Z",
          "wordCount": 1208,
          "title": "Introducing GPTs",
          "imageUrl": "https://images.openai.com/blob/2014517b-1a80-4b62-bbb6-caa490f69299/introducing-gpts.png?trim=0%2C0%2C0%2C0&width=1000&quality=80"
        },
        {
          "id": "https://openai.com/blog/new-models-and-developer-products-announced-at-devday",
          "author": null,
          "description": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL·E 3 API, and more.",
          "link": "https://openai.com/blog/new-models-and-developer-products-announced-at-devday",
          "publishedOn": "2023-11-06T08:00:00.000Z",
          "wordCount": 2108,
          "title": "New models and developer products announced at DevDay",
          "imageUrl": "https://images.openai.com/blob/a2e49de2-ba5b-4869-9c2d-db3b4b5dcc19/new-models-and-developer-products-announced-at-devday.jpg?width=1000&quality=80"
        },
        {
          "id": "https://openai.com/blog/frontier-risk-and-preparedness",
          "author": null,
          "description": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
          "link": "https://openai.com/blog/frontier-risk-and-preparedness",
          "publishedOn": "2023-10-26T07:00:00.000Z",
          "wordCount": 570,
          "title": "Frontier risk and preparedness",
          "imageUrl": "https://images.openai.com/blob/1f19f98e-798a-4d80-b1c6-431b75d6b41c/frontier-risk-and-preparedness.png?trim=452%2C0%2C443%2C0&width=1000&quality=80"
        },
        {
          "id": "https://openai.com/blog/frontier-model-forum-updates",
          "author": null,
          "description": "Together with Anthropic, Google, and Microsoft, we’re announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
          "link": "https://openai.com/blog/frontier-model-forum-updates",
          "publishedOn": "2023-10-25T07:00:00.000Z",
          "wordCount": 1191,
          "title": "Frontier Model Forum updates",
          "imageUrl": "https://images.openai.com/blob/4d1e00c7-f843-44a2-81a8-890b84b94a2b/frontier-model-forum-updates.png?trim=0%2C0%2C0%2C0&width=1000&quality=80"
        },
        {
          "id": "https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
          "author": null,
          "description": "We developed a safety mitigation stack to ready DALL·E 3 for wider release and are sharing updates on our provenance research.",
          "link": "https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
          "publishedOn": "2023-10-19T07:00:00.000Z",
          "wordCount": 865,
          "title": "DALL·E 3 is now available in ChatGPT Plus and Enterprise",
          "imageUrl": "https://images.openai.com/blob/f698e023-3373-4385-93f3-f0e0a24adbf0/VALERIECloudAstronaut.png?trim=55%2C0%2C45%2C148&width=1000&quality=80"
        }
      ]
    },
    {
      "title": "Microsoft Research",
      "feedUrl": "https://www.microsoft.com/en-us/research/feed",
      "siteUrl": "https://www.microsoft.com/en-us/research/",
      "articles": [
        {
          "id": "https://www.microsoft.com/en-us/research/?p=979812",
          "author": "Brenda Potts",
          "description": "Teachers are the backbone of any educational system. They are not just educators; they are indispensable navigators, mentors, and leaders. Teachers around the world face many challenges, which vary from country to country or even within a city or town. But some challenges are universal, including time management, classroom organization, and creating effective lesson plans. […]\nThe post Teachers in India help Microsoft Research design AI tool for creating great classroom content appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/teachers-in-india-help-microsoft-research-design-ai-tool-for-creating-great-classroom-content/",
          "publishedOn": "2023-10-30T16:00:00.000Z",
          "wordCount": 3745,
          "title": "Teachers in India help Microsoft Research design AI tool for creating great classroom content",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VeLLUM-BlogHeroFeature-1400x788-2.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=979374",
          "author": "Alyssa Hughes",
          "description": "Visualization is vital for understanding complex data, but existing tools require “tidy data,” adding extra steps. Learn how Data Formulator transforms concepts into visuals, promoting collaboration between analysts and AI agents.\nThe post Data Formulator: A concept-driven, AI-powered approach to data visualization appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/data-formulator-a-concept-driven-ai-powered-approach-to-data-visualization/",
          "publishedOn": "2023-10-27T16:00:00.000Z",
          "wordCount": 3109,
          "title": "Data Formulator: A concept-driven, AI-powered approach to data visualization",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/VICS-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=978618",
          "author": "Brenda Potts",
          "description": "This research paper was presented at the 29th ACM Symposium on Operating Systems Principles (opens in new tab) (SOSP 2023), the premier forum for the theory and practice of computer systems software. For millennia, data has woven itself into every facet of our lives, from business and academia to personal spheres. Our production of data […]\nThe post Project Silica: Sustainable cloud archival storage in glass appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/project-silica-sustainable-cloud-archival-storage-in-glass/",
          "publishedOn": "2023-10-26T16:00:00.000Z",
          "wordCount": 3066,
          "title": "Project Silica: Sustainable cloud archival storage in glass",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/Project-Silica-2023-TWLIFB-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=978693",
          "author": "Alyssa Hughes",
          "description": "In this issue: Kosmos-2.5: A Multimodal Literate Model; Can vine copulas explain complex relationships of weather variables; New system accelerates the adaptive training process; Structural inequalities and relational labor in the influencer industry.\nThe post Research Focus: Week of October 23, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-23-2023/",
          "publishedOn": "2023-10-25T16:00:00.000Z",
          "wordCount": 3051,
          "title": "Research Focus: Week of October 23, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF27-BlogHeroFeature-1400x788-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=977154",
          "author": "Alyssa Hughes",
          "description": "Today on “Abstracts,” Partner Research Manager Andy Gordon & Senior Researcher Carina Negreanu explore new work introducing co-audit, a term for any tool-assisted experience that helps users of generative AI find and fix mistakes in AI output.\nThe post Abstracts: October 23, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/abstracts-october-23-2023/",
          "publishedOn": "2023-10-23T13:00:00.000Z",
          "wordCount": 4687,
          "title": "Abstracts: October 23, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Episode1_Abstracts_TW_LI_FB_1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=975909",
          "author": "Brenda Potts",
          "description": "In this new Microsoft Research Podcast series What’s Your Story, Lab Director Johannes Gehrke explores the who behind the technical and scientific advancements helping to reshape the world. He talks to members of the research community at Microsoft about what motivates their work and how they got where they are today.  Ranveer Chandra is Managing […]\nThe post What’s Your Story: Ranveer Chandra appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/whats-your-story-ranveer-chandra/",
          "publishedOn": "2023-10-19T13:12:44.000Z",
          "wordCount": 9161,
          "title": "What’s Your Story: Ranveer Chandra",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/Ranveer_WYS_TW_LI_FB_1200x627.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=976521",
          "author": "Brenda Potts",
          "description": "This position research paper was presented at the 26th ACM Conference on Computer-Supported Cooperative Work and Social Computing (opens in new tab) (CSCW 2023), a premier venue for research on the design and use of technologies that affect groups, organizations, and communities. In the business world, measuring success is as critical as selecting the right […]\nThe post Understanding the user: How the Enterprise System Usability Scale aligns with user reality appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/understanding-the-user-how-the-enterprise-system-usability-scale-esus-aligns-with-user-reality/",
          "publishedOn": "2023-10-18T16:00:00.000Z",
          "wordCount": 2867,
          "title": "Understanding the user: How the Enterprise System Usability Scale aligns with user reality",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG-CSCW-2023-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=971940",
          "author": "Alyssa Hughes",
          "description": "How trustworthy are generative pre-trained transformer (GPT) models? To answer this question, University of Illinois Urbana-Champaign, together with Stanford University, University of California, Berkeley, Center for AI Safety, and Microsoft Research, released a comprehensive trustworthiness evaluation platform for large language models (LLMs), which is presented in the recent paper: DecodingTrust: A Comprehensive Assessment of Trustworthiness […]\nThe post DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models/",
          "publishedOn": "2023-10-16T16:00:00.000Z",
          "wordCount": 3278,
          "title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG-TWLIFB-no-text-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/microsoft-at-vl-hcc-2023-focus-on-co-audit-tools-for-spreadsheets/",
          "author": "Brenda Potts",
          "description": "These research papers were presented at the IEEE Symposium on Visual Languages and Human-Centric Computing (opens in new tab) (VL/HCC 2023), a premier forum for design, theory, and application of computing technologies for programming, modelling, and communication. Large language models (LLMs) have revolutionized the way novice programmers and everyday computer users tap into the capabilities […]\nThe post Microsoft at VL/HCC 2023: Focus on co-audit tools for spreadsheets appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/microsoft-at-vl-hcc-2023-focus-on-co-audit-tools-for-spreadsheets/",
          "publishedOn": "2023-10-12T16:00:00.000Z",
          "wordCount": 3033,
          "title": "Microsoft at VL/HCC 2023: Focus on co-audit tools for spreadsheets",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-TWLIFB-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-9-2023/",
          "author": "Alyssa Hughes",
          "description": "Research Focus: Principal researcher Lester Mackey recognized for pioneering statistical and ML techniques; Pareto frontiers in neural feature learning; structural inequality in the influencer industry; new research on cardinality estimation.\nThe post Research Focus: Week of October 9, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-9-2023/",
          "publishedOn": "2023-10-11T16:02:41.000Z",
          "wordCount": 2675,
          "title": "Research Focus: Week of October 9, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=970974",
          "author": "Alyssa Hughes",
          "description": "Researcher Dr. Sheng Zhang joins “Abstracts”—your source for cutting-edge research in brief—to discuss a recent paper on distilling large language models into smaller, more efficient ones capable of excelling in broad application classes.\nThe post Abstracts: October 9, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/abstracts-october-9-2023/",
          "publishedOn": "2023-10-09T14:35:09.000Z",
          "wordCount": 3858,
          "title": "Abstracts: October 9, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Episode3_Abstracts_Hero_Feature_No_Text_1400x788.png"
        }
      ]
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "http://feeds.feedburner.com/blogspot/gJZg",
      "siteUrl": "http://blog.research.google/",
      "articles": [
        {
          "id": "http://blog.research.google/2023/11/best-of-both-worlds-achieving.html",
          "author": null,
          "description": "Posted by Sara Ahmadian and Mehran Kazemi, Research Scientists, Google Research\n\n\n\n\nClustering is a fundamental, ubiquitous problem in data mining and unsupervised machine learning, where the goal is to group together similar items. The standard forms of clustering are metric clustering and graph clustering. In metric clustering, a given metric space defines distances between data points, which are grouped together based on their separation. In graph clustering, a given graph connects similar data points through edges, and the clustering process groups data points together based on the connections between them. Both clustering forms are particularly useful for large corpora where class labels can’t be defined. Examples of such corpora are the ever-growing digital text collections of variou…",
          "link": "http://blog.research.google/2023/11/best-of-both-worlds-achieving.html",
          "publishedOn": "2023-11-03T18:23:00.001Z",
          "wordCount": 27622,
          "title": "Best of both worlds: Achieving scalability and quality in text clustering",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjR2mD5afdT_Qg9Ex4Lj94FaxB9KHiq20iLoDlOY8S8Rk5XsV6n_4dU9CFbCvSeBSONGQYqy-yMGY6-KU_y_RGICOpz76GNdzv7ecxor_rVnF31lZOd3STQF4MIE4F_EadrSI1DXY67MXnsCswY3w3X8vX8KgU_rRPs6eTZndYAbVcEezgwaUsdZEAHD59Z/w1200-h630-p-k-no-nu/hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/11/zero-shot-adaptive-prompting-of-large.html",
          "author": null,
          "description": "Posted by Xingchen Wan, Student Researcher, and Ruoxi Sun, Research Scientist, Cloud AI Team\n\n\n\n\nRecent advances in large language models (LLMs) are very promising as reflected in their capability for general problem-solving in few-shot and zero-shot setups, even without explicit training on these tasks. This is impressive because in the few-shot setup, LLMs are presented with only a few question-answer demonstrations prior to being given a test question. Even more challenging is the zero-shot setup, where the LLM is directly prompted with the test question only. \n\n\n\n\nEven though the few-shot setup has dramatically reduced the amount of data required to adapt a model for a specific use-case, there are still cases where generating sample prompts can be challenging. For example, handcrafting…",
          "link": "http://blog.research.google/2023/11/zero-shot-adaptive-prompting-of-large.html",
          "publishedOn": "2023-11-02T22:01:00.001Z",
          "wordCount": 27945,
          "title": "Zero-shot adaptive prompting of large language models",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiqTosaeIs4AMYukkmgUBEii6iQcrr9_dNKM0cHnW6m9Wi8yX0V-QCduQfkqLyQPNpVbze3OFO-nPG5Wm9DLMM8pEAfhQGq-TEJroLJGQyqNr-hlJNkToBCmgJbphrCRvlv95gkDQH0ScT7VrXu2VCTKyiWy8yYM4G8voF0kD0K2oxwg2M2xBcz1yQnU0Zb/w1200-h630-p-k-no-nu/USP.gif"
        },
        {
          "id": "http://blog.research.google/2023/11/metnet-3-state-of-art-neural-weather.html",
          "author": null,
          "description": "Posted by Samier Merchant, Google Research, and Nal Kalchbrenner, Google DeepMind\n\n\n\n\n\n\nForecasting weather variables such as precipitation, temperature, and wind is key to numerous aspects of society, from daily planning and transportation to energy production. As we continue to see more extreme weather events such as floods, droughts, and heat waves, accurate forecasts can be essential to preparing for and mitigating their effects. The first 24 hours into the future are especially important as they are both highly predictable and actionable, which can help people make informed decisions in a timely manner and stay safe. \n \n\nToday we present a new weather model called MetNet-3, developed by Google Research and Google DeepMind. Building on the earlier MetNet and MetNet-2 models, MetNet-3 p…",
          "link": "http://blog.research.google/2023/11/metnet-3-state-of-art-neural-weather.html",
          "publishedOn": "2023-11-01T17:30:00.001Z",
          "wordCount": 28196,
          "title": "MetNet-3: A state-of-the-art neural weather model available in Google products",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhdgnhML03N9vxEdGH1TkBATtxGpjyO5XYgZwJY5dY0-sPIAvrmCll4J8I9owyJTNOHZdq6MMZskWsYJDZivZA_zvj2atWhUsPoxWnNyifiFAm83GC2EsZ4xgre8bCk32Yzv3vlR4pGn12H7T5Vkbz5BaErZ22JRB-OqveQ7EDHsrCYjKN65Soc1FrZNwvu/w1200-h630-p-k-no-nu/metnethero1.gif"
        },
        {
          "id": "http://blog.research.google/2023/10/audioplethysmography-for-cardiac.html",
          "author": null,
          "description": "Posted by Xiaoran \"Van\" Fan, Experimental Scientist, and Trausti Thormundsson, Director, Google\n\n\n\n\n\nThe market for true wireless stereo (TWS) active noise canceling (ANC) hearables (headphones and earbuds) has been soaring in recent years, and the global shipment volume will nearly double that of smart wristbands and watches in 2023. The on-head time for hearables has extended significantly due to the recent advances in ANC, transparency mode, and artificial intelligence. Users frequently wear hearables not just for music listening, but also for exercising, focusing, or simply mood adjustment. However, hearable health is still mostly uncharted territory for the consumer market. \n\n\n\nIn “APG: Audioplethysmography for Cardiac Monitoring in Hearables,” presented at MobiCom 2023, we introduce …",
          "link": "http://blog.research.google/2023/10/audioplethysmography-for-cardiac.html",
          "publishedOn": "2023-10-27T20:22:00.000Z",
          "wordCount": 27880,
          "title": "Audioplethysmography for cardiac monitoring with hearable devices",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhnCItsRGs939CGCBBAi5fA-xwk9JQi7b2CQ3voKK583p4uTkQkLIXUd1lU71SLynom0Yt78bRxDflolUzzfol5UbfkPmCaNn8bIUxwAbLDatqZTPxP7SYOT45g9qJODdM1kvT6NQUsixtFTiBYr_h_Hx-pFRsmbcBKdnW3WkbcD4Bcr_cZE590VL-cSu-a/w1200-h630-p-k-no-nu/hero.jpeg"
        },
        {
          "id": "http://blog.research.google/2023/10/supporting-benchmarks-for-ai-safety.html",
          "author": null,
          "description": "Posted by Anoop Sinha, Technology and Society, and Marian Croak, Google Research, Responsible AI and Human Centered Technology team\n\n\n\n\n\nStandard benchmarks are agreed upon ways of measuring important product qualities, and they exist in many fields. Some standard benchmarks measure safety: for example, when a car manufacturer touts a “five-star overall safety rating,” they’re citing a benchmark. Standard benchmarks already exist in machine learning (ML) and AI technologies: for instance, the MLCommons Association operates the MLPerf benchmarks that measure the speed of cutting edge AI hardware such as Google’s TPUs. However, though there has been significant work done on AI safety, there are as yet no similar standard benchmarks for AI safety.\n \n\nWe are excited to support a new effort by …",
          "link": "http://blog.research.google/2023/10/supporting-benchmarks-for-ai-safety.html",
          "publishedOn": "2023-10-26T18:01:00.000Z",
          "wordCount": 27387,
          "title": "Supporting benchmarks for AI safety with MLCommons",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg5URA9ivhxcgmfXwa0668O0HslgYQ_p_x9JJbg6nDgryyNc2QImQernPyzkLPcj1esCMOQTUnEsldIlb21E0DWPDIiE2m76qSruF0jA6jfl1sNl6mBW8JUPSWzOfE7IahHRtviFpxUTPcEZoADXHNMy3gZ2hg369y5QxhY01QRVj5kwJx4uwRKzdcBFp9v/w1200-h630-p-k-no-nu/GoogleResearch.png"
        },
        {
          "id": "http://blog.research.google/2023/10/spoken-question-answering-and-speech.html",
          "author": null,
          "description": "Posted by Eliya Nachmani, Research Scientist, and Alon Levkovitch, Student Researcher, Google Research\n\n\n\n\nThe goal of natural language processing (NLP) is to develop computational models that can understand and generate natural language. By capturing the statistical patterns and structures of text-based natural language, language models can predict and generate coherent and meaningful sequences of words. Enabled by the increasing use of the highly successful Transformer model architecture and with training on large amounts of text (with proportionate compute and model size), large language models (LLMs) have demonstrated remarkable success in NLP tasks. \n\n \n\n\nHowever, modeling spoken human language remains a challenging frontier. Spoken dialog systems have conventionally been built as a c…",
          "link": "http://blog.research.google/2023/10/spoken-question-answering-and-speech.html",
          "publishedOn": "2023-10-26T15:57:00.001Z",
          "wordCount": 27839,
          "title": "Spoken question answering and speech continuation using a spectrogram-powered LLM",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgQEWecXit-a9UwHz781_B9s9ZqxsJIGt7ZXx2Lk0bcSQxXBkmLfjhNQxSiq3gqVjiUZ81_178hArCQ8nNL0OaVyAi8mKixeWN2PvXTLL4I08ht-eCVqtrTRo36dxGBSDNMdlathtEd4g_qdU3T4ZmPMdGNSXHwlDP689sxzbI4Wwosyu9wp-mjadKqL3MN/w1200-h630-p-k-no-nu/Spectron-hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/10/looking-back-at-wildfire-research-in.html",
          "author": null,
          "description": "Posted by Yi-Fan Chen, Software Engineer, and Carla Bromberg, Program Lead, Google Research\n\nWildfires are becoming larger and affecting more and more communities around the world, often resulting in large-scale devastation. Just this year, communities have experienced catastrophic wildfires in Greece, Maui, and Canada to name a few. While the underlying causes leading to such an increase are complex — including changing climate patterns, forest management practices, land use development policies and many more — it is clear that the advancement of technologies can help to address the new challenges.\n \nAt Google Research, we’ve been investing in a number of climate adaptation efforts, including the application of machine learning (ML) to aid in wildfire prevention and provide information to…",
          "link": "http://blog.research.google/2023/10/looking-back-at-wildfire-research-in.html",
          "publishedOn": "2023-10-25T22:10:00.002Z",
          "wordCount": 27627,
          "title": "Looking back at wildfire research in 2023",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgCepSXB1QxIgipeUbH1YGd8N3TkVoT1tAgxG0fC0PPREhbsygTQ4i58OVw6-Dt_lagwgswT0jtxUorsVmtyO9UgPEDezJHz_QiKvbJlgYF8Db8W-68KFdyZsq_uvM7YuZo9BRo__NC4BNxD6nHZpzsimeNOaV3X8dh9aliqbAbk8ycXb25s5NfLTfNe42_/w1200-h630-p-k-no-nu/WildfireModeling.gif"
        },
        {
          "id": "http://blog.research.google/2023/10/grammar-checking-at-google-search-scale.html",
          "author": null,
          "description": "Posted by Eric Malmi, Senior Research Scientist, and Jakub Adamek, Senior Software Engineer, Google, Bard Team\n\n\n\n\n\nMany people with questions about grammar turn to Google Search for guidance. While existing features, such as “Did you mean”, already handle simple typo corrections, more complex grammatical error correction (GEC) is beyond their scope. What makes the development of new Google Search features challenging is that they must have high precision and recall while outputting results quickly.\n\n\n\nThe conventional approach to GEC is to treat it as a translation problem and use autoregressive Transformer models to decode the response token-by-token, conditioning on the previously generated tokens. However, although Transformer models have proven to be effective at GEC, they aren’t part…",
          "link": "http://blog.research.google/2023/10/grammar-checking-at-google-search-scale.html",
          "publishedOn": "2023-10-25T17:45:00.000Z",
          "wordCount": 27399,
          "title": "Grammar checking at Google Search scale",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhW7pWsW1-E7U1LH1bxmjBL_2W5fS6uN2iRb2cNPBks57ubvFNJj-SjE2Zk1lFqndKWBVAeO3g3MLeJ96QUIUNJDyLTcWjeO835NT6HfJMYQBEdGqL-X_sxQ1yxMy16a0OcOLb6gSz2lqM6VofToVtN_s_F_wGB41AZwlj146y7ZXQ4PFsdywX10QO54MJ4/w1200-h630-p-k-no-nu/HeroGC.jpg"
        },
        {
          "id": "http://blog.research.google/2023/10/answering-billions-of-reporting-queries.html",
          "author": null,
          "description": "Posted by Jagan Sankaranarayanan, Senior Staff Software Engineer, and Indrajit Roy, Head of Napa Product, Google\n\n\n\n\nGoogle Ads infrastructure runs on an internal data warehouse called Napa. Billions of reporting queries, which power critical dashboards used by advertising clients to measure campaign performance, run on tables stored in Napa. These tables contain records of ads performance that are keyed using particular customers and the campaign identifiers with which they are associated. Keys are tokens that are used both to associate an ads record with a particular client and campaign (e.g., customer_id, campaign_id) and for efficient retrieval. A record contains dozens of keys, so clients use reporting queries to specify keys needed to filter the data to understand ads performance (e.…",
          "link": "http://blog.research.google/2023/10/answering-billions-of-reporting-queries.html",
          "publishedOn": "2023-10-20T17:07:00.000Z",
          "wordCount": 27806,
          "title": "Answering billions of reporting queries each day with low latency",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIZSvPVFwZPeTv8ivB-lHMGfoLkP-fDBuAy9GEklUVNBPPoqOXRfme5Psui7DbKssImVjFHtxoygKhFBvgpAG_C5852ocu9i7AOfWPeC1mSlaim8jfqsV55wZIULDUPk7WhxW1OISfL_CjZswN3CcZN7GJgVLBdepic8lfYAUCT0rAlXGGbnf-WuA6mRc6/w1200-h630-p-k-no-nu/hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/10/google-search-can-now-help-with-english-speaking-practice.html",
          "author": null,
          "description": "Posted by Christian Plagemann, Director, and Katya Cox, Product Manager, Google Research\n\n\n\n\nLearning a language can open up new opportunities in a person’s life. It can help people connect with those from different cultures, travel the world, and advance their career. English alone is estimated to have 1.5 billion learners worldwide. Yet proficiency in a new language is difficult to achieve, and many learners cite a lack of opportunity to practice speaking actively and receiving actionable feedback as a barrier to learning.\n\n\n\n\nWe are excited to announce a new feature of Google Search that helps people practice speaking and improve their language skills. Within the next few days, Android users in Argentina, Colombia, India (Hindi), Indonesia, Mexico, and Venezuela can get even more langua…",
          "link": "http://blog.research.google/2023/10/google-search-can-now-help-with-english-speaking-practice.html",
          "publishedOn": "2023-10-19T16:24:00.002Z",
          "wordCount": 28075,
          "title": "English learners can now practice speaking on Search",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgfHhrdHOFN2-ZoUw8hxN1Gdmd5WBtL5kVUe27TeajsI3nrES8Ah13W7MIKpZ2avrsxFTdkzk-sD1noswtk20cMyPS8GjDnVMPquyxc6EhR9r53bMzncRYlj5ZBM3jMF15ndusFp2fe9ipy4bksiTLfWJ1umdcUrQUxg78SOtXfjqMbSxW_OQsSTAVZ9HV6/w1200-h630-p-k-no-nu/Tivoli.gif"
        },
        {
          "id": "http://blog.research.google/2023/10/measurement-induced-entanglement-phase.html",
          "author": null,
          "description": "Posted by Jesse Hoke, Student Researcher, and Pedram Roushan, Senior Research Scientist, Quantum AI Team\n\n\n\n\nQuantum mechanics allows many phenomena that are classically impossible: a quantum particle can exist in a superposition of two states simultaneously or be entangled with another particle, such that anything you do to one seems to instantaneously also affect the other, regardless of the space between them. But perhaps no aspect of quantum theory is as striking as the act of measurement. In classical mechanics, a measurement need not affect the system being studied. But a measurement on a quantum system can profoundly influence its behavior. For example, when a quantum bit of information, called a qubit, that is in a superposition of both “0” and “1” is measured, its state will sudde…",
          "link": "http://blog.research.google/2023/10/measurement-induced-entanglement-phase.html",
          "publishedOn": "2023-10-18T21:05:00.000Z",
          "wordCount": 28081,
          "title": "Measurement-induced entanglement phase transitions in a quantum circuit",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjD0d2Z3JPDRdCIvFvlT3VvnLnv7sx7HndEKEnek1t_g84zs__aAh3c2TAG5hPEPYjtjJM8hikDRiSHREYGrW_TrSbHeWVC6eCq6lN2nv4ZVqmtAEg2lTyK1G26q1T-Vo9TUL9YCxVD1tG_Q8hiWBU_cbvIUo_NWrs12hPFTvbJvML4x-OU_RBzidMcwAc_/w1200-h630-p-k-no-nu/order_param_blog_1200.jpg"
        },
        {
          "id": "http://blog.research.google/2023/10/improving-traffic-evacuations-case-study.html",
          "author": null,
          "description": "Posted by Damien Pierce, Software Engineer, and John Anderson, Senior Research Director, Google Research\n\n\n\n\nSome cities or communities develop an evacuation plan to be used in case of an emergency. There are a number of reasons why city officials might enact their plan, a primary one being a natural disaster, such as a tornado, flood, or wildfire. An evacuation plan can help the community more effectively respond to an emergency, and so could help save lives. However, it can be difficult for a city to evaluate such a plan because it is not practical to have an entire town or city rehearse a full blown evacuation. For example, Mill Valley, a city in northern California, created a wildfire evacuation plan but lacked an estimate for how long the evacuation would take.\n\n\nToday we describe a c…",
          "link": "http://blog.research.google/2023/10/improving-traffic-evacuations-case-study.html",
          "publishedOn": "2023-10-16T17:12:00.000Z",
          "wordCount": 28215,
          "title": "Improving traffic evacuations: A case study",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiq0gQYBrF4sBptEnwyqdXMyAuYpCBTZJf7JBevRgt8ZuEtflAdzaNbenGSfItI98BCpXDMpUkO3nEJyDs4XTVaCmpGrqBsLGL1E11V6-QbB629_OL_IrMhX1AfJRZIbL_O9AufL5o-kbESrDz6y_zJbP7Kj6MTn_RLQ8B7hOSlbKguvdd6jjthWNRTPZYl/w1200-h630-p-k-no-nu/trafficevac.png"
        },
        {
          "id": "http://blog.research.google/2023/10/batch-calibration-rethinking.html",
          "author": null,
          "description": "Posted by Han Zhou, Student Researcher, and Subhrajit Roy, Senior Research Scientist, Google Research\n\n\n\n\n\nPrompting large language models (LLMs) has become an efficient learning paradigm for adapting LLMs to a new task by conditioning on human-designed instructions. The remarkable in-context learning (ICL) ability of LLMs also leads to efficient few-shot learners that can generalize from few-shot input-label pairs. However, the predictions of LLMs are highly sensitive and even biased to the choice of templates, label spaces (such as yes/no, true/false, correct/incorrect), and demonstration examples, resulting in unexpected performance degradation and barriers for pursuing robust LLM applications. To address this problem, calibration methods have been developed to mitigate the effects of t…",
          "link": "http://blog.research.google/2023/10/batch-calibration-rethinking.html",
          "publishedOn": "2023-10-13T18:01:00.000Z",
          "wordCount": 27831,
          "title": "Batch calibration: Rethinking calibration for in-context learning and prompt engineering",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhcUnpQACR3ZhIfLnnazC6jATK0TZkwm-zGcHW0iMGYkd5bOrHtp0UAzDZ51hkI-ZesK4PAW_zn29G7r9hnq6bsNrp54dCEoiinN7l2bkNkIZVOj18ym1WQBk4QZfB_LlJnImIms-LSh6E88bcDP6NZ3yDssRhyJGUFgt2IhZurObVP8jn3Bb4aiAnB_Ysg/w1200-h630-p-k-no-nu/Screenshot%202023-10-13%20at%2010.57.44%20AM.png"
        },
        {
          "id": "http://blog.research.google/2023/10/developing-industrial-use-cases-for.html",
          "author": null,
          "description": "Posted by Nicholas Rubin, Senior Research Scientist, and Ryan Babbush, Head of Quantum Algorithms, Quantum AI Team\n\n\n\n\n\nIf you’ve paid attention to the quantum computing space, you’ve heard the claim that in the future, quantum computers will solve certain problems exponentially more efficiently than classical computers can. They have the potential to transform many industries, from pharmaceuticals to energy.\n\n\n\nFor the most part, these claims have rested on arguments about the asymptotic scaling of algorithms as the problem size approaches infinity, but this tells us very little about the practical performance of quantum computers for finite-sized problems. We want to be more concrete: Exactly which problems are quantum computers more suited to tackle than their classical counterparts, an…",
          "link": "http://blog.research.google/2023/10/developing-industrial-use-cases-for.html",
          "publishedOn": "2023-10-12T20:56:00.002Z",
          "wordCount": 28273,
          "title": "Developing industrial use cases for physical simulation on future error-corrected quantum computers",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigr1Q582VTmDaeIOT7X-hnXjEJ8QW237xvxICJqe-ZKg2zBAQn9gPfoAbLsJXmG8IFQ5B0ysoh7O60-U4mMKA4mJxB92Tm5MnY50n8B7dWpHwap3lk9_at6c4oEZ0lqjpeS-sqRZyKdyu1UjzJkbb2zRJp9nsZvkikxlK0eTZBjB5hJqvOtbaFPyWe7OfF/w1200-h630-p-k-no-nu/StoppingPower.jpg"
        },
        {
          "id": "http://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html",
          "author": null,
          "description": "Posted by Sagar M. Waghmare, Senior Software Engineer, and Kimberly Wilber, Software Engineer, Google Research, Perception Team\n\n\n\n\nAs most people navigate their everyday world, they process visual input from the environment using an eye-level perspective. Unlike robots and self-driving cars, people don't have any \"out-of-body\" sensors to help guide them. Instead, a person’s sensory input is completely \"egocentric\", or \"from the self.\" This also applies to new technologies that understand the world around us from a human-like perspective, e.g., robots navigating through unknown buildings, AR glasses that highlight objects, or assistive technology to help people run independently.\n\n\n\n\n\nIn computer vision, scene understanding is the subfield that studies how visible objects relate to the sce…",
          "link": "http://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html",
          "publishedOn": "2023-10-09T19:17:00.000Z",
          "wordCount": 27977,
          "title": "SANPO: A Scene understanding, Accessibility, Navigation, Pathfinding, & Obstacle avoidance dataset",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh10zxbymBGZgjXFHDrw-CdxlVL7nRi6yjaI3w3X_x5pjxn8UWA7NnymAqMXomfjSBXWVDQ4czo8nqINhxzIPLVx2Uv1l8RDQAbikuWWjIt9IwxSIuSlEtJ5AJwOJkdaKPwzUdu9BwkJJP1gDj2UJQpkJ15ELGjSKHMl9ce0_470SwRz5snz32lV-vSlMd2/w1200-h630-p-k-no-nu/SANPOHero.gif"
        }
      ]
    },
    {
      "title": "fast.ai",
      "feedUrl": "https://www.fast.ai/atom.xml",
      "siteUrl": "https://www.fast.ai/atom.xml",
      "articles": [
        {
          "id": "https://www.fast.ai/2022/09/06/homeschooling/",
          "author": null,
          "description": "My husband Jeremy and I never intended to homeschool, and yet we have now, unexpectedly, committed to homeschooling long-term. Prior to the pandemic, we both worked full-time in careers that we loved and found meaningful, and we sent our daughter to a full-day Montessori school. Although I struggled with significant health issues, I felt unbelievably lucky and fulfilled in both my family life and my professional life. The pandemic upended my careful balance. Every family is different, with different needs, circumstances, and constraints, and what works for one may not work for others. My intention here is primarily to share the journey of my own (very privileged) family.\n\n  \n\n\nOur unplanned introduction to homeschooling\nFor the first year of the pandemic, most schools in California, where …",
          "link": "https://www.fast.ai/2022/09/06/homeschooling/",
          "publishedOn": "2022-09-05T14:00:00.000Z",
          "wordCount": 2118,
          "title": "My family's unlikely homeschooling journey",
          "imageUrl": null
        },
        {
          "id": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "author": null,
          "description": "Jupyter notebooks don’t work with git by default. With nbdev2, the Jupyter+git problem has been totally solved. It provides a set of hooks which provide clean git diffs, solve most git conflicts automatically, and ensure that any remaining conflicts can be resolved entirely within the standard Jupyter notebook environment. To get started, follow the directions on Git-friendly Jupyter.\nContents\nThe Jupyter+git problem\nThe solution    \nThe nbdev2 git merge driver\nThe nbdev2 Jupyter save hook\nBackground\nThe result\nPostscript: other Jupyter+git tools    \nReviewNB\nAn alternative solution: Jupytext\nnbdime\nThe Jupyter+git problem\nJupyter notebooks are a powerful tool for scientists, engineers, technical writers, students, teachers, and more. They provide an ideal notebook environment for interact…",
          "link": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "publishedOn": "2022-08-24T14:00:00.000Z",
          "wordCount": 2227,
          "title": "The Jupyter+git problem is now solved",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Reinforcement Learning",
      "feedUrl": "https://www.reddit.com/r/reinforcementlearning/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/reinforcementlearning/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17pew32/mario_in_sheeprl_error/",
          "author": null,
          "description": "I'm getting this error in my code, and I'm trying to delve deeper into the code to figure out how to incorporate the mario environment (https://github.com/Kautenja/gym-super-mario-bros/tree/master) into SheepRL (https://github.com/Eclectic-Sheep/sheeprl). I've setup the configs and the wrapper, but I'm assuming I did something wrong. If anyone has suggestions to how I can fix the error, or on how I should go about debugging my code let me know. Here is my error:\n /home/dillon/anaconda3/envs/sheeprl/lib/python3.8/site-packages/gymnasium/experimental/wrappers/rendering.py:166: UserWarning: WARN: Overwriting existing videos at /home/dillon/sheeprl/logs/runs/dreamer_v3/mario/2023-11-06_15-13-28_default_42/version_0/train_videos folder (try specifying a different `video_folder` for the `RecordV…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17pew32/mario_in_sheeprl_error/",
          "publishedOn": "2023-11-06T22:20:29.000Z",
          "wordCount": null,
          "title": "Mario in SheepRL error",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17pe4la/gpomdp/",
          "author": null,
          "description": "I am trying to implement the G(PO)MDP algorithm from Inﬁnite-Horizon Policy-Gradient Estimation, specifically the pseudocode from Reinforcement learning of motor skills with policy gradients.\n For that I am using the gymnasium Pendulum environment.\n I have spent a substantial amount of time to fine tune and debug the code, but simply cannot get the agent to learn anything in reasonable time. Often times it seems as if the agent learns nicely at the beginning of the iterations but then oscillates and also often drops down to a low reward and stays there:\n Oscillating reward over iterations\n Another issue that I have is that the algorithm requires gradient estimates for each gradient element (a.k.a network parameter) for each time step. This however requires me to run num_trajectories \\ hori…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17pe4la/gpomdp/",
          "publishedOn": "2023-11-06T21:48:46.000Z",
          "wordCount": null,
          "title": "G(PO)MDP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17pasfw/how_to_mask_invalid_actions_in_ddpg/",
          "author": null,
          "description": "I am using DDPG in a customized environment. My action space is continuous and bounded between a minimum and a maximum value, [V_{min}, V_{max}]. The dimension of my action vector is k, for example k= 10. I consider my action to be valid if :\n  \nthe sum of the vector elements is less than or equal to 1, and\n each element of the vector is in the interval [V_{min}, V_{max}].\n  \nI am using Sigmoid as an activation function in the output layer to have action values in [0,1].\n I clip the action values between V_min and V_max before saving them in the replay buffer.\n If the sum of the elements in the action vector is greater than 1, the action is considered invalid.\n To mask invalid actions, I've tried to:\n  \nPenalize invalid actions by assigning them a negative reward.\n Manually assign a negative Q value when the action is invalid.\n  \nUnfortunately, none of these tricks work. My agent can't learn to choose valid actions.\n I haven't found an online example of how to mask invalid actions in a continuous action space.\n If anyone has faced a similar problem or if anyone has any ideas on how I can mask invalid actions in my case, I'd be grateful for your help. \n    submitted by    /u/afk-311  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17pasfw/how_to_mask_invalid_actions_in_ddpg/",
          "publishedOn": "2023-11-06T19:28:21.000Z",
          "wordCount": null,
          "title": "How to mask invalid actions in DDPG?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17pal8i/rl_agent_for_autonomous_vehicle_is_able_to_follow/",
          "author": null,
          "description": "sorry if bother you but i have been trying to figure something out for 3 weeks.\n I coded some deep rl algorithms (DQN and SAC) with tf2/keras to solve an environment where vehicle need to follow the track and avoid crashing to other vehicle(has only one other vehicle). Whatever i do, agent is able to follow road in one way or another but nearly always crash into other vehicle. I use some kinematics information for observation. (agent only controls steering)\n My observation is kinematics of the agent and other vehicle. This include coordinates, velocities, trigonometric headings, lateral and longitudinal offset to the closest lane, angular offset to the lane.\n A reward function how close is agent to the center. A negative reward (-1) if agent crashes. A negative reward if the agent runs out off road.\n If crash or off-road, done.\n With this information agent is able to follow road but as soon as it reaches the other vehicle, it crashes into it. I trained 1000 episodes.\n What did i try?\n I run my codes in different environments and it works. Code structure is not a problem. I added last actions (t and t-1) info to observations. Hyper parameter tuning. Changed crashing reward to different values. Used Stable-Baselines3's PPO algorithm. (Had the same problem.) Added distance and angular between vehicles to the observation space. I slowed down the discovery rate reduction in DQN. Used PER as buffer in DQN. \n None of these solved the crashing problem. Is there any suggestions? Any idea could help, i really don't know what to try to solve this. Thanks a lot of folks. Any idea needed.\n    submitted by    /u/rafiqollective  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17pal8i/rl_agent_for_autonomous_vehicle_is_able_to_follow/",
          "publishedOn": "2023-11-06T19:19:46.000Z",
          "wordCount": null,
          "title": "RL agent for autonomous vehicle is able to follow the road but can't avoid crashing at all (Highway-Env / Racetrack Env.)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17p55xw/how_many_pretraining_tasks_are_needed_for/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17p55xw/how_many_pretraining_tasks_are_needed_for/",
          "publishedOn": "2023-11-06T15:23:28.000Z",
          "wordCount": null,
          "title": "\"How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?\", Wu et al 2023 (\"effective pretraining only requires a small number of independent tasks...to achieve nearly Bayes-optimal risk on unseen tasks\")",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17p1d1f/can_i_access_a_custom_gymnasium_environment_from/",
          "author": null,
          "description": "Can I access a custom gymnasium environment from outside its directory? This is how I call my gym environment - \n ```\n import gym_examples\n import gym\n env = gym.make('gym_examples/GridWorld-v0')\n obs = env.reset()\n print(\"obs = \", obs)\n ``` \n https://preview.redd.it/9r994zodypyb1.png?width=271&format=png&auto=webp&s=dee78b18216d18c4aca4dcf7a9c041c1da02e5a8\n I have attached a picture of the structure of my folder. Basically, I am following the instructions given over here - https://www.gymlibrary.dev/content/environment_creation/ I already tried this - \n ```\n import gym_examples\n import gym\n env = gym.make('my_foo_folder/gym_examples/GridWorld-v0')\n obs = env.reset()\n print(\"obs = \", obs)\n ``` \n ```\n gym.error.Error: Malformed environment ID: my_foo_folder/gym_examples/GridWorld-v0.(Currently all IDs must be of the form [namespace/](env-name)-v(version). (namespace is optional))\n ``` \n Please let me know if I am missing any information. Thank you.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17p1d1f/can_i_access_a_custom_gymnasium_environment_from/",
          "publishedOn": "2023-11-06T12:13:57.000Z",
          "wordCount": null,
          "title": "Can I access a custom gymnasium environment from outside its directory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17oxz3a/d_deep_q_learning_q_values_starts_decreasing_on/",
          "author": null,
          "description": "submitted by    /u/Multitude0099  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17oxz3a/d_deep_q_learning_q_values_starts_decreasing_on/",
          "publishedOn": "2023-11-06T08:09:15.000Z",
          "wordCount": null,
          "title": "[D] Deep Q Learning: Q values starts decreasing on Mspacman-v0 environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17otdzv/impatience_for_information_curiosity_is_here/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17otdzv/impatience_for_information_curiosity_is_here/",
          "publishedOn": "2023-11-06T03:10:52.000Z",
          "wordCount": null,
          "title": "\"Impatience for information: Curiosity is here today, gone tomorrow\", Molnar & Golman 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17or2fl/pretraining_data_mixtures_enable_narrow_model/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17or2fl/pretraining_data_mixtures_enable_narrow_model/",
          "publishedOn": "2023-11-06T01:11:25.000Z",
          "wordCount": null,
          "title": "\"Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models\", Yadlowsky et al 2023 {DM}",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17oqtl6/in_sklearns_load_digits_if_you_were_to_use_neat/",
          "author": null,
          "description": "yes i know xgboost and others could get above 95% accuracy and faster, im trying out NEAT and looking at how to use NEAT to do multiclass classification.\n I could only get 56% accuracy at 50 population and 1000 generations. fitness function is based on accuracy of its predictions. is there a different way to reward it in the fitness function so it will get to 95% and above?\n    submitted by    /u/oniongarlic88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17oqtl6/in_sklearns_load_digits_if_you_were_to_use_neat/",
          "publishedOn": "2023-11-06T00:59:09.000Z",
          "wordCount": null,
          "title": "in sklearn's load_digits(), if you were to use NEAT, how would you do fitness function?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17okdzk/transfer_rl/",
          "author": null,
          "description": "What is the most famous benchmark example of transfer reinforcement learning? Does it work in continuous actions?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17okdzk/transfer_rl/",
          "publishedOn": "2023-11-05T20:05:05.000Z",
          "wordCount": null,
          "title": "Transfer RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ohzm1/rl_for_solving_a_scheduling_problem/",
          "author": null,
          "description": "Does anyone have an example, where an RL agent is used to solve a scheduling problem? This does not have to be the case where RL provides an improvement over traditional methods used in scheduling. I would just like to have a look at an example, theory and code implementation.\n Thanks!\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ohzm1/rl_for_solving_a_scheduling_problem/",
          "publishedOn": "2023-11-05T18:18:50.000Z",
          "wordCount": null,
          "title": "RL for solving a scheduling problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ohbm8/what_algorithm_should_i_use_in_this_situation/",
          "author": null,
          "description": "Hi guys i'm new to reinforcement learning so I need help with this situation:\n i want to make a portfolio optimisation agent that will take the state: historical data\n perform an action: output a box of percentages, each percentage corresponds to the amount of capital I will allocate for a certain stock. please let me know if you need more information.\n    submitted by    /u/AymanElmar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ohbm8/what_algorithm_should_i_use_in_this_situation/",
          "publishedOn": "2023-11-05T17:48:41.000Z",
          "wordCount": null,
          "title": "What algorithm should I use in this situation.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17odiui/rl_applications_and_basic_assumptions_rl_data/",
          "author": null,
          "description": "With the success of AlphaGo and GPT, Reinforcement Learning (RL) becomes increasingly important to bring AI to practice. More and more publications just apply RL for the sake of applying RL, sometimes we miss the basic theoretical assumptions in the problem models, i.e., Markov property -> Markov decision process (MDP).\n https://preview.redd.it/n5zefdbmljyb1.png?width=1200&format=png&auto=webp&s=43a42e22667c6327ec6511fa7aaae984094c8099\n As all RLer know the problems that can be solved by RL is obeying a basic assumption that our problem can be represented as an MDP. Considering a simple question, in an electronic business scenario, assuming that we want to make a dynamic pricing or other sales promotion action according to the website click volume, does it satisfy the MDP requirements or j…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17odiui/rl_applications_and_basic_assumptions_rl_data/",
          "publishedOn": "2023-11-05T14:51:01.000Z",
          "wordCount": null,
          "title": "RL applications and basic assumptions, RL & data science, did I miss something basically?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17o6thz/mc_methods/",
          "author": null,
          "description": "Can MC methods be used for policy improvement, or are they just used for policy evaluation?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17o6thz/mc_methods/",
          "publishedOn": "2023-11-05T07:32:31.000Z",
          "wordCount": null,
          "title": "MC Methods",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17o6t1r/simple_tutorial_on_extreme_qlearning/",
          "author": null,
          "description": "Any simple tutorial on Extreme Q-learning - theory and implementation?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17o6t1r/simple_tutorial_on_extreme_qlearning/",
          "publishedOn": "2023-11-05T07:31:34.000Z",
          "wordCount": null,
          "title": "Simple tutorial on Extreme Q-Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17o6ew4/dqn_vs_deep_sarsa/",
          "author": null,
          "description": "Why is DQN so famous, while deep sarsa isn’t? Is it because Deep Sarsa is on-policy?\n If that is the case, I do not get it. The action a is sampled in both cases using epsilon-greedy. It’s just that a’ for DQN is the greedy, while that for Sarsa is epsilon-greedy. But how does that make a difference?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17o6ew4/dqn_vs_deep_sarsa/",
          "publishedOn": "2023-11-05T07:01:21.000Z",
          "wordCount": null,
          "title": "DQN vs Deep Sarsa",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17o6d89/difference_between_ddpg_and_policy_gradient/",
          "author": null,
          "description": "I still cannot distinguish between regular policy gradient and DDPG, although the latter is supposed to be an extension of DQNs to the continuous action domains?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17o6d89/difference_between_ddpg_and_policy_gradient/",
          "publishedOn": "2023-11-05T06:57:50.000Z",
          "wordCount": null,
          "title": "Difference between DDPG and Policy Gradient",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17o6brs/code_for_a_paper/",
          "author": null,
          "description": "Is there a code available for the paper “Risk-Aware Transfer in Reinforcement Learning using Successor Features” published in NeurIPS 2021 by Gimelfarb et Al.?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17o6brs/code_for_a_paper/",
          "publishedOn": "2023-11-05T06:54:31.000Z",
          "wordCount": null,
          "title": "Code for a paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17o6avw/solving_an_optimization_problem_using_rl/",
          "author": null,
          "description": "I know that there are much better methods to do it, but can RL solve an optimization problem (linear, convex non-linear, non-convex)? If yes, is there a good link for an implementation / code?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17o6avw/solving_an_optimization_problem_using_rl/",
          "publishedOn": "2023-11-05T06:52:27.000Z",
          "wordCount": null,
          "title": "Solving an optimization problem using RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17o6a7e/stochasticity_in_the_cart_pole_example/",
          "author": null,
          "description": "In the famous Cart Pole example in OpenAI gym, from where does the stochasticity come from?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17o6a7e/stochasticity_in_the_cart_pole_example/",
          "publishedOn": "2023-11-05T06:50:52.000Z",
          "wordCount": null,
          "title": "Stochasticity in the Cart Pole example",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17o1biv/making_twin_delayed_deep_deterministic_policy/",
          "author": null,
          "description": "Hi everyone. I've been using ChatGPT(3.5) to help me convert Python code using TD3 into JavaScript with TensorFlow JS. This is for the community and not for personal gain.\n My goal is to make a basic blueprint for the community to use on TensorFlow JS projects. When complete, the agent will be displayed on an HTML5 canvas walking toward a civilian for good reward, while avoiding a zombie (negative penalty).\n The bad news: I'm not a professional of Python or Tensorflow JS, and ChatGPT is shakey when it comes to complex tasks. At the moment the agent isn't learning yet, but it's running without errors. I expect the code has mistakes I don't even know about yet.\n The good news: I have made a lot of progress and have a GitHub repository set up for the community to learn from and use the project: https://github.com/CloudZero2049/TD3-TensorFlowJS\n I would love for anyone who knows the intricacies of TD3 (DDPG is a close relative), and TensorFlow JS to help me get this blueprint project setup for everyone =) The README on GitHub has more info and resources.\n    submitted by    /u/CloudZero2049  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17o1biv/making_twin_delayed_deep_deterministic_policy/",
          "publishedOn": "2023-11-05T01:40:57.000Z",
          "wordCount": null,
          "title": "Making Twin Delayed Deep Deterministic Policy Gradient (TD3) with TensorFlow JS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17o11r4/why_cant_i_import_dqnagent/",
          "author": null,
          "description": "```python from tensorflow.python.keras.models import Sequentialfrom from tensorflow.python.keras.layers import Dense, Flattenfrom from tensorflow.python.keras.optimizer_v1 import Adam\n from rl.agents import DQNAgent from rl.policy import BoltzmannQPolicy from rl.memory import SequentialMemory\n print(\"hello world\") ```\n This is my whole code and why can't I import `DQNAgent`? I am new to RL area.\n Everything is working well without this line : \"from rl.agents.dqn import DQNAgent\"\n Error is like this :\n ``` Traceback (most recent call last):\n File \"/Users/isaac/temp.py\", line 5, in <module>\n from rl.agents.dqn import DQNAgent\n File \"/private/var/folders/q9/mtrgmhn96yq900lqp_sn9vgr0000gn/T/rlTest.py17471611196844209727/venv/lib/python3.11/site-packages/rl/agents/__init__.py\", line 1, in <module>\n from .dqn import DQNAgent, NAFAgent, ContinuousDQNAgent\n File \"/private/var/folders/q9/mtrgmhn96yq900lqp_sn9vgr0000gn/T/rlTest.py17471611196844209727/venv/lib/python3.11/site-packages/rl/agents/dqn.py\", line 7, in <module>\n from rl.core import Agent\n File \"/private/var/folders/q9/mtrgmhn96yq900lqp_sn9vgr0000gn/T/rlTest.py17471611196844209727/venv/lib/python3.11/site-packages/rl/core.py\", line 7, in <module>\n from rl.callbacks import (\n File \"/private/var/folders/q9/mtrgmhn96yq900lqp_sn9vgr0000gn/T/rlTest.py17471611196844209727/venv/lib/python3.11/site-packages/rl/callbacks.py\", line 8, in <module>\n from tensorflow.keras import __version__ as KERAS_VERSION\n ImportError: cannot import name '__version__' from 'tensorflow.keras' (/private/var/folders/q9/mtrgmhn96yq900lqp_sn9vgr0000gn/T/rlTest.py17471611196844209727/venv/lib/python3.11/site-packages/keras/api/_v2/keras/__init__.py) ```\n    submitted by    /u/Subject-Ad-9345  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17o11r4/why_cant_i_import_dqnagent/",
          "publishedOn": "2023-11-05T01:27:15.000Z",
          "wordCount": null,
          "title": "Why can't I import DQNAgent?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17o07eq/myoarm/",
          "author": null,
          "description": "I'm trying to create a MuJoCo/Open AI task for the new MyoSuite arm with 27 DoF https://github.com/MyoHub/myo_sim/tree/main/arm.\n Any ideas on some resources that I can use?\n ​\n    submitted by    /u/Terrible_Sleep_3484  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17o07eq/myoarm/",
          "publishedOn": "2023-11-05T00:45:10.000Z",
          "wordCount": null,
          "title": "MyoArm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17nvrzt/guide_for_marllib/",
          "author": null,
          "description": "The documentation for MARLlib is pretty lacklustre, does anyone know of any tutorial on how to make custom environments work with it, and also example code for handling training loops, etc?\n I'm mostly having issues with understanding what the ''make()'' function does from marllib.\n    submitted by    /u/EquivalentCurious745  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17nvrzt/guide_for_marllib/",
          "publishedOn": "2023-11-04T21:18:15.000Z",
          "wordCount": null,
          "title": "Guide for MARLLib",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17nq7it/custom_boid_flocking_environment_open_ai_gym/",
          "author": null,
          "description": "Background:\n Boids info are given here: https://en.wikipedia.org/wiki/Boids.\n I was able to successfully implement Reynold's model flocking (Results below). My open ai gym implementation doesn't work though.\n Objective:\n Build an RL Custom Open AI Gym Boid flocking environment, trained on Stable Baselines3 PPO algorithm.\n Error:\n Error\n What I have tried:\n Initializations and NaN value debugging. Honestly, have no idea what to do. I am an amateur with like 2 months of experience in Open AI gym, please be gentle.\n ​\n Results(Reynold's Model):\n Reynold's model flocking with 20 agents\n -RL code is named as Env.py and Error as Error.txt.\n -Flocking using reynold's model is called Agent.py, it works perfectly\n ​\n ​\n https://preview.redd.it/wlsasy6r5dyb1.png?width=1569&format=png&auto=webp&s=59661ae34273b459b2cf193775c1861851f6747e\n ​\n Link to files and error: https://drive.google.com/drive/folders/1RhsVen6CQNh0b1PWqT7FbTggYKDKEqsF?usp=sharing\n    submitted by    /u/Sadboi1010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17nq7it/custom_boid_flocking_environment_open_ai_gym/",
          "publishedOn": "2023-11-04T17:09:42.000Z",
          "wordCount": null,
          "title": "Custom Boid Flocking environment (Open AI Gym)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17nobxd/a_beginner_friendly_introduction_to_deep_rl/",
          "author": null,
          "description": "Hey people, sharing a video from my ML YT channel where I discuss what RL is all about and discuss four great papers from 2010s that personally got me into the subject during my grad study days… its kinda beginner friendly in tone, but more appropriately it highlights the strengths and challenges, and the key algorithmic ideas in the field!\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17nobxd/a_beginner_friendly_introduction_to_deep_rl/",
          "publishedOn": "2023-11-04T15:41:31.000Z",
          "wordCount": null,
          "title": "A beginner friendly introduction to Deep RL discussing four of the greatest seminal works",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17nkxqa/visual_observations_for_centralised_critic_in/",
          "author": null,
          "description": "Hello everyone, \n I'm working currently on a project that involves a multi-agent systems problem that I intend to solve using MARL. One common good practice when doing MARL, is to use a centralized critic for all agents, this critic takes as input the observations of all agents. In the case where the agents rely on RGB images, there are many ways to feed the observations to the centralized critic. My question is what is the best way to do so ( Should i just concatentate the images across the channel, Generate features of each image and concatenate after ...etc ) ?.\n Thank you in advance. \n ​\n    submitted by    /u/Many_Reception_4921  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17nkxqa/visual_observations_for_centralised_critic_in/",
          "publishedOn": "2023-11-04T12:47:05.000Z",
          "wordCount": null,
          "title": "Visual observations for centralised critic in MADDPG",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17nghz1/rl_courses_online/",
          "author": null,
          "description": "What courses are really useful to understand the theory of RL? Stanford? Berkeley?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17nghz1/rl_courses_online/",
          "publishedOn": "2023-11-04T07:34:55.000Z",
          "wordCount": null,
          "title": "RL courses online",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ngh8m/qlp/",
          "author": null,
          "description": "Are there any sources for the Linear Programming solution to the Q-function?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ngh8m/qlp/",
          "publishedOn": "2023-11-04T07:33:05.000Z",
          "wordCount": null,
          "title": "Q-LP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ngeqz/rl_books_references/",
          "author": null,
          "description": "Are there references that explain algorithms in modern RL like TRPO, PPO, A3C, in a clear way, and possibly implements them?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ngeqz/rl_books_references/",
          "publishedOn": "2023-11-04T07:27:50.000Z",
          "wordCount": null,
          "title": "RL books - references",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17nge76/ddpg_tutorial/",
          "author": null,
          "description": "Is there a site that explains DDPG theory and has an implementation for it in a very clear way?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17nge76/ddpg_tutorial/",
          "publishedOn": "2023-11-04T07:26:30.000Z",
          "wordCount": null,
          "title": "DDPG tutorial",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ngco2/policy_gradient_for_continous_actions/",
          "author": null,
          "description": "What if my action space is continuous, but is within a certain (interval) range?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ngco2/policy_gradient_for_continous_actions/",
          "publishedOn": "2023-11-04T07:23:02.000Z",
          "wordCount": null,
          "title": "Policy Gradient for Continous actions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ngbfy/qlearning_for_demand_response/",
          "author": null,
          "description": "In the paper (in the first comment), optimal electricity prices are determined via Q-learning. The MDP includes energy demand as states and electricity prices as actions. The reward is a weighted sum of service provider profit and customer satisfaction. In this case, state t=2 need not be dependent on state t=1 and action t = 1. I do not understand how Q(st, at) can then represent the discounted sum of expected rewards, especially that st+1 may not follow from an action taken at st. \n Is the modelling of the MDP valid? https://pdf.sciencedirectassets.com/271429/1-s2.0-S0306261918X00099/1-s2.0-S0306261918304112/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjELr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIGsBT5yR8u2kFHHVNsJMX4FAkc%2FB%2BuT0Elulb6gCmnntAiEAi2OBcPqvWhhGAQvYRKCCkc6dBRB4…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ngbfy/qlearning_for_demand_response/",
          "publishedOn": "2023-11-04T07:20:19.000Z",
          "wordCount": null,
          "title": "Q-learning for demand response",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17n9o52/ai_marketplace_to_buy_and_sell_ml_models/",
          "author": null,
          "description": "Hi,\n Im working on creating an AI marketplace where developers can upload models and startups, and enterprises can deploy and run them in the cloud at scale.\n Any feedback would be greatly appreciated! We are currently onboarding developers and waitlisting buyers.\n Here is our interest form: https://forms.gle/X4Wy7NyMcWULddEBA\n    submitted by    /u/Dismal-Call2668  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17n9o52/ai_marketplace_to_buy_and_sell_ml_models/",
          "publishedOn": "2023-11-04T00:37:51.000Z",
          "wordCount": null,
          "title": "AI MarketPlace to buy and sell ML models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17n66e6/dreamer_on_classic_control_like_cartpole/",
          "author": null,
          "description": "Has anyone ever seen a simple implementation of Dreamer on classic environments like CartPole ?\n There are tons and tons of examples of policy gradients algorithms for CartPole and so, but I haven't seen any results of Dreamer on a simple env like CartPole : a majority of Dreamer implementations (v1,v2,v3) focuses on visual environments, a few say that they are compatible with vector-only envs but don't provide any results nor config to work with these.\n Typically, I'm looking for a simple implementation that doesn't uses fancy tricks (like parallel processes, etc) and works out of the box on a simple env like CartPole.\n Of course, I know that Dreamer isn't meant for such simple environments but for educational purposes, I think it's important to start with something as simple as possible.\n ​\n Thank you!\n    submitted by    /u/alexandretorres_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17n66e6/dreamer_on_classic_control_like_cartpole/",
          "publishedOn": "2023-11-03T21:54:53.000Z",
          "wordCount": null,
          "title": "Dreamer on classic control like CartPole",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17n3mpa/multi_agent_ppo_in_grid_world_environment_using/",
          "author": null,
          "description": "I'm trying to create a simple environment using PettingZoo's parallel API: a 12x12 grid with fixed obstacles. I'm trying to train 3 agents using PPO , with the goal to cover the grid entirely. (Exploration/ Coverage task). Here's the entire colab notebook (with outputs) for the same:\n https://colab.research.google.com/drive/1yF4aRuQ0eZUIsboaoKZAx8JHgvHKLoof?usp=sharing\n Now, from what I see from the training statistics, the loss values are steadily decreasing and are converging to zero, which suggests that the model is being trained properly. However, when I evaluate the optimal policy, the results are not very good, with the average rewards of the 3 agents being 6.6, -6 and -6. Also, the environment was a pretty simple one, with just 2 obstacles.\n I tried testing my custom environment using PettingZoo's parallel api, and it threw an assertion error. (The last cell). The problem could be my environment is not properly formed. How can I debug this? And apart from this, what changes should I make to my PPO training loop ? \n Changing the architecture is an obvious option but I want to make sure all the basic stuff is correct before doing that. A simple MLP policy should work on such a simple environment.\n ​\n    submitted by    /u/esem29  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17n3mpa/multi_agent_ppo_in_grid_world_environment_using/",
          "publishedOn": "2023-11-03T20:01:20.000Z",
          "wordCount": null,
          "title": "Multi Agent PPO in Grid World environment using PettingZoo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17n2ebm/cartpole_equivalent_enviroments_in_marl/",
          "author": null,
          "description": "Hi all! I'm learning some MARL and in implementing some algorithms I'd like to test them on some simple environments. In the single agent setting people generally go to something like CartPole. Are there similar environments in MARL? For cooperative/zero-sum/general sum? \n    submitted by    /u/1cedrake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17n2ebm/cartpole_equivalent_enviroments_in_marl/",
          "publishedOn": "2023-11-03T19:05:09.000Z",
          "wordCount": null,
          "title": "CartPole equivalent enviroments in MARL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17n046n/parametrization_of_the_policy_in_policybased/",
          "author": null,
          "description": "Why is it the case that people mostly use neural networks to parameterize policies in policy-based methods, rather than probability distributions? Are there situations, where there is a stronger case to use the latter? \n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17n046n/parametrization_of_the_policy_in_policybased/",
          "publishedOn": "2023-11-03T17:19:26.000Z",
          "wordCount": null,
          "title": "Parametrization of the Policy in Policy-based Methods",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17mjguf/transformers_learn_higherorder_optimization/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17mjguf/transformers_learn_higherorder_optimization/",
          "publishedOn": "2023-11-03T01:24:00.000Z",
          "wordCount": null,
          "title": "\"Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models\", Fu et al 2023 (self-attention learns higher-order gradient descent)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17m6m9q/what_architecture_for_visionbased_rl/",
          "author": null,
          "description": "Hello dear community,\n Someone has just asked me this question and I have been unable to provide a satisfactory answer, as in practice I have been using very simple and quite naive CNNs for this setting thus far. \n I think I read a couple papers a while back that were advocating for specific types of NNs to deal with vision-based RL specifically, but I forgot.\n So, my question is: what are the most promising NN architectures for pure vision-based (end-to-end) RL according to you?\n Thanks :)\n    submitted by    /u/yannbouteiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17m6m9q/what_architecture_for_visionbased_rl/",
          "publishedOn": "2023-11-02T15:53:28.000Z",
          "wordCount": null,
          "title": "What architecture for vision-based RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17lw9ts/comparing_rl_vs_llm_prompting_for_game_playing_ai/",
          "author": null,
          "description": "Hey people, I wanted to share a video from my ML YouTube channel discussing the state of the art methods for game playing AI systems post the LLM boom. \n Of course, this space was dominated by Reinforcement Learning for most of the 2010s, but there has been some interesting work towards using LLMs solo or as an “RL assistant” to train better RL agents. Some of the papers I talked about in the video seem to indicate that LLMs can guide RL exploration at the start of training to drastically improve sample efficiency. \n Here’s my video breaking down the complex prompting systems that let LLMs like GPT4 play Minecraft-like open world games and reflect on their progress. Hope people who are interested find it worthwhile…\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17lw9ts/comparing_rl_vs_llm_prompting_for_game_playing_ai/",
          "publishedOn": "2023-11-02T05:13:33.000Z",
          "wordCount": null,
          "title": "Comparing RL vs LLM Prompting for Game Playing AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17lgxta/variance_reduction_technique_proof/",
          "author": null,
          "description": "submitted by    /u/Massive_Cup_4458  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17lgxta/variance_reduction_technique_proof/",
          "publishedOn": "2023-11-01T17:07:55.000Z",
          "wordCount": 2583,
          "title": "Variance reduction technique proof?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17lfmfh/newbie_here_trying_to_make_crude_image/",
          "author": null,
          "description": "Hi there! I recently dived into the topic of RL after finishing a neural networks course at my university. I have basic understanding of the underlying principles of CNNs, the general idea of what Reinforcement Learning is, and I'm trying to learn more by making a project. \n The problem that I came up with is as follows:\n The system receives consecutive images frame after a frame (let's assume the frames come from a prerecorded video of stationary object, but the cameraman's hand is shaking/moving slowly) and tries to compute offsets for them that allow the user to align new frames to the original one. \n My idea is to use RL to train a network to recognize how the current frame is offset from the original (initial, first frame fed to the network) to allow some other software or even the us…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17lfmfh/newbie_here_trying_to_make_crude_image/",
          "publishedOn": "2023-11-01T16:10:30.000Z",
          "wordCount": 2993,
          "title": "Newbie here - trying to make crude image stabilization using RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17l5b47/invalid_action_masking_when_action_space_is/",
          "author": null,
          "description": "Background: I am relatively new to RL, so apologies if this post comes off as repititive or the solution is immediately obvious. But to my knowledge, I couldn't find any examples online for my use-case hence posting here. \n The problem I'm trying to solve is a relatively simple one. Let's say that my action space has only two variables x1 & x2, both continuous (Box). I want my valid actions to be only those where x1 + x2 < k where k is some constant. So I decide to use invalid action masking because that's the most eficient solution. \n But all I see online is examples of invalid action masking when actions are categorical. Even the ray discussion forums say that action masking for continuous action spaces isn't something they have done. \n Has anyone done this before? Any resources that you can point towards?\n    submitted by    /u/Solitary_Walker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17l5b47/invalid_action_masking_when_action_space_is/",
          "publishedOn": "2023-11-01T05:41:25.000Z",
          "wordCount": null,
          "title": "Invalid Action Masking when action space is continuous",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17kne6r/control_of_spider_like_robots_using_gnn_rl/",
          "author": null,
          "description": "hii this is my project but I have bare minimum coding knowledge and know even lesser about GNN and RL, has anyone worked on something like this before and would be able to dumb it down for me??\n    submitted by    /u/sunshinebreakfast7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17kne6r/control_of_spider_like_robots_using_gnn_rl/",
          "publishedOn": "2023-10-31T15:16:29.000Z",
          "wordCount": null,
          "title": "Control of spider like robots using GNN & RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17kbnm8/rl_llms_an_indepth_look_at_modern_game_playing_ai/",
          "author": null,
          "description": "submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17kbnm8/rl_llms_an_indepth_look_at_modern_game_playing_ai/",
          "publishedOn": "2023-10-31T03:15:54.000Z",
          "wordCount": null,
          "title": "RL & LLMS: An in-depth look at modern Game Playing AI Systems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ka6rh/why_gymgymnasium_removed_done_from_the_step/",
          "author": null,
          "description": "submitted by    /u/jkterry1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ka6rh/why_gymgymnasium_removed_done_from_the_step/",
          "publishedOn": "2023-10-31T02:02:02.000Z",
          "wordCount": null,
          "title": "Why Gym/Gymnasium removed done from the step function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17k8x3q/sampleefficient_reinforcement_learning_by/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17k8x3q/sampleefficient_reinforcement_learning_by/",
          "publishedOn": "2023-10-31T00:59:49.000Z",
          "wordCount": null,
          "title": "\"Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier\", D'Oro et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17k3njt/runtime_error_with_custom_environment/",
          "author": null,
          "description": "I created a custom environment to use it with RL algorithms. My custom environment provides the observations and receives rewards. I test my environment with my custom RL algorithm (Policy gradient) and the algorithms in stable-baselines3. My custom algorithm and DQN from stable-baselines3 works. However, if I use baselines with my custom algorithm or use PPO or A2C from sb3, I get:\n RuntimeError: could not create a primitive descriptor for a matmul primitive\n Any idea why this is happening?\n Extra details: On the custom algo error occurs here:\n \"/app/src/networks/critics.py\", line 40, in forward\n return self.network(obs)\n    submitted by    /u/FragrantCockroach8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17k3njt/runtime_error_with_custom_environment/",
          "publishedOn": "2023-10-30T21:03:43.000Z",
          "wordCount": null,
          "title": "Runtime Error with custom environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17jxv49/reward_function/",
          "author": null,
          "description": "Hello everyone I am taking reinforcement learning course. I am studying the course from two different books. In one of them it says R(s,a) -> [0,1] in other it says -> R. I am confused about the linitation of the reward function. This is the link of book [0,1] (for infinite mdp for finite mdp it says [0.1] rh)(s,a), adds trajectory ) . I want learn that is one of them false or am i missing smth\n    submitted by    /u/karakobra1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17jxv49/reward_function/",
          "publishedOn": "2023-10-30T16:50:42.000Z",
          "wordCount": null,
          "title": "Reward Function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17jws5s/the_amazing_success_stories_of_reinforcement/",
          "author": null,
          "description": "A beginner friendly introduction to Reinforcement Learning and the intuitions behind it… with four seminal projects that revolutionized the field of AI and RL.\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17jws5s/the_amazing_success_stories_of_reinforcement/",
          "publishedOn": "2023-10-30T16:02:29.000Z",
          "wordCount": null,
          "title": "The amazing success stories of Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17jwpyb/unable_to_create_a_custom_gym_environment/",
          "author": null,
          "description": "I put up a post about this earlier but soon realized that I hadn't given much information.\n ​\n In order to create my custom gym environment, I did the following things -\n  \nI went over the documentation given over here.\n I cloned this repository.\n In the folder `gym-examples/gym-examples`, I created the file - `my_test.py`. The contents of the file are given over here -```\n  \n​\n import gym env = gym.make('gym_examples/GridWorld-v0') print(\"Did this work?\")``` \n However, when I try to run this file, I get the error -\n ```\n File \"D:\\custom_env\\gym-examples\\my_test.py\", line 2, in <module> env = gym.make('gym_examples/GridWorld-v0') ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File \"C:\\Users\\thoma\\anaconda3\\envs\\env_torch\\Lib\\site-packages\\gym\\envs\\registration.py\", line 569, in make _check_version_exists(ns, name, version) File \"C:\\Users\\thoma\\anaconda3\\envs\\env_torch\\Lib\\site-packages\\gym\\envs\\registration.py\", line 219, in _check_version_exists _check_name_exists(ns, name) File \"C:\\Users\\thoma\\anaconda3\\envs\\env_torch\\Lib\\site-packages\\gym\\envs\\registration.py\", line 187, in _check_name_exists _check_namespace_exists(ns) File \"C:\\Users\\thoma\\anaconda3\\envs\\env_torch\\Lib\\site-packages\\gym\\envs\\registration.py\", line 182, in _check_namespace_exists raise error.NamespaceNotFound(f\"Namespace {ns} not found. {suggestion_msg}\") gym.error.NamespaceNotFound: Namespace gym_examples not found. Have you installed the proper package for gym_examples? \n ``` \n ​\n https://preview.redd.it/f0m02hky4dxb1.png?width=521&format=png&auto=webp&s=9fcd6eb7bedb70273f011a02000d15eb7ed309df\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17jwpyb/unable_to_create_a_custom_gym_environment/",
          "publishedOn": "2023-10-30T16:00:04.000Z",
          "wordCount": null,
          "title": "Unable to create a custom gym environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17jw2th/master_agent_controls_different_agent/",
          "author": null,
          "description": "I'm looking for research in the field of Deep Reinforcement Learning, where one agent controls the \"action\" of another, where the other executes that said action. For example, a master agent (lets say air traffic controller) tells another agent (lets say an airplane) to go from Point A to Point B, where the second agent (airplane) needs to learn how to maneuver from Point A to Point B, and the master agent (air traffic controller) needs to learn to schedule multiple other agents, or needs to learn an optimal path for a single airplane. \n ​\n In essence, can anyone point me to research with multiple agents, where one is regarded as \"master\" agent and the others as the \"pawns\"? \n    submitted by    /u/MyActualUserName99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17jw2th/master_agent_controls_different_agent/",
          "publishedOn": "2023-10-30T15:31:08.000Z",
          "wordCount": null,
          "title": "Master Agent Controls Different Agent?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17jv63o/confusing_observation_behavior/",
          "author": null,
          "description": "Hello everyone, I'm new to RL and have been trying to set up an environment to learn to play Metroid 2: Return of Samus on the Game Boy using the pyboy emulator and sb3_contrib.QRDQN as the learning algorithm. https://github.com/lixado/PyBoy-RL was used as a base to build on and change. My reward function rewards the AI for progressing to a new area (every ~200 x/y coordinates is stored as an area) to encourage it to explore. I've had some progress so far and have been able to consistently produce a model that can get out of the starting area.\n The observation I was originally working with was a 16x20 array of tiles and sprites from pyboy._game_area_np. pyboy sets this observation shape to be a 16x20 MultiDiscrete with each element containing integers from 0 to 384. This was then transform…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17jv63o/confusing_observation_behavior/",
          "publishedOn": "2023-10-30T14:51:40.000Z",
          "wordCount": null,
          "title": "Confusing observation behavior",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17jr4li/drl_in_production_scheduling/",
          "author": null,
          "description": "Hello everyone,\n I have some questions about the application of DRL in production scheduling. Considering that we have N jobs, each consists of X operations and each operation can be processed on a set of machines.\n Is it appropriate to create a single agent that selects an action once a machine completes the in-process operation, where the action consists in selecting the next operation to be processed in this machine ? so at each decision time (i.e., when a machine requests processing), the agent selects an operation from the available operations of this machine. \n I'm wondering about the feasability because in the most papers I've seen so far, once an operation is completed, rather than selecting an action for the idle machine, the agent selects the next operation of the job and assign it to the closest available machine. \n Thank you!\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17jr4li/drl_in_production_scheduling/",
          "publishedOn": "2023-10-30T11:23:06.000Z",
          "wordCount": null,
          "title": "DRL in production scheduling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17jbwdn/help_with_creating_my_custom_gym_environment/",
          "author": null,
          "description": "I am trying to create my own gym environment. However, I am getting the following error - \n ```\n gym.error.NamespaceNotFound: Namespace envs not found. Have you installed the proper package for envs\n ```\n I followed all the instructions given over here - https://www.gymlibrary.dev/content/environment_creation/. Can someone please suggest what could have gone wrong? \n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17jbwdn/help_with_creating_my_custom_gym_environment/",
          "publishedOn": "2023-10-29T20:32:28.000Z",
          "wordCount": null,
          "title": "Help with creating my custom gym environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17jbfek/dual_graphics_cards_for_ai_training/",
          "author": null,
          "description": "I have 3070 in my pc right now. I also have a 2070 super that is not being used. I have been working on lots of AI side projects lately and am wondering if I would benefit from multi gpu training. If so I have some options to implement the 2070. I could either: 1. Get an external gpu enclosure. 2. Put the 2070 super in my second pcie slot which would sit uncomfortably close to my 3070. 3. Get some adapter so that I can still have the 2070 super in my pc but not so close to the 3070. 4. Not bother with this at all and sell the 2070 super. 5. Sell both cards and get a 40 series if it is equal to the power of the 3070 and the 2070 super.\n I would have to upgrade my power supply as its only a 750 watt if I choose to put both in my pc. My machine runs windows 10 which I understand does not support sli but it still can utilize multiple gpu’s. Any suggestions?\n    submitted by    /u/pillarman38  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17jbfek/dual_graphics_cards_for_ai_training/",
          "publishedOn": "2023-10-29T20:10:12.000Z",
          "wordCount": null,
          "title": "Dual graphics cards for ai training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17j9wer/how_to_set_up_an_observation_space_for_a_variable/",
          "author": null,
          "description": "Imagine a 2D Cartesian System from -1 to 1 on both axis. Now imagine that a few points appear in the system. For example:\n (-0.3, 0.1), (0.7, -0.2) and (0.9, 0.5). \n If I wanted to represent an observation like this in Gymnasium (formerly Gym), I'd write something like this in my custom environment:\n observation_space = spaces.Box(low=-1, high=1, shape=(3,), dtype=float32) \n Now my model will learn something specific to 3 points in a 2D space.\n Well, what happens if my environment now has 4 points? I guess should retrain the model again... Think of these points as objectives in the environment, sometimes there's only 1 and others there might be 20 or more at the same time. Sometimes a new point appears after a certain action. \n So there goes my question: how can I define an observation space in Gymnasium that allows me to introduce a variable number of points during training so that the model learns to do an specific task with any number of points?\n    submitted by    /u/_Strange__attractor_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17j9wer/how_to_set_up_an_observation_space_for_a_variable/",
          "publishedOn": "2023-10-29T19:00:42.000Z",
          "wordCount": null,
          "title": "How to set up an observation space for a variable number of points in Gymnasium?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17j9bfo/ppoclip_computing_gradient_without_auto/",
          "author": null,
          "description": "Hello guys\n I am in a bit of a bind, I am trying to implement PPO from scratch in another language than python, WITHOUT any auto differentation available.\n I am using this as implementation reference.\n I think I have most of the implementation aside from the differentation of the loss formula. In python, everything is done at this line right here, but it's basically auto differentiation and I cannot do this myself, so I have to compute it manually. Mean Squared Error is easy, but the entropy factor and the clip ones are a bit harder, and while I have a result of my own I have no way to confirm this. All the tutorial I have found just say \"we will let the autodiff do the job\"... So it doesn't really help me, and I don't really have the time to dig into how this autodiff part of the library works in detail when in theory this should be simple highschool-level maths.\n Does anyone know how I can fin the exact formula, find a tutorial, or something along those lines? I am talking about the derivative for the Value and Policy network for this formula.\n Here is what I have for the value part:\n if r(θ) < 1 - ε and At < 0: value_derivative = 0 if r(θ) > 1 + ε and At > 0: value_derivative = 0 else: value_derivative = At \n For the entropy part:\n entropy_derivative = ∑(1 + log(π(a|s))) \n But since I use softmax to choose the action from the policy network, I don't know is that should be taken into account or not...\n Any help is appreciated, thanks a lot.\n    submitted by    /u/Edgeaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17j9bfo/ppoclip_computing_gradient_without_auto/",
          "publishedOn": "2023-10-29T18:34:01.000Z",
          "wordCount": null,
          "title": "PPO-clip: Computing gradient WITHOUT auto differentiation library, help please?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17iyy9i/my_frozen_lake_agent_isnt_learning_anything_what/",
          "author": null,
          "description": "https://github.com/bherwanisuraj/gridworld\n I am new to RL. I am trying to train the agent on frozen lake environment but it is not learning. What am I doing wrong? Please help.\n    submitted by    /u/tlevelup  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17iyy9i/my_frozen_lake_agent_isnt_learning_anything_what/",
          "publishedOn": "2023-10-29T09:03:15.000Z",
          "wordCount": null,
          "title": "My frozen lake agent isn't learning anything, what am I doing wrong?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17inukb/deep_qlearning_to_actorcritic_using_robotics/",
          "author": null,
          "description": "Please like,follow and share: Deep Q-Learning to Actor-Critic using Robotics Simulations with Panda-Gym https://medium.com/@andysingal/deep-q-learning-to-actor-critic-using-robotics-simulations-with-panda-gym-ff220f980366\n    submitted by    /u/Fit_Maintenance_2455  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17inukb/deep_qlearning_to_actorcritic_using_robotics/",
          "publishedOn": "2023-10-28T21:40:54.000Z",
          "wordCount": null,
          "title": "Deep Q-Learning to Actor-Critic using Robotics Simulations with Panda-Gym",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ihdkx/created_a_video_for_beginners_about_what_is/",
          "author": null,
          "description": "submitted by    /u/Ecstatic-Ring3057  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ihdkx/created_a_video_for_beginners_about_what_is/",
          "publishedOn": "2023-10-28T16:28:00.000Z",
          "wordCount": null,
          "title": "Created a video for beginners about what is reinforcement learning and how it can control agents in the virtual environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17iahuw/how_can_i_predict_the_next_best_action_for_a_ddpg/",
          "author": null,
          "description": "I have a DDPG agent that takes a continuous observation and outputs a continuous action vector (see below).\n outputs = layers.Dense(self.action_size, activation=\"tanh\", kernel_initializer=last_init)(x) \n An example action output looks as follows:\n [0.48011236 0.47933139]\n When my agent observes a terminal state action pair, I add it to a list of observations called terminal observations. I would like it so these actions get blocked in the future so there is no possible way for the agent to take them again. I understand that I could just add a large negative penalty, but I would like to ensure that the state action pair cannot be taken again.\n Evidently, I would like it so when I input my state and recieve an action back, if this pair is in terminal observations. I would like it so these actions get blocked in the future so there is no possible way for the agent to retake them. I understand that I could just add a large negative penalty, but I would like to ensure that the state action pair cannot be taken again.\n I understand that this won't change much in the agent's behaviour as instead of taking `[0.48011236 0.47933139]`, it might pick `[0.4900000 0.47933139]`. But I am unsure how to go about this, specifically selecting the next best action.\n    submitted by    /u/ArchNemesisPlays  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17iahuw/how_can_i_predict_the_next_best_action_for_a_ddpg/",
          "publishedOn": "2023-10-28T09:58:43.000Z",
          "wordCount": null,
          "title": "How can I predict the next best action for a DDPG RL agent?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17hul99/r_bidirectional_negotiation_first_time_in_india/",
          "author": null,
          "description": "submitted by    /u/shani_786  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17hul99/r_bidirectional_negotiation_first_time_in_india/",
          "publishedOn": "2023-10-27T18:50:59.000Z",
          "wordCount": 2584,
          "title": "[R] Bidirectional Negotiation First Time in India | Autonomous Driving | Swaayatt Robots",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17hrhgp/r_tdmpc2_scalable_robust_world_models_for/",
          "author": null,
          "description": "submitted by    /u/joepadde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17hrhgp/r_tdmpc2_scalable_robust_world_models_for/",
          "publishedOn": "2023-10-27T16:30:31.000Z",
          "wordCount": 2616,
          "title": "[R] TD-MPC2: Scalable, Robust World Models for Continuous Control - TD-MPC2 performs 100+ tasks without tuning, and enables training of a single 317M parameter model that performs 80 tasks across multiple domains, embodiments, and action spaces!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17hpquq/reinforcement_learning_llms_an_indepth_look_at/",
          "author": null,
          "description": "submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17hpquq/reinforcement_learning_llms_an_indepth_look_at/",
          "publishedOn": "2023-10-27T15:11:28.000Z",
          "wordCount": 2548,
          "title": "Reinforcement Learning & LLMs : An in-depth look at various modern game-playing AI systems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17hpbnr/what_makes_the_epsilongreedy_policy_the_standard/",
          "author": null,
          "description": "I can see how the epsilon-greedy policy is a valid way to handle the exploration/exploitation tradeoff, but it’s also clearly not the only way, and results in a policy that is discontinuous with respect to the action-values (which intuitively I’d expect to be bad, but I also know a lot of RL/DRL can defy intuition). You could certainly create a policy using the softmax of the action-values, adjusting temperature as desired, for example, among countless other methods of converting logits into a probability distribution. So what makes epsilon-greedy stand out?\n    submitted by    /u/KalebMW99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17hpbnr/what_makes_the_epsilongreedy_policy_the_standard/",
          "publishedOn": "2023-10-27T14:52:30.000Z",
          "wordCount": 2640,
          "title": "What makes the epsilon-greedy policy the standard for implementing the exploration/exploitation tradeoff in Q-learing/DQN?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17hoz4h/curriculum_learning_and_selfplay_with_any_neural/",
          "author": null,
          "description": "We've just released an update to AglieRL, our SOTA evolutionary hyperparameter optimisation framework for reinforcement learning.\n This update includes a MakeEvolvable wrapper to make any PyTorch network, including pre-trained models, evolvable in one line of code. This can result in 10x faster training by using our framework.\n We've also created a curriculum learning and self-play tutorial that shows how to train a DQN agent to play Connect Four. Self-play can lead to amazing results, as demonstrated by AlphaGo etc, where agents discover new strategies to achieve superhuman performance, so we wanted to make it accessible to all.\n Please check it out! https://github.com/AgileRL/AgileRL\n    submitted by    /u/nicku_a  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17hoz4h/curriculum_learning_and_selfplay_with_any_neural/",
          "publishedOn": "2023-10-27T14:36:33.000Z",
          "wordCount": 2646,
          "title": "Curriculum learning and self-play with any neural network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17hey1d/any_example_library_for_vectorized_mdp_with/",
          "author": null,
          "description": "Hi all,\n I am following the chapter 4 from the book of Barto & Sutton on RL and I implemented the simple algorithm for value iteration for a given Transition probability matrix.\n As I kept increasing the state space, this became slower and slower. It seems to me that it is an embarrassingly parallelizable algorithm, since we can compute the value of each state independently (just with the values from the previous iteration). \n Is there any example online on how to do it efficiently with pytorch or any other library?\n ​\n    submitted by    /u/nlp7s  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17hey1d/any_example_library_for_vectorized_mdp_with/",
          "publishedOn": "2023-10-27T03:56:39.000Z",
          "wordCount": 2635,
          "title": "Any example / library for vectorized MDP with pytorch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17he3ak/can_sb3_or_alternatives_provide_full_endtoend_gpu/",
          "author": null,
          "description": "I want to get full end-to-end GPU computation since the data transfer between CPU-GPU significantly slows down computation. I'm currently using Stable Baselines3 as I could get it up and running quickly. So in this journey I tried to use tensors for the state and rewards, but it seems that SB3 is insisting on working with numpy and not tensors.\n ``TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.``\n I found the following repo which is rather interesting, but it seems last update was 2 years ago and not sure I want to use something that's not actively supported:\n https://github.com/MetcalfeTom/stable-baselines3-GPU\n What would you suggest I use to achive full end-to-end GPU computation?\n I also found RlLib but I saw comments that it might be a bit more complicated to get up & running:\n https://docs.ray.io/en/latest/rllib/index.html\n    submitted by    /u/asenski  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17he3ak/can_sb3_or_alternatives_provide_full_endtoend_gpu/",
          "publishedOn": "2023-10-27T03:07:22.000Z",
          "wordCount": 2689,
          "title": "Can SB3 or alternatives provide full end-to-end GPU computation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17h3l5c/where_to_start_with_debugging/",
          "author": null,
          "description": "I am working on a project using reinforcement learning, where a tensorflow DQN agent is being trained to choose from an action space of 16 different actions. The agent exhibits the following behavior during evaluation: for each evaluation run the agent only chooses one action regardless of the state, the action could change or remain the same for the following runs, however, for any specific run the action chosen is the same.\n Where should I start debugging?\n    submitted by    /u/Realistic_Mobile_183  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17h3l5c/where_to_start_with_debugging/",
          "publishedOn": "2023-10-26T18:51:08.000Z",
          "wordCount": null,
          "title": "Where to start with debugging?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17h2xoe/how_to_cluster_with_respect_to_the_transition/",
          "author": null,
          "description": "Hello, I have an environment in which the transition function changed depending on which state I am.\n I want to be able to cluster with respect to it. I have been trying to do this since quite a while but cannot find a way to do it, do you have any hints or suggestions?\n    submitted by    /u/Fragore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17h2xoe/how_to_cluster_with_respect_to_the_transition/",
          "publishedOn": "2023-10-26T18:22:31.000Z",
          "wordCount": null,
          "title": "How to cluster with respect to the transition function of a RL environment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17h2vjh/stuck_with_windowswsl_environment_help_needed/",
          "author": null,
          "description": "So I've started on trying to work on a custom game environment, and for the most part it's *mostly* done. One issue I have is getting MARLlib to run on windows. I know that it's not meant to, so I tried to use WSL to do it, but unfortunately pydirectinput doesn't work via WSL, so I don't know how to proceed further. Do I need to find a way to connect my windows machine which will play the game, and wsl which will probably run MARLlib? If so could anyone guide me to any resources for this? Trying a VM is a no go because the game is old and doesn't run on linux.\n Any help would be much appreciated.\n    submitted by    /u/EquivalentCurious745  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17h2vjh/stuck_with_windowswsl_environment_help_needed/",
          "publishedOn": "2023-10-26T18:19:59.000Z",
          "wordCount": null,
          "title": "Stuck with windows/wsl environment - help needed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17g2d3r/the_right_to_perform_rl_on_games/",
          "author": null,
          "description": "Hi all,\n I'm new to learning RL. I want to train an agent to clear a game such as vampire survivor, super mario brothers, etc, as my first research/project. I talked with my tutor , he reminded me to pay attention to copyright issues and that I needed a permission to use these works for training.\n I guess I could get permission by asking the game's author directly, but before that, or for games produced by some big companies, where can I find information about the rights?\n Although reading the game's memory is a challenge for me, it's cool to see a agent clear a game.\n    submitted by    /u/Ruine_fff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17g2d3r/the_right_to_perform_rl_on_games/",
          "publishedOn": "2023-10-25T11:16:08.000Z",
          "wordCount": null,
          "title": "The right to perform RL on games",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17g0snq/building_doom_with_ai_enemies/",
          "author": null,
          "description": "I'm planning to go down the rabbit hole of using RL to train agents in doom/vizdoom\n The goal would be to create a version of doom where the enemies have AI and are adaptive.\n Doom and Doom 2 are some of my all time classic favorites. There are people still making maps to this day!\n Let me know on what you think about the idea?\n Project plan - Nov 2023 : RL refresher from the David Silver RL course on YouTube Dec 2023 : start working on openAI and stablebaselines3 and watch Nicholas Renotte's videos Jan 2024 : play around with the Doom WAD and try to see if you can make changes to the doom engine + Training and setting up custom env Feb 2024 : hopefully first level with enemy AI created Mar 2024 : release fully completed open source version of the game\n Background: I work at a hedge fund, have some basics on reimbursement learning, although it has been a long long time.\n Time is a bit limited after 12 hours or work and 2 hours of gym (the real human world one) so kinda stretching this out\n Any suggestions are welcome. Any courses, books, libraries and tools you'd suggest?\n    submitted by    /u/Sahil231090  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17g0snq/building_doom_with_ai_enemies/",
          "publishedOn": "2023-10-25T09:25:38.000Z",
          "wordCount": null,
          "title": "Building Doom with AI enemies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17frz4s/surprise_for_learning/",
          "author": null,
          "description": "I was recently listening to a TalkRL podcast where Danijar Hafner explains that Minecraft as a learning environment is hard because of sparse rewards (30k steps before finding a diamond). Coincidentally, I was reading a collection neuroscience articles today where surprise or novel events are a major factor in learning and encoding memory.\n Does anyone know of RL algorithms that learn based on prediction error (i.e. \"surprise\") in addition to rewards?\n    submitted by    /u/CognitoIngeniarius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17frz4s/surprise_for_learning/",
          "publishedOn": "2023-10-25T00:27:09.000Z",
          "wordCount": null,
          "title": "\"Surprise\" for learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17fp4yj/rewards_in_montezumas_revenge/",
          "author": null,
          "description": "Hello all, \n I'm working on Montezuma's Revenge using the Gymnasium API. I wonder if there's anyone here that knows the numerical value of the rewards? And if so, how they are typically scaled down. \n ​\n Thanks!\n ​\n G_bes \n    submitted by    /u/G_bes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17fp4yj/rewards_in_montezumas_revenge/",
          "publishedOn": "2023-10-24T22:17:22.000Z",
          "wordCount": null,
          "title": "Rewards in Montezuma's Revenge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17fef8r/the_n_implementation_details_of_rlhf_with_ppo/",
          "author": null,
          "description": "submitted by    /u/vwxyzjn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17fef8r/the_n_implementation_details_of_rlhf_with_ppo/",
          "publishedOn": "2023-10-24T14:41:23.000Z",
          "wordCount": null,
          "title": "The N Implementation Details of RLHF with PPO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17f6ewb/creating_a_custom_environment_in_unreal_engine_5/",
          "author": null,
          "description": "Hello, I would like to create my own environment (Maze), in which I would like to train my drone using reinforcement learning, I am kind of new and I don't know how can I set the state space, rewards, and if I would like to use BS3 for training then how can I connect the environment? And for the agent which is the drone, should i just do the AirSim build.cmd and take the agent from there and place the starting position flag or what? I am a bit lost and I can't find tutorials on how to do this, I'd appreciate it if you could provide some guidance. Thanks in advance.\n    submitted by    /u/Gabii99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17f6ewb/creating_a_custom_environment_in_unreal_engine_5/",
          "publishedOn": "2023-10-24T06:37:19.000Z",
          "wordCount": null,
          "title": "Creating a Custom Environment in Unreal Engine 5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17eslsx/how_to_properly_evaluate_competitive_marl/",
          "author": null,
          "description": "Hello, everyone! I'm building a MARL agent for a zero-sum game and I'm having a hard time evaluating it.\n I managed to quickly train it for a simple case and I could manually verify that it was actually learning the optimal decision making because I already know how the game works and, for this simple case, I know that there actually is a mathematically correct way to play it (from both sides) and how it should be played, but that isn't true for most cases (and even if it was, I wouldn't be able to manually verify thousands of games). To complicate things even more, there are billions and billions of possible initial states.\n For single-agent RL, I could set a reward threshold (if I knew which was the maximum reward possible) or at least I could set a maximum time of \"no improvement\" but, in a zero-sum game, the sum of the policy rewards is, well, zero.\n I could think of two solutions:\n  \nEvaluate convergence to Nash Equilibrium on a subset of the possible initial states, which could be a problem because I'm not sure if the game dynamics guarantee the existance of Nash Equilibria;\n Evaluate convergence of the winrate of the trained agent against a \"hand-crafted\" baseline agent, which could be a problem because the quality of this evaluation method could depend on how well I can make this baseline agent (which won't be even close to optimal, otherwise I wouldn't be training an agent).\n  \nAny thoughts?\n    submitted by    /u/victorsevero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17eslsx/how_to_properly_evaluate_competitive_marl/",
          "publishedOn": "2023-10-23T19:20:29.000Z",
          "wordCount": null,
          "title": "How to properly evaluate competitive MARL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17er4jp/programmatic_backdoors_dnns_can_use_sgd_to_run/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17er4jp/programmatic_backdoors_dnns_can_use_sgd_to_run/",
          "publishedOn": "2023-10-23T18:18:22.000Z",
          "wordCount": null,
          "title": "Programmatic backdoors: DNNs can use SGD to run arbitrary stateful computation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17eqj5i/in_your_opinion_which_is_the_most_beautiful_form/",
          "author": null,
          "description": "Didn't see anything about this kind of post in the rules\n I'm asking for a tattoo idea haha\n    submitted by    /u/victorsevero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17eqj5i/in_your_opinion_which_is_the_most_beautiful_form/",
          "publishedOn": "2023-10-23T17:53:06.000Z",
          "wordCount": null,
          "title": "In your opinion, which is the most beautiful form of the Bellman Equation and why?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ej7ri/inverted_pendulum_swingup_problem_not_converging/",
          "author": null,
          "description": "I am making a thesis about using RL to solve the inverted pendulum swing-up problem. I have tried using TD3, SAC, and TD3-Fork. In my testing, TD3-Fork worked best, I think SAC would also work if I am able to tune the hyperparameters correctly. \n I would like a similar trained agent to td3 converged where the agent balances the pole almost indefinitely. I have tried the hyperparameters from the website and also different hyperparameters but it has not converged. I am wondering if I am missing something or if there is anything I can do to improve the agent. I have been thinking of using HER instead of FORK. Any help or advice would be appreciated.\n training reward data\n The 'maximum' reward that I could get in the simulation is >880. The reward function that I used is -[cos(theta) + 10(|x| > 0.9) + 10(|theta_dt| > 18)]. However, from the data above it only converges to about 837 max and rarely reaches >900.\n trained td3 fork agent\n    submitted by    /u/YEEETTT0708  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ej7ri/inverted_pendulum_swingup_problem_not_converging/",
          "publishedOn": "2023-10-23T12:29:00.000Z",
          "wordCount": null,
          "title": "Inverted pendulum swing-up problem not converging to global optimum using SAC or TD3.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17egoiw/godot_enables_me_to_do_pure_c_deep_reinforcement/",
          "author": null,
          "description": "submitted by    /u/Vae94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17egoiw/godot_enables_me_to_do_pure_c_deep_reinforcement/",
          "publishedOn": "2023-10-23T09:55:36.000Z",
          "wordCount": null,
          "title": "Godot enables me to do pure C# Deep reinforcement learning.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17e8no8/r_demo_of_flowlenia_towards_openended_evolution/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17e8no8/r_demo_of_flowlenia_towards_openended_evolution/",
          "publishedOn": "2023-10-23T01:19:37.000Z",
          "wordCount": null,
          "title": "[R] Demo of “Flow-Lenia: Towards open-ended evolution in cellular automata through mass conservation and parameter localization” (link to paper in the comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17dzk9i/how_the_self_play_algorithm_masters_multiagent_ai/",
          "author": null,
          "description": "submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17dzk9i/how_the_self_play_algorithm_masters_multiagent_ai/",
          "publishedOn": "2023-10-22T18:17:02.000Z",
          "wordCount": null,
          "title": "How the Self Play algorithm masters Multi-Agent AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17dpqyl/mujoco_rl_robotic_arm/",
          "author": null,
          "description": "Hi everyone, I'm new to robotic arms and I want to learn more about how to implement them using mujoco env. I'm looking for some open-source projects on github that I can run and understand. I tried MuJoCo_RL_UR5 repo but it didn't work well for me, it only deployed a random agent. Do you have any recommendations for good repos that are beginner-friendly and well-documented?\n    submitted by    /u/satyamstar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17dpqyl/mujoco_rl_robotic_arm/",
          "publishedOn": "2023-10-22T09:51:10.000Z",
          "wordCount": null,
          "title": "Mujoco RL Robotic Arm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17dkoyc/why_does_bellman_equation_converge/",
          "author": null,
          "description": "After multiple iterations the value function converge by bellaman updates (vale iteration algorithm). Can someone provide a intuitive reasoning why the value converges?\n    submitted by    /u/RaceCondition01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17dkoyc/why_does_bellman_equation_converge/",
          "publishedOn": "2023-10-22T04:01:40.000Z",
          "wordCount": null,
          "title": "Why does bellman equation converge?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17dcz2j/policy_evaluation/",
          "author": null,
          "description": "I know that given a policy, I can find the value function using iterative policy evaluation. \n Can I, given the value function, find the policy?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17dcz2j/policy_evaluation/",
          "publishedOn": "2023-10-21T21:30:17.000Z",
          "wordCount": null,
          "title": "Policy Evaluation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17dburc/question_on_advantage_recomputation_for_ppo/",
          "author": null,
          "description": "Hi,\n I've been re-reading the \"What matters in on-policy reinforcement learning\" paper (https://arxiv.org/abs/2006.05990), and noticed that they suggest to recompute advantages at the beginning of each epoch (choice C5, see section 3.5 and appendix B.1). I was wondering:\n  \nif someone here had already tried this and seen a significant improvement (which is what the paper suggests) ?\n if it did not also suppose to recompute the value targets at the beginning of each epoch, which could lead to some sort of moving target issue ?\n  \nBest,\n    submitted by    /u/Scrimbibete  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17dburc/question_on_advantage_recomputation_for_ppo/",
          "publishedOn": "2023-10-21T20:39:03.000Z",
          "wordCount": null,
          "title": "Question on advantage (re-)computation for PPO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17d8gmx/in_rl_how_can_we_reward_an_action_taken_5_steps/",
          "author": null,
          "description": "Let us say we are building a model that will learn how to play a computer game like DOTA or league of legends.\n If model for example, buys weapon A, and use the item's ability on opponent B, it should learn what damage it gives to opponent given the items opponent B is wearing. But we would have done a lot of other actions in between before being able to use that weapon to reward the model on what it does / how much damage it made.\n How does do you do delayed reward for specific action made X number of steps ago?\n Thank you.\n    submitted by    /u/oniongarlic88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17d8gmx/in_rl_how_can_we_reward_an_action_taken_5_steps/",
          "publishedOn": "2023-10-21T18:02:12.000Z",
          "wordCount": null,
          "title": "In RL, how can we reward an action taken 5 steps ago?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17cyih8/zoomposium_with_professor_dr_petra_ritter_the/",
          "author": null,
          "description": "Zoomposium with Professor Dr. Petra Ritter: \"The simulation of brains\" \n In another installment in our \"Zoomposium Series\" on the topic of \"Brain Research\", my colleague Axel Stöcker of the \"Blog der großen Fragen\" and I had the great honor and pleasure of conducting an interview with the very well-known and renowned German medical doctor and neuroscientist Professor Dr. Petra Ritter. \n In this context, Ms. Ritter became a co-founder and leader of the co-design project \"The Virtual Brain\", which is a component of the European Open Science Cloud (EOSC) and is \"a neuroinformatics platform for simulating whole brain networks using biologically realistic connectivity\". \n She is leading the development of a virtual research environment as a collaborative research platform for sensitive health data and head of the \"German National Neuroscience Research Infrastructure Initiative (NFDI-Neuroscince)\" and involved in the development of the \"Health Data Cloud EBRAINS\". \n Petra Ritter has been Johanna Quandt Professor and Head of the Section for Brain Simulation at the Department of Neurology with Experimental Neurology at Charité - Universitätsmedizin Berlin since 2017. \n There, Professor Ritter and her team are involved in the \"Simulation of Brains\". \n More at: https://philosophies.de/index.php/2023/09/17/die-simulation-von-gehirnen/ \n ​\n https://preview.redd.it/937m7mtyvivb1.jpg?width=1000&format=pjpg&auto=webp&s=22d1a7576f2ebbe7904f0187bd7c0234df7ddb8f\n    submitted by    /u/philosophiesde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17cyih8/zoomposium_with_professor_dr_petra_ritter_the/",
          "publishedOn": "2023-10-21T09:15:07.000Z",
          "wordCount": null,
          "title": "Zoomposium with Professor Dr. Petra Ritter: \"The simulation of brains\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17cmdzb/dqn_with_a_binary_vector_as_output/",
          "author": null,
          "description": "Heey everyone!\n I hope you're doing well.\n I need your help guys.\n I'm working on a DQN that outputs a binary vector of length L (I just applied sigmoid function on the ouptut layer and take p>0.5 as 1 and 0 otherwise). In this setting, how can modify the below code to update my DQN: \n def update(self):\n states, actions, rewards, next_states, dones = self.memory.sample(self.batch_size)\n states = torch.FloatTensor(np.array(states))\n actions = torch.LongTensor(np.array(actions))\n rewards = torch.FloatTensor(np.array(rewards))\n next_states = torch.FloatTensor(np.array(next_states))\n dones = torch.FloatTensor(np.array(dones))\n q_values = self.model(states)\n q_values = q_values.gather(1, actions.unsqueeze(1))\n next_q_values = self.target_model(next_states).detach()\n expected_q_values = rewards + self.gamma * (1 - dones) * next_q_values.max(1)[0]\n expected_q_values = expected_q_values.unsqueeze(1) \n loss = nn.BCELoss(q_values, expected_q_values)\n self.optimizer.zero_grad()\n loss.backward()\n self.optimizer.step()\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17cmdzb/dqn_with_a_binary_vector_as_output/",
          "publishedOn": "2023-10-20T21:45:20.000Z",
          "wordCount": null,
          "title": "DQN with a binary vector as output",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17cm8bg/is_the_deadly_triad_even_real/",
          "author": null,
          "description": "Sutton and Barto’s textbook mentions that combing off-policy learning, bootstrapping, and function approximation leads to extreme instability and should be avoided. Yet when I encounter a reinforcement problem in the wild and look how people go about solving it, if someone’s solution involves bootstrapping more often than not it’s some variation of deep Q-learning. Why is this?\n    submitted by    /u/BiasedEstimators  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17cm8bg/is_the_deadly_triad_even_real/",
          "publishedOn": "2023-10-20T21:38:31.000Z",
          "wordCount": null,
          "title": "Is the “Deadly Triad” even real?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17cdk6i/dead_simple_explanations_of_popular_rl_concepts/",
          "author": null,
          "description": "Hey everyone!\n I just started an open-source repo for RL explanations. https://github.com/DenseLayers/densewiki\n Many people, especially beginners struggle to develop the intuition around concepts (like actor-critic vs advantage actor-critic, GAE, PPO, etc).\n Often it's nice to see what's happening at a high level first, before we dive deeper into the math. That's what I'm trying to do here.\n But I can't do it alone, so I'm posting here to get help from others in the community to make sure the explanations are clear, extremely approachable, and accurate.\n If you'd like to work with me on this (whether you're a complete beginner or very knowledgeable), please reach out!\n ​\n    submitted by    /u/mngrwl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17cdk6i/dead_simple_explanations_of_popular_rl_concepts/",
          "publishedOn": "2023-10-20T15:11:14.000Z",
          "wordCount": null,
          "title": "Dead simple explanations of popular RL concepts (open source)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17c9q7t/reinforement_learning_on_the_game_quarto/",
          "author": null,
          "description": "hello, i am working on solving this board game called \"Quarto\" where we have 16 different pieces. but these pieces have attributes in common they black or white, short or tall, hollow top or closed top, and square shaped or circle shaped pieces each piece has four attributes. the winning condition is to place 4 pieces consecutively in a 4X4 board with at least one attribute in common to win. and also we hadve to choose the piece for the opponent to make and then opponent places that piece and gives us a piece to move. so there are two actions. i have made the action space as 256 + 16 where 256=16*16 as all pieces can be place anywhere on the board and the last 16 is the last possible move that is the move which leads to a terminating state so the next_piece for the opponent would be blank …",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17c9q7t/reinforement_learning_on_the_game_quarto/",
          "publishedOn": "2023-10-20T12:06:55.000Z",
          "wordCount": null,
          "title": "Reinforement learning on the game \"Quarto\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17c60uy/what_is_the_optimal_way_to_train_a_ppo/",
          "author": null,
          "description": "Hello!\n I've got a really simple question, i'm training a PPO algorithm and I wanna know what is the best way to train my model?\n Sorry, I'll try to be clear!\n So right now what i'm doing is :\n  \nI'm loading a previously trained PPO model\n Train the model on 20000 timesteps\n Evaluate the reward of the newly trained PPO model at the end of the timesteps and compare it to the reward from the model loaded in 1\n If the reward is greater then i'm going back to step 1 and using the new model\n  \nIf not then i'm going back to step 1.\n Is it a correct way to do so? \n Thanks a lot and have a great day!\n    submitted by    /u/PointNo1904  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17c60uy/what_is_the_optimal_way_to_train_a_ppo/",
          "publishedOn": "2023-10-20T08:10:21.000Z",
          "wordCount": null,
          "title": "What is the optimal way to train a PPO?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17by3my/new_chess_dataset_32b_games_608b_moves_generated/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17by3my/new_chess_dataset_32b_games_608b_moves_generated/",
          "publishedOn": "2023-10-20T00:25:50.000Z",
          "wordCount": null,
          "title": "new chess dataset: 3.2b games (608b moves) generated by 2500-ELO Stockfish selfplay {LAION}",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17bpy32/dreamerv2_stochastic_decoders/",
          "author": null,
          "description": "Hello,\n I am implementing the code for the paper DreamerV2, and there are some things that look a bit strange to me.\n The predictors and, in particular, the image and the reward predictors are stochastic and they output Normal distributions. Both the normal distributions have the mean, which is the output of the respective models, and the variance is 1. \n Usually, in RL we normalize observations and rewards to be between 0 and 1, and in such a case I don't know if it's reasonable to sample from a Gaussian with variance one.\n I don't know about the specific preprocessing done in DreamerV2, except in the paper DreamerV1, where in section 6 (Control tasks), they say that the reward ranges from 0 to 1. \n Do you know what are the advantages of using a stochastic decoder and when to use it?\n    submitted by    /u/ZioFranco1404  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17bpy32/dreamerv2_stochastic_decoders/",
          "publishedOn": "2023-10-19T18:27:55.000Z",
          "wordCount": null,
          "title": "DreamerV2 stochastic decoders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17bgf4v/reinforcement_learning_on_steam_games/",
          "author": null,
          "description": "Does anyone have any idea how to get game details such as character movements, environment information using api calls, as I want to use to do my reinforcement learning.\n    submitted by    /u/Important_Ad_55  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17bgf4v/reinforcement_learning_on_steam_games/",
          "publishedOn": "2023-10-19T10:58:44.000Z",
          "wordCount": null,
          "title": "Reinforcement learning on steam games",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17b4w0w/mujoco_with_openai_gym/",
          "author": null,
          "description": "Hello,\n I'm trying to use OpenAI's spinning up to learn about RL. Spinning up requires OpenAI gym, instead of the new gymnasium package. \n Trying to install MuJoCo with gym, I'm getting an error that I'm missing a MuJoCo liscense key. But MuJoCo is free now, right? So what is the status with backward compatibility with it? Is there some global license key that can be used? Or is it simply not backward compatible?\n Thanks a lot.\n    submitted by    /u/mega_monkey_mind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17b4w0w/mujoco_with_openai_gym/",
          "publishedOn": "2023-10-18T23:40:32.000Z",
          "wordCount": 2634,
          "title": "MuJoCo with OpenAI gym",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17axl9u/dqn_in_a_non_markovian_environment/",
          "author": null,
          "description": "Hello there,\n I am working on a school project in which we want to implement a RL algorithm on a simple problem.\n The goal is to maximise the heart rate of a person using a vibrator by setting its frequency.\n We wrote a simulator that outputs the new heart rate based on the vibration frequency. It implements several different classes of users: for example one for which the heart rate increases when the vibration frequency stays the same, another that prefers when it increases over time, etc.\n We determined that we need to have as a state the current heart rate but also a table of the k previous heart rates and the actions associated. Without that memory, we would not be able to tell apart the different profiles as in the same state, we would need to do different actions to satisfy them both. We then have a correlation between previous samples and the action we make at current state, which I have read makes the problem non markovian.\n Is there a way to solve this problem using a DQN algorithm, given that we need to memorize the previous samples linearly which seems to go against the algorithm behavior and the usage of a replay memory? Are there more suited algorithms?\n    submitted by    /u/Outrageous-Subject38  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17axl9u/dqn_in_a_non_markovian_environment/",
          "publishedOn": "2023-10-18T18:24:05.000Z",
          "wordCount": 2770,
          "title": "DQN in a non markovian environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17atv3b/best_books_to_learn_reinforcement_learning/",
          "author": null,
          "description": "submitted by    /u/Lakshmireddys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17atv3b/best_books_to_learn_reinforcement_learning/",
          "publishedOn": "2023-10-18T15:45:20.000Z",
          "wordCount": 2566,
          "title": "Best Books to Learn Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17artxz/gpt_learning_to_learn_with_generative_models_of/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17artxz/gpt_learning_to_learn_with_generative_models_of/",
          "publishedOn": "2023-10-18T14:14:15.000Z",
          "wordCount": 2584,
          "title": "\"gp.t: Learning to Learn with Generative Models of Neural Network Checkpoints\", Peebles et al 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17aqxgp/autonomous_driving_ellipsoidal_constrained_agent/",
          "author": null,
          "description": "submitted by    /u/shani_786  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17aqxgp/autonomous_driving_ellipsoidal_constrained_agent/",
          "publishedOn": "2023-10-18T13:33:34.000Z",
          "wordCount": 2969,
          "title": "Autonomous Driving: Ellipsoidal Constrained Agent Navigation | Swaayatt Robots | Motion Planning Research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17amiju/dqn_agent_stuck_at_local_minima_probably/",
          "author": null,
          "description": "I'm attempting to address a Day Ahead Electricity Market bidding problem. The concept revolves around purchasing electricity during the lowest price hours and selling it during the highest price hours to maximize profit. I possess 5 years of data featuring variables such as predicted wind speed, predicted temperature, predicted net load, predicted price, and more. I'm employing reinforcement learning and have made attempts to implement Deep Q Learning using the stablebaselin3 library. Each episode consists of 24 steps, corresponding to the 24 hours in a day, with each step representing the progression to the next hour. The ultimate objective is to maximize profits by the end of the day.\n ​\n Here are the configuration settings:\n - Learning rate: 0.0001\n - Gamma: 1.0\n - Exploration start: 1.…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17amiju/dqn_agent_stuck_at_local_minima_probably/",
          "publishedOn": "2023-10-18T09:26:34.000Z",
          "wordCount": null,
          "title": "DQN Agent stuck at local Minima (Probably)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ahjo6/6dof_simulation_rl_capability/",
          "author": null,
          "description": "I have a 6DOF simulink model of a Autonomous underwater vehicle that has properties [u v w p q r x y z phi theta psi] and two inputs [theta1 theta2] that govern the angle of control surfaces. Ocean current and depth are taken into account. \n How feasible would it be to use RL to reach waypoints at various [x, y, z] positions? I have a feeling hyper paremeter tuning might play a larger role in this? I expect training times to increase exponentially as well? \n I have done this using a single randomly spawned waypoint with a simple Unicycle Kinematic model, in both simulink/matlab and python with a vectorized/parallel environment using SB3/PettingZoo/Gym.\n    submitted by    /u/VisionZUS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ahjo6/6dof_simulation_rl_capability/",
          "publishedOn": "2023-10-18T03:56:28.000Z",
          "wordCount": null,
          "title": "6DOF Simulation RL Capability",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17aflqu/recommended_seeding_approach_when/",
          "author": null,
          "description": "Dear all,\n As part of my studies, I am running some RL experiments in which I want to compare some different catastrophic forgetting approaches in sequential task learning. I am using PPO as a baseline. What is the usual experimental setting in relation to seeds used during training and evaluation? If I do for example 3 trainings for a given approach using a different seed for each training, what is the best way of doing the evaluation afterwards?\n Let's say I have Approach/algorithm A -> train 3 times with 3 seeds -> model_A1, model_A2, model_A3\n Then I would like to use 3 different seeds for the evaluation, so to evaluate each of the previously trained models over a set of episodes (deterministic) for each evaluation seed, and get averaged rewards (or median).\n I wonder whether I might be over complicating things, so I would like to ask you for suggestions. To give a bit of context, this is not intended for a paper, but as part of my master studies, so conditions are a bit more relaxed.\n Thanks in advance for your insights and suggestions\n    submitted by    /u/cotorritaloca80  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17aflqu/recommended_seeding_approach_when/",
          "publishedOn": "2023-10-18T02:15:57.000Z",
          "wordCount": null,
          "title": "Recommended 'seeding' approach when training/evaluating an experiment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17a0ds4/starc_a_general_framework_for_quantifying/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17a0ds4/starc_a_general_framework_for_quantifying/",
          "publishedOn": "2023-10-17T15:01:48.000Z",
          "wordCount": null,
          "title": "\"STARC: A General Framework For Quantifying Differences Between Reward Functions\", Skalse et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17a06ra/goodharts_law_in_reinforcement_learning_karwoski/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17a06ra/goodharts_law_in_reinforcement_learning_karwoski/",
          "publishedOn": "2023-10-17T14:53:02.000Z",
          "wordCount": null,
          "title": "\"Goodhart's Law in Reinforcement Learning\", Karwoski et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/179vtbg/dynamic_state_and_action_space/",
          "author": null,
          "description": "Hello, I’m working on a scenario that involves many systems and each system involves many subsystems. At each decision time and according to the system that requests the decision, the RL agent must select a subsystem. Nevertheless, each system has a different number of subsystems which makes the action space and the state space dynamic since the each neurone in the output represents a subsystem. Can I use the maximal number of subsystems (not the total number) as the number of the output and masking some neurones according to the current system ?\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/179vtbg/dynamic_state_and_action_space/",
          "publishedOn": "2023-10-17T11:05:37.000Z",
          "wordCount": null,
          "title": "Dynamic state and action space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/179p0gv/offline_rl_interpreting_policy/",
          "author": null,
          "description": "I am new to RL and have a naive question. How interpretable would the policy be from building a rl algorithm in an offline setting? Could I make inferences about what the optimal sequences would be?\n    submitted by    /u/kwsunshine123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/179p0gv/offline_rl_interpreting_policy/",
          "publishedOn": "2023-10-17T03:29:38.000Z",
          "wordCount": null,
          "title": "Offline rl- interpreting policy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/179k124/article_key_concepts_and_open_questions_in_a/",
          "author": null,
          "description": "submitted by    /u/Stanford_Online  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/179k124/article_key_concepts_and_open_questions_in_a/",
          "publishedOn": "2023-10-16T23:26:23.000Z",
          "wordCount": null,
          "title": "Article: Key Concepts and Open Questions in a Golden Age for Natural Language Understanding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17973ri/dexcatch_learning_to_catch_arbitrary_objects_with/",
          "author": null,
          "description": "🌟 Excited to share our recent research, DexCatch!\n Pick-and-place is slow and boring, while throw-catching is a behaviour towards more human-like manipulation.\n We propose a new model-free framework that can catch diverse objects of daily life with dexterous hands in the air. This ability to catch anything from a cup to a banana, and a pen, can help the hand quickly manipulate objects without transporting objects to their destination -- and even generalize to unseen objects. Video demonstrations of learned behaviors and the code can be found at https://dexcatch.github.io/.\n ​\n https://reddit.com/link/17973ri/video/i4xdo39d4lub1/player\n    submitted by    /u/Shengjie_Wang  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17973ri/dexcatch_learning_to_catch_arbitrary_objects_with/",
          "publishedOn": "2023-10-16T14:21:03.000Z",
          "wordCount": null,
          "title": "DexCatch: Learning to Catch Arbitrary Objects with Dexterous Hands",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1794m95/help_with_model_based_policy_optimization/",
          "author": null,
          "description": "I am reading this paper and came across the following paragraph - \n ​\n \"Model usage. Many recent model-based algorithms have focused on the setting in which model\n rollouts begin from the initial state distribution (Kurutach et al., 2018; Clavera et al., 2018). While\n this may be a more faithful interpretation of Algorithm 1, as it is optimizing a policy purely under\n the state distribution of the model, this approach entangles the model rollout length with the task\n horizon. Because compounding model errors make extended rollouts difficult, these works evaluate\n on truncated versions of benchmarks. The branching strategy described in Section 4.2, in which\n model rollouts begin from the state distribution of a different policy under the true environment\n dynamics, effectively relieves this limitation. In practice, branching replaces few long rollouts from\n the initial state distribution with many short rollouts starting from replay buffer states.\"\n ​\n  \nWhat does state distribtion mean over here?\n Also in line 8 of the image, I don't understand what's the relation between model rollout and policy \\pi_t. Is it saying, use the model free algorithm to take future steps from that state? What does the model have to do with that?\n \n ​\n https://preview.redd.it/twlej5my3kub1.png?width=1182&format=png&auto=webp&s=4a515c8d237c963052bc1b60a9e7dda53a33f001\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1794m95/help_with_model_based_policy_optimization/",
          "publishedOn": "2023-10-16T12:17:10.000Z",
          "wordCount": null,
          "title": "Help with Model Based Policy Optimization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/178ttjc/math_prerequisites_for_reinforcement_learning/",
          "author": null,
          "description": "hi all! \n i’m an undergraduate that is really interested in pursuing a PhD. i think reinforcement learning is especially interesting, causal reinforcement learning in particular. for my current research job, which unfortunately doesn’t really involve ML, i read a little about causal inference and it really intrigued me. \n what mathematics courses should i take to get into RL research at a theoretical/algorithmic level? i am currently taking proof-based linear algebra, and have taken all the computational calculus offered. i imagine prob. theory/math stats is pretty important, too; what else?\n    submitted by    /u/treeman0469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/178ttjc/math_prerequisites_for_reinforcement_learning/",
          "publishedOn": "2023-10-16T00:52:15.000Z",
          "wordCount": null,
          "title": "math prerequisites for reinforcement learning research?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/178ifk9/hi_everyone_i_was_following_an_online_rl_tutorial/",
          "author": null,
          "description": "I was following Nicholas Renotte's RL in 3 hours tutorial and I ran into this issue at time stamp 1:10:00 while testing my trained Agent.\n ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n This is my code for testing my environment:\n episodes=5 for episode in range(1,episodes+1): obs=env.reset() done=False score=0 print(obs) while not done: env.render() action, _ = model.predict(obs) #Now using model here obs, reward, done, truncated, info = env.step(action) score += reward print('Episode:{} Score:{}'.format(episode,score)) env.close() \n And this is the environment I am using :\n environment_name = 'CartPole-v1' env=gym.make(environment_name,render_mode=\"human\") \n the model variable has my trained model stored in it and is initialized as such :\n model =PPO.load(PPO_Path, env=env) \n The print(obs) function returns this value :\n (array([ 0.03954345, -0.04975226, -0.02942382, -0.02261402], dtype=float32), {}) \n I am running this code in a Notebook on VS code on an M2 Macbook running MacOS 13.5, I am using Python 3.9.15 and the latest version of all the other libraries and dependencies. Please help\n    submitted by    /u/Straight-Knowledge83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/178ifk9/hi_everyone_i_was_following_an_online_rl_tutorial/",
          "publishedOn": "2023-10-15T15:58:29.000Z",
          "wordCount": 2737,
          "title": "Hi everyone , I was following an online RL tutorial that uses Stable baselines3 and Open AI's gym to implement a Cart Pole environment but I have ran into some problems. Can anyone of you please help me?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/178hk80/reinforcement_learning_platform_for_uavs/",
          "author": null,
          "description": "I'm doing a project that aims to use reinforcement learning (PPO variations) with UAVs. What are the most up to date tools are for implementing and trying new RL algorithms in this space?\n I've looked at AirSim, and it seems to no longer be supported by Micrsosoft. I've also been heavily looking at Flightmare, which is almost exactly what I want, but getting the tool that hasn't been maintained for years up and running is giving me headaches (and the documentation is not great/up to date either).\n Ultimately, what I'm looking for is: * Physics simulation * Photo-realistic vision * Built-in integration with Gym would be awesome * Python platform preferred, C++ also ok\n I've also used ROS/Gazebo with PyTorch previously, and that is my backup plan I suppose, but it's not photo-realistic and is kind of slow in my experience.\n    submitted by    /u/zeus_the_transistor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/178hk80/reinforcement_learning_platform_for_uavs/",
          "publishedOn": "2023-10-15T15:16:21.000Z",
          "wordCount": 2667,
          "title": "Reinforcement Learning Platform for UAVs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/178doj5/training_a_rl_model_with_continuous_state_action/",
          "author": null,
          "description": "Hello everyone,\n I'm a Data Science student diving into an exciting thesis topic: using reinforcement learning to stabilize boats in rough seas by adjusting a keel's angle. But I am a bit concerned about the high complexity of the problem and the given situation: \n  \nAction Space: Continuous, representing the keel's angle adjustments.\n State Space: Continuous, capturing the dynamic behavior of the sea, including waves.\n Training Environment: Currently, the company only has a real-world water tank setup to simulate the sea conditions. There's no computer simulation available.\n  \nGiven this setup, I have a couple of concerns:\n  \nIs it possible to train an RL model effectively in such a complex real-world scenario without first having a computer simulation? And if yes, what would be your initial steps in doing so?\n Are there possibilities to reduce the problem's complexity while training exclusively in the real-world water tank simulation? (i.e. transforming the action space into a discrete action space?)\n  \nAny insights or advice would be greatly appreciated!\n    submitted by    /u/No-Wasabi3556  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/178doj5/training_a_rl_model_with_continuous_state_action/",
          "publishedOn": "2023-10-15T11:46:52.000Z",
          "wordCount": 2701,
          "title": "Training a RL Model with Continuous State & Action Space in a Real-World Scenario",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1786bec/supercharging_reinforcement_learning_with_logic/",
          "author": null,
          "description": "Deep reinforcement learning has led to a variety of compelling results. However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly. Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.\n ​\n https://preview.redd.it/6wmg0qnlaaub1.png?width=1786&format=png&auto=webp&s=01f82cf24de79b317b6f9406b0b6379b949a34d3\n We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).\n ​\n https://preview.redd.it/u8f44fskaaub1.png?width=1636&format=png&auto=webp&s=9509f03a936f41cd0131388564833b86a39c295a\n However, the benefits of our semantic proxy go well beyond performance. The use of temporal logic programming has two crucial beneficial by-products such as symbolic explainability and modularity. PyReason provides an explainable symbolic trace that captures the evolution of the environment in a precise manner while modularity allows us to add or remove aspects of the logic program – allowing for adjustments to the simulation based on a library of behaviors. PyReason is well-suited to model simulated environments for other reasons – namely the ability to directly capture non-Markovian relationships and the open-world nature (defaults are “uncertain” instead of true or false). We have demonstrated that agents can be trained using standard RL techniques such as DQN using this framework.\n Preprint: https://arxiv.org/abs/2310.06835\n Video: https://youtu.be/9e6ZHJEJzgw\n Code for PyReason-as-a-Sim (integration with DQN): https://github.com/lab-v2/pyreason-rl-sim\n Code for PyReason Gym: https://github.com/lab-v2/pyreason-gym\n PyReason Home: neurosymbolic.asu.edu/pyreason/\n ​\n    submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1786bec/supercharging_reinforcement_learning_with_logic/",
          "publishedOn": "2023-10-15T03:16:49.000Z",
          "wordCount": 2765,
          "title": "Supercharging reinforcement learning with logic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1785s73/actorcritic_on_piecewise_constant_reward_function/",
          "author": null,
          "description": "I made a environment with piece wise constant reward function for testing the network architecture. And its episode length is 1.\n The critic will try to learn this and become a piecewise constant function. And have a gradient close to 0 making the gradient vanish for the policy. \n I can think of some solutions: - Change the reward function to a dense reward\n But i wanted some other views; has anyone solved such problems?\n    submitted by    /u/Automatic-Web8429  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1785s73/actorcritic_on_piecewise_constant_reward_function/",
          "publishedOn": "2023-10-15T02:46:32.000Z",
          "wordCount": null,
          "title": "Actor-critic on piecewise constant reward function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1785h5n/help_understanding_the_pets_algorithm/",
          "author": null,
          "description": "I am trying to read this paper and I am unable to get the big picture over here. Can someone please explain what's going on in the Propagation and Planning stage? In the Model stage, I understand that they are using a Probabilistic Model to handle uncertainty.\n ​\n https://preview.redd.it/idenqd492aub1.png?width=945&format=png&auto=webp&s=40da9bf53b21dbed63b70571f3833b0fe3a9dabb\n For instance, what does Particle mean in this paper? \n This big picture here is that I am trying to understand the Model Based Policy Optimization paper and it seemed like they built upon the above paper. \n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1785h5n/help_understanding_the_pets_algorithm/",
          "publishedOn": "2023-10-15T02:29:49.000Z",
          "wordCount": null,
          "title": "Help understanding the PETS algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/177q2l0/pitfalls_of_learning_a_reward_function_online/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/177q2l0/pitfalls_of_learning_a_reward_function_online/",
          "publishedOn": "2023-10-14T13:53:36.000Z",
          "wordCount": null,
          "title": "\"Pitfalls of learning a reward function online\", Armstrong et al 2020 {DM}",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1770iav/introducing_ppo_and_rainbow_dqn_to_our_super_fast/",
          "author": null,
          "description": "Hi, we've just released a new version of AgileRL, our evolutionary hyperparameter optimisation framework built for RL that is 10x faster than SOTA.\n We've introduced PPO, Rainbow DQN, some sophisticated replay buffers, and also collaborated with the Farama Foundation to create some tutorials (more on the way).\n Please check it out and take it for a spin. We're also looking for contributors so get in touch if you would like to be involved!\n https://github.com/AgileRL/AgileRL\n    submitted by    /u/nicku_a  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1770iav/introducing_ppo_and_rainbow_dqn_to_our_super_fast/",
          "publishedOn": "2023-10-13T14:50:39.000Z",
          "wordCount": null,
          "title": "Introducing PPO and Rainbow DQN to our super fast evolutionary HPO reinforcement learning framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176zs5e/masking_state_transitions_in_policy_updates_for/",
          "author": null,
          "description": "I am currently dealing with an environment, that most of the time (90% of all state transitions) clips the action selected from the agent. Sometimes even down to the point where the action selected by the agent is completly ignored. \n This causes a lot of problems, because for example the entropy bonus does not works, since the agent learns to select any action, when it doesn't matter anyway but selects the same action (low entropy) when the actions have an effect. \n Using the PPO algorithm I was thinking of masking the state transitions in the policy updates, according to how much the action was clipped in the environment. And I thought V(s) should be masked, because it can still learn from the state transitions even if the action was effectively ignored by the environment. \n    submitted by    /u/flxh13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176zs5e/masking_state_transitions_in_policy_updates_for/",
          "publishedOn": "2023-10-13T14:16:57.000Z",
          "wordCount": null,
          "title": "Masking state transitions in policy updates for invalid actions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176zir9/a_question_about_deterministic_action_selection/",
          "author": null,
          "description": "I'm training some agents using fairly vanilla PPO on a hand-made environment. These agents learn to perform the task pretty well, but while I was examining their action probabilities during an evaluation episode, I had the idea to turn off deterministic action selection. \n To my surprise, allowing probabilistic action selection (as opposed to argmax action selection) actually improved performance in some cases. I had always thought that deterministic actions during evaluation was fairly standard, but now am thinking that maybe I missed something and that there are cases where you wouldn't want determinism?\n My question is: how common is it actually to use deterministic actions vs. probabilistic ones at evaluation time, and does anyone know of studies/papers/examples where the authors found probabilistic evaluation to outperform determinism?\n    submitted by    /u/Impallion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176zir9/a_question_about_deterministic_action_selection/",
          "publishedOn": "2023-10-13T14:04:30.000Z",
          "wordCount": null,
          "title": "A question about deterministic action selection at evaluation time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176wi8b/a_simple_openloop_baseline_for_reinforcement/",
          "author": null,
          "description": "submitted by    /u/atooo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176wi8b/a_simple_openloop_baseline_for_reinforcement/",
          "publishedOn": "2023-10-13T11:25:32.000Z",
          "wordCount": null,
          "title": "\"A Simple Open-Loop Baseline for Reinforcement Learning Locomotion Tasks\" Raffin et al. 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176w3eu/looking_for_some_advice_regarding_universal/",
          "author": null,
          "description": "Hey, \n So I am working on reinforcement learning package in C# (currently under heavy development):\n https://github.com/asieradzk/RL_Matrix \n My goal is to create something superior to unity's ML Agents for Godot to democratize access to reinforcement learning for people (without having them know what a tensor is)\n So far I've added some barebones DQN and PPO that (only output single discrete action) as proof of concept to test my code architecture. So I am going through the daunting task of having some universal workflow for setting up environments. For any shape observations and any count actions, both discrete and continuous. \n As I am finishing my multi-head multi-action output I've come to realise that there are many possible architectures I could setup multi head outputs, for instanc…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176w3eu/looking_for_some_advice_regarding_universal/",
          "publishedOn": "2023-10-13T11:00:11.000Z",
          "wordCount": null,
          "title": "Looking for some advice regarding universal multi-head outputs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176v8qb/next_state_in_turn_based_game/",
          "author": null,
          "description": "To my knowledge, when using the Q Learning family algorithm, we must know the next state as well as the action spaces in couple with that observation in order to evaluate the reward for the next state with the target network.\n But I have some problem when trying to define this next state in turn turn-based game in which the agent have to make a certain number of actions and then wait for the opponent to do some actions before it can interact with the environment again. We can take Hearthstone as an example that each player have to wait for other to play a number of cards before can take any action.\n Currently, I have two options for this: \n - Treat the environment right after the agent's turn ended, which will lack the action space.\n - Treat the environment just before the agent's turn begins, which will have all the actions available that it can choose from but this will make the agent's last action very noisy. That state could be a good state if the opponent playing badly or they are very good and make our last decision seem like a very bad choice. \n Thanks in advance for any suggestions. If my problem is a common task that others have already solved many times, I will be very thankful for that keyword.\n    submitted by    /u/No-Concentrate-6037  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176v8qb/next_state_in_turn_based_game/",
          "publishedOn": "2023-10-13T10:02:23.000Z",
          "wordCount": null,
          "title": "Next state in turn based game",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176n5iv/small_batch_deep_reinforcement_learning/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176n5iv/small_batch_deep_reinforcement_learning/",
          "publishedOn": "2023-10-13T01:28:58.000Z",
          "wordCount": null,
          "title": "\"Small batch deep reinforcement learning\", Obando-Ceron et al 2023 {DM} (value-based agents explore & regularize better with small n)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176amv1/deepmind_2022_full_accounts_financial_report_2022/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176amv1/deepmind_2022_full_accounts_financial_report_2022/",
          "publishedOn": "2023-10-12T16:10:00.000Z",
          "wordCount": null,
          "title": "DeepMind 2022 'full accounts' financial report: 2022 budget: £1,081 million ($1.3b) (decreased by a fifth from 2021)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176a3re/rl_for_nonpython_environments/",
          "author": null,
          "description": "Most real world applications for RL (robotics, game dev, finance) are in not normally done in Python, yet all major RL frameworks are written in Python. Is there a good/high-performance cross-language framework to do RL in other languages like C++/.Net/Java? If not, do you think people would be interested in such a framework?\n ​\n    submitted by    /u/xor24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176a3re/rl_for_nonpython_environments/",
          "publishedOn": "2023-10-12T15:47:23.000Z",
          "wordCount": null,
          "title": "RL for non-Python environments?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1769e0g/reinforcement_learning_agents_that_adhere_to_a/",
          "author": null,
          "description": "Do you know any work that tries to develop RL agents that exploit some sort of high-level model of the problem (it could also be given by an expert human) to learn faster or operate on out-of-distribution scenarios?\n I'm particularly interested in Causal Models, but any similar thing could be interesting for me\n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1769e0g/reinforcement_learning_agents_that_adhere_to_a/",
          "publishedOn": "2023-10-12T15:16:14.000Z",
          "wordCount": null,
          "title": "Reinforcement learning agents that adhere to a causal model of the problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1767v70/what_is_the_intuitive_explanation_for_using_log/",
          "author": null,
          "description": "submitted by    /u/aabra__ka__daabra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1767v70/what_is_the_intuitive_explanation_for_using_log/",
          "publishedOn": "2023-10-12T14:09:07.000Z",
          "wordCount": null,
          "title": "What is the intuitive explanation for using log probabilities in Policy gradient methods instead of simple probabilities? does it improve gradient descent optimization ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1763ixm/why_does_drqv2_sample_from_replay_by_episode_then/",
          "author": null,
          "description": "I've been looking at DrQ-v2 (https://github.com/facebookresearch/drqv2) recently and it samples from replay in a way that seems odd to me but may have a purpose I don't understand.\n They store experiences in a compressed file by episode, this makes some sense since it means they don't have to store everything in RAM and they delay disk writes until the end of the episode so they don't slow down the sim operation. \n On sampling, they randomly select an episode then randomly select an experience from the episode, calculating the n-step reward dynamically at sample time instead of at experience storage time. This is then fed to the model by a pytorch DataLoader. This means a _lot_ of disk reads during the optimization step which can't be ideal but I'll put that aside. \n What is the advantage of doing this selection by episode? It may give a better spread across episodes in each update, but I'm not sure that makes up for the potential downsides of making prioritization and other replay tricks much harder. Any ideas?\n    submitted by    /u/EDMismyO2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1763ixm/why_does_drqv2_sample_from_replay_by_episode_then/",
          "publishedOn": "2023-10-12T10:16:40.000Z",
          "wordCount": null,
          "title": "Why does Drq-v2 sample from replay by episode then experience?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/175utfv/can_reinforcement_learning_models_learn_to_rank/",
          "author": null,
          "description": "I have a very simple observation: a list of random value state = [random.uniform(-0.2, 0.2) for _ in range(200)]\n reward = state * actions . The reward is not using the next state, it's using the previous state i gave to the model.\n So basically i already give the answer to the model, the best action is : if state > 0 action =1, if state < 0 action = -1\n I tried using PPO, but it seem not learning at all.\n My test_env.py is here:\n ``` import gymnasium as gym import numpy as np from gymnasium import spaces from gymnasium.utils import seeding from stable_baselines3.common.vec_env import DummyVecEnv import random\n class TestEnv(gym.Env): \n metadata = {\"render.modes\": [\"human\"]} def __init__( self, item_count, test_steps, is_train = True, ): self.is_train = is_train self.test_steps = test_step…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/175utfv/can_reinforcement_learning_models_learn_to_rank/",
          "publishedOn": "2023-10-12T01:31:23.000Z",
          "wordCount": null,
          "title": "Can reinforcement learning models learn to rank?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/175898n/gain_and_bias_params_in_mujoco/",
          "author": null,
          "description": "Hi! I'm new to Mujoco and robot dynamics.\n When I read the Mujoco document, I'm confused about the gainprm and biasprm parameters. I want to understand the meaning of these parameters and tune the actuation speed of my actuator. An easy-to-understand explanation or supporting material would be appreciated. \n Thanks in advance.\n    submitted by    /u/UpperSearch4172  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/175898n/gain_and_bias_params_in_mujoco/",
          "publishedOn": "2023-10-11T07:27:54.000Z",
          "wordCount": null,
          "title": "Gain and bias params in Mujoco",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17557z7/loopquest_a_githublike_platform_to_host/",
          "author": null,
          "description": "Hello everyone! Here is my pet project, https://www.loopquest.ai/. I am trying to build a platform like Github to let people upload their simulation environments so people can train their AI agents by interacting with the environments created by others. Here is a 2-min demo, https://youtu.be/d53NFjkU7JA. It is not launched yet but would love to get some early feedbacks.\n Here is the corresponding Github repo https://github.com/LoopMind-AI/loopquest. For now, the package can log env-agent interaction data by adding one extra line of code. You can think of it similar to https://github.com/google-deepmind/envlogger but with much better backend and frontend support.\n Any feedbacks are appreciated :)\n    submitted by    /u/jxx123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17557z7/loopquest_a_githublike_platform_to_host/",
          "publishedOn": "2023-10-11T04:08:39.000Z",
          "wordCount": null,
          "title": "LoopQuest, A Github-like platform to host simulation environments for AI training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174vpzw/issue_with_mujoco_simulation_robot_penetrates_the/",
          "author": null,
          "description": "Hello everyone,\n I'm working on simulating a modified humanoid robot, \"DARwIn OP 3\", using MuJoCo through dm_control in Python. My goal is to train the model to ascend stairs rapidly but these are the first steps. However, I've encountered a problem where the robot appears to sink into the ground and is then ejected with significant force under specific conditions.\n ​\n https://reddit.com/link/174vpzw/video/u636vf49tftb1/player\n  \nEnvironment: MuJoCo via dm_control.\n Issue Description: When the robot falls and its feet move, it behaves as though one of its motors sinks into the floor.\n Attempts: I've tweaked contact parameters and ground properties with no luck. Interestingly, this doesn't occur in the standalone MuJoCo simulator.\n Visual Aid: I've attached a video to illustrate the problem…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174vpzw/issue_with_mujoco_simulation_robot_penetrates_the/",
          "publishedOn": "2023-10-10T20:46:50.000Z",
          "wordCount": null,
          "title": "Issue with MuJoCo Simulation: Robot Penetrates the Ground",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174u530/algorithms_for_average_reward_reinforcement/",
          "author": null,
          "description": "I see that discounted reward reinforcement learning has been extensively studied in the literature. However, the average reward metric receives less attention, and it looks like algorithms for this metric (R-learning, H-learning, SMART, etc.) are much less than the discount metric. Could you suggest any algorithms for average reward reinforcement learning for continuous/general state-action space?\n    submitted by    /u/S1gnature  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174u530/algorithms_for_average_reward_reinforcement/",
          "publishedOn": "2023-10-10T19:42:48.000Z",
          "wordCount": null,
          "title": "Algorithms for average reward reinforcement learning in continuous/general state-action space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174trnk/how_disney_packed_big_emotion_into_a_little_robot/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174trnk/how_disney_packed_big_emotion_into_a_little_robot/",
          "publishedOn": "2023-10-10T19:27:55.000Z",
          "wordCount": null,
          "title": "\"How Disney Packed Big Emotion Into a Little Robot\" (sim2real)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174ldr6/i_took_openais_paper_about_defeating_dota2_world/",
          "author": null,
          "description": "submitted by    /u/mngrwl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174ldr6/i_took_openais_paper_about_defeating_dota2_world/",
          "publishedOn": "2023-10-10T13:34:59.000Z",
          "wordCount": null,
          "title": "I took OpenAI's paper about defeating Dota2 world champions, and explained it paragraph-by-paragraph.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1747p76/whats_your_view_on_the_recent_rtx_effortsscaling/",
          "author": null,
          "description": "With recent RT-X efforts from Deepmind, it seems the community has been shifting towards the development of a more generalized foundational model, combining with visions and languages, and scaling via imitation learning. \n I know RL algorithms are expensive to train and hard to scale due to the way the samples are generated, but I am still fascinated by the intelligence behind their philosophies. What do you think the future would look like? Like NLP or CV, having a big foundational model pre-trained via IL, and fine-tune on different tasks via RL? How can we tell if a task is simple enough that we don't need to leverage the power of a foundational model?\n    submitted by    /u/Old_Reading_669  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1747p76/whats_your_view_on_the_recent_rtx_effortsscaling/",
          "publishedOn": "2023-10-10T00:27:16.000Z",
          "wordCount": null,
          "title": "What's your view on the recent RT-X efforts/scaling via IL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173u9fn/switching_off_a_specified_rotor_in_airsim/",
          "author": null,
          "description": "Hello Everyone,\n I am working on a project to train a Reinforcement Learning agent to recover a quadrotor after any of the rotor’s failures. I am using AirSim for my project, but I can’t find a way to adjust the quad-rotor so that only 3 of the four rotors are working. \n Any suggestions? I appreciate any help you can provide.\n    submitted by    /u/audaciouslion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173u9fn/switching_off_a_specified_rotor_in_airsim/",
          "publishedOn": "2023-10-09T15:11:51.000Z",
          "wordCount": null,
          "title": "Switching off a specified rotor in AirSim",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173hbka/i_trained_a_reinforcement_learning_agent_to_play/",
          "author": null,
          "description": "Hi all, over the last couple years I've been training a reinforcement learning agent to play pokemon red. I put together a video which analyzes the AI's learning, as well as documenting my process and quite a bit of technical details. Enjoy! \n Video:\n https://youtu.be/DcYLT37ImBY\n Code:\n https://github.com/PWhiddy/PokemonRedExperiments\n https://preview.redd.it/4dw3yasqb3tb1.jpg?width=1280&format=pjpg&auto=webp&s=bdef1aa0d24d75ab548f3944c558840667ff0ed5\n    submitted by    /u/Pwhids  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173hbka/i_trained_a_reinforcement_learning_agent_to_play/",
          "publishedOn": "2023-10-09T02:50:51.000Z",
          "wordCount": null,
          "title": "I trained a reinforcement learning agent to play pokemon red!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173fpzz/feature_importance_in_ray_rllib/",
          "author": null,
          "description": "I am training an RL agent using Ray RLlib. Does anyone know how I can find which features (observations) help the agent learn the policy? I found this: https://discuss.ray.io/t/feature-importance/10362/2, but I'd really appreciate if someone could expand on this a bit more. Thank you!\n    submitted by    /u/greenteabiitch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173fpzz/feature_importance_in_ray_rllib/",
          "publishedOn": "2023-10-09T01:30:55.000Z",
          "wordCount": null,
          "title": "Feature Importance in Ray RLlib",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173dkt0/my_first_multiagent_rl_model/",
          "author": null,
          "description": "Hey Reddit,\n I am new to reinforcement learning. I have sufficient knowledge on supervised learning, but I am yet to stumble onto a cheat sheet for RL and from what I can tell, my use case is less common. \n I'm reaching out to the community in hopes of getting guidance and assistance in cutting through the noise of redundant and irrelevant information so I can attempt to built a toy model to validate my use case. I am deeply grateful for any help in advance.\n ​\n From what I can tell, here are the conditions I need to work with for my use case.\n  \nI'm trying to train a simulator.\n This is a multi-agent problem, perhaps with more than 2 agents. Each agent is responding based on it's own state, the state of the other agent[s], and historical context.\n Both the action space and state space are highly dimensional and highly dynamic based on the dataset and all agents' decisions. I still haven't figured out how the feature engineering will work yet, but I assume (but PLEASE correct my ignorance) I will need a DNN architecture that is more complex than the average deep RL algorithm, and I have considering using CNNs as a component.\n At scale, the datasets can and will be very large, random, and dynamic.\n  \n​\n Note to reader: I am self-taught. If I stare at technical equations long enough and google for additional resources, I can figure out what I am looking at, but I am very comfortable with technical concepts being shared as if I was a 5 year old. \n    submitted by    /u/CoggFest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173dkt0/my_first_multiagent_rl_model/",
          "publishedOn": "2023-10-08T23:44:07.000Z",
          "wordCount": null,
          "title": "My First [Multi-Agent] RL model",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "RL News",
      "feedUrl": "https://www.getrevue.co/profile/seungjaeryanlee?format=rss",
      "siteUrl": "http://rlnews.ryanlee.ai/",
      "articles": []
    },
    {
      "title": "Damian Bogunowicz - dtransposed",
      "feedUrl": "https://dtransposed.github.io/feed.xml",
      "siteUrl": "http://dtransposed.github.io/",
      "articles": [
        {
          "id": "http://dtransposed.github.io/blog/2023/11/02/Remote-SWE/",
          "author": null,
          "description": "The original tweet by Sahil Lavingia\n\n\nSome time ago, I stumbled upon this amusing tweet from @shl. I love how true this statement is, although it feels very wrong to admit it. Let’s think about the day in the life of a software engineer:\nYou interact with people from all corners of the world.\nYou complete tasks on different online platforms (Slack, GitHub, VS Code, Google Docs, etc.).\nYou have a list of your main quests to complete (you can find them in your journ… Kanban board!)\nThere are also side-quests to take care of (“Hey Damian, could you take a look at this bug?”).\nSometimes you can gang up with your teammates to slay a big beast (“Hey, I have this nasty bug that I have been working on for the past few days. I know you have better knowledge of this particular part of the repositor…",
          "link": "http://dtransposed.github.io/blog/2023/11/02/Remote-SWE/",
          "publishedOn": "2023-11-02T00:00:00.000Z",
          "wordCount": 2363,
          "title": "A Video Game that Pays: Lessons Learned from Working Remotely",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Data Science Central",
      "feedUrl": "http://feeds.feedburner.com/FeaturedBlogPosts-DataScienceCentral?format=xml",
      "siteUrl": "https://www.datasciencecentral.com/",
      "articles": [
        {
          "id": "https://www.datasciencecentral.com/?p=63484",
          "author": "Bill Schmarzo",
          "description": "79.8% of organizations cite cultural barriers to data adoption, yet AI and data literacy rank at only 1.6% in the CDO’s list of priorities. I find the research from New Vantage Partners, headed by industry legends Tom Davenport and Randy Bean, incredibly valuable.  Their annual “Data and Analytics Leadership Annual Executive Survey” series delivers invaluable… Read More »Your Data-to-Value Journey Starts with AI and Data Literacy\nThe post Your Data-to-Value Journey Starts with AI and Data Literacy appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/your-data-to-value-journey-starts-with-ai-and-data-literacy/",
          "publishedOn": "2023-11-04T17:44:57.000Z",
          "wordCount": 6750,
          "title": "Your Data-to-Value Journey Starts with AI and Data Literacy",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/11/Slide1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63454",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 31 October 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-31-october-2023/",
          "publishedOn": "2023-10-31T18:36:10.000Z",
          "wordCount": 6065,
          "title": "DSC Weekly 31 October 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63455",
          "author": "Dr. Andy Drotos",
          "description": "From ensuring that mobile apps function smoothly to facilitating personalized recommendations and targeted ads, data engineering powers the digital experiences that have become part of many of our day-to-day lives. There is currently a major need for knowledgeable and skilled professionals to fill open data engineer roles. Do you have the skills and experience to… Read More »Data engineering career guide\nThe post Data engineering career guide appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-engineering-career-guide/",
          "publishedOn": "2023-10-31T18:01:44.000Z",
          "wordCount": 6266,
          "title": "Data engineering career guide",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/AdobeStock_540627415-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63416",
          "author": "Anastasia Molodoria",
          "description": "Virtual fitting room software with AR and AI is the next best alternative to physical stores. With many different kinds of virtual fitting room solutions on offer though, it can be hard to know which ones are the most feasible for your business. Let’s talk about the various approaches to developing such solutions.  Types of… Read More »Approaches to creating virtual fitting room software using AR and AI\nThe post Approaches to creating virtual fitting room software using AR and AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/approaches-to-creating-virtual-fitting-room-software-using-ar-and-ai/",
          "publishedOn": "2023-10-31T17:36:55.000Z",
          "wordCount": 6341,
          "title": "Approaches to creating virtual fitting room software using AR and AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/charlesdeluvio-FK81rxilUXg-unsplash.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63433",
          "author": "Alan Morrison",
          "description": "Back in 2015, Pedro Domingos of the University of Washington’s computer science department published The Master Algorithm. In the book, Domingos explored the possibility that one master algorithm could indeed rule them all. The main challenge, he said, was to bring the AI tribes together so that the strengths of the various approaches could be… Read More »How hybrid AI can help LLMs become more trustworthy\nThe post How hybrid AI can help LLMs become more trustworthy appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-hybrid-ai-can-help-llms-become-more-trustworthy/",
          "publishedOn": "2023-10-31T17:35:21.000Z",
          "wordCount": 6307,
          "title": "How hybrid AI can help LLMs become more trustworthy",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/team-spirit-2447163_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63450",
          "author": "Alice Huang",
          "description": "Introduction The financial world is on the cusp of a remarkable transformation, thanks to the integration of advanced AI models like GPT-4. In this article, we delve into the evolving landscape of Machine Learning (ML) in finance and explore the potential impact of these cutting-edge AI systems. The need for speed: Reacting to regime shifts… Read More »AGI Jesse and the future of finance\nThe post AGI Jesse and the future of finance appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/agi-jesse-and-the-future-of-finance/",
          "publishedOn": "2023-10-31T15:20:20.000Z",
          "wordCount": 5548,
          "title": "AGI Jesse and the future of finance",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/AdobeStock_577653739-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63446",
          "author": "Arshima Siddikee",
          "description": "AI chatbot technology has taken the world by storm. From assisting individuals with their content requirements to facilitating top-notch customer service for businesses, AI chatbot technology offers it all.  The technology has penetrated multiple prominent industries. And rightly so. AI chatbots provide customer insights that help businesses strategize their marketing and sales plans, ultimately driving… Read More »How AI chatbots are transforming the world?\nThe post How AI chatbots are transforming the world? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-ai-chatbots-are-transforming-the-world/",
          "publishedOn": "2023-10-31T15:15:55.000Z",
          "wordCount": 6532,
          "title": "How AI chatbots are transforming the world?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/image-11.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63442",
          "author": "Kannamangalam Chakaravarthi Lakshminarasimham",
          "description": "The modern digital ecosystem, buzzing with the chatter of data and algorithms, presents both promises and challenges. In this intricate web, generative artificial intelligence (GenAI) shines as a beacon of innovation. To harness this power, enterprises need more than just cutting-edge technology. They need a bridge between ambition and realization—a role aptly filled by… Read More »How technical program managers can build a robust Generative AI future\nThe post How technical program managers can build a robust Generative AI future appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-technical-program-managers-can-build-a-robust-generative-ai-future/",
          "publishedOn": "2023-10-31T15:09:12.000Z",
          "wordCount": 6290,
          "title": "How technical program managers can build a robust Generative AI future",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/AdobeStock_396137427-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63435",
          "author": "Tredence Analytics",
          "description": "Generative AI is revolutionizing our creative landscape, unlocking unprecedented possibilities. But at what cost? Dive into the ethical dilemmas of this transformative technology, exploring the fine line between innovation and ethical consideration.  2022 was a huge year for Generative AI. The release of DALL-E 2 in April showed the public the possibilities of text-to-image Gen… Read More »Generative AI ethics: Navigating the boundary between human and machine creativity\nThe post Generative AI ethics: Navigating the boundary between human and machine creativity appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-ethics-navigating-the-boundary-between-human-and-machine-creativity/",
          "publishedOn": "2023-10-31T15:00:27.000Z",
          "wordCount": 7049,
          "title": "Generative AI ethics: Navigating the boundary between human and machine creativity",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Generative-AI-Tredence-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63430",
          "author": "Alan Morrison",
          "description": "Two roads diverged in a wood, and I;I took the one less traveled by,And that has made all the difference. — Robert Frost At certain points in the evolution of enterprise artificial intelligence, there’s been a fork in the road. The road less traveled has suggested a different route to a more satisfying kind of… Read More »FAIR knowledge: The key precondition for trusted generative AI\nThe post FAIR knowledge: The key precondition for trusted generative AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/fair-knowledge-the-key-precondition-for-trusted-generative-ai/",
          "publishedOn": "2023-10-30T17:42:36.000Z",
          "wordCount": 6244,
          "title": "FAIR knowledge: The key precondition for trusted generative AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/road-7670240_1280-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63427",
          "author": "Evan Morris",
          "description": "Unlock Success in AI Adoption: Discover 6 Essential Tips for Business Leaders to Navigate Artificial Intelligence Integration Smoothly.\nThe post 6 tips to navigate AI adoption appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/6-tips-to-navigate-ai-adoption/",
          "publishedOn": "2023-10-30T17:12:00.000Z",
          "wordCount": 6223,
          "title": "6 tips to navigate AI adoption",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/pexels-fauxels-3184298.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63412",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 24 October 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-24-october-2023/",
          "publishedOn": "2023-10-24T19:58:44.000Z",
          "wordCount": 6187,
          "title": "DSC Weekly 24 October 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63372",
          "author": "Venkata Nori",
          "description": "Written by Venkata Nori and Kshitij Gopali. Introduction As technology is evolving, most companies in the world are adopting advanced mechanisms for their daily tasks of storing/updating data, project management & tracking, incident management, version control, etc. Periodically, these companies’ business stakeholders would want to extract and analyze the data to see how the business… Read More »Seamless integration of data from unconventional source systems into Business Intelligence using data science techniques\nThe post Seamless integration of data from unconventional source systems into Business Intelligence using data science techniques appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/seamless-integration-of-data-from-unconventional-source-systems-into-business-intelligence-using-data-science-techniques/",
          "publishedOn": "2023-10-24T16:45:26.000Z",
          "wordCount": 7441,
          "title": "Seamless integration of data from unconventional source systems into Business Intelligence using data science techniques",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Picture-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63366",
          "author": "Evan Morris",
          "description": "A recent interview by Medical Device Network with GlobalData medical analyst Alexandra Murdoch shares interesting insights into cybersecurity for medical devices.\nThe post How data science and medical device cybersecurity cross paths to protect patients and enhance healthcare appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-data-science-and-medical-device-cybersecurity-cross-paths-to-protect-patients-and-enhance-healthcare/",
          "publishedOn": "2023-10-24T16:02:02.000Z",
          "wordCount": 6523,
          "title": "How data science and medical device cybersecurity cross paths to protect patients and enhance healthcare",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/healthcare.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63396",
          "author": "Erika Balla",
          "description": "In the contemporary business landscape, where data is heralded as the new oil, Business Analytics has emerged as a pivotal domain, steering organizations towards informed decision-making and strategic planning. business analytics encompasses the utilization of data, statistical algorithms, and machine learning techniques to comprehend the business context, forecast future trends, and facilitate optimal decision-making. The… Read More »Skills required to excel in a business analytics career\nThe post Skills required to excel in a business analytics career appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/skills-required-to-excel-in-a-business-analytics-career/",
          "publishedOn": "2023-10-24T15:34:44.000Z",
          "wordCount": 6560,
          "title": "Skills required to excel in a business analytics career",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/img2-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63386",
          "author": "Yana Ihnatchyck",
          "description": "In an era where data drives decisions, GenAI emerges as a prodigy force in the realm of data analytics. According to Statista, LLM’s market size is expected to show an annual growth rate of 24%, resulting in a market volume of $207 bn by the end of 2030.  This cutting-edge technology, built on sophisticated algorithms… Read More »GenAI: The game-changer in data analytics\nThe post GenAI: The game-changer in data analytics appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/genai-the-game-changer-in-data-analytics/",
          "publishedOn": "2023-10-24T13:30:15.000Z",
          "wordCount": 6453,
          "title": "GenAI: The game-changer in data analytics",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/ai-software.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63389",
          "author": "Bill Schmarzo",
          "description": "I recently wrote the book “AI & Data Literacy: Empowering Citizens of Data Science” to help non-data scientists – which is most of the world – understand the risks associated with how companies capture and use your personal data to influence your viewing and buying habits… and even your political and societal beliefs.  And while… Read More »Grade School & Preteen AI & Data Literacy\nThe post Grade School & Preteen AI & Data Literacy appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/grade-school-preteen-ai-data-literacy/",
          "publishedOn": "2023-10-21T12:19:58.000Z",
          "wordCount": 6518,
          "title": "Grade School & Preteen AI & Data Literacy",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Slide1-6.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63364",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 17 October 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-17-october-2023/",
          "publishedOn": "2023-10-17T19:28:23.000Z",
          "wordCount": 5919,
          "title": "DSC Weekly 17 October 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63362",
          "author": "Michael Peres",
          "description": "In a recent podcast episode, Lex Freedman and Mark Zuckerberg convened in the Metaverse, where the digital realm intertwines with reality. Their astonishingly realistic interaction, while highlighting technological advancements, also prompted deeper contemplations. As the line between digital recreations and reality becomes increasingly blurred, it beckons questions about the definitions of identity and consciousness and… Read More »Uncharted digital landscapes and the quest for timeless identity\nThe post Uncharted digital landscapes and the quest for timeless identity appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/uncharted-digital-landscapes-and-the-quest-for-timeless-identity/",
          "publishedOn": "2023-10-17T19:09:16.000Z",
          "wordCount": 6558,
          "title": "Uncharted digital landscapes and the quest for timeless identity",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Mark-Zuckerberg-and-Lex-Fridman-on-Lex-Fridmans-recent-podcast.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63356",
          "author": "Kartik Gandhi, Dr. Suraj Pardeshi",
          "description": "Introduction to Internet of Things (IOT): Internet of Things (IoT) represents the fourth-generation technology that facilitates the connection and transformation of products into smart, intelligent and communicative entities. IoT has already established its footprint in various business verticals such as medical, heath care, automobile, and industrial applications. IoT empowers the collection, analysis, and transmission of… Read More »Internet Of Things (IOT):  Application In Hazardous Locations\nThe post Internet Of Things (IOT):  Application In Hazardous Locations appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/internet-of-things-iot-application-in-hazardous-locations/",
          "publishedOn": "2023-10-17T19:03:35.000Z",
          "wordCount": 6890,
          "title": "Internet Of Things (IOT):  Application In Hazardous Locations",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/AdobeStock_370505641-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63354",
          "author": "Jeremy Bowen",
          "description": "Long before passengers sit back, relax, and enjoy their flight, data has played a critical role in getting them to their seats. It has been a cornerstone of the aviation industry since the early days of air travel. Indeed, from the early 20th century, data was collected through manual processes such as pilots logging information… Read More »The digital evolution in aviation: how big data and analytics are transforming the industry\nThe post <strong>The digital evolution in aviation: how big data and analytics are transforming the industry</strong> appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-digital-evolution-in-aviation-how-big-data-and-analytics-are-transforming-the-industry/",
          "publishedOn": "2023-10-17T18:50:27.000Z",
          "wordCount": 5966,
          "title": "The digital evolution in aviation: how big data and analytics are transforming the industry",
          "imageUrl": null
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63347",
          "author": "Shanthababu Pandian",
          "description": "Introduction Hello AI&ML Engineers, as you all know, Artificial Intelligence (AI) and Machine Learning Engineering are the fastest growing fields, and almost all industries are adopting them to enhance and expedite their business decisions and needs; for the same, they are working on various aspects and preparing the data for the AIML platform with the help of SMEs… Read More »Explainable Artificial Intelligence (XAI) for AI & ML Engineers\nThe post Explainable Artificial Intelligence (XAI) for AI & ML Engineers appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/explainable-artificial-intelligence-xai-for-ai-ml-engineers/",
          "publishedOn": "2023-10-16T15:26:13.000Z",
          "wordCount": 6934,
          "title": "Explainable Artificial Intelligence (XAI) for AI & ML Engineers",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/14775XMI.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63348",
          "author": "Bill Schmarzo",
          "description": "The ability of Generative AI (GenAI) tools to deliver accurate and reliable outputs entirely depends on the accuracy and reliability of the data used to train the Large Language Models (LLMs) that power the GenAI tool. Unfortunately, the Law of GIGO – Garbage In, Garbage Out – threatens the widespread adoption of GenAI.  Whether generating… Read More »AI’s Kryptonite: Data Quality\nThe post AI’s Kryptonite: Data Quality appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ais-kryptonite-data-quality/",
          "publishedOn": "2023-10-14T18:53:32.000Z",
          "wordCount": 6730,
          "title": "AI’s Kryptonite: Data Quality",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Slide1-5.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63333",
          "author": "Ryan Williamson",
          "description": "Artificial Intelligence (AI) is emerging as a formidable force, revolutionizing how we conceive, create, and deliver software solutions. As technology advances at an unprecedented pace, the role of AI in this domain has become increasingly significant. It’s no longer just a buzzword; it’s a fundamental tool that promises to reshape the entire software development process.… Read More »Significance of AI in the development of software products\nThe post Significance of AI in the development of software products appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/significance-of-ai-in-the-development-of-software-products/",
          "publishedOn": "2023-10-13T17:35:00.000Z",
          "wordCount": 5838,
          "title": "Significance of AI in the development of software products",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Significance-of-AI-in-Development-of-Software-Products-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63341",
          "author": "Aileen Scott",
          "description": "Companies, more often, pay attention to automation and innovation over proficiency and productivity. However, firms can maintain a balance between both due to the extensive usage of AI and data science programs. Here are the stats that show the impact of AI and data science in diverse sectors: Applications of AI and data science have… Read More »Future of AI and data science – How to secure a bright career\nThe post Future of AI and data science – How to secure a bright career appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/future-of-ai-and-data-science-how-to-secure-a-bright-career/",
          "publishedOn": "2023-10-13T15:47:39.000Z",
          "wordCount": 6348,
          "title": "Future of AI and data science – How to secure a bright career",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Future-of-AI-and-Data-Science-How-to-Secure-A-Bright-Career.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63337",
          "author": "Roger Brown",
          "description": "The advent of generative AI is empowering everyone alike – organizations, small businesses, individuals, students, and medical professionals, to name a few. The last couple of years have been revolutionary for artificial intelligence innovation and transformation. How will 2024 shape up for AI, AI tools, and related professionals? Let’s analyze the trends that are most… Read More »12 Generative AI Trends to Watch Out for\nThe post 12 Generative AI Trends to Watch Out for appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/12-generative-ai-trends-to-watch-out-for/",
          "publishedOn": "2023-10-12T11:03:08.000Z",
          "wordCount": 6148,
          "title": "12 Generative AI Trends to Watch Out for",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/3-Month-for-2024-12-Generative-AI-Trends-to-Watch-Out-for.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63331",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 10 October 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-10-october-2023/",
          "publishedOn": "2023-10-10T18:50:24.000Z",
          "wordCount": 6038,
          "title": "DSC Weekly 10 October 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63034",
          "author": "Ovais Naseem",
          "description": "Introduction  In an era where data is often termed the ‘new oil,’ its security holds unparalleled importance for businesses across industries. With the proliferation of digital platforms, sharing business-critical information has become routine yet perilous. From financial records to customer data, organizations frequently exchange sensitive information that, if compromised, could have dire consequences. Given the… Read More »How to ensure data security when sharing business-critical information\nThe post How to ensure data security when sharing business-critical information appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-to-ensure-data-security-when-sharing-business-critical-information/",
          "publishedOn": "2023-10-10T18:12:57.000Z",
          "wordCount": 6274,
          "title": "How to ensure data security when sharing business-critical information",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/images.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63303",
          "author": "John Lee",
          "description": "Gartner predicts blockchain’s economic impact to reach $176 billion by 2025 and $3.1 trillion by 2030. The AI software market is expected to reach $134.8 billion by 2025. Blockchain and AI benefit businesses. AI models process data, extract insights, and make decisions. Blockchain ensures data integrity and trust among participants. Read on to discover the… Read More »How does combining blockchain and AI create new business opportunities?\nThe post How does combining blockchain and AI create new business opportunities? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-does-combining-blockchain-and-ai-create-new-business-opportunities/",
          "publishedOn": "2023-10-10T16:23:00.000Z",
          "wordCount": 6505,
          "title": "How does combining blockchain and AI create new business opportunities?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/blockchain.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63315",
          "author": "Erika Balla",
          "description": "In the contemporary digital landscape, data has emerged as a critical asset for organizations aiming to make informed decisions and foster innovation. Data analytics can unlock a treasure trove of insights, driving competitive advantage and operational excellence by leveraging the vast amounts of data generated every second. As a consequence, the demand for skilled professionals… Read More »Understanding the difference: Data analyst, data scientist, and data engineer\nThe post Understanding the difference: Data analyst, data scientist, and data engineer appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/understanding-the-difference-data-analyst-data-scientist-and-data-engineer/",
          "publishedOn": "2023-10-10T13:30:40.000Z",
          "wordCount": 7123,
          "title": "Understanding the difference: Data analyst, data scientist, and data engineer",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/1_iY8FOlPv0CJ3AOxQ7t8zHw.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63320",
          "author": "Bill Schmarzo",
          "description": "I’ve been in this industry for over 40 years (yes, I just started in the data and analytics industry when I was 11), and I have NEVER seen anything like Artificial Intelligence (AI) and Generative AI (GenAI) capture the attention of CEOs (and the dystopic fear of everyone else). Is AI a game-changer?  Definitely!  Will… Read More »11 Questions Every CEO Should Ask about AI / Generative AI\nThe post 11 Questions Every CEO Should Ask about AI / Generative AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/11-questions-every-ceo-should-ask-about-ai-generative-ai/",
          "publishedOn": "2023-10-10T11:44:54.000Z",
          "wordCount": 6813,
          "title": "11 Questions Every CEO Should Ask about AI / Generative AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Slide1-4.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63300",
          "author": "Evan Rogen",
          "description": "This cutting-edge area of AI focuses on building models that can create original material, including music, images, text, and even entire virtual worlds.\nThe post Revolutionizing business: A look at generative AI’s real-world impact appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/revolutionizing-business-a-look-at-generative-ais-real-world-impact/",
          "publishedOn": "2023-10-09T12:38:10.000Z",
          "wordCount": 6119,
          "title": "Revolutionizing business: A look at generative AI’s real-world impact",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Revolutionizing-Business-A-Look-at-Generative-AIs-Real-World-Impact.png"
        }
      ]
    },
    {
      "title": "John D. Cook",
      "feedUrl": "https://www.johndcook.com/blog/feed",
      "siteUrl": "https://www.johndcook.com/blog",
      "articles": [
        {
          "id": "https://www.johndcook.com/blog/?p=218078",
          "author": "John",
          "description": "There are many ways to describe the distance between two probability distributions. The previous two posts looked at using the p-norm to measure the difference between the PDFs and using Kullbach-Leibler divergence. Earth mover’s distance (EMD) is yet another approach. Imagine a probability distribution on ℝ² as a pile of dirt. Earth mover’s distance measures […]\nEarth mover’s distance first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/06/earth-movers-distance/",
          "publishedOn": "2023-11-06T14:56:56.000Z",
          "wordCount": 1625,
          "title": "Earth mover’s distance",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=217884",
          "author": "John",
          "description": "The previous post looked at the best approximation to a normal density by normal density with a different mean. Dan Piponi suggested in the comments that it would be good to look at the Kullback-Leibler (KL) divergence. The previous post looked at the difference from between two densities from an analytic perspective, solving the problem […]\nKL divergence from normal to normal first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/05/kl-divergence-normal/",
          "publishedOn": "2023-11-05T19:01:11.000Z",
          "wordCount": 1458,
          "title": "KL divergence from normal to normal",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=217702",
          "author": "John",
          "description": "In my previous post on approximating a logistic distribution with a normal distribution I accidentally said something about approximating a normal with a normal. Obviously the best approximation to a probability distribution is itself. As Norbert Wiener said “The best material model of a cat is another, or preferably the same, cat.” But this made […]\nNormal approximation to normal first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/04/normal-approximation-to-normal/",
          "publishedOn": "2023-11-04T23:01:08.000Z",
          "wordCount": 1470,
          "title": "Normal approximation to normal",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=217462",
          "author": "John",
          "description": "In a recent post I pointed out that a soliton, a solution to the KdV equation, looks a lot like a normal density for fixed x. As someone pointed out in the comments, one way to look at this is that the soliton is exactly proportional to the density of a logistic distribution, and it’s […]\nLogistic / Normal approximation first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/04/logistic-normal-approximation/",
          "publishedOn": "2023-11-04T11:30:08.000Z",
          "wordCount": 1905,
          "title": "Logistic / Normal approximation",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=217453",
          "author": "John",
          "description": "There are still tens of millions of fax machines still exist. My business line gets calls from modems and fax machines fairly often. Maybe my number is close to that of a fax machine. Fax machines and health care Fax machines are especially common in health care. I remember when I was working at MD […]\nFax machines in the 21st century first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/03/fax-machines/",
          "publishedOn": "2023-11-03T19:55:27.000Z",
          "wordCount": 1726,
          "title": "Fax machines in the 21st century",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=217420",
          "author": "John",
          "description": "I got an email from someone saying the RSS feed for this site stopped working. Anyone else having this problem? I subscribe to my RSS feed and it’s working fine for me. It may be that there are variations on the RSS feed, and the version I’m using works while the variation some others use […]\nBlog RSS feed first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/03/blog-rss-feed/",
          "publishedOn": "2023-11-03T15:58:59.000Z",
          "wordCount": 1580,
          "title": "Blog RSS feed",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=217405",
          "author": "John",
          "description": "Rarely does a nonlinear differential equation, especially a nonlinear partial differential equation, have a closed-form solution. But that is the case for the Korteweg–De Vries equation. (Technically I should say it’s rare for a naturally-occurring nonlinear differential equation to have a closed-form solution. You can always start with a solution and cook up a contrived […]\nSolitons and the KdV equation first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/03/solitons-and-the-kdv-equation/",
          "publishedOn": "2023-11-03T15:22:07.000Z",
          "wordCount": 1661,
          "title": "Solitons and the KdV equation",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=217050",
          "author": "John",
          "description": "The other day I saw an image of a large disk centered on Paris subjected to the Mercator projection. I was playing around in Mathematica and made similar images for different projections. Each image below is a disk of radius 4200 km centered on Paris (latitude 49°, longitude 2°). All images were produced with the […]\nA disk around Paris first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/01/a-disk-around-paris/",
          "publishedOn": "2023-11-02T01:31:32.000Z",
          "wordCount": 1367,
          "title": "A disk around Paris",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=216950",
          "author": "John",
          "description": "On June 29 this year I said on Twitter that companies would start avoiding AI to avoid regulation. I followed that up with an article Three advantages of non-AI models. The third advantage I listed was Statistical models are not subject to legislation hastily written in response to recent improvements in AI. The chances that […]\nUsing classical statistics to avoid regulatory burden first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/01/using-classical-statistics-to-avoid-regulatory-burden/",
          "publishedOn": "2023-11-01T16:14:12.000Z",
          "wordCount": 1640,
          "title": "Using classical statistics to avoid regulatory burden",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=216938",
          "author": "John",
          "description": "This week President Biden signed a long, technically detailed executive order that among other things requires the Secretary of Commerce to look into differential privacy. Within 365 days of the date of this order … the Secretary of Commerce … shall create guidelines for agencies to evaluate the efficacy of differential-privacy-guarantee protections, including for AI. […]\nExecutive order on differential privacy first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/01/executive-order-on-differential-privacy/",
          "publishedOn": "2023-11-01T15:03:01.000Z",
          "wordCount": 1933,
          "title": "Executive order on differential privacy",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=216914",
          "author": "John",
          "description": "Differential entropy is the continuous analog of Shannon entropy. Given a random variable X with density function fX, the differential entropy of X, denoted h(X), is defined as where the integration is over the support of fX. You may see differential entropy defined using logarithm to a different base, which changes h(X) by a constant […]\nDifferential entropy and privacy first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/11/01/differential-entropy-and-privacy/",
          "publishedOn": "2023-11-01T13:28:29.000Z",
          "wordCount": 1634,
          "title": "Differential entropy and privacy",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=216618",
          "author": "John",
          "description": "The square of a real-valued polynomial is clearly non-negative, and so the sum of the squares of polynomials is non-negative. What about the converse? Is a non-negative polynomial the sum of the squares of polynomials? For polynomials in one variable, yes. For polynomials in several variables, no. However, Emil Artin proved nearly a century ago […]\nPositive polynomials revisited first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/30/artin-theorem/",
          "publishedOn": "2023-10-31T01:17:45.000Z",
          "wordCount": 1450,
          "title": "Positive polynomials revisited",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=216606",
          "author": "John",
          "description": "Can you tell who someone is from their telephone number? That’s kinda the point of telephone numbers, to let you contact someone. And indeed telephone number is one the 18 identifiers under HIPAA Safe Harbor. But whether any piece of information allows you to identify someone depends on context. If you don’t have access to […]\nIdentifiers depend on context first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/30/identifiers/",
          "publishedOn": "2023-10-30T23:06:40.000Z",
          "wordCount": 1474,
          "title": "Identifiers depend on context",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=216335",
          "author": "John",
          "description": "I recently had to mark a bit of German text as German in an HTML file and I wondered whether the abbreviation might be GER for German, or DEU for deutsche. Turns out the answer is both, almost. The language abbreviations used for HTML microdata are given in ISO 639, and they come in three-letter […]\nCountry and language abbreviations first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/29/country-and-language-abbreviations/",
          "publishedOn": "2023-10-29T21:29:44.000Z",
          "wordCount": 1433,
          "title": "Country and language abbreviations",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=216039",
          "author": "John",
          "description": "It’s usually easier to show that a problem has a solution than to show that it does not have a solution. Analogy with prime numbers Showing that a number is prime amounts to saying that the problem of finding nontrivial factors has no solution. How could you convince a skeptic that a large number N is […]\nCertifying that a system of polynomial equations has no solution first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/28/certificate-of-infeasibility/",
          "publishedOn": "2023-10-28T13:59:03.000Z",
          "wordCount": 1756,
          "title": "Certifying that a system of polynomial equations has no solution",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=215850",
          "author": "John",
          "description": "A simple question sent me down a rabbit hole this morning: what is the time difference between Houston and London? At the moment the difference is six hours. But how will that change when Daylight Saving Time ends this year. Wait a minute, will Daylight Saving Time end this year? I wasn’t even sure whether […]\nTime difference first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/27/time-difference/",
          "publishedOn": "2023-10-27T13:04:05.000Z",
          "wordCount": 1808,
          "title": "Time difference",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=215216",
          "author": "John",
          "description": "A couple days ago I wrote about the likelihood of the better team winning a best-of-five or best-of-seven series. That is, if the probability of X winning a game against Y is p > ½, how likely is it that X will win a majority of 5 games or a majority of 7 games. This […]\nBest of N series first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/24/best-of-n-series-2/",
          "publishedOn": "2023-10-24T14:13:38.000Z",
          "wordCount": 1678,
          "title": "Best of N series",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=215197",
          "author": "John",
          "description": "I discovered the Space Rocket History Podcast a while back and listened to all the episodes on the Apollo program. I’m now listening to the episodes on Skylab as they come out. I came for Apollo; I stayed for Skylab. I would not have sought out the episodes on Skylab, and that would have been […]\nLessons from Skylab first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/24/skylab/",
          "publishedOn": "2023-10-24T13:08:45.000Z",
          "wordCount": 1752,
          "title": "Lessons from Skylab",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=215183",
          "author": "John",
          "description": "This post will compute the center of curvature for an object described in the previous post. In order to do that we first need to describe principle curvature and Gauss curvature, and we’ll throw in mean curvature while we’re at it. Let S be a surface sitting in three dimensional space. No need for more […]\nCurvature: principal, Gauss, and mean first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/24/curvature/",
          "publishedOn": "2023-10-24T11:44:01.000Z",
          "wordCount": 1670,
          "title": "Curvature: principal, Gauss, and mean",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=215107",
          "author": "John",
          "description": "One year ago I wrote about a variant of the squircle that is quantitatively close to the customary definition but that has nicer algebraic properties. That post used the term p-squircle for the usual squircle with equation where p > 2, and the term s-squircle for the variation with equation where s is between 0 […]\nAn algebraic superegg first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/23/an-algebraic-superegg/",
          "publishedOn": "2023-10-24T01:32:55.000Z",
          "wordCount": 1564,
          "title": "An algebraic superegg",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=215014",
          "author": "John",
          "description": "What is nonlinear algebra? Negations are tricky. They may be the largest source of bugs in database queries. You have to carefully think about what exactly are you negating. Any time you see “non-” attached to something, you have to ask what the context is in which the negation takes place. For example, if you […]\nNonlinear algebra first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/23/nonlinear-algebra/",
          "publishedOn": "2023-10-23T15:04:45.000Z",
          "wordCount": 1769,
          "title": "Nonlinear algebra",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=214834",
          "author": "John",
          "description": "Three weeks ago I wrote about supereggs, a shape popularized by Piet Hein. One aspect of supereggs that I did not address is their stability. Looking at the photo above, you could imagine that if you gave the object a slight nudge it would not fall over. Your intuition would be right: supereggs are stable. […]\nStability of a superegg first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/22/stability-of-a-superegg/",
          "publishedOn": "2023-10-22T20:55:45.000Z",
          "wordCount": 1837,
          "title": "Stability of a superegg",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=214825",
          "author": "John",
          "description": "Suppose that when Team X and Team Y play, the probability that X will win a single game is p and the probability that Y will win is q = 1 − p. What is the probability that X will win the majority of a series of N games for some odd number N? We know intuitively […]\nBest-of-five versus Best-of-seven first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/22/best-of-n-series/",
          "publishedOn": "2023-10-22T16:30:05.000Z",
          "wordCount": 1566,
          "title": "Best-of-five versus Best-of-seven",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=214424",
          "author": "John",
          "description": "The HIPAA Safe Harbor provision says that data can be considered deidentified if 18 kinds of data are removed or reported at low resolution. At the end of the list of 18 items, there is an extra category, sometimes informally called the 19th rule: The covered entity does not have actual knowledge that the information […]\nThe 19th rule of HIPAA Safe Harbor first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/20/hipaa-safe-harbor/",
          "publishedOn": "2023-10-20T11:59:58.000Z",
          "wordCount": 1586,
          "title": "The 19th rule of HIPAA Safe Harbor",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=214248",
          "author": "John",
          "description": "I saw a comment from Christos Argyropoulos on Twitter implying that there’s a good scientific community on Bluesky, so I went there and looked around a little bit. I have account, but I haven’t done much with it. I was surprised that a fair number of people had followed me on Bluesky even though I […]\nBluesky first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/18/bluesky/",
          "publishedOn": "2023-10-19T02:22:55.000Z",
          "wordCount": 1460,
          "title": "Bluesky",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=214059",
          "author": "John",
          "description": "The -i flag to ask sed to edit a file in place works differently on Linux and MacOS. If you want to create a backup of your file before you edit it, say with the extension .bak, then on Linux you would run sed -i.bak myfile but for the version of sed that ships with […]\nPortable sed -i across MacOS and Linux first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/18/portable-sed-i/",
          "publishedOn": "2023-10-18T12:00:25.000Z",
          "wordCount": 1895,
          "title": "Portable sed -i across MacOS and Linux",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=213816",
          "author": "John",
          "description": "From Love What Lasts, Joshua Gibbs: … there are too many things in the world to care equally about them all. The sheer volume of things … demands that we have hierarchical standards by which to judge their value, or else we are condemned to give our lives over entirely to what is nearest, easiest, […]\nNearest, easiest, and most accessible first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/16/nearest/",
          "publishedOn": "2023-10-16T13:06:04.000Z",
          "wordCount": 1321,
          "title": "Nearest, easiest, and most accessible",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=213692",
          "author": "John",
          "description": "Draw three circles of radius r that intersect at a single point. Then draw a triangle connecting the remaining three points of intersection. (Each pair of circles intersects in two points, one of which is the point where all three circles intersect, so there are three other intersection points.) Then the circumcircle of the triangle, […]\nJohnson circle theorem first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/15/johnson-circle-theorem/",
          "publishedOn": "2023-10-15T21:28:36.000Z",
          "wordCount": 1556,
          "title": "Johnson circle theorem",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=213505",
          "author": "John",
          "description": "Let Q be a convex quadrilateral with at most two parallel sides. Draw the two diagonals then draw a line through their midpoints. This line is called the Newton line. (The requirement that at most two sides are parallel insures that the midpoints are distinct and so there is a unique line joining them.) In […]\nNewton line first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/14/newton-line/",
          "publishedOn": "2023-10-14T13:32:45.000Z",
          "wordCount": 1440,
          "title": "Newton line",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=213221",
          "author": "John",
          "description": "This post is a follow-on to a discussion that started on Twitter yesterday. This tweet must have resonated with a lot of people because it’s had over 230,000 views so far. You almost have to study advanced math to solve basic math problems. Sometimes a high school student can solve a real world problem that […]\nHomework problems are rigged first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/12/homework-problems-are-rigged/",
          "publishedOn": "2023-10-12T14:19:56.000Z",
          "wordCount": 2095,
          "title": "Homework problems are rigged",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=213076",
          "author": "John",
          "description": "The last couple article have looked at various kinds of mean. The Python code for four of these means is trivial: gm = lambda a, b: (a*b)**0.5 am = lambda a, b: (a + b)/2 hm = lambda a, b: 2*a*b/(a+b) chm = lambda a, b: (a**2 + b**2)/(a + b) But the arithmetic-geometric mean […]\nPython code for means first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/11/python-agm/",
          "publishedOn": "2023-10-11T16:05:18.000Z",
          "wordCount": 1572,
          "title": "Python code for means",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212976",
          "author": "John",
          "description": "in an earlier post I said that the arithmetic mean of two frequencies an octave apart is an interval of a perfect fifth, and the geometric mean gives a tritone. This post will look at a few other means. Intervals The harmonic mean (HM) gives a perfect fourth. The arithmetic-geometric mean (AGM) gives a pitch […]\nMore ways of splitting the octave first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/octave-means/",
          "publishedOn": "2023-10-11T02:53:02.000Z",
          "wordCount": 1801,
          "title": "More ways of splitting the octave",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212960",
          "author": "John",
          "description": "This afternoon I wrote a brief post about Terence Tao’s new paper A Maclaurin type inequality. That paper builds on two classical inequalities: Newton’s inequality and Maclaurin’s inequality. The previous post expanded a bit on Newton’s inequality. This post will do the same for Maclaurin’s inequality. As before, let x be a list of real […]\nMaclaurin’s inequality first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/maclaurins-inequality/",
          "publishedOn": "2023-10-11T01:12:29.000Z",
          "wordCount": 1371,
          "title": "Maclaurin’s inequality",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212956",
          "author": "John",
          "description": "The previous post mentioned Newton’s inequality. This post will explore this inequality. Let x be a list of real numbers and define Sn(x) to be the average over all products of n elements from x. Newton’s inequality says that Sn−1 Sn+1 ≤ S²n In more terminology more recent than Newton, we say that the sequence […]\nNewton’s inequality and log concave sequences first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/newton-logconcave/",
          "publishedOn": "2023-10-11T00:54:38.000Z",
          "wordCount": 1442,
          "title": "Newton’s inequality and log concave sequences",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212924",
          "author": "John",
          "description": "Terence Tao has a new paper out that relates to a couple things I’ve written about recently. Elementary symmetric polynomials came up when developing the general equations for tangent sum and hyperbolic tangent sum. The latter post goes into more detail. Before that, means of symmetric functions, not necessarily elementary polynomials or even polynomials, came up […]\nU statistics and a new paper by Terence Tao first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/statistics-and-tao/",
          "publishedOn": "2023-10-10T19:10:57.000Z",
          "wordCount": 1417,
          "title": "U statistics and a new paper by Terence Tao",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212884",
          "author": "John",
          "description": "The latest episode of Erik Seligman’s podcast is entitled The Grim State of Modern Pizza. Although you might not realize it from the title, the post is about fraud detection. GRIM stands for Granularity-Related Inconsistency of Means. In a nutshell, the test looks for means (averages) that are not possible on number theoretic grounds. If […]\nDetecting fraud with the GRIM test first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/grim-test/",
          "publishedOn": "2023-10-10T14:51:10.000Z",
          "wordCount": 1557,
          "title": "Detecting fraud with the GRIM test",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212860",
          "author": "John",
          "description": "A few weeks ago I wrote about how the dissonance of a musical interval is related to the complexity of the frequency ratio as a fraction, where complexity is measured by the sum of the numerator and denominator. Consonant intervals have simple frequency ratios and dissonant intervals have complex frequency ratios. By this measure, the […]\nTritone first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/tritone/",
          "publishedOn": "2023-10-10T13:42:14.000Z",
          "wordCount": 1784,
          "title": "Tritone",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212781",
          "author": "John",
          "description": "The relation between a function and its power series is subtle. In a calculus class you’ll see equations of the form “series = function” which may need some footnotes. Maybe the series only represents the function over part of its domain: the function extends further than the power series representation. Starting with the power series, […]\nWhen a function cannot be extended first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/09/when-a-function-cannot-be-extended/",
          "publishedOn": "2023-10-10T01:23:50.000Z",
          "wordCount": 1609,
          "title": "When a function cannot be extended",
          "imageUrl": null
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}