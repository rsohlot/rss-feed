{
  "sources": [
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Blog",
      "feedUrl": "http://machinelearningmastery.com/blog/feed",
      "siteUrl": "https://machinelearningmastery.com/blog/",
      "articles": [
        {
          "id": "https://machinelearningmastery.com/?p=14330",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "The gradient descent algorithm is one of the most popular techniques for training deep neural networks. It has many applications in fields such as computer vision, speech recognition, and natural language processing. While the idea of gradient descent has been around for decades, it’s only recently that it’s been applied to applications related to deep […]\nThe post Implementing Gradient Descent in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/implementing-gradient-descent-in-pytorch/",
          "publishedOn": "2022-11-26T20:28:14.000Z",
          "wordCount": 7592,
          "title": "Implementing Gradient Descent in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/michael-behrens-DA-iYgv8kjE-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14318",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a simple yet powerful technique for predicting the values of variables based on other variables. It is often used for modeling relationships between two or more continuous variables, such as the relationship between income and age, or the relationship between weight and height. Likewise, linear regression can be used to predict continuous […]\nThe post Training a Linear Regression Model in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/training-a-linear-regression-model-in-pytorch/",
          "publishedOn": "2022-11-24T17:24:24.000Z",
          "wordCount": 7119,
          "title": "Training a Linear Regression Model in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/ryan-tasto-chbXE4o0ryU-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14311",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a statistical technique for estimating the relationship between two variables. A simple example of linear regression is to predict the height of someone based on the square root of the person’s weight (that’s what BMI is based on). To do this, we need to find the slope and intercept of the line. […]\nThe post Making Linear Predictions in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/making-linear-predictions-in-pytorch/",
          "publishedOn": "2022-11-24T04:11:30.000Z",
          "wordCount": 6417,
          "title": "Making Linear Predictions in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/daryan-shamkhali-pMCbPPPBSkA-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14301",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Structuring the data pipeline in a way that it can be effortlessly linked to your deep learning model is an important aspect of any deep learning-based system. PyTorch packs everything to do just that. While in the previous tutorial, we used simple datasets, we’ll need to work with larger datasets in real world scenarios in […]\nThe post Loading and Providing Datasets in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/loading-and-providing-datasets-in-pytorch/",
          "publishedOn": "2022-11-19T01:57:22.000Z",
          "wordCount": 5933,
          "title": "Loading and Providing Datasets in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/uriel-sc-11KDtiUWRq4-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14298",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "In machine learning and deep learning problems, a lot of effort goes into preparing the data. Data is usually messy and needs to be preprocessed before it can be used for training a model. If the data is not prepared correctly, the model won’t be able to generalize well. Some of the common steps required […]\nThe post Using Dataset Classes in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/using-dataset-classes-in-pytorch/",
          "publishedOn": "2022-11-17T01:55:54.000Z",
          "wordCount": 6445,
          "title": "Using Dataset Classes in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/nasa-1lfI7wkGWZ4-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13195",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Derivatives are one of the most fundamental concepts in calculus. They describe how changes in the variable inputs affect the function outputs. The objective of this article is to provide a high-level introduction to calculating derivatives in PyTorch for those who are new to the framework. PyTorch offers a convenient way to calculate derivatives for […]\nThe post Calculating Derivatives in PyTorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/calculating-derivatives-in-pytorch/",
          "publishedOn": "2022-11-11T21:30:18.000Z",
          "wordCount": 6011,
          "title": "Calculating Derivatives in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/jossuha-theophile-H-CZjCQfsFw-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13183",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Two-dimensional tensors are analogous to two-dimensional metrics. Like a two-dimensional metric, a two-dimensional tensor also has $n$ number of rows and columns. Let’s take a gray-scale image as an example, which is a two-dimensional matrix of numeric values, commonly known as pixels. Ranging from ‘0’ to ‘255’, each number represents a pixel intensity value. Here, […]\nThe post Two-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/two-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-09T21:30:51.000Z",
          "wordCount": 6286,
          "title": "Two-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/dylan-nolte-NIrgENd0sAY-unsplash-scaled.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13157",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "PyTorch is an open-source deep learning framework based on Python language. It allows you to build, train, and deploy deep learning models, offering a lot of versatility and efficiency. PyTorch is primarily focused on tensor operations while a tensor can be a number, matrix, or a multi-dimensional array. In this tutorial, we will perform some […]\nThe post One-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/one-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-07T21:30:13.000Z",
          "wordCount": 6633,
          "title": "One-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2021/12/jo-szczepanska-9OKGEVJiTKk-unsplash.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14064",
          "author": "MLM Team",
          "description": "Sponsored Post   The unlimited access initiative presents a risk-free way to break into data science.     The online educational platform 365 Data Science launches the #21DaysFREE campaign and provides 100% free unlimited access to all content for three weeks. From November 1 to 21, you can take courses from renowned instructors and earn […]\nThe post 365 Data Science courses free until November 21 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/365-data-science-courses-free-until-november-21/",
          "publishedOn": "2022-11-02T15:50:51.000Z",
          "wordCount": 4628,
          "title": "365 Data Science courses free until November 21",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/mlm-365ds-20221102-1.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14006",
          "author": "MLM Team",
          "description": "Sponsored Post      Attend the Data Science Symposium 2022 on November 8 The Center for Business Analytics at the University of Cincinnati will present its annual Data Science Symposium 2022 on November 8. This all day in-person event will have three featured speakers and two tech talk tracks with four concurrent presentations in each track. The […]\nThe post Attend the Data Science Symposium 2022, November 8 in Cincinnati appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/uccsb-data-science-symposium-2022-cincinnati/",
          "publishedOn": "2022-11-01T15:16:00.000Z",
          "wordCount": 3115,
          "title": "Attend the Data Science Symposium 2022, November 8 in Cincinnati",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/10/mlm-uccsb-221018.png"
        }
      ]
    },
    {
      "title": "Machine Learning Archives - Uber Engineering Blog",
      "feedUrl": "https://eng.uber.com/tag/machine-learning/feed",
      "siteUrl": null,
      "articles": []
    },
    {
      "title": "AWS Machine Learning Blog",
      "feedUrl": "https://aws.amazon.com/blogs/machine-learning/feed",
      "siteUrl": "https://aws.amazon.com/blogs/machine-learning/",
      "articles": [
        {
          "id": "e69d903525d682df7cd9db492b9f19e0a55ed94f",
          "author": "Channa Basavaraja",
          "description": "Amazon Kendra is an intelligent search service powered by machine learning (ML). Amazon Kendra helps you easily aggregate content from a variety of content repositories into a centralized index that lets you quickly search all your enterprise data and find the most accurate answer. Drupal is a content management software. It’s used to make many […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/intelligently-search-drupal-content-using-amazon-kendra/",
          "publishedOn": "2023-10-26T17:37:27.000Z",
          "wordCount": 2167,
          "title": "Intelligently search Drupal content using Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/20/ml-13088-image003-1178x630.jpg"
        },
        {
          "id": "2e1abf2525294fbbdf909a4f84dbb71855ec6e2d",
          "author": "Jose Benitez",
          "description": "This is a guest post by Jose Benitez, Founder and Director of AI and Mattias Ponchon, Head of Infrastructure at Intuitivo. Intuitivo, a pioneer in retail innovation, is revolutionizing shopping with its cloud-based AI and machine learning (AI/ML) transactional processing system. This groundbreaking technology enables us to operate millions of autonomous points of purchase (A-POPs) […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/intuitivo-achieves-higher-throughput-while-saving-on-ai-ml-costs-using-aws-inferentia-and-pytorch/",
          "publishedOn": "2023-10-26T17:23:19.000Z",
          "wordCount": 2503,
          "title": "Intuitivo achieves higher throughput while saving on AI/ML costs using AWS Inferentia and PyTorch",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/23/ML15012_APop-842x630.png"
        },
        {
          "id": "014c2ae344a6ff50cb497774092856a4b918278d",
          "author": "Davide Gallitelli",
          "description": "Enterprises seek to harness the potential of Machine Learning (ML) to solve complex problems and improve outcomes. Until recently, building and deploying ML models required deep levels of technical and coding skills, including tuning ML models and maintaining operational pipelines. Since its introduction in 2021, Amazon SageMaker Canvas has enabled business analysts to build, deploy, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/empower-your-business-users-to-extract-insights-from-company-documents-using-amazon-sagemaker-canvas-generative-ai/",
          "publishedOn": "2023-10-26T17:16:42.000Z",
          "wordCount": 2428,
          "title": "Empower your business users to extract insights from company documents using Amazon SageMaker Canvas Generative AI",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/24/ML-15763-image017-971x630.png"
        },
        {
          "id": "d17f5048164c69bf3e9133fa165254ce0437b6e5",
          "author": "Karsten Schroer",
          "description": "Methane (CH4) is a major anthropogenic greenhouse gas that‘s a by-product of oil and gas extraction, coal mining, large-scale animal farming, and waste disposal, among other sources. The global warming potential of CH4 is 86 times that of CO2 and the Intergovernmental Panel on Climate Change (IPCC) estimates that methane is responsible for 30 percent of observed […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/detection-and-high-frequency-monitoring-of-methane-emission-point-sources-using-amazon-sagemaker-geospatial-capabilities/",
          "publishedOn": "2023-10-25T18:46:52.000Z",
          "wordCount": 3732,
          "title": "Detection and high-frequency monitoring of methane emission point sources using Amazon SageMaker geospatial capabilities",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/04/ML-15188-figure-01-1260x560.jpg"
        },
        {
          "id": "fd38fb1f95610e27afc699bd48fa09b6963a4838",
          "author": "Sonali Sahu",
          "description": "In today’s information age, the vast volumes of data housed in countless documents present both a challenge and an opportunity for businesses. Traditional document processing methods often fall short in efficiency and accuracy, leaving room for innovation, cost-efficiency, and optimizations. Document processing has witnessed significant advancements with the advent of Intelligent Document Processing (IDP). With […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/intelligent-document-processing-with-amazon-textract-amazon-bedrock-and-langchain/",
          "publishedOn": "2023-10-24T20:52:03.000Z",
          "wordCount": 5862,
          "title": "Intelligent document processing with Amazon Textract, Amazon Bedrock, and LangChain",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/13/map-reduce-workflow-1260x604.png"
        },
        {
          "id": "965b9ff827f2e9047ee6f03512dd20912d159d0d",
          "author": "Dhurjati Brahma",
          "description": "This post is co-authored by Dhurjati Brahma, Senior Systems Architect at T-Mobile US, Inc and Jim Chao, Principal Engineer/Architect at T-Mobile US, Inc and Nicholas Zellerhoff Associate Systems Architect at T-Mobile US, Inc. T-Mobile US, Inc. provides a Voicemail to Text service to its customers, which allows customers to quickly read through their voicemails and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/t-mobile-us-inc-uses-artificial-intelligence-through-amazon-transcribe-and-amazon-translate-to-deliver-voicemail-in-the-language-of-their-customers-choice/",
          "publishedOn": "2023-10-24T16:23:59.000Z",
          "wordCount": 1967,
          "title": "T-Mobile US, Inc. uses artificial intelligence through Amazon Transcribe and Amazon Translate to deliver voicemail in the language of their customers’ choice",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/24/t-mobile-voicemail.jpg"
        },
        {
          "id": "e7bb51c56e2e2b1bbfe9df22a65d3e21c6de66f4",
          "author": "Yi Xiang",
          "description": "This post is co-authored by Anatoly Khomenko, Machine Learning Engineer, and Abdenour Bezzouh, Chief Technology Officer at Talent.com. Founded in 2011, Talent.com is one of the world’s largest sources of employment. The company combines paid job listings from their clients with public job listings into a single searchable platform. With over 30 million jobs listed […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/from-text-to-dream-job-building-an-nlp-based-job-recommender-at-talent-com-with-amazon-sagemaker/",
          "publishedOn": "2023-10-23T21:33:28.000Z",
          "wordCount": 3634,
          "title": "From text to dream job: Building an NLP-based job recommender at Talent.com with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/16/ml-14927-image001-1260x422.png"
        },
        {
          "id": "16591370cdafab2fc7272925545c0644a06d6e27",
          "author": "Ram Vittal",
          "description": "Customers of every size and industry are innovating on AWS by infusing machine learning (ML) into their products and services. Recent developments in generative AI models have further sped up the need of ML adoption across industries. However, implementing security, data privacy, and governance controls are still key challenges faced by customers when implementing ML […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/governing-the-ml-lifecycle-at-scale-part-1-a-framework-for-architecting-ml-workloads-using-amazon-sagemaker/",
          "publishedOn": "2023-10-20T17:30:59.000Z",
          "wordCount": 4812,
          "title": "Governing the ML lifecycle at scale, Part 1: A framework for architecting ML workloads using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/05/image001-1146x630.png"
        },
        {
          "id": "d7d157d3ca5e8424ebdb05083c4fd8ecb5fd56f1",
          "author": "Utkarsh Agrawal",
          "description": "This is a guest post co-written by Rama Badrinath, Divay Jindal and Utkarsh Agrawal at Meesho. Meesho is India’s fastest growing ecommerce company with a mission to democratize internet commerce for everyone and make it accessible to the next billion users of India. Meesho was founded in 2015 and today focuses on buyers and sellers […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-meesho-built-a-generalized-feed-ranker-using-amazon-sagemaker-inference/",
          "publishedOn": "2023-10-20T17:18:26.000Z",
          "wordCount": 1943,
          "title": "How Meesho built a generalized feed ranker using Amazon SageMaker inference",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/20/meesho-sagemaker-1260x628.jpg"
        },
        {
          "id": "e2bcf4362e7e60f9963cf8751678af424ead1e3c",
          "author": "Lana Zhang",
          "description": "Companies increasingly rely on user-generated images and videos for engagement. From ecommerce platforms encouraging customers to share product images to social media companies promoting user-generated videos and images, using user content for engagement is a powerful strategy. However, it can be challenging to ensure that this user-generated content is consistent with your policies and fosters […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/announcing-rekogniton-custom-moderation-enhance-accuracy-of-pre-trained-rekognition-moderation-models-with-your-data/",
          "publishedOn": "2023-10-19T22:47:25.000Z",
          "wordCount": 2245,
          "title": "Announcing Rekogniton Custom Moderation: Enhance accuracy of pre-trained Rekognition moderation models with your data",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/18/ml-15641-6-1.png"
        },
        {
          "id": "6882dcd3f5ffd98e092fa93530aab539a7a7fb6b",
          "author": "Andreas Karagounis",
          "description": "High-resolution imagery is very prevalent in today’s world, from satellite imagery to drones and DLSR cameras. From this imagery, we can capture damage due to natural disasters, anomalies in manufacturing equipment, or very small defects such as defects on printed circuit boards (PCBs) or semiconductors. Building anomaly detection models using high-resolution imagery can be challenging […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/defect-detection-in-high-resolution-imagery-using-two-stage-amazon-rekognition-custom-labels-models/",
          "publishedOn": "2023-10-19T18:00:36.000Z",
          "wordCount": 2371,
          "title": "Defect detection in high-resolution imagery using two-stage Amazon Rekognition Custom Labels models",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/19/high-resolution-two-stage-1260x630.jpg"
        },
        {
          "id": "a6c178033994ad61e906ed8ad00ff93d8abd0468",
          "author": "Tricia Jamison",
          "description": "Customers increasingly want to use deep learning approaches such as large language models (LLMs) to automate the extraction of data and insights. For many industries, data that is useful for machine learning (ML) may contain personally identifiable information (PII). To ensure customer privacy and maintain regulatory compliance while training, fine-tuning, and using deep learning models, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automatically-redact-pii-for-machine-learning-using-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2023-10-19T16:57:49.000Z",
          "wordCount": 3517,
          "title": "Automatically redact PII for machine learning using Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/11/sagemaker-pipelines.png"
        },
        {
          "id": "054b1f9ced560f2b18481d3f8fa07562e572850a",
          "author": "Mason Cahill",
          "description": "Purina US, a subsidiary of Nestlé, has a long history of enabling people to more easily adopt pets through Petfinder, a digital marketplace of over 11,000 animal shelters and rescue groups across the US, Canada, and Mexico. As the leading pet adoption platform, Petfinder has helped millions of pets find their forever homes. Purina consistently […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/optimize-pet-profiles-for-purinas-petfinder-application-using-amazon-rekognition-custom-labels-and-aws-step-functions/",
          "publishedOn": "2023-10-18T16:00:44.000Z",
          "wordCount": 2587,
          "title": "Optimize pet profiles for Purina’s Petfinder application using Amazon Rekognition Custom Labels and AWS Step Functions",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/18/petfinder-dogs.jpg"
        },
        {
          "id": "c8e8335028a2065122b24ebf754e06211ef2b0cd",
          "author": "Burak Gozluklu",
          "description": "Amazon Pharmacy is a full-service pharmacy on Amazon.com that offers transparent pricing, clinical and customer support, and free delivery right to your door. Customer care agents play a crucial role in quickly and accurately retrieving information related to pharmacy information, including prescription clarifications and transfer status, order and dispensing details, and patient profile information, in […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/learn-how-amazon-pharmacy-created-their-llm-based-chat-bot-using-amazon-sagemaker/",
          "publishedOn": "2023-10-17T19:43:52.000Z",
          "wordCount": 2541,
          "title": "Learn how Amazon Pharmacy created their LLM-based chat-bot using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/17/ML-15416-pic4-arch-1-1170x630.png"
        },
        {
          "id": "a4918b4d88c3b09b68431e6a485c20ca9f74cc02",
          "author": "Hao Huang",
          "description": "At Amazon Web Services (AWS), not only are we passionate about providing customers with a variety of comprehensive technical solutions, but we’re also keen on deeply understanding our customers’ business processes. We adopt a third-party perspective and objective judgment to help customers sort out their value propositions, collect pain points, propose appropriate solutions, and create […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/keeping-an-eye-on-your-cattle-using-ai-technology/",
          "publishedOn": "2023-10-17T19:40:30.000Z",
          "wordCount": 4903,
          "title": "Keeping an eye on your cattle using AI technology",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/07/process.png"
        },
        {
          "id": "20d350c5be42ba78896aab8753d9e03ddb68e2a4",
          "author": "Shreeya Sharma",
          "description": "Amazon Personalize has launched a new integration with Amazon OpenSearch Service that enables you to personalize search results for each user and assists in predicting their search needs. The Amazon Personalize Search Ranking plugin within OpenSearch Service allows you to improve the end-user engagement and conversion from your website and app search by taking advantage […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/personalize-your-search-results-with-amazon-personalize-and-amazon-opensearch-service-integration/",
          "publishedOn": "2023-10-17T19:33:03.000Z",
          "wordCount": 1972,
          "title": "Personalize your search results with Amazon Personalize and Amazon OpenSearch Service integration",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/17/personalize-personalize.jpg"
        },
        {
          "id": "d7275290cb2b3aafe167dc7e96c44fc8f137a4ac",
          "author": "Ricard Borràs",
          "description": "Veriff is an identity verification platform partner for innovative growth-driven organizations, including pioneers in financial services, FinTech, crypto, gaming, mobility, and online marketplaces. In this post, we show you how Veriff standardized their model deployment workflow using Amazon SageMaker, reducing costs and development time.",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-veriff-decreased-deployment-time-by-80-using-amazon-sagemaker-multi-model-endpoints/",
          "publishedOn": "2023-10-16T19:30:47.000Z",
          "wordCount": 2516,
          "title": "How Veriff decreased deployment time by 80% using Amazon SageMaker multi-model endpoints",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/10/MLBLOG64069-im01-1260x532.png"
        },
        {
          "id": "26f6bce232483d6777c2e86268fa4b4222390aab",
          "author": "Abhi Shivaditya",
          "description": "What is the optimal framework and configuration for hosting large language models (LLMs) for text-generating generative AI applications? Despite the abundance of options for serving LLMs, this is a hard question to answer due to the size of the models, varying model architectures, performance requirements of applications, and more. The Amazon SageMaker Large Model Inference […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/improve-performance-of-falcon-models-with-amazon-sagemaker/",
          "publishedOn": "2023-10-11T16:28:05.000Z",
          "wordCount": 3961,
          "title": "Improve performance of Falcon models with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/11/improve-falcon-performance-1257x630.jpg"
        },
        {
          "id": "3fc93bffa4117e4687f3a09d0dc8af011798dc3e",
          "author": "Jiten Dedhia",
          "description": "In this post, we show how to index information stored in websites and use the intelligent search in Amazon Kendra to search for answers from content stored in internal and external websites. In addition, the ML-powered intelligent search can accurately get answers for your questions from unstructured documents with natural language narrative content, for which keyword search is not very effective.",
          "link": "https://aws.amazon.com/blogs/machine-learning/index-your-web-crawled-content-using-the-new-web-crawler-for-amazon-kendra/",
          "publishedOn": "2023-10-11T16:15:29.000Z",
          "wordCount": 2053,
          "title": "Index your web crawled content using the new Web Crawler for Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/11/web-crawled-content-kendra.jpg"
        },
        {
          "id": "145ebaed28dda5de4846c2e0dd8e4a54f97b1216",
          "author": "Anand Iyer",
          "description": "Launched in 2021, Amazon SageMaker Canvas is a visual, point-and-click service that allows business analysts and citizen data scientists to use ready-to-use machine learning (ML) models and build custom ML models to generate accurate predictions without the need to write any code. Ready-to-use models enable you to derive immediate insights from text, image, and document […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/new-no-code-generative-ai-capabilities-now-available-in-amazon-sagemaker-canvas/",
          "publishedOn": "2023-10-10T17:20:10.000Z",
          "wordCount": 2138,
          "title": "New – No-code generative AI capabilities now available in Amazon SageMaker Canvas",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/l-ml-15314-image001-881x630.png"
        },
        {
          "id": "6fbdc7b2c25e72984d866afa8c3024fda8a29b5f",
          "author": "Hemant Singh",
          "description": "Today, we’re excited to announce that the OpenAI Whisper foundation model is available for customers using Amazon SageMaker JumpStart. Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680 thousand hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/whisper-models-for-automatic-speech-recognition-now-available-in-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-10-10T17:09:35.000Z",
          "wordCount": 3269,
          "title": "Whisper models for automatic speech recognition now available in Amazon SageMaker JumpStart",
          "enclosure": {
            "length": "1280078",
            "type": "audio/wav",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-15311/sample1.wav"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/02/ML-15311-image001-1225x630.jpg"
        },
        {
          "id": "38ddfd3589f3778d8f34f15c640e9e2097fcaabe",
          "author": "Qiong Zhang",
          "description": "In this blog, you will learn to build a cloud-native FL architecture on AWS. By using infrastructure as code (IaC) tools on AWS, you can deploy FL architectures with ease. Also, a cloud-native architecture takes full advantage of a variety of AWS services with proven security and operational excellence, thereby simplifying the development of FL.",
          "link": "https://aws.amazon.com/blogs/machine-learning/reinventing-a-cloud-native-federated-learning-architecture-on-aws/",
          "publishedOn": "2023-10-10T17:01:51.000Z",
          "wordCount": 3708,
          "title": "Reinventing a cloud-native federated learning architecture on AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/26/fl-arch.png"
        },
        {
          "id": "f6379ad2217c7af13a0224391c6b4156d9af2a3d",
          "author": "Kyle Ulrich",
          "description": "Today, we are excited to announce that the Mistral 7B foundation models, developed by Mistral AI, are available for customers through Amazon SageMaker JumpStart to deploy with one click for running inference. With 7 billion parameters, Mistral 7B can be easily customized and quickly deployed. You can try out this model with SageMaker JumpStart, a […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-10-09T21:37:48.000Z",
          "wordCount": 4168,
          "title": "Mistral 7B foundation models from Mistral AI are now available in Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/mistral-7b-sagemaker-jumpstart.jpg"
        },
        {
          "id": "c5e6ca49ccc13a7f87d34949c97eec679ed55d46",
          "author": "Gavin Satur",
          "description": "According to Gartner, 85% of software buyers trust online reviews as much as personal recommendations. Customers provide feedback and reviews about products they have purchased through many channels, including review websites, vendor websites, sales calls, social media, and many others. The problem with the increasing volume of customer reviews across multiple channels is that it […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-no-code-machine-learning-to-derive-insights-from-product-reviews-using-amazon-sagemaker-canvas-sentiment-analysis-and-text-analysis-models/",
          "publishedOn": "2023-10-09T17:49:32.000Z",
          "wordCount": 2206,
          "title": "Use no-code machine learning to derive insights from product reviews using Amazon SageMaker Canvas sentiment analysis and text analysis models",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/no-code-sentiment-reviews.jpg"
        },
        {
          "id": "433fa61bee27e013db333bccd4fcf2d6c6952342",
          "author": "Maysara Hamdan",
          "description": "A recommendation engine is only as good as the data used to prepare it. Transforming raw data into a format that is suitable for a model is key to getting better personalized recommendations for end-users. In this post, we walk through how to prepare and import the MovieLens dataset, a dataset prepared by GroupLens research […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/prepare-your-data-for-amazon-personalize-with-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2023-10-09T17:45:27.000Z",
          "wordCount": 3264,
          "title": "Prepare your data for Amazon Personalize with Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/prepare-amazon-personalize-data-wrangler.jpg"
        },
        {
          "id": "17c1ee4bd12ee4affb4e4d86cd777cd7aad766c0",
          "author": "Yanwei Cui",
          "description": "In this post, we elucidate the simple yet powerful idea of combining user profiles and item attributes to generate personalized content recommendations using LLMs. As demonstrated throughout the post, these models hold immense potential in generating high-quality, context-aware input text, which leads to enhanced recommendations. To illustrate this, we guide you through the process of integrating a feature store (representing user profiles) with an LLM to generate these personalized recommendations.",
          "link": "https://aws.amazon.com/blogs/machine-learning/personalize-your-generative-ai-applications-with-amazon-sagemaker-feature-store/",
          "publishedOn": "2023-10-06T16:26:35.000Z",
          "wordCount": 3820,
          "title": "Personalize your generative AI applications with Amazon SageMaker Feature Store",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/21/LLMRecIllustration-1183x630.png"
        },
        {
          "id": "781b6ebbbb8d93ed3fd71d5f18773e75d56a494b",
          "author": "Yanwei Cui",
          "description": "In this post, we provide an overview of popular multimodality models. We also demonstrate how to deploy these pre-trained models on Amazon SageMaker. Furthermore, we discuss the diverse applications of these models, focusing particularly on several real-world scenarios, such as zero-shot tag and attribution generation for ecommerce and automatic prompt generation from images.",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-image-to-text-generative-ai-application-using-multimodality-models-on-amazon-sagemaker/",
          "publishedOn": "2023-10-06T16:12:48.000Z",
          "wordCount": 3860,
          "title": "Build an image-to-text generative AI application using multimodality models on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/15/ML-15190-clip-1012x630.png"
        },
        {
          "id": "b29c68eb95cf8e07624bc83a702735c83f8886bc",
          "author": "Sathya Balakrishnan",
          "description": "In this post, we explain how to build and optimize a custom classification model using Amazon Comprehend. We demonstrate this using an Amazon Comprehend custom classification to build a multi-label custom classification model, and provide guidelines on how to prepare the training dataset and tune the model to meet performance metrics such as accuracy, precision, recall, and F1 score.",
          "link": "https://aws.amazon.com/blogs/machine-learning/improve-prediction-quality-in-custom-classification-models-with-amazon-comprehend/",
          "publishedOn": "2023-10-05T17:21:48.000Z",
          "wordCount": 2363,
          "title": "Improve prediction quality in custom classification models with Amazon Comprehend",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/14/ml-13080-image5.png"
        },
        {
          "id": "ec895ac7cb8adf123a7c801707ca652deb3ea4d3",
          "author": "Hao Zhou",
          "description": "Large language models (LLMs) have captured the imagination and attention of developers, scientists, technologists, entrepreneurs, and executives across several industries. These models can be used for question answering, summarization, translation, and more in applications such as conversational agents for customer support, content creation for marketing, and coding assistants. Recently, Meta released Llama 2 for both […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/fast-and-cost-effective-llama-2-fine-tuning-with-aws-trainium/",
          "publishedOn": "2023-10-05T17:14:03.000Z",
          "wordCount": 2036,
          "title": "Fast and cost-effective LLaMA 2 fine-tuning with AWS Trainium",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/05/fast-cost-effective-llama.jpg"
        },
        {
          "id": "be5af0f28c609a01c405a677e484ed6b08cc7d12",
          "author": "Ramakant Joshi",
          "description": "Analyzing medical images plays a crucial role in diagnosing and treating diseases. The ability to automate this process using machine learning (ML) techniques allows healthcare professionals to more quickly diagnose certain cancers, coronary diseases, and ophthalmologic conditions. However, one of the key challenges faced by clinicians and researchers in this field is the time-consuming and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/simplify-medical-image-classification-using-amazon-sagemaker-canvas/",
          "publishedOn": "2023-10-04T18:58:00.000Z",
          "wordCount": 3421,
          "title": "Simplify medical image classification using Amazon SageMaker Canvas",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/04/simplify-medical-image-classification.jpg"
        },
        {
          "id": "339cdca51b4db2b0c1dffa4ec7bdf02a334b97ef",
          "author": "John Kitaoka",
          "description": "Healthcare and life sciences (HCLS) customers are adopting generative AI as a tool to get more from their data. Use cases include document summarization to help readers focus on key points of a document and transforming unstructured text into standardized formats to highlight important attributes. With unique data formats and strict regulatory requirements, customers are […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/create-an-hcls-document-summarization-application-with-falcon-using-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-10-04T18:50:15.000Z",
          "wordCount": 2767,
          "title": "Create an HCLS document summarization application with Falcon using Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/04/hcls-document-repository-falcon.jpg"
        },
        {
          "id": "134f648e31243787082518b77533e5e96df76c88",
          "author": "Manish Patel",
          "description": "Prior authorization is a crucial process in healthcare that involves the approval of medical treatments or procedures before they are carried out. This process is necessary to ensure that patients receive the right care and that healthcare providers are following the correct procedures. However, prior authorization can be a time-consuming and complex process that requires […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automate-prior-authorization-using-crd-with-cds-hooks-and-aws-healthlake/",
          "publishedOn": "2023-10-04T18:40:53.000Z",
          "wordCount": 2199,
          "title": "Automate prior authorization using CRD with CDS Hooks and AWS HealthLake",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/26/CRDArchitecture.png"
        },
        {
          "id": "cd418e3c11f7ef613ec7b0e321c2181724319993",
          "author": "Gabriel Synnaeve",
          "description": "Today, we are excited to announce Code Llama foundation models, developed by Meta, are available for customers through Amazon SageMaker JumpStart to deploy with one click for running inference. Code Llama is a state-of-the-art large language model (LLM) capable of generating code and natural language about code from both code and natural language prompts. Code […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/code-llama-code-generation-models-from-meta-are-now-available-via-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-10-02T21:30:04.000Z",
          "wordCount": 3445,
          "title": "Code Llama code generation models from Meta are now available via Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/02/code-llama-jumpstart.jpg"
        },
        {
          "id": "fed81d50529eb0b948d390863fd3936ac8a38a50",
          "author": "Michael Roth",
          "description": "A successful deployment of a machine learning (ML) model in a production environment heavily relies on an end-to-end ML pipeline. Although developing such a pipeline can be challenging, it becomes even more complex when dealing with an edge ML use case. Machine learning at the edge is a concept that brings the capability of running […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-end-to-end-mlops-pipeline-for-visual-quality-inspection-at-the-edge-part-1/",
          "publishedOn": "2023-10-02T16:31:29.000Z",
          "wordCount": 3074,
          "title": "Build an end-to-end MLOps pipeline for visual quality inspection at the edge – Part 1",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/21/ML-6965-pipeline-scribble-820x630.jpg"
        },
        {
          "id": "0840f232e2b2b2594035da8f8fea5ce874257200",
          "author": "Michael Roth",
          "description": "In Part 1 of this series, we drafted an architecture for an end-to-end MLOps pipeline for a visual quality inspection use case at the edge. It is architected to automate the entire machine learning (ML) process, from data labeling to model training and deployment at the edge. The focus on managed and serverless services reduces […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-end-to-end-mlops-pipeline-for-visual-quality-inspection-at-the-edge-part-2/",
          "publishedOn": "2023-10-02T16:31:23.000Z",
          "wordCount": 2687,
          "title": "Build an end-to-end MLOps pipeline for visual quality inspection at the edge – Part 2",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/21/ML-6965-scratch-sample.jpg"
        },
        {
          "id": "02a4b68b189babfa161fbe557826981b865d651c",
          "author": "Michael Roth",
          "description": "This is Part 3 of our series where we design and implement an MLOps pipeline for visual quality inspection at the edge. In this post, we focus on how to automate the edge deployment part of the end-to-end MLOps pipeline. We show you how to use AWS IoT Greengrass to manage model inference at the […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-end-to-end-mlops-pipeline-for-visual-quality-inspection-at-the-edge-part-3/",
          "publishedOn": "2023-10-02T16:31:18.000Z",
          "wordCount": 2770,
          "title": "Build an end-to-end MLOps pipeline for visual quality inspection at the edge – Part 3",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/21/ML-6965-arch-diag-1149x630.jpg"
        },
        {
          "id": "e6926913d81f18288eff67d35b63dc80ea3dbb05",
          "author": "Lydia Lihui Zhang",
          "description": "In this analysis, we use a K-nearest neighbors (KNN) model to conduct crop segmentation, and we compare these results with ground truth imagery on an agricultural region. Our results reveal that the classification from the KNN model is more accurately representative of the state of the current crop field in 2017 than the ground truth classification data from 2015. These results are a testament to the power of Planet’s high-cadence geospatial imagery. Agricultural fields change often, sometimes multiple times a season, and having high-frequency satellite imagery available to observe and analyze this land can provide immense value to our understanding of agricultural land and quickly-changing environments.",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-crop-segmentation-machine-learning-model-with-planet-data-and-amazon-sagemaker-geospatial-capabilities/",
          "publishedOn": "2023-09-29T21:08:49.000Z",
          "wordCount": 4487,
          "title": "Build a crop segmentation machine learning model with Planet data and Amazon SageMaker geospatial capabilities",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/28/ML-14309-image003.png"
        },
        {
          "id": "24f5f889b8c34a0086855adf5610ddc45d4b8e21",
          "author": "Ilan Geller",
          "description": "This post is co-written with Ilan Geller and Shuyu Yang from Accenture. Enterprises today face major challenges when it comes to using their information and knowledge bases for both internal and external business operations. With constantly evolving operations, processes, policies, and compliance requirements, it can be extremely difficult for employees and customers to stay up […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/accenture-creates-a-knowledge-assist-solution-using-generative-ai-services-on-aws/",
          "publishedOn": "2023-09-28T19:28:41.000Z",
          "wordCount": 2536,
          "title": "Accenture creates a Knowledge Assist solution using generative AI services on AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/27/ml-15315-image001-1260x551.png"
        },
        {
          "id": "be5c3861265a49ba4c4d5f34f7428d0baa8bac20",
          "author": "Nirmal Kumar",
          "description": "We’re excited to announce that Amazon SageMaker Canvas now offers a quicker and more user-friendly way to create machine learning models for time-series forecasting. SageMaker Canvas is a visual point-and-click service that enables business analysts to generate accurate machine learning (ML) models without requiring any machine learning experience or having to write a single line of code. SageMaker […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/speed-up-your-time-series-forecasting-by-up-to-50-percent-with-amazon-sagemaker-canvas-ui-and-automl-apis/",
          "publishedOn": "2023-09-28T17:23:10.000Z",
          "wordCount": 2178,
          "title": "Speed up your time series forecasting by up to 50 percent with Amazon SageMaker Canvas UI and AutoML APIs",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/27/ML-15508-image002-1252x630.jpg"
        },
        {
          "id": "9f3745bfee5c63ba48a09c4c8cf8d81544701a20",
          "author": "Nick Biso",
          "description": "In the world of data-driven decision-making, time series forecasting is key in enabling businesses to use historical data patterns to anticipate future outcomes. Whether you are working in asset risk management, trading, weather prediction, energy demand forecasting, vital sign monitoring, or traffic analysis, the ability to forecast accurately is crucial for success. In these applications, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/robust-time-series-forecasting-with-mlops-on-amazon-sagemaker/",
          "publishedOn": "2023-09-28T17:05:11.000Z",
          "wordCount": 3034,
          "title": "Robust time series forecasting with MLOps on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/21/ML-13454-image015.png"
        },
        {
          "id": "f48418b4cb0675d9c19c3900e5b213373fb9b183",
          "author": "Talha Chattha",
          "description": "In the rapidly evolving world of AI and machine learning (ML), foundation models (FMs) have shown tremendous potential for driving innovation and unlocking new use cases. However, as organizations increasingly harness the power of FMs, concerns surrounding data privacy, security, added cost, and compliance have become paramount. Regulated and compliance-oriented industries, such as financial services, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/create-a-generative-ai-gateway-to-allow-secure-and-compliant-consumption-of-foundation-models/",
          "publishedOn": "2023-09-28T17:00:33.000Z",
          "wordCount": 3946,
          "title": "Create a Generative AI Gateway to allow secure and compliant consumption of foundation models",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/18/ML-14882-Gen-AI-Gateway-Model-Abstraction.png"
        },
        {
          "id": "b328f2a8d5dcd7e4df0e267b25500c9c34765060",
          "author": "Charles Laughlin",
          "description": "Companies use time series forecasting to make core planning decisions that help them navigate through uncertain futures. This post is meant to address supply chain stakeholders, who share a common need of determining how many finished goods are needed over a mixed variety of planning time horizons. In addition to planning how many units of […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/beyond-forecasting-the-delicate-balance-of-serving-customers-and-growing-your-business/",
          "publishedOn": "2023-09-28T16:56:56.000Z",
          "wordCount": 3291,
          "title": "Beyond forecasting: The delicate balance of serving customers and growing your business",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/01/quantile-graphic-blog-1164x630.png"
        },
        {
          "id": "d2dd860a3d9d2f3453bc4683eb72be7f89f33465",
          "author": "Swami Sivasubramanian",
          "description": "From startups to enterprises, organizations of all sizes are getting started with generative AI. They want to capitalize on generative AI and translate the momentum from betas, prototypes, and demos into real-world productivity gains and innovations. But what do organizations need to bring generative AI into the enterprise and make it real? When we talk […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/announcing-new-tools-to-help-every-business-embrace-generative-ai/",
          "publishedOn": "2023-09-28T13:40:01.000Z",
          "wordCount": 3829,
          "title": "Announcing New Tools to Help Every Business Embrace Generative AI",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/28/Updated_slide-1127x630.jpg"
        },
        {
          "id": "5fa30641ce2cc6076bed63a524900037901a3a7c",
          "author": "Yunfei Bai",
          "description": "The Amazon EU Design and Construction (Amazon D&C) team is the engineering team designing and constructing Amazon Warehouses across Europe and the MENA region. The design and deployment processes of projects involve many types of Requests for Information (RFIs) about engineering requirements regarding Amazon and project-specific guidelines. These requests range from simple retrieval of baseline […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/a-generative-ai-powered-solution-on-amazon-sagemaker-to-help-amazon-eu-design-and-construction/",
          "publishedOn": "2023-09-27T18:50:49.000Z",
          "wordCount": 3750,
          "title": "A generative AI-powered solution on Amazon SageMaker to help Amazon EU Design and Construction",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/12/GESS_LLM_architecture_V4.1.png"
        },
        {
          "id": "023cef7ec7be1de4c1d3adc8dda1692a97737a71",
          "author": "Jake Bernstein",
          "description": "MDaudit provides a cloud-based billing compliance and revenue integrity software as a service (SaaS) platform to more than 70,000 healthcare providers and 1,500 healthcare facilities, ensuring healthcare customers maintain regulatory compliance and retain revenue. Working with the top 60+ US healthcare networks, MDaudit needs to be able to scale its artificial intelligence (AI) capabilities to […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/mdaudit-uses-ai-to-improve-revenue-outcomes-for-healthcare-customers/",
          "publishedOn": "2023-09-27T17:12:59.000Z",
          "wordCount": 1619,
          "title": "MDaudit uses AI to improve revenue outcomes for healthcare customers",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/19/ML-13668-arch-diag-1129x630.png"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2310.12244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Haizhou Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>",
          "description": "Domain incremental learning aims to adapt to a sequence of domains with\naccess to only a small subset of data (i.e., memory) from previous domains.\nVarious methods have been proposed for this problem, but it is still unclear\nhow they are related and when practitioners should choose one method over\nanother. In response, we propose a unified framework, dubbed Unified Domain\nIncremental Learning (UDIL), for domain incremental learning with memory. Our\nUDIL **unifies** various existing methods, and our theoretical analysis shows\nthat UDIL always achieves a tighter generalization error bound compared to\nthese methods. The key insight is that different existing methods correspond to\nour bound with different **fixed** coefficients; based on insights from this\nunification, our UDIL allows **adaptive** coefficients during training, thereby\nalways achieving the tightest bound. Empirical results show that our UDIL\noutperforms the state-of-the-art domain incremental learning methods on both\nsynthetic and real-world datasets. Code will be available at\nhttps://github.com/Wang-ML-Lab/unified-continual-learning.",
          "link": "http://arxiv.org/abs/2310.12244",
          "publishedOn": "2023-10-21T00:41:44.691Z",
          "wordCount": 682,
          "title": "A Unified Approach to Domain Incremental Learning with Memory: Theory and Algorithm. (arXiv:2310.12244v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balin_M/0/1/0/all/0/1\">Muhammed Fatih Balin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LaSalle_D/0/1/0/all/0/1\">Dominique LaSalle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catalyurek_U/0/1/0/all/0/1\">&#xdc;mit V. &#xc7;ataly&#xfc;rek</a>",
          "description": "Significant computational resources are required to train Graph Neural\nNetworks (GNNs) at a large scale, and the process is highly data-intensive. One\nof the most effective ways to reduce resource requirements is minibatch\ntraining coupled with graph sampling. GNNs have the unique property that items\nin a minibatch have overlapping data. However, the commonly implemented\nIndependent Minibatching approach assigns each Processing Element (PE) its own\nminibatch to process, leading to duplicated computations and input data access\nacross PEs. This amplifies the Neighborhood Explosion Phenomenon (NEP), which\nis the main bottleneck limiting scaling. To reduce the effects of NEP in the\nmulti-PE setting, we propose a new approach called Cooperative Minibatching.\nOur approach capitalizes on the fact that the size of the sampled subgraph is a\nconcave function of the batch size, leading to significant reductions in the\namount of work per seed vertex as batch sizes increase. Hence, it is favorable\nfor processors equipped with a fast interconnect to work on a large minibatch\ntogether as a single larger processor, instead of working on separate smaller\nminibatches, even though global batch size is identical. We also show how to\ntake advantage of the same phenomenon in serial execution by generating\ndependent consecutive minibatches. Our experimental evaluations show up to 4x\nbandwidth savings for fetching vertex embeddings, by simply increasing this\ndependency without harming model convergence. Combining our proposed\napproaches, we achieve up to 64% speedup over Independent Minibatching on\nsingle-node multi-GPU systems.",
          "link": "http://arxiv.org/abs/2310.12403",
          "publishedOn": "2023-10-21T00:41:44.683Z",
          "wordCount": 750,
          "title": "Cooperative Minibatching in Graph Neural Networks. (arXiv:2310.12403v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12442",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_D/0/1/0/all/0/1\">Dhananjay Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hawkins_C/0/1/0/all/0/1\">Cole Hawkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_S/0/1/0/all/0/1\">Sheng Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>",
          "description": "Pretrained transformer models have demonstrated remarkable performance across\nvarious natural language processing tasks. These models leverage the attention\nmechanism to capture long- and short-range dependencies in the sequence.\nHowever, the (full) attention mechanism incurs high computational cost -\nquadratic in the sequence length, which is not affordable in tasks with long\nsequences, e.g., inputs with 8k tokens. Although sparse attention can be used\nto improve computational efficiency, as suggested in existing work, it has\nlimited modeling capacity and often fails to capture complicated dependencies\nin long sequences. To tackle this challenge, we propose MASFormer, an\neasy-to-implement transformer variant with Mixed Attention Spans. Specifically,\nMASFormer is equipped with full attention to capture long-range dependencies,\nbut only at a small number of layers. For the remaining layers, MASformer only\nemploys sparse attention to capture short-range dependencies. Our experiments\non natural language modeling and generation tasks show that a decoder-only\nMASFormer model of 1.3B parameters can achieve competitive performance to\nvanilla transformers with full attention while significantly reducing\ncomputational cost (up to 75%). Additionally, we investigate the effectiveness\nof continual training with long sequence data and how sequence length impacts\ndownstream generation performance, which may be of independent interest.",
          "link": "http://arxiv.org/abs/2310.12442",
          "publishedOn": "2023-10-21T00:41:44.676Z",
          "wordCount": 739,
          "title": "Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer. (arXiv:2310.12442v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giambagli_L/0/1/0/all/0/1\">Lorenzo Giambagli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buffoni_L/0/1/0/all/0/1\">Lorenzo Buffoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chicchi_L/0/1/0/all/0/1\">Lorenzo Chicchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fanelli_D/0/1/0/all/0/1\">Duccio Fanelli</a>",
          "description": "In theoretical ML, the teacher-student paradigm is often employed as an\neffective metaphor for real-life tuition. The above scheme proves particularly\nrelevant when the student network is overparameterized as compared to the\nteacher network. Under these operating conditions, it is tempting to speculate\nthat the student ability to handle the given task could be eventually stored in\na sub-portion of the whole network. This latter should be to some extent\nreminiscent of the frozen teacher structure, according to suitable metrics,\nwhile being approximately invariant across different architectures of the\nstudent candidate network. Unfortunately, state-of-the-art conventional\nlearning techniques could not help in identifying the existence of such an\ninvariant subnetwork, due to the inherent degree of non-convexity that\ncharacterizes the examined problem. In this work, we take a leap forward by\nproposing a radically different optimization scheme which builds on a spectral\nrepresentation of the linear transfer of information between layers. The\ngradient is hence calculated with respect to both eigenvalues and eigenvectors\nwith negligible increase in terms of computational and complexity load, as\ncompared to standard training algorithms. Working in this framework, we could\nisolate a stable student substructure, that mirrors the true complexity of the\nteacher in terms of computing neurons, path distribution and topological\nattributes. When pruning unimportant nodes of the trained student, as follows a\nranking that reflects the optimized eigenvalues, no degradation in the recorded\nperformance is seen above a threshold that corresponds to the effective teacher\nsize. The observed behavior can be pictured as a genuine second-order phase\ntransition that bears universality traits.",
          "link": "http://arxiv.org/abs/2310.12612",
          "publishedOn": "2023-10-21T00:41:44.669Z",
          "wordCount": 805,
          "title": "How a student becomes a teacher: learning and forgetting through Spectral methods. (arXiv:2310.12612v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanno_R/0/1/0/all/0/1\">Ryutaro Tanno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saseendran_A/0/1/0/all/0/1\">Amrutha Saseendran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diethe_T/0/1/0/all/0/1\">Tom Diethe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teare_P/0/1/0/all/0/1\">Philip Teare</a>",
          "description": "Textural Inversion, a prompt learning method, learns a singular embedding for\na new \"word\" to represent image style and appearance, allowing it to be\nintegrated into natural language sentences to generate novel synthesised\nimages. However, identifying and integrating multiple object-level concepts\nwithin one scene poses significant challenges even when embeddings for\nindividual concepts are attainable. This is further confirmed by our empirical\ntests. To address this challenge, we introduce a framework for Multi-Concept\nPrompt Learning (MCPL), where multiple new \"words\" are simultaneously learned\nfrom a single sentence-image pair. To enhance the accuracy of word-concept\ncorrelation, we propose three regularisation techniques: Attention Masking\n(AttnMask) to concentrate learning on relevant areas; Prompts Contrastive Loss\n(PromptCL) to separate the embeddings of different concepts; and Bind adjective\n(Bind adj.) to associate new \"words\" with known words. We evaluate via image\ngeneration, editing, and attention visualisation with diverse images. Extensive\nquantitative comparisons demonstrate that our method can learn more\nsemantically disentangled concepts with enhanced word-concept correlation.\nAdditionally, we introduce a novel dataset and evaluation protocol tailored for\nthis new task of learning object-level concepts.",
          "link": "http://arxiv.org/abs/2310.12274",
          "publishedOn": "2023-10-21T00:41:44.653Z",
          "wordCount": 728,
          "title": "An Image is Worth Multiple Words: Learning Object Level Concepts using Multi-Concept Prompt Learning. (arXiv:2310.12274v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bernasconi_M/0/1/0/all/0/1\">Martino Bernasconi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castiglioni_M/0/1/0/all/0/1\">Matteo Castiglioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celli_A/0/1/0/all/0/1\">Andrea Celli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1\">Federico Fusco</a>",
          "description": "Bilateral trade revolves around the challenge of facilitating transactions\nbetween two strategic agents -- a seller and a buyer -- both of whom have a\nprivate valuations for the item. We study the online version of the problem, in\nwhich at each time step a new seller and buyer arrive. The learner's task is to\nset a price for each agent, without any knowledge about their valuations. The\nsequence of sellers and buyers is chosen by an oblivious adversary. In this\nsetting, known negative results rule out the possibility of designing\nalgorithms with sublinear regret when the learner has to guarantee budget\nbalance for each iteration. In this paper, we introduce the notion of global\nbudget balance, which requires the agent to be budget balance only over the\nentire time horizon. By requiring global budget balance, we provide the first\nno-regret algorithms for bilateral trade with adversarial inputs under various\nfeedback models. First, we show that in the full-feedback model the learner can\nguarantee $\\tilde{O}(\\sqrt{T})$ regret against the best fixed prices in\nhindsight, which is order-wise optimal. Then, in the case of partial feedback\nmodels, we provide an algorithm guaranteeing a $\\tilde{O}(T^{3/4})$ regret\nupper bound with one-bit feedback, which we complement with a nearly-matching\nlower bound. Finally, we investigate how these results vary when measuring\nregret using an alternative benchmark.",
          "link": "http://arxiv.org/abs/2310.12370",
          "publishedOn": "2023-10-21T00:41:44.647Z",
          "wordCount": 731,
          "title": "No-Regret Learning in Bilateral Trade via Global Budget Balance. (arXiv:2310.12370v1 [cs.GT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Md Rashedul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiawei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_I/0/1/0/all/0/1\">Iftekhar Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagheri_H/0/1/0/all/0/1\">Hamid Bagheri</a>",
          "description": "The growing adoption of declarative software specification languages, coupled\nwith their inherent difficulty in debugging, has underscored the need for\neffective and automated repair techniques applicable to such languages.\nResearchers have recently explored various methods to automatically repair\ndeclarative software specifications, such as template-based repair,\nfeedback-driven iterative repair, and bounded exhaustive approaches. The latest\ndevelopments in large language models provide new opportunities for the\nautomatic repair of declarative specifications. In this study, we assess the\neffectiveness of utilizing OpenAI's ChatGPT to repair software specifications\nwritten in the Alloy declarative language. Unlike imperative languages,\nspecifications in Alloy are not executed but rather translated into logical\nformulas and evaluated using backend constraint solvers to identify\nspecification instances and counterexamples to assertions. Our evaluation\nfocuses on ChatGPT's ability to improve the correctness and completeness of\nAlloy declarative specifications through automatic repairs. We analyze the\nresults produced by ChatGPT and compare them with those of leading automatic\nAlloy repair methods. Our study revealed that while ChatGPT falls short in\ncomparison to existing techniques, it was able to successfully repair bugs that\nno other technique could address. Our analysis also identified errors in\nChatGPT's generated repairs, including improper operator usage, type errors,\nhigher-order logic misuse, and relational arity mismatches. Additionally, we\nobserved instances of hallucinations in ChatGPT-generated repairs and\ninconsistency in its results. Our study provides valuable insights for software\npractitioners, researchers, and tool builders considering ChatGPT for\ndeclarative specification repairs.",
          "link": "http://arxiv.org/abs/2310.12425",
          "publishedOn": "2023-10-21T00:41:44.641Z",
          "wordCount": 773,
          "title": "Automated Repair of Declarative Software Specifications in the Era of Large Language Models. (arXiv:2310.12425v1 [cs.SE])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12407",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xianglong Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zengfu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Q/0/1/0/all/0/1\">Quan Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_T/0/1/0/all/0/1\">Tao Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_H/0/1/0/all/0/1\">Hua Lan</a>",
          "description": "We address the challenge of tracking an unknown number of targets in strong\nclutter environments using measurements from a radar sensor. Leveraging the\nrange-Doppler spectra information, we identify the measurement classes, which\nserve as additional information to enhance clutter rejection and data\nassociation, thus bolstering the robustness of target tracking. We first\nintroduce a novel neural enhanced message passing approach, where the beliefs\nobtained by the unified message passing are fed into the neural network as\nadditional information. The output beliefs are then utilized to refine the\noriginal beliefs. Then, we propose a classification-aided robust multiple\ntarget tracking algorithm, employing the neural enhanced message passing\ntechnique. This algorithm is comprised of three modules: a message-passing\nmodule, a neural network module, and a Dempster-Shafer module. The\nmessage-passing module is used to represent the statistical model by the factor\ngraph and infers target kinematic states, visibility states, and data\nassociations based on the spatial measurement information. The neural network\nmodule is employed to extract features from range-Doppler spectra and derive\nbeliefs on whether a measurement is target-generated or clutter-generated. The\nDempster-Shafer module is used to fuse the beliefs obtained from both the\nfactor graph and the neural network. As a result, our proposed algorithm adopts\na model-and-data-driven framework, effectively enhancing clutter suppression\nand data association, leading to significant improvements in multiple target\ntracking performance. We validate the effectiveness of our approach using both\nsimulated and real data scenarios, demonstrating its capability to handle\nchallenging tracking scenarios in practical radar applications.",
          "link": "http://arxiv.org/abs/2310.12407",
          "publishedOn": "2023-10-21T00:41:44.634Z",
          "wordCount": 791,
          "title": "Classification-Aided Robust Multiple Target Tracking Using Neural Enhanced Message Passing. (arXiv:2310.12407v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Josef Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xuehai Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruiyang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jiaming Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xinbo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mickel Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>",
          "description": "With the development of large language models (LLMs), striking a balance\nbetween the performance and safety of AI systems has never been more critical.\nHowever, the inherent tension between the objectives of helpfulness and\nharmlessness presents a significant challenge during LLM training. To address\nthis issue, we propose Safe Reinforcement Learning from Human Feedback (Safe\nRLHF), a novel algorithm for human value alignment. Safe RLHF explicitly\ndecouples human preferences regarding helpfulness and harmlessness, effectively\navoiding the crowdworkers' confusion about the tension and allowing us to train\nseparate reward and cost models. We formalize the safety concern of LLMs as an\noptimization task of maximizing the reward function while satisfying specified\ncost constraints. Leveraging the Lagrangian method to solve this constrained\nproblem, Safe RLHF dynamically adjusts the balance between the two objectives\nduring fine-tuning. Through a three-round fine-tuning using Safe RLHF, we\ndemonstrate a superior ability to mitigate harmful responses while enhancing\nmodel performance compared to existing value-aligned algorithms.\nExperimentally, we fine-tuned the Alpaca-7B using Safe RLHF and aligned it with\ncollected human preferences, significantly improving its helpfulness and\nharmlessness according to human evaluations.",
          "link": "http://arxiv.org/abs/2310.12773",
          "publishedOn": "2023-10-21T00:41:44.627Z",
          "wordCount": 692,
          "title": "Safe RLHF: Safe Reinforcement Learning from Human Feedback. (arXiv:2310.12773v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12209",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Shih_D/0/1/0/all/0/1\">David Shih</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Freytsis_M/0/1/0/all/0/1\">Marat Freytsis</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Taylor_S/0/1/0/all/0/1\">Stephen R. Taylor</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Dror_J/0/1/0/all/0/1\">Jeff A. Dror</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Smyth_N/0/1/0/all/0/1\">Nolan Smyth</a>",
          "description": "Pulsar timing arrays (PTAs) perform Bayesian posterior inference with\nexpensive MCMC methods. Given a dataset of ~10-100 pulsars and O(10^3) timing\nresiduals each, producing a posterior distribution for the stochastic\ngravitational wave background (SGWB) can take days to a week. The computational\nbottleneck arises because the likelihood evaluation required for MCMC is\nextremely costly when considering the dimensionality of the search space.\nFortunately, generating simulated data is fast, so modern simulation-based\ninference techniques can be brought to bear on the problem. In this paper, we\ndemonstrate how conditional normalizing flows trained on simulated data can be\nused for extremely fast and accurate estimation of the SGWB posteriors,\nreducing the sampling time from weeks to a matter of seconds.",
          "link": "http://arxiv.org/abs/2310.12209",
          "publishedOn": "2023-10-21T00:41:44.609Z",
          "wordCount": 670,
          "title": "Fast Parameter Inference on Pulsar Timing Arrays with Normalizing Flows. (arXiv:2310.12209v1 [astro-ph.IM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haitian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Renjie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xiao Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zhenkun Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Minjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1\">David Wipf</a>",
          "description": "Among the many variants of graph neural network (GNN) architectures capable\nof modeling data with cross-instance relations, an important subclass involves\nlayers designed such that the forward pass iteratively reduces a\ngraph-regularized energy function of interest. In this way, node embeddings\nproduced at the output layer dually serve as both predictive features for\nsolving downstream tasks (e.g., node classification) and energy function\nminimizers that inherit desirable inductive biases and interpretability.\nHowever, scaling GNN architectures constructed in this way remains challenging,\nin part because the convergence of the forward pass may involve models with\nconsiderable depth. To tackle this limitation, we propose a sampling-based\nenergy function and scalable GNN layers that iteratively reduce it, guided by\nconvergence guarantees in certain settings. We also instantiate a full GNN\narchitecture based on these designs, and the model achieves competitive\naccuracy and scalability when applied to the largest publicly-available node\nclassification benchmark exceeding 1TB in size.",
          "link": "http://arxiv.org/abs/2310.12457",
          "publishedOn": "2023-10-21T00:41:44.160Z",
          "wordCount": 667,
          "title": "MuseGNN: Interpretable and Convergent Graph Neural Network Layers at Scale. (arXiv:2310.12457v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scarvelis_C/0/1/0/all/0/1\">Christopher Scarvelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borde_H/0/1/0/all/0/1\">Haitz S&#xe1;ez de Oc&#xe1;riz Borde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1\">Justin Solomon</a>",
          "description": "Score-based generative models (SGMs) sample from a target distribution by\niteratively transforming noise using the score function of the perturbed\ntarget. For any finite training set, this score function can be evaluated in\nclosed form, but the resulting SGM memorizes its training data and does not\ngenerate novel samples. In practice, one approximates the score by training a\nneural network via score-matching. The error in this approximation promotes\ngeneralization, but neural SGMs are costly to train and sample, and the\neffective regularization this error provides is not well-understood\ntheoretically. In this work, we instead explicitly smooth the closed-form score\nto obtain an SGM that generates novel samples without training. We analyze our\nmodel and propose an efficient nearest-neighbor-based estimator of its score\nfunction. Using this estimator, our method achieves sampling times competitive\nwith neural SGMs while running on consumer-grade CPUs.",
          "link": "http://arxiv.org/abs/2310.12395",
          "publishedOn": "2023-10-21T00:41:44.146Z",
          "wordCount": 634,
          "title": "Closed-Form Diffusion Models. (arXiv:2310.12395v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khatri_M/0/1/0/all/0/1\">Mann Khatri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yusuf_M/0/1/0/all/0/1\">Mirza Yusuf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_Y/0/1/0/all/0/1\">Yaman Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1\">Ponnurangam Kumaraguru</a>",
          "description": "The burdensome impact of a skewed judges-to-cases ratio on the judicial\nsystem manifests in an overwhelming backlog of pending cases alongside an\nongoing influx of new ones. To tackle this issue and expedite the judicial\nprocess, the proposition of an automated system capable of suggesting case\noutcomes based on factual evidence and precedent from past cases gains\nsignificance. This research paper centres on developing a graph neural\nnetwork-based model to address the Legal Judgment Prediction (LJP) problem,\nrecognizing the intrinsic graph structure of judicial cases and making it a\nbinary node classification problem. We explored various embeddings as model\nfeatures, while nodes such as time nodes and judicial acts were added and\npruned to evaluate the model's performance. The study is done while considering\nthe ethical dimension of fairness in these predictions, considering gender and\nname biases. A link prediction task is also conducted to assess the model's\nproficiency in anticipating connections between two specified nodes. By\nharnessing the capabilities of graph neural networks and incorporating fairness\nanalyses, this research aims to contribute insights towards streamlining the\nadjudication process, enhancing judicial efficiency, and fostering a more\nequitable legal landscape, ultimately alleviating the strain imposed by\nmounting case backlogs. Our best-performing model with XLNet pre-trained\nembeddings as its features gives the macro F1 score of 75% for the LJP task.\nFor link prediction, the same set of features is the best performing giving ROC\nof more than 80%",
          "link": "http://arxiv.org/abs/2310.12800",
          "publishedOn": "2023-10-21T00:41:43.292Z",
          "wordCount": null,
          "title": "Exploring Graph Neural Networks for Indian Legal Judgment Prediction. (arXiv:2310.12800v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.10170",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kaplan_D/0/1/0/all/0/1\">David L. Kaplan</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Buehler_M/0/1/0/all/0/1\">Markus J. Buehler</a>",
          "description": "Spider silks are remarkable materials characterized by superb mechanical\nproperties such as strength, extensibility and lightweightedness. Yet, to date,\nlimited models are available to fully explore sequence-property relationships\nfor analysis and design. Here we propose a custom generative large-language\nmodel to enable design of novel spider silk protein sequences to meet complex\ncombinations of target mechanical properties. The model, pretrained on a large\nset of protein sequences, is fine-tuned on ~1,000 major ampullate spidroin\n(MaSp) sequences for which associated fiber-level mechanical properties exist,\nto yield an end-to-end forward and inverse generative strategy. Performance is\nassessed through: (1), a novelty analysis and protein type classification for\ngenerated spidroin sequences through BLAST searches, (2) property evaluation\nand comparison with similar sequences, (3) comparison of molecular structures,\nas well as, and (4) a detailed sequence motif analyses. We generate silk\nsequences with property combinations that do not exist in nature, and develop a\ndeep understanding the mechanistic roles of sequence patterns in achieving\noverarching key mechanical properties (elastic modulus, strength, toughness,\nfailure strain). The model provides an efficient approach to expand the silkome\ndataset, facilitating further sequence-structure analyses of silks, and\nestablishes a foundation for synthetic silk design and optimization.",
          "link": "http://arxiv.org/abs/2309.10170",
          "publishedOn": "2023-10-21T00:41:43.278Z",
          "wordCount": null,
          "title": "Generative modeling, design and analysis of spider silk protein sequences for enhanced mechanical properties. (arXiv:2309.10170v1 [cond-mat.mtrl-sci] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zilong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birke_R/0/1/0/all/0/1\">Robert Birke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lydia Chen</a>",
          "description": "Given the ubiquitous use of tabular data in industries and the growing\nconcerns in data privacy and security, tabular data synthesis emerges as a\ncritical research area. The recent state-of-the-art methods show that large\nlanguage models (LLMs) can be adopted to generate realistic tabular data. As\nLLMs pre-process tabular data as full text, they have the advantage of avoiding\nthe curse of dimensionality associated with one-hot encoding high-dimensional\ndata. However, their long training time and limited re-usability on new tasks\nprevent them from replacing exiting tabular generative models. In this paper,\nwe propose Tabula, a tabular data synthesizer based on the language model\nstructure. Through Tabula, we demonstrate the inherent limitation of employing\npre-trained language models designed for natural language processing (NLP) in\nthe context of tabular data synthesis. Our investigation delves into the\ndevelopment of a dedicated foundational model tailored specifically for tabular\ndata synthesis. Additionally, we propose a token sequence compression strategy\nto significantly reduce training time while preserving the quality of synthetic\ndata. Extensive experiments on six datasets demonstrate that using a language\nmodel structure without loading the well-trained model weights yields a better\nstarting model for tabular data synthesis. Moreover, the Tabula model,\npreviously trained on other tabular data, serves as an excellent foundation\nmodel for new tabular data synthesis tasks. Additionally, the token sequence\ncompression method substantially reduces the model's training time. Results\nshow that Tabula averagely reduces 46.2% training time per epoch comparing to\ncurrent LLMs-based state-of-the-art algorithm and consistently achieves even\nhigher synthetic data utility.",
          "link": "http://arxiv.org/abs/2310.12746",
          "publishedOn": "2023-10-21T00:41:43.277Z",
          "wordCount": null,
          "title": "TabuLa: Harnessing Language Models for Tabular Data Synthesis. (arXiv:2310.12746v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lazarsfeld_J/0/1/0/all/0/1\">John Lazarsfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>",
          "description": "We study a distributed multi-armed bandit setting among a population of $n$\nmemory-constrained nodes in the gossip model: at each round, every node locally\nadopts one of $m$ arms, observes a reward drawn from the arm's (adversarially\nchosen) distribution, and then communicates with a randomly sampled neighbor,\nexchanging information to determine its policy in the next round. We introduce\nand analyze several families of dynamics for this task that are decentralized:\neach node's decision is entirely local and depends only on its most recently\nobtained reward and that of the neighbor it sampled. We show a connection\nbetween the global evolution of these decentralized dynamics with a certain\nclass of \"zero-sum\" multiplicative weights update algorithms, and we develop a\ngeneral framework for analyzing the population-level regret of these natural\nprotocols. Using this framework, we derive sublinear regret bounds under a wide\nrange of parameter regimes (i.e., the size of the population and number of\narms) for both the stationary reward setting (where the mean of each arm's\ndistribution is fixed over time) and the adversarial reward setting (where\nmeans can vary over time). Further, we show that these protocols can\napproximately optimize convex functions over the simplex when the reward\ndistributions are generated from a stochastic gradient oracle.",
          "link": "http://arxiv.org/abs/2306.08670",
          "publishedOn": "2023-10-21T00:41:43.277Z",
          "wordCount": null,
          "title": "The Power of Populations in Decentralized Learning Dynamics. (arXiv:2306.08670v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shomer_H/0/1/0/all/0/1\">Harry Shomer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Haitao Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanhui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bo Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>",
          "description": "Link prediction is a common task on graph-structured data that has seen\napplications in a variety of domains. Classically, hand-crafted heuristics were\nused for this task. Heuristic measures are chosen such that they correlate well\nwith the underlying factors related to link formation. In recent years, a new\nclass of methods has emerged that combines the advantages of message-passing\nneural networks (MPNN) and heuristics methods. These methods perform\npredictions by using the output of an MPNN in conjunction with a \"pairwise\nencoding\" that captures the relationship between nodes in the candidate link.\nThey have been shown to achieve strong performance on numerous datasets.\nHowever, current pairwise encodings often contain a strong inductive bias,\nusing the same underlying factors to classify all links. This limits the\nability of existing methods to learn how to properly classify a variety of\ndifferent links that may form from different factors. To address this\nlimitation, we propose a new method, LPFormer, which attempts to adaptively\nlearn the pairwise encodings for each link. LPFormer models the link factors\nvia an attention module that learns the pairwise encoding that exists between\nnodes by modeling multiple factors integral to link prediction. Extensive\nexperiments demonstrate that LPFormer can achieve SOTA performance on numerous\ndatasets while maintaining efficiency.",
          "link": "http://arxiv.org/abs/2310.11009",
          "publishedOn": "2023-10-21T00:41:43.277Z",
          "wordCount": null,
          "title": "Adaptive Pairwise Encodings for Link Prediction. (arXiv:2310.11009v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.03659",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hubert_N/0/1/0/all/0/1\">Nicolas Hubert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1\">Heiko Paulheim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monnin_P/0/1/0/all/0/1\">Pierre Monnin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brun_A/0/1/0/all/0/1\">Armelle Brun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monticolo_D/0/1/0/all/0/1\">Davy Monticolo</a>",
          "description": "Knowledge graph embedding models (KGEMs) have gained considerable traction in\nrecent years. These models learn a vector representation of knowledge graph\nentities and relations, a.k.a. knowledge graph embeddings (KGEs). Learning\nversatile KGEs is desirable as it makes them useful for a broad range of tasks.\nHowever, KGEMs are usually trained for a specific task, which makes their\nembeddings task-dependent. In parallel, the widespread assumption that KGEMs\nactually create a semantic representation of the underlying entities and\nrelations (e.g., project similar entities closer than dissimilar ones) has been\nchallenged. In this work, we design heuristics for generating protographs --\nsmall, modified versions of a KG that leverage RDF/S information. The learnt\nprotograph-based embeddings are meant to encapsulate the semantics of a KG, and\ncan be leveraged in learning KGEs that, in turn, also better capture semantics.\nExtensive experiments on various evaluation benchmarks demonstrate the\nsoundness of this approach, which we call Modular and Agnostic SCHema-based\nIntegration of protograph Embeddings (MASCHInE). In particular, MASCHInE helps\nproduce more versatile KGEs that yield substantially better performance for\nentity clustering and node classification tasks. For link prediction, using\nMASCHinE substantially increases the number of semantically valid predictions\nwith equivalent rank-based performance.",
          "link": "http://arxiv.org/abs/2306.03659",
          "publishedOn": "2023-10-21T00:41:43.275Z",
          "wordCount": null,
          "title": "Schema First! Learn Versatile Knowledge Graph Embeddings by Capturing Semantics with MASCHInE. (arXiv:2306.03659v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.12129",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Aigner_R/0/1/0/all/0/1\">Roland Aigner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stockl_A/0/1/0/all/0/1\">Andreas St&#xf6;ckl</a>",
          "description": "Knitted sensors frequently suffer from inconsistencies due to innate effects\nsuch as offset, relaxation, and drift. These properties, in combination, make\nit challenging to reliably map from sensor data to physical actuation. In this\npaper, we demonstrate a method for counteracting this by applying processing\nusing a minimal artificial neural network (ANN) in combination with\nstraightforward pre-processing. We apply a number of exponential smoothing\nfilters on a re-sampled sensor signal, to produce features that preserve\ndifferent levels of historical sensor data and, in combination, represent an\nadequate state of previous sensor actuation. By training a three-layer ANN with\na total of 8 neurons, we manage to significantly improve the mapping between\nsensor reading and actuation force. Our findings also show that our technique\ntranslates to sensors of reasonably different composition in terms of material\nand structure, and it can furthermore be applied to related physical features\nsuch as strain.",
          "link": "http://arxiv.org/abs/2306.12129",
          "publishedOn": "2023-10-21T00:41:43.275Z",
          "wordCount": null,
          "title": "Machine Learning Based Compensation for Inconsistencies in Knitted Force Sensors. (arXiv:2306.12129v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meidani_K/0/1/0/all/0/1\">Kazem Meidani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shojaee_P/0/1/0/all/0/1\">Parshin Shojaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1\">Chandan K. Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1\">Amir Barati Farimani</a>",
          "description": "In an era where symbolic mathematical equations are indispensable for\nmodeling complex natural phenomena, scientific inquiry often involves\ncollecting observations and translating them into mathematical expressions.\nRecently, deep learning has emerged as a powerful tool for extracting insights\nfrom data. However, existing models typically specialize in either numeric or\nsymbolic domains, and are usually trained in a supervised manner tailored to\nspecific tasks. This approach neglects the substantial benefits that could\narise from a task-agnostic unified understanding between symbolic equations and\ntheir numeric counterparts. To bridge the gap, we introduce SNIP, a\nSymbolic-Numeric Integrated Pre-training, which employs joint contrastive\nlearning between symbolic and numeric domains, enhancing their mutual\nsimilarities in the pre-trained embeddings. By performing latent space\nanalysis, we observe that SNIP provides cross-domain insights into the\nrepresentations, revealing that symbolic supervision enhances the embeddings of\nnumeric data and vice versa. We evaluate SNIP across diverse tasks, including\nsymbolic-to-numeric mathematical property prediction and numeric-to-symbolic\nequation discovery, commonly known as symbolic regression. Results show that\nSNIP effectively transfers to various tasks, consistently outperforming fully\nsupervised baselines and competing strongly with established task-specific\nmethods, especially in few-shot learning scenarios where available data is\nlimited.",
          "link": "http://arxiv.org/abs/2310.02227",
          "publishedOn": "2023-10-21T00:41:43.274Z",
          "wordCount": null,
          "title": "SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training. (arXiv:2310.02227v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiaobin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Benben Jiang</a>",
          "description": "Bayesian optimization (BO) is widely used for black-box optimization\nproblems, and have been shown to perform well in various real-world tasks.\nHowever, most of the existing BO methods aim to learn the optimal solution,\nwhich may become infeasible when the parameter space is extremely large or the\nproblem is time-sensitive. In these contexts, switching to a satisficing\nsolution that requires less information can result in better performance. In\nthis work, we focus on time-sensitive black-box optimization problems and\npropose satisficing Thompson sampling-based parallel Bayesian optimization\n(STS-PBO) approaches, including synchronous and asynchronous versions. We shift\nthe target from an optimal solution to a satisficing solution that is easier to\nlearn. The rate-distortion theory is introduced to construct a loss function\nthat balances the amount of information that needs to be learned with\nsub-optimality, and the Blahut-Arimoto algorithm is adopted to compute the\ntarget solution that reaches the minimum information rate under the distortion\nlimit at each step. Both discounted and undiscounted Bayesian cumulative regret\nbounds are theoretically derived for the proposed STS-PBO approaches. The\neffectiveness of the proposed methods is demonstrated on a fast-charging design\nproblem of Lithium-ion batteries. The results are accordant with theoretical\nanalyses, and show that our STS-PBO methods outperform both sequential\ncounterparts and parallel BO with traditional Thompson sampling in both\nsynchronous and asynchronous settings.",
          "link": "http://arxiv.org/abs/2310.12526",
          "publishedOn": "2023-10-21T00:41:43.223Z",
          "wordCount": null,
          "title": "Parallel Bayesian Optimization Using Satisficing Thompson Sampling for Time-Sensitive Black-Box Optimization. (arXiv:2310.12526v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12447",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_A/0/1/0/all/0/1\">Abhisek Chakraborty</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Anirban Bhattacharya</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pati_D/0/1/0/all/0/1\">Debdeep Pati</a>",
          "description": "We commonly encounter the problem of identifying an optimally weight adjusted\nversion of the empirical distribution of observed data, adhering to predefined\nconstraints on the weights. Such constraints often manifest as restrictions on\nthe moments, tail behaviour, shapes, number of modes, etc., of the resulting\nweight adjusted empirical distribution. In this article, we substantially\nenhance the flexibility of such methodology by introducing a nonparametrically\nimbued distributional constraints on the weights, and developing a general\nframework leveraging the maximum entropy principle and tools from optimal\ntransport. The key idea is to ensure that the maximum entropy weight adjusted\nempirical distribution of the observed data is close to a pre-specified\nprobability distribution in terms of the optimal transport metric while\nallowing for subtle departures. The versatility of the framework is\ndemonstrated in the context of three disparate applications where data\nre-weighting is warranted to satisfy side constraints on the optimization\nproblem at the heart of the statistical task: namely, portfolio allocation,\nsemi-parametric inference for complex surveys, and ensuring algorithmic\nfairness in machine learning algorithms.",
          "link": "http://arxiv.org/abs/2310.12447",
          "publishedOn": "2023-10-21T00:41:43.220Z",
          "wordCount": null,
          "title": "Constrained Reweighting of Distributions: an Optimal Transport Approach. (arXiv:2310.12447v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12069",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Tanoglidis_D/0/1/0/all/0/1\">Dimitrios Tanoglidis</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Jain_B/0/1/0/all/0/1\">Bhuvnesh Jain</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Qu_H/0/1/0/all/0/1\">Helen Qu</a> (University of Pennsylvania)",
          "description": "The deep learning architecture associated with ChatGPT and related generative\nAI products is known as transformers. Initially applied to Natural Language\nProcessing, transformers and the self-attention mechanism they exploit have\ngained widespread interest across the natural sciences. The goal of this\npedagogical and informal review is to introduce transformers to scientists. The\nreview includes the mathematics underlying the attention mechanism, a\ndescription of the original transformer architecture, and a section on\napplications to time series and imaging data in astronomy. We include a\nFrequently Asked Questions section for readers who are curious about generative\nAI or interested in getting started with transformers for their research\nproblem.",
          "link": "http://arxiv.org/abs/2310.12069",
          "publishedOn": "2023-10-21T00:41:43.220Z",
          "wordCount": null,
          "title": "Transformers for scientific data: a pedagogical review for astronomers. (arXiv:2310.12069v2 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yufei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Siyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jin Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lirong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_O/0/1/0/all/0/1\">Odin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haitao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jingqi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhangyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1\">Jiangbin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan.ZQ.Li</a>",
          "description": "Protein structure-based property prediction has emerged as a promising\napproach for various biological tasks, such as protein function prediction and\nsub-cellular location estimation. The existing methods highly rely on\nexperimental protein structure data and fail in scenarios where these data are\nunavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were\nutilized as alternatives. However, we observed that current practices, which\nsimply employ accurately predicted structures during inference, suffer from\nnotable degradation in prediction accuracy. While similar phenomena have been\nextensively studied in general fields (e.g., Computer Vision) as model\nrobustness, their impact on protein property prediction remains unexplored. In\nthis paper, we first investigate the reason behind the performance decrease\nwhen utilizing predicted structures, attributing it to the structure embedding\nbias from the perspective of structure representation learning. To study this\nproblem, we identify a Protein 3D Graph Structure Learning Problem for Robust\nProtein Property Prediction (PGSL-RP3), collect benchmark datasets, and present\na protein Structure embedding Alignment Optimization framework (SAO) to\nmitigate the problem of structure embedding bias between the predicted and\nexperimental protein structures. Extensive experiments have shown that our\nframework is model-agnostic and effective in improving the property prediction\nof both predicted structures and experimental structures. The benchmark\ndatasets and codes will be released to benefit the community.",
          "link": "http://arxiv.org/abs/2310.11466",
          "publishedOn": "2023-10-21T00:41:43.213Z",
          "wordCount": null,
          "title": "Protein 3D Graph Structure Learning for Robust Structure-based Protein Property Prediction. (arXiv:2310.11466v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jiyuan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenzhuo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1\">Kwok-Yan Lam</a>",
          "description": "Training a large and state-of-the-art machine learning model typically\nnecessitates the use of large-scale datasets, which, in turn, makes the\ntraining and parameter-tuning process expensive and time-consuming. Some\nresearchers opt to distil information from real-world datasets into tiny and\ncompact synthetic datasets while maintaining their ability to train a\nwell-performing model, hence proposing a data-efficient method known as Dataset\nDistillation (DD). Despite recent progress in this field, existing methods\nstill underperform and cannot effectively replace large datasets. In this\npaper, unlike previous methods that focus solely on improving the efficacy of\nstudent distillation, we are the first to recognize the important interplay\nbetween expert and student. We argue the significant impact of expert\nsmoothness when employing more potent expert trajectories in subsequent dataset\ndistillation. Based on this, we introduce the integration of clipping loss and\ngradient penalty to regulate the rate of parameter changes in expert\ntrajectories. Furthermore, in response to the sensitivity exhibited towards\nrandomly initialized variables during distillation, we propose representative\ninitialization for synthetic dataset and balanced inner-loop loss. Finally, we\npresent two enhancement strategies, namely intermediate matching loss and\nweight perturbation, to mitigate the potential occurrence of cumulative errors.\nWe conduct extensive experiments on datasets of different scales, sizes, and\nresolutions. The results demonstrate that the proposed method significantly\noutperforms prior methods.",
          "link": "http://arxiv.org/abs/2310.10541",
          "publishedOn": "2023-10-21T00:41:43.213Z",
          "wordCount": null,
          "title": "Efficient Dataset Distillation through Alignment with Smooth and High-Quality Expert Trajectories. (arXiv:2310.10541v1 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.10194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+McCarter_C/0/1/0/all/0/1\">Calvin McCarter</a>",
          "description": "Feature preprocessing continues to play a critical role when applying machine\nlearning and statistical methods to tabular data. In this paper, we propose the\nuse of the kernel density integral transformation as a feature preprocessing\nstep. Our approach subsumes the two leading feature preprocessing methods as\nlimiting cases: linear min-max scaling and quantile transformation. We\ndemonstrate that, without hyperparameter tuning, the kernel density integral\ntransformation can be used as a simple drop-in replacement for either method,\noffering protection from the weaknesses of each. Alternatively, with tuning of\na single continuous hyperparameter, we frequently outperform both of these\nmethods. Finally, we show that the kernel density transformation can be\nprofitably applied to statistical data analysis, particularly in correlation\nanalysis and univariate clustering.",
          "link": "http://arxiv.org/abs/2309.10194",
          "publishedOn": "2023-10-21T00:41:43.204Z",
          "wordCount": null,
          "title": "The Kernel Density Integral Transformation. (arXiv:2309.10194v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rouhani_B/0/1/0/all/0/1\">Bita Darvish Rouhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Ritchie Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+More_A/0/1/0/all/0/1\">Ankit More</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_M/0/1/0/all/0/1\">Mathew Hall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khodamoradi_A/0/1/0/all/0/1\">Alireza Khodamoradi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Summer Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_D/0/1/0/all/0/1\">Dhruv Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornea_M/0/1/0/all/0/1\">Marius Cornea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dellinger_E/0/1/0/all/0/1\">Eric Dellinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denolf_K/0/1/0/all/0/1\">Kristof Denolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusan_S/0/1/0/all/0/1\">Stosic Dusan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elango_V/0/1/0/all/0/1\">Venmugil Elango</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golub_M/0/1/0/all/0/1\">Maximilian Golub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinecke_A/0/1/0/all/0/1\">Alexander Heinecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_Roxby_P/0/1/0/all/0/1\">Phil James-Roxby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jani_D/0/1/0/all/0/1\">Dharmesh Jani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolhe_G/0/1/0/all/0/1\">Gaurav Kolhe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langhammer_M/0/1/0/all/0/1\">Martin Langhammer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ada Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melnick_L/0/1/0/all/0/1\">Levi Melnick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mesmakhosroshahi_M/0/1/0/all/0/1\">Maral Mesmakhosroshahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Andres Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulte_M/0/1/0/all/0/1\">Michael Schulte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafipour_R/0/1/0/all/0/1\">Rasoul Shafipour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Lei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siu_M/0/1/0/all/0/1\">Michael Siu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_P/0/1/0/all/0/1\">Pradeep Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micikevicius_P/0/1/0/all/0/1\">Paulius Micikevicius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumov_M/0/1/0/all/0/1\">Maxim Naumov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verrilli_C/0/1/0/all/0/1\">Colin Verrilli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wittig_R/0/1/0/all/0/1\">Ralph Wittig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burger_D/0/1/0/all/0/1\">Doug Burger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_E/0/1/0/all/0/1\">Eric Chung</a>",
          "description": "Narrow bit-width data formats are key to reducing the computational and\nstorage costs of modern deep learning applications. This paper evaluates\nMicroscaling (MX) data formats that combine a per-block scaling factor with\nnarrow floating-point and integer types for individual elements. MX formats\nbalance the competing needs of hardware efficiency, model accuracy, and user\nfriction. Empirical results on over two dozen benchmarks demonstrate\npracticality of MX data formats as a drop-in replacement for baseline FP32 for\nAI inference and training with low user friction. We also show the first\ninstance of training generative language models at sub-8-bit weights,\nactivations, and gradients with minimal accuracy loss and no modifications to\nthe training recipe.",
          "link": "http://arxiv.org/abs/2310.10537",
          "publishedOn": "2023-10-21T00:41:43.204Z",
          "wordCount": null,
          "title": "Microscaling Data Formats for Deep Learning. (arXiv:2310.10537v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yuan Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1\">Wenbin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zhiheng Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haoran Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>",
          "description": "The success of AI assistants based on language models (LLMs) hinges crucially\non Reinforcement Learning from Human Feedback (RLHF), which enables the\ngeneration of responses more aligned with human preferences. As universal AI\nassistants, there's a growing expectation for them to perform consistently\nacross various domains. However, previous work shows that Reinforcement\nLearning (RL) often exploits shortcuts to attain high rewards and overlooks\nchallenging samples. This focus on quick reward gains undermines both the\nstability in training and the model's ability to generalize to new, unseen\ndata. In this work, we propose a novel approach that can learn a consistent\npolicy via RL across various data groups or domains. Given the challenges\nassociated with acquiring group annotations, our method automatically\nclassifies data into different groups, deliberately maximizing performance\nvariance. Then, we optimize the policy to perform well on challenging groups.\nLastly, leveraging the established groups, our approach adaptively adjusts the\nexploration space, allocating more learning capacity to more challenging data\nand preventing the model from over-optimizing on simpler data. Experimental\nresults indicate that our approach significantly enhances training stability\nand model generalization.",
          "link": "http://arxiv.org/abs/2310.11971",
          "publishedOn": "2023-10-21T00:41:43.201Z",
          "wordCount": null,
          "title": "Improving Generalization of Alignment with Human Preferences through Group Invariant Learning. (arXiv:2310.11971v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1\">Harshavardhan Kamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingkai Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Alexander Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1\">B. Aditya Prakash</a>",
          "description": "Probabilistic hierarchical time-series forecasting is an important variant of\ntime-series forecasting, where the goal is to model and forecast multivariate\ntime-series that have underlying hierarchical relations. Most methods focus on\npoint predictions and do not provide well-calibrated probabilistic forecasts\ndistributions. Recent state-of-art probabilistic forecasting methods also\nimpose hierarchical relations on point predictions and samples of distribution\nwhich does not account for coherency of forecast distributions. Previous works\nalso silently assume that datasets are always consistent with given\nhierarchical relations and do not adapt to real-world datasets that show\ndeviation from this assumption. We close both these gap and propose PROFHiT,\nwhich is a fully probabilistic hierarchical forecasting model that jointly\nmodels forecast distribution of entire hierarchy. PROFHiT uses a flexible\nprobabilistic Bayesian approach and introduces a novel Distributional Coherency\nregularization to learn from hierarchical relations for entire forecast\ndistribution that enables robust and calibrated forecasts as well as adapt to\ndatasets of varying hierarchical consistency. On evaluating PROFHiT over wide\nrange of datasets, we observed 41-88% better performance in accuracy and\nsignificantly better calibration. Due to modeling the coherency over full\ndistribution, we observed that PROFHiT can robustly provide reliable forecasts\neven if up to 10% of input time-series data is missing where other methods'\nperformance severely degrade by over 70%.",
          "link": "http://arxiv.org/abs/2310.11569",
          "publishedOn": "2023-10-21T00:41:43.198Z",
          "wordCount": null,
          "title": "When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting. (arXiv:2310.11569v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07587",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Zikai Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zihan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Songshang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hualiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jin Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Joey Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Howard Hao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zuozhu Liu</a>",
          "description": "Data privacy and long-tailed distribution are the norms rather than the\nexception in many real-world tasks. This paper investigates a federated\nlong-tailed learning (Fed-LT) task in which each client holds a locally\nheterogeneous dataset; if the datasets can be globally aggregated, they jointly\nexhibit a long-tailed distribution. Under such a setting, existing federated\noptimization and/or centralized long-tailed learning methods hardly apply due\nto challenges in (a) characterizing the global long-tailed distribution under\nprivacy constraints and (b) adjusting the local learning strategy to cope with\nthe head-tail imbalance. In response, we propose a method termed\n$\\texttt{Fed-GraB}$, comprised of a Self-adjusting Gradient Balancer (SGB)\nmodule that re-weights clients' gradients in a closed-loop manner, based on the\nfeedback of global long-tailed distribution evaluated by a Direct Prior\nAnalyzer (DPA) module. Using $\\texttt{Fed-GraB}$, clients can effectively\nalleviate the distribution drift caused by data heterogeneity during the model\ntraining process and obtain a global model with better performance on the\nminority classes while maintaining the performance of the majority classes.\nExtensive experiments demonstrate that $\\texttt{Fed-GraB}$ achieves\nstate-of-the-art performance on representative datasets such as CIFAR-10-LT,\nCIFAR-100-LT, ImageNet-LT, and iNaturalist.",
          "link": "http://arxiv.org/abs/2310.07587",
          "publishedOn": "2023-10-21T00:41:43.195Z",
          "wordCount": null,
          "title": "Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer. (arXiv:2310.07587v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pourcel_J/0/1/0/all/0/1\">Julien Pourcel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colas_C/0/1/0/all/0/1\">C&#xe9;dric Colas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teodorescu_L/0/1/0/all/0/1\">Laetitia Teodorescu</a>",
          "description": "Finding and selecting new and interesting problems to solve is at the heart\nof curiosity, science and innovation. We here study automated problem\ngeneration in the context of the open-ended space of python programming\npuzzles. Existing generative models often aim at modeling a reference\ndistribution without any explicit diversity optimization. Other methods\nexplicitly optimizing for diversity do so either in limited hand-coded\nrepresentation spaces or in uninterpretable learned embedding spaces that may\nnot align with human perceptions of interesting variations. With ACES\n(Autotelic Code Exploration via Semantic descriptors), we introduce a new\nautotelic generation method that leverages semantic descriptors produced by a\nlarge language model (LLM) to directly optimize for interesting diversity, as\nwell as few-shot-based generation. Each puzzle is labeled along 10 dimensions,\neach capturing a programming skill required to solve it. ACES generates and\npursues novel and feasible goals to explore that abstract semantic space,\nslowly discovering a diversity of solvable programming puzzles in any given\nrun. Across a set of experiments, we show that ACES discovers a richer\ndiversity of puzzles than existing diversity-maximizing algorithms as measured\nacross a range of diversity metrics. We further study whether and in which\nconditions this diversity can translate into the successful training of puzzle\nsolving models.",
          "link": "http://arxiv.org/abs/2310.10692",
          "publishedOn": "2023-10-21T00:41:43.192Z",
          "wordCount": null,
          "title": "ACES: Generating Diverse Programming Puzzles with Autotelic Language Models and Semantic Descriptors. (arXiv:2310.10692v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kirchhof_M/0/1/0/all/0/1\">Michael Kirchhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mucsanyi_B/0/1/0/all/0/1\">B&#xe1;lint Mucs&#xe1;nyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seong Joon Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1\">Enkelejda Kasneci</a>",
          "description": "Representation learning has significantly driven the field to develop\npretrained models that can act as a valuable starting point when transferring\nto new datasets. With the rising demand for reliable machine learning and\nuncertainty quantification, there is a need for pretrained models that not only\nprovide embeddings but also transferable uncertainty estimates. To guide the\ndevelopment of such models, we propose the Uncertainty-aware Representation\nLearning (URL) benchmark. Besides the transferability of the representations,\nit also measures the zero-shot transferability of the uncertainty estimate\nusing a novel metric. We apply URL to evaluate eleven uncertainty quantifiers\nthat are pretrained on ImageNet and transferred to eight downstream datasets.\nWe find that approaches that focus on the uncertainty of the representation\nitself or estimate the prediction risk directly outperform those that are based\non the probabilities of upstream classes. Yet, achieving transferable\nuncertainty quantification remains an open challenge. Our findings indicate\nthat it is not necessarily in conflict with traditional representation learning\ngoals. Code is provided under https://github.com/mkirchhof/url .",
          "link": "http://arxiv.org/abs/2307.03810",
          "publishedOn": "2023-10-21T00:41:43.191Z",
          "wordCount": null,
          "title": "URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates. (arXiv:2307.03810v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khalife_S/0/1/0/all/0/1\">Sammy Khalife</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_A/0/1/0/all/0/1\">Amitabh Basu</a>",
          "description": "In this article we present new results about the expressivity of Graph Neural\nNetworks (GNNs). We prove that for any GNN with piecewise polynomial\nactivations, whose architecture size does not grow with the graph input sizes,\nthere exists a pair of non-isomorphic rooted trees of depth two such that the\nGNN cannot distinguish their root vertex up to an arbitrary number of\niterations. The proof relies on tools from the algebra of symmetric\npolynomials. In contrast, it was already known that unbounded GNNs (those whose\nsize is allowed to change with the graph sizes) with piecewise polynomial\nactivations can distinguish these vertices in only two iterations. Our results\nimply a strict separation between bounded and unbounded size GNNs, answering an\nopen question formulated by [Grohe, 2021]. We next prove that if one allows\nactivations that are not piecewise polynomial, then in two iterations a single\nneuron perceptron can distinguish the root vertices of any pair of\nnonisomorphic trees of depth two (our results hold for activations like the\nsigmoid, hyperbolic tan and others). This shows how the power of graph neural\nnetworks can change drastically if one changes the activation function of the\nneural networks. The proof of this result utilizes the Lindemann-Weierstrauss\ntheorem from transcendental number theory.",
          "link": "http://arxiv.org/abs/2307.04661",
          "publishedOn": "2023-10-21T00:41:43.191Z",
          "wordCount": null,
          "title": "On the power of graph neural networks and the role of the activation function. (arXiv:2307.04661v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Sewon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lomeli_M/0/1/0/all/0/1\">Maria Lomeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Margaret Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_V/0/1/0/all/0/1\">Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_S/0/1/0/all/0/1\">Scott Yih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>",
          "description": "Large language models (LMs) are currently trained to predict tokens given\ndocument prefixes, enabling them to directly perform long-form generation and\nprompting-style tasks which can be reduced to document completion. Existing\npretraining pipelines train LMs by concatenating random sets of short documents\nto create input contexts but the prior documents provide no signal for\npredicting the next document. We instead present In-Context Pretraining, a new\napproach where language models are pretrained on a sequence of related\ndocuments, thereby explicitly encouraging them to read and reason across\ndocument boundaries. We can do In-Context Pretraining by simply changing the\ndocument ordering so that each context contains related documents, and directly\napplying existing pretraining pipelines. However, this document sorting problem\nis challenging. There are billions of documents and we would like the sort to\nmaximize contextual similarity for every document without repeating any data.\nTo do this, we introduce approximate algorithms for finding related documents\nwith efficient nearest neighbor search and constructing coherent input contexts\nwith a graph traversal algorithm. Our experiments show In-Context Pretraining\noffers a simple and scalable approach to significantly enhance LMs'performance:\nwe see notable improvements in tasks that require more complex contextual\nreasoning, including in-context learning (+8%), reading comprehension (+15%),\nfaithfulness to previous contexts (+16%), long-context reasoning (+5%), and\nretrieval augmentation (+9%).",
          "link": "http://arxiv.org/abs/2310.10638",
          "publishedOn": "2023-10-21T00:41:43.190Z",
          "wordCount": null,
          "title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries. (arXiv:2310.10638v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yulan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhirui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1\">Sheng Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1\">Junchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fuzheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>",
          "description": "Generative self-supervised learning (SSL) has exhibited significant potential\nand garnered increasing interest in graph learning. In this study, we aim to\nexplore the problem of generative SSL in the context of heterogeneous graph\nlearning (HGL). The previous SSL approaches for heterogeneous graphs have\nprimarily relied on contrastive learning, necessitating the design of complex\nviews to capture heterogeneity. However, existing generative SSL methods have\nnot fully leveraged the capabilities of generative models to address the\nchallenges of HGL. In this paper, we present HGCVAE, a novel contrastive\nvariational graph auto-encoder that liberates HGL from the burden of intricate\nheterogeneity capturing. Instead of focusing on complicated heterogeneity,\nHGCVAE harnesses the full potential of generative SSL. HGCVAE innovatively\nconsolidates contrastive learning with generative SSL, introducing several key\ninnovations. Firstly, we employ a progressive mechanism to generate\nhigh-quality hard negative samples for contrastive learning, utilizing the\npower of variational inference. Additionally, we present a dynamic mask\nstrategy to ensure effective and stable learning. Moreover, we propose an\nenhanced scaled cosine error as the criterion for better attribute\nreconstruction. As an initial step in combining generative and contrastive SSL,\nHGCVAE achieves remarkable results compared to various state-of-the-art\nbaselines, confirming its superiority.",
          "link": "http://arxiv.org/abs/2310.11102",
          "publishedOn": "2023-10-21T00:41:43.190Z",
          "wordCount": null,
          "title": "HGCVAE: Integrating Generative and Contrastive Learning for Heterogeneous Graph Learning. (arXiv:2310.11102v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Przystupa_M/0/1/0/all/0/1\">Michael Przystupa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haghverd_F/0/1/0/all/0/1\">Faezeh Haghverd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagersand_M/0/1/0/all/0/1\">Martin Jagersand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tosatto_S/0/1/0/all/0/1\">Samuele Tosatto</a>",
          "description": "Movement primitives are trainable parametric models that reproduce robotic\nmovements starting from a limited set of demonstrations. Previous works\nproposed simple linear models that exhibited high sample efficiency and\ngeneralization power by allowing temporal modulation of movements (reproducing\nmovements faster or slower), blending (merging two movements into one),\nvia-point conditioning (constraining a movement to meet some particular\nvia-points) and context conditioning (generation of movements based on an\nobserved variable, e.g., position of an object). Previous works have proposed\nneural network-based motor primitive models, having demonstrated their capacity\nto perform tasks with some forms of input conditioning or time-modulation\nrepresentations. However, there has not been a single unified deep motor\nprimitive's model proposed that is capable of all previous operations, limiting\nneural motor primitive's potential applications. This paper proposes a deep\nmovement primitive architecture that encodes all the operations above and uses\na Bayesian context aggregator that allows a more sound context conditioning and\nblending. Our results demonstrate our approach can scale to reproduce complex\nmotions on a larger variety of input choices compared to baselines while\nmaintaining operations of linear movement primitives provide.",
          "link": "http://arxiv.org/abs/2307.05141",
          "publishedOn": "2023-10-21T00:41:43.174Z",
          "wordCount": null,
          "title": "Deep Probabilistic Movement Primitives with a Bayesian Aggregator. (arXiv:2307.05141v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05270",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1\">Mohsin Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teja_K/0/1/0/all/0/1\">Kandukuri Sai Teja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1\">Neeharika Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patwa_P/0/1/0/all/0/1\">Parth Patwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1\">Anubhab Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1\">Vinija Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>",
          "description": "The mixing of two or more languages is called Code-Mixing (CM). CM is a\nsocial norm in multilingual societies. Neural Language Models (NLMs) like\ntransformers have been effective on many NLP tasks. However, NLM for CM is an\nunder-explored area. Though transformers are capable and powerful, they cannot\nalways encode positional information since they are non-recurrent. Therefore,\nto enrich word information and incorporate positional information, positional\nencoding is defined. We hypothesize that Switching Points (SPs), i.e.,\njunctions in the text where the language switches (L1 -> L2 or L2 -> L1), pose\na challenge for CM Language Models (LMs), and hence give special emphasis to\nSPs in the modeling process. We experiment with several positional encoding\nmechanisms and show that rotatory positional encodings along with switching\npoint information yield the best results.\n\nWe introduce CONFLATOR: a neural language modeling approach for code-mixed\nlanguages. CONFLATOR tries to learn to emphasize switching points using smarter\npositional encoding, both at unigram and bigram levels. CONFLATOR outperforms\nthe state-of-the-art on two tasks based on code-mixed Hindi and English\n(Hinglish): (i) sentiment analysis and (ii) machine translation.",
          "link": "http://arxiv.org/abs/2309.05270",
          "publishedOn": "2023-10-21T00:41:43.150Z",
          "wordCount": null,
          "title": "CONFLATOR: Incorporating Switching Point based Rotatory Positional Encodings for Code-Mixed Language Modeling. (arXiv:2309.05270v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.09983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fluri_L/0/1/0/all/0/1\">Lukas Fluri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paleka_D/0/1/0/all/0/1\">Daniel Paleka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tramer_F/0/1/0/all/0/1\">Florian Tram&#xe8;r</a>",
          "description": "If machine learning models were to achieve superhuman abilities at various\nreasoning or decision-making tasks, how would we go about evaluating such\nmodels, given that humans would necessarily be poor proxies for ground truth?\nIn this paper, we propose a framework for evaluating superhuman models via\nconsistency checks. Our premise is that while the correctness of superhuman\ndecisions may be impossible to evaluate, we can still surface mistakes if the\nmodel's decisions fail to satisfy certain logical, human-interpretable rules.\nWe instantiate our framework on three tasks where correctness of decisions is\nhard to evaluate due to either superhuman model abilities, or to otherwise\nmissing ground truth: evaluating chess positions, forecasting future events,\nand making legal judgments. We show that regardless of a model's (possibly\nsuperhuman) performance on these tasks, we can discover logical inconsistencies\nin decision making. For example: a chess engine assigning opposing valuations\nto semantically identical boards; GPT-4 forecasting that sports records will\nevolve non-monotonically over time; or an AI judge assigning bail to a\ndefendant only after we add a felony to their criminal record.",
          "link": "http://arxiv.org/abs/2306.09983",
          "publishedOn": "2023-10-21T00:41:43.139Z",
          "wordCount": null,
          "title": "Evaluating Superhuman Models with Consistency Checks. (arXiv:2306.09983v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhenmei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Junyi Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingyu Liang</a>",
          "description": "Neural networks have achieved remarkable empirical performance, while the\ncurrent theoretical analysis is not adequate for understanding their success,\ne.g., the Neural Tangent Kernel approach fails to capture their key feature\nlearning ability, while recent analyses on feature learning are typically\nproblem-specific. This work proposes a unified analysis framework for two-layer\nnetworks trained by gradient descent. The framework is centered around the\nprinciple of feature learning from gradients, and its effectiveness is\ndemonstrated by applications in several prototypical problems, such as mixtures\nof Gaussians and parity functions. The framework also sheds light on\ninteresting network learning phenomena such as feature learning beyond kernels\nand the lottery ticket hypothesis.",
          "link": "http://arxiv.org/abs/2310.12408",
          "publishedOn": "2023-10-21T00:41:43.129Z",
          "wordCount": null,
          "title": "Provable Guarantees for Neural Networks via Gradient Feature Learning. (arXiv:2310.12408v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kini_G/0/1/0/all/0/1\">Ganesh Ramachandra Kini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakilian_V/0/1/0/all/0/1\">Vala Vakilian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behnia_T/0/1/0/all/0/1\">Tina Behnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gill_J/0/1/0/all/0/1\">Jaidev Gill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "Supervised contrastive loss (SCL) is a competitive and often superior\nalternative to the cross-entropy loss for classification. While prior studies\nhave demonstrated that both losses yield symmetric training representations\nunder balanced data, this symmetry breaks under class imbalances. This paper\npresents an intriguing discovery: the introduction of a ReLU activation at the\nfinal layer effectively restores the symmetry in SCL-learned representations.\nWe arrive at this finding analytically, by establishing that the global\nminimizers of an unconstrained features model with SCL loss and entry-wise\nnon-negativity constraints form an orthogonal frame. Extensive experiments\nconducted across various datasets, architectures, and imbalance scenarios\ncorroborate our finding. Importantly, our experiments reveal that the inclusion\nof the ReLU activation restores symmetry without compromising test accuracy.\nThis constitutes the first geometry characterization of SCL under imbalances.\nAdditionally, our analysis and experiments underscore the pivotal role of batch\nselection strategies in representation geometry. By proving necessary and\nsufficient conditions for mini-batch choices that ensure invariant symmetric\nrepresentations, we introduce batch-binding as an efficient strategy that\nguarantees these conditions hold.",
          "link": "http://arxiv.org/abs/2306.07960",
          "publishedOn": "2023-10-21T00:41:43.111Z",
          "wordCount": null,
          "title": "Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching. (arXiv:2306.07960v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1\">Reid Pryzant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iter_D/0/1/0/all/0/1\">Dan Iter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yin Tat Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>",
          "description": "Large Language Models (LLMs) have shown impressive performance as general\npurpose agents, but their abilities remain highly dependent on prompts which\nare hand written with onerous trial-and-error effort. We propose a simple and\nnonparametric solution to this problem, Automatic Prompt Optimization (APO),\nwhich is inspired by numerical gradient descent to automatically improve\nprompts, assuming access to training data and an LLM API. The algorithm uses\nminibatches of data to form natural language \"gradients\" that criticize the\ncurrent prompt. The gradients are then \"propagated\" into the prompt by editing\nthe prompt in the opposite semantic direction of the gradient. These gradient\ndescent steps are guided by a beam search and bandit selection procedure which\nsignificantly improves algorithmic efficiency. Preliminary results across three\nbenchmark NLP tasks and the novel problem of LLM jailbreak detection suggest\nthat Automatic Prompt Optimization can outperform prior prompt editing\ntechniques and improve an initial prompt's performance by up to 31%, by using\ndata to rewrite vague task descriptions into more precise annotation\ninstructions.",
          "link": "http://arxiv.org/abs/2305.03495",
          "publishedOn": "2023-10-21T00:41:43.107Z",
          "wordCount": null,
          "title": "Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search. (arXiv:2305.03495v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_Z/0/1/0/all/0/1\">Ziyi Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koulieris_G/0/1/0/all/0/1\">George Alex Koulieris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1\">Hubert P. H. Shum</a>",
          "description": "Diffusion models are generative models, which gradually add and remove noise\nto learn the underlying distribution of training data for data generation. The\ncomponents of diffusion models have gained significant attention with many\ndesign choices proposed. Existing reviews have primarily focused on\nhigher-level solutions, thereby covering less on the design fundamentals of\ncomponents. This study seeks to address this gap by providing a comprehensive\nand coherent review on component-wise design choices in diffusion models.\nSpecifically, we organize this review according to their three key components,\nnamely the forward process, the reverse process, and the sampling procedure.\nThis allows us to provide a fine-grained perspective of diffusion models,\nbenefiting future studies in the analysis of individual components, the\napplicability of design choices, and the implementation of diffusion models.",
          "link": "http://arxiv.org/abs/2306.04542",
          "publishedOn": "2023-10-21T00:41:43.107Z",
          "wordCount": null,
          "title": "On the Design Fundamentals of Diffusion Models: A Survey. (arXiv:2306.04542v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.00477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1\">Baohao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Shaomu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1\">Christof Monz</a>",
          "description": "Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs)\nhas emerged as a highly successful approach, with training only a small number\nof parameters without sacrificing performance and becoming the de-facto\nlearning paradigm with the increasing size of PLMs. However, existing PEFT\nmethods are not memory-efficient, because they still require caching most of\nthe intermediate activations for the gradient calculation, akin to fine-tuning.\nOne effective way to reduce the activation memory is to apply a reversible\nmodel, so the intermediate activations are not necessary to be cached and can\nbe recomputed. Nevertheless, modifying a PLM to its reversible variant is not\nstraightforward, since the reversible model has a distinct architecture from\nthe currently released PLMs. In this paper, we first investigate what is a key\nfactor for the success of existing PEFT methods, and realize that it's\nessential to preserve the PLM's starting point when initializing a PEFT method.\nWith this finding, we propose memory-efficient fine-tuning (MEFT) that inserts\nadapters into a PLM, preserving the PLM's starting point and making it\nreversible without additional pre-training. We evaluate MEFT on the GLUE\nbenchmark and five question-answering tasks with various backbones, BERT,\nRoBERTa, BART and OPT. MEFT significantly reduces the activation memory up to\n84% of full fine-tuning with a negligible amount of trainable parameters.\nMoreover, MEFT achieves the same score on GLUE and a comparable score on the\nquestion-answering tasks as full fine-tuning. A similar finding is also\nobserved for the image classification task.",
          "link": "http://arxiv.org/abs/2306.00477",
          "publishedOn": "2023-10-21T00:41:43.106Z",
          "wordCount": null,
          "title": "Make Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v4 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vodrahalli_K/0/1/0/all/0/1\">Kailas Vodrahalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>",
          "description": "As generative AI becomes more prevalent, it is important to study how human\nusers interact with such models. In this work, we investigate how people use\ntext-to-image models to generate desired target images. To study this\ninteraction, we created ArtWhisperer, an online game where users are given a\ntarget image and are tasked with iteratively finding a prompt that creates a\nsimilar-looking image as the target. Through this game, we recorded over 50,000\nhuman-AI interactions; each interaction corresponds to one text prompt created\nby a user and the corresponding generated image. The majority of these are\nrepeated interactions where a user iterates to find the best prompt for their\ntarget image, making this a unique sequential dataset for studying human-AI\ncollaborations. In an initial analysis of this dataset, we identify several\ncharacteristics of prompt interactions and user strategies. People submit\ndiverse prompts and are able to discover a variety of text descriptions that\ngenerate similar images. Interestingly, prompt diversity does not decrease as\nusers find better prompts. We further propose a new metric to quantify the\nsteerability of AI using our dataset. We define steerability as the expected\nnumber of interactions required to adequately complete a task. We estimate this\nvalue by fitting a Markov chain for each target task and calculating the\nexpected time to reach an adequate score in the Markov chain. We quantify and\ncompare AI steerability across different types of target images and two\ndifferent models, finding that images of cities and natural world images are\nmore steerable than artistic and fantasy images. These findings provide\ninsights into human-AI interaction behavior, present a concrete method of\nassessing AI steerability, and demonstrate the general utility of the\nArtWhisperer dataset.",
          "link": "http://arxiv.org/abs/2306.08141",
          "publishedOn": "2023-10-21T00:41:43.100Z",
          "wordCount": null,
          "title": "ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations. (arXiv:2306.08141v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1\">Evan Unit Lim</a>",
          "description": "The Quasi Manhattan Wasserstein Distance (QMWD) is a metric designed to\nquantify the dissimilarity between two matrices by combining elements of the\nWasserstein Distance with specific transformations. It offers improved time and\nspace complexity compared to the Manhattan Wasserstein Distance (MWD) while\nmaintaining accuracy. QMWD is particularly advantageous for large datasets or\nsituations with limited computational resources. This article provides a\ndetailed explanation of QMWD, its computation, complexity analysis, and\ncomparisons with WD and MWD.",
          "link": "http://arxiv.org/abs/2310.12498",
          "publishedOn": "2023-10-21T00:41:43.093Z",
          "wordCount": null,
          "title": "Quasi Manhattan Wasserstein Distance. (arXiv:2310.12498v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hui_W/0/1/0/all/0/1\">Wendy Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_W/0/1/0/all/0/1\">Wai Kwong Lau</a>",
          "description": "This paper proposes the use of causal modeling to detect and mitigate\nalgorithmic bias. We provide a brief description of causal modeling and a\ngeneral overview of our approach. We then use the Adult dataset, which is\navailable for download from the UC Irvine Machine Learning Repository, to\ndevelop (1) a prediction model, which is treated as a black box, and (2) a\ncausal model for bias mitigation. In this paper, we focus on gender bias and\nthe problem of binary classification. We show that gender bias in the\nprediction model is statistically significant at the 0.05 level. We demonstrate\nthe effectiveness of the causal model in mitigating gender bias by\ncross-validation. Furthermore, we show that the overall classification accuracy\nis improved slightly. Our novel approach is intuitive, easy-to-use, and can be\nimplemented using existing statistical software tools such as \"lavaan\" in R.\nHence, it enhances explainability and promotes trust.",
          "link": "http://arxiv.org/abs/2310.12421",
          "publishedOn": "2023-10-21T00:41:43.092Z",
          "wordCount": null,
          "title": "Detecting and Mitigating Algorithmic Bias in Binary Classification using Causal Modeling. (arXiv:2310.12421v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.10744",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Duksang Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Overman_W/0/1/0/all/0/1\">William Overman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dabeen Lee</a>",
          "description": "This paper studies a long-term resource allocation problem over multiple\nperiods where each period requires a multi-stage decision-making process. We\nformulate the problem as an online allocation problem in an episodic\nfinite-horizon constrained Markov decision process with an unknown\nnon-stationary transition function and stochastic non-stationary reward and\nresource consumption functions. We propose the observe-then-decide regime and\nimprove the existing decide-then-observe regime, while the two settings differ\nin how the observations and feedback about the reward and resource consumption\nfunctions are given to the decision-maker. We develop an online dual mirror\ndescent algorithm that achieves near-optimal regret bounds for both settings.\nFor the observe-then-decide regime, we prove that the expected regret against\nthe dynamic clairvoyant optimal policy is bounded by $\\tilde\nO(\\rho^{-1}{H^{3/2}}S\\sqrt{AT})$ where $\\rho\\in(0,1)$ is the budget parameter,\n$H$ is the length of the horizon, $S$ and $A$ are the numbers of states and\nactions, and $T$ is the number of episodes. For the decide-then-observe regime,\nwe show that the regret against the static optimal policy that has access to\nthe mean reward and mean resource consumption functions is bounded by $\\tilde\nO(\\rho^{-1}{H^{3/2}}S\\sqrt{AT})$ with high probability. We test the numerical\nefficiency of our method for a variant of the resource-constrained inventory\nmanagement problem.",
          "link": "http://arxiv.org/abs/2305.10744",
          "publishedOn": "2023-10-21T00:41:43.092Z",
          "wordCount": null,
          "title": "Online Resource Allocation in Episodic Markov Decision Processes. (arXiv:2305.10744v3 [cs.DS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Doshi_L/0/1/0/all/0/1\">Lyric Doshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_V/0/1/0/all/0/1\">Vincent Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_G/0/1/0/all/0/1\">Gaurav Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcus_R/0/1/0/all/0/1\">Ryan Marcus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haoyu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altinbuken_D/0/1/0/all/0/1\">Deniz Altinb&#xfc;ken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brevdo_E/0/1/0/all/0/1\">Eugene Brevdo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fraser_C/0/1/0/all/0/1\">Campbell Fraser</a>",
          "description": "Most existing parametric query optimization (PQO) techniques rely on\ntraditional query optimizer cost models, which are often inaccurate and result\nin suboptimal query performance. We propose Kepler, an end-to-end\nlearning-based approach to PQO that demonstrates significant speedups in query\nlatency over a traditional query optimizer. Central to our method is Row Count\nEvolution (RCE), a novel plan generation algorithm based on perturbations in\nthe sub-plan cardinality space. While previous approaches require accurate cost\nmodels, we bypass this requirement by evaluating candidate plans via actual\nexecution data and training an ML model to predict the fastest plan given\nparameter binding values. Our models leverage recent advances in neural network\nuncertainty in order to robustly predict faster plans while avoiding\nregressions in query performance. Experimentally, we show that Kepler achieves\nsignificant improvements in query runtime on multiple datasets on PostgreSQL.",
          "link": "http://arxiv.org/abs/2306.06798",
          "publishedOn": "2023-10-21T00:41:43.089Z",
          "wordCount": null,
          "title": "Kepler: Robust Learning for Faster Parametric Query Optimization. (arXiv:2306.06798v2 [cs.DB] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zehan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xize Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haifeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiageng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1\">Li Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_A/0/1/0/all/0/1\">Aoxiong Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhou Zhao</a>",
          "description": "Multi-modal Contrastive Representation learning aims to encode different\nmodalities into a semantically aligned shared space. This paradigm shows\nremarkable generalization ability on numerous downstream tasks across various\nmodalities. However, the reliance on massive high-quality data pairs limits its\nfurther development on more modalities. This paper proposes a novel\ntraining-efficient method for learning MCR without paired data called\nConnecting Multi-modal Contrastive Representations (C-MCR). Specifically, given\ntwo existing MCRs pre-trained on (A, B) and (B, C) modality pairs, we project\nthem to a new space and use the data from the overlapping modality B to\naligning the two MCRs in the new space. Meanwhile, since the modality pairs (A,\nB) and (B, C) are already aligned within each MCR, the connection learned by\noverlapping modality can also be transferred to non-overlapping modality pair\n(A, C). To unleash the potential of C-MCR, we further introduce a\nsemantic-enhanced inter- and intra-MCR connection method. We first enhance the\nsemantic consistency and completion of embeddings across different modalities\nfor more robust alignment. Then we utilize the inter-MCR alignment to establish\nthe connection, and employ the intra-MCR alignment to better maintain the\nconnection for inputs from non-overlapping modalities. To demonstrate the\neffectiveness of C-MCR, we connect CLIP and CLAP via texts to derive\naudio-visual representations, and integrate CLIP and ULIP via images for\n3D-language representations. Remarkably, without using any paired data, C-MCR\nfor audio-visual achieves state-of-the-art performance on audio-image\nretrieval, audio-visual source localization, and counterfactual audio-image\nrecognition tasks. Furthermore, C-MCR for 3D-language also attains advanced\nzero-shot 3D point cloud classification accuracy on ModelNet40.",
          "link": "http://arxiv.org/abs/2305.14381",
          "publishedOn": "2023-10-21T00:41:43.078Z",
          "wordCount": null,
          "title": "Connecting Multi-modal Contrastive Representations. (arXiv:2305.14381v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.05799",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Flynn_A/0/1/0/all/0/1\">Andrew Flynn</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tsachouridis_V/0/1/0/all/0/1\">Vassilios A. Tsachouridis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Amann_A/0/1/0/all/0/1\">Andreas Amann</a>",
          "description": "Multifunctional biological neural networks exploit multistability in order to\nperform multiple tasks without changing any network properties. Enabling\nartificial neural networks (ANNs) to obtain certain multistabilities in order\nto perform several tasks, where each task is related to a particular attractor\nin the network's state space, naturally has many benefits from a machine\nlearning perspective. Given the association to multistability, in this paper we\nexplore how the relationship between different attractors influences the\nability of a reservoir computer (RC), which is a dynamical system in the form\nof an ANN, to achieve multifunctionality. We construct the `seeing double'\nproblem to systematically study how a RC reconstructs a coexistence of\nattractors when there is an overlap between them. As the amount of overlap\nincreases, we discover that for multifunctionality to occur, there is a\ncritical dependence on a suitable choice of the spectral radius for the RC's\ninternal network connections. A bifurcation analysis reveals how\nmultifunctionality emerges and is destroyed as the RC enters a chaotic regime\nthat can lead to chaotic itinerancy.",
          "link": "http://arxiv.org/abs/2305.05799",
          "publishedOn": "2023-10-21T00:41:43.076Z",
          "wordCount": null,
          "title": "Seeing double with a multifunctional reservoir computer. (arXiv:2305.05799v2 [math.DS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.09310",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mozafari_Majd_E/0/1/0/all/0/1\">Emadaldin Mozafari-Majd</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Koivunen_V/0/1/0/all/0/1\">Visa Koivunen</a>",
          "description": "This paper introduces a new regularized version of the robust\n$\\tau$-regression estimator for analyzing high-dimensional datasets subject to\ngross contamination in the response variables and covariates (explanatory\nvariables). The resulting estimator, termed adaptive $\\tau$-Lasso, is robust to\noutliers and high-leverage points. It also incorporates an adaptive\n$\\ell_1$-norm penalty term, which enables the selection of relevant variables\nand reduces the bias associated with large true regression coefficients. More\nspecifically, this adaptive $\\ell_1$-norm penalty term assigns a weight to each\nregression coefficient. For a fixed number of predictors $p$, we show that the\nadaptive $\\tau$-Lasso has the oracle property, ensuring both variable-selection\nconsistency and asymptotic normality. Asymptotic normality applies only to the\nentries of the regression vector corresponding to the true support, assuming\nknowledge of the true regression vector support. We characterize its robustness\nvia the finite-sample breakdown point and the influence function. We carry out\nextensive simulations and observe that the class of $\\tau$-Lasso estimators\nexhibits robustness and reliable performance in both contaminated and\nuncontaminated data settings. We also validate our theoretical findings on\nrobustness properties through simulation experiments. In the face of outliers\nand high-leverage points, the adaptive $\\tau$-Lasso and $\\tau$-Lasso estimators\nachieve the best performance or close-to-best performance in terms of\nprediction and variable selection accuracy compared to other competing\nregularized estimators for all scenarios considered in this study. Therefore,\nthe adaptive $\\tau$-Lasso and $\\tau$-Lasso estimators can be effectively\nemployed for a variety of sparse linear regression problems, particularly in\nhigh-dimensional settings and when the data is contaminated by outliers and\nhigh-leverage points.",
          "link": "http://arxiv.org/abs/2304.09310",
          "publishedOn": "2023-10-21T00:41:43.069Z",
          "wordCount": null,
          "title": "The Adaptive $\\tau$-Lasso: Robustness and Oracle Properties. (arXiv:2304.09310v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12547",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junghyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_G/0/1/0/all/0/1\">Gi-Cheon Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jaein Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Seoyun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_M/0/1/0/all/0/1\">Minjoon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Byoung-Tak Zhang</a>",
          "description": "Language-Conditioned Robotic Grasping (LCRG) aims to develop robots that\nground and grasp objects based on natural language instructions. While robots\ncapable of recognizing personal objects like \"my wallet\" can interact more\nnaturally with non-expert users, current LCRG systems primarily limit robots to\nunderstanding only generic expressions. To this end, we introduce a task\nscenario GraspMine with a novel dataset that aims to locate and grasp personal\nobjects given personal indicators via learning from a single human-robot\ninteraction. To address GraspMine, we propose Personalized Grasping Agent\n(PGA), that learns personal objects by propagating user-given information\nthrough a Reminiscence-a collection of raw images from the user's environment.\nSpecifically, PGA acquires personal object information by a user presenting a\npersonal object with its associated indicator, followed by PGA inspecting the\nobject by rotating it. Based on the acquired information, PGA pseudo-labels\nobjects in the Reminiscence by our proposed label propagation algorithm.\nHarnessing the information acquired from the interactions and the\npseudo-labeled objects in the Reminiscence, PGA adapts the object grounding\nmodel to grasp personal objects. Experiments on GraspMine show that PGA\nsignificantly outperforms baseline methods both in offline and online settings,\nsignifying its effectiveness and personalization applicability on real-world\nscenarios. Finally, qualitative analysis shows the effectiveness of PGA through\na detailed investigation of results in each phase.",
          "link": "http://arxiv.org/abs/2310.12547",
          "publishedOn": "2023-10-21T00:41:43.064Z",
          "wordCount": null,
          "title": "PGA: Personalizing Grasping Agents with Single Human-Robot Interaction. (arXiv:2310.12547v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12667",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Karimi_B/0/1/0/all/0/1\">Belhal Karimi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_J/0/1/0/all/0/1\">Jianwen Xie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>",
          "description": "We propose in this paper, STANLEY, a STochastic gradient ANisotropic LangEvin\ndYnamics, for sampling high dimensional data. With the growing efficacy and\npotential of Energy-Based modeling, also known as non-normalized probabilistic\nmodeling, for modeling a generative process of different natures of high\ndimensional data observations, we present an end-to-end learning algorithm for\nEnergy-Based models (EBM) with the purpose of improving the quality of the\nresulting sampled data points. While the unknown normalizing constant of EBMs\nmakes the training procedure intractable, resorting to Markov Chain Monte Carlo\n(MCMC) is in general a viable option. Realizing what MCMC entails for the EBM\ntraining, we propose in this paper, a novel high dimensional sampling method,\nbased on an anisotropic stepsize and a gradient-informed covariance matrix,\nembedded into a discretized Langevin diffusion. We motivate the necessity for\nan anisotropic update of the negative samples in the Markov Chain by the\nnonlinearity of the backbone of the EBM, here a Convolutional Neural Network.\nOur resulting method, namely STANLEY, is an optimization algorithm for training\nEnergy-Based models via our newly introduced MCMC method. We provide a\ntheoretical understanding of our sampling scheme by proving that the sampler\nleads to a geometrically uniformly ergodic Markov Chain. Several image\ngeneration experiments are provided in our paper to show the effectiveness of\nour method.",
          "link": "http://arxiv.org/abs/2310.12667",
          "publishedOn": "2023-10-21T00:41:43.064Z",
          "wordCount": null,
          "title": "STANLEY: Stochastic Gradient Anisotropic Langevin Dynamics for Learning Energy-Based Models. (arXiv:2310.12667v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.03098",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andrew_G/0/1/0/all/0/1\">Galen Andrew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kairouz_P/0/1/0/all/0/1\">Peter Kairouz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Sewoong Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprea_A/0/1/0/all/0/1\">Alina Oprea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McMahan_H/0/1/0/all/0/1\">H. Brendan McMahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suriyakumar_V/0/1/0/all/0/1\">Vinith Suriyakumar</a>",
          "description": "Privacy estimation techniques for differentially private (DP) algorithms are\nuseful for comparing against analytical bounds, or to empirically measure\nprivacy loss in settings where known analytical bounds are not tight. However,\nexisting privacy auditing techniques usually make strong assumptions on the\nadversary (e.g., knowledge of intermediate model iterates or the training data\ndistribution), are tailored to specific tasks, model architectures, or DP\nalgorithm, and/or require retraining the model many times (typically on the\norder of thousands). These shortcomings make deploying such techniques at scale\ndifficult in practice, especially in federated settings where model training\ncan take days or weeks. In this work, we present a novel ``one-shot'' approach\nthat can systematically address these challenges, allowing efficient auditing\nor estimation of the privacy loss of a model during the same, single training\nrun used to fit model parameters, and without requiring any a priori knowledge\nabout the model architecture, task, or DP training algorithm. We show that our\nmethod provides provably correct estimates for the privacy loss under the\nGaussian mechanism, and we demonstrate its performance on well-established FL\nbenchmark datasets under several adversarial threat models.",
          "link": "http://arxiv.org/abs/2302.03098",
          "publishedOn": "2023-10-21T00:41:43.059Z",
          "wordCount": null,
          "title": "One-shot Empirical Privacy Estimation for Federated Learning. (arXiv:2302.03098v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.06368",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hasan_T/0/1/0/all/0/1\">Tonmoy Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bunescu_R/0/1/0/all/0/1\">Razvan Bunescu</a>",
          "description": "A recommender system that optimizes its recommendations solely to fit a\nuser's history of ratings for consumed items can create a filter bubble,\nwherein the user does not get to experience items from novel, unseen\ncategories. One approach to mitigate this undesired behavior is to recommend\nitems with high potential for serendipity, namely surprising items that are\nlikely to be highly rated. In this paper, we propose a content-based\nformulation of serendipity that is rooted in Bayesian surprise and use it to\nmeasure the serendipity of items after they are consumed and rated by the user.\nWhen coupled with a collaborative-filtering component that identifies similar\nusers, this enables recommending items with high potential for serendipity. To\nfacilitate the evaluation of topic-level models for surprise and serendipity,\nwe introduce a dataset of book reading histories extracted from Goodreads,\ncontaining over 26 thousand users and close to 1.3 million books, where we\nmanually annotate 449 books read by 4 users in terms of their time-dependent,\ntopic-level surprise. Experimental evaluations show that models that use\nBayesian surprise correlate much better with the manual annotations of\ntopic-level surprise than distance-based heuristics, and also obtain better\nserendipitous item recommendation performance.",
          "link": "http://arxiv.org/abs/2308.06368",
          "publishedOn": "2023-10-21T00:41:43.055Z",
          "wordCount": null,
          "title": "Topic-Level Bayesian Surprise and Serendipity for Recommender Systems. (arXiv:2308.06368v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.04934",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Buehler_M/0/1/0/all/0/1\">Markus J. Buehler</a>",
          "description": "We report a flexible language-model based deep learning strategy, applied\nhere to solve complex forward and inverse problems in protein modeling, based\non an attention neural network that integrates transformer and graph\nconvolutional architectures in a causal multi-headed graph mechanism, to\nrealize a generative pretrained model. The model is applied to predict\nsecondary structure content (per-residue level and overall content), protein\nsolubility, and sequencing tasks. Further trained on inverse tasks, the model\nis rendered capable of designing proteins with these properties as target\nfeatures. The model is formulated as a general framework, completely\nprompt-based, and can be adapted for a variety of downstream tasks. We find\nthat adding additional tasks yields emergent synergies that the model exploits\nin improving overall performance, beyond what would be possible by training a\nmodel on each dataset alone. Case studies are presented to validate the method,\nyielding protein designs specifically focused on structural proteins, but also\nexploring the applicability in the design of soluble, antimicrobial\nbiomaterials. While our model is trained to ultimately perform 8 distinct\ntasks, with available datasets it can be extended to solve additional problems.\nIn a broader sense, this work illustrates a form of multiscale modeling that\nrelates a set of ultimate building blocks (here, byte-level utf8 characters\nthat define the nature of the physical system at hand) to complex output. This\nmateriomic scheme captures complex emergent relationships between universal\nbuilding block and resulting properties via a synergizing learning capacity to\nexpress a set of potentialities embedded in the knowledge used in training, via\nthe interplay of universality and diversity.",
          "link": "http://arxiv.org/abs/2305.04934",
          "publishedOn": "2023-10-21T00:41:43.054Z",
          "wordCount": null,
          "title": "Generative Pretrained Autoregressive Transformer Graph Neural Network applied to the Analysis and Discovery of Novel Proteins. (arXiv:2305.04934v2 [q-bio.BM] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rege_A/0/1/0/all/0/1\">Aniket Rege</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1\">Aditya Kusupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_S/0/1/0/all/0/1\">Sharan Ranjit S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1\">Alan Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qingqing Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>",
          "description": "Web-scale search systems learn an encoder to embed a given query which is\nthen hooked into an approximate nearest neighbor search (ANNS) pipeline to\nretrieve similar data points. To accurately capture tail queries and data\npoints, learned representations typically are rigid, high-dimensional vectors\nthat are generally used as-is in the entire ANNS pipeline and can lead to\ncomputationally expensive retrieval. In this paper, we argue that instead of\nrigid representations, different stages of ANNS can leverage adaptive\nrepresentations of varying capacities to achieve significantly better\naccuracy-compute trade-offs, i.e., stages of ANNS that can get away with more\napproximate computation should use a lower-capacity representation of the same\ndata point. To this end, we introduce AdANNS, a novel ANNS design framework\nthat explicitly leverages the flexibility of Matryoshka Representations. We\ndemonstrate state-of-the-art accuracy-compute trade-offs using novel\nAdANNS-based key ANNS building blocks like search data structures (AdANNS-IVF)\nand quantization (AdANNS-OPQ). For example on ImageNet retrieval, AdANNS-IVF is\nup to 1.5% more accurate than the rigid representations-based IVF at the same\ncompute budget; and matches accuracy while being up to 90x faster in wall-clock\ntime. For Natural Questions, 32-byte AdANNS-OPQ matches the accuracy of the\n64-byte OPQ baseline constructed using rigid representations -- same accuracy\nat half the cost! We further show that the gains from AdANNS translate to\nmodern-day composite ANNS indices that combine search structures and\nquantization. Finally, we demonstrate that AdANNS can enable inference-time\nadaptivity for compute-aware search on ANNS indices built non-adaptively on\nmatryoshka representations. Code is open-sourced at\nhttps://github.com/RAIVNLab/AdANNS.",
          "link": "http://arxiv.org/abs/2305.19435",
          "publishedOn": "2023-10-21T00:41:43.051Z",
          "wordCount": null,
          "title": "AdANNS: A Framework for Adaptive Semantic Search. (arXiv:2305.19435v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01225",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gonon_A/0/1/0/all/0/1\">Antoine Gonon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brisebarre_N/0/1/0/all/0/1\">Nicolas Brisebarre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Riccietti_E/0/1/0/all/0/1\">Elisa Riccietti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gribonval_R/0/1/0/all/0/1\">R&#xe9;mi Gribonval</a>",
          "description": "This work introduces the first toolkit around path-norms that is fully able\nto encompass general DAG ReLU networks with biases, skip connections and any\noperation based on the extraction of order statistics: max pooling, GroupSort\netc. This toolkit notably allows us to establish generalization bounds for\nmodern neural networks that are not only the most widely applicable path-norm\nbased ones, but also recover or beat the sharpest known bounds of this type.\nThese extended path-norms further enjoy the usual benefits of path-norms: ease\nof computation, invariance under the symmetries of the network, and improved\nsharpness on feedforward networks compared to the product of operators' norms,\nanother complexity measure most commonly used.\n\nThe versatility of the toolkit and its ease of implementation allow us to\nchallenge the concrete promises of path-norm-based generalization bounds, by\nnumerically evaluating the sharpest known bounds for ResNets on ImageNet.",
          "link": "http://arxiv.org/abs/2310.01225",
          "publishedOn": "2023-10-21T00:41:43.048Z",
          "wordCount": null,
          "title": "A path-norm toolkit for modern networks: consequences, promises and challenges. (arXiv:2310.01225v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.12467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingze Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chao Ma</a>",
          "description": "The training process of ReLU neural networks often exhibits complicated\nnonlinear phenomena. The nonlinearity of models and non-convexity of loss pose\nsignificant challenges for theoretical analysis. Therefore, most previous\ntheoretical works on the optimization dynamics of neural networks focus either\non local analysis (like the end of training) or approximate linear models (like\nNeural Tangent Kernel). In this work, we conduct a complete theoretical\ncharacterization of the training process of a two-layer ReLU network trained by\nGradient Flow on a linearly separable data. In this specific setting, our\nanalysis captures the whole optimization process starting from random\ninitialization to final convergence. Despite the relatively simple model and\ndata that we studied, we reveal four different phases from the whole training\nprocess showing a general simplifying-to-complicating learning trend. Specific\nnonlinear behaviors can also be precisely identified and captured\ntheoretically, such as initial condensation, saddle-to-plateau dynamics,\nplateau escape, changes of activation patterns, learning with increasing\ncomplexity, etc.",
          "link": "http://arxiv.org/abs/2305.12467",
          "publishedOn": "2023-10-21T00:41:43.044Z",
          "wordCount": null,
          "title": "Understanding Multi-phase Optimization Dynamics and Rich Nonlinear Behaviors of ReLU Networks. (arXiv:2305.12467v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.10557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>",
          "description": "The transformer is a neural network component that can be used to learn\nuseful representations of sequences or sets of data-points. The transformer has\ndriven recent advances in natural language processing, computer vision, and\nspatio-temporal modelling. There are many introductions to transformers, but\nmost do not contain precise mathematical descriptions of the architecture and\nthe intuitions behind the design choices are often also missing. Moreover, as\nresearch takes a winding path, the explanations for the components of the\ntransformer can be idiosyncratic. In this note we aim for a mathematically\nprecise, intuitive, and clean description of the transformer architecture. We\nwill not discuss training as this is rather standard. We assume that the reader\nis familiar with fundamental topics in machine learning including multi-layer\nperceptrons, linear transformations, softmax functions and basic probability.",
          "link": "http://arxiv.org/abs/2304.10557",
          "publishedOn": "2023-10-21T00:41:43.036Z",
          "wordCount": null,
          "title": "An Introduction to Transformers. (arXiv:2304.10557v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mingkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Shan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>",
          "description": "Self-supervised Learning (SSL) including the mainstream contrastive learning\nhas achieved great success in learning visual representations without data\nannotations. However, most methods mainly focus on the instance level\ninformation (\\ie, the different augmented images of the same instance should\nhave the same feature or cluster into the same class), but there is a lack of\nattention on the relationships between different instances. In this paper, we\nintroduce a novel SSL paradigm, which we term as relational self-supervised\nlearning (ReSSL) framework that learns representations by modeling the\nrelationship between different instances. Specifically, our proposed method\nemploys sharpened distribution of pairwise similarities among different\ninstances as \\textit{relation} metric, which is thus utilized to match the\nfeature embeddings of different augmentations. To boost the performance, we\nargue that weak augmentations matter to represent a more reliable relation, and\nleverage momentum strategy for practical efficiency. The designed asymmetric\npredictor head and an InfoNCE warm-up strategy enhance the robustness to\nhyper-parameters and benefit the resulting performance. Experimental results\nshow that our proposed ReSSL substantially outperforms the state-of-the-art\nmethods across different network architectures, including various lightweight\nnetworks (\\eg, EfficientNet and MobileNet).",
          "link": "http://arxiv.org/abs/2203.08717",
          "publishedOn": "2023-10-21T00:41:43.035Z",
          "wordCount": null,
          "title": "Relational Self-Supervised Learning. (arXiv:2203.08717v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.12410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brehmer_J/0/1/0/all/0/1\">Johann Brehmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bose_J/0/1/0/all/0/1\">Joey Bose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haan_P/0/1/0/all/0/1\">Pim de Haan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1\">Taco Cohen</a>",
          "description": "Embodied agents operate in a structured world, often solving tasks with\nspatial, temporal, and permutation symmetries. Most algorithms for planning and\nmodel-based reinforcement learning (MBRL) do not take this rich geometric\nstructure into account, leading to sample inefficiency and poor generalization.\nWe introduce the Equivariant Diffuser for Generating Interactions (EDGI), an\nalgorithm for MBRL and planning that is equivariant with respect to the product\nof the spatial symmetry group SE(3), the discrete-time translation group Z, and\nthe object permutation group Sn. EDGI follows the Diffuser framework (Janner et\nal., 2022) in treating both learning a world model and planning in it as a\nconditional generative modeling problem, training a diffusion model on an\noffline trajectory dataset. We introduce a new SE(3)xZxSn-equivariant diffusion\nmodel that supports multiple representations. We integrate this model in a\nplanning loop, where conditioning and classifier guidance let us softly break\nthe symmetry for specific tasks as needed. On object manipulation and\nnavigation tasks, EDGI is substantially more sample efficient and generalizes\nbetter across the symmetry group than non-equivariant models.",
          "link": "http://arxiv.org/abs/2303.12410",
          "publishedOn": "2023-10-21T00:41:43.035Z",
          "wordCount": null,
          "title": "EDGI: Equivariant Diffusion for Planning with Embodied Agents. (arXiv:2303.12410v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.10060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zijun Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lingbo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tianhua Xu</a>",
          "description": "Data Augmentation (DA) has emerged as an indispensable strategy in Time\nSeries Classification (TSC), primarily due to its capacity to amplify training\nsamples, thereby bolstering model robustness, diversifying datasets, and\ncurtailing overfitting. However, the current landscape of DA in TSC is plagued\nwith fragmented literature reviews, nebulous methodological taxonomies,\ninadequate evaluative measures, and a dearth of accessible, user-oriented\ntools. In light of these challenges, this study embarks on an exhaustive\ndissection of DA methodologies within the TSC realm. Our initial approach\ninvolved an extensive literature review spanning a decade, revealing that\ncontemporary surveys scarcely capture the breadth of advancements in DA for\nTSC, prompting us to meticulously analyze over 100 scholarly articles to\ndistill more than 60 unique DA techniques. This rigorous analysis precipitated\nthe formulation of a novel taxonomy, purpose-built for the intricacies of DA in\nTSC, categorizing techniques into five principal echelons:\nTransformation-Based, Pattern-Based, Generative, Decomposition-Based, and\nAutomated Data Augmentation. Our taxonomy promises to serve as a robust\nnavigational aid for scholars, offering clarity and direction in method\nselection. Addressing the conspicuous absence of holistic evaluations for\nprevalent DA techniques, we executed an all-encompassing empirical assessment,\nwherein upwards of 15 DA strategies were subjected to scrutiny across 8 UCR\ntime-series datasets, employing ResNet and a multi-faceted evaluation paradigm\nencompassing Accuracy, Method Ranking, and Residual Analysis, yielding a\nbenchmark accuracy of 88.94 +- 11.83%. Our investigation underscored the\ninconsistent efficacies of DA techniques, with...",
          "link": "http://arxiv.org/abs/2310.10060",
          "publishedOn": "2023-10-21T00:41:43.028Z",
          "wordCount": null,
          "title": "Data Augmentation for Time-Series Classification: An Extensive Empirical Study and Comprehensive Survey. (arXiv:2310.10060v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.06348",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Han_W/0/1/0/all/0/1\">William Han</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qiu_J/0/1/0/all/0/1\">Jielin Qiu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhu_J/0/1/0/all/0/1\">Jiacheng Zhu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xu_M/0/1/0/all/0/1\">Mengdi Xu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Weber_D/0/1/0/all/0/1\">Douglas Weber</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>",
          "description": "Brain Signals, such as Electroencephalography (EEG), and human languages have\nbeen widely explored independently for many downstream tasks, however, the\nconnection between them has not been well explored. In this study, we explore\nthe relationship and dependency between EEG and language. To study at the\nrepresentation level, we introduced \\textbf{MTAM}, a \\textbf{M}ultimodal\n\\textbf{T}ransformer \\textbf{A}lignment \\textbf{M}odel, to observe coordinated\nrepresentations between the two modalities. We used various relationship\nalignment-seeking techniques, such as Canonical Correlation Analysis and\nWasserstein Distance, as loss functions to transfigure features. On downstream\napplications, sentiment analysis and relation detection, we achieved new\nstate-of-the-art results on two datasets, ZuCo and K-EmoCon. Our method\nachieved an F1-score improvement of 1.7% on K-EmoCon and 9.3% on Zuco datasets\nfor sentiment analysis, and 7.4% on ZuCo for relation detection. In addition,\nwe provide interpretations of the performance improvement: (1) feature\ndistribution shows the effectiveness of the alignment module for discovering\nand encoding the relationship between EEG and language; (2) alignment weights\nshow the influence of different language semantics as well as EEG frequency\nfeatures; (3) brain topographical maps provide an intuitive demonstration of\nthe connectivity in the brain regions. Our code is available at\n\\url{https://github.com/Jason-Qiu/EEG_Language_Alignment}.",
          "link": "http://arxiv.org/abs/2208.06348",
          "publishedOn": "2023-10-21T00:41:43.027Z",
          "wordCount": null,
          "title": "Can Brain Signals Reveal Inner Alignment with Human Languages?. (arXiv:2208.06348v4 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12806",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gauss_J/0/1/0/all/0/1\">Jana Gauss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scheipl_F/0/1/0/all/0/1\">Fabian Scheipl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Herrmann_M/0/1/0/all/0/1\">Moritz Herrmann</a>",
          "description": "Whether class labels in a given data set correspond to meaningful clusters is\ncrucial for the evaluation of clustering algorithms using real-world data sets.\nThis property can be quantified by separability measures. A review of the\nexisting literature shows that neither classification-based complexity measures\nnor cluster validity indices (CVIs) adequately incorporate the central aspects\nof separability for density-based clustering: between-class separation and\nwithin-class connectedness. A newly developed measure (density cluster\nseparability index, DCSI) aims to quantify these two characteristics and can\nalso be used as a CVI. Extensive experiments on synthetic data indicate that\nDCSI correlates strongly with the performance of DBSCAN measured via the\nadjusted rand index (ARI) but lacks robustness when it comes to multi-class\ndata sets with overlapping classes that are ill-suited for density-based hard\nclustering. Detailed evaluation on frequently used real-world data sets shows\nthat DCSI can correctly identify touching or overlapping classes that do not\nform meaningful clusters.",
          "link": "http://arxiv.org/abs/2310.12806",
          "publishedOn": "2023-10-21T00:41:43.021Z",
          "wordCount": null,
          "title": "DCSI -- An improved measure of cluster separability based on separation and connectedness. (arXiv:2310.12806v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06344",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1\">Ziyuan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rempe_D/0/1/0/all/0/1\">Davis Rempe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxiao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivanovic_B/0/1/0/all/0/1\">Boris Ivanovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yulong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Danfei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1\">Baishakhi Ray</a>",
          "description": "Realistic and controllable traffic simulation is a core capability that is\nnecessary to accelerate autonomous vehicle (AV) development. However, current\napproaches for controlling learning-based traffic models require significant\ndomain expertise and are difficult for practitioners to use. To remedy this, we\npresent CTG++, a scene-level conditional diffusion model that can be guided by\nlanguage instructions. Developing this requires tackling two challenges: the\nneed for a realistic and controllable traffic model backbone, and an effective\nmethod to interface with a traffic model using language. To address these\nchallenges, we first propose a scene-level diffusion model equipped with a\nspatio-temporal transformer backbone, which generates realistic and\ncontrollable traffic. We then harness a large language model (LLM) to convert a\nuser's query into a loss function, guiding the diffusion model towards\nquery-compliant generation. Through comprehensive evaluation, we demonstrate\nthe effectiveness of our proposed method in generating realistic,\nquery-compliant traffic simulations.",
          "link": "http://arxiv.org/abs/2306.06344",
          "publishedOn": "2023-10-21T00:41:43.021Z",
          "wordCount": null,
          "title": "Language-Guided Traffic Simulation via Scene-Level Diffusion. (arXiv:2306.06344v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.15687",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Le_M/0/1/0/all/0/1\">Matthew Le</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vyas_A/0/1/0/all/0/1\">Apoorv Vyas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_B/0/1/0/all/0/1\">Bowen Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karrer_B/0/1/0/all/0/1\">Brian Karrer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sari_L/0/1/0/all/0/1\">Leda Sari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moritz_R/0/1/0/all/0/1\">Rashel Moritz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Williamson_M/0/1/0/all/0/1\">Mary Williamson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Manohar_V/0/1/0/all/0/1\">Vimal Manohar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mahadeokar_J/0/1/0/all/0/1\">Jay Mahadeokar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>",
          "description": "Large-scale generative models such as GPT and DALL-E have revolutionized the\nresearch community. These models not only generate high fidelity outputs, but\nare also generalists which can solve tasks not explicitly taught. In contrast,\nspeech generative models are still primitive in terms of scale and task\ngeneralization. In this paper, we present Voicebox, the most versatile\ntext-guided generative model for speech at scale. Voicebox is a\nnon-autoregressive flow-matching model trained to infill speech, given audio\ncontext and text, trained on over 50K hours of speech that are not filtered or\nenhanced. Similar to GPT, Voicebox can perform many different tasks through\nin-context learning, but is more flexible as it can also condition on future\ncontext. Voicebox can be used for mono or cross-lingual zero-shot\ntext-to-speech synthesis, noise removal, content editing, style conversion, and\ndiverse sample generation. In particular, Voicebox outperforms the\nstate-of-the-art zero-shot TTS model VALL-E on both intelligibility (5.9% vs\n1.9% word error rates) and audio similarity (0.580 vs 0.681) while being up to\n20 times faster. Audio samples can be found in\n\\url{https://voicebox.metademolab.com}.",
          "link": "http://arxiv.org/abs/2306.15687",
          "publishedOn": "2023-10-21T00:41:43.021Z",
          "wordCount": null,
          "title": "Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale. (arXiv:2306.15687v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingcheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haoran Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yuxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hulei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Hongqiao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zheng Tian</a>",
          "description": "Data-driven black-box model-based optimization (MBO) problems arise in a\ngreat number of practical application scenarios, where the goal is to find a\ndesign over the whole space maximizing a black-box target function based on a\nstatic offline dataset. In this work, we consider a more general but\nchallenging MBO setting, named constrained MBO (CoMBO), where only part of the\ndesign space can be optimized while the rest is constrained by the environment.\nA new challenge arising from CoMBO is that most observed designs that satisfy\nthe constraints are mediocre in evaluation. Therefore, we focus on optimizing\nthese mediocre designs in the offline dataset while maintaining the given\nconstraints rather than further boosting the best observed design in the\ntraditional MBO setting. We propose retrieval-enhanced offline model-based\noptimization (ROMO), a new derivable forward approach that retrieves the\noffline dataset and aggregates relevant samples to provide a trusted\nprediction, and use it for gradient-based optimization. ROMO is simple to\nimplement and outperforms state-of-the-art approaches in the CoMBO setting.\nEmpirically, we conduct experiments on a synthetic Hartmann (3D) function\ndataset, an industrial CIO dataset, and a suite of modified tasks in the\nDesign-Bench benchmark. Results show that ROMO performs well in a wide range of\nconstrained optimization tasks.",
          "link": "http://arxiv.org/abs/2310.07560",
          "publishedOn": "2023-10-21T00:41:43.021Z",
          "wordCount": null,
          "title": "ROMO: Retrieval-enhanced Offline Model-based Optimization. (arXiv:2310.07560v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Changhun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyungjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1\">Eunhyeok Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jae-Joon Kim</a>",
          "description": "Binary Neural Networks (BNNs) have emerged as a promising solution for\nreducing the memory footprint and compute costs of deep neural networks, but\nthey suffer from quality degradation due to the lack of freedom as activations\nand weights are constrained to the binary values. To compensate for the\naccuracy drop, we propose a novel BNN design called Binary Neural Network with\nINSTAnce-aware threshold (INSTA-BNN), which controls the quantization threshold\ndynamically in an input-dependent or instance-aware manner. According to our\nobservation, higher-order statistics can be a representative metric to estimate\nthe characteristics of the input distribution. INSTA-BNN is designed to adjust\nthe threshold dynamically considering various information, including\nhigher-order statistics, but it is also optimized judiciously to realize\nminimal overhead on a real device. Our extensive study shows that INSTA-BNN\noutperforms the baseline by 3.0% and 2.8% on the ImageNet classification task\nwith comparable computing cost, achieving 68.5% and 72.2% top-1 accuracy on\nResNet-18 and MobileNetV1 based models, respectively.",
          "link": "http://arxiv.org/abs/2204.07439",
          "publishedOn": "2023-10-21T00:41:43.020Z",
          "wordCount": null,
          "title": "INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold. (arXiv:2204.07439v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuelong Li</a>",
          "description": "Spectral clustering and its extensions usually consist of two steps: (1)\nconstructing a graph and computing the relaxed solution; (2) discretizing\nrelaxed solutions. Although the former has been extensively investigated, the\ndiscretization techniques are mainly heuristic methods, e.g., k-means, spectral\nrotation. Unfortunately, the goal of the existing methods is not to find a\ndiscrete solution that minimizes the original objective. In other words, the\nprimary drawback is the neglect of the original objective when computing the\ndiscrete solution. Inspired by the first-order optimization algorithms, we\npropose to develop a first-order term to bridge the original problem and\ndiscretization algorithm, which is the first non-heuristic to the best of our\nknowledge. Since the non-heuristic method is aware of the original graph cut\nproblem, the final discrete solution is more reliable and achieves the\npreferable loss value. We also theoretically show that the continuous optimum\nis beneficial to discretization algorithms though simply finding its closest\ndiscrete solution is an existing heuristic algorithm which is also unreliable.\nSufficient experiments significantly show the superiority of our method.",
          "link": "http://arxiv.org/abs/2310.12752",
          "publishedOn": "2023-10-21T00:41:43.005Z",
          "wordCount": null,
          "title": "Discretize Relaxed Solution of Spectral Clustering via a Non-Heuristic Algorithm. (arXiv:2310.12752v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Halabi_M/0/1/0/all/0/1\">Marwa El Halabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1\">Federico Fusco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_Fard_A/0/1/0/all/0/1\">Ashkan Norouzi-Fard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tardos_J/0/1/0/all/0/1\">Jakab Tardos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarnawski_J/0/1/0/all/0/1\">Jakub Tarnawski</a>",
          "description": "Streaming submodular maximization is a natural model for the task of\nselecting a representative subset from a large-scale dataset. If datapoints\nhave sensitive attributes such as gender or race, it becomes important to\nenforce fairness to avoid bias and discrimination. This has spurred significant\ninterest in developing fair machine learning algorithms. Recently, such\nalgorithms have been developed for monotone submodular maximization under a\ncardinality constraint.\n\nIn this paper, we study the natural generalization of this problem to a\nmatroid constraint. We give streaming algorithms as well as impossibility\nresults that provide trade-offs between efficiency, quality and fairness. We\nvalidate our findings empirically on a range of well-known real-world\napplications: exemplar-based clustering, movie recommendation, and maximum\ncoverage in social networks.",
          "link": "http://arxiv.org/abs/2305.15118",
          "publishedOn": "2023-10-21T00:41:42.989Z",
          "wordCount": null,
          "title": "Fairness in Streaming Submodular Maximization over a Matroid Constraint. (arXiv:2305.15118v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sabry_M/0/1/0/all/0/1\">Mohammed Sabry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belz_A/0/1/0/all/0/1\">Anya Belz</a>",
          "description": "Recent parameter-efficient finetuning (PEFT) techniques aim to improve over\nthe considerable cost of fully finetuning large pretrained language models\n(PLM). As different PEFT techniques proliferate, it is becoming difficult to\ncompare them, in particular in terms of (i) the structure and functionality\nthey add to the PLM, (ii) the different types and degrees of efficiency\nimprovements achieved, (iii) performance at different downstream tasks, and\n(iv) how differences in structure and functionality relate to efficiency and\ntask performance. To facilitate such comparisons, this paper presents a\nreference architecture which standardises aspects shared by different PEFT\ntechniques, while isolating differences to specific locations and interactions\nwith the standard components. Through this process of standardising and\nisolating differences, a modular view of PEFT techniques emerges, supporting\nnot only direct comparison of different techniques and their efficiency and\ntask performance, but also systematic exploration of reusability and\ncomposability of the different types of finetuned modules. We demonstrate how\nthe reference architecture can be applied to understand properties and relative\nadvantages of PEFT techniques, hence to inform selection of techniques for\nspecific tasks, and design choices for new PEFT techniques.",
          "link": "http://arxiv.org/abs/2304.12410",
          "publishedOn": "2023-10-21T00:41:42.959Z",
          "wordCount": null,
          "title": "PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques. (arXiv:2304.12410v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kujanpaa_K/0/1/0/all/0/1\">Kalle Kujanp&#xe4;&#xe4;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1\">Joni Pajarinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilin_A/0/1/0/all/0/1\">Alexander Ilin</a>",
          "description": "Solving complex planning problems has been a long-standing challenge in\ncomputer science. Learning-based subgoal search methods have shown promise in\ntackling these problems, but they often suffer from a lack of completeness\nguarantees, meaning that they may fail to find a solution even if one exists.\nIn this paper, we propose an efficient approach to augment a subgoal search\nmethod to achieve completeness in discrete action spaces. Specifically, we\naugment the high-level search with low-level actions to execute a multi-level\n(hybrid) search, which we call complete subgoal search. This solution achieves\nthe best of both worlds: the practical efficiency of high-level search and the\ncompleteness of low-level search. We apply the proposed search method to a\nrecently proposed subgoal search algorithm and evaluate the algorithm trained\non offline data on complex planning problems. We demonstrate that our complete\nsubgoal search not only guarantees completeness but can even improve\nperformance in terms of search expansions for instances that the high-level\ncould solve without low-level augmentations. Our approach makes it possible to\napply subgoal-level planning for systems where completeness is a critical\nrequirement.",
          "link": "http://arxiv.org/abs/2310.12819",
          "publishedOn": "2023-10-21T00:41:42.949Z",
          "wordCount": null,
          "title": "Hybrid Search for Efficient Planning with Completeness Guarantees. (arXiv:2310.12819v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.07940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1\">Harshavardhan Kamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingkai Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Alexander Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1\">B. Aditya Prakash</a>",
          "description": "Probabilistic hierarchical time-series forecasting is an important variant of\ntime-series forecasting, where the goal is to model and forecast multivariate\ntime-series that have underlying hierarchical relations. Most methods focus on\npoint predictions and do not provide well-calibrated probabilistic forecasts\ndistributions. Recent state-of-art probabilistic forecasting methods also\nimpose hierarchical relations on point predictions and samples of distribution\nwhich does not account for coherency of forecast distributions. Previous works\nalso silently assume that datasets are always consistent with given\nhierarchical relations and do not adapt to real-world datasets that show\ndeviation from this assumption. We close both these gap and propose PROFHiT,\nwhich is a fully probabilistic hierarchical forecasting model that jointly\nmodels forecast distribution of entire hierarchy. PROFHiT uses a flexible\nprobabilistic Bayesian approach and introduces a novel Distributional Coherency\nregularization to learn from hierarchical relations for entire forecast\ndistribution that enables robust and calibrated forecasts as well as adapt to\ndatasets of varying hierarchical consistency. On evaluating PROFHiT over wide\nrange of datasets, we observed 41-88% better performance in accuracy and\nsignificantly better calibration. Due to modeling the coherency over full\ndistribution, we observed that PROFHiT can robustly provide reliable forecasts\neven if up to 10% of input time-series data is missing where other methods'\nperformance severely degrade by over 70%.",
          "link": "http://arxiv.org/abs/2206.07940",
          "publishedOn": "2023-10-21T00:41:42.943Z",
          "wordCount": null,
          "title": "When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting. (arXiv:2206.07940v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12774",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Han Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>",
          "description": "Prompt-based learning has been an effective paradigm for large pretrained\nlanguage models (LLM), enabling few-shot or even zero-shot learning. Black-box\nprompt search has received growing interest recently for its distinctive\nproperties of gradient-free optimization, proven particularly useful and\npowerful for model-as-a-service usage. However, the discrete nature and the\ncomplexity of combinatorial optimization hinder the efficiency of modern\nblack-box approaches. Despite extensive research on search algorithms, the\ncrucial aspect of search space design and optimization has been largely\noverlooked. In this paper, we first conduct a sensitivity analysis by prompting\nLLM, revealing that only a small number of tokens exert a disproportionate\namount of influence on LLM predictions. Leveraging this insight, we propose the\nClustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple\nblack-box search method that first clusters and prunes the search space to\nfocus exclusively on influential prompt tokens. By employing even simple search\nmethods within the pruned search space, ClaPS achieves state-of-the-art\nperformance across various tasks and LLMs, surpassing the performance of\ncomplex approaches while significantly reducing search costs. Our findings\nunderscore the critical role of search space design and optimization in\nenhancing both the usefulness and the efficiency of black-box prompt-based\nlearning.",
          "link": "http://arxiv.org/abs/2310.12774",
          "publishedOn": "2023-10-21T00:41:42.937Z",
          "wordCount": null,
          "title": "Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning. (arXiv:2310.12774v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12346",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Kerber_S/0/1/0/all/0/1\">Samuel W Kerber</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Duncan_N/0/1/0/all/0/1\">Nicholas A Duncan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+LHer_G/0/1/0/all/0/1\">Guillaume F LHer</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bazilian_M/0/1/0/all/0/1\">Morgan Bazilian</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Elvidge_C/0/1/0/all/0/1\">Chris Elvidge</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Deinert_M/0/1/0/all/0/1\">Mark R Deinert</a>",
          "description": "Urban environments are intricate systems where the breakdown of critical\ninfrastructure can impact both the economic and social well-being of\ncommunities. Electricity systems hold particular significance, as they are\nessential for other infrastructure, and disruptions can trigger widespread\nconsequences. Typically, assessing electricity availability requires\nground-level data, a challenge in conflict zones and regions with limited\naccess. This study shows how satellite imagery, social media, and information\nextraction can monitor blackouts and their perceived causes. Night-time light\ndata (in March 2019 for Caracas, Venezuela) is used to indicate blackout\nregions. Twitter data is used to determine sentiment and topic trends, while\nstatistical analysis and topic modeling delved into public perceptions\nregarding blackout causes. The findings show an inverse relationship between\nnighttime light intensity. Tweets mentioning the Venezuelan President displayed\nheightened negativity and a greater prevalence of blame-related terms,\nsuggesting a perception of government accountability for the outages.",
          "link": "http://arxiv.org/abs/2310.12346",
          "publishedOn": "2023-10-21T00:41:42.931Z",
          "wordCount": null,
          "title": "Tracking electricity losses and their perceived causes using nighttime light and social media. (arXiv:2310.12346v1 [physics.soc-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1\">Amir Feder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wald_Y/0/1/0/all/0/1\">Yoav Wald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Claudia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saria_S/0/1/0/all/0/1\">Suchi Saria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blei_D/0/1/0/all/0/1\">David Blei</a>",
          "description": "The reliance of text classifiers on spurious correlations can lead to poor\ngeneralization at deployment, raising concerns about their use in\nsafety-critical domains such as healthcare. In this work, we propose to use\ncounterfactual data augmentation, guided by knowledge of the causal structure\nof the data, to simulate interventions on spurious features and to learn more\nrobust text classifiers. We show that this strategy is appropriate in\nprediction problems where the label is spuriously correlated with an attribute.\nUnder the assumptions of such problems, we discuss the favorable sample\ncomplexity of counterfactual data augmentation, compared to importance\nre-weighting. Pragmatically, we match examples using auxiliary data, based on\ndiff-in-diff methodology, and use a large language model (LLM) to represent a\nconditional probability of text. Through extensive experimentation on learning\ncaregiver-invariant predictors of clinical diagnoses from medical narratives\nand on semi-synthetic data, we demonstrate that our method for simulating\ninterventions improves out-of-distribution (OOD) accuracy compared to baseline\ninvariant learning algorithms.",
          "link": "http://arxiv.org/abs/2310.12803",
          "publishedOn": "2023-10-21T00:41:42.930Z",
          "wordCount": null,
          "title": "Causal-structure Driven Augmentations for Text OOD Generalization. (arXiv:2310.12803v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paissan_F/0/1/0/all/0/1\">Francesco Paissan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhepei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravanelli_M/0/1/0/all/0/1\">Mirco Ravanelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smaragdis_P/0/1/0/all/0/1\">Paris Smaragdis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subakan_C/0/1/0/all/0/1\">Cem Subakan</a>",
          "description": "In this paper, we explore audio-editing with non-rigid text edits. We show\nthat the proposed editing pipeline is able to create audio edits that remain\nfaithful to the input audio. We explore text prompts that perform addition,\nstyle transfer, and in-painting. We quantitatively and qualitatively show that\nthe edits are able to obtain results which outperform Audio-LDM, a recently\nreleased text-prompted audio generation model. Qualitative inspection of the\nresults points out that the edits given by our approach remain more faithful to\nthe input audio in terms of keeping the original onsets and offsets of the\naudio events.",
          "link": "http://arxiv.org/abs/2310.12858",
          "publishedOn": "2023-10-21T00:41:42.930Z",
          "wordCount": null,
          "title": "Audio Editing with Non-Rigid Text Prompts. (arXiv:2310.12858v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.12321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jang-Hyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Sangdoo Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hyun Oh Song</a>",
          "description": "Diagnosing and cleaning data is a crucial step for building robust machine\nlearning systems. However, identifying problems within large-scale datasets\nwith real-world distributions is challenging due to the presence of complex\nissues such as label errors, under-representation, and outliers. In this paper,\nwe propose a unified approach for identifying the problematic data by utilizing\na largely ignored source of information: a relational structure of data in the\nfeature-embedded space. To this end, we present scalable and effective\nalgorithms for detecting label errors and outlier data based on the relational\ngraph structure of data. We further introduce a visualization tool that\nprovides contextual information of a data point in the feature-embedded space,\nserving as an effective tool for interactively diagnosing data. We evaluate the\nlabel error and outlier/out-of-distribution (OOD) detection performances of our\napproach on the large-scale image, speech, and language domain tasks, including\nImageNet, ESC-50, and SST2. Our approach achieves state-of-the-art detection\nperformance on all tasks considered and demonstrates its effectiveness in\ndebugging large-scale real-world datasets across various domains. We release\ncodes at https://github.com/snu-mllab/Neural-Relation-Graph.",
          "link": "http://arxiv.org/abs/2301.12321",
          "publishedOn": "2023-10-21T00:41:42.929Z",
          "wordCount": null,
          "title": "Neural Relation Graph: A Unified Framework for Identifying Label Noise and Outlier Data. (arXiv:2301.12321v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoshikawa_u/0/1/0/all/0/1\">uya Yoshikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1\">Tomoharu Iwata</a>",
          "description": "The quality of explanations for the predictions of complex machine learning\npredictors is often measured using insertion and deletion metrics, which assess\nthe faithfulness of the explanations, i.e., how correctly the explanations\nreflect the predictor's behavior. To improve the faithfulness, we propose\ninsertion/deletion metric-aware explanation-based optimization (ID-ExpO), which\noptimizes differentiable predictors to improve both insertion and deletion\nscores of the explanations while keeping their predictive accuracy. Since the\noriginal insertion and deletion metrics are indifferentiable with respect to\nthe explanations and directly unavailable for gradient-based optimization, we\nextend the metrics to be differentiable and use them to formalize insertion and\ndeletion metric-based regularizers. The experimental results on image and\ntabular datasets show that the deep neural networks-based predictors fine-tuned\nusing ID-ExpO enable popular post-hoc explainers to produce more faithful and\neasy-to-interpret explanations while keeping high predictive accuracy.",
          "link": "http://arxiv.org/abs/2310.12553",
          "publishedOn": "2023-10-21T00:41:42.923Z",
          "wordCount": null,
          "title": "Explanation-Based Training with Differentiable Insertion/Deletion Metric-Aware Regularizers. (arXiv:2310.12553v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.14276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Volk_T/0/1/0/all/0/1\">Tomer Volk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_David_E/0/1/0/all/0/1\">Eyal Ben-David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amosy_O/0/1/0/all/0/1\">Ohad Amosy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1\">Roi Reichart</a>",
          "description": "As Natural Language Processing (NLP) algorithms continually achieve new\nmilestones, out-of-distribution generalization remains a significant challenge.\nThis paper addresses the issue of multi-source adaptation for unfamiliar\ndomains: We leverage labeled data from multiple source domains to generalize to\nunknown target domains at training. Our innovative framework employs\nexample-based Hypernetwork adaptation: a T5 encoder-decoder initially generates\na unique signature from an input example, embedding it within the source\ndomains' semantic space. This signature is subsequently utilized by a\nHypernetwork to generate the task classifier's weights. We evaluated our method\nacross two tasks - sentiment classification and natural language inference - in\n29 adaptation scenarios, where it outpaced established algorithms. In an\nadvanced version, the signature also enriches the input example's\nrepresentation. We also compare our finetuned architecture to few-shot GPT-3,\ndemonstrating its effectiveness in essential use cases. To our knowledge, this\nmarks the first application of Hypernetworks to the adaptation for unknown\ndomains.",
          "link": "http://arxiv.org/abs/2203.14276",
          "publishedOn": "2023-10-21T00:41:42.923Z",
          "wordCount": null,
          "title": "Example-based Hypernetworks for Out-of-Distribution Generalization. (arXiv:2203.14276v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jiayi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Lei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiaoyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhengzong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhirui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengnan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xue Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xucheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yiqiao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1\">Chao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chengru Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1\">Junchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zijia Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fuzheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Di Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gai_K/0/1/0/all/0/1\">Kun Gai</a>",
          "description": "Recent advancements in large language models (LLMs) have demonstrated\nremarkable abilities in handling a variety of natural language processing (NLP)\ndownstream tasks, even on mathematical tasks requiring multi-step reasoning. In\nthis report, we introduce the KwaiYiiMath which enhances the mathematical\nreasoning abilities of KwaiYiiBase1, by applying Supervised Fine-Tuning (SFT)\nand Reinforced Learning from Human Feedback (RLHF), including on both English\nand Chinese mathematical tasks. Meanwhile, we also constructed a small-scale\nChinese primary school mathematics test set (named KMath), consisting of 188\nexamples to evaluate the correctness of the problem-solving process generated\nby the models. Empirical studies demonstrate that KwaiYiiMath can achieve\nstate-of-the-art (SOTA) performance on GSM8k, CMath, and KMath compared with\nthe similar size models, respectively.",
          "link": "http://arxiv.org/abs/2310.07488",
          "publishedOn": "2023-10-21T00:41:42.920Z",
          "wordCount": null,
          "title": "KwaiYiiMath: Technical Report. (arXiv:2310.07488v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.00617",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Giegrich_M/0/1/0/all/0/1\">Michael Giegrich</a>, <a href=\"http://arxiv.org/find/math/1/au:+Reisinger_C/0/1/0/all/0/1\">Christoph Reisinger</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1\">Yufei Zhang</a>",
          "description": "We study the global linear convergence of policy gradient (PG) methods for\nfinite-horizon continuous-time exploratory linear-quadratic control (LQC)\nproblems. The setting includes stochastic LQC problems with indefinite costs\nand allows additional entropy regularisers in the objective. We consider a\ncontinuous-time Gaussian policy whose mean is linear in the state variable and\nwhose covariance is state-independent. Contrary to discrete-time problems, the\ncost is noncoercive in the policy and not all descent directions lead to\nbounded iterates. We propose geometry-aware gradient descents for the mean and\ncovariance of the policy using the Fisher geometry and the Bures-Wasserstein\ngeometry, respectively. The policy iterates are shown to satisfy an a-priori\nbound, and converge globally to the optimal policy with a linear rate. We\nfurther propose a novel PG method with discrete-time policies. The algorithm\nleverages the continuous-time analysis, and achieves a robust linear\nconvergence across different action frequencies. A numerical experiment\nconfirms the convergence and robustness of the proposed algorithm.",
          "link": "http://arxiv.org/abs/2211.00617",
          "publishedOn": "2023-10-21T00:41:42.909Z",
          "wordCount": null,
          "title": "Convergence of policy gradient methods for finite-horizon stochastic linear-quadratic control problems. (arXiv:2211.00617v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.01328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_D/0/1/0/all/0/1\">David M. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myers_A/0/1/0/all/0/1\">Austin Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vijayanarasimhan_S/0/1/0/all/0/1\">Sudheendra Vijayanarasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_D/0/1/0/all/0/1\">David A. Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canny_J/0/1/0/all/0/1\">John Canny</a>",
          "description": "If you ask a human to describe an image, they might do so in a thousand\ndifferent ways. Traditionally, image captioning models are trained to generate\na single \"best\" (most like a reference) image caption. Unfortunately, doing so\nencourages captions that are \"informationally impoverished,\" and focus on only\na subset of the possible details, while ignoring other potentially useful\ninformation in the scene. In this work, we introduce a simple, yet novel,\nmethod: \"Image Captioning by Committee Consensus\" (IC3), designed to generate a\nsingle caption that captures high-level details from several annotator\nviewpoints. Humans rate captions produced by IC3 at least as helpful as\nbaseline SOTA models more than two thirds of the time, and IC3 can improve the\nperformance of SOTA automated recall systems by up to 84%, outperforming single\nhuman-generated reference captions, and indicating significant improvements\nover SOTA approaches for visual description. Code is available at\nhttps://davidmchan.github.io/caption-by-committee/",
          "link": "http://arxiv.org/abs/2302.01328",
          "publishedOn": "2023-10-21T00:41:42.908Z",
          "wordCount": null,
          "title": "IC3: Image Captioning by Committee Consensus. (arXiv:2302.01328v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.01365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1\">Hong Jun Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "We study the compute-optimal trade-off between model and training data set\nsizes for large neural networks. Our result suggests a linear relation similar\nto that supported by the empirical analysis of chinchilla. While that work\nstudies transformer-based large language models trained on the MassiveText\ncorpus gopher, as a starting point for development of a mathematical theory, we\nfocus on a simpler learning model and data generating process, each based on a\nneural network with a sigmoidal output unit and single hidden layer of ReLU\nactivation units. We introduce general error upper bounds for a class of\nalgorithms which incrementally update a statistic (for example gradient\ndescent). For a particular learning model inspired by barron 1993, we establish\nan upper bound on the minimal information-theoretically achievable expected\nerror as a function of model and data set sizes. We then derive allocations of\ncomputation that minimize this bound. We present empirical results which\nsuggest that this approximation correctly identifies an asymptotic linear\ncompute-optimal scaling. This approximation also generates new insights. Among\nother things, it suggests that, as the input dimension or latent space\ncomplexity grows, as might be the case for example if a longer history of\ntokens is taken as input to a language model, a larger fraction of the compute\nbudget should be allocated to growing the learning model rather than training\ndata.",
          "link": "http://arxiv.org/abs/2212.01365",
          "publishedOn": "2023-10-21T00:41:42.907Z",
          "wordCount": null,
          "title": "An Information-Theoretic Analysis of Compute-Optimal Neural Scaling Laws. (arXiv:2212.01365v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.09730",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maimon_G/0/1/0/all/0/1\">Gallil Maimon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>",
          "description": "We introduce DISSC, a novel, lightweight method that converts the rhythm,\npitch contour and timbre of a recording to a target speaker in a textless\nmanner. Unlike DISSC, most voice conversion (VC) methods focus primarily on\ntimbre, and ignore people's unique speaking style (prosody). The proposed\napproach uses a pretrained, self-supervised model for encoding speech to\ndiscrete units, which makes it simple, effective, and fast to train. All\nconversion modules are only trained on reconstruction like tasks, thus suitable\nfor any-to-many VC with no paired data. We introduce a suite of quantitative\nand qualitative evaluation metrics for this setup, and empirically demonstrate\nthat DISSC significantly outperforms the evaluated baselines. Code and samples\nare available at https://pages.cs.huji.ac.il/adiyoss-lab/dissc/.",
          "link": "http://arxiv.org/abs/2212.09730",
          "publishedOn": "2023-10-21T00:41:42.904Z",
          "wordCount": null,
          "title": "Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units. (arXiv:2212.09730v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shufan Jiang</a> (CRESTIC, ISEP), <a href=\"http://arxiv.org/find/cs/1/au:+Angarita_R/0/1/0/all/0/1\">Rafael Angarita</a> (ISEP), <a href=\"http://arxiv.org/find/cs/1/au:+Cormier_S/0/1/0/all/0/1\">St&#xe9;phane Cormier</a> (CRESTIC), <a href=\"http://arxiv.org/find/cs/1/au:+Rousseaux_F/0/1/0/all/0/1\">Francis Rousseaux</a> (CRESTIC)",
          "description": "An important application scenario of precision agriculture is detecting and\nmeasuring crop health threats using sensors and data analysis techniques.\nHowever, the textual data are still under-explored among the existing solutions\ndue to the lack of labelled data and fine-grained semantic resources. Recent\nresearch suggests that the increasing connectivity of farmers and the emergence\nof online farming communities make social media like Twitter a participatory\nplatform for detecting unfamiliar plant health events if we can extract\nessential information from unstructured textual data. ChouBERT is a French\npre-trained language model that can identify Tweets concerning observations of\nplant health issues with generalizability on unseen natural hazards. This paper\ntackles the lack of labelled data by further studying ChouBERT's know-how on\ntoken-level annotation tasks over small labeled sets.",
          "link": "http://arxiv.org/abs/2310.12522",
          "publishedOn": "2023-10-21T00:41:42.902Z",
          "wordCount": null,
          "title": "Named Entity Recognition for Monitoring Plant Health Threats in Tweets: a ChouBERT Approach. (arXiv:2310.12522v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.13623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Baihan Lin</a>",
          "description": "In recent years, reinforcement learning and bandits have transformed a wide\nrange of real-world applications including healthcare, finance, recommendation\nsystems, robotics, and last but not least, the speech and natural language\nprocessing. While most speech and language applications of reinforcement\nlearning algorithms are centered around improving the training of deep neural\nnetworks with its flexible optimization properties, there are still many\ngrounds to explore to utilize the benefits of reinforcement learning, such as\nits reward-driven adaptability, state representations, temporal structures and\ngeneralizability. In this survey, we present an overview of recent advancements\nof reinforcement learning and bandits, and discuss how they can be effectively\nemployed to solve speech and natural language processing problems with models\nthat are adaptive, interactive and scalable.",
          "link": "http://arxiv.org/abs/2210.13623",
          "publishedOn": "2023-10-21T00:41:42.899Z",
          "wordCount": null,
          "title": "Reinforcement Learning and Bandits for Speech and Language Processing: Tutorial, Review and Outlook. (arXiv:2210.13623v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.13001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dey_J/0/1/0/all/0/1\">Jayanta Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeVine_W/0/1/0/all/0/1\">Will LeVine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoyin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1\">Ashwin De Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomita_T/0/1/0/all/0/1\">Tyler M. Tomita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geisa_A/0/1/0/all/0/1\">Ali Geisa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1\">Tiffany Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desman_J/0/1/0/all/0/1\">Jacob Desman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>",
          "description": "Deep discriminative approaches like random forests and deep neural networks\nhave recently found applications in many important real-world scenarios.\nHowever, deploying these learning algorithms in safety-critical applications\nraises concerns, particularly when it comes to ensuring confidence calibration\nfor both in-distribution and out-of-distribution data points. Many popular\nmethods for in-distribution (ID) calibration, such as isotonic regression and\nPlatt's sigmoidal regression, exhibit excellent ID calibration performance but\noften at the cost of classification accuracy. Moreover, these methods are not\ncalibrated for the entire feature space, leading to overconfidence in the case\nof out-of-distribution (OOD) samples. In this paper, we leveraged the fact that\ndeep models, including both random forests and deep-nets, learn internal\nrepresentations which are unions of polytopes with affine activation functions\nto conceptualize them both as partitioning rules of the feature space. We\nreplace the affine function in each polytope populated by the training data\nwith a Gaussian kernel. We propose sufficient conditions for our proposed\nmethods to be consistent estimators of the corresponding class conditional\ndensities. Moreover, our experiments on both tabular and vision benchmarks show\nthat the proposed approaches obtain well-calibrated posteriors while mostly\npreserving or improving the classification accuracy of the original algorithm\nfor in-distribution region, and extrapolates beyond the training data to handle\nout-of-distribution inputs appropriately.",
          "link": "http://arxiv.org/abs/2201.13001",
          "publishedOn": "2023-10-21T00:41:42.894Z",
          "wordCount": null,
          "title": "Deep Discriminative to Kernel Density Networks for Calibrated Inference. (arXiv:2201.13001v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.10398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tianqi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1\">Ngan Thi Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanjalic_A/0/1/0/all/0/1\">Alan Hanjalic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khosla_M/0/1/0/all/0/1\">Megha Khosla</a>",
          "description": "Graph Neural Networks (GNNs) have shown state-of-the-art improvements in node\nclassification tasks on graphs. While these improvements have been largely\ndemonstrated in a multi-class classification scenario, a more general and\nrealistic scenario in which each node could have multiple labels has so far\nreceived little attention. The first challenge in conducting focused studies on\nmulti-label node classification is the limited number of publicly available\nmulti-label graph datasets. Therefore, as our first contribution, we collect\nand release three real-world biological datasets and develop a multi-label\ngraph generator to generate datasets with tunable properties. While high label\nsimilarity (high homophily) is usually attributed to the success of GNNs, we\nargue that a multi-label scenario does not follow the usual semantics of\nhomophily and heterophily so far defined for a multi-class scenario. As our\nsecond contribution, we define homophily and Cross-Class Neighborhood\nSimilarity for the multi-label scenario and provide a thorough analyses of the\ncollected $9$ multi-label datasets. Finally, we perform a large-scale\ncomparative study with $8$ methods and $9$ datasets and analyse the\nperformances of the methods to assess the progress made by current state of the\nart in the multi-label node classification scenario. We release our benchmark\nat https://github.com/Tianqi-py/MLGNC.",
          "link": "http://arxiv.org/abs/2304.10398",
          "publishedOn": "2023-10-21T00:41:42.894Z",
          "wordCount": null,
          "title": "Multi-label Node Classification On Graph-Structured Data. (arXiv:2304.10398v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.11762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Minjie Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hongteng Xu</a>",
          "description": "When learning graph neural networks (GNNs) in node-level prediction tasks,\nmost existing loss functions are applied for each node independently, even if\nnode embeddings and their labels are non-i.i.d. because of their graph\nstructures. To eliminate such inconsistency, in this study we propose a novel\nQuasi-Wasserstein (QW) loss with the help of the optimal transport defined on\ngraphs, leading to new learning and prediction paradigms of GNNs. In\nparticular, we design a \"Quasi-Wasserstein\" distance between the observed\nmulti-dimensional node labels and their estimations, optimizing the label\ntransport defined on graph edges. The estimations are parameterized by a GNN in\nwhich the optimal label transport may determine the graph edge weights\noptionally. By reformulating the strict constraint of the label transport to a\nBregman divergence-based regularizer, we obtain the proposed Quasi-Wasserstein\nloss associated with two efficient solvers learning the GNN together with\noptimal label transport. When predicting node labels, our model combines the\noutput of the GNN with the residual component provided by the optimal label\ntransport, leading to a new transductive prediction paradigm. Experiments show\nthat the proposed QW loss applies to various GNNs and helps to improve their\nperformance in node-level classification and regression tasks.",
          "link": "http://arxiv.org/abs/2310.11762",
          "publishedOn": "2023-10-21T00:41:42.890Z",
          "wordCount": null,
          "title": "A Quasi-Wasserstein Loss for Learning Graph Neural Networks. (arXiv:2310.11762v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12893",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_C/0/1/0/all/0/1\">Changhao Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_B/0/1/0/all/0/1\">Boning Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Amer_O/0/1/0/all/0/1\">Omar Amer</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Shaydulin_R/0/1/0/all/0/1\">Ruslan Shaydulin</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Chakrabarti_S/0/1/0/all/0/1\">Shouvanik Chakrabarti</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_G/0/1/0/all/0/1\">Guoqing Wang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Xu_H/0/1/0/all/0/1\">Haowei Xu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tang_H/0/1/0/all/0/1\">Hao Tang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Schoch_I/0/1/0/all/0/1\">Isidor Schoch</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kumar_N/0/1/0/all/0/1\">Niraj Kumar</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lim_C/0/1/0/all/0/1\">Charles Lim</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_J/0/1/0/all/0/1\">Ju Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cappellaro_P/0/1/0/all/0/1\">Paola Cappellaro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Pistoia_M/0/1/0/all/0/1\">Marco Pistoia</a>",
          "description": "Distributed quantum computing is a promising computational paradigm for\nperforming computations that are beyond the reach of individual quantum\ndevices. Privacy in distributed quantum computing is critical for maintaining\nconfidentiality and protecting the data in the presence of untrusted computing\nnodes. In this work, we introduce novel blind quantum machine learning\nprotocols based on the quantum bipartite correlator algorithm. Our protocols\nhave reduced communication overhead while preserving the privacy of data from\nuntrusted parties. We introduce robust algorithm-specific privacy-preserving\nmechanisms with low computational overhead that do not require complex\ncryptographic techniques. We then validate the effectiveness of the proposed\nprotocols through complexity and privacy analysis. Our findings pave the way\nfor advancements in distributed quantum computing, opening up new possibilities\nfor privacy-aware machine learning applications in the era of quantum\ntechnologies.",
          "link": "http://arxiv.org/abs/2310.12893",
          "publishedOn": "2023-10-21T00:41:42.887Z",
          "wordCount": null,
          "title": "Blind quantum machine learning with quantum bipartite correlator. (arXiv:2310.12893v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yupei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yuqi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_R/0/1/0/all/0/1\">Runpeng Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jinyuan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>",
          "description": "Large Language Models (LLMs) are increasingly deployed as the backend for a\nvariety of real-world applications called LLM-Integrated Applications. Multiple\nrecent works showed that LLM-Integrated Applications are vulnerable to prompt\ninjection attacks, in which an attacker injects malicious instruction/data into\nthe input of those applications such that they produce results as the attacker\ndesires. However, existing works are limited to case studies. As a result, the\nliterature lacks a systematic understanding of prompt injection attacks and\ntheir defenses. We aim to bridge the gap in this work. In particular, we\npropose a general framework to formalize prompt injection attacks. Existing\nattacks, which are discussed in research papers and blog posts, are special\ncases in our framework. Our framework enables us to design a new attack by\ncombining existing attacks. Moreover, we also propose a framework to\nsystematize defenses against prompt injection attacks. Using our frameworks, we\nconduct a systematic evaluation on prompt injection attacks and their defenses\nwith 10 LLMs and 7 tasks. We hope our frameworks can inspire future research in\nthis field. Our code is available at\nhttps://github.com/liu00222/Open-Prompt-Injection.",
          "link": "http://arxiv.org/abs/2310.12815",
          "publishedOn": "2023-10-21T00:41:42.886Z",
          "wordCount": null,
          "title": "Prompt Injection Attacks and Defenses in LLM-Integrated Applications. (arXiv:2310.12815v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12862",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krupnik_O/0/1/0/all/0/1\">Orr Krupnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafer_E/0/1/0/all/0/1\">Elisei Shafer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurgenson_T/0/1/0/all/0/1\">Tom Jurgenson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamar_A/0/1/0/all/0/1\">Aviv Tamar</a>",
          "description": "Adaptable models could greatly benefit robotic agents operating in the real\nworld, allowing them to deal with novel and varying conditions. While\napproaches such as Bayesian inference are well-studied frameworks for adapting\nmodels to evidence, we build on recent advances in deep generative models which\nhave greatly affected many areas of robotics. Harnessing modern GPU\nacceleration, we investigate how to quickly adapt the sample generation of\nneural network models to observations in robotic tasks. We propose a simple and\ngeneral method that is applicable to various deep generative models and robotic\nenvironments. The key idea is to quickly fine-tune the model by fitting it to\ngenerated samples matching the observed evidence, using the cross-entropy\nmethod. We show that our method can be applied to both autoregressive models\nand variational autoencoders, and demonstrate its usability in object shape\ninference from grasping, inverse kinematics calculation, and point cloud\ncompletion.",
          "link": "http://arxiv.org/abs/2310.12862",
          "publishedOn": "2023-10-21T00:41:42.886Z",
          "wordCount": null,
          "title": "Fine-Tuning Generative Models as an Inference Method for Robotic Tasks. (arXiv:2310.12862v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1811.11479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_E/0/1/0/all/0/1\">Eunjeong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seungeun Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyesung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jihong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1\">Mehdi Bennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seong-Lyun Kim</a>",
          "description": "On-device machine learning (ML) enables the training process to exploit a\nmassive amount of user-generated private data samples. To enjoy this benefit,\ninter-device communication overhead should be minimized. With this end, we\npropose federated distillation (FD), a distributed model training algorithm\nwhose communication payload size is much smaller than a benchmark scheme,\nfederated learning (FL), particularly when the model size is large. Moreover,\nuser-generated data samples are likely to become non-IID across devices, which\ncommonly degrades the performance compared to the case with an IID dataset. To\ncope with this, we propose federated augmentation (FAug), where each device\ncollectively trains a generative model, and thereby augments its local data\ntowards yielding an IID dataset. Empirical studies demonstrate that FD with\nFAug yields around 26x less communication overhead while achieving 95-98% test\naccuracy compared to FL.",
          "link": "http://arxiv.org/abs/1811.11479",
          "publishedOn": "2023-10-21T00:41:42.878Z",
          "wordCount": null,
          "title": "Communication-Efficient On-Device Machine Learning: Federated Distillation and Augmentation under Non-IID Private Data. (arXiv:1811.11479v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12842",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wood_D/0/1/0/all/0/1\">Danny Wood</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papamarkou_T/0/1/0/all/0/1\">Theodore Papamarkou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Benatan_M/0/1/0/all/0/1\">Matt Benatan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Allmendinger_R/0/1/0/all/0/1\">Richard Allmendinger</a>",
          "description": "In order to trust the predictions of a machine learning algorithm, it is\nnecessary to understand the factors that contribute to those predictions. In\nthe case of probabilistic and uncertainty-aware models, it is necessary to\nunderstand not only the reasons for the predictions themselves, but also the\nmodel's level of confidence in those predictions. In this paper, we show how\nexisting methods in explainability can be extended to uncertainty-aware models\nand how such extensions can be used to understand the sources of uncertainty in\na model's predictive distribution. In particular, by adapting permutation\nfeature importance, partial dependence plots, and individual conditional\nexpectation plots, we demonstrate that novel insights into model behaviour may\nbe obtained and that these methods can be used to measure the impact of\nfeatures on both the entropy of the predictive distribution and the\nlog-likelihood of the ground truth labels under that distribution. With\nexperiments using both synthetic and real-world data, we demonstrate the\nutility of these approaches in understanding both the sources of uncertainty\nand their impact on model performance.",
          "link": "http://arxiv.org/abs/2310.12842",
          "publishedOn": "2023-10-21T00:41:42.870Z",
          "wordCount": null,
          "title": "Model-agnostic variable importance for predictive uncertainty: an entropy-based approach. (arXiv:2310.12842v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.08117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khalife_S/0/1/0/all/0/1\">Sammy Khalife</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hongyu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_A/0/1/0/all/0/1\">Amitabh Basu</a>",
          "description": "In this article we present new results on neural networks with linear\nthreshold activation functions. We precisely characterize the class of\nfunctions that are representable by such neural networks and show that 2 hidden\nlayers are necessary and sufficient to represent any function representable in\nthe class. This is a surprising result in the light of recent exact\nrepresentability investigations for neural networks using other popular\nactivation functions like rectified linear units (ReLU). We also give precise\nbounds on the sizes of the neural networks required to represent any function\nin the class. Finally, we design an algorithm to solve the empirical risk\nminimization (ERM) problem to global optimality for these neural networks with\na fixed architecture. The algorithm's running time is polynomial in the size of\nthe data sample, if the input dimension and the size of the network\narchitecture are considered fixed constants. The algorithm is unique in the\nsense that it works for any architecture with any number of layers, whereas\nprevious polynomial time globally optimal algorithms work only for very\nrestricted classes of architectures. Using these insights, we propose a new\nclass of neural networks that we call shortcut linear threshold networks. To\nthe best of our knowledge, this way of designing neural networks has not been\nexplored before in the literature. We show that these neural networks have\nseveral desirable theoretical properties.",
          "link": "http://arxiv.org/abs/2111.08117",
          "publishedOn": "2023-10-21T00:41:42.867Z",
          "wordCount": null,
          "title": "Neural networks with linear threshold activations: structure and algorithms. (arXiv:2111.08117v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12822",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Carrizosa_E/0/1/0/all/0/1\">Emilio Carrizosa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramirez_Ayerbe_J/0/1/0/all/0/1\">Jasone Ram&#xed;rez-Ayerbe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Morales_D/0/1/0/all/0/1\">Dolores Romero Morales</a>",
          "description": "Due to the increasing use of Machine Learning models in high stakes decision\nmaking settings, it has become increasingly important to have tools to\nunderstand how models arrive at decisions. Assuming a trained Supervised\nClassification model, explanations can be obtained via counterfactual analysis:\na counterfactual explanation of an instance indicates how this instance should\nbe minimally modified so that the perturbed instance is classified in the\ndesired class by the Machine Learning classification model. Most of the\nCounterfactual Analysis literature focuses on the single-instance\nsingle-counterfactual setting, in which the analysis is done for one single\ninstance to provide one single explanation. Taking a stakeholder's perspective,\nin this paper we introduce the so-called collective counterfactual\nexplanations. By means of novel Mathematical Optimization models, we provide a\ncounterfactual explanation for each instance in a group of interest, so that\nthe total cost of the perturbations is minimized under some linking\nconstraints. Making the process of constructing counterfactuals collective\ninstead of individual enables us to detect the features that are critical to\nthe entire dataset to have the individuals classified in the desired class. Our\nmethodology allows for some instances to be treated individually, performing\nthe collective counterfactual analysis for a fraction of records of the group\nof interest. This way, outliers are identified and handled appropriately. Under\nsome assumptions on the classifier and the space in which counterfactuals are\nsought, finding collective counterfactuals is reduced to solving a convex\nquadratic linearly constrained mixed integer optimization problem, which, for\ndatasets of moderate size, can be solved to optimality using existing solvers.\nThe performance of our approach is illustrated on real-world datasets,\ndemonstrating its usefulness.",
          "link": "http://arxiv.org/abs/2310.12822",
          "publishedOn": "2023-10-21T00:41:42.860Z",
          "wordCount": null,
          "title": "Generating collective counterfactual explanations in score-based classification via mathematical optimization. (arXiv:2310.12822v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sprangers_O/0/1/0/all/0/1\">Olivier Sprangers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadman_W/0/1/0/all/0/1\">Wander Wadman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schelter_S/0/1/0/all/0/1\">Sebastian Schelter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1\">Maarten de Rijke</a>",
          "description": "Existing hierarchical forecasting techniques scale poorly when the number of\ntime series increases. We propose to learn a coherent forecast for millions of\ntime series with a single bottom-level forecast model by using a sparse loss\nfunction that directly optimizes the hierarchical product and/or temporal\nstructure. The benefit of our sparse hierarchical loss function is that it\nprovides practitioners a method of producing bottom-level forecasts that are\ncoherent to any chosen cross-sectional or temporal hierarchy. In addition,\nremoving the need for a post-processing step as required in traditional\nhierarchical forecasting techniques reduces the computational cost of the\nprediction phase in the forecasting pipeline. On the public M5 dataset, our\nsparse hierarchical loss function performs up to 10% (RMSE) better compared to\nthe baseline loss function. We implement our sparse hierarchical loss function\nwithin an existing forecasting model at bol, a large European e-commerce\nplatform, resulting in an improved forecasting performance of 2% at the product\nlevel. Finally, we found an increase in forecasting performance of about 5-10%\nwhen evaluating the forecasting performance across the cross-sectional\nhierarchies that we defined. These results demonstrate the usefulness of our\nsparse hierarchical loss applied to a production forecasting system at a major\ne-commerce platform.",
          "link": "http://arxiv.org/abs/2310.12809",
          "publishedOn": "2023-10-21T00:41:42.859Z",
          "wordCount": null,
          "title": "Hierarchical Forecasting at Scale. (arXiv:2310.12809v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hua Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ninghao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Mengnan Du</a>",
          "description": "While the accuracy-fairness trade-off has been frequently observed in the\nliterature of fair machine learning, rigorous theoretical analyses have been\nscarce. To demystify this long-standing challenge, this work seeks to develop a\ntheoretical framework by characterizing the shape of the accuracy-fairness\ntrade-off Pareto frontier (FairFrontier), determined by a set of all optimal\nPareto classifiers that no other classifiers can dominate. Specifically, we\nfirst demonstrate the existence of the trade-off in real-world scenarios and\nthen propose four potential categories to characterize the important properties\nof the accuracy-fairness Pareto frontier. For each category, we identify the\nnecessary conditions that lead to corresponding trade-offs. Experimental\nresults on synthetic data suggest insightful findings of the proposed\nframework: (1) When sensitive attributes can be fully interpreted by\nnon-sensitive attributes, FairFrontier is mostly continuous. (2) Accuracy can\nsuffer a \\textit{sharp} decline when over-pursuing fairness. (3) Eliminate the\ntrade-off via a two-step streamlined approach. The proposed research enables an\nin-depth understanding of the accuracy-fairness trade-off, pushing current fair\nmachine-learning research to a new frontier.",
          "link": "http://arxiv.org/abs/2310.12785",
          "publishedOn": "2023-10-21T00:41:42.854Z",
          "wordCount": null,
          "title": "A Theoretical Approach to Characterize the Accuracy-Fairness Trade-off Pareto Frontier. (arXiv:2310.12785v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.00608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yuxiang Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Chunqiu Steven Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lingming Zhang</a>",
          "description": "During Automated Program Repair (APR), it can be challenging to synthesize\ncorrect patches for real-world systems in general-purpose programming\nlanguages. Recent Large Language Models (LLMs) have been shown to be helpful\n\"copilots\" in assisting developers with various coding tasks, and have also\nbeen directly applied for patch synthesis. However, most LLMs treat programs as\nsequences of tokens, meaning that they are ignorant of the underlying semantics\nconstraints of the target programming language. This results in plenty of\nstatically invalid generated patches, impeding the practicality of the\ntechnique. Therefore, we propose Repilot, a framework to further copilot the AI\n\"copilots\" (i.e., LLMs) by synthesizing more valid patches during the repair\nprocess. Our key insight is that many LLMs produce outputs autoregressively\n(i.e., token by token), resembling human writing programs, which can be\nsignificantly boosted and guided through a Completion Engine. Repilot\nsynergistically synthesizes a candidate patch through the interaction between\nan LLM and a Completion Engine, which 1) prunes away infeasible tokens\nsuggested by the LLM and 2) proactively completes the token based on the\nsuggestions provided by the Completion Engine. Our evaluation on a subset of\nthe widely-used Defects4j 1.2 and 2.0 datasets shows that Repilot fixes 66 and\n50 bugs, respectively, surpassing the best-performing baseline by 14 and 16\nbugs fixed. More importantly, Repilot is capable of producing more valid and\ncorrect patches than the base LLM when given the same generation budget.",
          "link": "http://arxiv.org/abs/2309.00608",
          "publishedOn": "2023-10-21T00:41:42.853Z",
          "wordCount": null,
          "title": "Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair. (arXiv:2309.00608v2 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04228",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Meles_G/0/1/0/all/0/1\">Giovanni Angelo Meles</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Amaya_M/0/1/0/all/0/1\">Macarena Amaya</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Levy_S/0/1/0/all/0/1\">Shiran Levy</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Marelli_S/0/1/0/all/0/1\">Stefano Marelli</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Linde_N/0/1/0/all/0/1\">Niklas Linde</a>",
          "description": "Implementations of Markov chain Monte Carlo (MCMC) methods need to confront\ntwo fundamental challenges: accurate representation of prior information and\nefficient evaluation of likelihoods. Principal component analysis (PCA) and\nrelated techniques can in some cases facilitate the definition and sampling of\nthe prior distribution, as well as the training of accurate surrogate models,\nusing for instance, polynomial chaos expansion (PCE). However, complex\ngeological priors with sharp contrasts necessitate more complex\ndimensionality-reduction techniques, such as, deep generative models (DGMs). By\nsampling a low-dimensional prior probability distribution defined in the\nlow-dimensional latent space of such a model, it becomes possible to\nefficiently sample the physical domain at the price of a generator that is\ntypically highly non-linear. Training a surrogate that is capable of capturing\nintricate non-linear relationships between latent parameters and outputs of\nforward modeling presents a notable challenge. Indeed, while PCE models provide\nhigh accuracy when the input-output relationship can be effectively\napproximated by relatively low-degree multivariate polynomials, this condition\nis typically not met when employing latent variables derived from DGMs. In this\ncontribution, we present a strategy combining the excellent reconstruction\nperformances of a variational autoencoder (VAE) with the accuracy of PCA-PCE\nsurrogate modeling in the context of Bayesian ground penetrating radar (GPR)\ntraveltime tomography. Within the MCMC process, the parametrization of the VAE\nis leveraged for prior exploration and sample proposals. Concurrently,\nsurrogate modeling is conducted using PCE, which operates on either globally or\nlocally defined principal components of the VAE samples under examination.",
          "link": "http://arxiv.org/abs/2307.04228",
          "publishedOn": "2023-10-21T00:41:42.851Z",
          "wordCount": null,
          "title": "Bayesian tomography using polynomial chaos expansion and deep generative networks. (arXiv:2307.04228v4 [physics.geo-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.05161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Svete_A/0/1/0/all/0/1\">Anej Svete</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Studying language models (LMs) in terms of well-understood formalisms allows\nus to precisely characterize their abilities and limitations. Previous work has\ninvestigated the representational capacity of recurrent neural network (RNN)\nLMs in terms of their capacity to recognize unweighted formal languages.\nHowever, LMs do not describe unweighted formal languages -- rather, they define\nprobability distributions over strings. In this work, we study what classes of\nsuch probability distributions RNN LMs can represent, which allows us to make\nmore direct statements about their capabilities. We show that simple RNNs are\nequivalent to a subclass of probabilistic finite-state automata, and can thus\nmodel a strict subset of probability distributions expressible by finite-state\nmodels. Furthermore, we study the space complexity of representing finite-state\nLMs with RNNs. We show that, to represent an arbitrary deterministic\nfinite-state LM with $N$ states over an alphabet $\\Sigma$, an RNN requires\n$\\Omega\\left(N |\\Sigma|\\right)$ neurons. These results present a first step\ntowards characterizing the classes of distributions RNN LMs can represent and\nthus help us understand their capabilities and limitations.",
          "link": "http://arxiv.org/abs/2310.05161",
          "publishedOn": "2023-10-21T00:41:42.851Z",
          "wordCount": null,
          "title": "Recurrent Neural Language Models as Probabilistic Finite-state Automata. (arXiv:2310.05161v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sehgal_A/0/1/0/all/0/1\">Atharva Sehgal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grayeli_A/0/1/0/all/0/1\">Arya Grayeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1\">Swarat Chaudhuri</a>",
          "description": "We introduce Cosmos, a framework for object-centric world modeling that is\ndesigned for compositional generalization (CG), i.e., high performance on\nunseen input scenes obtained through the composition of known visual \"atoms.\"\nThe central insight behind Cosmos is the use of a novel form of neurosymbolic\ngrounding. Specifically, the framework introduces two new tools: (i)\nneurosymbolic scene encodings, which represent each entity in a scene using a\nreal vector computed using a neural encoder, as well as a vector of composable\nsymbols describing attributes of the entity, and (ii) a neurosymbolic attention\nmechanism that binds these entities to learned rules of interaction. Cosmos is\nend-to-end differentiable; also, unlike traditional neurosymbolic methods that\nrequire representations to be manually mapped to symbols, it computes an\nentity's symbolic attributes using vision-language foundation models. Through\nan evaluation that considers two different forms of CG on an established\nblocks-pushing domain, we show that the framework establishes a new\nstate-of-the-art for CG in world modeling.",
          "link": "http://arxiv.org/abs/2310.12690",
          "publishedOn": "2023-10-21T00:41:42.850Z",
          "wordCount": null,
          "title": "Neurosymbolic Grounding for Compositional World Models. (arXiv:2310.12690v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08854",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1\">Yifan Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1\">Weicong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yiduo Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yuhui Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yukang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Han Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>",
          "description": "Modern detection transformers (DETRs) use a set of object queries to predict\na list of bounding boxes, sort them by their classification confidence scores,\nand select the top-ranked predictions as the final detection results for the\ngiven input image. A highly performant object detector requires accurate\nranking for the bounding box predictions. For DETR-based detectors, the\ntop-ranked bounding boxes suffer from less accurate localization quality due to\nthe misalignment between classification scores and localization accuracy, thus\nimpeding the construction of high-quality detectors. In this work, we introduce\na simple and highly performant DETR-based object detector by proposing a series\nof rank-oriented designs, combinedly called Rank-DETR. Our key contributions\ninclude: (i) a rank-oriented architecture design that can prompt positive\npredictions and suppress the negative ones to ensure lower false positive\nrates, as well as (ii) a rank-oriented loss function and matching cost design\nthat prioritizes predictions of more accurate localization accuracy during\nranking to boost the AP under high IoU thresholds. We apply our method to\nimprove the recent SOTA methods (e.g., H-DETR and DINO-DETR) and report strong\nCOCO object detection results when using different backbones such as\nResNet-$50$, Swin-T, and Swin-L, demonstrating the effectiveness of our\napproach. Code is available at \\url{https://github.com/LeapLabTHU/Rank-DETR}.",
          "link": "http://arxiv.org/abs/2310.08854",
          "publishedOn": "2023-10-21T00:41:42.850Z",
          "wordCount": null,
          "title": "Rank-DETR for High Quality Object Detection. (arXiv:2310.08854v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Holvoet_F/0/1/0/all/0/1\">Freek Holvoet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antonio_K/0/1/0/all/0/1\">Katrien Antonio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henckaerts_R/0/1/0/all/0/1\">Roel Henckaerts</a>",
          "description": "Insurers usually turn to generalized linear models for modelling claim\nfrequency and severity data. Due to their success in other fields, machine\nlearning techniques are gaining popularity within the actuarial toolbox. Our\npaper contributes to the literature on frequency-severity insurance pricing\nwith machine learning via deep learning structures. We present a benchmark\nstudy on four insurance data sets with frequency and severity targets in the\npresence of multiple types of input features. We compare in detail the\nperformance of: a generalized linear model on binned input data, a\ngradient-boosted tree model, a feed-forward neural network (FFNN), and the\ncombined actuarial neural network (CANN). Our CANNs combine a baseline\nprediction established with a GLM and GBM, respectively, with a neural network\ncorrection. We explain the data preprocessing steps with specific focus on the\nmultiple types of input features typically present in tabular insurance data\nsets, such as postal codes, numeric and categorical covariates. Autoencoders\nare used to embed the categorical variables into the neural network and we\nexplore their potential advantages in a frequency-severity setting. Finally, we\nconstruct global surrogate models for the neural nets' frequency and severity\nmodels. These surrogates enable the translation of the essential insights\ncaptured by the FFNNs or CANNs to GLMs. As such, a technical tariff table\nresults that can easily be deployed in practice.",
          "link": "http://arxiv.org/abs/2310.12671",
          "publishedOn": "2023-10-21T00:41:42.845Z",
          "wordCount": null,
          "title": "Neural networks for insurance pricing with frequency and severity data: a benchmark study from data preprocessing to technical tariff. (arXiv:2310.12671v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Wei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Haitao Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haoming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1\">Chen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1\">Hongzhi Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1\">Haoyu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruirui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Monica Xiao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goutam_R/0/1/0/all/0/1\">Rahul Goutam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haiyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subbian_K/0/1/0/all/0/1\">Karthik Subbian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yizhou Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xianfeng Tang</a>",
          "description": "Modeling customer shopping intentions is a crucial task for e-commerce, as it\ndirectly impacts user experience and engagement. Thus, accurately understanding\ncustomer preferences is essential for providing personalized recommendations.\nSession-based recommendation, which utilizes customer session data to predict\ntheir next interaction, has become increasingly popular. However, existing\nsession datasets have limitations in terms of item attributes, user diversity,\nand dataset scale. As a result, they cannot comprehensively capture the\nspectrum of user behaviors and preferences. To bridge this gap, we present the\nAmazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It\nis the first multilingual dataset consisting of millions of user sessions from\nsix different locales, where the major languages of products are English,\nGerman, Japanese, French, Italian, and Spanish. Remarkably, the dataset can\nhelp us enhance personalization and understanding of user preferences, which\ncan benefit various existing tasks as well as enable new tasks. To test the\npotential of the dataset, we introduce three tasks in this work: (1)\nnext-product recommendation, (2) next-product recommendation with domain\nshifts, and (3) next-product title generation. With the above tasks, we\nbenchmark a range of algorithms on our proposed dataset, drawing new insights\nfor further research and practice. In addition, based on the proposed dataset\nand tasks, we hosted a competition in the KDD CUP 2023 and have attracted\nthousands of users and submissions. The winning solutions and the associated\nworkshop can be accessed at our website https://kddcup23.github.io/.",
          "link": "http://arxiv.org/abs/2307.09688",
          "publishedOn": "2023-10-21T00:41:42.836Z",
          "wordCount": null,
          "title": "Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation. (arXiv:2307.09688v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhipeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1\">Nanqing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiahao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knottenbelt_W/0/1/0/all/0/1\">William Knottenbelt</a>",
          "description": "Federated Learning (FL) is a machine learning paradigm, which enables\nmultiple and decentralized clients to collaboratively train a model under the\norchestration of a central aggregator. Traditional FL solutions rely on the\ntrust assumption of the centralized aggregator, which forms cohorts of clients\nin a fair and honest manner. However, a malicious aggregator, in reality, could\nabandon and replace the client's training models, or launch Sybil attacks to\ninsert fake clients. Such malicious behaviors give the aggregator more power to\ncontrol clients in the FL setting and determine the final training results. In\nthis work, we introduce zkFL, which leverages zero-knowledge proofs (ZKPs) to\ntackle the issue of a malicious aggregator during the training model\naggregation process. To guarantee the correct aggregation results, the\naggregator needs to provide a proof per round. The proof can demonstrate to the\nclients that the aggregator executes the intended behavior faithfully. To\nfurther reduce the verification cost of clients, we employ a blockchain to\nhandle the proof in a zero-knowledge way, where miners (i.e., the nodes\nvalidating and maintaining the blockchain data) can verify the proof without\nknowing the clients' local and aggregated models. The theoretical analysis and\nempirical results show that zkFL can achieve better security and privacy than\ntraditional FL, without modifying the underlying FL network structure or\nheavily compromising the training speed.",
          "link": "http://arxiv.org/abs/2310.02554",
          "publishedOn": "2023-10-21T00:41:42.836Z",
          "wordCount": null,
          "title": "zkFL: Zero-Knowledge Proof-based Gradient Aggregation for Federated Learning. (arXiv:2310.02554v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12802",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Arola_Fernandez_L/0/1/0/all/0/1\">Llu&#xed;s Arola-Fern&#xe1;ndez</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lacasa_L/0/1/0/all/0/1\">Lucas Lacasa</a>",
          "description": "Unraveling the emergence of collective learning in systems of coupled\nartificial neural networks is an endeavor with broader implications for\nphysics, machine learning, neuroscience and society. Here we introduce a\nminimal model that condenses several recent decentralized algorithms by\nconsidering a competition between two terms: the local learning dynamics in the\nparameters of each neural network unit, and a diffusive coupling among units\nthat tends to homogenize the parameters of the ensemble. We derive the\ncoarse-grained behavior of our model via an effective theory for linear\nnetworks that we show is analogous to a deformed Ginzburg-Landau model with\nquenched disorder. This framework predicts (depth-dependent)\ndisorder-order-disorder phase transitions in the parameters' solutions that\nreveal the onset of a collective learning phase, along with a depth-induced\ndelay of the critical point and a robust shape of the microscopic learning\npath. We validate our theory in realistic ensembles of coupled nonlinear\nnetworks trained in the MNIST dataset under privacy constraints. Interestingly,\nexperiments confirm that individual networks -- trained only with private data\n-- can fully generalize to unseen data classes when the collective learning\nphase emerges. Our work elucidates the physics of collective learning and\ncontributes to the mechanistic interpretability of deep learning in\ndecentralized settings.",
          "link": "http://arxiv.org/abs/2310.12802",
          "publishedOn": "2023-10-21T00:41:42.825Z",
          "wordCount": null,
          "title": "An effective theory of collective deep learning. (arXiv:2310.12802v1 [physics.soc-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.11586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Egressy_B/0/1/0/all/0/1\">B&#xe9;ni Egressy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niederhausern_L/0/1/0/all/0/1\">Luc von Niederh&#xe4;usern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanusa_J/0/1/0/all/0/1\">Jovan Blanusa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altman_E/0/1/0/all/0/1\">Erik Altman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1\">Roger Wattenhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atasu_K/0/1/0/all/0/1\">Kubilay Atasu</a>",
          "description": "This paper analyses a set of simple adaptations that transform standard\nmessage-passing Graph Neural Networks (GNN) into provably powerful directed\nmultigraph neural networks. The adaptations include multigraph port numbering,\nego IDs, and reverse message passing. We prove that the combination of these\ntheoretically enables the detection of any directed subgraph pattern. To\nvalidate the effectiveness of our proposed adaptations in practice, we conduct\nexperiments on synthetic subgraph detection tasks, which demonstrate\noutstanding performance with almost perfect results. Moreover, we apply our\nproposed adaptations to two financial crime analysis tasks. We observe dramatic\nimprovements in detecting money laundering transactions, improving the\nminority-class F1 score of a standard message-passing GNN by up to 30%, and\nclosely matching or outperforming tree-based and GNN baselines. Similarly\nimpressive results are observed on a real-world phishing detection dataset,\nboosting three standard GNNs' F1 scores by around 15% and outperforming all\nbaselines.",
          "link": "http://arxiv.org/abs/2306.11586",
          "publishedOn": "2023-10-21T00:41:42.789Z",
          "wordCount": null,
          "title": "Provably Powerful Graph Neural Networks for Directed Multigraphs. (arXiv:2306.11586v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12544",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+OLoughlin_L/0/1/0/all/0/1\">Luke O&#x27;Loughlin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maclean_J/0/1/0/all/0/1\">John Maclean</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Black_A/0/1/0/all/0/1\">Andrew Black</a>",
          "description": "Stochastic processes defined on integer valued state spaces are popular\nwithin the physical and biological sciences. These models are necessary for\ncapturing the dynamics of small systems where the individual nature of the\npopulations cannot be ignored and stochastic effects are important. The\ninference of the parameters of such models, from time series data, is difficult\ndue to intractability of the likelihood; current methods, based on simulations\nof the underlying model, can be so computationally expensive as to be\nprohibitive. In this paper we construct a neural likelihood approximation for\ninteger valued time series data using causal convolutions, which allows us to\nevaluate the likelihood of the whole time series in parallel. We demonstrate\nour method by performing inference on a number of ecological and\nepidemiological models, showing that we can accurately approximate the true\nposterior while achieving significant computational speed ups in situations\nwhere current methods struggle.",
          "link": "http://arxiv.org/abs/2310.12544",
          "publishedOn": "2023-10-21T00:41:42.778Z",
          "wordCount": null,
          "title": "Neural Likelihood Approximation for Integer Valued Time Series Data. (arXiv:2310.12544v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12631",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Bachtis_D/0/1/0/all/0/1\">Dimitrios Bachtis</a>",
          "description": "We propose inverse renormalization group transformations to construct\napproximate configurations for lattice volumes that have not yet been accessed\nby supercomputers or large-scale simulations in the study of spin glasses.\nSpecifically, starting from lattices of volume $V=8^{3}$ in the case of the\nthree-dimensional Edwards-Anderson model we employ machine learning algorithms\nto construct rescaled lattices up to $V'=128^{3}$, which we utilize to extract\ntwo critical exponents. We conclude by discussing how to incorporate numerical\nexactness within inverse renormalization group approaches of disordered\nsystems, thus opening up the opportunity to explore a sustainable and\nenergy-efficient generation of exact configurations for increasing lattice\nvolumes without the use of dedicated supercomputers.",
          "link": "http://arxiv.org/abs/2310.12631",
          "publishedOn": "2023-10-21T00:41:42.774Z",
          "wordCount": null,
          "title": "Inverse Renormalization Group of Disordered Systems. (arXiv:2310.12631v1 [cond-mat.stat-mech])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maison_L/0/1/0/all/0/1\">Lucas Maison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bourboux_H/0/1/0/all/0/1\">H&#xe9;lion du Mas des Bourboux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courtat_T/0/1/0/all/0/1\">Thomas Courtat</a>",
          "description": "Compressing neural networks is a key step when deploying models for real-time\nor embedded applications. Factorizing the model's matrices using low-rank\napproximations is a promising method for achieving compression. While it is\npossible to set the rank before training, this approach is neither flexible nor\noptimal. In this work, we propose a post-training rank-selection method called\nRank-Tuning that selects a different rank for each matrix. Used in combination\nwith training adaptations, our method achieves high compression rates with no\nor little performance degradation. Our numerical experiments on signal\nprocessing tasks show that we can compress recurrent neural networks up to 14x\nwith at most 1.4% relative performance reduction.",
          "link": "http://arxiv.org/abs/2310.12688",
          "publishedOn": "2023-10-21T00:41:42.766Z",
          "wordCount": null,
          "title": "Compression of Recurrent Neural Networks using Matrix Factorization. (arXiv:2310.12688v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1\">Syed Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filipovska_M/0/1/0/all/0/1\">Monika Filipovska</a>",
          "description": "Traffic state forecasting is crucial for traffic management and control\nstrategies, as well as user- and system-level decision making in the\ntransportation network. While traffic forecasting has been approached with a\nvariety of techniques over the last couple of decades, most approaches simply\nrely on endogenous traffic variables for state prediction, despite the evidence\nthat exogenous factors can significantly impact traffic conditions. This paper\nproposes a multi-dimensional spatio-temporal graph attention-based traffic\nprediction approach (M-STGAT), which predicts traffic based on past\nobservations of speed, along with lane closure events, temperature, and\nvisibility across the transportation network. The approach is based on a graph\nattention network architecture, which also learns based on the structure of the\ntransportation network on which these variables are observed. Numerical\nexperiments are performed using traffic speed and lane closure data from the\nCalifornia Department of Transportation (Caltrans) Performance Measurement\nSystem (PeMS). The corresponding weather data were downloaded from the National\nOceanic and Atmospheric Administration (NOOA) Automated Surface Observing\nSystems (ASOS). For comparison, the numerical experiments implement three\nalternative models which do not allow for the multi-dimensional input. The\nM-STGAT is shown to outperform the three alternative models, when performing\ntests using our primary data set for prediction with a 30-, 45-, and 60-minute\nprediction horizon, in terms of three error measures: Mean Absolute Error\n(MAE), Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE).\nHowever, the model's transferability can vary for different transfer data sets\nand this aspect may require further investigation.",
          "link": "http://arxiv.org/abs/2310.12353",
          "publishedOn": "2023-10-21T00:41:42.763Z",
          "wordCount": null,
          "title": "Networkwide Traffic State Forecasting Using Exogenous Information: A Multi-Dimensional Graph Attention-Based Approach. (arXiv:2310.12353v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1\">Jungbin Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>",
          "description": "Time is one of the crucial factors in real-world question answering (QA)\nproblems. However, language models have difficulty understanding the\nrelationships between time specifiers, such as 'after' and 'before', and\nnumbers, since existing QA datasets do not include sufficient time expressions.\nTo address this issue, we propose a Time-Context aware Question Answering\n(TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE)\ntask, and build a time-context dependent data generation framework for model\ntraining. Moreover, we present a metric to evaluate the time awareness of the\nQA model using TCSE. The TCSE task consists of a question and four sentence\ncandidates classified as correct or incorrect based on time and context. The\nmodel is trained to extract the answer span from the sentence that is both\ncorrect in time and context. The model trained with TCQA outperforms baseline\nmodels up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code\nare available at https://github.com/sonjbin/TCQA",
          "link": "http://arxiv.org/abs/2310.12585",
          "publishedOn": "2023-10-21T00:41:42.755Z",
          "wordCount": null,
          "title": "Time-Aware Representation Learning for Time-Sensitive Question Answering. (arXiv:2310.12585v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guanzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuqi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yunfan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandlekar_A/0/1/0/all/0/1\">Ajay Mandlekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Linxi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "We introduce Voyager, the first LLM-powered embodied lifelong learning agent\nin Minecraft that continuously explores the world, acquires diverse skills, and\nmakes novel discoveries without human intervention. Voyager consists of three\nkey components: 1) an automatic curriculum that maximizes exploration, 2) an\never-growing skill library of executable code for storing and retrieving\ncomplex behaviors, and 3) a new iterative prompting mechanism that incorporates\nenvironment feedback, execution errors, and self-verification for program\nimprovement. Voyager interacts with GPT-4 via blackbox queries, which bypasses\nthe need for model parameter fine-tuning. The skills developed by Voyager are\ntemporally extended, interpretable, and compositional, which compounds the\nagent's abilities rapidly and alleviates catastrophic forgetting. Empirically,\nVoyager shows strong in-context lifelong learning capability and exhibits\nexceptional proficiency in playing Minecraft. It obtains 3.3x more unique\nitems, travels 2.3x longer distances, and unlocks key tech tree milestones up\nto 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill\nlibrary in a new Minecraft world to solve novel tasks from scratch, while other\ntechniques struggle to generalize. We open-source our full codebase and prompts\nat https://voyager.minedojo.org/.",
          "link": "http://arxiv.org/abs/2305.16291",
          "publishedOn": "2023-10-21T00:41:42.725Z",
          "wordCount": null,
          "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models. (arXiv:2305.16291v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.01319",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ahmed_I/0/1/0/all/0/1\">I. Zakir Ahmed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sadjadpour_H/0/1/0/all/0/1\">Hamid R. Sadjadpour</a>",
          "description": "The Orthogonal-Time-Frequency-Space (OTFS) signaling is known to be resilient\nto doubly-dispersive channels, which impacts high mobility scenarios. On the\nother hand, the Orthogonal-Frequency-Division-Multiplexing (OFDM) waveforms\nenjoy the benefits of the reuse of legacy architectures, simplicity of receiver\ndesign, and low-complexity detection. Several studies that compare the\nperformance of OFDM and OTFS have indicated mixed outcomes due to the plethora\nof system parameters at play beyond high-mobility conditions. In this work, we\nexemplify this observation using simulations and propose a deep neural network\n(DNN)-based adaptation scheme to switch between using either an OTFS or OFDM\nsignal processing chain at the transmitter and receiver for optimal\nmean-squared-error (MSE) performance. The DNN classifier is trained to switch\nbetween the two schemes by observing the channel condition, received SNR, and\nmodulation format. We compare the performance of the OTFS, OFDM, and the\nproposed switched-waveform scheme. The simulations indicate superior\nperformance with the proposed scheme with a well-trained DNN, thus improving\nthe MSE performance of the communication significantly.",
          "link": "http://arxiv.org/abs/2309.01319",
          "publishedOn": "2023-10-21T00:41:42.721Z",
          "wordCount": null,
          "title": "An ML-assisted OTFS vs. OFDM adaptable modem. (arXiv:2309.01319v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Openja_M/0/1/0/all/0/1\">Moses Openja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laberge_G/0/1/0/all/0/1\">Gabriel Laberge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1\">Foutse Khomh</a>",
          "description": "The cause-to-effect analysis can help us decompose all the likely causes of a\nproblem, such as an undesirable business situation or unintended harm to the\nindividual(s). This implies that we can identify how the problems are\ninherited, rank the causes to help prioritize fixes, simplify a complex problem\nand visualize them. In the context of machine learning (ML), one can use\ncause-to-effect analysis to understand the reason for the biased behavior of\nthe system. For example, we can examine the root causes of biases by checking\neach feature for a potential cause of bias in the model. To approach this, one\ncan apply small changes to a given feature or a pair of features in the data,\nfollowing some guidelines and observing how it impacts the decision made by the\nmodel (i.e., model prediction). Therefore, we can use cause-to-effect analysis\nto identify the potential bias-inducing features, even when these features are\noriginally are unknown. This is important since most current methods require a\npre-identification of sensitive features for bias assessment and can actually\nmiss other relevant bias-inducing features, which is why systematic\nidentification of such features is necessary. Moreover, it often occurs that to\nachieve an equitable outcome, one has to take into account sensitive features\nin the model decision. Therefore, it should be up to the domain experts to\ndecide based on their knowledge of the context of a decision whether bias\ninduced by specific features is acceptable or not. In this study, we propose an\napproach for systematically identifying all bias-inducing features of a model\nto help support the decision-making of domain experts. We evaluated our\ntechnique using four well-known datasets to showcase how our contribution can\nhelp spearhead the standard procedure when developing, testing, maintaining,\nand deploying fair/equitable machine learning systems.",
          "link": "http://arxiv.org/abs/2310.12805",
          "publishedOn": "2023-10-21T00:41:42.715Z",
          "wordCount": null,
          "title": "Detection and Evaluation of bias-inducing Features in Machine learning. (arXiv:2310.12805v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takhanov_R/0/1/0/all/0/1\">Rustem Takhanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tezekbayev_M/0/1/0/all/0/1\">Maxat Tezekbayev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pak_A/0/1/0/all/0/1\">Artur Pak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolatov_A/0/1/0/all/0/1\">Arman Bolatov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assylbekov_Z/0/1/0/all/0/1\">Zhenisbek Assylbekov</a>",
          "description": "Classes of target functions containing a large number of approximately\northogonal elements are known to be hard to learn by the Statistical Query\nalgorithms. Recently this classical fact re-emerged in a theory of\ngradient-based optimization of neural networks. In the novel framework, the\nhardness of a class is usually quantified by the variance of the gradient with\nrespect to a random choice of a target function.\n\nA set of functions of the form $x\\to ax \\bmod p$, where $a$ is taken from\n${\\mathbb Z}_p$, has attracted some attention from deep learning theorists and\ncryptographers recently. This class can be understood as a subset of\n$p$-periodic functions on ${\\mathbb Z}$ and is tightly connected with a class\nof high-frequency periodic functions on the real line.\n\nWe present a mathematical analysis of limitations and challenges associated\nwith using gradient-based learning techniques to train a high-frequency\nperiodic function or modular multiplication from examples. We highlight that\nthe variance of the gradient is negligibly small in both cases when either a\nfrequency or the prime base $p$ is large. This in turn prevents such a learning\nalgorithm from being successful.",
          "link": "http://arxiv.org/abs/2310.12660",
          "publishedOn": "2023-10-21T00:41:42.713Z",
          "wordCount": null,
          "title": "Gradient Descent Fails to Learn High-frequency Functions and Modular Arithmetic. (arXiv:2310.12660v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhouxing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_F/0/1/0/all/0/1\">Fan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiangning Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>",
          "description": "The prevalence and strong capability of large language models (LLMs) present\nsignificant safety and ethical risks if exploited by malicious users. To\nprevent the potentially deceptive usage of LLMs, recent works have proposed\nalgorithms to detect LLM-generated text and protect LLMs. In this paper, we\ninvestigate the robustness and reliability of these LLM detectors under\nadversarial attacks. We study two types of attack strategies: 1) replacing\ncertain words in an LLM's output with their synonyms given the context; 2)\nautomatically searching for an instructional prompt to alter the writing style\nof the generation. In both strategies, we leverage an auxiliary LLM to generate\nthe word replacements or the instructional prompt. Different from previous\nworks, we consider a challenging setting where the auxiliary LLM can also be\nprotected by a detector. Experiments reveal that our attacks effectively\ncompromise the performance of all detectors in the study with plausible\ngenerations, underscoring the urgent need to improve the robustness of\nLLM-generated text detection systems.",
          "link": "http://arxiv.org/abs/2305.19713",
          "publishedOn": "2023-10-21T00:41:42.709Z",
          "wordCount": null,
          "title": "Red Teaming Language Model Detectors with Language Models. (arXiv:2305.19713v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.11084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yifei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Juntao Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fengyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabih_R/0/1/0/all/0/1\">Ramin Zabih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Ser-Nam Lim</a>",
          "description": "Advances in the field of vision-language contrastive learning have made it\npossible for many downstream applications to be carried out efficiently and\naccurately by simply taking the dot product between image and text\nrepresentations. One of the most representative approaches proposed recently\nknown as CLIP has garnered widespread adoption due to its effectiveness. CLIP\nis trained with an InfoNCE loss that takes into account both positive and\nnegative samples to help learn a much more robust representation space. This\npaper reveals that the common downstream practice of taking a dot product is\nonly a zeroth-order approximation of the optimization goal, resulting in a loss\nof information during test-time. Intuitively, since the model has been\noptimized based on the InfoNCE loss, test-time procedures should also be in\nalignment. The question lies in how one can retrieve any semblance of negative\nsamples information during inference in a computationally efficient way. To\nthis end, we propose Distribution Normalization (DN), where we approximate the\nmean representation of a batch of test samples and use such a mean to represent\nwhat would be analogous to negative samples in the InfoNCE loss. DN requires no\nretraining or fine-tuning and can be effortlessly applied during inference.\nExtensive experiments on a wide variety of downstream tasks exhibit a clear\nadvantage of DN over the dot product on top of other existing test-time\naugmentation methods.",
          "link": "http://arxiv.org/abs/2302.11084",
          "publishedOn": "2023-10-21T00:41:42.686Z",
          "wordCount": null,
          "title": "Test-Time Distribution Normalization for Contrastively Learned Vision-language Models. (arXiv:2302.11084v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudalairaj_S/0/1/0/all/0/1\">Shivchander Sudalairaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henning_J/0/1/0/all/0/1\">John Henning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenewald_K/0/1/0/all/0/1\">Kristjan Greenewald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1\">Akash Srivastava</a>",
          "description": "Existing private synthetic data generation algorithms are agnostic to\ndownstream tasks. However, end users may have specific requirements that the\nsynthetic data must satisfy. Failure to meet these requirements could\nsignificantly reduce the utility of the data for downstream use. We introduce a\npost-processing technique that improves the utility of the synthetic data with\nrespect to measures selected by the end user, while preserving strong privacy\nguarantees and dataset quality. Our technique involves resampling from the\nsynthetic data to filter out samples that do not meet the selected utility\nmeasures, using an efficient stochastic first-order algorithm to find optimal\nresampling weights. Through comprehensive numerical experiments, we demonstrate\nthat our approach consistently improves the utility of synthetic data across\nmultiple benchmark datasets and state-of-the-art synthetic data generation\nalgorithms.",
          "link": "http://arxiv.org/abs/2305.15538",
          "publishedOn": "2023-10-21T00:41:42.686Z",
          "wordCount": null,
          "title": "Post-processing Private Synthetic Data for Improving Utility on Selected Measures. (arXiv:2305.15538v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.14090",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Dai_Z/0/1/0/all/0/1\">Zhenyu Dai</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Moews_B/0/1/0/all/0/1\">Ben Moews</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Vilalta_R/0/1/0/all/0/1\">Ricardo Vilalta</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Dave_R/0/1/0/all/0/1\">Romeel Dave</a>",
          "description": "Physics-informed neural networks have emerged as a coherent framework for\nbuilding predictive models that combine statistical patterns with domain\nknowledge. The underlying notion is to enrich the optimization loss function\nwith known relationships to constrain the space of possible solutions.\nHydrodynamic simulations are a core constituent of modern cosmology, while the\nrequired computations are both expensive and time-consuming. At the same time,\nthe comparatively fast simulation of dark matter requires fewer resources,\nwhich has led to the emergence of machine learning algorithms for baryon\ninpainting as an active area of research; here, recreating the scatter found in\nhydrodynamic simulations is an ongoing challenge. This paper presents the first\napplication of physics-informed neural networks to baryon inpainting by\ncombining advances in neural network architectures with physical constraints,\ninjecting theory on baryon conversion efficiency into the model loss function.\nWe also introduce a punitive prediction comparison based on the\nKullback-Leibler divergence, which enforces scatter reproduction. By\nsimultaneously extracting the complete set of baryonic properties for the Simba\nsuite of cosmological simulations, our results demonstrate improved accuracy of\nbaryonic predictions based on dark matter halo properties, successful recovery\nof the fundamental metallicity relation, and retrieve scatter that traces the\ntarget simulation's distribution.",
          "link": "http://arxiv.org/abs/2303.14090",
          "publishedOn": "2023-10-21T00:41:42.596Z",
          "wordCount": null,
          "title": "Physics-informed neural networks in the recreation of hydrodynamic simulations from dark matter. (arXiv:2303.14090v2 [astro-ph.CO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hahn_Y/0/1/0/all/0/1\">Yannik Hahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maack_R/0/1/0/all/0/1\">Robert Maack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buchholz_G/0/1/0/all/0/1\">Guido Buchholz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purrio_M/0/1/0/all/0/1\">Marion Purrio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angerhausen_M/0/1/0/all/0/1\">Matthias Angerhausen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tercan_H/0/1/0/all/0/1\">Hasan Tercan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meisen_T/0/1/0/all/0/1\">Tobias Meisen</a>",
          "description": "The digitization of manufacturing processes enables promising applications\nfor machine learning-assisted quality assurance. A widely used manufacturing\nprocess that can strongly benefit from data-driven solutions is \\ac{GMAW}. The\nwelding process is characterized by complex cause-effect relationships between\nmaterial properties, process conditions and weld quality. In non-laboratory\nenvironments with frequently changing process parameters, accurate\ndetermination of weld quality by destructive testing is economically\nunfeasible. Deep learning offers the potential to identify the relationships in\navailable process data and predict the weld quality from process observations.\nIn this paper, we present a concept for a deep learning based predictive\nquality system in \\ac{GMAW}. At its core, the concept involves a pipeline\nconsisting of four major phases: collection and management of multi-sensor data\n(e.g. current and voltage), real-time processing and feature engineering of the\ntime series data by means of autoencoders, training and deployment of suitable\nrecurrent deep learning models for quality predictions, and model evolutions\nunder changing process conditions using continual learning. The concept\nprovides the foundation for future research activities in which we will realize\nan online predictive quality system for running production.",
          "link": "http://arxiv.org/abs/2310.12632",
          "publishedOn": "2023-10-21T00:41:42.587Z",
          "wordCount": null,
          "title": "Towards a Deep Learning-based Online Quality Prediction System for Welding Processes. (arXiv:2310.12632v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jiaming Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Borong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiayi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xuehai Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Weidong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruiyang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_Y/0/1/0/all/0/1\">Yiran Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yifan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Juntao Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>",
          "description": "Artificial intelligence (AI) systems possess significant potential to drive\nsocietal progress. However, their deployment often faces obstacles due to\nsubstantial safety concerns. Safe reinforcement learning (SafeRL) emerges as a\nsolution to optimize policies while simultaneously adhering to multiple\nconstraints, thereby addressing the challenge of integrating reinforcement\nlearning in safety-critical scenarios. In this paper, we present an environment\nsuite called Safety-Gymnasium, which encompasses safety-critical tasks in both\nsingle and multi-agent scenarios, accepting vector and vision-only input.\nAdditionally, we offer a library of algorithms named Safe Policy Optimization\n(SafePO), comprising 16 state-of-the-art SafeRL algorithms. This comprehensive\nlibrary can serve as a validation tool for the research community. By\nintroducing this benchmark, we aim to facilitate the evaluation and comparison\nof safety performance, thus fostering the development of reinforcement learning\nfor safer, more reliable, and responsible real-world applications. The website\nof this project can be accessed at\nhttps://sites.google.com/view/safety-gymnasium.",
          "link": "http://arxiv.org/abs/2310.12567",
          "publishedOn": "2023-10-21T00:41:42.584Z",
          "wordCount": null,
          "title": "Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark. (arXiv:2310.12567v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1\">Wei Ping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAfee_L/0/1/0/all/0/1\">Lawrence McAfee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1\">Mohammad Shoeybi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yi Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuchaiev_O/0/1/0/all/0/1\">Oleksii Kuchaiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>",
          "description": "Large decoder-only language models (LMs) can be largely improved in terms of\nperplexity by retrieval (e.g., RETRO), but its impact on text generation\nquality and downstream task accuracy is unclear. Thus, it is still an open\nquestion: shall we pretrain large autoregressive LMs with retrieval? To answer\nit, we perform a comprehensive study on a scalable pre-trained\nretrieval-augmented LM (i.e., RETRO) compared with standard GPT and\nretrieval-augmented GPT incorporated at fine-tuning or inference stages. We\nfirst provide the recipe to reproduce RETRO up to 9.5B parameters while\nretrieving a text corpus with 330B tokens. Based on that, we have the following\nnovel findings: i) RETRO outperforms GPT on text generation with much less\ndegeneration (i.e., repetition), moderately higher factual accuracy, and\nslightly lower toxicity with a nontoxic retrieval database. ii) On the LM\nEvaluation Harness benchmark, RETRO largely outperforms GPT on\nknowledge-intensive tasks, but is on par with GPT on other tasks. Furthermore,\nwe introduce a simple variant of the model, RETRO++, which largely improves\nopen-domain QA results of original RETRO (e.g., EM score +8.6 on Natural\nQuestion) and significantly outperforms retrieval-augmented GPT in both\nfine-tuning and zero-shot evaluation settings. Our findings highlight the\npromising direction of pretraining autoregressive LMs with retrieval as future\nfoundation models. We release our implementation at:\nhttps://github.com/NVIDIA/Megatron-LM#retro.",
          "link": "http://arxiv.org/abs/2304.06762",
          "publishedOn": "2023-10-21T00:41:42.574Z",
          "wordCount": null,
          "title": "Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study. (arXiv:2304.06762v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hull_M/0/1/0/all/0/1\">Matthew Hull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijie J. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1\">Duen Horng Chau</a>",
          "description": "Deep Learning models, such as those used in an autonomous vehicle are\nvulnerable to adversarial attacks where an attacker could place an adversarial\nobject in the environment, leading to mis-classification. Generating these\nadversarial objects in the digital space has been extensively studied, however\nsuccessfully transferring these attacks from the digital realm to the physical\nrealm has proven challenging when controlling for real-world environmental\nfactors. In response to these limitations, we introduce REVAMP, an easy-to-use\nPython library that is the first-of-its-kind tool for creating attack scenarios\nwith arbitrary objects and simulating realistic environmental factors,\nlighting, reflection, and refraction. REVAMP enables researchers and\npractitioners to swiftly explore various scenarios within the digital realm by\noffering a wide range of configurable options for designing experiments and\nusing differentiable rendering to reproduce physically plausible adversarial\nobjects. We will demonstrate and invite the audience to try REVAMP to produce\nan adversarial texture on a chosen object while having control over various\nscene parameters. The audience will choose a scene, an object to attack, the\ndesired attack class, and the number of camera positions to use. Then, in real\ntime, we show how this altered texture causes the chosen object to be\nmis-classified, showcasing the potential of REVAMP in real-world scenarios.\nREVAMP is open-source and available at https://github.com/poloclub/revamp.",
          "link": "http://arxiv.org/abs/2310.12243",
          "publishedOn": "2023-10-21T00:41:42.570Z",
          "wordCount": null,
          "title": "REVAMP: Automated Simulations of Adversarial Attacks on Arbitrary Objects in Realistic Scenes. (arXiv:2310.12243v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhendong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yifan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Huangjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>",
          "description": "Diffusion models are powerful, but they require a lot of time and data to\ntrain. We propose Patch Diffusion, a generic patch-wise training framework, to\nsignificantly reduce the training time costs while improving data efficiency,\nwhich thus helps democratize diffusion model training to broader users. At the\ncore of our innovations is a new conditional score function at the patch level,\nwhere the patch location in the original image is included as additional\ncoordinate channels, while the patch size is randomized and diversified\nthroughout training to encode the cross-region dependency at multiple scales.\nSampling with our method is as easy as in the original diffusion model. Through\nPatch Diffusion, we could achieve $\\mathbf{\\ge 2\\times}$ faster training, while\nmaintaining comparable or better generation quality. Patch Diffusion meanwhile\nimproves the performance of diffusion models trained on relatively small\ndatasets, $e.g.$, as few as 5,000 images to train from scratch. We achieve\noutstanding FID scores in line with state-of-the-art benchmarks: 1.77 on\nCelebA-64$\\times$64, 1.93 on AFHQv2-Wild-64$\\times$64, and 2.72 on\nImageNet-256$\\times$256. We share our code and pre-trained models at\nhttps://github.com/Zhendong-Wang/Patch-Diffusion.",
          "link": "http://arxiv.org/abs/2304.12526",
          "publishedOn": "2023-10-21T00:41:42.567Z",
          "wordCount": null,
          "title": "Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models. (arXiv:2304.12526v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deora_P/0/1/0/all/0/1\">Puneesh Deora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaderi_R/0/1/0/all/0/1\">Rouzbeh Ghaderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taheri_H/0/1/0/all/0/1\">Hossein Taheri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "The training and generalization dynamics of the Transformer's core mechanism,\nnamely the Attention mechanism, remain under-explored. Besides, existing\nanalyses primarily focus on single-head attention. Inspired by the demonstrated\nbenefits of overparameterization when training fully-connected networks, we\ninvestigate the potential optimization and generalization advantages of using\nmultiple attention heads. Towards this goal, we derive convergence and\ngeneralization guarantees for gradient-descent training of a single-layer\nmulti-head self-attention model, under a suitable realizability condition on\nthe data. We then establish primitive conditions on the initialization that\nensure realizability holds. Finally, we demonstrate that these conditions are\nsatisfied for a simple tokenized-mixture model. We expect the analysis can be\nextended to various data-model and architecture variations.",
          "link": "http://arxiv.org/abs/2310.12680",
          "publishedOn": "2023-10-21T00:41:42.565Z",
          "wordCount": null,
          "title": "On the Optimization and Generalization of Multi-head Attention. (arXiv:2310.12680v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1\">Mateo Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somenzi_F/0/1/0/all/0/1\">Fabio Somenzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Ashutosh Trivedi</a>",
          "description": "Linear temporal logic (LTL) and omega-regular objectives -- a superset of LTL\n-- have seen recent use as a way to express non-Markovian objectives in\nreinforcement learning. We introduce a model-based probably approximately\ncorrect (PAC) learning algorithm for omega-regular objectives in Markov\ndecision processes. Unlike prior approaches, our algorithm learns from sampled\ntrajectories of the system and does not require prior knowledge of the system's\ntopology.",
          "link": "http://arxiv.org/abs/2310.12248",
          "publishedOn": "2023-10-21T00:41:42.557Z",
          "wordCount": null,
          "title": "A PAC Learning Algorithm for LTL and Omega-regular Objectives in MDPs. (arXiv:2310.12248v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_M/0/1/0/all/0/1\">Masahiro Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furuta_S/0/1/0/all/0/1\">Shomu Furuta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fukazawa_Y/0/1/0/all/0/1\">Yusuke Fukazawa</a>",
          "description": "We explain the methodology used to create the data submitted to HuMob\nChallenge, a data analysis competition for human mobility prediction. We\nadopted a personalized model to predict the individual's movement trajectory\nfrom their data, instead of predicting from the overall movement, based on the\nhypothesis that human movement is unique to each person. We devised the\nfeatures such as the date and time, activity time, days of the week, time of\nday, and frequency of visits to POI (Point of Interest). As additional\nfeatures, we incorporated the movement of other individuals with similar\nbehavior patterns through the employment of clustering. The machine learning\nmodel we adopted was the Support Vector Regression (SVR). We performed accuracy\nthrough offline assessment and carried out feature selection and parameter\ntuning. Although overall dataset provided consists of 100,000 users trajectory,\nour method use only 20,000 target users data, and do not need to use other\n80,000 data. Despite the personalized model's traditional feature engineering\napproach, this model yields reasonably good accuracy with lower computational\ncost.",
          "link": "http://arxiv.org/abs/2310.12900",
          "publishedOn": "2023-10-21T00:41:42.532Z",
          "wordCount": null,
          "title": "Personalized human mobility prediction for HuMob challenge. (arXiv:2310.12900v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Junwoo Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryu_H/0/1/0/all/0/1\">Hyunwoo Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jiwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1\">Soochul Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Joohwan Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_N/0/1/0/all/0/1\">Nikhil Prakash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jongeun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horowitz_R/0/1/0/all/0/1\">Roberto Horowitz</a>",
          "description": "Diffusion models have risen as a powerful tool in robotics due to their\nflexibility and multi-modality. While some of these methods effectively address\ncomplex problems, they often depend heavily on inference-time obstacle\ndetection and require additional equipment. Addressing these challenges, we\npresent a method that, during inference time, simultaneously generates only\nreachable goals and plans motions that avoid obstacles, all from a single\nvisual input. Central to our approach is the novel use of a collision-avoiding\ndiffusion kernel for training. Through evaluations against behavior-cloning and\nclassical diffusion models, our framework has proven its robustness. It is\nparticularly effective in multi-modal environments, navigating toward goals and\navoiding unreachable ones blocked by obstacles, while ensuring collision\navoidance.",
          "link": "http://arxiv.org/abs/2310.12609",
          "publishedOn": "2023-10-21T00:41:42.523Z",
          "wordCount": null,
          "title": "Denoising Heat-inspired Diffusion with Insulators for Collision Free Motion Planning. (arXiv:2310.12609v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.13047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Le Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Leilei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bowen Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_W/0/1/0/all/0/1\">Weifeng Lv</a>",
          "description": "We propose DyGFormer, a new Transformer-based architecture for dynamic graph\nlearning. DyGFormer is conceptually simple and only needs to learn from nodes'\nhistorical first-hop interactions by: (1) a neighbor co-occurrence encoding\nscheme that explores the correlations of the source node and destination node\nbased on their historical sequences; (2) a patching technique that divides each\nsequence into multiple patches and feeds them to Transformer, allowing the\nmodel to effectively and efficiently benefit from longer histories. We also\nintroduce DyGLib, a unified library with standard training pipelines,\nextensible coding interfaces, and comprehensive evaluating protocols to promote\nreproducible, scalable, and credible dynamic graph learning research. By\nperforming exhaustive experiments on thirteen datasets for dynamic link\nprediction and dynamic node classification tasks, we find that DyGFormer\nachieves state-of-the-art performance on most of the datasets, demonstrating\nits effectiveness in capturing nodes' correlations and long-term temporal\ndependencies. Moreover, some results of baselines are inconsistent with\nprevious reports, which may be caused by their diverse but less rigorous\nimplementations, showing the importance of DyGLib. All the used resources are\npublicly available at https://github.com/yule-BUAA/DyGLib.",
          "link": "http://arxiv.org/abs/2303.13047",
          "publishedOn": "2023-10-21T00:41:42.520Z",
          "wordCount": null,
          "title": "Towards Better Dynamic Graph Learning: New Architecture and Unified Library. (arXiv:2303.13047v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Notsawo_P/0/1/0/all/0/1\">Pascal Junior Tikeng Notsawo</a>",
          "description": "Despite the recent growth of theoretical studies and empirical successes of\nneural networks, gradient backpropagation is still the most widely used\nalgorithm for training such networks. On the one hand, we have deterministic or\nfull gradient (FG) approaches that have a cost proportional to the amount of\ntraining data used but have a linear convergence rate, and on the other hand,\nstochastic gradient (SG) methods that have a cost independent of the size of\nthe dataset, but have a less optimal convergence rate than the determinist\napproaches. To combine the cost of the stochastic approach with the convergence\nrate of the deterministic approach, a stochastic average gradient (SAG) has\nbeen proposed. SAG is a method for optimizing the sum of a finite number of\nsmooth convex functions. Like SG methods, the SAG method's iteration cost is\nindependent of the number of terms in the sum. In this work, we propose to\ncompare SAG to some standard optimizers used in machine learning. SAG converges\nfaster than other optimizers on simple toy problems and performs better than\nmany other optimizers on simple machine learning problems. We also propose a\ncombination of SAG with the momentum algorithm and Adam. These combinations\nallow empirically higher speed and obtain better performance than the other\nmethods, especially when the landscape of the function to optimize presents\nobstacles or is ill-conditioned.",
          "link": "http://arxiv.org/abs/2310.12771",
          "publishedOn": "2023-10-21T00:41:42.519Z",
          "wordCount": null,
          "title": "Stochastic Average Gradient : A Simple Empirical Investigation. (arXiv:2310.12771v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Barbier__Chebbah_A/0/1/0/all/0/1\">Alex Barbier--Chebbah</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Vestergaard_C/0/1/0/all/0/1\">Christian L. Vestergaard</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Masson_J/0/1/0/all/0/1\">Jean-Baptiste Masson</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Boursier_E/0/1/0/all/0/1\">Etienne Boursier</a> (CELESTE)",
          "description": "Entropy maximization and free energy minimization are general physical\nprinciples for modeling the dynamics of various physical systems. Notable\nexamples include modeling decision-making within the brain using the\nfree-energy principle, optimizing the accuracy-complexity trade-off when\naccessing hidden variables with the information bottleneck principle (Tishby et\nal., 2000), and navigation in random environments using information\nmaximization (Vergassola et al., 2007). Built on this principle, we propose a\nnew class of bandit algorithms that maximize an approximation to the\ninformation of a key variable within the system. To this end, we develop an\napproximated analytical physics-based representation of an entropy to forecast\nthe information gain of each action and greedily choose the one with the\nlargest information gain. This method yields strong performances in classical\nbandit settings. Motivated by its empirical success, we prove its asymptotic\noptimality for the two-armed bandit problem with Gaussian rewards. Owing to its\nability to encompass the system's properties in a global physical functional,\nthis approach can be efficiently adapted to more complex bandit settings,\ncalling for further investigation of information maximization approaches for\nmulti-armed bandit problems.",
          "link": "http://arxiv.org/abs/2310.12563",
          "publishedOn": "2023-10-21T00:41:42.518Z",
          "wordCount": null,
          "title": "Approximate information maximization for bandit games. (arXiv:2310.12563v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fazekas_A/0/1/0/all/0/1\">Attila Fazekas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovacs_G/0/1/0/all/0/1\">Gy&#xf6;rgy Kov&#xe1;cs</a>",
          "description": "Binary classification is a fundamental task in machine learning, with\napplications spanning various scientific domains. Whether scientists are\nconducting fundamental research or refining practical applications, they\ntypically assess and rank classification techniques based on performance\nmetrics such as accuracy, sensitivity, and specificity. However, reported\nperformance scores may not always serve as a reliable basis for research\nranking. This can be attributed to undisclosed or unconventional practices\nrelated to cross-validation, typographical errors, and other factors. In a\ngiven experimental setup, with a specific number of positive and negative test\nitems, most performance scores can assume specific, interrelated values. In\nthis paper, we introduce numerical techniques to assess the consistency of\nreported performance scores and the assumed experimental setup. Importantly,\nthe proposed approach does not rely on statistical inference but uses numerical\nmethods to identify inconsistencies with certainty. Through three different\napplications related to medicine, we demonstrate how the proposed techniques\ncan effectively detect inconsistencies, thereby safeguarding the integrity of\nresearch fields. To benefit the scientific community, we have made the\nconsistency tests available in an open-source Python package.",
          "link": "http://arxiv.org/abs/2310.12527",
          "publishedOn": "2023-10-21T00:41:42.513Z",
          "wordCount": null,
          "title": "Testing the Consistency of Performance Scores Reported for Binary Classification Problems. (arXiv:2310.12527v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.08503",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1\">Xiaoming Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cuie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Liang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linqi Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1\">Kay Chen Tan</a>",
          "description": "Sequential transfer optimization (STO), which aims to improve the\noptimization performance on a task of interest by exploiting the knowledge\ncaptured from several previously-solved optimization tasks stored in a\ndatabase, has been gaining increasing research attention over the years.\nHowever, despite the remarkable advances in algorithm design, the development\nof a systematic benchmark suite for comprehensive comparisons of STO algorithms\nreceived far less attention. Existing test problems are either simply generated\nby assembling other benchmark functions or extended from specific practical\nproblems with limited scalability. The relationships between the optimal\nsolutions of the source and target tasks in these problems are also often\nmanually configured, limiting their ability to model different similarity\nrelationships presented in real-world problems. Consequently, the good\nperformance achieved by an algorithm on these problems might be biased and hard\nto be generalized to other problems. In light of the above, in this study, we\nfirst introduce four concepts for characterizing STO problems and present an\nimportant problem feature, namely similarity distribution, which quantitatively\ndelineates the relationship between the optima of the source and target tasks.\nThen, we present the general design guidelines of STO problems and a particular\nSTO problem generator with good scalability. Specifically, the similarity\ndistribution of a problem can be easily customized, enabling a continuous\nspectrum of representation of the diverse similarity relationships of\nreal-world problems. Lastly, a benchmark suite with 12 STO problems featured by\na variety of customized similarity relationships is developed using the\nproposed generator. The source code of the problem generator is available at\nhttps://github.com/XmingHsueh/STOP-G.",
          "link": "http://arxiv.org/abs/2304.08503",
          "publishedOn": "2023-10-21T00:41:42.512Z",
          "wordCount": null,
          "title": "A Scalable Test Problem Generator for Sequential Transfer Optimization. (arXiv:2304.08503v4 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12768",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_W/0/1/0/all/0/1\">Wensheng Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yan_Y/0/1/0/all/0/1\">Yuna Yan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_L/0/1/0/all/0/1\">Lixin Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_Z/0/1/0/all/0/1\">Zhu Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Matsumoto_T/0/1/0/all/0/1\">Tad Matsumoto</a>",
          "description": "This letter proposes a novel anti-interference technique, semantic\ninterference cancellation (SemantIC), for enhancing information quality towards\nthe sixth-generation (6G) wireless networks. SemantIC only requires the\nreceiver to concatenate the channel decoder with a semantic auto-encoder. This\nconstructs a turbo loop which iteratively and alternately eliminates noise in\nthe signal domain and the semantic domain. From the viewpoint of network\ninformation theory, the neural network of the semantic auto-encoder stores side\ninformation by training, and provides side information in iterative decoding,\nas an implementation of the Wyner-Ziv theorem. Simulation results verify the\nperformance improvement by SemantIC without extra channel resource cost.",
          "link": "http://arxiv.org/abs/2310.12768",
          "publishedOn": "2023-10-21T00:41:42.501Z",
          "wordCount": null,
          "title": "SemantIC: Semantic Interference Cancellation Towards 6G Wireless Communications. (arXiv:2310.12768v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "Although remarkable progress has been achieved in preventing large language\nmodel (LLM) hallucinations using instruction tuning and retrieval augmentation,\nit remains challenging to measure the reliability of LLMs using human-crafted\nevaluation data which is not available for many tasks and domains and could\nsuffer from data leakage. Inspired by adversarial machine learning, this paper\naims to develop a method of automatically generating evaluation data by\nappropriately modifying existing data on which LLMs behave faithfully.\nSpecifically, this paper presents AutoDebug, an LLM-based framework to use\nprompting chaining to generate transferable adversarial attacks in the form of\nquestion-answering examples. We seek to understand the extent to which these\nexamples trigger the hallucination behaviors of LLMs.\n\nWe implement AutoDebug using ChatGPT and evaluate the resulting two variants\nof a popular open-domain question-answering dataset, Natural Questions (NQ), on\na collection of open-source and proprietary LLMs under various prompting\nsettings. Our generated evaluation data is human-readable and, as we show,\nhumans can answer these modified questions well. Nevertheless, we observe\npronounced accuracy drops across multiple LLMs including GPT-4. Our\nexperimental results show that LLMs are likely to hallucinate in two categories\nof question-answering scenarios where (1) there are conflicts between knowledge\ngiven in the prompt and their parametric knowledge, or (2) the knowledge\nexpressed in the prompt is complex. Finally, we find that the adversarial\nexamples generated by our method are transferable across all considered LLMs.\nThe examples generated by a small model can be used to debug a much larger\nmodel, making our approach cost-effective.",
          "link": "http://arxiv.org/abs/2310.12516",
          "publishedOn": "2023-10-21T00:41:42.497Z",
          "wordCount": null,
          "title": "Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks. (arXiv:2310.12516v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoffmann_M/0/1/0/all/0/1\">Marcel Hoffmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galke_L/0/1/0/all/0/1\">Lukas Galke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherp_A/0/1/0/all/0/1\">Ansgar Scherp</a>",
          "description": "We study the problem of lifelong graph learning in an open-world scenario,\nwhere a model needs to deal with new tasks and potentially unknown classes. We\nutilize Out-of-Distribution (OOD) detection methods to recognize new classes\nand adapt existing non-graph OOD detection methods to graph data. Crucially, we\nsuggest performing new class detection by combining OOD detection methods with\ninformation aggregated from the graph neighborhood. Most OOD detection methods\navoid determining a crisp threshold for deciding whether a vertex is OOD. To\ntackle this problem, we propose a Weakly-supervised Relevance Feedback\n(Open-WRF) method, which decreases the sensitivity to thresholds in OOD\ndetection. We evaluate our approach on six benchmark datasets. Our results show\nthat the proposed neighborhood aggregation method for OOD scores outperforms\nexisting methods independent of the underlying graph neural network.\nFurthermore, we demonstrate that our Open-WRF method is more robust to\nthreshold selection and analyze the influence of graph neighborhood on OOD\ndetection. The aggregation and threshold methods are compatible with arbitrary\ngraph neural networks and OOD detection methods, making our approach versatile\nand applicable to many real-world applications.",
          "link": "http://arxiv.org/abs/2310.12565",
          "publishedOn": "2023-10-21T00:41:42.491Z",
          "wordCount": null,
          "title": "Open-World Lifelong Graph Learning. (arXiv:2310.12565v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12309",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mileva_Z/0/1/0/all/0/1\">Zlatina Mileva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bikakis_A/0/1/0/all/0/1\">Antonis Bikakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAsaro_F/0/1/0/all/0/1\">Fabio Aurelio D&#x27;Asaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1\">Mark Law</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russo_A/0/1/0/all/0/1\">Alessandra Russo</a>",
          "description": "Argumentation is a very active research field of Artificial Intelligence\nconcerned with the representation and evaluation of arguments used in dialogues\nbetween humans and/or artificial agents. Acceptability semantics of formal\nargumentation systems define the criteria for the acceptance or rejection of\narguments. Several software systems, known as argumentation solvers, have been\ndeveloped to compute the accepted/rejected arguments using such criteria. These\ninclude systems that learn to identify the accepted arguments using\nnon-interpretable methods. In this paper we present a novel framework, which\nuses an Inductive Logic Programming approach to learn the acceptability\nsemantics for several abstract and structured argumentation frameworks in an\ninterpretable way. Through an empirical evaluation we show that our framework\noutperforms existing argumentation solvers, thus opening up new future research\ndirections in the area of formal argumentation and human-machine dialogues.",
          "link": "http://arxiv.org/abs/2310.12309",
          "publishedOn": "2023-10-21T00:41:42.486Z",
          "wordCount": null,
          "title": "A Unifying Framework for Learning Argumentation Semantics. (arXiv:2310.12309v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12156",
          "author": "<a href=\"http://arxiv.org/find/nlin/1/au:+Tavasoli_A/0/1/0/all/0/1\">Ali Tavasoli</a>, <a href=\"http://arxiv.org/find/nlin/1/au:+Shakeri_H/0/1/0/all/0/1\">Heman Shakeri</a>",
          "description": "This paper examines the use of operator-theoretic approaches to the analysis\nof chaotic systems through the lens of their unstable periodic orbits (UPOs).\nOur approach involves three data-driven steps for detecting, identifying, and\nstabilizing UPOs. We demonstrate the use of kernel integral operators within\ndelay coordinates as an innovative method for UPO detection. For identifying\nthe dynamic behavior associated with each individual UPO, we utilize the\nKoopman operator to present the dynamics as linear equations in the space of\nKoopman eigenfunctions. This allows for characterizing the chaotic attractor by\ninvestigating its principal dynamical modes across varying UPOs. We extend this\nmethodology into an interpretable machine learning framework aimed at\nstabilizing strange attractors on their UPOs. To illustrate the efficacy of our\napproach, we apply it to the Lorenz attractor as a case study.",
          "link": "http://arxiv.org/abs/2310.12156",
          "publishedOn": "2023-10-21T00:41:42.470Z",
          "wordCount": null,
          "title": "Operator-Based Detecting, Learning, and Stabilizing Unstable Periodic Orbits of Chaotic Attractors. (arXiv:2310.12156v1 [nlin.AO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.07162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yumeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1\">Ning Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1\">Hanna Ziesche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1\">Gerhard Neumann</a>",
          "description": "We present a novel meta-learning approach for 6D pose estimation on unknown\nobjects. In contrast to ``instance-level\" and ``category-level\" pose estimation\nmethods, our algorithm learns object representation in a category-agnostic way,\nwhich endows it with strong generalization capabilities across object\ncategories. Specifically, we employ a neural process-based meta-learning\napproach to train an encoder to capture texture and geometry of an object in a\nlatent representation, based on very few RGB-D images and ground-truth\nkeypoints. The latent representation is then used by a simultaneously\nmeta-trained decoder to predict the 6D pose of the object in new images.\nFurthermore, we propose a novel geometry-aware decoder for the keypoint\nprediction using a Graph Neural Network (GNN), which explicitly takes geometric\nconstraints specific to each object into consideration. To evaluate our\nalgorithm, extensive experiments are conducted on the \\linemod dataset, and on\nour new fully-annotated synthetic datasets generated from Multiple Categories\nin Multiple Scenes (MCMS). Experimental results demonstrate that our model\nperforms well on unseen objects with very different shapes and appearances.\nRemarkably, our model also shows robust performance on occluded scenes although\ntrained fully on data without occlusion. To our knowledge, this is the first\nwork exploring \\textbf{cross-category level} 6D pose estimation.",
          "link": "http://arxiv.org/abs/2206.07162",
          "publishedOn": "2023-10-21T00:41:42.456Z",
          "wordCount": null,
          "title": "Category-Agnostic 6D Pose Estimation with Conditional Neural Processes. (arXiv:2206.07162v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamdan_S/0/1/0/all/0/1\">Sami Hamdan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+More_S/0/1/0/all/0/1\">Shammi More</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasse_L/0/1/0/all/0/1\">Leonard Sasse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komeyer_V/0/1/0/all/0/1\">Vera Komeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_K/0/1/0/all/0/1\">Kaustubh R. Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raimondo_F/0/1/0/all/0/1\">Federico Raimondo</a> (for the Alzheimer&#x27;s Disease Neuroimaging Initiative)",
          "description": "The fast-paced development of machine learning (ML) methods coupled with its\nincreasing adoption in research poses challenges for researchers without\nextensive training in ML. In neuroscience, for example, ML can help understand\nbrain-behavior relationships, diagnose diseases, and develop biomarkers using\nvarious data sources like magnetic resonance imaging and\nelectroencephalography. The primary objective of ML is to build models that can\nmake accurate predictions on unseen data. Researchers aim to prove the\nexistence of such generalizable models by evaluating performance using\ntechniques such as cross-validation (CV), which uses systematic subsampling to\nestimate the generalization performance. Choosing a CV scheme and evaluating an\nML pipeline can be challenging and, if used improperly, can lead to\noverestimated results and incorrect interpretations.\n\nWe created julearn, an open-source Python library, that allow researchers to\ndesign and evaluate complex ML pipelines without encountering in common\npitfalls. In this manuscript, we present the rationale behind julearn's design,\nits core features, and showcase three examples of previously-published research\nprojects that can be easily implemented using this novel library. Julearn aims\nto simplify the entry into the ML world by providing an easy-to-use environment\nwith built in guards against some of the most common ML pitfalls. With its\ndesign, unique features and simple interface, it poses as a useful Python-based\nlibrary for research projects.",
          "link": "http://arxiv.org/abs/2310.12568",
          "publishedOn": "2023-10-21T00:41:42.444Z",
          "wordCount": null,
          "title": "Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models. (arXiv:2310.12568v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12804",
          "author": "<a href=\"http://arxiv.org/find/hep-ex/1/au:+Smith_R/0/1/0/all/0/1\">Rachel E. C. Smith</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Ochoa_I/0/1/0/all/0/1\">In&#xea;s Ochoa</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Inacio_R/0/1/0/all/0/1\">R&#xfa;ben In&#xe1;cio</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Shoemaker_J/0/1/0/all/0/1\">Jonathan Shoemaker</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Kagan_M/0/1/0/all/0/1\">Michael Kagan</a>",
          "description": "We propose a differentiable vertex fitting algorithm that can be used for\nsecondary vertex fitting, and that can be seamlessly integrated into neural\nnetworks for jet flavour tagging. Vertex fitting is formulated as an\noptimization problem where gradients of the optimized solution vertex are\ndefined through implicit differentiation and can be passed to upstream or\ndownstream neural network components for network training. More broadly, this\nis an application of differentiable programming to integrate physics knowledge\ninto neural network models in high energy physics. We demonstrate how\ndifferentiable secondary vertex fitting can be integrated into larger\ntransformer-based models for flavour tagging and improve heavy flavour jet\nclassification.",
          "link": "http://arxiv.org/abs/2310.12804",
          "publishedOn": "2023-10-21T00:41:42.440Z",
          "wordCount": null,
          "title": "Differentiable Vertex Fitting for Jet Flavour Tagging. (arXiv:2310.12804v1 [hep-ex])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.07469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahn_K/0/1/0/all/0/1\">Kwangjun Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bubeck_S/0/1/0/all/0/1\">S&#xe9;bastien Bubeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chewi_S/0/1/0/all/0/1\">Sinho Chewi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yin Tat Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suarez_F/0/1/0/all/0/1\">Felipe Suarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>",
          "description": "Existing analyses of neural network training often operate under the\nunrealistic assumption of an extremely small learning rate. This lies in stark\ncontrast to practical wisdom and empirical studies, such as the work of J.\nCohen et al. (ICLR 2021), which exhibit startling new phenomena (the \"edge of\nstability\" or \"unstable convergence\") and potential benefits for generalization\nin the large learning rate regime. Despite a flurry of recent works on this\ntopic, however, the latter effect is still poorly understood. In this paper, we\ntake a step towards understanding genuinely non-convex training dynamics with\nlarge learning rates by performing a detailed analysis of gradient descent for\nsimplified models of two-layer neural networks. For these models, we provably\nestablish the edge of stability phenomenon and discover a sharp phase\ntransition for the step size below which the neural network fails to learn\n\"threshold-like\" neurons (i.e., neurons with a non-zero first-layer bias). This\nelucidates one possible mechanism by which the edge of stability can in fact\nlead to better generalization, as threshold neurons are basic building blocks\nwith useful inductive bias for many tasks.",
          "link": "http://arxiv.org/abs/2212.07469",
          "publishedOn": "2023-10-21T00:41:42.439Z",
          "wordCount": null,
          "title": "Learning threshold neurons via the \"edge of stability\". (arXiv:2212.07469v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12570",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sun_G/0/1/0/all/0/1\">Guanqun Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_Y/0/1/0/all/0/1\">Yizhi Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kong_W/0/1/0/all/0/1\">Weikun Kong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Z/0/1/0/all/0/1\">Zichang Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_J/0/1/0/all/0/1\">Jianhua Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Racharak_T/0/1/0/all/0/1\">Teeradaj Racharak</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nguyen_L/0/1/0/all/0/1\">Le-Minh Nguyen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xin_J/0/1/0/all/0/1\">Junyi Xin</a>",
          "description": "Great progress has been made in automatic medical image segmentation due to\npowerful deep representation learning. The influence of transformer has led to\nresearch into its variants, and large-scale replacement of traditional CNN\nmodules. However, such trend often overlooks the intrinsic feature extraction\ncapabilities of the transformer and potential refinements to both the model and\nthe transformer module through minor adjustments. This study proposes a novel\ndeep medical image segmentation framework, called DA-TransUNet, aiming to\nintroduce the Transformer and dual attention block into the encoder and decoder\nof the traditional U-shaped architecture. Unlike prior transformer-based\nsolutions, our DA-TransUNet utilizes attention mechanism of transformer and\nmultifaceted feature extraction of DA-Block, which can efficiently combine\nglobal, local, and multi-scale features to enhance medical image segmentation.\nMeanwhile, experimental results show that a dual attention block is added\nbefore the Transformer layer to facilitate feature extraction in the U-net\nstructure. Furthermore, incorporating dual attention blocks in skip connections\ncan enhance feature transfer to the decoder, thereby improving image\nsegmentation performance. Experimental results across various benchmark of\nmedical image segmentation reveal that DA-TransUNet significantly outperforms\nthe state-of-the-art methods. The codes and parameters of our model will be\npublicly available at https://github.com/SUN-1024/DA-TransUnet.",
          "link": "http://arxiv.org/abs/2310.12570",
          "publishedOn": "2023-10-21T00:41:42.438Z",
          "wordCount": null,
          "title": "DA-TransUNet: Integrating Spatial and Channel Dual Attention with Transformer U-Net for Medical Image Segmentation. (arXiv:2310.12570v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12743",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Flouris_K/0/1/0/all/0/1\">Kyriakos Flouris</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Konukoglu_E/0/1/0/all/0/1\">Ender Konukoglu</a>",
          "description": "Manifold learning flows are a class of generative modelling techniques that\nassume a low-dimensional manifold description of the data. The embedding of\nsuch manifold into the high-dimensional space of the data is achieved via\nlearnable invertible transformations. Therefore, once the manifold is properly\naligned via a reconstruction loss, the probability density is tractable on the\nmanifold and maximum likelihood can be used optimize the network parameters.\nNaturally, the lower-dimensional representation of the data requires an\ninjective-mapping. Recent approaches were able to enforce that density aligns\nwith the modelled manifold, while efficiently calculating the density\nvolume-change term when embedding to the higher-dimensional space. However,\nunless the injective-mapping is analytically predefined, the learned manifold\nis not necessarily an efficient representation of the data. Namely, the latent\ndimensions of such models frequently learn an entangled intrinsic basis with\ndegenerate information being stored in each dimension. Alternatively, if a\nlocally orthogonal and/or sparse basis is to be learned, here coined canonical\nintrinsic basis, it can serve in learning a more compact latent space\nrepresentation. Towards this end, we propose a canonical manifold learning flow\nmethod, where a novel optimization objective enforces the transformation matrix\nto have few prominent and orthogonal basis functions. Canonical manifold flow\nyields a more efficient use of the latent space, automatically generating fewer\nprominent and distinct dimensions to represent data, and consequently a better\napproximation of target distributions than other manifold flow methods in most\nexperiments we conducted, resulting in lower FID scores.",
          "link": "http://arxiv.org/abs/2310.12743",
          "publishedOn": "2023-10-21T00:41:42.438Z",
          "wordCount": null,
          "title": "Canonical normalizing flows for manifold learning. (arXiv:2310.12743v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arimond_A/0/1/0/all/0/1\">Alexander Arimond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molteni_M/0/1/0/all/0/1\">Mauro Molteni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jany_D/0/1/0/all/0/1\">Dominik Jany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manolova_Z/0/1/0/all/0/1\">Zornitsa Manolova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1\">Damian Borth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoepner_A/0/1/0/all/0/1\">Andreas G.F. Hoepner</a>",
          "description": "We propose the application of Transformer-based language models for\nclassifying entity legal forms from raw legal entity names. Specifically, we\nemploy various BERT variants and compare their performance against multiple\ntraditional baselines. Our evaluation encompasses a substantial subset of\nfreely available Legal Entity Identifier (LEI) data, comprising over 1.1\nmillion legal entities from 30 different legal jurisdictions. The ground truth\nlabels for classification per jurisdiction are taken from the Entity Legal Form\n(ELF) code standard (ISO 20275). Our findings demonstrate that pre-trained BERT\nvariants outperform traditional text classification approaches in terms of F1\nscore, while also performing comparably well in the Macro F1 Score. Moreover,\nthe validity of our proposal is supported by the outcome of third-party expert\nreviews conducted in ten selected jurisdictions. This study highlights the\nsignificant potential of Transformer-based models in advancing data\nstandardization and data integration. The presented approaches can greatly\nbenefit financial institutions, corporations, governments and other\norganizations in assessing business relationships, understanding risk exposure,\nand promoting effective governance.",
          "link": "http://arxiv.org/abs/2310.12766",
          "publishedOn": "2023-10-21T00:41:42.438Z",
          "wordCount": null,
          "title": "Transformer-based Entity Legal Form Classification. (arXiv:2310.12766v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rosaler_J/0/1/0/all/0/1\">Joshua Rosaler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Desai_D/0/1/0/all/0/1\">Dhruv Desai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sarmah_B/0/1/0/all/0/1\">Bhaskarjit Sarmah</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vamvourellis_D/0/1/0/all/0/1\">Dimitrios Vamvourellis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Onay_D/0/1/0/all/0/1\">Deran Onay</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mehta_D/0/1/0/all/0/1\">Dhagash Mehta</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pasquali_S/0/1/0/all/0/1\">Stefano Pasquali</a>",
          "description": "We initiate a novel approach to explain the out of sample performance of\nrandom forest (RF) models by exploiting the fact that any RF can be formulated\nas an adaptive weighted K nearest-neighbors model. Specifically, we use the\nproximity between points in the feature space learned by the RF to re-write\nrandom forest predictions exactly as a weighted average of the target labels of\ntraining data points. This linearity facilitates a local notion of\nexplainability of RF predictions that generates attributions for any model\nprediction across observations in the training set, and thereby complements\nestablished methods like SHAP, which instead generates attributions for a model\nprediction across dimensions of the feature space. We demonstrate this approach\nin the context of a bond pricing model trained on US corporate bond trades, and\ncompare our approach to various existing approaches to model explainability.",
          "link": "http://arxiv.org/abs/2310.12428",
          "publishedOn": "2023-10-21T00:41:42.435Z",
          "wordCount": null,
          "title": "Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarker_I/0/1/0/all/0/1\">Iqbal H. Sarker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janicke_H/0/1/0/all/0/1\">Helge Janicke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_N/0/1/0/all/0/1\">Nazeeruddin Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watters_P/0/1/0/all/0/1\">Paul Watters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nepal_S/0/1/0/all/0/1\">Surya Nepal</a>",
          "description": "This position paper explores the broad landscape of AI potentiality in the\ncontext of cybersecurity, with a particular emphasis on its possible risk\nfactors with awareness, which can be managed by incorporating human experts in\nthe loop, i.e., \"Human-AI\" teaming. As artificial intelligence (AI)\ntechnologies advance, they will provide unparalleled opportunities for attack\nidentification, incident response, and recovery. However, the successful\ndeployment of AI into cybersecurity measures necessitates an in-depth\nunderstanding of its capabilities, challenges, and ethical and legal\nimplications to handle associated risk factors in real-world application areas.\nTowards this, we emphasize the importance of a balanced approach that\nincorporates AI's computational power with human expertise. AI systems may\nproactively discover vulnerabilities and detect anomalies through pattern\nrecognition, and predictive modeling, significantly enhancing speed and\naccuracy. Human experts can explain AI-generated decisions to stakeholders,\nregulators, and end-users in critical situations, ensuring responsibility and\naccountability, which helps establish trust in AI-driven security solutions.\nTherefore, in this position paper, we argue that human-AI teaming is worthwhile\nin cybersecurity, in which human expertise such as intuition, critical\nthinking, or contextual understanding is combined with AI's computational power\nto improve overall cyber defenses.",
          "link": "http://arxiv.org/abs/2310.12162",
          "publishedOn": "2023-10-21T00:41:42.434Z",
          "wordCount": null,
          "title": "AI Potentiality and Awareness: A Position Paper from the Perspective of Human-AI Teaming in Cybersecurity. (arXiv:2310.12162v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16546",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_D/0/1/0/all/0/1\">Davi Guimar&#xe3;es da Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meneses_A/0/1/0/all/0/1\">Anderson Alvarenga de Moura Meneses</a>",
          "description": "Electric consumption prediction methods are investigated for many reasons\nsuch as decision-making related to energy efficiency as well as for\nanticipating demand in the energy market dynamics. The objective of the present\nwork is the comparison between two Deep Learning models, namely the Long\nShort-Term Memory (LSTM) and Bi-directional LSTM (BLSTM) for univariate\nelectric consumption Time Series (TS) short-term forecast. The Data Sets (DSs)\nwere selected for their different contexts and scales, aiming the assessment of\nthe models' robustness. Four DSs were used, related to the power consumption\nof: (a) a household in France; (b) a university building in Santar\\'em, Brazil;\n(c) the T\\'etouan city zones, in Morocco; and (c) the Singapore aggregated\nelectric demand. The metrics RMSE, MAE, MAPE and R2 were calculated in a TS\ncross-validation scheme. The Friedman's test was applied to normalized RMSE\n(NRMSE) results, showing that BLSTM outperforms LSTM with statistically\nsignificant difference (p = 0.0455), corroborating the fact that bidirectional\nweight updating improves significantly the LSTM performance concerning\ndifferent scales of electric power consumption.",
          "link": "http://arxiv.org/abs/2305.16546",
          "publishedOn": "2023-10-21T00:41:42.433Z",
          "wordCount": null,
          "title": "Preliminary studies: Comparing LSTM and BLSTM Deep Neural Networks for Power Consumption Prediction. (arXiv:2305.16546v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maezawa_A/0/1/0/all/0/1\">Akira Maezawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1\">Gus Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamamoto_K/0/1/0/all/0/1\">Kazuhiko Yamamoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixon_S/0/1/0/all/0/1\">Simon Dixon</a>",
          "description": "Creating music is iterative, requiring varied methods at each stage. However,\nexisting AI music systems fall short in orchestrating multiple subsystems for\ndiverse needs. To address this gap, we introduce Loop Copilot, a novel system\nthat enables users to generate and iteratively refine music through an\ninteractive, multi-round dialogue interface. The system uses a large language\nmodel to interpret user intentions and select appropriate AI models for task\nexecution. Each backend model is specialized for a specific task, and their\noutputs are aggregated to meet the user's requirements. To ensure musical\ncoherence, essential attributes are maintained in a centralized table. We\nevaluate the effectiveness of the proposed system through semi-structured\ninterviews and questionnaires, highlighting its utility not only in\nfacilitating music creation but also its potential for broader applications.",
          "link": "http://arxiv.org/abs/2310.12404",
          "publishedOn": "2023-10-21T00:41:42.428Z",
          "wordCount": null,
          "title": "Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative Editing. (arXiv:2310.12404v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Davies_C/0/1/0/all/0/1\">Cai Davies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vilamala_M/0/1/0/all/0/1\">Marc Roig Vilamala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preece_A/0/1/0/all/0/1\">Alun D. Preece</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cerutti_F/0/1/0/all/0/1\">Federico Cerutti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaplan_L/0/1/0/all/0/1\">Lance M. Kaplan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Supriyo Chakraborty</a>",
          "description": "This work reveals an evidential signal that emerges from the uncertainty\nvalue in Evidential Deep Learning (EDL). EDL is one example of a class of\nuncertainty-aware deep learning approaches designed to provide confidence (or\nepistemic uncertainty) about the current test sample. In particular for\ncomputer vision and bidirectional encoder large language models, the\n`evidential signal' arising from the Dirichlet strength in EDL can, in some\ncases, discriminate between classes, which is particularly strong when using\nlarge language models. We hypothesise that the KL regularisation term causes\nEDL to couple aleatoric and epistemic uncertainty. In this paper, we\nempirically investigate the correlations between misclassification and\nevaluated uncertainty, and show that EDL's `evidential signal' is due to\nmisclassification bias. We critically evaluate EDL with other Dirichlet-based\napproaches, namely Generative Evidential Neural Networks (EDL-GEN) and Prior\nNetworks, and show theoretically and empirically the differences between these\nloss functions. We conclude that EDL's coupling of uncertainty arises from\nthese differences due to the use (or lack) of out-of-distribution samples\nduring training.",
          "link": "http://arxiv.org/abs/2310.12663",
          "publishedOn": "2023-10-21T00:41:42.382Z",
          "wordCount": null,
          "title": "Knowledge from Uncertainty in Evidential Deep Learning. (arXiv:2310.12663v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.07063",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>",
          "description": "Reasoning on knowledge graphs is a challenging task because it utilizes\nobserved information to predict the missing one. Particularly, answering\ncomplex queries based on first-order logic is one of the crucial tasks to\nverify learning to reason abilities for generalization and composition.\nRecently, the prevailing method is query embedding which learns the embedding\nof a set of entities and treats logic operations as set operations and has\nshown great empirical success. Though there has been much research following\nthe same formulation, many of its claims lack a formal and systematic\ninspection. In this paper, we rethink this formulation and justify many of the\nprevious claims by characterizing the scope of queries investigated previously\nand precisely identifying the gap between its formulation and its goal, as well\nas providing complexity analysis for the currently investigated queries.\nMoreover, we develop a new dataset containing ten new types of queries with\nfeatures that have never been considered and therefore can provide a thorough\ninvestigation of complex queries. Finally, we propose a new neural-symbolic\nmethod, Fuzzy Inference with Truth value (FIT), where we equip the neural link\npredictors with fuzzy logic theory to support end-to-end learning using complex\nqueries with provable reasoning capability. Empirical results show that our\nmethod outperforms previous methods significantly in the new dataset and also\nsurpasses previous methods in the existing dataset at the same time.",
          "link": "http://arxiv.org/abs/2304.07063",
          "publishedOn": "2023-10-21T00:41:42.364Z",
          "wordCount": null,
          "title": "Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors. (arXiv:2304.07063v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng-Kun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min-Hung Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yung-Yu Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yen-Yu Lin</a>",
          "description": "We present a Multimodal Interlaced Transformer (MIT) that jointly considers\n2D and 3D data for weakly supervised point cloud segmentation. Research studies\nhave shown that 2D and 3D features are complementary for point cloud\nsegmentation. However, existing methods require extra 2D annotations to achieve\n2D-3D information fusion. Considering the high annotation cost of point clouds,\neffective 2D and 3D feature fusion based on weakly supervised learning is in\ngreat demand. To this end, we propose a transformer model with two encoders and\none decoder for weakly supervised point cloud segmentation using only\nscene-level class tags. Specifically, the two encoders compute the\nself-attended features for 3D point clouds and 2D multi-view images,\nrespectively. The decoder implements interlaced 2D-3D cross-attention and\ncarries out implicit 2D and 3D feature fusion. We alternately switch the roles\nof queries and key-value pairs in the decoder layers. It turns out that the 2D\nand 3D features are iteratively enriched by each other. Experiments show that\nit performs favorably against existing weakly supervised point cloud\nsegmentation methods by a large margin on the S3DIS and ScanNet benchmarks. The\nproject page will be available at https://jimmy15923.github.io/mit_web/.",
          "link": "http://arxiv.org/abs/2310.12817",
          "publishedOn": "2023-10-21T00:41:42.295Z",
          "wordCount": null,
          "title": "2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision. (arXiv:2310.12817v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daheim_N/0/1/0/all/0/1\">Nico Daheim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mollenhoff_T/0/1/0/all/0/1\">Thomas M&#xf6;llenhoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1\">Edoardo Maria Ponti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>",
          "description": "Models trained on different datasets can be merged by a weighted-averaging of\ntheir parameters, but why does it work and when can it fail? Here, we connect\nthe inaccuracy of weighted-averaging to mismatches in the gradients and propose\na new uncertainty-based scheme to improve the performance by reducing the\nmismatch. The connection also reveals implicit assumptions in other schemes\nsuch as averaging, task arithmetic, and Fisher-weighted averaging. Our new\nmethod gives consistent improvements for large language models and vision\ntransformers, both in terms of performance and robustness to hyperparameters.",
          "link": "http://arxiv.org/abs/2310.12808",
          "publishedOn": "2023-10-21T00:41:42.265Z",
          "wordCount": null,
          "title": "Model Merging by Uncertainty-Based Gradient Matching. (arXiv:2310.12808v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jinheon Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1\">Soyeong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Minki Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jong C. Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Recent Language Models (LMs) have shown impressive capabilities in generating\ntexts with the knowledge internalized in parameters. Yet, LMs often generate\nthe factually incorrect responses to the given queries, since their knowledge\nmay be inaccurate, incomplete, and outdated. To address this problem, previous\nworks propose to augment LMs with the knowledge retrieved from an external\nknowledge source. However, such approaches often show suboptimal text\ngeneration performance due to two reasons: 1) the model may fail to retrieve\nthe knowledge relevant to the given query, or 2) the model may not faithfully\nreflect the retrieved knowledge in the generated text. To overcome these, we\npropose to verify the output and the knowledge of the knowledge-augmented LMs\nwith a separate verifier, which is a small LM that is trained to detect those\ntwo types of errors through instruction-finetuning. Then, when the verifier\nrecognizes an error, we can rectify it by either retrieving new knowledge or\ngenerating new text. Further, we use an ensemble of the outputs from different\ninstructions with a single verifier to enhance the reliability of the\nverification processes. We validate the effectiveness of the proposed\nverification steps on multiple question answering benchmarks, whose results\nshow that the proposed verifier effectively identifies retrieval and generation\nerrors, allowing LMs to provide more factually correct outputs. Our code is\navailable at https://github.com/JinheonBaek/KALMV.",
          "link": "http://arxiv.org/abs/2310.12836",
          "publishedOn": "2023-10-21T00:41:42.264Z",
          "wordCount": null,
          "title": "Knowledge-Augmented Language Model Verification. (arXiv:2310.12836v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Aohan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mingdao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Rui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuxiao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Open large language models (LLMs) with great performance in various tasks\nhave significantly advanced the development of LLMs. However, they are far\ninferior to commercial models such as ChatGPT and GPT-4 when acting as agents\nto tackle complex tasks in the real world. These agent tasks employ LLMs as the\ncentral controller responsible for planning, memorization, and tool\nutilization, necessitating both fine-grained prompting methods and robust LLMs\nto achieve satisfactory performance. Though many prompting methods have been\nproposed to complete particular agent tasks, there is lack of research focusing\non improving the agent capabilities of LLMs themselves without compromising\ntheir general abilities. In this work, we present AgentTuning, a simple and\ngeneral method to enhance the agent abilities of LLMs while maintaining their\ngeneral LLM capabilities. We construct AgentInstruct, a lightweight\ninstruction-tuning dataset containing high-quality interaction trajectories. We\nemploy a hybrid instruction-tuning strategy by combining AgentInstruct with\nopen-source instructions from general domains. AgentTuning is used to\ninstruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show\nthat AgentTuning enables LLMs' agent capabilities without compromising general\nabilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent\ntasks, demonstrating generalized agent capabilities. We open source the\nAgentInstruct and AgentLM-7B, 13B, and 70B models at\nhttps://github.com/THUDM/AgentTuning , serving open and powerful alternatives\nto commercial LLMs for agent tasks.",
          "link": "http://arxiv.org/abs/2310.12823",
          "publishedOn": "2023-10-21T00:41:42.245Z",
          "wordCount": null,
          "title": "AgentTuning: Enabling Generalized Agent Abilities for LLMs. (arXiv:2310.12823v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yaohua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jiaxin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_X/0/1/0/all/0/1\">Xianghao Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Risheng Liu</a>",
          "description": "In light of the vulnerability of deep learning models to adversarial samples\nand the ensuing security issues, a range of methods, including Adversarial\nTraining (AT) as a prominent representative, aimed at enhancing model\nrobustness against various adversarial attacks, have seen rapid development.\nHowever, existing methods essentially assist the current state of target model\nto defend against parameter-oriented adversarial attacks with explicit or\nimplicit computation burdens, which also suffers from unstable convergence\nbehavior due to inconsistency of optimization trajectories. Diverging from\nprevious work, this paper reconsiders the update rule of target model and\ncorresponding deficiency to defend based on its current state. By introducing\nthe historical state of the target model as a proxy, which is endowed with much\nprior information for defense, we formulate a two-stage update rule, resulting\nin a general adversarial defense framework, which we refer to as `LAST' ({\\bf\nL}earn from the P{\\bf ast}). Besides, we devise a Self Distillation (SD) based\ndefense objective to constrain the update process of the proxy model without\nthe introduction of larger teacher models. Experimentally, we demonstrate\nconsistent and significant performance enhancements by refining a series of\nsingle-step and multi-step AT methods (e.g., up to $\\bf 9.2\\%$ and $\\bf 20.5\\%$\nimprovement of Robust Accuracy (RA) on CIFAR10 and CIFAR100 datasets,\nrespectively) across various datasets, backbones and attack modalities, and\nvalidate its ability to enhance training stability and ameliorate catastrophic\noverfitting issues meanwhile.",
          "link": "http://arxiv.org/abs/2310.12713",
          "publishedOn": "2023-10-21T00:41:42.244Z",
          "wordCount": null,
          "title": "Learn from the Past: A Proxy based Adversarial Defense Framework to Boost Robustness. (arXiv:2310.12713v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yida Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_D/0/1/0/all/0/1\">Daxiong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guozhou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>",
          "description": "Ocean science, which delves into the oceans that are reservoirs of life and\nbiodiversity, is of great significance given that oceans cover over 70% of our\nplanet's surface. Recently, advances in Large Language Models (LLMs) have\ntransformed the paradigm in science. Despite the success in other domains,\ncurrent LLMs often fall short in catering to the needs of domain experts like\noceanographers, and the potential of LLMs for ocean science is under-explored.\nThe intrinsic reason may be the immense and intricate nature of ocean data as\nwell as the necessity for higher granularity and richness in knowledge. To\nalleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean\ndomain, which is expert in various ocean science tasks. We propose DoInstruct,\na novel framework to automatically obtain a large volume of ocean domain\ninstruction data, which generates instructions based on multi-agent\ncollaboration. Additionally, we construct the first oceanography benchmark,\nOceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though\ncomprehensive experiments, OceanGPT not only shows a higher level of knowledge\nexpertise for oceans science tasks but also gains preliminary embodied\nintelligence capabilities in ocean technology. Codes, data and checkpoints will\nsoon be available at https://github.com/zjunlp/KnowLM.",
          "link": "http://arxiv.org/abs/2310.02031",
          "publishedOn": "2023-10-21T00:41:42.238Z",
          "wordCount": null,
          "title": "OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12595",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wharrie_S/0/1/0/all/0/1\">Sophie Wharrie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "The key challenge underlying machine learning is generalisation to new data.\nThis work studies generalisation for datasets consisting of related tasks that\nmay differ in causal mechanisms. For example, observational medical data for\ncomplex diseases suffers from heterogeneity in causal mechanisms of disease\nacross patients, creating challenges for machine learning algorithms that need\nto generalise to new patients outside of the training dataset. Common\napproaches for learning supervised models with heterogeneous datasets include\nlearning a global model for the entire dataset, learning local models for each\ntasks' data, or utilising hierarchical, meta-learning and multi-task learning\napproaches to learn how to generalise from data pooled across multiple tasks.\nIn this paper we propose causal similarity-based hierarchical Bayesian models\nto improve generalisation to new tasks by learning how to pool data from\ntraining tasks with similar causal mechanisms. We apply this general modelling\nprinciple to Bayesian neural networks and compare a variety of methods for\nestimating causal task similarity (for both known and unknown causal models).\nWe demonstrate the benefits of our approach and applicability to real world\nproblems through a range of experiments on simulated and real data.",
          "link": "http://arxiv.org/abs/2310.12595",
          "publishedOn": "2023-10-21T00:41:42.183Z",
          "wordCount": null,
          "title": "Causal Similarity-Based Hierarchical Bayesian Models. (arXiv:2310.12595v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yichuan Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shenghao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chiwun Yang</a>",
          "description": "In the realm of deep learning, transformers have emerged as a dominant\narchitecture, particularly in natural language processing tasks. However, with\ntheir widespread adoption, concerns regarding the security and privacy of the\ndata processed by these models have arisen. In this paper, we address a pivotal\nquestion: Can the data fed into transformers be recovered using their attention\nweights and outputs? We introduce a theoretical framework to tackle this\nproblem. Specifically, we present an algorithm that aims to recover the input\ndata $X \\in \\mathbb{R}^{d \\times n}$ from given attention weights $W = QK^\\top\n\\in \\mathbb{R}^{d \\times d}$ and output $B \\in \\mathbb{R}^{n \\times n}$ by\nminimizing the loss function $L(X)$. This loss function captures the\ndiscrepancy between the expected output and the actual output of the\ntransformer. Our findings have significant implications for the Localized\nLayer-wise Mechanism (LLM), suggesting potential vulnerabilities in the model's\ndesign from a security and privacy perspective. This work underscores the\nimportance of understanding and safeguarding the internal workings of\ntransformers to ensure the confidentiality of processed data.",
          "link": "http://arxiv.org/abs/2310.12462",
          "publishedOn": "2023-10-21T00:41:42.085Z",
          "wordCount": null,
          "title": "Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights. (arXiv:2310.12462v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12781",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xiong_X/0/1/0/all/0/1\">Xiaofei Xiong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ju_N/0/1/0/all/0/1\">Nianqiao P. Ju</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Sanguo Zhang</a>",
          "description": "Many modern statistical analysis and machine learning applications require\ntraining models on sensitive user data. Differential privacy provides a formal\nguarantee that individual-level information about users does not leak. In this\nframework, randomized algorithms inject calibrated noise into the confidential\ndata, resulting in privacy-protected datasets or queries. However, restricting\naccess to only the privatized data during statistical analysis makes it\ncomputationally challenging to perform valid inferences on parameters\nunderlying the confidential data. In this work, we propose simulation-based\ninference methods from privacy-protected datasets. Specifically, we use neural\nconditional density estimators as a flexible family of distributions to\napproximate the posterior distribution of model parameters given the observed\nprivate query results. We illustrate our methods on discrete time-series data\nunder an infectious disease model and on ordinary linear regression models.\nIllustrating the privacy-utility trade-off, our experiments and analysis\ndemonstrate the necessity and feasibility of designing valid statistical\ninference procedures to correct for biases introduced by the privacy-protection\nmechanisms.",
          "link": "http://arxiv.org/abs/2310.12781",
          "publishedOn": "2023-10-21T00:41:41.920Z",
          "wordCount": null,
          "title": "Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weize Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaoyue Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Ruobing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Parameter-shared pre-trained language models (PLMs) have emerged as a\nsuccessful approach in resource-constrained environments, enabling substantial\nreductions in model storage and memory costs without significant performance\ncompromise. However, it is important to note that parameter sharing does not\nalleviate computational burdens associated with inference, thus impeding its\npracticality in situations characterized by limited stringent latency\nrequirements or computational resources. Building upon neural ordinary\ndifferential equations (ODEs), we introduce a straightforward technique to\nenhance the inference efficiency of parameter-shared PLMs. Additionally, we\npropose a simple pre-training technique that leads to fully or partially shared\nmodels capable of achieving even greater inference acceleration. The\nexperimental results demonstrate the effectiveness of our methods on both\nautoregressive and autoencoding PLMs, providing novel insights into more\nefficient utilization of parameter-shared models in resource-constrained\nsettings.",
          "link": "http://arxiv.org/abs/2310.12818",
          "publishedOn": "2023-10-21T00:41:41.918Z",
          "wordCount": null,
          "title": "Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models. (arXiv:2310.12818v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Ruizhe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Huimin Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jianhong Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1\">Tianxiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jin Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Joey Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zuozhu Liu</a>",
          "description": "Recent discoveries have revealed that deep neural networks might behave in a\nbiased manner in many real-world scenarios. For instance, deep networks trained\non a large-scale face recognition dataset CelebA tend to predict blonde hair\nfor females and black hair for males. Such biases not only jeopardize the\nrobustness of models but also perpetuate and amplify social biases, which is\nespecially concerning for automated decision-making processes in healthcare,\nrecruitment, etc., as they could exacerbate unfair economic and social\ninequalities among different groups. Existing debiasing methods suffer from\nhigh costs in bias labeling or model re-training, while also exhibiting a\ndeficiency in terms of elucidating the origins of biases within the model. To\nthis respect, we propose a fast model debiasing framework (FMD) which offers an\nefficient approach to identify, evaluate and remove biases inherent in trained\nmodels. The FMD identifies biased attributes through an explicit counterfactual\nconcept and quantifies the influence of data samples with influence functions.\nMoreover, we design a machine unlearning-based strategy to efficiently and\neffectively remove the bias in a trained model with a small counterfactual\ndataset. Experiments on the Colored MNIST, CelebA, and Adult Income datasets\nalong with experiments with large language models demonstrate that our method\nachieves superior or competing accuracies compared with state-of-the-art\nmethods while attaining significantly fewer biases and requiring much less\ndebiasing cost. Notably, our method requires only a small external dataset and\nupdating a minimal amount of model parameters, without the requirement of\naccess to training data that may be too large or unavailable in practice.",
          "link": "http://arxiv.org/abs/2310.12560",
          "publishedOn": "2023-10-21T00:41:41.739Z",
          "wordCount": null,
          "title": "Fast Model Debias with Machine Unlearning. (arXiv:2310.12560v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mitsuboshi_R/0/1/0/all/0/1\">Ryotaro Mitsuboshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hatano_K/0/1/0/all/0/1\">Kohei Hatano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takimoto_E/0/1/0/all/0/1\">Eiji Takimoto</a>",
          "description": "Metarounding is an approach to convert an approximation algorithm for linear\noptimization over some combinatorial classes to an online linear optimization\nalgorithm for the same class. We propose a new metarounding algorithm under a\nnatural assumption that a relax-based approximation algorithm exists for the\ncombinatorial class. Our algorithm is much more efficient in both theoretical\nand practical aspects.",
          "link": "http://arxiv.org/abs/2310.12629",
          "publishedOn": "2023-10-21T00:41:41.733Z",
          "wordCount": null,
          "title": "An Improved Metarounding Algorithm via Frank-Wolfe. (arXiv:2310.12629v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thaminkaew_T/0/1/0/all/0/1\">Thanakorn Thaminkaew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lertvittayakumjorn_P/0/1/0/all/0/1\">Piyawat Lertvittayakumjorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vateekul_P/0/1/0/all/0/1\">Peerapon Vateekul</a>",
          "description": "Prompt-based learning has shown its effectiveness in few-shot text\nclassification. One important factor in its success is a verbalizer, which\ntranslates output from a language model into a predicted class. Notably, the\nsimplest and widely acknowledged verbalizer employs manual labels to represent\nthe classes. However, manual selection does not guarantee the optimality of the\nselected words when conditioned on the chosen language model. Therefore, we\npropose Label-Aware Automatic Verbalizer (LAAV), effectively augmenting the\nmanual labels to achieve better few-shot classification results. Specifically,\nwe use the manual labels along with the conjunction \"and\" to induce the model\nto generate more effective words for the verbalizer. The experimental results\non five datasets across five languages demonstrate that LAAV significantly\noutperforms existing verbalizers. Furthermore, our analysis reveals that LAAV\nsuggests more relevant words compared to similar approaches, especially in\nmid-to-low resource languages.",
          "link": "http://arxiv.org/abs/2310.12778",
          "publishedOn": "2023-10-21T00:41:41.717Z",
          "wordCount": null,
          "title": "Label-Aware Automatic Verbalizer for Few-Shot Text Classification. (arXiv:2310.12778v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huayu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carreon_Rascon_A/0/1/0/all/0/1\">Ana S. Carreon-Rascon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiwen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1\">Geng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ao Li</a>",
          "description": "Medical time series data are indispensable in healthcare, providing critical\ninsights for disease diagnosis, treatment planning, and patient management. The\nexponential growth in data complexity, driven by advanced sensor technologies,\nhas presented challenges related to data labeling. Self-supervised learning\n(SSL) has emerged as a transformative approach to address these challenges,\neliminating the need for extensive human annotation. In this study, we\nintroduce a novel framework for Medical Time Series Representation Learning,\nknown as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and\nMasked Autoencoder (MAE) methods, offering a unique approach to representation\nlearning for medical time series data. By combining these techniques, MTS-LOF\nenhances the potential of healthcare applications by providing more\nsophisticated, context-rich representations. Additionally, MTS-LOF employs a\nmulti-masking strategy to facilitate occlusion-invariant feature learning. This\napproach allows the model to create multiple views of the data by masking\nportions of it. By minimizing the discrepancy between the representations of\nthese masked patches and the fully visible patches, MTS-LOF learns to capture\nrich contextual information within medical time series datasets. The results of\nexperiments conducted on diverse medical time series datasets demonstrate the\nsuperiority of MTS-LOF over other methods. These findings hold promise for\nsignificantly enhancing healthcare applications by improving representation\nlearning. Furthermore, our work delves into the integration of joint-embedding\nSSL and MAE techniques, shedding light on the intricate interplay between\ntemporal and structural dependencies in healthcare data. This understanding is\ncrucial, as it allows us to grasp the complexities of healthcare data analysis.",
          "link": "http://arxiv.org/abs/2310.12451",
          "publishedOn": "2023-10-21T00:41:41.697Z",
          "wordCount": null,
          "title": "MTS-LOF: Medical Time-Series Representation Learning via Occlusion-Invariant Features. (arXiv:2310.12451v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Zipeng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1\">Zhongkai Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bokai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhijie Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>",
          "description": "Neural operators, as an efficient surrogate model for learning the solutions\nof PDEs, have received extensive attention in the field of scientific machine\nlearning. Among them, attention-based neural operators have become one of the\nmainstreams in related research. However, existing approaches overfit the\nlimited training data due to the considerable number of parameters in the\nattention mechanism. To address this, we develop an orthogonal attention based\non the eigendecomposition of the kernel integral operator and the neural\napproximation of eigenfunctions. The orthogonalization naturally poses a proper\nregularization effect on the resulting neural operator, which aids in resisting\noverfitting and boosting generalization. Experiments on six standard neural\noperator benchmark datasets comprising both regular and irregular geometries\nshow that our method can outperform competing baselines with decent margins.",
          "link": "http://arxiv.org/abs/2310.12487",
          "publishedOn": "2023-10-21T00:41:41.694Z",
          "wordCount": null,
          "title": "Improved Operator Learning by Orthogonal Attention. (arXiv:2310.12487v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1\">Boyi Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>",
          "description": "Large language models (LLMs) are susceptible to red teaming attacks, which\ncan induce LLMs to generate harmful content. Previous research constructs\nattack prompts via manual or automatic methods, which have their own\nlimitations on construction cost and quality. To address these issues, we\npropose an integrated approach that combines manual and automatic methods to\neconomically generate high-quality attack prompts. Specifically, considering\nthe impressive capabilities of newly emerged LLMs, we propose an attack\nframework to instruct LLMs to mimic human-generated prompts through in-context\nlearning. Furthermore, we propose a defense framework that fine-tunes victim\nLLMs through iterative interactions with the attack framework to enhance their\nsafety against red teaming attacks. Extensive experiments on different LLMs\nvalidate the effectiveness of our proposed attack and defense frameworks.\nAdditionally, we release a series of attack prompts datasets named SAP with\nvarying sizes, facilitating the safety evaluation and enhancement of more LLMs.\nOur code and dataset is available on https://github.com/Aatrox103/SAP .",
          "link": "http://arxiv.org/abs/2310.12505",
          "publishedOn": "2023-10-21T00:41:41.580Z",
          "wordCount": null,
          "title": "Attack Prompt Generation for Red Teaming and Defending Large Language Models. (arXiv:2310.12505v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08724",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Goan_E/0/1/0/all/0/1\">Ethan Goan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Perrin_D/0/1/0/all/0/1\">Dimitri Perrin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mengersen_K/0/1/0/all/0/1\">Kerrie Mengersen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fookes_C/0/1/0/all/0/1\">Clinton Fookes</a>",
          "description": "Inference on modern Bayesian Neural Networks (BNNs) often relies on a\nvariational inference treatment, imposing violated assumptions of independence\nand the form of the posterior. Traditional MCMC approaches avoid these\nassumptions at the cost of increased computation due to its incompatibility to\nsubsampling of the likelihood. New Piecewise Deterministic Markov Process\n(PDMP) samplers permit subsampling, though introduce a model specific\ninhomogenous Poisson Process (IPPs) which is difficult to sample from. This\nwork introduces a new generic and adaptive thinning scheme for sampling from\nthese IPPs, and demonstrates how this approach can accelerate the application\nof PDMPs for inference in BNNs. Experimentation illustrates how inference with\nthese methods is computationally feasible, can improve predictive accuracy,\nMCMC mixing performance, and provide informative uncertainty measurements when\ncompared against other approximate inference schemes.",
          "link": "http://arxiv.org/abs/2302.08724",
          "publishedOn": "2023-10-21T00:41:41.548Z",
          "wordCount": null,
          "title": "Piecewise Deterministic Markov Processes for Bayesian Neural Networks. (arXiv:2302.08724v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.06949",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saligkaras_D/0/1/0/all/0/1\">Dimitrios Saligkaras</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papageorgiou_V/0/1/0/all/0/1\">Vasileios E. Papageorgiou</a>",
          "description": "Clustering is an unsupervised machine learning methodology where unlabeled\nelements/objects are grouped together aiming to the construction of\nwell-established clusters that their elements are classified according to their\nsimilarity. The goal of this process is to provide a useful aid to the\nresearcher that will help her/him to identify patterns among the data. Dealing\nwith large databases, such patterns may not be easily detectable without the\ncontribution of a clustering algorithm. This article provides a deep\ndescription of the most widely used clustering methodologies accompanied by\nuseful presentations concerning suitable parameter selection and\ninitializations. Simultaneously, this article not only represents a review\nhighlighting the major elements of examined clustering techniques but\nemphasizes the comparison of these algorithms' clustering efficiency based on 3\ndatasets, revealing their existing weaknesses and capabilities through accuracy\nand complexity, during the confrontation of discrete and continuous\nobservations. The produced results help us extract valuable conclusions about\nthe appropriateness of the examined clustering techniques in accordance with\nthe dataset's size.",
          "link": "http://arxiv.org/abs/2207.06949",
          "publishedOn": "2023-10-21T00:41:41.410Z",
          "wordCount": null,
          "title": "Seeking the Truth Beyond the Data. An Unsupervised Machine Learning Approach. (arXiv:2207.06949v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12793",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitawarin_C/0/1/0/all/0/1\">Chawin Sitawarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spratling_M/0/1/0/all/0/1\">Michael Spratling</a>",
          "description": "Existing works have made great progress in improving adversarial robustness,\nbut typically test their method only on data from the same distribution as the\ntraining data, i.e. in-distribution (ID) testing. As a result, it is unclear\nhow such robustness generalizes under input distribution shifts, i.e.\nout-of-distribution (OOD) testing. This is a concerning omission as such\ndistribution shifts are unavoidable when methods are deployed in the wild. To\naddress this issue we propose a benchmark named OODRobustBench to\ncomprehensively assess OOD adversarial robustness using 23 dataset-wise shifts\n(i.e. naturalistic shifts in input distribution) and 6 threat-wise shifts\n(i.e., unforeseen adversarial threat models). OODRobustBench is used to assess\n706 robust models using 60.7K adversarial evaluations. This large-scale\nanalysis shows that: 1) adversarial robustness suffers from a severe OOD\ngeneralization issue; 2) ID robustness correlates strongly with OOD robustness,\nin a positive linear way, under many distribution shifts. The latter enables\nthe prediction of OOD robustness from ID robustness. Based on this, we are able\nto predict the upper limit of OOD robustness for existing robust training\nschemes. The results suggest that achieving OOD robustness requires designing\nnovel methods beyond the conventional ones. Last, we discover that extra data,\ndata augmentation, advanced model architectures and particular regularization\napproaches can improve OOD robustness. Noticeably, the discovered training\nschemes, compared to the baseline, exhibit dramatically higher robustness under\nthreat shift while keeping high ID robustness, demonstrating new promising\nsolutions for robustness against both multi-attack and unforeseen attacks.",
          "link": "http://arxiv.org/abs/2310.12793",
          "publishedOn": "2023-10-21T00:41:41.222Z",
          "wordCount": null,
          "title": "OODRobustBench: benchmarking and analyzing adversarial robustness under distribution shift. (arXiv:2310.12793v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wanli Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zehai Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ragni_A/0/1/0/all/0/1\">Anton Ragni</a>",
          "description": "Recently there has been a lot of interest in non-autoregressive (non-AR)\nmodels for speech synthesis, such as FastSpeech 2 and diffusion models. Unlike\nAR models, these models do not have autoregressive dependencies among outputs\nwhich makes inference efficient. This paper expands the range of available\nnon-AR models with another member called energy-based models (EBMs). The paper\ndescribes how noise contrastive estimation, which relies on the comparison\nbetween positive and negative samples, can be used to train EBMs. It proposes a\nnumber of strategies for generating effective negative samples, including using\nhigh-performing AR models. It also describes how sampling from EBMs can be\nperformed using Langevin Markov Chain Monte-Carlo (MCMC). The use of Langevin\nMCMC enables to draw connections between EBMs and currently popular diffusion\nmodels. Experiments on LJSpeech dataset show that the proposed approach offers\nimprovements over Tacotron 2.",
          "link": "http://arxiv.org/abs/2310.12765",
          "publishedOn": "2023-10-21T00:41:41.049Z",
          "wordCount": null,
          "title": "Energy-Based Models For Speech Synthesis. (arXiv:2310.12765v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12528",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Huppenkothen_D/0/1/0/all/0/1\">D. Huppenkothen</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ntampaka_M/0/1/0/all/0/1\">M. Ntampaka</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ho_M/0/1/0/all/0/1\">M. Ho</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Fouesneau_M/0/1/0/all/0/1\">M. Fouesneau</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Nord_B/0/1/0/all/0/1\">B. Nord</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Peek_J/0/1/0/all/0/1\">J. E. G. Peek</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Walmsley_M/0/1/0/all/0/1\">M. Walmsley</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wu_J/0/1/0/all/0/1\">J. F. Wu</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Avestruz_C/0/1/0/all/0/1\">C. Avestruz</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Buck_T/0/1/0/all/0/1\">T. Buck</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Brescia_M/0/1/0/all/0/1\">M. Brescia</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Finkbeiner_D/0/1/0/all/0/1\">D. P. Finkbeiner</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Goulding_A/0/1/0/all/0/1\">A. D. Goulding</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kacprzak_T/0/1/0/all/0/1\">T. Kacprzak</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Melchior_P/0/1/0/all/0/1\">P. Melchior</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Pasquato_M/0/1/0/all/0/1\">M. Pasquato</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ramachandra_N/0/1/0/all/0/1\">N. Ramachandra</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ting_Y/0/1/0/all/0/1\">Y.-S. Ting</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ven_G/0/1/0/all/0/1\">G. van de Ven</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Villar_S/0/1/0/all/0/1\">S. Villar</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Villar_V/0/1/0/all/0/1\">V.A. Villar</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Zinger_E/0/1/0/all/0/1\">E. Zinger</a>",
          "description": "Machine learning has rapidly become a tool of choice for the astronomical\ncommunity. It is being applied across a wide range of wavelengths and problems,\nfrom the classification of transients to neural network emulators of\ncosmological simulations, and is shifting paradigms about how we generate and\nreport scientific results. At the same time, this class of method comes with\nits own set of best practices, challenges, and drawbacks, which, at present,\nare often reported on incompletely in the astrophysical literature. With this\npaper, we aim to provide a primer to the astronomical community, including\nauthors, reviewers, and editors, on how to implement machine learning models\nand report their results in a way that ensures the accuracy of the results,\nreproducibility of the findings, and usefulness of the method.",
          "link": "http://arxiv.org/abs/2310.12528",
          "publishedOn": "2023-10-21T00:41:40.859Z",
          "wordCount": null,
          "title": "Constructing Impactful Machine Learning Research for Astronomy: Best Practices for Researchers and Reviewers. (arXiv:2310.12528v1 [astro-ph.IM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.12303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petrick_F/0/1/0/all/0/1\">Frithjof Petrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herold_C/0/1/0/all/0/1\">Christian Herold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrushkov_P/0/1/0/all/0/1\">Pavel Petrushkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_S/0/1/0/all/0/1\">Shahram Khadivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Despite the known limitations, most machine translation systems today still\noperate on the sentence-level. One reason for this is, that most parallel\ntraining data is only sentence-level aligned, without document-level meta\ninformation available. In this work, we set out to build context-aware\ntranslation systems utilizing document-level monolingual data instead. This can\nbe achieved by combining any existing sentence-level translation model with a\ndocument-level language model. We improve existing approaches by leveraging\nrecent advancements in model combination. Additionally, we propose novel\nweighting techniques that make the system combination more flexible and\nsignificantly reduce computational overhead. In a comprehensive evaluation on\nfour diverse translation tasks, we show that our extensions improve\ndocument-targeted scores substantially and are also computationally more\nefficient. However, we also find that in most scenarios, back-translation gives\neven better results, at the cost of having to re-train the translation system.\nFinally, we explore language model fusion in the light of recent advancements\nin large language models. Our findings suggest that there might be strong\npotential in utilizing large language models via model combination.",
          "link": "http://arxiv.org/abs/2310.12303",
          "publishedOn": "2023-10-21T00:41:40.338Z",
          "wordCount": 696,
          "title": "Document-Level Language Models for Machine Translation. (arXiv:2310.12303v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yazdanpanah_I/0/1/0/all/0/1\">Iman Yazdanpanah</a>",
          "description": "SCGAN adds a similarity constraint between generated images and conditions as\na regularization term on generative adversarial networks. Similarity constraint\nworks as a tutor to instruct the generator network to comprehend the difference\nof representations based on conditions. We understand how SCGAN works on a\ndeeper level. This understanding makes us realize that the similarity\nconstraint functions like the contrastive loss function. We believe that a\nmodel with high understanding and intelligence measures the similarity between\nimages based on their structure and high level features, just like humans do.\nTwo major changes we applied to SCGAN in order to make a modified model are\nusing SSIM to measure similarity between images and applying contrastive loss\nprinciples to the similarity constraint. The modified model performs better\nusing FID and FactorVAE metrics. The modified model also has better\ngeneralisability compared to other models. Keywords Generative Adversarial\nNets, Unsupervised Learning, Disentangled Representation Learning, Contrastive\nDisentanglement, SSIM",
          "link": "http://arxiv.org/abs/2310.12262",
          "publishedOn": "2023-10-21T00:41:40.331Z",
          "wordCount": 661,
          "title": "Improving SCGAN's Similarity Constraint and Learning a Better Disentangled Representation. (arXiv:2310.12262v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12500",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Shen_Y/0/1/0/all/0/1\">Yanhui Shen</a>",
          "description": "Options, serving as a crucial financial instrument, are used by investors to\nmanage and mitigate their investment risks within the securities market.\nPrecisely predicting the present price of an option enables investors to make\ninformed and efficient decisions. In this paper, we propose a machine learning\nmethod for forecasting the prices of SPY (ETF) option based on gated recurrent\nunit (GRU) and self-attention mechanism. We first partitioned the raw dataset\ninto 15 subsets according to moneyness and days to maturity criteria. For each\nsubset, we matched the corresponding U.S. government bond rates and Implied\nVolatility Indices. This segmentation allows for a more insightful exploration\nof the impacts of risk-free rates and underlying volatility on option pricing.\nNext, we built four different machine learning models, including multilayer\nperceptron (MLP), long short-term memory (LSTM), self-attention LSTM, and\nself-attention GRU in comparison to the traditional binomial model. The\nempirical result shows that self-attention GRU with historical data outperforms\nother models due to its ability to capture complex temporal dependencies and\nleverage the contextual information embedded in the historical data. Finally,\nin order to unveil the \"black box\" of artificial intelligence, we employed the\nSHapley Additive exPlanations (SHAP) method to interpret and analyze the\nprediction results of the self-attention GRU model with historical data. This\nprovides insights into the significance and contributions of different input\nfeatures on the pricing of American-style options.",
          "link": "http://arxiv.org/abs/2310.12500",
          "publishedOn": "2023-10-21T00:41:40.322Z",
          "wordCount": 729,
          "title": "American Option Pricing using Self-Attention GRU and Shapley Value Interpretation. (arXiv:2310.12500v1 [q-fin.PR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12324",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Musabirov_I/0/1/0/all/0/1\">Ilya Musabirov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zavaleta_Bernuy_A/0/1/0/all/0/1\">Angela Zavaleta-Bernuy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liut_M/0/1/0/all/0/1\">Michael Liut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1\">Joseph Jay Williams</a>",
          "description": "Randomized experimental comparisons of alternative pedagogical strategies\ncould provide useful empirical evidence in instructors' decision-making.\nHowever, traditional experiments do not have a clear and simple pathway to\nusing data rapidly to try to increase the chances that students in an\nexperiment get the best conditions. Drawing inspiration from the use of machine\nlearning and experimentation in product development at leading technology\ncompanies, we explore how adaptive experimentation might help in continuous\ncourse improvement. In adaptive experiments, as different arms/conditions are\ndeployed to students, data is analyzed and used to change the experience for\nfuture students. This can be done using machine learning algorithms to identify\nwhich actions are more promising for improving student experience or outcomes.\nThis algorithm can then dynamically deploy the most effective conditions to\nfuture students, resulting in better support for students' needs. We illustrate\nthe approach with a case study providing a side-by-side comparison of\ntraditional and adaptive experimentation of self-explanation prompts in online\nhomework problems in a CS1 course. This provides a first step in exploring the\nfuture of how this methodology can be useful in bridging research and practice\nin doing continuous improvement.",
          "link": "http://arxiv.org/abs/2310.12324",
          "publishedOn": "2023-10-21T00:41:40.291Z",
          "wordCount": 721,
          "title": "Opportunities for Adaptive Experiments to Enable Continuous Improvement that Trades-off Instructor and Researcher Incentives. (arXiv:2310.12324v1 [cs.HC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sone_S/0/1/0/all/0/1\">Shusaku Sone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jiaxin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_A/0/1/0/all/0/1\">Atsushi Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiba_N/0/1/0/all/0/1\">Naoya Chiba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ushiku_Y/0/1/0/all/0/1\">Yoshitaka Ushiku</a>",
          "description": "Matching, a task to optimally assign limited resources under constraints, is\na fundamental technology for society. The task potentially has various\nobjectives, conditions, and constraints; however, the efficient neural network\narchitecture for matching is underexplored. This paper proposes a novel graph\nneural network (GNN), \\textit{WeaveNet}, designed for bipartite graphs. Since a\nbipartite graph is generally dense, general GNN architectures lose node-wise\ninformation by over-smoothing when deeply stacked. Such a phenomenon is\nundesirable for solving matching problems. WeaveNet avoids it by preserving\nedge-wise information while passing messages densely to reach a better\nsolution. To evaluate the model, we approximated one of the \\textit{strongly\nNP-hard} problems, \\textit{fair stable matching}. Despite its inherent\ndifficulties and the network's general purpose design, our model reached a\ncomparative performance with state-of-the-art algorithms specially designed for\nstable matching for small numbers of agents.",
          "link": "http://arxiv.org/abs/2310.12515",
          "publishedOn": "2023-10-21T00:41:40.283Z",
          "wordCount": 633,
          "title": "WeaveNet for Approximating Two-sided Matching Problems. (arXiv:2310.12515v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Said_A/0/1/0/all/0/1\">Anwar Said</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shabbir_M/0/1/0/all/0/1\">Mudassir Shabbir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Derr_T/0/1/0/all/0/1\">Tyler Derr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbas_W/0/1/0/all/0/1\">Waseem Abbas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koutsoukos_X/0/1/0/all/0/1\">Xenofon Koutsoukos</a>",
          "description": "Graph Neural Networks (GNNs) have shown remarkable merit in performing\nvarious learning-based tasks in complex networks. The superior performance of\nGNNs often correlates with the availability and quality of node-level features\nin the input networks. However, for many network applications, such node-level\ninformation may be missing or unreliable, thereby limiting the applicability\nand efficacy of GNNs. To address this limitation, we present a novel approach\ndenoted as Ego-centric Spectral subGraph Embedding Augmentation (ESGEA), which\naims to enhance and design node features, particularly in scenarios where\ninformation is lacking. Our method leverages the topological structure of the\nlocal subgraph to create topology-aware node features. The subgraph features\nare generated using an efficient spectral graph embedding technique, and they\nserve as node features that capture the local topological organization of the\nnetwork. The explicit node features, if present, are then enhanced with the\nsubgraph embeddings in order to improve the overall performance. ESGEA is\ncompatible with any GNN-based architecture and is effective even in the absence\nof node features. We evaluate the proposed method in a social network graph\nclassification task where node attributes are unavailable, as well as in a node\nclassification task where node features are corrupted or even absent. The\nevaluation results on seven datasets and eight baseline models indicate up to a\n10% improvement in AUC and a 7% improvement in accuracy for graph and node\nclassification tasks, respectively.",
          "link": "http://arxiv.org/abs/2310.12169",
          "publishedOn": "2023-10-21T00:41:40.271Z",
          "wordCount": 755,
          "title": "Enhanced Graph Neural Networks with Ego-Centric Spectral Subgraph Embeddings Augmentation. (arXiv:2310.12169v1 [cs.SI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_N/0/1/0/all/0/1\">Nan Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiuling Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wendy Hui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_V/0/1/0/all/0/1\">Violet Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Y/0/1/0/all/0/1\">Yue Ning</a>",
          "description": "Graph Neural Networks (GNNs) have been widely used for various types of graph\ndata processing and analytical tasks in different domains. Training GNNs over\ncentralized graph data can be infeasible due to privacy concerns and regulatory\nrestrictions. Thus, federated learning (FL) becomes a trending solution to\naddress this challenge in a distributed learning paradigm. However, as GNNs may\ninherit historical bias from training data and lead to discriminatory\npredictions, the bias of local models can be easily propagated to the global\nmodel in distributed settings. This poses a new challenge in mitigating bias in\nfederated GNNs. To address this challenge, we propose $\\text{F}^2$GNN, a Fair\nFederated Graph Neural Network, that enhances group fairness of federated GNNs.\nAs bias can be sourced from both data and learning algorithms, $\\text{F}^2$GNN\naims to mitigate both types of bias under federated settings. First, we provide\ntheoretical insights on the connection between data bias in a training graph\nand statistical fairness metrics of the trained GNN models. Based on the\ntheoretical analysis, we design $\\text{F}^2$GNN which contains two key\ncomponents: a fairness-aware local model update scheme that enhances group\nfairness of the local models on the client side, and a fairness-weighted global\nmodel update scheme that takes both data bias and fairness metrics of local\nmodels into consideration in the aggregation process. We evaluate\n$\\text{F}^2$GNN empirically versus a number of baseline methods, and\ndemonstrate that $\\text{F}^2$GNN outperforms these baselines in terms of both\nfairness and model accuracy.",
          "link": "http://arxiv.org/abs/2310.12350",
          "publishedOn": "2023-10-21T00:41:40.264Z",
          "wordCount": 752,
          "title": "Equipping Federated Graph Neural Networks with Structure-aware Group Fairness. (arXiv:2310.12350v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vosylius_V/0/1/0/all/0/1\">Vitalis Vosylius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1\">Edward Johns</a>",
          "description": "Consider the following problem: given a few demonstrations of a task across a\nfew different objects, how can a robot learn to perform that same task on new,\npreviously unseen objects? This is challenging because the large variety of\nobjects within a class makes it difficult to infer the task-relevant\nrelationship between the new objects and the objects in the demonstrations. We\naddress this by formulating imitation learning as a conditional alignment\nproblem between graph representations of objects. Consequently, we show that\nthis conditioning allows for in-context learning, where a robot can perform a\ntask on a set of new objects immediately after the demonstrations, without any\nprior knowledge about the object class or any further training. In our\nexperiments, we explore and validate our design choices, and we show that our\nmethod is highly effective for few-shot learning of several real-world,\neveryday tasks, whilst outperforming baselines. Videos are available on our\nproject webpage at https://www.robot-learning.uk/implicit-graph-alignment.",
          "link": "http://arxiv.org/abs/2310.12238",
          "publishedOn": "2023-10-21T00:41:40.246Z",
          "wordCount": 669,
          "title": "Few-Shot In-Context Imitation Learning via Implicit Graph Alignment. (arXiv:2310.12238v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hakim_G/0/1/0/all/0/1\">Gustavo A. Vargas Hakim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osowiechi_D/0/1/0/all/0/1\">David Osowiechi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noori_M/0/1/0/all/0/1\">Mehrdad Noori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheraghalikhani_M/0/1/0/all/0/1\">Milad Cheraghalikhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ismail Ben Ayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desrosiers_C/0/1/0/all/0/1\">Christian Desrosiers</a>",
          "description": "Deep Learning models have shown remarkable performance in a broad range of\nvision tasks. However, they are often vulnerable against domain shifts at\ntest-time. Test-time training (TTT) methods have been developed in an attempt\nto mitigate these vulnerabilities, where a secondary task is solved at training\ntime simultaneously with the main task, to be later used as an self-supervised\nproxy task at test-time. In this work, we propose a novel unsupervised TTT\ntechnique based on the maximization of Mutual Information between multi-scale\nfeature maps and a discrete latent representation, which can be integrated to\nthe standard training as an auxiliary clustering task. Experimental results\ndemonstrate competitive classification performance on different popular\ntest-time adaptation benchmarks.",
          "link": "http://arxiv.org/abs/2310.12345",
          "publishedOn": "2023-10-21T00:41:40.238Z",
          "wordCount": 647,
          "title": "ClusT3: Information Invariant Test-Time Training. (arXiv:2310.12345v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_V/0/1/0/all/0/1\">Victoria Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hui Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bryce Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_J/0/1/0/all/0/1\">Jochen Schmidt</a>",
          "description": "The optimal placement of sensors for environmental monitoring and disaster\nmanagement is a challenging problem due to its NP-hard nature. Traditional\nmethods for sensor placement involve exact, approximation, or heuristic\napproaches, with the latter being the most widely used. However, heuristic\nmethods are limited by expert intuition and experience. Deep learning (DL) has\nemerged as a promising approach for generating heuristic algorithms\nautomatically. In this paper, we introduce a novel sensor placement approach\nfocused on learning improvement heuristics using deep reinforcement learning\n(RL) methods. Our approach leverages an RL formulation for learning improvement\nheuristics, driven by an actor-critic algorithm for training the policy\nnetwork. We compare our method with several state-of-the-art approaches by\nconducting comprehensive experiments, demonstrating the effectiveness and\nsuperiority of our proposed approach in producing high-quality solutions. Our\nwork presents a promising direction for applying advanced DL and RL techniques\nto challenging climate sensor placement problems.",
          "link": "http://arxiv.org/abs/2310.12387",
          "publishedOn": "2023-10-21T00:41:40.173Z",
          "wordCount": 669,
          "title": "Learning to Solve Climate Sensor Placement Problems with a Transformer. (arXiv:2310.12387v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12281",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farokhi_S/0/1/0/all/0/1\">Soheila Farokhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yaramala_A/0/1/0/all/0/1\">Aswani Yaramala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiangtao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Muhammad F. A. Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiaojun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karimi_H/0/1/0/all/0/1\">Hamid Karimi</a>",
          "description": "In recent years, Massive Open Online Courses (MOOCs) have gained significant\ntraction as a rapidly growing phenomenon in online learning. Unlike traditional\nclassrooms, MOOCs offer a unique opportunity to cater to a diverse audience\nfrom different backgrounds and geographical locations. Renowned universities\nand MOOC-specific providers, such as Coursera, offer MOOC courses on various\nsubjects. Automated assessment tasks like grade and early dropout predictions\nare necessary due to the high enrollment and limited direct interaction between\nteachers and learners. However, current automated assessment approaches\noverlook the structural links between different entities involved in the\ndownstream tasks, such as the students and courses. Our hypothesis suggests\nthat these structural relationships, manifested through an interaction graph,\ncontain valuable information that can enhance the performance of the task at\nhand. To validate this, we construct a unique knowledge graph for a large MOOC\ndataset, which will be publicly available to the research community.\nFurthermore, we utilize graph embedding techniques to extract latent structural\ninformation encoded in the interactions between entities in the dataset. These\ntechniques do not require ground truth labels and can be utilized for various\ntasks. Finally, by combining entity-specific features, behavioral features, and\nextracted structural features, we enhance the performance of predictive machine\nlearning models in student assignment grade prediction. Our experiments\ndemonstrate that structural features can significantly improve the predictive\nperformance of downstream assessment tasks. The code and data are available in\n\\url{https://github.com/DSAatUSU/MOOPer_grade_prediction}",
          "link": "http://arxiv.org/abs/2310.12281",
          "publishedOn": "2023-10-21T00:41:40.166Z",
          "wordCount": 768,
          "title": "Enhancing the Performance of Automated Grade Prediction in MOOC using Graph Representation Learning. (arXiv:2310.12281v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12359",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quinones_Grueiro_M/0/1/0/all/0/1\">Marcos Quinones-Grueiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanbing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barbour_W/0/1/0/all/0/1\">William Barbour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biswas_G/0/1/0/all/0/1\">Gautam Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Work_D/0/1/0/all/0/1\">Daniel Work</a>",
          "description": "Variable speed limit (VSL) control is a promising traffic management strategy\nfor enhancing safety and mobility. This work introduces MARVEL, a multi-agent\nreinforcement learning (MARL) framework for implementing large-scale VSL\ncontrol on freeway corridors using only commonly available data. The agents\nlearn through a reward structure that incorporates adaptability to traffic\nconditions, safety, and mobility; enabling coordination among the agents. The\nproposed framework scales to cover corridors with many gantries thanks to a\nparameter sharing among all VSL agents. The agents are trained in a\nmicrosimulation environment based on a short freeway stretch with 8 gantries\nspanning 7 miles and tested with 34 gantries spanning 17 miles of I-24 near\nNashville, TN. MARVEL improves traffic safety by 63.4% compared to the no\ncontrol scenario and enhances traffic mobility by 14.6% compared to a\nstate-of-the-practice algorithm that has been deployed on I-24. An\nexplainability analysis is undertaken to explore the learned policy under\ndifferent traffic conditions and the results provide insights into the\ndecision-making process of agents. Finally, we test the policy learned from the\nsimulation-based experiments on real input data from I-24 to illustrate the\npotential deployment capability of the learned policy.",
          "link": "http://arxiv.org/abs/2310.12359",
          "publishedOn": "2023-10-21T00:41:40.108Z",
          "wordCount": 699,
          "title": "MARVEL: Multi-Agent Reinforcement-Learning for Large-Scale Variable Speed Limits. (arXiv:2310.12359v1 [cs.MA])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yingjie Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianlei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Ao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_T/0/1/0/all/0/1\">Tong Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1\">Chunming Hu</a>",
          "description": "Graph neural networks (GNNs) have gained significant popularity due to the\npowerful capability to extract useful representations from graph data. As the\nneed for efficient GNN computation intensifies, a variety of programming\nabstractions designed for optimizing GNN Aggregation have emerged to facilitate\nacceleration. However, there is no comprehensive evaluation and analysis upon\nexisting abstractions, thus no clear consensus on which approach is better. In\nthis letter, we classify existing programming abstractions for GNN Aggregation\nby the dimension of data organization and propagation method. By constructing\nthese abstractions on a state-of-the-art GNN library, we perform a thorough and\ndetailed characterization study to compare their performance and efficiency,\nand provide several insights on future GNN acceleration based on our analysis.",
          "link": "http://arxiv.org/abs/2310.12184",
          "publishedOn": "2023-10-21T00:41:40.089Z",
          "wordCount": 640,
          "title": "Architectural Implications of GNN Aggregation Programming Abstractions. (arXiv:2310.12184v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Youngkyu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jongho Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chang-Ock Lee</a>",
          "description": "The performance of neural networks has been significantly improved by\nincreasing the number of channels in convolutional layers. However, this\nincrease in performance comes with a higher computational cost, resulting in\nnumerous studies focused on reducing it. One promising approach to address this\nissue is group convolution, which effectively reduces the computational cost by\ngrouping channels. However, to the best of our knowledge, there has been no\ntheoretical analysis on how well the group convolution approximates the\nstandard convolution. In this paper, we mathematically analyze the\napproximation of the group convolution to the standard convolution with respect\nto the number of groups. Furthermore, we propose a novel variant of the group\nconvolution called balanced group convolution, which shows a higher\napproximation with a small additional computational cost. We provide\nexperimental results that validate our theoretical findings and demonstrate the\nsuperior performance of the balanced group convolution over other variants of\ngroup convolution.",
          "link": "http://arxiv.org/abs/2310.12461",
          "publishedOn": "2023-10-21T00:41:39.955Z",
          "wordCount": 679,
          "title": "Balanced Group Convolution: An Improved Group Convolution Based on Approximability Estimates. (arXiv:2310.12461v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yutian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jiaqi Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zuohui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xuan_Q/0/1/0/all/0/1\">Qi Xuan</a>",
          "description": "Recently, the field of machine learning has undergone a transition from\nmodel-centric to data-centric. The advancements in diverse learning tasks have\nbeen propelled by the accumulation of more extensive datasets, subsequently\nfacilitating the training of larger models on these datasets. However, these\ndatasets remain relatively under-explored. To this end, we introduce a\npioneering approach known as RK-core, to empower gaining a deeper understanding\nof the intricate hierarchical structure within datasets. Across several\nbenchmark datasets, we find that samples with low coreness values appear less\nrepresentative of their respective categories, and conversely, those with high\ncoreness values exhibit greater representativeness. Correspondingly, samples\nwith high coreness values make a more substantial contribution to the\nperformance in comparison to those with low coreness values. Building upon\nthis, we further employ RK-core to analyze the hierarchical structure of\nsamples with different coreset selection methods. Remarkably, we find that a\nhigh-quality coreset should exhibit hierarchical diversity instead of solely\nopting for representative samples. The code is available at\nhttps://github.com/yaolu-zjut/Kcore.",
          "link": "http://arxiv.org/abs/2310.12168",
          "publishedOn": "2023-10-21T00:41:39.878Z",
          "wordCount": 696,
          "title": "RK-core: An Established Methodology for Exploring the Hierarchical Structure within Datasets. (arXiv:2310.12168v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12294",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_T/0/1/0/all/0/1\">Thomas Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_T/0/1/0/all/0/1\">Thi Kieu Khanh Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armanfard_N/0/1/0/all/0/1\">Narges Armanfard</a>",
          "description": "Numerous methods for time series anomaly detection (TSAD) methods have\nemerged in recent years. Most existing methods are unsupervised and assume the\navailability of normal training samples only, while few supervised methods have\nshown superior performance by incorporating labeled anomalous samples in the\ntraining phase. However, certain anomaly types are inherently challenging for\nunsupervised methods to differentiate from normal data, while supervised\nmethods are constrained to detecting anomalies resembling those present during\ntraining, failing to generalize to unseen anomaly classes. This paper is the\nfirst attempt in providing a novel approach for the open-set TSAD problem, in\nwhich a small number of labeled anomalies from a limited class of anomalies are\nvisible in the training phase, with the objective of detecting both seen and\nunseen anomaly classes in the test phase. The proposed method, called\nMultivariate Open-Set timeseries Anomaly Detection (MOSAD) consists of three\nprimary modules: a Feature Extractor to extract meaningful time-series\nfeatures; a Multi-head Network consisting of Generative-, Deviation-, and\nContrastive heads for capturing both seen and unseen anomaly classes; and an\nAnomaly Scoring module leveraging the insights of the three heads to detect\nanomalies. Extensive experiments on three real-world datasets consistently show\nthat our approach surpasses existing methods under various experimental\nsettings, thus establishing a new state-of-the-art performance in the TSAD\nfield.",
          "link": "http://arxiv.org/abs/2310.12294",
          "publishedOn": "2023-10-21T00:41:39.811Z",
          "wordCount": 717,
          "title": "Open-Set Multivariate Time-Series Anomaly Detection. (arXiv:2310.12294v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12304",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Park_R/0/1/0/all/0/1\">Ryan Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Theisen_R/0/1/0/all/0/1\">Ryan Theisen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sahni_N/0/1/0/all/0/1\">Navriti Sahni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Patek_M/0/1/0/all/0/1\">Marcel Patek</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cichonska_A/0/1/0/all/0/1\">Anna Cicho&#x144;ska</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rahman_R/0/1/0/all/0/1\">Rayees Rahman</a>",
          "description": "Molecular language modeling is an effective approach to generating novel\nchemical structures. However, these models do not \\emph{a priori} encode\ncertain preferences a chemist may desire. We investigate the use of fine-tuning\nusing Direct Preference Optimization to better align generated molecules with\nchemist preferences. Our findings suggest that this approach is simple,\nefficient, and highly effective.",
          "link": "http://arxiv.org/abs/2310.12304",
          "publishedOn": "2023-10-21T00:41:39.804Z",
          "wordCount": 557,
          "title": "Preference Optimization for Molecular Language Models. (arXiv:2310.12304v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chongyu Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiancheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yihua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Dennis Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1\">Eric Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>",
          "description": "With evolving data regulations, machine unlearning (MU) has become an\nimportant tool for fostering trust and safety in today's AI models. However,\nexisting MU methods focusing on data and/or weight perspectives often grapple\nwith limitations in unlearning accuracy, stability, and cross-domain\napplicability. To address these challenges, we introduce the concept of 'weight\nsaliency' in MU, drawing parallels with input saliency in model explanation.\nThis innovation directs MU's attention toward specific model weights rather\nthan the entire model, improving effectiveness and efficiency. The resultant\nmethod that we call saliency unlearning (SalUn) narrows the performance gap\nwith 'exact' unlearning (model retraining from scratch after removing the\nforgetting dataset). To the best of our knowledge, SalUn is the first\nprincipled MU approach adaptable enough to effectively erase the influence of\nforgetting data, classes, or concepts in both image classification and\ngeneration. For example, SalUn yields a stability advantage in high-variance\nrandom data forgetting, e.g., with a 0.2% gap compared to exact unlearning on\nthe CIFAR-10 dataset. Moreover, in preventing conditional diffusion models from\ngenerating harmful images, SalUn achieves nearly 100% unlearning accuracy,\noutperforming current state-of-the-art baselines like Erased Stable Diffusion\nand Forget-Me-Not.",
          "link": "http://arxiv.org/abs/2310.12508",
          "publishedOn": "2023-10-21T00:41:39.790Z",
          "wordCount": 726,
          "title": "SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation. (arXiv:2310.12508v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klu_E/0/1/0/all/0/1\">Emmanuel Klu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethi_S/0/1/0/all/0/1\">Sameer Sethi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passey_D/0/1/0/all/0/1\">DJ Passey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_D/0/1/0/all/0/1\">Donald Martin Jr</a>",
          "description": "Understanding the long-term impact of algorithmic interventions on society is\nvital to achieving responsible AI. Traditional evaluation strategies often fall\nshort due to the complex, adaptive and dynamic nature of society. While\nreinforcement learning (RL) can be a powerful approach for optimizing decisions\nin dynamic settings, the difficulty of realistic environment design remains a\nbarrier to building robust agents that perform well in practical settings. To\naddress this issue we tap into the field of system dynamics (SD) as a\ncomplementary method that incorporates collaborative simulation model\nspecification practices. We introduce SDGym, a low-code library built on the\nOpenAI Gym framework which enables the generation of custom RL environments\nbased on SD simulation models. Through a feasibility study we validate that\nwell specified, rich RL environments can be generated from preexisting SD\nmodels and a few lines of configuration code. We demonstrate the capabilities\nof the SDGym environment using an SD model of the electric vehicle adoption\nproblem. We compare two SD simulators, PySD and BPTK-Py for parity, and train a\nD4PG agent using the Acme framework to showcase learning and environment\ninteraction. Our preliminary findings underscore the dual potential of SD to\nimprove RL environment design and for RL to improve dynamic policy discovery\nwithin SD models. By open-sourcing SDGym, the intent is to galvanize further\nresearch and promote adoption across the SD and RL communities, thereby\ncatalyzing collaboration in this emerging interdisciplinary space.",
          "link": "http://arxiv.org/abs/2310.12494",
          "publishedOn": "2023-10-21T00:41:39.767Z",
          "wordCount": 745,
          "title": "SDGym: Low-Code Reinforcement Learning Environments using System Dynamics Models. (arXiv:2310.12494v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Siddharth Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sating_Z/0/1/0/all/0/1\">Zachary Sating</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatele_A/0/1/0/all/0/1\">Abhinav Bhatele</a>",
          "description": "Despite their better convergence properties compared to first-order\noptimizers, second-order optimizers for deep learning have been less popular\ndue to their significant computational costs. The primary efficiency bottleneck\nin such optimizers is matrix inverse calculations in the preconditioning step,\nwhich are expensive to compute on GPUs. In this paper, we introduce Jorge, a\nsecond-order optimizer that promises the best of both worlds -- rapid\nconvergence benefits of second-order methods, and high computational efficiency\ntypical of first-order methods. We address the primary computational bottleneck\nof computing matrix inverses by completely eliminating them using an\napproximation of the preconditioner computation. This makes Jorge extremely\nefficient on GPUs in terms of wall-clock time. Further, we describe an approach\nto determine Jorge's hyperparameters directly from a well-tuned SGD baseline,\nthereby significantly minimizing tuning efforts. Our empirical evaluations\ndemonstrate the distinct advantages of using Jorge, outperforming\nstate-of-the-art optimizers such as SGD, AdamW, and Shampoo across multiple\ndeep learning models, both in terms of sample efficiency and wall-clock time.",
          "link": "http://arxiv.org/abs/2310.12298",
          "publishedOn": "2023-10-21T00:41:39.761Z",
          "wordCount": 673,
          "title": "Jorge: Approximate Preconditioning for GPU-efficient Second-order Optimization. (arXiv:2310.12298v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhenghao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Quanyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bolei Zhou</a>",
          "description": "Driving safety is a top priority for autonomous vehicles. Orthogonal to prior\nwork handling accident-prone traffic events by algorithm designs at the policy\nlevel, we investigate a Closed-loop Adversarial Training (CAT) framework for\nsafe end-to-end driving in this paper through the lens of environment\naugmentation. CAT aims to continuously improve the safety of driving agents by\ntraining the agent on safety-critical scenarios that are dynamically generated\nover time. A novel resampling technique is developed to turn log-replay\nreal-world driving scenarios into safety-critical ones via probabilistic\nfactorization, where the adversarial traffic generation is modeled as the\nmultiplication of standard motion prediction sub-problems. Consequently, CAT\ncan launch more efficient physical attacks compared to existing safety-critical\nscenario generation methods and yields a significantly less computational cost\nin the iterative learning pipeline. We incorporate CAT into the MetaDrive\nsimulator and validate our approach on hundreds of driving scenarios imported\nfrom real-world driving datasets. Experimental results demonstrate that CAT can\neffectively generate adversarial scenarios countering the agent being trained.\nAfter training, the agent can achieve superior driving safety in both\nlog-replay and safety-critical traffic scenarios on the held-out test set. Code\nand data are available at https://metadriverse.github.io/cat.",
          "link": "http://arxiv.org/abs/2310.12432",
          "publishedOn": "2023-10-21T00:41:39.752Z",
          "wordCount": 715,
          "title": "CAT: Closed-loop Adversarial Training for Safe End-to-End Driving. (arXiv:2310.12432v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.06763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pei_Q/0/1/0/all/0/1\">Qizhi Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_K/0/1/0/all/0/1\">Kaiyuan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lijun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jinhua Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingce Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shufang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1\">Kun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>",
          "description": "Modeling the interaction between proteins and ligands and accurately\npredicting their binding structures is a critical yet challenging task in drug\ndiscovery. Recent advancements in deep learning have shown promise in\naddressing this challenge, with sampling-based and regression-based methods\nemerging as two prominent approaches. However, these methods have notable\nlimitations. Sampling-based methods often suffer from low efficiency due to the\nneed for generating multiple candidate structures for selection. On the other\nhand, regression-based methods offer fast predictions but may experience\ndecreased accuracy. Additionally, the variation in protein sizes often requires\nexternal modules for selecting suitable binding pockets, further impacting\nefficiency. In this work, we propose $\\mathbf{FABind}$, an end-to-end model\nthat combines pocket prediction and docking to achieve accurate and fast\nprotein-ligand binding. $\\mathbf{FABind}$ incorporates a unique ligand-informed\npocket prediction module, which is also leveraged for docking pose estimation.\nThe model further enhances the docking process by incrementally integrating the\npredicted pocket to optimize protein-ligand binding, reducing discrepancies\nbetween training and inference. Through extensive experiments on benchmark\ndatasets, our proposed $\\mathbf{FABind}$ demonstrates strong advantages in\nterms of effectiveness and efficiency compared to existing methods. Our code is\navailable at $\\href{https://github.com/QizhiPei/FABind}{Github}$.",
          "link": "http://arxiv.org/abs/2310.06763",
          "publishedOn": "2023-10-14T00:41:50.946Z",
          "wordCount": 730,
          "title": "FABind: Fast and Accurate Protein-Ligand Binding. (arXiv:2310.06763v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08150",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Steland_A/0/1/0/all/0/1\">Ansgar Steland</a>",
          "description": "Maximum-type statistics of certain functions of the sample covariance matrix\nof high-dimensional vector time series are studied to statistically confirm or\nreject the null hypothesis that a data set has been collected under normal\nconditions. The approach generalizes the case of the maximal deviation of the\nsample autocovariances function from its assumed values. Within a linear time\nseries framework it is shown that Gumbel-type extreme value asymptotics holds\ntrue. As applications we discuss long-only mimimal-variance portfolio\noptimization and subportfolio analysis with respect to idiosyncratic risks, ETF\nindex tracking by sparse tracking portfolios, convolutional deep learners for\nimage analysis and the analysis of array-of-sensors data.",
          "link": "http://arxiv.org/abs/2310.08150",
          "publishedOn": "2023-10-14T00:41:50.938Z",
          "wordCount": 634,
          "title": "On Extreme Value Asymptotics of Projected Sample Covariances in High Dimensions with Applications in Finance and Convolutional Networks. (arXiv:2310.08150v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miller_Z/0/1/0/all/0/1\">Zohair Shafi. Benjamin A. Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1\">Ayan Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1\">Tina Eliassi-Rad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caceres_R/0/1/0/all/0/1\">Rajmonda S. Caceres</a>",
          "description": "Recent advances in machine learning (ML) have shown promise in aiding and\naccelerating classical combinatorial optimization algorithms. ML-based speed\nups that aim to learn in an end to end manner (i.e., directly output the\nsolution) tend to trade off run time with solution quality. Therefore,\nsolutions that are able to accelerate existing solvers while maintaining their\nperformance guarantees, are of great interest. We consider an APX-hard problem,\nwhere an adversary aims to attack shortest paths in a graph by removing the\nminimum number of edges. We propose the GRASP algorithm: Graph Attention\nAccelerated Shortest Path Attack, an ML aided optimization algorithm that\nachieves run times up to 10x faster, while maintaining the quality of solution\ngenerated. GRASP uses a graph attention network to identify a smaller subgraph\ncontaining the combinatorial solution, thus effectively reducing the input\nproblem size. Additionally, we demonstrate how careful representation of the\ninput graph, including node features that correlate well with the optimization\ntask, can highlight important structure in the optimization solution.",
          "link": "http://arxiv.org/abs/2310.07980",
          "publishedOn": "2023-10-14T00:41:50.934Z",
          "wordCount": 676,
          "title": "GRASP: Accelerating Shortest Path Attacks via Graph Attention. (arXiv:2310.07980v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07793",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1\">Ruotong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xu Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yunpu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>",
          "description": "The rapid advancements in large language models (LLMs) have ignited interest\nin the temporal knowledge graph (tKG) domain, where conventional carefully\ndesigned embedding-based and rule-based models dominate. The question remains\nopen of whether pre-trained LLMs can understand structured temporal relational\ndata and replace them as the foundation model for temporal relational\nforecasting. Therefore, we bring temporal knowledge forecasting into the\ngenerative setting. However, challenges occur in the huge chasms between\ncomplex temporal graph data structure and sequential natural expressions LLMs\ncan handle, and between the enormous data sizes of tKGs and heavy computation\ncosts of finetuning LLMs. To address these challenges, we propose a novel\nretrieval augmented generation framework that performs generative forecasting\non tKGs named GenTKG, which combines a temporal logical rule-based retrieval\nstrategy and lightweight parameter-efficient instruction tuning. Extensive\nexperiments have shown that GenTKG outperforms conventional methods of temporal\nrelational forecasting under low computation resources. GenTKG also highlights\nremarkable transferability with exceeding performance on unseen datasets\nwithout re-training. Our work reveals the huge potential of LLMs in the tKG\ndomain and opens a new frontier for generative forecasting on tKGs.",
          "link": "http://arxiv.org/abs/2310.07793",
          "publishedOn": "2023-10-14T00:41:46.981Z",
          "wordCount": 685,
          "title": "GenTKG: Generative Forecasting on Temporal Knowledge Graph. (arXiv:2310.07793v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1\">Fu Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingfu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenkun Wang</a>",
          "description": "Neural combinatorial optimization (NCO) is a promising learning-based\napproach for solving challenging combinatorial optimization problems without\nspecialized algorithm design by experts. However, most constructive NCO methods\ncannot solve problems with large-scale instance sizes, which significantly\ndiminishes their usefulness for real-world applications. In this work, we\npropose a novel Light Encoder and Heavy Decoder (LEHD) model with a strong\ngeneralization ability to address this critical issue. The LEHD model can learn\nto dynamically capture the relationships between all available nodes of varying\nsizes, which is beneficial for model generalization to problems of various\nscales. Moreover, we develop a data-efficient training scheme and a flexible\nsolution construction mechanism for the proposed LEHD model. By training on\nsmall-scale problem instances, the LEHD model can generate nearly optimal\nsolutions for the Travelling Salesman Problem (TSP) and the Capacitated Vehicle\nRouting Problem (CVRP) with up to 1000 nodes, and also generalizes well to\nsolve real-world TSPLib and CVRPLib problems. These results confirm our\nproposed LEHD model can significantly improve the state-of-the-art performance\nfor constructive NCO. The code is available at\nhttps://github.com/CIAM-Group/NCO_code/tree/main/single_objective/LEHD.",
          "link": "http://arxiv.org/abs/2310.07985",
          "publishedOn": "2023-10-14T00:41:46.976Z",
          "wordCount": 707,
          "title": "Neural Combinatorial Optimization with Heavy Decoder: Toward Large Scale Generalization. (arXiv:2310.07985v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.04234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tengfei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dachuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_P/0/1/0/all/0/1\">Peng Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>",
          "description": "Neural operators as novel neural architectures for fast approximating\nsolution operators of partial differential equations (PDEs), have shown\nconsiderable promise for future scientific computing. However, the mainstream\nof training neural operators is still data-driven, which needs an expensive\nground-truth dataset from various sources (e.g., solving PDEs' samples with the\nconventional solvers, real-world experiments) in addition to training stage\ncosts. From a computational perspective, marrying operator learning and\nspecific domain knowledge to solve PDEs is an essential step in reducing\ndataset costs and label-free learning. We propose a novel paradigm that\nprovides a unified framework of training neural operators and solving PDEs with\nthe variational form, which we refer to as the variational operator learning\n(VOL). Ritz and Galerkin approach with finite element discretization are\ndeveloped for VOL to achieve matrix-free approximation of system functional and\nresidual, then direct minimization and iterative update are proposed as two\noptimization strategies for VOL. Various types of experiments based on\nreasonable benchmarks about variable heat source, Darcy flow, and variable\nstiffness elasticity are conducted to demonstrate the effectiveness of VOL.\nWith a label-free training set and a 5-label-only shift set, VOL learns\nsolution operators with its test errors decreasing in a power law with respect\nto the amount of unlabeled data. To the best of the authors' knowledge, this is\nthe first study that integrates the perspectives of the weak form and efficient\niterative methods for solving sparse linear systems into the end-to-end\noperator learning task.",
          "link": "http://arxiv.org/abs/2304.04234",
          "publishedOn": "2023-10-14T00:41:35.486Z",
          "wordCount": 805,
          "title": "Variational operator learning: A unified paradigm marrying training neural operators and solving partial differential equations. (arXiv:2304.04234v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.12233",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Kim_S/0/1/0/all/0/1\">Seonghwan Kim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Woo_J/0/1/0/all/0/1\">Jeheon Woo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kim_W/0/1/0/all/0/1\">Woo Youn Kim</a>",
          "description": "The exploration of transition state (TS) geometries is crucial for\nelucidating chemical reaction mechanisms and modeling their kinetics. Recently,\nmachine learning (ML) models have shown remarkable performance for prediction\nof TS geometries. However, they require 3D conformations of reactants and\nproducts often with their appropriate orientations as input, which demands\nsubstantial efforts and computational cost. Here, we propose a generative\napproach based on the stochastic diffusion method, namely TSDiff, for\nprediction of TS geometries just from 2D molecular graphs. TSDiff outperformed\nthe existing ML models with 3D geometries in terms of both accuracy and\nefficiency. Moreover, it enables to sample various TS conformations, because it\nlearned the distribution of TS geometries for diverse reactions in training.\nThus, TSDiff was able to find more favorable reaction pathways with lower\nbarrier heights than those in the reference database. These results demonstrate\nthat TSDiff shows promising potential for an efficient and reliable TS\nexploration.",
          "link": "http://arxiv.org/abs/2304.12233",
          "publishedOn": "2023-10-14T00:41:35.462Z",
          "wordCount": 691,
          "title": "Diffusion-based Generative AI for Exploring Transition States from 2D Molecular Graphs. (arXiv:2304.12233v3 [physics.chem-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.00457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Puchert_P/0/1/0/all/0/1\">Patrik Puchert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poonam_P/0/1/0/all/0/1\">Poonam Poonam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onzenoodt_C/0/1/0/all/0/1\">Christian van Onzenoodt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1\">Timo Ropinski</a>",
          "description": "Large Language Models (LLMs) have revolutionized natural language processing\nand demonstrated impressive capabilities in various tasks. Unfortunately, they\nare prone to hallucinations, where the model exposes incorrect or false\ninformation in its responses, which renders diligent evaluation approaches\nmandatory. While LLM performance in specific knowledge fields is often\nevaluated based on question and answer (Q&A) datasets, such evaluations usually\nreport only a single accuracy number for the dataset, which often covers an\nentire field. This field-based evaluation, is problematic with respect to\ntransparency and model improvement. A stratified evaluation could instead\nreveal subfields, where hallucinations are more likely to occur and thus help\nto better assess LLMs' risks and guide their further development. To support\nsuch stratified evaluations, we propose LLMMaps as a novel visualization\ntechnique that enables users to evaluate LLMs' performance with respect to Q&A\ndatasets. LLMMaps provide detailed insights into LLMs' knowledge capabilities\nin different subfields, by transforming Q&A datasets as well as LLM responses\ninto an internal knowledge structure. An extension for comparative\nvisualization furthermore, allows for the detailed comparison of multiple LLMs.\nTo assess LLMMaps we use them to conduct a comparative analysis of several\nstate-of-the-art LLMs, such as BLOOM, GPT-2, GPT-3, ChatGPT and LLaMa-13B, as\nwell as two qualitative user evaluations. All necessary source code and data\nfor generating LLMMaps to be used in scientific publications and elsewhere is\navailable on GitHub: https://github.com/viscom-ulm/LLMMaps",
          "link": "http://arxiv.org/abs/2304.00457",
          "publishedOn": "2023-10-14T00:41:35.454Z",
          "wordCount": 780,
          "title": "LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models. (arXiv:2304.00457v3 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.14219",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sousa_M/0/1/0/all/0/1\">Martim Sousa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tome_A/0/1/0/all/0/1\">Ana Maria Tom&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moreira_J/0/1/0/all/0/1\">Jos&#xe9; Moreira</a>",
          "description": "This paper introduces a novel model-agnostic algorithm called adaptive\nensemble batch multi-input multi-output conformalized quantile regression\n(AEnbMIMOCQR} that enables forecasters to generate multi-step ahead prediction\nintervals for a fixed pre-specified miscoverage rate in a distribution-free\nmanner. Our method is grounded on conformal prediction principles, however, it\ndoes not require data splitting and provides close to exact coverage even when\nthe data is not exchangeable. Moreover, the resulting prediction intervals,\nbesides being empirically valid along the forecast horizon, do not neglect\nheteroscedasticity. AEnbMIMOCQR is designed to be robust to distribution\nshifts, which means that its prediction intervals remain reliable over an\nunlimited period of time, without entailing retraining or imposing unrealistic\nstrict assumptions on the data-generating process. Through methodically\nexperimentation, we demonstrate that our approach outperforms other competitive\nmethods on both real-world and synthetic datasets. The code used in the\nexperimental part and a tutorial on how to use AEnbMIMOCQR can be found at the\nfollowing GitHub repository: https://github.com/Quilograma/AEnbMIMOCQR.",
          "link": "http://arxiv.org/abs/2207.14219",
          "publishedOn": "2023-10-14T00:41:35.155Z",
          "wordCount": 757,
          "title": "A general framework for multi-step ahead adaptive conformal heteroscedastic time series forecasting. (arXiv:2207.14219v9 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14133",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dunion_M/0/1/0/all/0/1\">Mhairi Dunion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McInroe_T/0/1/0/all/0/1\">Trevor McInroe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luck_K/0/1/0/all/0/1\">Kevin Sebastian Luck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanna_J/0/1/0/all/0/1\">Josiah P. Hanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>",
          "description": "Reinforcement Learning (RL) environments can produce training data with\nspurious correlations between features due to the amount of training data or\nits limited feature coverage. This can lead to RL agents encoding these\nmisleading correlations in their latent representation, preventing the agent\nfrom generalising if the correlation changes within the environment or when\ndeployed in the real world. Disentangled representations can improve\nrobustness, but existing disentanglement techniques that minimise mutual\ninformation between features require independent features, thus they cannot\ndisentangle correlated features. We propose an auxiliary task for RL algorithms\nthat learns a disentangled representation of high-dimensional observations with\ncorrelated features by minimising the conditional mutual information between\nfeatures in the representation. We demonstrate experimentally, using continuous\ncontrol tasks, that our approach improves generalisation under correlation\nshifts, as well as improving the training performance of RL algorithms in the\npresence of correlated features.",
          "link": "http://arxiv.org/abs/2305.14133",
          "publishedOn": "2023-10-14T00:41:35.128Z",
          "wordCount": 681,
          "title": "Conditional Mutual Information for Disentangled Representations in Reinforcement Learning. (arXiv:2305.14133v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.00848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1\">Nazmus Sakib Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noor_S/0/1/0/all/0/1\">Saad Sakib Noor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikder_A/0/1/0/all/0/1\">Ashraful Islam Shanto Sikder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1\">Abhijit Paul</a>",
          "description": "This paper focuses on enhancing Bengali Document Layout Analysis (DLA) using\nthe YOLOv8 model and innovative post-processing techniques. We tackle\nchallenges unique to the complex Bengali script by employing data augmentation\nfor model robustness. After meticulous validation set evaluation, we fine-tune\nour approach on the complete dataset, leading to a two-stage prediction\nstrategy for accurate element segmentation. Our ensemble model, combined with\npost-processing, outperforms individual base architectures, addressing issues\nidentified in the BaDLAD dataset. By leveraging this approach, we aim to\nadvance Bengali document analysis, contributing to improved OCR and document\ncomprehension and BaDLAD serves as a foundational resource for this endeavor,\naiding future research in the field. Furthermore, our experiments provided key\ninsights to incorporate new strategies into the established solution.",
          "link": "http://arxiv.org/abs/2309.00848",
          "publishedOn": "2023-10-14T00:41:35.116Z",
          "wordCount": null,
          "title": "Bengali Document Layout Analysis -- A YOLOV8 Based Ensembling Approach. (arXiv:2309.00848v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.06970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathys_J/0/1/0/all/0/1\">Jo&#xeb;l Mathys</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grotschla_F/0/1/0/all/0/1\">Florian Gr&#xf6;tschla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadimpalli_K/0/1/0/all/0/1\">Kalyan Varma Nadimpalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1\">Roger Wattenhofer</a>",
          "description": "Graph Neural Networks are a natural fit for learning algorithms. They can\ndirectly represent tasks through an abstract but versatile graph structure and\nhandle inputs of different sizes. This opens up the possibility for scaling and\nextrapolation to larger graphs, one of the most important advantages of an\nalgorithm. However, this raises two core questions i) How can we enable nodes\nto gather the required information in a given graph ($\\textit{information\nexchange}$), even if is far away and ii) How can we design an execution\nframework which enables this information exchange for extrapolation to larger\ngraph sizes ($\\textit{algorithmic alignment for extrapolation}$). We propose a\nnew execution framework that is inspired by the design principles of\ndistributed algorithms: Flood and Echo Net. It propagates messages through the\nentire graph in a wave like activation pattern, which naturally generalizes to\nlarger instances. Through its sparse but parallel activations it is provably\nmore efficient in terms of message complexity. We study the proposed model and\nprovide both empirical evidence and theoretical insights in terms of its\nexpressiveness, efficiency, information exchange and ability to extrapolate.",
          "link": "http://arxiv.org/abs/2310.06970",
          "publishedOn": "2023-10-14T00:41:35.098Z",
          "wordCount": null,
          "title": "Flood and Echo: Algorithmic Alignment of GNNs with Distributed Computing. (arXiv:2310.06970v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Letafati_M/0/1/0/all/0/1\">Mehdi Letafati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1\">Samad Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latva_aho_M/0/1/0/all/0/1\">Matti Latva-aho</a>",
          "description": "Innovative foundation models, such as GPT-3 and stable diffusion models, have\nmade a paradigm shift in the realm of artificial intelligence (AI) towards\ngenerative AI-based systems. In unison, from data communication and networking\nperspective, AI and machine learning (AI/ML) algorithms are envisioned to be\npervasively incorporated into the future generations of wireless communications\nsystems, highlighting the need for novel AI-native solutions for the emergent\ncommunication scenarios. In this article, we outline the applications of\ngenerative AI in wireless communication systems to lay the foundations for\nresearch in this field. Diffusion-based generative models, as the new\nstate-of-the-art paradigm of generative models, are introduced, and their\napplications in wireless communication systems are discussed. Two case studies\nare also presented to showcase how diffusion models can be exploited for the\ndevelopment of resilient AI-native communication systems. Specifically, we\npropose denoising diffusion probabilistic models (DDPM) for a wireless\ncommunication scheme with non-ideal transceivers, where 30% improvement is\nachieved in terms of bit error rate. As the second application, DDPMs are\nemployed at the transmitter to shape the constellation symbols, highlighting a\nrobust out-of-distribution performance. Finally, future directions and open\nissues for the development of generative AI-based wireless systems are\ndiscussed to promote future research endeavors towards wireless generative AI\n(WiGenAI).",
          "link": "http://arxiv.org/abs/2310.07312",
          "publishedOn": "2023-10-14T00:41:35.097Z",
          "wordCount": null,
          "title": "WiGenAI: The Symphony of Wireless and Generative AI via Diffusion Models. (arXiv:2310.07312v2 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19443",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maldonado_S/0/1/0/all/0/1\">Sebasti&#xe1;n Maldonado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vairetti_C/0/1/0/all/0/1\">Carla Vairetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jara_K/0/1/0/all/0/1\">Katherine Jara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carrasco_M/0/1/0/all/0/1\">Miguel Carrasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_J/0/1/0/all/0/1\">Julio L&#xf3;pez</a>",
          "description": "In this paper, we propose a fuzzy adaptive loss function for enhancing deep\nlearning performance in classification tasks. Specifically, we redefine the\ncross-entropy loss to effectively address class-level noise conditions,\nincluding the challenging problem of class imbalance. Our approach introduces\naggregation operators, leveraging the power of fuzzy logic to improve\nclassification accuracy. The rationale behind our proposed method lies in the\niterative up-weighting of class-level components within the loss function,\nfocusing on those with larger errors. To achieve this, we employ the ordered\nweighted average (OWA) operator and combine it with an adaptive scheme for\ngradient-based learning. Through extensive experimentation, our method\noutperforms other commonly used loss functions, such as the standard\ncross-entropy or focal loss, across various binary and multiclass\nclassification tasks. Furthermore, we explore the influence of hyperparameters\nassociated with the OWA operators and present a default configuration that\nperforms well across different experimental settings.",
          "link": "http://arxiv.org/abs/2305.19443",
          "publishedOn": "2023-10-14T00:41:35.090Z",
          "wordCount": 711,
          "title": "OWAdapt: An adaptive loss function for deep learning using OWA operators. (arXiv:2305.19443v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.00767",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Orlichenko_A/0/1/0/all/0/1\">Anton Orlichenko</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Daly_G/0/1/0/all/0/1\">Grant Daly</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhou_Z/0/1/0/all/0/1\">Ziyu Zhou</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_A/0/1/0/all/0/1\">Anqi Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Shen_H/0/1/0/all/0/1\">Hui Shen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deng_H/0/1/0/all/0/1\">Hong-Wen Deng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Ping Wang</a>",
          "description": "Most packages for the analysis of fMRI-based functional connectivity (FC) and\ngenomic data are used with a programming language interface, lacking an\neasy-to-navigate GUI frontend. This exacerbates two problems found in these\ntypes of data: demographic confounds and quality control in the face of high\ndimensionality of features. The reason is that it is too slow and cumbersome to\nuse a programming interface to create all the necessary visualizations required\nto identify all correlations, confounding effects, or quality control problems\nin a dataset. To remedy this situation, we have developed ImageNomer, a data\nvisualization and analysis tool that allows inspection of both subject-level\nand cohort-level demographic, genomic, and imaging features. The software is\nPython-based, runs in a self-contained Docker image, and contains a\nbrowser-based GUI frontend. We demonstrate the usefulness of ImageNomer by\nidentifying an unexpected race confound when predicting achievement scores in\nthe Philadelphia Neurodevelopmental Cohort (PNC) dataset. In the past, many\nstudies have attempted to use FC to identify achievement-related features in\nfMRI. Using ImageNomer, we find a clear potential for confounding effects of\nrace. Using correlation analysis in the ImageNomer software, we show that FCs\ncorrelated with Wide Range Achievement Test (WRAT) score are in fact more\nhighly correlated with race. Investigating further, we find that whereas both\nFC and SNP (genomic) features can account for 10-15\\% of WRAT score variation,\nthis predictive ability disappears when controlling for race. In this work, we\ndemonstrate the advantage of our ImageNomer GUI tool in data exploration and\nconfound detection. Additionally, this work identifies race as a strong\nconfound in FC data and casts doubt on the possibility of finding unbiased\nachievement-related features in fMRI and SNP data of healthy adolescents.",
          "link": "http://arxiv.org/abs/2302.00767",
          "publishedOn": "2023-10-14T00:41:35.084Z",
          "wordCount": null,
          "title": "ImageNomer: description of a functional connectivity and omics analysis tool and case study identifying a race confound. (arXiv:2302.00767v2 [q-bio.PE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.04610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuaiwen Leon Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruft_B/0/1/0/all/0/1\">Bonnie Kruft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Minjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Conglong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shiyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chengming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_M/0/1/0/all/0/1\">Masahiro Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaoxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasley_J/0/1/0/all/0/1\">Jeff Rasley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awan_A/0/1/0/all/0/1\">Ammar Ahmad Awan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmes_C/0/1/0/all/0/1\">Connor Holmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1\">Martin Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_A/0/1/0/all/0/1\">Adam Ghanem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhongzhu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuxiong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luferenko_P/0/1/0/all/0/1\">Pete Luferenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_D/0/1/0/all/0/1\">Divya Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weyn_J/0/1/0/all/0/1\">Jonathan Weyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruixiong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klocek_S/0/1/0/all/0/1\">Sylwester Klocek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vragov_V/0/1/0/all/0/1\">Volodymyr Vragov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AlQuraishi_M/0/1/0/all/0/1\">Mohammed AlQuraishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahdritz_G/0/1/0/all/0/1\">Gustaf Ahdritz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Floristean_C/0/1/0/all/0/1\">Christina Floristean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negri_C/0/1/0/all/0/1\">Cristina Negri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotamarthi_R/0/1/0/all/0/1\">Rao Kotamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishwanath_V/0/1/0/all/0/1\">Venkatram Vishwanath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanathan_A/0/1/0/all/0/1\">Arvind Ramanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foreman_S/0/1/0/all/0/1\">Sam Foreman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hippe_K/0/1/0/all/0/1\">Kyle Hippe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcomano_T/0/1/0/all/0/1\">Troy Arcomano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maulik_R/0/1/0/all/0/1\">Romit Maulik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zvyagin_M/0/1/0/all/0/1\">Maxim Zvyagin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brace_A/0/1/0/all/0/1\">Alexander Brace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohorquez_C/0/1/0/all/0/1\">Cindy Orozco Bohorquez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clyde_A/0/1/0/all/0/1\">Austin Clyde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kale_B/0/1/0/all/0/1\">Bharat Kale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Rivera_D/0/1/0/all/0/1\">Danilo Perez-Rivera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Heng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mann_C/0/1/0/all/0/1\">Carla M. Mann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irvin_M/0/1/0/all/0/1\">Michael Irvin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauloski_J/0/1/0/all/0/1\">J. Gregory Pauloski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ward_L/0/1/0/all/0/1\">Logan Ward</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayot_V/0/1/0/all/0/1\">Valerie Hayot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emani_M/0/1/0/all/0/1\">Murali Emani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Diangen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukla_M/0/1/0/all/0/1\">Maulik Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1\">Ian Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">James J. Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papka_M/0/1/0/all/0/1\">Michael E. Papka</a>, et al. (40 additional authors not shown)",
          "description": "In the upcoming decade, deep learning may revolutionize the natural sciences,\nenhancing our capacity to model and predict natural occurrences. This could\nherald a new era of scientific exploration, bringing significant advancements\nacross sectors from drug development to renewable energy. To answer this call,\nwe present DeepSpeed4Science initiative (deepspeed4science.ai) which aims to\nbuild unique capabilities through AI system technology innovations to help\ndomain experts to unlock today's biggest science mysteries. By leveraging\nDeepSpeed's current technology pillars (training, inference and compression) as\nbase technology enablers, DeepSpeed4Science will create a new set of AI system\ntechnologies tailored for accelerating scientific discoveries by addressing\ntheir unique complexity beyond the common technical approaches used for\naccelerating generic large language models (LLMs). In this paper, we showcase\nthe early progress we made with DeepSpeed4Science in addressing two of the\ncritical system challenges in structural biology research.",
          "link": "http://arxiv.org/abs/2310.04610",
          "publishedOn": "2023-10-14T00:41:35.083Z",
          "wordCount": null,
          "title": "DeepSpeed4Science Initiative: Enabling Large-Scale Scientific Discovery through Sophisticated AI System Technologies. (arXiv:2310.04610v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.05421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1\">Shujian Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_H/0/1/0/all/0/1\">Hao Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpruch_L/0/1/0/all/0/1\">Lukasz Szpruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiese_M/0/1/0/all/0/1\">Magnus Wiese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabate_Vidales_M/0/1/0/all/0/1\">Marc Sabate-Vidales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Baoren Xiao</a>",
          "description": "Generative adversarial networks (GANs) have been extremely successful in\ngenerating samples, from seemingly high dimensional probability measures.\nHowever, these methods struggle to capture the temporal dependence of joint\nprobability distributions induced by time-series data. Furthermore, long\ntime-series data streams hugely increase the dimension of the target space,\nwhich may render generative modelling infeasible. To overcome these challenges,\nmotivated by the autoregressive models in econometric, we are interested in the\nconditional distribution of future time series given the past information. We\npropose the generic conditional Sig-WGAN framework by integrating\nWasserstein-GANs (WGANs) with mathematically principled and efficient path\nfeature extraction called the signature of a path. The signature of a path is a\ngraded sequence of statistics that provides a universal description for a\nstream of data, and its expected value characterises the law of the time-series\nmodel. In particular, we develop the conditional Sig-$W_1$ metric, that\ncaptures the conditional joint law of time series models, and use it as a\ndiscriminator. The signature feature space enables the explicit representation\nof the proposed discriminators which alleviates the need for expensive\ntraining. We validate our method on both synthetic and empirical dataset and\nobserve that our method consistently and significantly outperforms\nstate-of-the-art benchmarks with respect to measures of similarity and\npredictive ability.",
          "link": "http://arxiv.org/abs/2006.05421",
          "publishedOn": "2023-10-14T00:41:35.077Z",
          "wordCount": 761,
          "title": "Conditional Sig-Wasserstein GANs for Time Series Generation. (arXiv:2006.05421v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.14041",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenyuan Liu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Parys_B/0/1/0/all/0/1\">Bart P. G. Van Parys</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lam_H/0/1/0/all/0/1\">Henry Lam</a>",
          "description": "In data-driven optimization, sample average approximation (SAA) is known to\nsuffer from the so-called optimizer's curse that causes an over-optimistic\nevaluation of the solution performance. We argue that a special type of\ndistributionallly robust optimization (DRO) formulation offers theoretical\nadvantages in correcting for this optimizer's curse compared to simple\n``margin'' adjustments to SAA and other DRO approaches: It attains a\nstatistical bound on the out-of-sample performance, for a wide class of\nobjective functions and distributions, that is nearly tightest in terms of\nexponential decay rate. This DRO uses an ambiguity set based on a Kullback\nLeibler (KL) divergence smoothed by the Wasserstein or L\\'evy-Prokhorov (LP)\ndistance via a suitable distance optimization. Computationally, we also show\nthat such a DRO, and its generalized versions using smoothed $f$-divergence,\nare not harder than DRO problems based on $f$-divergence or Wasserstein\ndistances, rendering our DRO formulations both statistically optimal and\ncomputationally viable.",
          "link": "http://arxiv.org/abs/2306.14041",
          "publishedOn": "2023-10-14T00:41:35.072Z",
          "wordCount": 678,
          "title": "Smoothed $f$-Divergence Distributionally Robust Optimization. (arXiv:2306.14041v2 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Ivan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>",
          "description": "What is the relationship between model architecture and the ability to\nperform in-context learning? In this empirical study, we take the first steps\ntowards answering this question. In particular, we evaluate fifteen model\narchitectures across a suite of synthetic in-context learning tasks. The\nselected architectures represent a broad range of paradigms, including\nrecurrent and convolution-based neural networks, transformers, and emerging\nattention alternatives. We discover that all considered architectures can\nperform in-context learning under certain conditions. However, contemporary\narchitectures are found to be the best performing, especially as task\ncomplexity grows. Additionally, our follow-up experiments delve into various\nfactors that influence in-context learning. We observe varied sensitivities\namong architectures with respect to hyperparameter settings. Our study of\ntraining dynamics reveals that certain architectures exhibit a smooth,\nprogressive learning trajectory, while others demonstrate periods of stagnation\nfollowed by abrupt mastery of the task. Finally, and somewhat surprisingly, we\nfind that several emerging attention alternatives are more robust in-context\nlearners than transformers; since such approaches have constant-sized memory\nfootprints at inference time, this result opens the future possibility of\nscaling up in-context learning to vastly larger numbers of in-context examples.",
          "link": "http://arxiv.org/abs/2310.08049",
          "publishedOn": "2023-10-14T00:41:35.066Z",
          "wordCount": null,
          "title": "Exploring the Relationship Between Model Architecture and In-Context Learning Ability. (arXiv:2310.08049v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.04263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cagatan_O/0/1/0/all/0/1\">Omer Veysel Cagatan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akgun_B/0/1/0/all/0/1\">Baris Akgun</a>",
          "description": "This paper introduces BarlowRL, a data-efficient reinforcement learning agent\nthat combines the Barlow Twins self-supervised learning framework with DER\n(Data-Efficient Rainbow) algorithm. BarlowRL outperforms both DER and its\ncontrastive counterpart CURL on the Atari 100k benchmark. BarlowRL avoids\ndimensional collapse by enforcing information spread to the whole space. This\nhelps RL algorithms to utilize uniformly spread state representation that\neventually results in a remarkable performance. The integration of Barlow Twins\nwith DER enhances data efficiency and achieves superior performance in the RL\ntasks. BarlowRL demonstrates the potential of incorporating self-supervised\nlearning techniques to improve RL algorithms.",
          "link": "http://arxiv.org/abs/2308.04263",
          "publishedOn": "2023-10-14T00:41:35.066Z",
          "wordCount": null,
          "title": "BarlowRL: Barlow Twins for Data-Efficient Reinforcement Learning. (arXiv:2308.04263v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.11355",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Agarwal_A/0/1/0/all/0/1\">Anish Agarwal</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Cen_S/0/1/0/all/0/1\">Sarah H. Cen</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Yu_C/0/1/0/all/0/1\">Christina Lee Yu</a>",
          "description": "We propose a generalization of the synthetic controls and synthetic\ninterventions methodology to incorporate network interference. We consider the\nestimation of unit-specific potential outcomes from panel data in the presence\nof spillover across units and unobserved confounding. Key to our approach is a\nnovel latent factor model that takes into account network interference and\ngeneralizes the factor models typically used in panel data settings. We propose\nan estimator, Network Synthetic Interventions (NSI), and show that it\nconsistently estimates the mean outcomes for a unit under an arbitrary set of\ncounterfactual treatments for the network. We further establish that the\nestimator is asymptotically normal. We furnish two validity tests for whether\nthe NSI estimator reliably generalizes to produce accurate counterfactual\nestimates. We provide a novel graph-based experiment design that guarantees the\nNSI estimator produces accurate counterfactual estimates, and also analyze the\nsample complexity of the proposed design. We conclude with simulations that\ncorroborate our theoretical findings.",
          "link": "http://arxiv.org/abs/2210.11355",
          "publishedOn": "2023-10-14T00:41:35.063Z",
          "wordCount": null,
          "title": "Network Synthetic Interventions: A Causal Framework for Panel Data Under Network Interference. (arXiv:2210.11355v2 [econ.EM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.15889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenguan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>",
          "description": "Neural-symbolic computing (NeSy), which pursues the integration of the\nsymbolic and statistical paradigms of cognition, has been an active research\narea of Artificial Intelligence (AI) for many years. As NeSy shows promise of\nreconciling the advantages of reasoning and interpretability of symbolic\nrepresentation and robust learning in neural networks, it may serve as a\ncatalyst for the next generation of AI. In the present paper, we provide a\nsystematic overview of the recent developments and important contributions of\nNeSy research. Firstly, we introduce study history of this area, covering early\nwork and foundations. We further discuss background concepts and identify key\ndriving factors behind the development of NeSy. Afterward, we categorize recent\nlandmark approaches along several main characteristics that underline this\nresearch paradigm, including neural-symbolic integration, knowledge\nrepresentation, knowledge embedding, and functionality. Next, we briefly\ndiscuss the successful application of modern NeSy approaches in several\ndomains. Then, we benchmark several NeSy methods on three representative\napplication tasks. Finally, we identify the open problems together with\npotential future research directions. This survey is expected to help new\nresearchers enter this rapidly evolving field and accelerate the progress\ntowards data-and knowledge-driven AI.",
          "link": "http://arxiv.org/abs/2210.15889",
          "publishedOn": "2023-10-14T00:41:35.063Z",
          "wordCount": 740,
          "title": "Towards Data-and Knowledge-Driven Artificial Intelligence: A Survey on Neuro-Symbolic Computing. (arXiv:2210.15889v4 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelsalam_M/0/1/0/all/0/1\">Mohamed Ashraf Abdelsalam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangrej_S/0/1/0/all/0/1\">Samrudhdhi B. Rangrej</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadji_I/0/1/0/all/0/1\">Isma Hadji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dvornik_N/0/1/0/all/0/1\">Nikita Dvornik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Derpanis_K/0/1/0/all/0/1\">Konstantinos G. Derpanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazly_A/0/1/0/all/0/1\">Afsaneh Fazly</a>",
          "description": "We study the problem of future step anticipation in procedural videos. Given\na video of an ongoing procedural activity, we predict a plausible next\nprocedure step described in rich natural language. While most previous work\nfocus on the problem of data scarcity in procedural video datasets, another\ncore challenge of future anticipation is how to account for multiple plausible\nfuture realizations in natural settings. This problem has been largely\noverlooked in previous work. To address this challenge, we frame future step\nprediction as modelling the distribution of all possible candidates for the\nnext step. Specifically, we design a generative model that takes a series of\nvideo clips as input, and generates multiple plausible and diverse candidates\n(in natural language) for the next step. Following previous work, we side-step\nthe video annotation scarcity by pretraining our model on a large text-based\ncorpus of procedural activities, and then transfer the model to the video\ndomain. Our experiments, both in textual and video domains, show that our model\ncaptures diversity in the next step prediction and generates multiple plausible\nfuture predictions. Moreover, our model establishes new state-of-the-art\nresults on YouCookII, where it outperforms existing baselines on the next step\nanticipation. Finally, we also show that our model can successfully transfer\nfrom text to the video domain zero-shot, ie, without fine-tuning or adaptation,\nand produces good-quality future step predictions from video.",
          "link": "http://arxiv.org/abs/2310.08312",
          "publishedOn": "2023-10-14T00:41:35.056Z",
          "wordCount": null,
          "title": "GePSAn: Generative Procedure Step Anticipation in Cooking Videos. (arXiv:2310.08312v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaoke Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Haizhou Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenshuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siliang Tang</a>",
          "description": "Graph-structured data is ubiquitous in the world which models complex\nrelationships between objects, enabling various Web applications. Daily\ninfluxes of unlabeled graph data on the Web offer immense potential for these\napplications. Graph self-supervised algorithms have achieved significant\nsuccess in acquiring generic knowledge from abundant unlabeled graph data.\nThese pre-trained models can be applied to various downstream Web applications,\nsaving training time and improving downstream (target) performance. However,\ndifferent graphs, even across seemingly similar domains, can differ\nsignificantly in terms of attribute semantics, posing difficulties, if not\ninfeasibility, for transferring the pre-trained models to downstream tasks.\nConcretely speaking, for example, the additional task-specific node information\nin downstream tasks (specificity) is usually deliberately omitted so that the\npre-trained representation (transferability) can be leveraged. The trade-off as\nsuch is termed as \"transferability-specificity dilemma\" in this work. To\naddress this challenge, we introduce an innovative deployment module coined as\nGraphControl, motivated by ControlNet, to realize better graph domain transfer\nlearning. Specifically, by leveraging universal structural pre-trained models\nand GraphControl, we align the input space across various graphs and\nincorporate unique characteristics of target data as conditional inputs. These\nconditions will be progressively integrated into the model during fine-tuning\nor prompt tuning through ControlNet, facilitating personalized deployment.\nExtensive experiments show that our method significantly enhances the\nadaptability of pre-trained models on target attributed datasets, achieving\n1.4-3x performance gain. Furthermore, it outperforms training-from-scratch\nmethods on target data with a comparable margin and exhibits faster\nconvergence.",
          "link": "http://arxiv.org/abs/2310.07365",
          "publishedOn": "2023-10-14T00:41:35.050Z",
          "wordCount": null,
          "title": "GraphControl: Adding Conditional Control to Universal Graph Pre-trained Models for Graph Domain Transfer Learning. (arXiv:2310.07365v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuanlin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yunhao Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhuowen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>",
          "description": "Large vision-language models have achieved outstanding performance, but their\nsize and computational requirements make their deployment on\nresource-constrained devices and time-sensitive tasks impractical. Model\ndistillation, the process of creating smaller, faster models that maintain the\nperformance of larger models, is a promising direction towards the solution.\nThis paper investigates the distillation of visual representations in large\nteacher vision-language models into lightweight student models using a small-\nor mid-scale dataset. Notably, this study focuses on open-vocabulary\nout-of-distribution (OOD) generalization, a challenging problem that has been\noverlooked in previous model distillation literature. We propose two principles\nfrom vision and language modality perspectives to enhance student's OOD\ngeneralization: (1) by better imitating teacher's visual representation space,\nand carefully promoting better coherence in vision-language alignment with the\nteacher; (2) by enriching the teacher's language representations with\ninformative and finegrained semantic attributes to effectively distinguish\nbetween different labels. We propose several metrics and conduct extensive\nexperiments to investigate their techniques. The results demonstrate\nsignificant improvements in zero-shot and few-shot student performance on\nopen-vocabulary out-of-distribution classification, highlighting the\neffectiveness of our proposed approaches. Poster:\nhttps://xuanlinli17.github.io/pdfs/iccv23_large_vlm_distillation_poster.pdf\nCode: https://github.com/xuanlinli17/large_vlm_distillation_ood",
          "link": "http://arxiv.org/abs/2307.03135",
          "publishedOn": "2023-10-14T00:41:35.049Z",
          "wordCount": 738,
          "title": "Distilling Large Vision-Language Model with Out-of-Distribution Generalizability. (arXiv:2307.03135v3 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1\">Weijun Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yingdong Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1\">Chuan Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhao-Heng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "Humans often acquire new skills through observation and imitation. For\nrobotic agents, learning from the plethora of unlabeled video demonstration\ndata available on the Internet necessitates imitating the expert without access\nto its action, presenting a challenge known as Imitation Learning from\nObservations (ILfO). A common approach to tackle ILfO problems is to convert\nthem into inverse reinforcement learning problems, utilizing a proxy reward\ncomputed from the agent's and the expert's observations. Nonetheless, we\nidentify that tasks characterized by a progress dependency property pose\nsignificant challenges for such approaches; in these tasks, the agent needs to\ninitially learn the expert's preceding behaviors before mastering the\nsubsequent ones. Our investigation reveals that the main cause is that the\nreward signals assigned to later steps hinder the learning of initial\nbehaviors. To address this challenge, we present a novel ILfO framework that\nenables the agent to master earlier behaviors before advancing to later ones.\nWe introduce an Automatic Discount Scheduling (ADS) mechanism that adaptively\nalters the discount factor in reinforcement learning during the training phase,\nprioritizing earlier rewards initially and gradually engaging later rewards\nonly when the earlier behaviors have been mastered. Our experiments, conducted\non nine Meta-World tasks, demonstrate that our method significantly outperforms\nstate-of-the-art methods across all tasks, including those that are unsolvable\nby them.",
          "link": "http://arxiv.org/abs/2310.07433",
          "publishedOn": "2023-10-14T00:41:35.044Z",
          "wordCount": null,
          "title": "Imitation Learning from Observation with Automatic Discount Scheduling. (arXiv:2310.07433v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.02285",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Leng_Y/0/1/0/all/0/1\">Yichong Leng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_Z/0/1/0/all/0/1\">Zhifang Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_K/0/1/0/all/0/1\">Kai Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ju_Z/0/1/0/all/0/1\">Zeqian Ju</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yanqing Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yufei Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_D/0/1/0/all/0/1\">Dongchao Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1\">Leying Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_K/0/1/0/all/0/1\">Kaitao Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_L/0/1/0/all/0/1\">Lei He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xiang-Yang Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_S/0/1/0/all/0/1\">Sheng Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>",
          "description": "Speech conveys more information than text, as the same word can be uttered in\nvarious voices to convey diverse information. Compared to traditional\ntext-to-speech (TTS) methods relying on speech prompts (reference speech) for\nvoice variability, using text prompts (descriptions) is more user-friendly\nsince speech prompts can be hard to find or may not exist at all. TTS\napproaches based on the text prompt face two main challenges: 1) the\none-to-many problem, where not all details about voice variability can be\ndescribed in the text prompt, and 2) the limited availability of text prompt\ndatasets, where vendors and large cost of data labeling are required to write\ntext prompts for speech. In this work, we introduce PromptTTS 2 to address\nthese challenges with a variation network to provide variability information of\nvoice not captured by text prompts, and a prompt generation pipeline to utilize\nthe large language models (LLM) to compose high quality text prompts.\nSpecifically, the variation network predicts the representation extracted from\nthe reference speech (which contains full information about voice variability)\nbased on the text prompt representation. For the prompt generation pipeline, it\ngenerates text prompts for speech with a speech language understanding model to\nrecognize voice attributes (e.g., gender, speed) from speech and a large\nlanguage model to formulate text prompts based on the recognition results.\nExperiments on a large-scale (44K hours) speech dataset demonstrate that\ncompared to the previous works, PromptTTS 2 generates voices more consistent\nwith text prompts and supports the sampling of diverse voice variability,\nthereby offering users more choices on voice generation. Additionally, the\nprompt generation pipeline produces high-quality text prompts, eliminating the\nlarge labeling cost. The demo page of PromptTTS 2 is available online.",
          "link": "http://arxiv.org/abs/2309.02285",
          "publishedOn": "2023-10-14T00:41:35.041Z",
          "wordCount": null,
          "title": "PromptTTS 2: Describing and Generating Voices with Text Prompt. (arXiv:2309.02285v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.00177",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Lan_K/0/1/0/all/0/1\">Kai Weixian Lan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gueidon_E/0/1/0/all/0/1\">Elias Gueidon</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kaneda_A/0/1/0/all/0/1\">Ayano Kaneda</a>, <a href=\"http://arxiv.org/find/math/1/au:+Panetta_J/0/1/0/all/0/1\">Julian Panetta</a>, <a href=\"http://arxiv.org/find/math/1/au:+Teran_J/0/1/0/all/0/1\">Joseph Teran</a>",
          "description": "We introduce a neural-preconditioned iterative solver for Poisson equations\nwith mixed boundary conditions. The Poisson equation is ubiquitous in\nscientific computing: it governs a wide array of physical phenomena, arises as\na subproblem in many numerical algorithms, and serves as a model problem for\nthe broader class of elliptic PDEs. The most popular Poisson discretizations\nyield large sparse linear systems. At high resolution, and for\nperformance-critical applications, iterative solvers can be advantageous for\nthese -- but only when paired with powerful preconditioners. The core of our\nsolver is a neural network trained to approximate the inverse of a discrete\nstructured-grid Laplace operator for a domain of arbitrary shape and with mixed\nboundary conditions. The structure of this problem motivates a novel network\narchitecture that we demonstrate is highly effective as a preconditioner even\nfor boundary conditions outside the training set. We show that on challenging\ntest cases arising from an incompressible fluid simulation, our method\noutperforms state-of-the-art solvers like algebraic multigrid as well as some\nrecent neural preconditioners.",
          "link": "http://arxiv.org/abs/2310.00177",
          "publishedOn": "2023-10-14T00:41:35.040Z",
          "wordCount": null,
          "title": "A Neural-preconditioned Poisson Solver for Mixed Dirichlet and Neumann Boundary Conditions. (arXiv:2310.00177v3 [math.NA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.04948",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1\">Furong Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1\">Sercan O Arik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yixiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wen Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "The past decade has witnessed significant advances in time series modeling\nwith deep learning. While achieving state-of-the-art results, the\nbest-performing architectures vary highly across applications and domains.\nMeanwhile, for natural language processing, the Generative Pre-trained\nTransformer (GPT) has demonstrated impressive performance via training one\ngeneral-purpose model across various textual datasets. It is intriguing to\nexplore whether GPT-type architectures can be effective for time series,\ncapturing the intrinsic dynamic attributes and leading to significant accuracy\nimprovements. In this paper, we propose a novel framework, TEMPO, that can\neffectively learn time series representations. We focus on utilizing two\nessential inductive biases of the time series task for pre-trained models: (i)\ndecomposition of the complex interaction between trend, seasonal and residual\ncomponents; and (ii) introducing the selection-based prompts to facilitate\ndistribution adaptation in non-stationary time series. TEMPO expands the\ncapability for dynamically modeling real-world temporal phenomena from data\nwithin diverse domains. Our experiments demonstrate the superior performance of\nTEMPO over state-of-the-art methods on a number of time series benchmark\ndatasets. This performance gain is observed not only in standard supervised\nlearning settings but also in scenarios involving previously unseen datasets as\nwell as in scenarios with multi-modal inputs. This compelling finding\nhighlights TEMPO's potential to constitute a foundational model-building\nframework.",
          "link": "http://arxiv.org/abs/2310.04948",
          "publishedOn": "2023-10-14T00:41:35.040Z",
          "wordCount": null,
          "title": "TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting. (arXiv:2310.04948v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.02286",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zambon_L/0/1/0/all/0/1\">Lorenzo Zambon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Azzimonti_D/0/1/0/all/0/1\">Dario Azzimonti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Corani_G/0/1/0/all/0/1\">Giorgio Corani</a>",
          "description": "Hierarchical time series are common in several applied fields. The forecasts\nfor these time series are required to be coherent, that is, to satisfy the\nconstraints given by the hierarchy. The most popular technique to enforce\ncoherence is called reconciliation, which adjusts the base forecasts computed\nfor each time series. However, recent works on probabilistic reconciliation\npresent several limitations. In this paper, we propose a new approach based on\nconditioning to reconcile any type of forecast distribution. We then introduce\na new algorithm, called Bottom-Up Importance Sampling, to efficiently sample\nfrom the reconciled distribution. It can be used for any base forecast\ndistribution: discrete, continuous, or in the form of samples, providing a\nmajor speedup compared to the current methods. Experiments on several temporal\nhierarchies show a significant improvement over base probabilistic forecasts.",
          "link": "http://arxiv.org/abs/2210.02286",
          "publishedOn": "2023-10-14T00:41:35.038Z",
          "wordCount": 677,
          "title": "Efficient probabilistic reconciliation of forecasts for real-valued and count time series. (arXiv:2210.02286v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.05898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lizhang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kaizhao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>",
          "description": "Lion (Evolved Sign Momentum), a new optimizer discovered through program\nsearch, has shown promising results in training large AI models. It performs\ncomparably or favorably to AdamW but with greater memory efficiency. As we can\nexpect from the results of a random search program, Lion incorporates elements\nfrom several existing algorithms, including signed momentum, decoupled weight\ndecay, Polak, and Nesterov momentum, but does not fit into any existing\ncategory of theoretically grounded optimizers. Thus, even though Lion appears\nto perform well as a general-purpose optimizer for a wide range of tasks, its\ntheoretical basis remains uncertain. This lack of theoretical clarity limits\nopportunities to further enhance and expand Lion's efficacy.\n\nThis work aims to demystify Lion. Based on both continuous-time and\ndiscrete-time analysis, we demonstrate that Lion is a theoretically novel and\nprincipled approach for minimizing a general loss function $f(x)$ while\nenforcing a bound constraint $\\|x\\|_\\infty \\leq 1/\\lambda$. Lion achieves this\nthrough the incorporation of decoupled weight decay, where $\\lambda$ represents\nthe weight decay coefficient. Our analysis is made possible by the development\nof a new Lyapunov function for the Lion updates. It applies to a broader family\nof Lion-$\\kappa$ algorithms, where the $\\text{sign}(\\cdot)$ operator in Lion is\nreplaced by the subgradient of a convex function $\\kappa$, leading to the\nsolution of a general composite optimization problem of $\\min_x f(x) +\n\\kappa^*(x)$. Our findings provide valuable insights into the dynamics of Lion\nand pave the way for further improvements and extensions of Lion-related\nalgorithms.",
          "link": "http://arxiv.org/abs/2310.05898",
          "publishedOn": "2023-10-14T00:41:35.029Z",
          "wordCount": null,
          "title": "Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts. (arXiv:2310.05898v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.05288",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Clark_K/0/1/0/all/0/1\">Katharine M. Clark</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McNicholas_P/0/1/0/all/0/1\">Paul D. McNicholas</a>",
          "description": "Matrix-variate distributions are a recent addition to the model-based\nclustering field, thereby making it possible to analyze data in matrix form\nwith complex structure such as images and time series. Due to its recent\nappearance, there is limited literature on matrix-variate data, with even less\non dealing with outliers in these models. An approach for clustering\nmatrix-variate normal data with outliers is discussed. The approach, which uses\nthe distribution of subset log-likelihoods, extends the OCLUST algorithm to\nmatrix-variate normal data and uses an iterative approach to detect and trim\noutliers.",
          "link": "http://arxiv.org/abs/2310.05288",
          "publishedOn": "2023-10-14T00:41:35.027Z",
          "wordCount": null,
          "title": "Clustering Three-Way Data with Outliers. (arXiv:2310.05288v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zheshun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1\">Dun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>",
          "description": "Federated Learning (FL) has surged in prominence due to its capability of\ncollaborative model training without direct data sharing. However, the vast\ndisparity in local data distributions among clients, often termed the\nnon-Independent Identically Distributed (non-IID) challenge, poses a\nsignificant hurdle to FL's generalization efficacy. The scenario becomes even\nmore complex when not all clients participate in the training process, a common\noccurrence due to unstable network connections or limited computational\ncapacities. This can greatly complicate the assessment of the trained models'\ngeneralization abilities. While a plethora of recent studies has centered on\nthe generalization gap pertaining to unseen data from participating clients\nwith diverse distributions, the divergence between the training distributions\nof participating clients and the testing distributions of non-participating\nones has been largely overlooked. In response, our paper unveils an\ninformation-theoretic generalization framework for FL. Specifically, it\nquantifies generalization errors by evaluating the information entropy of local\ndistributions and discerning discrepancies across these distributions. Inspired\nby our deduced generalization bounds, we introduce a weighted aggregation\napproach and a duo of client selection strategies. These innovations aim to\nbolster FL's generalization prowess by encompassing a more varied set of client\ndata distributions. Our extensive empirical evaluations reaffirm the potency of\nour proposed methods, aligning seamlessly with our theoretical construct.",
          "link": "http://arxiv.org/abs/2310.07171",
          "publishedOn": "2023-10-14T00:41:35.026Z",
          "wordCount": null,
          "title": "Federated Generalization via Information-Theoretic Distribution Diversification. (arXiv:2310.07171v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.06488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianlong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wenhao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1\">Changze Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jianhan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cenyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Muling Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiaoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>",
          "description": "Spiking neural networks (SNNs) have demonstrated the capability to achieve\ncomparable performance to deep neural networks (DNNs) in both visual and\nlinguistic domains while offering the advantages of improved energy efficiency\nand adherence to biological plausibility. However, the extension of such\nsingle-modality SNNs into the realm of multimodal scenarios remains an\nunexplored territory. Drawing inspiration from the concept of contrastive\nlanguage-image pre-training (CLIP), we introduce a novel framework, named\nSpikeCLIP, to address the gap between two modalities within the context of\nspike-based computing through a two-step recipe involving ``Alignment\nPre-training + Dual-Loss Fine-tuning\". Extensive experiments demonstrate that\nSNNs achieve comparable results to their DNN counterparts while significantly\nreducing energy consumption across a variety of datasets commonly used for\nmultimodal model evaluation. Furthermore, SpikeCLIP maintains robust\nperformance in image classification tasks that involve class labels not\npredefined within specific categories.",
          "link": "http://arxiv.org/abs/2310.06488",
          "publishedOn": "2023-10-14T00:41:35.025Z",
          "wordCount": null,
          "title": "SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network. (arXiv:2310.06488v2 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.10404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Konrad_A/0/1/0/all/0/1\">Anna Konrad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_J/0/1/0/all/0/1\">John McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villing_R/0/1/0/all/0/1\">Rudi Villing</a>",
          "description": "We present the Grasp Proposal Network (GP-net), a Convolutional Neural\nNetwork model which can generate 6-DoF grasps from flexible viewpoints, e.g. as\nexperienced by mobile manipulators. To train GP-net, we synthetically generate\na dataset containing depth-images and ground-truth grasp information. In\nreal-world experiments, we use the EGAD evaluation benchmark to evaluate GP-net\nagainst two commonly used algorithms, the Volumetric Grasping Network (VGN) and\nthe Grasp Pose Detection package (GPD), on a PAL TIAGo mobile manipulator. In\ncontrast to the state-of-the-art methods in robotic grasping, GP-net can be\nused for grasping objects from flexible, unknown viewpoints without the need to\ndefine the workspace and achieves a grasp success of 54.4% compared to 51.6%\nfor VGN and 44.2% for GPD. We provide a ROS package along with our code and\npre-trained models at https://aucoroboticsmu.github.io/GP-net/.",
          "link": "http://arxiv.org/abs/2209.10404",
          "publishedOn": "2023-10-14T00:41:35.024Z",
          "wordCount": null,
          "title": "GP-net: Flexible Viewpoint Grasp Proposal. (arXiv:2209.10404v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07807",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kiyamousavi_E/0/1/0/all/0/1\">Ensiye Kiyamousavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraychev_B/0/1/0/all/0/1\">Boris Kraychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koychev_I/0/1/0/all/0/1\">Ivan Koychev</a>",
          "description": "Federated learning (FL) is a decentralized machine learning approach where\nindependent learners process data privately. Its goal is to create a robust and\naccurate model by aggregating and retraining local models over multiple rounds.\nHowever, FL faces challenges regarding data heterogeneity and model aggregation\neffectiveness. In order to simulate real-world data, researchers use methods\nfor data partitioning that transform a dataset designated for centralized\nlearning into a group of sub-datasets suitable for distributed machine learning\nwith different data heterogeneity. In this paper, we study the currently\npopular data partitioning techniques and visualize their main disadvantages:\nthe lack of precision in the data diversity, which leads to unreliable\nheterogeneity indexes, and the inability to incrementally challenge the FL\nalgorithms. To resolve this problem, we propose a method that leverages entropy\nand symmetry to construct 'the most challenging' and controllable data\ndistributions with gradual difficulty. We introduce a metric to measure data\nheterogeneity among the learning agents and a transformation technique that\ndivides any dataset into splits with precise data diversity. Through a\ncomparative study, we demonstrate the superiority of our method over existing\nFL data partitioning approaches, showcasing its potential to challenge model\naggregation algorithms. Experimental results indicate that our approach\ngradually challenges the FL strategies, and the models trained on FedSym\ndistributions are more distinct.",
          "link": "http://arxiv.org/abs/2310.07807",
          "publishedOn": "2023-10-14T00:41:35.022Z",
          "wordCount": null,
          "title": "FedSym: Unleashing the Power of Entropy for Benchmarking the Algorithms for Federated Learning. (arXiv:2310.07807v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.06225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_B/0/1/0/all/0/1\">Bruno Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nunes_L/0/1/0/all/0/1\">Leonardo Nunes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Estevao_R/0/1/0/all/0/1\">Roberto Estev&#xe3;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aski_V/0/1/0/all/0/1\">Vijay Aski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1\">Ranveer Chandra</a>",
          "description": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding across various domains, including healthcare and\nfinance. For some tasks, LLMs achieve similar or better performance than\ntrained human beings, therefore it is reasonable to employ human exams (e.g.,\ncertification tests) to assess the performance of LLMs. We present a\ncomprehensive evaluation of popular LLMs, such as Llama 2 and GPT, on their\nability to answer agriculture-related questions. In our evaluation, we also\nemploy RAG (Retrieval-Augmented Generation) and ER (Ensemble Refinement)\ntechniques, which combine information retrieval, generation capabilities, and\nprompting strategies to improve the LLMs' performance. To demonstrate the\ncapabilities of LLMs, we selected agriculture exams and benchmark datasets from\nthree of the largest agriculture producer countries: Brazil, India, and the\nUSA. Our analysis highlights GPT-4's ability to achieve a passing score on\nexams to earn credits for renewing agronomist certifications, answering 93% of\nthe questions correctly and outperforming earlier general-purpose models, which\nachieved 88% accuracy. On one of our experiments, GPT-4 obtained the highest\nperformance when compared to human subjects. This performance suggests that\nGPT-4 could potentially pass on major graduate education admission tests or\neven earn credits for renewing agronomy certificates. We also explore the\nmodels' capacity to address general agriculture-related questions and generate\ncrop management guidelines for Brazilian and Indian farmers, utilizing robust\ndatasets from the Brazilian Agency of Agriculture (Embrapa) and graduate\nprogram exams from India. The results suggest that GPT-4, ER, and RAG can\ncontribute meaningfully to agricultural education, assessment, and crop\nmanagement practice, offering valuable insights to farmers and agricultural\nprofessionals.",
          "link": "http://arxiv.org/abs/2310.06225",
          "publishedOn": "2023-10-14T00:41:35.020Z",
          "wordCount": null,
          "title": "GPT-4 as an Agronomist Assistant? Answering Agriculture Exams Using Large Language Models. (arXiv:2310.06225v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.06823",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ammar_M/0/1/0/all/0/1\">Mou&#xef;n Ben Ammar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Belkhir_N/0/1/0/all/0/1\">Nacim Belkhir</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Popescu_S/0/1/0/all/0/1\">Sebastian Popescu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Manzanera_A/0/1/0/all/0/1\">Antoine Manzanera</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Franchi_G/0/1/0/all/0/1\">Gianni Franchi</a>",
          "description": "Detecting out-of-distribution (OOD) data is a critical challenge in machine\nlearning due to model overconfidence, often without awareness of their\nepistemological limits. We hypothesize that ``neural collapse'', a phenomenon\naffecting in-distribution data for models trained beyond loss convergence, also\ninfluences OOD data. To benefit from this interplay, we introduce NECO, a novel\npost-hoc method for OOD detection, which leverages the geometric properties of\n``neural collapse'' and of principal component spaces to identify OOD data. Our\nextensive experiments demonstrate that NECO achieves state-of-the-art results\non both small and large-scale OOD detection tasks while exhibiting strong\ngeneralization capabilities across different network architectures.\nFurthermore, we provide a theoretical explanation for the effectiveness of our\nmethod in OOD detection. We plan to release the code after the anonymity\nperiod.",
          "link": "http://arxiv.org/abs/2310.06823",
          "publishedOn": "2023-10-14T00:41:35.019Z",
          "wordCount": null,
          "title": "NECO: NEural Collapse Based Out-of-distribution detection. (arXiv:2310.06823v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.05624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Doyup Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chiheon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1\">Minsu Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wook-Shin Han</a>",
          "description": "Generalizable implicit neural representation (INR) enables a single\ncontinuous function, i.e., a coordinate-based neural network, to represent\nmultiple data instances by modulating its weights or intermediate features\nusing latent codes. However, the expressive power of the state-of-the-art\nmodulation is limited due to its inability to localize and capture fine-grained\ndetails of data entities such as specific pixels and rays. To address this\nissue, we propose a novel framework for generalizable INR that combines a\ntransformer encoder with a locality-aware INR decoder. The transformer encoder\npredicts a set of latent tokens from a data instance to encode local\ninformation into each latent token. The locality-aware INR decoder extracts a\nmodulation vector by selectively aggregating the latent tokens via\ncross-attention for a coordinate input and then predicts the output by\nprogressively decoding with coarse-to-fine modulation through multiple\nfrequency bandwidths. The selective token aggregation and the multi-band\nfeature modulation enable us to learn locality-aware representation in spatial\nand spectral aspects, respectively. Our framework significantly outperforms\nprevious generalizable INRs and validates the usefulness of the locality-aware\nlatents for downstream tasks such as image generation.",
          "link": "http://arxiv.org/abs/2310.05624",
          "publishedOn": "2023-10-14T00:41:35.017Z",
          "wordCount": null,
          "title": "Locality-Aware Generalizable Implicit Neural Representation. (arXiv:2310.05624v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hintersdorf_D/0/1/0/all/0/1\">Dominik Hintersdorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Struppek_L/0/1/0/all/0/1\">Lukas Struppek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neider_D/0/1/0/all/0/1\">Daniel Neider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>",
          "description": "The proliferation of large AI models trained on uncurated, often sensitive\nweb-scraped data has raised significant privacy concerns. One of the concerns\nis that adversaries can extract information about the training data using\nprivacy attacks. Unfortunately, the task of removing specific information from\nthe models without sacrificing performance is not straightforward and has\nproven to be challenging. We propose a rather easy yet effective defense based\non backdoor attacks to remove private information such as names of individuals\nfrom models, and focus in this work on text encoders. Specifically, through\nstrategic insertion of backdoors, we align the embeddings of sensitive phrases\nwith those of neutral terms-\"a person\" instead of the person's name. Our\nempirical results demonstrate the effectiveness of our backdoor-based defense\non CLIP by assessing its performance using a specialized privacy attack for\nzero-shot classifiers. Our approach provides not only a new \"dual-use\"\nperspective on backdoor attacks, but also presents a promising avenue to\nenhance the privacy of individuals within models trained on uncurated\nweb-scraped data.",
          "link": "http://arxiv.org/abs/2310.08320",
          "publishedOn": "2023-10-14T00:41:35.015Z",
          "wordCount": null,
          "title": "Defending Our Privacy With Backdoors. (arXiv:2310.08320v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kai Liu</a>",
          "description": "Sparse logistic regression is for classification and feature selection\nsimultaneously. Although many studies have been done to solve\n$\\ell_1$-regularized logistic regression, there is no equivalently abundant\nwork on solving sparse logistic regression with nonconvex regularization term.\nIn this paper, we propose a unified framework to solve $\\ell_1$-regularized\nlogistic regression, which can be naturally extended to nonconvex\nregularization term, as long as certain requirement is satisfied. In addition,\nwe also utilize a different line search criteria to guarantee monotone\nconvergence for various regularization terms. Empirical experiments on binary\nclassification tasks with real-world datasets demonstrate our proposed\nalgorithms are capable of performing classification and feature selection\neffectively at a lower computational cost.",
          "link": "http://arxiv.org/abs/2309.05925",
          "publishedOn": "2023-10-14T00:41:35.012Z",
          "wordCount": null,
          "title": "On Regularized Sparse Logistic Regression. (arXiv:2309.05925v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08069",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haochen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>",
          "description": "Recently, contrastive learning has become a key component in fine-tuning code\nsearch models for software development efficiency and effectiveness. It pulls\ntogether positive code snippets while pushing negative samples away given\nsearch queries. Among contrastive learning, InfoNCE is the most widely used\nloss function due to its better performance. However, the following problems in\nnegative samples of InfoNCE may deteriorate its representation learning: 1) The\nexistence of false negative samples in large code corpora due to duplications.\n2). The failure to explicitly differentiate between the potential relevance of\nnegative samples. As an example, a bubble sorting algorithm example is less\n``negative'' than a file saving function for the quick sorting algorithm query.\nIn this paper, we tackle the above problems by proposing a simple yet effective\nSoft-InfoNCE loss that inserts weight terms into InfoNCE. In our proposed loss\nfunction, we apply three methods to estimate the weights of negative pairs and\nshow that the vanilla InfoNCE loss is a special case of Soft-InfoNCE.\nTheoretically, we analyze the effects of Soft-InfoNCE on controlling the\ndistribution of learnt code representations and on deducing a more precise\nmutual information estimation. We furthermore discuss the superiority of\nproposed loss functions with other design alternatives. Extensive experiments\ndemonstrate the effectiveness of Soft-InfoNCE and weights estimation methods\nunder state-of-the-art code search models on a large-scale public dataset\nconsisting of six programming languages. Source code is available at\n\\url{https://github.com/Alex-HaochenLi/Soft-InfoNCE}.",
          "link": "http://arxiv.org/abs/2310.08069",
          "publishedOn": "2023-10-14T00:41:35.009Z",
          "wordCount": null,
          "title": "Rethinking Negative Pairs in Code Search. (arXiv:2310.08069v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galliera_R/0/1/0/all/0/1\">Raffaele Galliera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venable_K/0/1/0/all/0/1\">Kristen Brent Venable</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bassani_M/0/1/0/all/0/1\">Matteo Bassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suri_N/0/1/0/all/0/1\">Niranjan Suri</a>",
          "description": "In modern communication systems, efficient and reliable information\ndissemination is crucial for supporting critical operations across domains like\ndisaster response, autonomous vehicles, and sensor networks. This paper\nintroduces a Multi-Agent Reinforcement Learning (MARL) approach as a\nsignificant step forward in achieving more decentralized, efficient, and\ncollaborative solutions. We propose a Partially Observable Stochastic Game\n(POSG) formulation for information dissemination empowering each agent to\ndecide on message forwarding independently, based on their one-hop\nneighborhood. This constitutes a significant paradigm shift from traditional\nheuristics based on Multi-Point Relay (MPR) selection. Our approach harnesses\nGraph Convolutional Reinforcement Learning, employing Graph Attention Networks\n(GAT) with dynamic attention to capture essential network features. We propose\ntwo approaches, L-DGN and HL-DGN, which differ in the information that is\nexchanged among agents. We evaluate the performance of our decentralized\napproaches, by comparing them with a widely-used MPR heuristic, and we show\nthat our trained policies are able to efficiently cover the network while\nbypassing the MPR set selection process. Our approach is a first step toward\nsupporting the resilience of real-world broadcast communication infrastructures\nvia learned, collaborative information dissemination.",
          "link": "http://arxiv.org/abs/2308.16198",
          "publishedOn": "2023-10-14T00:41:35.006Z",
          "wordCount": null,
          "title": "Learning Collaborative Information Dissemination with Graph-based Multi-Agent Reinforcement Learning. (arXiv:2308.16198v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.03807",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fan_X/0/1/0/all/0/1\">Xiaohong Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1\">Yin Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_K/0/1/0/all/0/1\">Ke Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feng_Y/0/1/0/all/0/1\">Yujie Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1\">Jianping Zhang</a>",
          "description": "Proximal gradient-based optimization is one of the most common strategies to\nsolve inverse problem of images, and it is easy to implement. However, these\ntechniques often generate heavy artifacts in image reconstruction. One of the\nmost popular refinement methods is to fine-tune the regularization parameter to\nalleviate such artifacts, but it may not always be sufficient or applicable due\nto increased computational costs. In this work, we propose a deep geometric\nincremental learning framework based on the second Nesterov proximal gradient\noptimization. The proposed end-to-end network not only has the powerful\nlearning ability for high-/low-frequency image features, but also can\ntheoretically guarantee that geometric texture details will be reconstructed\nfrom preliminary linear reconstruction. Furthermore, it can avoid the risk of\nintermediate reconstruction results falling outside the geometric decomposition\ndomains and achieve fast convergence. Our reconstruction framework is\ndecomposed into four modules including general linear reconstruction, cascade\ngeometric incremental restoration, Nesterov acceleration, and post-processing.\nIn the image restoration step, a cascade geometric incremental learning module\nis designed to compensate for missing texture information from different\ngeometric spectral decomposition domains. Inspired by the overlap-tile\nstrategy, we also develop a post-processing module to remove the block effect\nin patch-wise-based natural image reconstruction. All parameters in the\nproposed model are learnable, an adaptive initialization technique of physical\nparameters is also employed to make model flexibility and ensure converging\nsmoothly. We compare the reconstruction performance of the proposed method with\nexisting state-of-the-art methods to demonstrate its superiority. Our source\ncodes are available at https://github.com/fanxiaohong/Nest-DGIL.",
          "link": "http://arxiv.org/abs/2308.03807",
          "publishedOn": "2023-10-14T00:41:34.996Z",
          "wordCount": null,
          "title": "Nest-DGIL: Nesterov-optimized Deep Geometric Incremental Learning for CS Image Reconstruction. (arXiv:2308.03807v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08165",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Morani_K/0/1/0/all/0/1\">Kenan Morani</a>",
          "description": "The accurate and efficient diagnosis of COVID-19 is of paramount importance,\nparticularly in the context of large-scale medical imaging datasets. In this\npreprint paper, we propose a novel approach for COVID-19 diagnosis using CT\nimages that leverages the power of Swin Transformer models, state-of-the-art\nsolutions in computer vision tasks. Our method includes a systematic approach\nfor patient-level predictions, where individual CT slices are classified as\nCOVID-19 or non-COVID, and the patient's overall diagnosis is determined\nthrough majority voting. The application of the Swin Transformer in this\ncontext results in patient-level predictions that demonstrate exceptional\ndiagnostic accuracy. In terms of evaluation metrics, our approach consistently\noutperforms the baseline, as well as numerous competing methods, showcasing its\neffectiveness in COVID-19 diagnosis. The macro F1 score achieved by our model\nexceeds the baseline and offers a robust solution for accurate diagnosis.",
          "link": "http://arxiv.org/abs/2310.08165",
          "publishedOn": "2023-10-14T00:41:34.989Z",
          "wordCount": null,
          "title": "COVID-19 Detection Using Swin Transformer Approach from Computed Tomography Images. (arXiv:2310.08165v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hongling Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_A/0/1/0/all/0/1\">Anke Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Han Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Foundation models (FM) have demonstrated remarkable performance across a wide\nrange of tasks (especially in the fields of natural language processing and\ncomputer vision), primarily attributed to their ability to comprehend\ninstructions and access extensive, high-quality data. This not only showcases\ntheir current effectiveness but also sets a promising trajectory towards the\ndevelopment of artificial general intelligence. Unfortunately, due to multiple\nconstraints, the raw data of the model used for large model training are often\ninaccessible, so the use of end-to-end models for downstream tasks has become a\nnew research trend, which we call Learn From Model (LFM) in this article. LFM\nfocuses on the research, modification, and design of FM based on the model\ninterface, so as to better understand the model structure and weights (in a\nblack box environment), and to generalize the model to downstream tasks. The\nstudy of LFM techniques can be broadly categorized into five major areas: model\ntuning, model distillation, model reuse, meta learning and model editing. Each\ncategory encompasses a repertoire of methods and strategies that aim to enhance\nthe capabilities and performance of FM. This paper gives a comprehensive review\nof the current methods based on FM from the perspective of LFM, in order to\nhelp readers better understand the current research status and ideas. To\nconclude, we summarize the survey by highlighting several critical areas for\nfuture exploration and addressing open issues that require further attention\nfrom the research community. The relevant papers we investigated in this\narticle can be accessed at\n<https://github.com/ruthless-man/Awesome-Learn-from-Model>.",
          "link": "http://arxiv.org/abs/2310.08184",
          "publishedOn": "2023-10-14T00:41:34.986Z",
          "wordCount": null,
          "title": "Learn From Model Beyond Fine-Tuning: A Survey. (arXiv:2310.08184v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08224",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sbailo_L/0/1/0/all/0/1\">Luigi Sbail&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghiringhelli_L/0/1/0/all/0/1\">Luca Ghiringhelli</a>",
          "description": "We observe the emergence of binary encoding within the latent space of\ndeep-neural-network classifiers. Such binary encoding is induced by introducing\na linear penultimate layer, which is equipped during training with a loss\nfunction that grows as $\\exp(\\vec{x}^2)$, where $\\vec{x}$ are the coordinates\nin the latent space. The phenomenon we describe represents a specific instance\nof a well-documented occurrence known as \\textit{neural collapse}, which arises\nin the terminal phase of training and entails the collapse of latent class\nmeans to the vertices of a simplex equiangular tight frame (ETF). We show that\nbinary encoding accelerates convergence toward the simplex ETF and enhances\nclassification accuracy.",
          "link": "http://arxiv.org/abs/2310.08224",
          "publishedOn": "2023-10-14T00:41:34.971Z",
          "wordCount": null,
          "title": "Emergence of Latent Binary Encoding in Deep Neural Network Classifiers. (arXiv:2310.08224v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1\">KaiChieh Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Daniel Huang</a>",
          "description": "We refer to the setting where the (partial) derivatives of a neural network's\n(NN's) predictions with respect to its inputs are used as additional training\nsignal as a derivative-constrained (DC) NN. This situation is common in\nphysics-informed settings in the natural sciences. We propose an integrated\nRELU (IReLU) activation function to improve training of DC NNs. We also\ninvestigate denormalization and label rescaling to help stabilize DC training.\nWe evaluate our methods on physics-informed settings including quantum\nchemistry and Scientific Machine Learning (SciML) tasks. We demonstrate that\nexisting architectures with IReLU activations combined with denormalization and\nlabel rescaling better incorporate training signal provided by derivative\nconstraints.",
          "link": "http://arxiv.org/abs/2310.01649",
          "publishedOn": "2023-10-14T00:41:34.953Z",
          "wordCount": null,
          "title": "On Training Derivative-Constrained Neural Networks. (arXiv:2310.01649v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.06648",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Marion_P/0/1/0/all/0/1\">Pierre Marion</a>",
          "description": "Neural ordinary differential equations (neural ODEs) are a popular family of\ncontinuous-depth deep learning models. In this work, we consider a large family\nof parameterized ODEs with continuous-in-time parameters, which include\ntime-dependent neural ODEs. We derive a generalization bound for this class by\na Lipschitz-based argument. By leveraging the analogy between neural ODEs and\ndeep residual networks, our approach yields in particular a generalization\nbound for a class of deep residual networks. The bound involves the magnitude\nof the difference between successive weight matrices. We illustrate numerically\nhow this quantity affects the generalization capability of neural networks.",
          "link": "http://arxiv.org/abs/2305.06648",
          "publishedOn": "2023-10-14T00:41:34.947Z",
          "wordCount": 616,
          "title": "Generalization bounds for neural ordinary differential equations and deep residual networks. (arXiv:2305.06648v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.04102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jason Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahrzad_H/0/1/0/all/0/1\">Hormoz Shahrzad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1\">Risto Miikkulainen</a>",
          "description": "Many evolutionary algorithms (EAs) take advantage of parallel evaluation of\ncandidates. However, if evaluation times vary significantly, many worker nodes\n(i.e.,\\ compute clients) are idle much of the time, waiting for the next\ngeneration to be created. Evolutionary neural architecture search (ENAS), a\nclass of EAs that optimizes the architecture and hyperparameters of deep neural\nnetworks, is particularly vulnerable to this issue. This paper proposes a\ngeneric asynchronous evaluation strategy (AES) that is then adapted to work\nwith ENAS. AES increases throughput by maintaining a queue of up to $K$\nindividuals ready to be sent to the workers for evaluation and proceeding to\nthe next generation as soon as $M<<K$ individuals have been evaluated. A\nsuitable value for $M$ is determined experimentally, balancing diversity and\nefficiency. To showcase the generality and power of AES, it was first evaluated\nin eight-line sorting network design (a single-population optimization task\nwith limited evaluation-time variability), achieving an over two-fold speedup.\nNext, it was evaluated in 11-bit multiplexer design (a single-population\ndiscovery task with extended variability), where a 14-fold speedup was\nobserved. It was then scaled up to ENAS for image captioning (a\nmulti-population open-ended-optimization task), resulting in an over two-fold\nspeedup. In all problems, a multifold performance improvement was observed,\nsuggesting that AES is a promising method for parallelizing the evolution of\ncomplex systems with long and variable evaluation times, such as those in ENAS.",
          "link": "http://arxiv.org/abs/2308.04102",
          "publishedOn": "2023-10-14T00:41:34.931Z",
          "wordCount": null,
          "title": "Asynchronous Evolution of Deep Neural Network Architectures. (arXiv:2308.04102v2 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_M/0/1/0/all/0/1\">Mingyang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1\">Lucas Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benton_J/0/1/0/all/0/1\">Joe Benton</a>",
          "description": "Recent works have proposed that activations in language models can be\nmodelled as sparse linear combinations of vectors corresponding to features of\ninput text. Under this assumption, these works aimed to reconstruct feature\ndirections using sparse coding. We develop metrics to assess the success of\nthese sparse coding techniques and test the validity of the linearity and\nsparsity assumptions. We show our metrics can predict the level of sparsity on\nsynthetic sparse linear activations, and can distinguish between sparse linear\ndata and several other distributions. We use our metrics to measure levels of\nsparsity in several language models. We find evidence that language model\nactivations can be accurately modelled by sparse linear combinations of\nfeatures, significantly more so than control datasets. We also show that model\nactivations appear to be sparsest in the first and final layers.",
          "link": "http://arxiv.org/abs/2310.07837",
          "publishedOn": "2023-10-14T00:41:34.930Z",
          "wordCount": null,
          "title": "Measuring Feature Sparsity in Language Models. (arXiv:2310.07837v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhengxiang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipani_A/0/1/0/all/0/1\">Aldo Lipani</a>",
          "description": "Prompt tuning (PT), where a small amount of trainable soft (continuous)\nprompt vectors is affixed to the input of language models (LM), has shown\npromising results across various tasks and models for parameter-efficient\nfine-tuning (PEFT). PT stands out from other PEFT approaches because it\nmaintains competitive performance with fewer trainable parameters and does not\ndrastically scale up its parameters as the model size expands. However, PT\nintroduces additional soft prompt tokens, leading to longer input sequences,\nwhich significantly impacts training and inference time and memory usage due to\nthe Transformer's quadratic complexity. Particularly concerning for Large\nLanguage Models (LLMs) that face heavy daily querying. To address this issue,\nwe propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt\ninto a shorter soft prompt and a pair of low-rank matrices that are then\noptimised with two different learning rates. This allows DePT to achieve better\nperformance while saving over 20% memory and time costs compared to vanilla PT\nand its variants, without changing trainable parameter sizes. Through extensive\nexperiments on 23 natural language processing (NLP) and vision-language (VL)\ntasks, we demonstrate that DePT outperforms state-of-the-art PEFT approaches,\nincluding the full fine-tuning baseline in some scenarios. Additionally, we\nempirically show that DEPT grows more efficient as the model size increases.\nOur further study reveals that DePT integrates seamlessly with\nparameter-efficient transfer learning in the few-shot learning setting and\nhighlights its adaptability to various model architectures and sizes.",
          "link": "http://arxiv.org/abs/2309.05173",
          "publishedOn": "2023-10-14T00:41:34.930Z",
          "wordCount": null,
          "title": "DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning. (arXiv:2309.05173v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.00327",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dirksen_S/0/1/0/all/0/1\">Sjoerd Dirksen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Finke_P/0/1/0/all/0/1\">Patrick Finke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Genzel_M/0/1/0/all/0/1\">Martin Genzel</a>",
          "description": "In practice, deep neural networks are often able to easily interpolate their\ntraining data. To understand this phenomenon, many works have aimed to quantify\nthe memorization capacity of a neural network architecture: the largest number\nof points such that the architecture can interpolate any placement of these\npoints with any assignment of labels. For real-world data, however, one\nintuitively expects the presence of a benign structure so that interpolation\nalready occurs at a smaller network size than suggested by memorization\ncapacity. In this paper, we investigate interpolation by adopting an\ninstance-specific viewpoint. We introduce a simple randomized algorithm that,\ngiven a fixed finite dataset with two classes, with high probability constructs\nan interpolating three-layer neural network in polynomial time. The required\nnumber of parameters is linked to geometric properties of the two classes and\ntheir mutual arrangement. As a result, we obtain guarantees that are\nindependent of the number of samples and hence move beyond worst-case\nmemorization capacity bounds. We illustrate the effectiveness of the algorithm\nin non-pathological situations with extensive numerical experiments and link\nthe insights back to the theoretical results.",
          "link": "http://arxiv.org/abs/2310.00327",
          "publishedOn": "2023-10-14T00:41:34.924Z",
          "wordCount": null,
          "title": "Memorization with neural nets: going beyond the worst case. (arXiv:2310.00327v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Ze Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1\">Lei Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yinghuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "A recent empirical observation (Li et al., 2022b) of activation sparsity in\nMLP blocks offers an opportunity to drastically reduce computation costs for\nfree. Although having attributed it to training dynamics, existing theoretical\nexplanations of activation sparsity are restricted to shallow networks, small\ntraining steps and special training, despite its emergence in deep models\nstandardly trained for a large number of steps. To fill these gaps, we propose\nthe notion of gradient sparsity as one source of activation sparsity and a\ntheoretical explanation based on it that sees sparsity a necessary step to\nadversarial robustness w.r.t. hidden features and parameters, which is\napproximately the flatness of minima for well-learned models. The theory\napplies to standardly trained LayerNorm-ed MLPs, and further to Transformers or\nother architectures trained with weight noises. Eliminating other sources of\nflatness except for sparsity, we discover the phenomenon that the ratio between\nthe largest and smallest non-zero singular values of weight matrices is small.\nWhen discussing the emergence of this spectral concentration, we use random\nmatrix theory (RMT) as a powerful tool to analyze stochastic gradient noises.\nValidational experiments are conducted to verify our gradient-sparsity-based\nexplanation. We propose two plug-and-play modules for both training and\nfinetuning for sparsity. Experiments on ImageNet-1k and C4 demonstrate their\n50% sparsity improvements, indicating further potential cost reduction in both\ntraining and inference.",
          "link": "http://arxiv.org/abs/2309.03004",
          "publishedOn": "2023-10-14T00:41:34.918Z",
          "wordCount": null,
          "title": "A Theoretical Explanation of Activation Sparsity through Flat Minima and Adversarial Robustness. (arXiv:2309.03004v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07987",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wensheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yuna Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lixin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_T/0/1/0/all/0/1\">Tad Matsumoto</a>",
          "description": "This letter proposes a novel relaying framework, semantic-forward (SF), for\ncooperative communications towards the sixth-generation (6G) wireless networks.\nThe SF relay extracts and transmits the semantic features, which reduces\nforwarding payload, and also improves the network robustness against intra-link\nerrors. Based on the theoretical basis for cooperative communications with side\ninformation and the turbo principle, we design a joint source-channel coding\nalgorithm to iteratively exchange the extrinsic information for enhancing the\ndecoding gains at the destination. Surprisingly, simulation results indicate\nthat even in bad channel conditions, SF relaying can still effectively improve\nthe recovered information quality.",
          "link": "http://arxiv.org/abs/2310.07987",
          "publishedOn": "2023-10-14T00:41:34.917Z",
          "wordCount": null,
          "title": "Semantic-Forward Relaying: A Novel Framework Towards 6G Cooperative Communications. (arXiv:2310.07987v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.15363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xutan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jingfeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevenson_M/0/1/0/all/0/1\">Mark Stevenson</a>",
          "description": "Although it has been demonstrated that Natural Language Processing (NLP)\nalgorithms are vulnerable to deliberate attacks, the question of whether such\nweaknesses can lead to software security threats is under-explored. To bridge\nthis gap, we conducted vulnerability tests on Text-to-SQL systems that are\ncommonly used to create natural language interfaces to databases. We showed\nthat the Text-to-SQL modules within six commercial applications can be\nmanipulated to produce malicious code, potentially leading to data breaches and\nDenial of Service attacks. This is the first demonstration that NLP models can\nbe exploited as attack vectors in the wild. In addition, experiments using four\nopen-source language models verified that straightforward backdoor attacks on\nText-to-SQL systems achieve a 100% success rate without affecting their\nperformance. The aim of this work is to draw the community's attention to\npotential software security issues associated with NLP algorithms and encourage\nexploration of methods to mitigate against them.",
          "link": "http://arxiv.org/abs/2211.15363",
          "publishedOn": "2023-10-14T00:41:34.914Z",
          "wordCount": null,
          "title": "On the Security Vulnerabilities of Text-to-SQL Models. (arXiv:2211.15363v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingyun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>",
          "description": "Literature-Based Discovery (LBD) aims to discover new scientific knowledge by\nmining papers and generating hypotheses. Standard LBD is limited to predicting\npairwise relations between discrete concepts (e.g., drug-disease links), and\nignores critical contexts like experimental settings (e.g., a specific patient\npopulation where a drug is evaluated) and background motivations (e.g., to find\ndrugs without specific side effects). We address these limitations with a novel\nformulation of contextualized-LBD (C-LBD): generating scientific hypotheses in\nnatural language, while grounding them in a context that controls the\nhypothesis search space. We present a modeling framework using retrieval of\n``inspirations'' from past scientific papers. Our evaluations reveal that GPT-4\ntends to generate ideas with overall low technical depth and novelty, while our\ninspiration prompting approaches partially mitigate this issue. Our work\nrepresents a first step toward building language models that generate new ideas\nderived from scientific literature.",
          "link": "http://arxiv.org/abs/2305.14259",
          "publishedOn": "2023-10-14T00:41:34.913Z",
          "wordCount": 693,
          "title": "Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery. (arXiv:2305.14259v3 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frati_L/0/1/0/all/0/1\">Lapo Frati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Traft_N/0/1/0/all/0/1\">Neil Traft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1\">Jeff Clune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheney_N/0/1/0/all/0/1\">Nick Cheney</a>",
          "description": "This work identifies a simple pre-training mechanism that leads to\nrepresentations exhibiting better continual and transfer learning. This\nmechanism -- the repeated resetting of weights in the last layer, which we\nnickname \"zapping\" -- was originally designed for a meta-continual-learning\nprocedure, yet we show it is surprisingly applicable in many settings beyond\nboth meta-learning and continual learning. In our experiments, we wish to\ntransfer a pre-trained image classifier to a new set of classes, in a few\nshots. We show that our zapping procedure results in improved transfer accuracy\nand/or more rapid adaptation in both standard fine-tuning and continual\nlearning settings, while being simple to implement and computationally\nefficient. In many cases, we achieve performance on par with state of the art\nmeta-learning without needing the expensive higher-order gradients, by using a\ncombination of zapping and sequential learning. An intuitive explanation for\nthe effectiveness of this zapping procedure is that representations trained\nwith repeated zapping learn features that are capable of rapidly adapting to\nnewly initialized classifiers. Such an approach may be considered a\ncomputationally cheaper type of, or alternative to, meta-learning rapidly\nadaptable features with higher-order gradients. This adds to recent work on the\nusefulness of resetting neural network parameters during training, and invites\nfurther investigation of this mechanism.",
          "link": "http://arxiv.org/abs/2310.07996",
          "publishedOn": "2023-10-14T00:41:34.903Z",
          "wordCount": null,
          "title": "Reset It and Forget It: Relearning Last-Layer Weights Improves Continual and Transfer Learning. (arXiv:2310.07996v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mentzer_F/0/1/0/all/0/1\">Fabian Mentzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minnen_D/0/1/0/all/0/1\">David Minnen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agustsson_E/0/1/0/all/0/1\">Eirikur Agustsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tschannen_M/0/1/0/all/0/1\">Michael Tschannen</a>",
          "description": "We propose to replace vector quantization (VQ) in the latent representation\nof VQ-VAEs with a simple scheme termed finite scalar quantization (FSQ), where\nwe project the VAE representation down to a few dimensions (typically less than\n10). Each dimension is quantized to a small set of fixed values, leading to an\n(implicit) codebook given by the product of these sets. By appropriately\nchoosing the number of dimensions and values each dimension can take, we obtain\nthe same codebook size as in VQ. On top of such discrete representations, we\ncan train the same models that have been trained on VQ-VAE representations. For\nexample, autoregressive and masked transformer models for image generation,\nmultimodal generation, and dense prediction computer vision tasks. Concretely,\nwe employ FSQ with MaskGIT for image generation, and with UViM for depth\nestimation, colorization, and panoptic segmentation. Despite the much simpler\ndesign of FSQ, we obtain competitive performance in all these tasks. We\nemphasize that FSQ does not suffer from codebook collapse and does not need the\ncomplex machinery employed in VQ (commitment losses, codebook reseeding, code\nsplitting, entropy penalties, etc.) to learn expressive discrete\nrepresentations.",
          "link": "http://arxiv.org/abs/2309.15505",
          "publishedOn": "2023-10-14T00:41:34.902Z",
          "wordCount": null,
          "title": "Finite Scalar Quantization: VQ-VAE Made Simple. (arXiv:2309.15505v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08337",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bartosh_G/0/1/0/all/0/1\">Grigory Bartosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naesseth_C/0/1/0/all/0/1\">Christian A. Naesseth</a>",
          "description": "Diffusion models have shown remarkable performance on many generative tasks.\nDespite recent success, most diffusion models are restricted in that they only\nallow linear transformation of the data distribution. In contrast, broader\nfamily of transformations can potentially help train generative distributions\nmore efficiently, simplifying the reverse process and closing the gap between\nthe true negative log-likelihood and the variational approximation. In this\npaper, we present Neural Diffusion Models (NDMs), a generalization of\nconventional diffusion models that enables defining and learning time-dependent\nnon-linear transformations of data. We show how to optimise NDMs using a\nvariational bound in a simulation-free setting. Moreover, we derive a\ntime-continuous formulation of NDMs, which allows fast and reliable inference\nusing off-the-shelf numerical ODE and SDE solvers. Finally, we demonstrate the\nutility of NDMs with learnable transformations through experiments on standard\nimage generation benchmarks, including CIFAR-10, downsampled versions of\nImageNet and CelebA-HQ. NDMs outperform conventional diffusion models in terms\nof likelihood and produce high-quality samples.",
          "link": "http://arxiv.org/abs/2310.08337",
          "publishedOn": "2023-10-14T00:41:34.899Z",
          "wordCount": null,
          "title": "Neural Diffusion Models. (arXiv:2310.08337v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Ju Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_T/0/1/0/all/0/1\">Ting Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hei_F/0/1/0/all/0/1\">Falun Hei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zhemei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yunfeng Luo</a>",
          "description": "Counterfactual Regret Minimization (CFR) and its variants are the best\nalgorithms so far for solving large-scale incomplete information games.\nHowever, we believe that there are two problems with CFR: First, matrix\nmultiplication is required in CFR iteration, and the time complexity of one\niteration is too high; Secondly, the game characteristics in the real world are\ndifferent. Just using one CFR algorithm will not be perfectly suitable for all\ngame problems.\n\nFor these two problems, this paper proposes a new algorithm called Pure CFR\n(PCFR) based on CFR. PCFR can be seen as a combination of CFR and Fictitious\nPlay (FP), inheriting the concept of counterfactual regret (value) from CFR,\nand using the best response strategy instead of the regret matching strategy\nfor the next iteration. This algorithm has three advantages. First, PCFR can be\ncombined with any CFR variant. The resulting Pure MCCFR (PMCCFR) can\nsignificantly reduce the time and space complexity of one iteration. Secondly,\nour experiments show that the convergence speed of the PMCCFR is 2$\\sim$3 times\nthat of the MCCFR. Finally, there is a type of game that is very suitable for\nPCFR, we call this type of game clear-game, which is characterized by a high\nproportion of dominated strategies. Experiments show that in clear-game, the\nconvergence rate of PMCCFR is two orders of magnitude higher than that of\nMCCFR.",
          "link": "http://arxiv.org/abs/2309.03084",
          "publishedOn": "2023-10-14T00:41:34.897Z",
          "wordCount": null,
          "title": "Pure Monte Carlo Counterfactual Regret Minimization. (arXiv:2309.03084v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08087",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Barbieri_L/0/1/0/all/0/1\">Luca Barbieri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Savazzi_S/0/1/0/all/0/1\">Stefano Savazzi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kianoush_S/0/1/0/all/0/1\">Sanaz Kianoush</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nicoli_M/0/1/0/all/0/1\">Monica Nicoli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Serio_L/0/1/0/all/0/1\">Luigi Serio</a>",
          "description": "Federated Learning (FL) methods adopt efficient communication technologies to\ndistribute machine learning tasks across edge devices, reducing the overhead in\nterms of data storage and computational complexity compared to centralized\nsolutions. Rather than moving large data volumes from producers (sensors,\nmachines) to energy-hungry data centers, raising environmental concerns due to\nresource demands, FL provides an alternative solution to mitigate the energy\ndemands of several learning tasks while enabling new Artificial Intelligence of\nThings (AIoT) applications. This paper proposes a framework for real-time\nmonitoring of the energy and carbon footprint impacts of FL systems. The carbon\ntracking tool is evaluated for consensus (fully decentralized) and classical FL\npolicies. For the first time, we present a quantitative evaluation of different\ncomputationally and communication efficient FL methods from the perspectives of\nenergy consumption and carbon equivalent emissions, suggesting also general\nguidelines for energy-efficient design. Results indicate that consensus-driven\nFL implementations should be preferred for limiting carbon emissions when the\nenergy efficiency of the communication is low (i.e., < 25 Kbit/Joule). Besides,\nquantization and sparsification operations are shown to strike a balance\nbetween learning performances and energy consumption, leading to sustainable FL\ndesigns.",
          "link": "http://arxiv.org/abs/2310.08087",
          "publishedOn": "2023-10-14T00:41:34.881Z",
          "wordCount": null,
          "title": "A Carbon Tracking Model for Federated Learning: Impact of Quantization and Sparsification. (arXiv:2310.08087v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Palmer_G/0/1/0/all/0/1\">Gregory Palmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parry_C/0/1/0/all/0/1\">Chris Parry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harrold_D/0/1/0/all/0/1\">Daniel J.B. Harrold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willis_C/0/1/0/all/0/1\">Chris Willis</a>",
          "description": "The rapid increase in the number of cyber-attacks in recent years raises the\nneed for principled methods for defending networks against malicious actors.\nDeep reinforcement learning (DRL) has emerged as a promising approach for\nmitigating these attacks. However, while DRL has shown much potential for\ncyber-defence, numerous challenges must be overcome before DRL can be applied\nto autonomous cyber-operations (ACO) at scale. Principled methods are required\nfor environments that confront learners with very high-dimensional state\nspaces, large multi-discrete action spaces, and adversarial learning. Recent\nworks have reported success in solving these problems individually. There have\nalso been impressive engineering efforts towards solving all three for\nreal-time strategy games. However, applying DRL to the full ACO problem remains\nan open challenge. Here, we survey the relevant DRL literature and\nconceptualize an idealised ACO-DRL agent. We provide: i.) A summary of the\ndomain properties that define the ACO problem; ii.) A comprehensive evaluation\nof the extent to which domains used for benchmarking DRL approaches are\ncomparable to ACO; iii.) An overview of state-of-the-art approaches for scaling\nDRL to domains that confront learners with the curse of dimensionality, and;\niv.) A survey and critique of current methods for limiting the exploitability\nof agents within adversarial settings from the perspective of ACO. We conclude\nwith open research questions that we hope will motivate future directions for\nresearchers and practitioners working on ACO.",
          "link": "http://arxiv.org/abs/2310.07745",
          "publishedOn": "2023-10-14T00:41:34.879Z",
          "wordCount": null,
          "title": "Deep Reinforcement Learning for Autonomous Cyber Operations: A Survey. (arXiv:2310.07745v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qingyue Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Banghua Zhu</a>",
          "description": "We characterize the statistical efficiency of knowledge transfer through $n$\nsamples from a teacher to a probabilistic student classifier with input space\n$\\mathcal S$ over labels $\\mathcal A$. We show that privileged information at\nthree progressive levels accelerates the transfer. At the first level, only\nsamples with hard labels are known, via which the maximum likelihood estimator\nattains the minimax rate $\\sqrt{{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. The\nsecond level has the teacher probabilities of sampled labels available in\naddition, which turns out to boost the convergence rate lower bound to\n${{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. However, under this second data\nacquisition protocol, minimizing a naive adaptation of the cross-entropy loss\nresults in an asymptotically biased student. We overcome this limitation and\nachieve the fundamental limit by using a novel empirical variant of the squared\nerror logit loss. The third level further equips the student with the soft\nlabels (complete logits) on ${\\mathcal A}$ given every sampled input, thereby\nprovably enables the student to enjoy a rate ${|{\\mathcal S}|}/{n}$ free of\n$|{\\mathcal A}|$. We find any Kullback-Leibler divergence minimizer to be\noptimal in the last case. Numerical simulations distinguish the four learners\nand corroborate our theory.",
          "link": "http://arxiv.org/abs/2310.07838",
          "publishedOn": "2023-10-14T00:41:34.876Z",
          "wordCount": null,
          "title": "Towards the Fundamental Limits of Knowledge Transfer over Finite Domains. (arXiv:2310.07838v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03486",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Seungyong Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeom_J/0/1/0/all/0/1\">Junyoung Yeom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1\">Bumsoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hyun Oh Song</a>",
          "description": "Discovering achievements with a hierarchical structure in procedurally\ngenerated environments presents a significant challenge. This requires an agent\nto possess a broad range of abilities, including generalization and long-term\nreasoning. Many prior methods have been built upon model-based or hierarchical\napproaches, with the belief that an explicit module for long-term planning\nwould be advantageous for learning hierarchical dependencies. However, these\nmethods demand an excessive number of environment interactions or large model\nsizes, limiting their practicality. In this work, we demonstrate that proximal\npolicy optimization (PPO), a simple yet versatile model-free algorithm,\noutperforms previous methods when optimized with recent implementation\npractices. Moreover, we find that the PPO agent can predict the next\nachievement to be unlocked to some extent, albeit with limited confidence.\nBased on this observation, we introduce a novel contrastive learning method,\ncalled achievement distillation, which strengthens the agent's ability to\npredict the next achievement. Our method exhibits a strong capacity for\ndiscovering hierarchical achievements and shows state-of-the-art performance on\nthe challenging Crafter environment in a sample-efficient manner while\nutilizing fewer model parameters.",
          "link": "http://arxiv.org/abs/2307.03486",
          "publishedOn": "2023-10-14T00:41:34.876Z",
          "wordCount": null,
          "title": "Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning. (arXiv:2307.03486v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08209",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cholaquidis_A/0/1/0/all/0/1\">Alejandro Cholaquidis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gamboa_F/0/1/0/all/0/1\">Fabrice Gamboa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moreno_L/0/1/0/all/0/1\">Leonardo Moreno</a>",
          "description": "Regression on manifolds, and, more broadly, statistics on manifolds, has\ngarnered significant importance in recent years due to the vast number of\napplications for this type of data. Circular data is a classic example, but so\nis data in the space of covariance matrices, data on the Grassmannian manifold\nobtained as a result of principal component analysis, among many others. In\nthis work we investigate prediction sets for regression scenarios when the\nresponse variable, denoted by $Y$, resides in a manifold, and the covariable,\ndenoted by X, lies in Euclidean space. This extends the concepts delineated in\n[Lei and Wasserman, 2014] to this novel context. Aligning with traditional\nprinciples in conformal inference, these prediction sets are distribution-free,\nindicating that no specific assumptions are imposed on the joint distribution\nof $(X, Y)$, and they maintain a non-parametric character. We prove the\nasymptotic almost sure convergence of the empirical version of these regions on\nthe manifold to their population counterparts. The efficiency of this method is\nshown through a comprehensive simulation study and an analysis involving\nreal-world data.",
          "link": "http://arxiv.org/abs/2310.08209",
          "publishedOn": "2023-10-14T00:41:34.874Z",
          "wordCount": null,
          "title": "Conformal inference for regression on Riemannian Manifolds. (arXiv:2310.08209v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.04413",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_Z/0/1/0/all/0/1\">Zhang-Wei Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Aviral Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnik_S/0/1/0/all/0/1\">Sathwik Karnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhandwaldar_A/0/1/0/all/0/1\">Abhishek Bhandwaldar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1\">Akash Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1\">Joni Pajarinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laroche_R/0/1/0/all/0/1\">Romain Laroche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhishek Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Pulkit Agrawal</a>",
          "description": "Offline policy learning is aimed at learning decision-making policies using\nexisting datasets of trajectories without collecting additional data. The\nprimary motivation for using reinforcement learning (RL) instead of supervised\nlearning techniques such as behavior cloning is to find a policy that achieves\na higher average return than the trajectories constituting the dataset.\nHowever, we empirically find that when a dataset is dominated by suboptimal\ntrajectories, state-of-the-art offline RL algorithms do not substantially\nimprove over the average return of trajectories in the dataset. We argue this\nis due to an assumption made by current offline RL algorithms of staying close\nto the trajectories in the dataset. If the dataset primarily consists of\nsub-optimal trajectories, this assumption forces the policy to mimic the\nsuboptimal actions. We overcome this issue by proposing a sampling strategy\nthat enables the policy to only be constrained to ``good data\" rather than all\nactions in the dataset (i.e., uniform sampling). We present a realization of\nthe sampling strategy and an algorithm that can be used as a plug-and-play\nmodule in standard offline RL algorithms. Our evaluation demonstrates\nsignificant performance gains in 72 imbalanced datasets, D4RL dataset, and\nacross three different offline RL algorithms. Code is available at\nhttps://github.com/Improbable-AI/dw-offline-rl.",
          "link": "http://arxiv.org/abs/2310.04413",
          "publishedOn": "2023-10-14T00:41:34.867Z",
          "wordCount": null,
          "title": "Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets. (arXiv:2310.04413v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.03770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hanlin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy Zhang</a>",
          "description": "Goal-conditioned reinforcement learning (GCRL) refers to learning\ngeneral-purpose skills that aim to reach diverse goals. In particular, offline\nGCRL only requires purely pre-collected datasets to perform training tasks\nwithout additional interactions with the environment. Although offline GCRL has\nbecome increasingly prevalent and many previous works have demonstrated its\nempirical success, the theoretical understanding of efficient offline GCRL\nalgorithms is not well established, especially when the state space is huge and\nthe offline dataset only covers the policy we aim to learn. In this paper, we\nprovide a rigorous theoretical analysis of an existing empirically successful\noffline GCRL algorithm. We prove that under slight modification, this algorithm\nenjoys an $\\widetilde{O}(\\text{poly}(1/\\epsilon))$ sample complexity (where\n$\\epsilon$ is the desired suboptimality of the learned policy) with general\nfunction approximation thanks to the property of (semi-)strong convexity of the\nobjective functions. We only require nearly minimal assumptions on the dataset\n(single-policy concentrability) and the function class (realizability).\nMoreover, this algorithm consists of two uninterleaved optimization steps,\nwhich we refer to as $V$-learning and policy learning, and is computationally\nstable since it does not involve minimax optimization. We also empirically\nvalidate our theory by showing that the modified algorithm outperforms the\nprevious algorithm in various real-world environments. To the best of our\nknowledge, this is the first algorithm that is both provably efficient with\ngeneral function approximation and single-policy concentrability, and\nempirically successful without requiring solving minimax optimization problems.",
          "link": "http://arxiv.org/abs/2302.03770",
          "publishedOn": "2023-10-14T00:41:34.866Z",
          "wordCount": 778,
          "title": "Provably Efficient Offline Goal-Conditioned Reinforcement Learning with General Function Approximation and Single-Policy Concentrability. (arXiv:2302.03770v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.12461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamparth_M/0/1/0/all/0/1\">Max Lamparth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reuel_A/0/1/0/all/0/1\">Anka Reuel</a>",
          "description": "Poisoning of data sets is a potential security threat to large language\nmodels that can lead to backdoored models. A description of the internal\nmechanisms of backdoored language models and how they process trigger inputs,\ne.g., when switching to toxic language, has yet to be found. In this work, we\nstudy the internal representations of transformer-based backdoored language\nmodels and determine early-layer MLP modules as most important for the backdoor\nmechanism in combination with the initial embedding projection. We use this\nknowledge to remove, insert, and modify backdoor mechanisms with engineered\nreplacements that reduce the MLP module outputs to essentials for the backdoor\nmechanism. To this end, we introduce PCP ablation, where we replace transformer\nmodules with low-rank matrices based on the principal components of their\nactivations. We demonstrate our results on backdoored toy, backdoored large,\nand non-backdoored open-source models. We show that we can improve the backdoor\nrobustness of large language models by locally constraining individual modules\nduring fine-tuning on potentially poisonous data sets.\n\nTrigger warning: Offensive language.",
          "link": "http://arxiv.org/abs/2302.12461",
          "publishedOn": "2023-10-14T00:41:34.858Z",
          "wordCount": null,
          "title": "Analyzing And Editing Inner Mechanisms Of Backdoored Language Models. (arXiv:2302.12461v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07427",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhengmeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hai Lin</a>",
          "description": "We propose a time series forecasting method named Quantum Gramian Angular\nField (QGAF). This approach merges the advantages of quantum computing\ntechnology with deep learning, aiming to enhance the precision of time series\nclassification and forecasting. We successfully transformed stock return time\nseries data into two-dimensional images suitable for Convolutional Neural\nNetwork (CNN) training by designing specific quantum circuits. Distinct from\nthe classical Gramian Angular Field (GAF) approach, QGAF's uniqueness lies in\neliminating the need for data normalization and inverse cosine calculations,\nsimplifying the transformation process from time series data to two-dimensional\nimages. To validate the effectiveness of this method, we conducted experiments\non datasets from three major stock markets: the China A-share market, the Hong\nKong stock market, and the US stock market. Experimental results revealed that\ncompared to the classical GAF method, the QGAF approach significantly improved\ntime series prediction accuracy, reducing prediction errors by an average of\n25% for Mean Absolute Error (MAE) and 48% for Mean Squared Error (MSE). This\nresearch confirms the potential and promising prospects of integrating quantum\ncomputing with deep learning techniques in financial time series forecasting.",
          "link": "http://arxiv.org/abs/2310.07427",
          "publishedOn": "2023-10-14T00:41:34.853Z",
          "wordCount": null,
          "title": "Quantum-Enhanced Forecasting: Leveraging Quantum Gramian Angular Field and CNNs for Stock Return Predictions. (arXiv:2310.07427v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deuschel_J/0/1/0/all/0/1\">Jannik Deuschel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellington_C/0/1/0/all/0/1\">Caleb N. Ellington</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lengerich_B/0/1/0/all/0/1\">Benjamin J. Lengerich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yingtao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friederich_P/0/1/0/all/0/1\">Pascal Friederich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>",
          "description": "Interpretable policy learning seeks to estimate intelligible decision\npolicies from observed actions; however, existing models fall short by forcing\na tradeoff between accuracy and interpretability. This tradeoff limits\ndata-driven interpretations of human decision-making process. e.g. to audit\nmedical decisions for biases and suboptimal practices, we require models of\ndecision processes which provide concise descriptions of complex behaviors.\nFundamentally, existing approaches are burdened by this tradeoff because they\nrepresent the underlying decision process as a universal policy, when in fact\nhuman decisions are dynamic and can change drastically with contextual\ninformation. Thus, we propose Contextualized Policy Recovery (CPR), which\nre-frames the problem of modeling complex decision processes as a multi-task\nlearning problem in which complex decision policies are comprised of\ncontext-specific policies. CPR models each context-specific policy as a linear\nobservation-to-action mapping, and generates new decision models\n$\\textit{on-demand}$ as contexts are updated with new observations. CPR is\ncompatible with fully offline and partially observable decision environments,\nand can be tailored to incorporate any recurrent black-box model or\ninterpretable decision model. We assess CPR through studies on simulated and\nreal data, achieving state-of-the-art performance on the canonical tasks of\npredicting antibiotic prescription in intensive care units ($+22\\%$ AUROC vs.\nprevious SOTA) and predicting MRI prescription for Alzheimer's patients\n($+7.7\\%$ AUROC vs. previous SOTA). With this improvement in predictive\nperformance, CPR closes the accuracy gap between interpretable and black-box\nmethods for policy learning, allowing high-resolution exploration and analysis\nof context-specific decision models.",
          "link": "http://arxiv.org/abs/2310.07918",
          "publishedOn": "2023-10-14T00:41:34.845Z",
          "wordCount": null,
          "title": "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning. (arXiv:2310.07918v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07402",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenguo Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xumeng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_W/0/1/0/all/0/1\">Wei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Congrui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Stephen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhirong Wu</a>",
          "description": "Recent research on time-series self-supervised models shows great promise in\nlearning semantic representations. However, it has been limited to small-scale\ndatasets, e.g., thousands of temporal sequences. In this work, we make key\ntechnical contributions that are tailored to the numerical properties of\ntime-series data and allow the model to scale to large datasets, e.g., millions\nof temporal sequences. We adopt the Transformer architecture by first\npartitioning the input into non-overlapping windows. Each window is then\ncharacterized by its normalized shape and two scalar values denoting the mean\nand standard deviation within each window. To embed scalar values that may\npossess arbitrary numerical scales to high-dimensional vectors, we propose a\nnumerically multi-scaled embedding module enumerating all possible scales for\nthe scalar values. The model undergoes pretraining using the proposed\nnumerically multi-scaled embedding with a simple contrastive objective on a\nlarge-scale dataset containing over a million sequences. We study its transfer\nperformance on a number of univariate and multivariate classification\nbenchmarks. Our method exhibits remarkable improvement against previous\nrepresentation learning approaches and establishes the new state of the art,\neven compared with domain-specific non-learning-based methods.",
          "link": "http://arxiv.org/abs/2310.07402",
          "publishedOn": "2023-10-14T00:41:34.831Z",
          "wordCount": null,
          "title": "NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series Pretraining. (arXiv:2310.07402v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.09222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Ziqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuntao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianguo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1\">Junliang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1\">Shwetak Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuanchun Shi</a>",
          "description": "Multimodal sensors provide complementary information to develop accurate\nmachine-learning methods for human activity recognition (HAR), but introduce\nsignificantly higher computational load, which reduces efficiency. This paper\nproposes an efficient multimodal neural architecture for HAR using an RGB\ncamera and inertial measurement units (IMUs) called Multimodal Temporal Segment\nAttention Network (MMTSA). MMTSA first transforms IMU sensor data into a\ntemporal and structure-preserving gray-scale image using the Gramian Angular\nField (GAF), representing the inherent properties of human activities. MMTSA\nthen applies a multimodal sparse sampling method to reduce data redundancy.\nLastly, MMTSA adopts an inter-segment attention module for efficient multimodal\nfusion. Using three well-established public datasets, we evaluated MMTSA's\neffectiveness and efficiency in HAR. Results show that our method achieves\nsuperior performance improvements 11.13% of cross-subject F1-score on the MMAct\ndataset than the previous state-of-the-art (SOTA) methods. The ablation study\nand analysis suggest that MMTSA's effectiveness in fusing multimodal data for\naccurate HAR. The efficiency evaluation on an edge device showed that MMTSA\nachieved significantly better accuracy, lower computational load, and lower\ninference latency than SOTA methods.",
          "link": "http://arxiv.org/abs/2210.09222",
          "publishedOn": "2023-10-14T00:41:34.795Z",
          "wordCount": 713,
          "title": "MMTSA: Multimodal Temporal Segment Attention Network for Efficient Human Activity Recognition. (arXiv:2210.09222v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuang_W/0/1/0/all/0/1\">Weijie Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_H/0/1/0/all/0/1\">Hann Woei Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Ye Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suandi_S/0/1/0/all/0/1\">Shahrel Azmin Suandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ismail_F/0/1/0/all/0/1\">Farzad Ismail</a>",
          "description": "Unmanned Aerial Vehicles (UAVs) are considered cutting-edge technology with\nhighly cost-effective and flexible usage scenarios. Although many papers have\nreviewed the application of UAVs in agriculture, the review of the application\nfor tree detection is still insufficient. This paper focuses on tree detection\nmethods applied to UAV data collected by UAVs. There are two kinds of data, the\npoint cloud and the images, which are acquired by the Light Detection and\nRanging (LiDAR) sensor and camera, respectively. Among the detection methods\nusing point-cloud data, this paper mainly classifies these methods according to\nLiDAR and Digital Aerial Photography (DAP). For the detection methods using\nimages directly, this paper reviews these methods by whether or not to use the\nDeep Learning (DL) method. Our review concludes and analyses the comparison and\ncombination between the application of LiDAR-based and DAP-based point cloud\ndata. The performance, relative merits, and application fields of the methods\nare also introduced. Meanwhile, this review counts the number of tree detection\nstudies using different methods in recent years. From our statics, the\ndetection task using DL methods on the image has become a mainstream trend as\nthe number of DL-based detection researches increases to 45% of the total\nnumber of tree detection studies up to 2022. As a result, this review could\nhelp and guide researchers who want to carry out tree detection on specific\nforests and for farmers to use UAVs in managing agriculture production.",
          "link": "http://arxiv.org/abs/2309.16375",
          "publishedOn": "2023-10-14T00:41:34.696Z",
          "wordCount": null,
          "title": "A Comprehensive Review on Tree Detection Methods Using Point Cloud and Aerial Imagery from Unmanned Aerial Vehicles. (arXiv:2309.16375v2 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahabadi_S/0/1/0/all/0/1\">Sepideh Mahabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trajanovski_S/0/1/0/all/0/1\">Stojan Trajanovski</a>",
          "description": "We study core-set construction algorithms for the task of Diversity\nMaximization under fairness/partition constraint. Given a set of points $P$ in\na metric space partitioned into $m$ groups, and given $k_1,\\ldots,k_m$, the\ngoal of this problem is to pick $k_i$ points from each group $i$ such that the\noverall diversity of the $k=\\sum_i k_i$ picked points is maximized. We consider\ntwo natural diversity measures: sum-of-pairwise distances and\nsum-of-nearest-neighbor distances, and show improved core-set construction\nalgorithms with respect to these measures. More precisely, we show the first\nconstant factor core-set w.r.t. sum-of-pairwise distances whose size is\nindependent of the size of the dataset and the aspect ratio. Second, we show\nthe first core-set w.r.t. the sum-of-nearest-neighbor distances. Finally, we\nrun several experiments showing the effectiveness of our core-set approach. In\nparticular, we apply constrained diversity maximization to summarize a set of\ntimed messages that takes into account the messages' recency. Specifically, the\nsummary should include more recent messages compared to older ones. This is a\nreal task in one of the largest communication platforms, affecting the\nexperience of hundreds of millions daily active users. By utilizing our\ncore-set method for this task, we achieve a 100x speed-up while losing the\ndiversity by only a few percent. Moreover, our approach allows us to improve\nthe space usage of the algorithm in the streaming setting.",
          "link": "http://arxiv.org/abs/2310.08122",
          "publishedOn": "2023-10-14T00:41:34.453Z",
          "wordCount": null,
          "title": "Core-sets for Fair and Diverse Data Summarization. (arXiv:2310.08122v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zeyuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hongshu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiacheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenrui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_G/0/1/0/all/0/1\">Guojun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yue-Jiao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yining Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Zhiguang Cao</a>",
          "description": "Recently, Meta-Black-Box Optimization with Reinforcement Learning\n(MetaBBO-RL) has showcased the power of leveraging RL at the meta-level to\nmitigate manual fine-tuning of low-level black-box optimizers. However, this\nfield is hindered by the lack of a unified benchmark. To fill this gap, we\nintroduce MetaBox, the first benchmark platform expressly tailored for\ndeveloping and evaluating MetaBBO-RL methods. MetaBox offers a flexible\nalgorithmic template that allows users to effortlessly implement their unique\ndesigns within the platform. Moreover, it provides a broad spectrum of over 300\nproblem instances, collected from synthetic to realistic scenarios, and an\nextensive library of 19 baseline methods, including both traditional black-box\noptimizers and recent MetaBBO-RL methods. Besides, MetaBox introduces three\nstandardized performance metrics, enabling a more thorough assessment of the\nmethods. In a bid to illustrate the utility of MetaBox for facilitating\nrigorous evaluation and in-depth analysis, we carry out a wide-ranging\nbenchmarking study on existing MetaBBO-RL methods. Our MetaBox is open-source\nand accessible at: https://github.com/GMC-DRL/MetaBox.",
          "link": "http://arxiv.org/abs/2310.08252",
          "publishedOn": "2023-10-14T00:41:34.444Z",
          "wordCount": null,
          "title": "MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning. (arXiv:2310.08252v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.09663",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Botvinick_Greenhouse_J/0/1/0/all/0/1\">Jonah Botvinick-Greenhouse</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1\">Yunan Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maulik_R/0/1/0/all/0/1\">Romit Maulik</a>",
          "description": "Motivated by the computational difficulties incurred by popular deep learning\nalgorithms for the generative modeling of temporal densities, we propose a\ncheap alternative which requires minimal hyperparameter tuning and scales\nfavorably to high dimensional problems. In particular, we use a\nprojection-based optimal transport solver [Meng et al., 2019] to join\nsuccessive samples and subsequently use transport splines [Chewi et al., 2020]\nto interpolate the evolving density. When the sampling frequency is\nsufficiently high, the optimal maps are close to the identity and are thus\ncomputationally efficient to compute. Moreover, the training process is highly\nparallelizable as all optimal maps are independent and can thus be learned\nsimultaneously. Finally, the approach is based solely on numerical linear\nalgebra rather than minimizing a nonconvex objective function, allowing us to\neasily analyze and control the algorithm. We present several numerical\nexperiments on both synthetic and real-world datasets to demonstrate the\nefficiency of our method. In particular, these experiments show that the\nproposed approach is highly competitive compared with state-of-the-art\nnormalizing flows conditioned on time across a wide range of dimensionalities.",
          "link": "http://arxiv.org/abs/2304.09663",
          "publishedOn": "2023-10-14T00:41:34.434Z",
          "wordCount": null,
          "title": "Generative modeling of time-dependent densities via optimal transport and projection pursuit. (arXiv:2304.09663v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.17823",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Okuno_A/0/1/0/all/0/1\">Akifumi Okuno</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Harada_K/0/1/0/all/0/1\">Kazuharu Harada</a>",
          "description": "This study proposes an interpretable neural network-based non-proportional\nodds model (N$^3$POM) for ordinal regression. N$^3$POM is different from\nconventional approaches to ordinal regression with non-proportional models in\nseveral ways: (1) N$^3$POM is designed to directly handle continuous responses,\nwhereas standard methods typically treat de facto ordered continuous variables\nas discrete, (2) instead of estimating response-dependent finite coefficients\nof linear models from discrete responses as is done in conventional approaches,\nwe train a non-linear neural network to serve as a coefficient function. Thanks\nto the neural network, N$^3$POM offers flexibility while preserving the\ninterpretability of conventional ordinal regression. We establish a sufficient\ncondition under which the predicted conditional cumulative probability locally\nsatisfies the monotonicity constraint over a user-specified region in the\ncovariate space. Additionally, we provide a monotonicity-preserving stochastic\n(MPS) algorithm for effectively training the neural network. We apply N$^3$POM\nto several real-world datasets.",
          "link": "http://arxiv.org/abs/2303.17823",
          "publishedOn": "2023-10-14T00:41:34.433Z",
          "wordCount": null,
          "title": "An interpretable neural network-based non-proportional odds model for ordinal regression. (arXiv:2303.17823v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.02931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Setlur_A/0/1/0/all/0/1\">Amrith Setlur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_D/0/1/0/all/0/1\">Don Dennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1\">Benjamin Eysenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghunathan_A/0/1/0/all/0/1\">Aditi Raghunathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1\">Virginia Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Training machine learning models robust to distribution shifts is critical\nfor real-world applications. Some robust training algorithms (e.g., Group DRO)\nspecialize to group shifts and require group information on all training\npoints. Other methods (e.g., CVaR DRO) that do not need group annotations can\nbe overly conservative, since they naively upweight high loss points which may\nform a contrived set that does not correspond to any meaningful group in the\nreal world (e.g., when the high loss points are randomly mislabeled training\npoints). In this work, we address limitations in prior approaches by assuming a\nmore nuanced form of group shift: conditioned on the label, we assume that the\ntrue group function (indicator over group) is simple. For example, we may\nexpect that group shifts occur along low bitrate features (e.g., image\nbackground, lighting). Thus, we aim to learn a model that maintains high\naccuracy on simple group functions realized by these low bitrate features, that\nneed not spend valuable model capacity achieving high accuracy on contrived\ngroups of examples. Based on this, we consider the two-player game formulation\nof DRO where the adversary's capacity is bitrate-constrained. Our resulting\npractical algorithm, Bitrate-Constrained DRO (BR-DRO), does not require group\ninformation on training samples yet matches the performance of Group DRO on\ndatasets that have training group annotations and that of CVaR DRO on\nlong-tailed distributions. Our theoretical analysis reveals that in some\nsettings BR-DRO objective can provably yield statistically efficient and less\nconservative solutions than unconstrained CVaR DRO.",
          "link": "http://arxiv.org/abs/2302.02931",
          "publishedOn": "2023-10-14T00:41:34.432Z",
          "wordCount": null,
          "title": "Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts. (arXiv:2302.02931v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nikpour_B/0/1/0/all/0/1\">Bahareh Nikpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armanfard_N/0/1/0/all/0/1\">Narges Armanfard</a>",
          "description": "Attention mechanisms have exhibited promising potential in enhancing learning\nmodels by identifying salient portions of input data. This is particularly\nvaluable in scenarios where limited training samples are accessible due to\nchallenges in data collection and labeling. Drawing inspiration from human\nrecognition processes, we posit that an AI baseline's performance could be more\naccurate and dependable if it is exposed to essential segments of raw data\nrather than the entire input dataset, akin to human perception. However, the\ntask of selecting these informative data segments, referred to as hard\nattention finding, presents a formidable challenge. In situations with few\ntraining samples, existing studies struggle to locate such informative regions\ndue to the large number of training parameters that cannot be effectively\nlearned from the available limited samples. In this study, we introduce a novel\nand practical framework for achieving explainable hard attention finding,\nspecifically tailored for few-shot learning scenarios, called FewXAT. Our\napproach employs deep reinforcement learning to implement the concept of hard\nattention, directly impacting raw input data and thus rendering the process\ninterpretable for human understanding. Through extensive experimentation across\nvarious benchmark datasets, we demonstrate the efficacy of our proposed method.",
          "link": "http://arxiv.org/abs/2310.07800",
          "publishedOn": "2023-10-14T00:41:34.426Z",
          "wordCount": null,
          "title": "Explainable Attention for Few-shot Learning and Beyond. (arXiv:2310.07800v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwajong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seong-Woo Kim</a>",
          "description": "A flow control system is a critical concept for increasing the production\ncapacity of manufacturing systems. To solve the scheduling optimization problem\nrelated to the flow control with the aim of improving productivity, existing\nmethods depend on a heuristic design by domain human experts. Therefore, the\nmethods require correction, monitoring, and verification by using real\nequipment. As system designs increase in complexity, the monitoring time\nincreases, which decreases the probability of arriving at the optimal design.\nAs an alternative approach to the heuristic design of flow control systems, the\nuse of deep reinforcement learning to solve the scheduling optimization problem\nhas been considered. Although the existing research on reinforcement learning\nhas yielded excellent performance in some areas, the applicability of the\nresults to actual FAB such as display and semiconductor manufacturing processes\nis not evident so far. To this end, we propose a method to implement a physical\nsimulation environment and devise a feasible flow control system design using a\ntransfer robot in display manufacturing through reinforcement learning. We\npresent a model and parameter setting to build a virtual environment for\ndifferent display transfer robots, and training methods of reinforcement\nlearning on the environment to obtain an optimal scheduling of glass flow\ncontrol systems. Its feasibility was verified by using different types of\nrobots used in the actual process.",
          "link": "http://arxiv.org/abs/2310.07981",
          "publishedOn": "2023-10-14T00:41:34.422Z",
          "wordCount": null,
          "title": "Reinforcement Learning of Display Transfer Robots in Glass Flow Control Systems: A Physical Simulation-Based Approach. (arXiv:2310.07981v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.10010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pouplin_A/0/1/0/all/0/1\">Alison Pouplin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eklund_D/0/1/0/all/0/1\">David Eklund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ek_C/0/1/0/all/0/1\">Carl Henrik Ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>",
          "description": "Riemannian geometry provides us with powerful tools to explore the latent\nspace of generative models while preserving the underlying structure of the\ndata. The latent space can be equipped it with a Riemannian metric, pulled back\nfrom the data manifold. With this metric, we can systematically navigate the\nspace relying on geodesics defined as the shortest curves between two points.\nGenerative models are often stochastic, causing the data space, the Riemannian\nmetric, and the geodesics, to be stochastic as well. Stochastic objects are at\nbest impractical, and at worst impossible, to manipulate. A common solution is\nto approximate the stochastic pullback metric by its expectation. But the\ngeodesics derived from this expected Riemannian metric do not correspond to the\nexpected length-minimising curves. In this work, we propose another metric\nwhose geodesics explicitly minimise the expected length of the pullback metric.\nWe show this metric defines a Finsler metric, and we compare it with the\nexpected Riemannian metric. In high dimensions, we prove that both metrics\nconverge to each other at a rate of $O\\left(\\frac{1}{D}\\right)$. This\nconvergence implies that the established expected Riemannian metric is an\naccurate approximation of the theoretically more grounded Finsler metric. This\nprovides justification for using the expected Riemannian metric for practical\nimplementations.",
          "link": "http://arxiv.org/abs/2212.10010",
          "publishedOn": "2023-10-14T00:41:34.419Z",
          "wordCount": null,
          "title": "Identifying latent distances with Finslerian geometry. (arXiv:2212.10010v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1\">Ming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingbin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shroff_N/0/1/0/all/0/1\">Ness Shroff</a>",
          "description": "Partially observable Markov decision processes (POMDPs) have been widely\napplied to capture many real-world applications. However, existing theoretical\nresults have shown that learning in general POMDPs could be intractable, where\nthe main challenge lies in the lack of latent state information. A key\nfundamental question here is how much online state information (OSI) is\nsufficient to achieve tractability. In this paper, we establish a lower bound\nthat reveals a surprising hardness result: unless we have full OSI, we need an\nexponentially scaling sample complexity to obtain an $\\epsilon$-optimal policy\nsolution for POMDPs. Nonetheless, inspired by the key insights in our lower\nbound design, we find that there exist important tractable classes of POMDPs\neven with only partial OSI. In particular, for two novel classes of POMDPs with\npartial OSI, we provide new algorithms that are proved to be near-optimal by\nestablishing new regret upper and lower bounds.",
          "link": "http://arxiv.org/abs/2306.08762",
          "publishedOn": "2023-10-14T00:41:34.411Z",
          "wordCount": null,
          "title": "Theoretical Hardness and Tractability of POMDPs in RL with Partial Online State Information. (arXiv:2306.08762v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cobanoglu_Y/0/1/0/all/0/1\">Yunus Cobanoglu</a>",
          "description": "This work analyzes Graph Neural Networks, a generalization of Fully-Connected\nDeep Neural Nets on Graph structured data, when their width, that is the number\nof nodes in each fullyconnected layer is increasing to infinity. Infinite Width\nNeural Networks are connecting Deep Learning to Gaussian Processes and Kernels,\nboth Machine Learning Frameworks with long traditions and extensive theoretical\nfoundations. Gaussian Processes and Kernels have much less hyperparameters then\nNeural Networks and can be used for uncertainty estimation, making them more\nuser friendly for applications. This works extends the increasing amount of\nresearch connecting Gaussian Processes and Kernels to Neural Networks. The\nKernel and Gaussian Process closed forms are derived for a variety of\narchitectures, namely the standard Graph Neural Network, the Graph Neural\nNetwork with Skip-Concatenate Connections and the Graph Attention Neural\nNetwork. All architectures are evaluated on a variety of datasets on the task\nof transductive Node Regression and Classification. Additionally, a Spectral\nSparsification method known as Effective Resistance is used to improve runtime\nand memory requirements. Extending the setting to inductive graph learning\ntasks (Graph Regression/ Classification) is straightforward and is briefly\ndiscussed in 3.5.",
          "link": "http://arxiv.org/abs/2310.08176",
          "publishedOn": "2023-10-14T00:41:34.409Z",
          "wordCount": null,
          "title": "Infinite Width Graph Neural Networks for Node Regression/ Classification. (arXiv:2310.08176v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1\">Xin Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tal_A/0/1/0/all/0/1\">Avishay Tal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hongxun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junzhao Yang</a>",
          "description": "In his breakthrough paper, Raz showed that any parity learning algorithm\nrequires either quadratic memory or an exponential number of samples [FOCS'16,\nJACM'19]. A line of work that followed extended this result to a large class of\nlearning problems. Until recently, all these results considered learning in the\nstreaming model, where each sample is drawn independently, and the learner is\nallowed a single pass over the stream of samples. Garg, Raz, and Tal [CCC'19]\nconsidered a stronger model, allowing multiple passes over the stream. In the\n$2$-pass model, they showed that learning parities of size $n$ requires either\na memory of size $n^{1.5}$ or at least $2^{\\sqrt{n}}$ samples. (Their result\nalso generalizes to other learning problems.)\n\nIn this work, for any constant $q$, we prove tight memory-sample lower bounds\nfor any parity learning algorithm that makes $q$ passes over the stream of\nsamples. We show that such a learner requires either $\\Omega(n^{2})$ memory\nsize or at least $2^{\\Omega(n)}$ samples. Beyond establishing a tight lower\nbound, this is the first non-trivial lower bound for $q$-pass learning for any\n$q\\ge 3$. Similar to prior work, our results extend to any learning problem\nwith many nearly-orthogonal concepts.\n\nWe complement the lower bound with an upper bound, showing that parity\nlearning with $q$ passes can be done efficiently with $O(n^2/\\log q)$ memory.",
          "link": "http://arxiv.org/abs/2310.08070",
          "publishedOn": "2023-10-14T00:41:34.408Z",
          "wordCount": null,
          "title": "Tight Time-Space Lower Bounds for Constant-Pass Learning. (arXiv:2310.08070v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ao_W/0/1/0/all/0/1\">Wei Ao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boddeti_V/0/1/0/all/0/1\">Vishnu Naresh Boddeti</a>",
          "description": "Secure inference of deep convolutional neural networks (CNNs) under RNS-CKKS\ninvolves polynomial approximation of unsupported non-linear activation\nfunctions. However, existing approaches have three main limitations: 1)\nInflexibility: The polynomial approximation and associated homomorphic\nevaluation architecture are customized manually for each CNN architecture and\ndo not generalize to other networks. 2) Suboptimal Approximation: Each\nactivation function is approximated instead of the function represented by the\nCNN. 3) Restricted Design: Either high-degree or low-degree polynomial\napproximations are used. The former retains high accuracy but slows down\ninference due to bootstrapping operations, while the latter accelerates\nciphertext inference but compromises accuracy. To address these limitations, we\npresent AutoFHE, which automatically adapts standard CNNs for secure inference\nunder RNS-CKKS. The key idea is to adopt layerwise mixed-degree polynomial\nactivation functions, which are optimized jointly with the homomorphic\nevaluation architecture in terms of the placement of bootstrapping operations.\nThe problem is modeled within a multi-objective optimization framework to\nmaximize accuracy and minimize the number of bootstrapping operations. AutoFHE\ncan be applied flexibly on any CNN architecture, and it provides diverse\nsolutions that span the trade-off between accuracy and latency. Experimental\nevaluation over RNS-CKKS encrypted CIFAR datasets shows that AutoFHE\naccelerates secure inference by $1.32\\times$ to $1.8\\times$ compared to methods\nemploying high-degree polynomials. It also improves accuracy by up to 2.56%\ncompared to methods using low-degree polynomials. Lastly, AutoFHE accelerates\ninference and improves accuracy by $103\\times$ and 3.46%, respectively,\ncompared to CNNs under TFHE.",
          "link": "http://arxiv.org/abs/2310.08012",
          "publishedOn": "2023-10-14T00:41:34.407Z",
          "wordCount": null,
          "title": "AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE. (arXiv:2310.08012v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08331",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zangirolami_V/0/1/0/all/0/1\">Valentina Zangirolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Borrotti_M/0/1/0/all/0/1\">Matteo Borrotti</a>",
          "description": "Incomplete knowledge of the environment leads an agent to make decisions\nunder uncertainty. One of the major dilemmas in Reinforcement Learning (RL)\nwhere an autonomous agent has to balance two contrasting needs in making its\ndecisions is: exploiting the current knowledge of the environment to maximize\nthe cumulative reward as well as exploring actions that allow improving the\nknowledge of the environment, hopefully leading to higher reward values\n(exploration-exploitation trade-off). Concurrently, another relevant issue\nregards the full observability of the states, which may not be assumed in all\napplications. Such as when only 2D images are considered as input in a RL\napproach used for finding the optimal action within a 3D simulation\nenvironment. In this work, we address these issues by deploying and testing\nseveral techniques to balance exploration and exploitation trade-off on\npartially observable systems for predicting steering wheels in autonomous\ndriving scenario. More precisely, the final aim is to investigate the effects\nof using both stochastic and deterministic multi-armed bandit strategies\ncoupled with a Deep Recurrent Q-Network. Additionally, we adapted and evaluated\nthe impact of an innovative method to improve the learning phase of the\nunderlying Convolutional Recurrent Neural Network. We aim to show that adaptive\nstochastic methods for exploration better approximate the trade-off between\nexploration and exploitation as, in general, Softmax and Max-Boltzmann\nstrategies are able to outperform epsilon-greedy techniques.",
          "link": "http://arxiv.org/abs/2310.08331",
          "publishedOn": "2023-10-14T00:41:34.407Z",
          "wordCount": null,
          "title": "Impact of multi-armed bandit strategies on deep recurrent reinforcement learning. (arXiv:2310.08331v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianfei Ma</a>",
          "description": "Future sequence represents the outcome after executing the action into the\nenvironment. When driven by the information-theoretic concept of mutual\ninformation, it seeks maximally informative consequences. Explicit outcomes may\nvary across state, return, or trajectory serving different purposes such as\ncredit assignment or imitation learning. However, the inherent nature of\nincorporating intrinsic motivation with reward maximization is often neglected.\nIn this work, we propose a variational approach to jointly learn the necessary\nquantity for estimating the mutual information and the dynamics model,\nproviding a general framework for incorporating different forms of outcomes of\ninterest. Integrated into a policy iteration scheme, our approach guarantees\nconvergence to the optimal policy. While we mainly focus on theoretical\nanalysis, our approach opens the possibilities of leveraging intrinsic control\nwith model learning to enhance sample efficiency and incorporate uncertainty of\nthe environment into decision-making.",
          "link": "http://arxiv.org/abs/2310.08100",
          "publishedOn": "2023-10-14T00:41:34.403Z",
          "wordCount": null,
          "title": "Generative Intrinsic Optimization: Intrisic Control with Model Learning. (arXiv:2310.08100v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_K/0/1/0/all/0/1\">Kushagra Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudolph_M/0/1/0/all/0/1\">Maja Rudolph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Diffusion models suffer from slow sample generation at inference time.\nTherefore, developing a principled framework for fast deterministic/stochastic\nsampling for a broader class of diffusion models is a promising direction. We\npropose two complementary frameworks for accelerating sample generation in\npre-trained models: Conjugate Integrators and Splitting Integrators. Conjugate\nintegrators generalize DDIM, mapping the reverse diffusion dynamics to a more\namenable space for sampling. In contrast, splitting-based integrators, commonly\nused in molecular dynamics, reduce the numerical simulation error by cleverly\nalternating between numerical updates involving the data and auxiliary\nvariables. After extensively studying these methods empirically and\ntheoretically, we present a hybrid method that leads to the best-reported\nperformance for diffusion models in augmented spaces. Applied to Phase Space\nLangevin Diffusion [Pandey & Mandt, 2023] on CIFAR-10, our deterministic and\nstochastic samplers achieve FID scores of 2.11 and 2.36 in only 100 network\nfunction evaluations (NFE) as compared to 2.57 and 2.63 for the best-performing\nbaselines, respectively. Our code and model checkpoints will be made publicly\navailable at \\url{https://github.com/mandt-lab/PSLD}.",
          "link": "http://arxiv.org/abs/2310.07894",
          "publishedOn": "2023-10-14T00:41:34.397Z",
          "wordCount": null,
          "title": "Efficient Integrators for Diffusion Generative Models. (arXiv:2310.07894v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Decker_T/0/1/0/all/0/1\">Thomas Decker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gross_R/0/1/0/all/0/1\">Ralf Gross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koebler_A/0/1/0/all/0/1\">Alexander Koebler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lebacher_M/0/1/0/all/0/1\">Michael Lebacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schnitzer_R/0/1/0/all/0/1\">Ronald Schnitzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_S/0/1/0/all/0/1\">Stefan H. Weber</a>",
          "description": "In this paper, we investigate the practical relevance of explainable\nartificial intelligence (XAI) with a special focus on the producing industries\nand relate them to the current state of academic XAI research. Our findings are\nbased on an extensive series of interviews regarding the role and applicability\nof XAI along the Machine Learning (ML) lifecycle in current industrial practice\nand its expected relevance in the future. The interviews were conducted among a\ngreat variety of roles and key stakeholders from different industry sectors. On\ntop of that, we outline the state of XAI research by providing a concise review\nof the relevant literature. This enables us to provide an encompassing overview\ncovering the opinions of the surveyed persons as well as the current state of\nacademic research. By comparing our interview results with the current research\napproaches we reveal several discrepancies. While a multitude of different XAI\napproaches exists, most of them are centered around the model evaluation phase\nand data scientists. Their versatile capabilities for other stages are\ncurrently either not sufficiently explored or not popular among practitioners.\nIn line with existing work, our findings also confirm that more efforts are\nneeded to enable also non-expert users' interpretation and understanding of\nopaque AI models with existing methods and frameworks.",
          "link": "http://arxiv.org/abs/2310.07882",
          "publishedOn": "2023-10-14T00:41:34.393Z",
          "wordCount": null,
          "title": "The Thousand Faces of Explainable AI Along the Machine Learning Life Cycle: Industrial Reality and Current State of Research. (arXiv:2310.07882v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.04370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DeFazio_D/0/1/0/all/0/1\">David DeFazio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirota_E/0/1/0/all/0/1\">Eisuke Hirota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiqi Zhang</a>",
          "description": "Seeing-eye robots are very useful tools for guiding visually impaired people,\npotentially producing a huge societal impact given the low availability and\nhigh cost of real guide dogs. Although a few seeing-eye robot systems have\nalready been demonstrated, none considered external tugs from humans, which\nfrequently occur in a real guide dog setting. In this paper, we simultaneously\ntrain a locomotion controller that is robust to external tugging forces via\nReinforcement Learning (RL), and an external force estimator via supervised\nlearning. The controller ensures stable walking, and the force estimator\nenables the robot to respond to the external forces from the human. These\nforces are used to guide the robot to the global goal, which is unknown to the\nrobot, while the robot guides the human around nearby obstacles via a local\nplanner. Experimental results in simulation and on hardware show that our\ncontroller is robust to external forces, and our seeing-eye system can\naccurately detect force direction. We demonstrate our full seeing-eye robot\nsystem on a real quadruped robot with a blindfolded human. The video can be\nseen at our project page: https://bu-air-lab.github.io/guide_dog/",
          "link": "http://arxiv.org/abs/2309.04370",
          "publishedOn": "2023-10-14T00:41:34.363Z",
          "wordCount": null,
          "title": "Seeing-Eye Quadruped Navigation with Force Responsive Locomotion Control. (arXiv:2309.04370v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.08469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Ching Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wen-Chih Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tien-Fu Chen</a>",
          "description": "In this work, we leverage pre-trained Large Language Models (LLMs) to enhance\ntime-series forecasting. Mirroring the growing interest in unifying models for\nNatural Language Processing and Computer Vision, we envision creating an\nanalogous model for long-term time-series forecasting. Due to limited\nlarge-scale time-series data for building robust foundation models, our\napproach LLM4TS focuses on leveraging the strengths of pre-trained LLMs. By\ncombining time-series patching with temporal encoding, we have enhanced the\ncapability of LLMs to handle time-series data effectively. Inspired by the\nsupervised fine-tuning in chatbot domains, we prioritize a two-stage\nfine-tuning process: first conducting supervised fine-tuning to orient the LLM\ntowards time-series data, followed by task-specific downstream fine-tuning.\nFurthermore, to unlock the flexibility of pre-trained LLMs without extensive\nparameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT)\ntechniques. Drawing on these innovations, LLM4TS has yielded state-of-the-art\nresults in long-term forecasting. Our model has also shown exceptional\ncapabilities as both a robust representation learner and an effective few-shot\nlearner, thanks to the knowledge transferred from the pre-trained LLM.",
          "link": "http://arxiv.org/abs/2308.08469",
          "publishedOn": "2023-10-14T00:41:34.362Z",
          "wordCount": null,
          "title": "LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs. (arXiv:2308.08469v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hotegni_S/0/1/0/all/0/1\">S. S. Hotegni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peitz_S/0/1/0/all/0/1\">S. Peitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berkemeier_M/0/1/0/all/0/1\">M. Berkemeier</a>",
          "description": "Different conflicting optimization criteria arise naturally in various Deep\nLearning scenarios. These can address different main tasks (i.e., in the\nsetting of Multi-Task Learning), but also main and secondary tasks such as loss\nminimization versus sparsity. The usual approach is a simple weighting of the\ncriteria, which formally only works in the convex setting. In this paper, we\npresent a Multi-Objective Optimization algorithm using a modified Weighted\nChebyshev scalarization for training Deep Neural Networks (DNNs) with respect\nto several tasks. By employing this scalarization technique, the algorithm can\nidentify all optimal solutions of the original problem while reducing its\ncomplexity to a sequence of single-objective problems. The simplified problems\nare then solved using an Augmented Lagrangian method, enabling the use of\npopular optimization techniques such as Adam and Stochastic Gradient Descent,\nwhile efficaciously handling constraints. Our work aims to address the\n(economical and also ecological) sustainability issue of DNN models, with a\nparticular focus on Deep Multi-Task models, which are typically designed with a\nvery large number of weights to perform equally well on multiple tasks. Through\nexperiments conducted on two Machine Learning datasets, we demonstrate the\npossibility of adaptively sparsifying the model during training without\nsignificantly impacting its performance, if we are willing to apply\ntask-specific adaptations to the network weights. Code is available at\nhttps://github.com/salomonhotegni/MDMTN.",
          "link": "http://arxiv.org/abs/2308.12243",
          "publishedOn": "2023-10-14T00:41:34.359Z",
          "wordCount": null,
          "title": "Multi-Objective Optimization for Sparse Deep Neural Network Training. (arXiv:2308.12243v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zihao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xuan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yufei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingsong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xian Wei</a>",
          "description": "In continual learning, the learner learns multiple tasks in sequence, with\ndata being acquired only once for each task. Catastrophic forgetting is a major\nchallenge to continual learning. To reduce forgetting, some existing\nrehearsal-based methods use episodic memory to replay samples of previous\ntasks. However, in the process of knowledge integration when learning a new\ntask, this strategy also suffers from catastrophic forgetting due to an\nimbalance between old and new knowledge. To address this problem, we propose a\nnovel replay strategy called Manifold Expansion Replay (MaER). We argue that\nexpanding the implicit manifold of the knowledge representation in the episodic\nmemory helps to improve the robustness and expressiveness of the model. To this\nend, we propose a greedy strategy to keep increasing the diameter of the\nimplicit manifold represented by the knowledge in the buffer during memory\nmanagement. In addition, we introduce Wasserstein distance instead of cross\nentropy as distillation loss to preserve previous knowledge. With extensive\nexperimental validation on MNIST, CIFAR10, CIFAR100, and TinyImageNet, we show\nthat the proposed method significantly improves the accuracy in continual\nlearning setup, outperforming the state of the arts.",
          "link": "http://arxiv.org/abs/2310.08038",
          "publishedOn": "2023-10-14T00:41:34.336Z",
          "wordCount": null,
          "title": "Continual Learning via Manifold Expansion Replay. (arXiv:2310.08038v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.10691",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiateng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yangyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lifan Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>",
          "description": "To solve complex tasks, large language models (LLMs) often require multiple\nrounds of interactions with the user, sometimes assisted by external tools.\nHowever, current evaluation protocols often emphasize benchmark performance\nwith single-turn exchanges, neglecting the nuanced interactions among the user,\nLLMs, and external tools, while also underestimating the importance of natural\nlanguage feedback from users. These oversights contribute to discrepancies\nbetween research benchmark evaluations and real-world use cases. We introduce\nMINT, a benchmark that evaluates LLMs' ability to solve tasks with multi-turn\ninteractions by (1) using tools and (2) leveraging natural language feedback.\nTo ensure reproducibility, we provide an evaluation framework where LLMs can\naccess tools by executing Python code and receive users' natural language\nfeedback simulated by GPT-4. We repurpose a diverse set of established\nevaluation datasets focusing on reasoning, coding, and decision-making and\ncarefully curate them into a compact subset for efficient evaluation. Our\nanalysis of 20 open- and closed-source LLMs offers intriguing findings. (a)\nLLMs generally benefit from tools and language feedback, with performance gains\n(absolute, same below) of 1-8% for each turn of tool use and 2-17% with natural\nlanguage feedback. (b) Better single-turn performance does not guarantee better\nmulti-turn performance. (c) Surprisingly, on the LLMs evaluated, supervised\ninstruction-finetuning (SIFT) and reinforcement learning from human feedback\n(RLHF) generally hurt multi-turn capabilities. We expect MINT can help measure\nprogress and incentivize research in improving LLMs' capabilities in multi-turn\ninteractions, especially for open-source communities where multi-turn human\nevaluation can be less accessible compared to commercial LLMs with a larger\nuser base.",
          "link": "http://arxiv.org/abs/2309.10691",
          "publishedOn": "2023-10-14T00:41:34.326Z",
          "wordCount": null,
          "title": "MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback. (arXiv:2309.10691v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maesumi_A/0/1/0/all/0/1\">Arman Maesumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerrero_P/0/1/0/all/0/1\">Paul Guerrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_V/0/1/0/all/0/1\">Vladimir G. Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisher_M/0/1/0/all/0/1\">Matthew Fisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1\">Siddhartha Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aigerman_N/0/1/0/all/0/1\">Noam Aigerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritchie_D/0/1/0/all/0/1\">Daniel Ritchie</a>",
          "description": "Exploring variations of 3D shapes is a time-consuming process in traditional\n3D modeling tools. Deep generative models of 3D shapes often feature continuous\nlatent spaces that can, in principle, be used to explore potential variations\nstarting from a set of input shapes. In practice, doing so can be problematic:\nlatent spaces are high dimensional and hard to visualize, contain shapes that\nare not relevant to the input shapes, and linear paths through them often lead\nto sub-optimal shape transitions. Furthermore, one would ideally be able to\nexplore variations in the original high-quality meshes used to train the\ngenerative model, not its lower-quality output geometry. In this paper, we\npresent a method to explore variations among a given set of landmark shapes by\nconstructing a mapping from an easily-navigable 2D exploration space to a\nsubspace of a pre-trained generative model. We first describe how to find a\nmapping that spans the set of input landmark shapes and exhibits smooth\nvariations between them. We then show how to turn the variations in this\nsubspace into deformation fields, to transfer those variations to high-quality\nmeshes for the landmark shapes. Our results show that our method can produce\nvisually-pleasing and easily-navigable 2D exploration spaces for several\ndifferent shape categories, especially as compared to prior work on learning\ndeformation spaces for 3D shapes.",
          "link": "http://arxiv.org/abs/2310.07814",
          "publishedOn": "2023-10-14T00:41:34.303Z",
          "wordCount": null,
          "title": "Explorable Mesh Deformation Subspaces from Unstructured Generative Models. (arXiv:2310.07814v1 [cs.GR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07747",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huyuk_A/0/1/0/all/0/1\">Alihan H&#xfc;y&#xfc;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarrett_D/0/1/0/all/0/1\">Daniel Jarrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Learning transparent, interpretable controllers with offline data in\ndecision-making systems is an essential area of research due to its potential\nto reduce the risk of applications in real-world systems. However, in\nresponsibility-sensitive settings such as healthcare, decision accountability\nis of paramount importance, yet has not been adequately addressed by the\nliterature. This paper introduces the Accountable Offline Controller (AOC) that\nemploys the offline dataset as the Decision Corpus and performs accountable\ncontrol based on a tailored selection of examples, referred to as the Corpus\nSubset. ABC operates effectively in low-data scenarios, can be extended to the\nstrictly offline imitation setting, and displays qualities of both conservation\nand adaptability. We assess ABC's performance in both simulated and real-world\nhealthcare scenarios, emphasizing its capability to manage offline control\ntasks with high levels of performance while maintaining accountability.\n\nKeywords: Interpretable Reinforcement Learning, Explainable Reinforcement\nLearning, Reinforcement Learning Transparency, Offline Reinforcement Learning,\nBatched Control.",
          "link": "http://arxiv.org/abs/2310.07747",
          "publishedOn": "2023-10-14T00:41:34.300Z",
          "wordCount": null,
          "title": "Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples. (arXiv:2310.07747v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.01748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_K/0/1/0/all/0/1\">Kushagra Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Score-based Generative Models (SGMs) have demonstrated exceptional synthesis\noutcomes across various tasks. However, the current design landscape of the\nforward diffusion process remains largely untapped and often relies on physical\nheuristics or simplifying assumptions. Utilizing insights from the development\nof scalable Bayesian posterior samplers, we present a complete recipe for\nformulating forward processes in SGMs, ensuring convergence to the desired\ntarget distribution. Our approach reveals that several existing SGMs can be\nseen as specific manifestations of our framework. Building upon this method, we\nintroduce Phase Space Langevin Diffusion (PSLD), which relies on score-based\nmodeling within an augmented space enriched by auxiliary variables akin to\nphysical phase space. Empirical results exhibit the superior sample quality and\nimproved speed-quality trade-off of PSLD compared to various competing\napproaches on established image synthesis benchmarks. Remarkably, PSLD achieves\nsample quality akin to state-of-the-art SGMs (FID: 2.10 for unconditional\nCIFAR-10 generation). Lastly, we demonstrate the applicability of PSLD in\nconditional synthesis using pre-trained score networks, offering an appealing\nalternative as an SGM backbone for future advancements. Code and model\ncheckpoints can be accessed at \\url{https://github.com/mandt-lab/PSLD}.",
          "link": "http://arxiv.org/abs/2303.01748",
          "publishedOn": "2023-10-14T00:41:34.278Z",
          "wordCount": null,
          "title": "A Complete Recipe for Diffusion Generative Models. (arXiv:2303.01748v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marks_L/0/1/0/all/0/1\">Luke Marks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdullah_A/0/1/0/all/0/1\">Amir Abdullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendez_L/0/1/0/all/0/1\">Luna Mendez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arike_R/0/1/0/all/0/1\">Rauno Arike</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barez_F/0/1/0/all/0/1\">Fazl Barez</a>",
          "description": "Large language models (LLMs) aligned to human preferences via reinforcement\nlearning from human feedback (RLHF) underpin many commercial applications.\nHowever, how RLHF impacts LLM internals remains opaque. We propose a novel\nmethod to interpret learned reward functions in RLHF-tuned LLMs using sparse\nautoencoders. Our approach trains autoencoder sets on activations from a base\nLLM and its RLHF-tuned version. By comparing autoencoder hidden spaces, we\nidentify unique features that reflect the accuracy of the learned reward model.\nTo quantify this, we construct a scenario where the tuned LLM learns\ntoken-reward mappings to maximize reward. This is the first application of\nsparse autoencoders for interpreting learned rewards and broadly inspecting\nreward learning in LLMs. Our method provides an abstract approximation of\nreward integrity. This presents a promising technique for ensuring alignment\nbetween specified objectives and model behaviors.",
          "link": "http://arxiv.org/abs/2310.08164",
          "publishedOn": "2023-10-14T00:41:34.277Z",
          "wordCount": null,
          "title": "Interpreting Reward Models in RLHF-Tuned Language Models Using Sparse Autoencoders. (arXiv:2310.08164v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huayu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Cheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Recent developments in offline reinforcement learning have uncovered the\nimmense potential of diffusion modeling, which excels at representing\nheterogeneous behavior policies. However, sampling from diffusion policies is\nconsiderably slow because it necessitates tens to hundreds of iterative\ninference steps for one action. To address this issue, we propose to extract an\nefficient deterministic inference policy from critic models and pretrained\ndiffusion behavior models, leveraging the latter to directly regularize the\npolicy gradient with the behavior distribution's score function during\noptimization. Our method enjoys powerful generative capabilities of diffusion\nmodeling while completely circumventing the computationally intensive and\ntime-consuming diffusion sampling scheme, both during training and evaluation.\nExtensive results on D4RL tasks show that our method boosts action sampling\nspeed by more than 25 times compared with various leading diffusion-based\nmethods in locomotion tasks, while still maintaining state-of-the-art\nperformance.",
          "link": "http://arxiv.org/abs/2310.07297",
          "publishedOn": "2023-10-14T00:41:34.273Z",
          "wordCount": null,
          "title": "Score Regularized Policy Optimization through Diffusion Behavior. (arXiv:2310.07297v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.09033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Aadirupa Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>",
          "description": "Most bandit algorithms assume that the reward variances or their upper bounds\nare known, and that they are the same for all arms. This naturally leads to\nsuboptimal performance and higher regret due to variance overestimation. On the\nother hand, underestimated reward variances may lead to linear regret due to\ncommitting early to a suboptimal arm. This motivated prior works on\nvariance-adaptive frequentist algorithms, which have strong instance-dependent\nregret bounds but cannot incorporate prior knowledge on reward variances. We\nlay foundations for the Bayesian setting, which incorporates prior knowledge.\nThis results in lower regret in practice, due to using the prior in the\nalgorithm design, and also improved regret guarantees. Specifically, we study\nGaussian bandits with {unknown heterogeneous reward variances}, and develop a\nThompson sampling algorithm with prior-dependent Bayes regret bounds. We\nachieve lower regret with lower reward variances and more informative priors on\nthem, which is precisely why we pay only for what is uncertain. This is the\nfirst result of its kind. Finally, we corroborate our theory with extensive\nexperiments, which show the superiority of our variance-adaptive Bayesian\nalgorithm over prior frequentist approaches. We also show that our approach is\nrobust to model misspecification and can be applied with estimated priors.",
          "link": "http://arxiv.org/abs/2303.09033",
          "publishedOn": "2023-10-14T00:41:34.262Z",
          "wordCount": null,
          "title": "Only Pay for What Is Uncertain: Variance-Adaptive Thompson Sampling. (arXiv:2303.09033v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malik_G/0/1/0/all/0/1\">Girik Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowder_D/0/1/0/all/0/1\">Dakarai Crowder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mingolla_E/0/1/0/all/0/1\">Ennio Mingolla</a>",
          "description": "Adversarial attacks can affect the object recognition capabilities of\nmachines in wild. These can often result from spurious correlations between\ninput and class labels, and are prone to memorization in large networks. While\nnetworks are expected to do automated feature selection, it is not effective at\nthe scale of the object. Humans, however, are able to select the minimum set of\nfeatures required to form a robust representation of an object. In this work,\nwe show that finetuning any pretrained off-the-shelf network with Extreme Image\nTransformations (EIT) not only helps in learning a robust latent\nrepresentation, it also improves the performance of these networks against\ncommon adversarial attacks of various intensities. Our EIT trained networks\nshow strong activations in the object regions even when tested with more\nintense noise, showing promising generalizations across different kinds of\nadversarial attacks.",
          "link": "http://arxiv.org/abs/2310.07725",
          "publishedOn": "2023-10-14T00:41:34.261Z",
          "wordCount": null,
          "title": "Extreme Image Transformations Facilitate Robust Latent Object Representations. (arXiv:2310.07725v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.11014",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Hoidn_O/0/1/0/all/0/1\">Oliver Hoidn</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mishra_A/0/1/0/all/0/1\">Aashwin Ananda Mishra</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mehta_A/0/1/0/all/0/1\">Apurva Mehta</a>",
          "description": "By circumventing the resolution limitations of optics, coherent diffractive\nimaging (CDI) and ptychography are making their way into scientific fields\nranging from X-ray imaging to astronomy. Yet, the need for time consuming\niterative phase recovery hampers real-time imaging. While supervised deep\nlearning strategies have increased reconstruction speed, they sacrifice image\nquality. Furthermore, these methods' demand for extensive labeled training data\nis experimentally burdensome. Here, we propose an unsupervised physics-informed\nneural network reconstruction method, PtychoPINN, that retains the factor of\n100-to-1000 speedup of deep learning-based reconstruction while improving\nreconstruction quality by combining the diffraction forward map with real-space\nconstraints from overlapping measurements. In particular, PtychoPINN\nsignificantly advances generalizability, accuracy (with a typical 10 dB PSNR\nincrease), and linear resolution (2- to 6-fold gain). This blend of performance\nand speed offers exciting prospects for high-resolution real-time imaging in\nhigh-throughput environments such as X-ray free electron lasers (XFELs) and\ndiffraction-limited light sources.",
          "link": "http://arxiv.org/abs/2306.11014",
          "publishedOn": "2023-10-14T00:41:34.261Z",
          "wordCount": null,
          "title": "Physics Constrained Unsupervised Deep Learning for Rapid, High Resolution Scanning Coherent Diffraction Reconstruction. (arXiv:2306.11014v2 [physics.comp-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pawelczyk_M/0/1/0/all/0/1\">Martin Pawelczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neel_S/0/1/0/all/0/1\">Seth Neel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>",
          "description": "Machine unlearning, the study of efficiently removing the impact of specific\ntraining points on the trained model, has garnered increased attention of late,\ndriven by the need to comply with privacy regulations like the Right to be\nForgotten. Although unlearning is particularly relevant for LLMs in light of\nthe copyright issues they raise, achieving precise unlearning is\ncomputationally infeasible for very large models. To this end, recent work has\nproposed several algorithms which approximate the removal of training data\nwithout retraining the model. These algorithms crucially rely on access to the\nmodel parameters in order to update them, an assumption that may not hold in\npractice due to computational constraints or when the LLM is accessed via API.\nIn this work, we propose a new class of unlearning methods for LLMs we call\n''In-Context Unlearning'', providing inputs in context and without having to\nupdate model parameters. To unlearn a particular training instance, we provide\nthe instance alongside a flipped label and additional correctly labelled\ninstances which are prepended as inputs to the LLM at inference time. Our\nexperimental results demonstrate that these contexts effectively remove\nspecific information from the training set while maintaining performance levels\nthat are competitive with (or in some cases exceed) state-of-the-art unlearning\nmethods that require access to the LLM parameters.",
          "link": "http://arxiv.org/abs/2310.07579",
          "publishedOn": "2023-10-14T00:41:34.259Z",
          "wordCount": null,
          "title": "In-Context Unlearning: Language Models as Few Shot Unlearners. (arXiv:2310.07579v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jaewoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaehong Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Wonjae Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yunji Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "We present a lifelong audio-video masked autoencoder that continually learns\nthe multimodal representations from a video stream containing audio-video\npairs, while its distribution continually shifts over time. Specifically, we\npropose two novel ideas to tackle the problem: (1) Localized Alignment: We\nintroduce a small trainable multimodal encoder that predicts the audio and\nvideo tokens that are well-aligned with each other. This allows the model to\nlearn only the highly correlated audiovisual patches with accurate multimodal\nrelationships. (2) Forget-robust multimodal patch selection: We compare the\nrelative importance of each audio-video patch between the current and past data\npair to mitigate unintended drift of the previously learned audio-video\nrepresentations. Our proposed method, FLAVA (Forget-robust Localized\nAudio-Video Alignment), therefore, captures the complex relationships between\nthe audio and video modalities during training on a sequence of pre-training\ntasks while alleviating the forgetting of learned audiovisual correlations. Our\nexperiments validate that FLAVA outperforms the state-of-the-art continual\nlearning methods on several benchmark datasets under continual audio-video\nrepresentation learning scenarios.",
          "link": "http://arxiv.org/abs/2310.08204",
          "publishedOn": "2023-10-14T00:41:34.250Z",
          "wordCount": null,
          "title": "Lifelong Audio-video Masked Autoencoder with Forget-robust Localized Alignments. (arXiv:2310.08204v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_C/0/1/0/all/0/1\">Cheongwoong Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaesik Choi</a>",
          "description": "Large language models (LLMs) often make factually incorrect responses despite\ntheir success in various applications. In this paper, we hypothesize that\nrelying heavily on simple co-occurrence statistics of the pre-training corpora\nis one of the main factors that cause factual errors. Our results reveal that\nLLMs are vulnerable to the co-occurrence bias, defined as preferring frequently\nco-occurred words over the correct answer. Consequently, LLMs struggle to\nrecall facts whose subject and object rarely co-occur in the pre-training\ndataset although they are seen during finetuning. We show that co-occurrence\nbias remains despite scaling up model sizes or finetuning. Therefore, we\nsuggest finetuning on a debiased dataset to mitigate the bias by filtering out\nbiased samples whose subject-object co-occurrence count is high. Although\ndebiased finetuning allows LLMs to memorize rare facts in the training set, it\nis not effective in recalling rare facts unseen during finetuning. Further\nresearch in mitigation will help build reliable language models by preventing\npotential errors. The code is available at\n\\url{https://github.com/CheongWoong/impact_of_cooccurrence}.",
          "link": "http://arxiv.org/abs/2310.08256",
          "publishedOn": "2023-10-14T00:41:34.236Z",
          "wordCount": null,
          "title": "Impact of Co-occurrence on Factual Knowledge of Large Language Models. (arXiv:2310.08256v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cong_T/0/1/0/all/0/1\">Tianji Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hulsebos_M/0/1/0/all/0/1\">Madelon Hulsebos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhenjie Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groth_P/0/1/0/all/0/1\">Paul Groth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagadish_H/0/1/0/all/0/1\">H. V. Jagadish</a>",
          "description": "Language models and specialized table embedding models have recently\ndemonstrated strong performance on many tasks over tabular data. Researchers\nand practitioners are keen to leverage these models in many new application\ncontexts; but limited understanding of the strengths and weaknesses of these\nmodels, and the table representations they generate, makes the process of\nfinding a suitable model for a given task reliant on trial and error. There is\nan urgent need to gain a comprehensive understanding of these models to\nminimize inefficiency and failures in downstream usage.\n\nTo address this need, we propose Observatory, a formal framework to\nsystematically analyze embedding representations of relational tables.\nMotivated both by invariants of the relational data model and by statistical\nconsiderations regarding data distributions, we define eight primitive\nproperties, and corresponding measures to quantitatively characterize table\nembeddings for these properties. Based on these properties, we define an\nextensible framework to evaluate language and table embedding models. We\ncollect and synthesize a suite of datasets and use Observatory to analyze seven\nsuch models. Our analysis provides insights into the strengths and weaknesses\nof learned representations over tables. We find, for example, that some models\nare sensitive to table structure such as column order, that functional\ndependencies are rarely reflected in embeddings, and that specialized table\nembedding models have relatively lower sample fidelity. Such insights help\nresearchers and practitioners better anticipate model behaviors and select\nappropriate models for their downstream tasks, while guiding researchers in the\ndevelopment of new models.",
          "link": "http://arxiv.org/abs/2310.07736",
          "publishedOn": "2023-10-14T00:41:34.211Z",
          "wordCount": null,
          "title": "Observatory: Characterizing Embeddings of Relational Tables. (arXiv:2310.07736v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.12345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldwaser_A/0/1/0/all/0/1\">Adrian Goldwaser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1\">Hong Ge</a>",
          "description": "Larger and deeper networks generalise well despite their increased capacity\nto overfit. Understanding why this happens is theoretically and practically\nimportant. One recent approach looks at the infinitely wide limits of such\nnetworks and their corresponding kernels. However, these theoretical tools\ncannot fully explain finite networks as the empirical kernel changes\nsignificantly during gradient-descent-based training in contrast to infinite\nnetworks. In this work, we derive an iterative linearised training method as a\nnovel empirical tool to further investigate this distinction, allowing us to\ncontrol for sparse (i.e. infrequent) feature updates and quantify the frequency\nof feature learning needed to achieve comparable performance. We justify\niterative linearisation as an interpolation between a finite analog of the\ninfinite width regime, which does not learn features, and standard gradient\ndescent training, which does. Informally, we also show that it is analogous to\na damped version of the Gauss-Newton algorithm -- a second-order method. We\nshow that in a variety of cases, iterative linearised training surprisingly\nperforms on par with standard training, noting in particular how much less\nfrequent feature learning is required to achieve comparable performance. We\nalso show that feature learning is essential for good performance. Since such\nfeature learning inevitably causes changes in the NTK kernel, we provide direct\nnegative evidence for the NTK theory, which states the NTK kernel remains\nconstant during training.",
          "link": "http://arxiv.org/abs/2211.12345",
          "publishedOn": "2023-10-14T00:41:34.188Z",
          "wordCount": null,
          "title": "Understanding Sparse Feature Updates in Deep Networks using Iterative Linearisation. (arXiv:2211.12345v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08088",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozanec_J/0/1/0/all/0/1\">Jo&#x17e;e M. Ro&#x17e;anec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petelin_G/0/1/0/all/0/1\">Ga&#x161;per Petelin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_J/0/1/0/all/0/1\">Jo&#xe3;o Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertalanic_B/0/1/0/all/0/1\">Bla&#x17e; Bertalani&#x10d;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cerar_G/0/1/0/all/0/1\">Gregor Cerar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gucek_M/0/1/0/all/0/1\">Marko Gu&#x10d;ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papa_G/0/1/0/all/0/1\">Gregor Papa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mladenic_D/0/1/0/all/0/1\">Dunja Mladeni&#x107;</a>",
          "description": "In many cases, a machine learning model must learn to correctly predict a few\ndata points with particular values of interest in a broader range of data where\nmany target values are zero. Zero-inflated data can be found in diverse\nscenarios, such as lumpy and intermittent demands, power consumption for home\nappliances being turned on and off, impurities measurement in distillation\nprocesses, and even airport shuttle demand prediction. The presence of zeroes\naffects the models' learning and may result in poor performance. Furthermore,\nzeroes also distort the metrics used to compute the model's prediction quality.\nThis paper showcases two real-world use cases (home appliances classification\nand airport shuttle demand prediction) where a hierarchical model applied in\nthe context of zero-inflated data leads to excellent results. In particular,\nfor home appliances classification, the weighted average of Precision, Recall,\nF1, and AUC ROC was increased by 27%, 34%, 49%, and 27%, respectively.\nFurthermore, it is estimated that the proposed approach is also four times more\nenergy efficient than the SOTA approach against which it was compared to.\nTwo-fold models performed best in all cases when predicting airport shuttle\ndemand, and the difference against other models has been proven to be\nstatistically significant.",
          "link": "http://arxiv.org/abs/2310.08088",
          "publishedOn": "2023-10-14T00:41:34.153Z",
          "wordCount": 729,
          "title": "Dealing with zero-inflated data: achieving SOTA with a two-fold machine learning approach. (arXiv:2310.08088v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1\">Mauro Conti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farronato_N/0/1/0/all/0/1\">Nicola Farronato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koffas_S/0/1/0/all/0/1\">Stefanos Koffas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajola_L/0/1/0/all/0/1\">Luca Pajola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Picek_S/0/1/0/all/0/1\">Stjepan Picek</a>",
          "description": "Optical Character Recognition (OCR) is a widely used tool to extract text\nfrom scanned documents. Today, the state-of-the-art is achieved by exploiting\ndeep neural networks. However, the cost of this performance is paid at the\nprice of system vulnerability. For instance, in backdoor attacks, attackers\ncompromise the training phase by inserting a backdoor in the victim's model\nthat will be activated at testing time by specific patterns while leaving the\noverall model performance intact. This work proposes a backdoor attack for OCR\nresulting in the injection of non-readable characters from malicious input\nimages. This simple but effective attack exposes the state-of-the-art OCR\nweakness, making the extracted text correct to human eyes but simultaneously\nunusable for the NLP application that uses OCR as a preprocessing step.\nExperimental results show that the attacked models successfully output\nnon-readable characters for around 90% of the poisoned instances without\nharming their performance for the remaining instances.",
          "link": "http://arxiv.org/abs/2310.08259",
          "publishedOn": "2023-10-14T00:41:34.147Z",
          "wordCount": null,
          "title": "Invisible Threats: Backdoor Attack in OCR Systems. (arXiv:2310.08259v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.14432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yun Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yongchao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_S/0/1/0/all/0/1\">Suo Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Minghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1\">Chunyang Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Huanjun Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_L/0/1/0/all/0/1\">Lihong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinjie Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yixiang Mu</a>",
          "description": "We develop a novel framework that adds the regularizers of the sparse group\nlasso to a family of adaptive optimizers in deep learning, such as Momentum,\nAdagrad, Adam, AMSGrad, AdaHessian, and create a new class of optimizers, which\nare named Group Momentum, Group Adagrad, Group Adam, Group AMSGrad and Group\nAdaHessian, etc., accordingly. We establish theoretically proven convergence\nguarantees in the stochastic convex settings, based on primal-dual methods. We\nevaluate the regularized effect of our new optimizers on three large-scale\nreal-world ad click datasets with state-of-the-art deep learning models. The\nexperimental results reveal that compared with the original optimizers with the\npost-processing procedure which uses the magnitude pruning method, the\nperformance of the models can be significantly improved on the same sparsity\nlevel. Furthermore, in comparison to the cases without magnitude pruning, our\nmethods can achieve extremely high sparsity with significantly better or highly\ncompetitive performance. The code is available at\nhttps://github.com/intelligent-machine-learning/dlrover/blob/master/tfplus.",
          "link": "http://arxiv.org/abs/2107.14432",
          "publishedOn": "2023-10-14T00:41:34.132Z",
          "wordCount": 796,
          "title": "Adaptive Optimizers with Sparse Group Lasso for Neural Networks in CTR Prediction. (arXiv:2107.14432v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.11670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Everaert_D/0/1/0/all/0/1\">Dante Everaert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>",
          "description": "It is often advantageous to train models on a subset of the available train\nexamples, because the examples are of variable quality or because one would\nlike to train with fewer examples, without sacrificing performance. We present\nGradient Information Optimization (GIO), a scalable, task-agnostic approach to\nthis data selection problem that requires only a small set of (unlabeled)\nexamples representing a target distribution. GIO begins from a natural,\ninformation-theoretic objective that is intractable in practice. Our\ncontribution is in showing that it can be made highly scalable through a simple\nrelaxation of the objective and a highly efficient implementation. In\nexperiments with machine translation, spelling correction, and image\nrecognition, we show that GIO delivers outstanding results with very small\ntrain sets. These findings are robust to different representation models and\nhyperparameters for GIO itself. GIO is task- and domain-agnostic and can be\napplied out-of-the-box to new datasets and domains.",
          "link": "http://arxiv.org/abs/2306.11670",
          "publishedOn": "2023-10-14T00:41:34.120Z",
          "wordCount": null,
          "title": "GIO: Gradient Information Optimization for Training Dataset Selection. (arXiv:2306.11670v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07891",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Moniri_B/0/1/0/all/0/1\">Behrad Moniri</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_D/0/1/0/all/0/1\">Donghwan Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>",
          "description": "Feature learning is thought to be one of the fundamental reasons for the\nsuccess of deep neural networks. It is rigorously known that in two-layer\nfully-connected neural networks under certain conditions, one step of gradient\ndescent on the first layer followed by ridge regression on the second layer can\nlead to feature learning; characterized by the appearance of a separated\nrank-one component -- spike -- in the spectrum of the feature matrix. However,\nwith a constant gradient descent step size, this spike only carries information\nfrom the linear component of the target function and therefore learning\nnon-linear components is impossible. We show that with a learning rate that\ngrows with the sample size, such training in fact introduces multiple rank-one\ncomponents, each corresponding to a specific polynomial feature. We further\nprove that the limiting large-dimensional and large sample training and test\nerrors of the updated neural networks are fully characterized by these spikes.\nBy precisely analyzing the improvement in the loss, we demonstrate that these\nnon-linear features can enhance learning.",
          "link": "http://arxiv.org/abs/2310.07891",
          "publishedOn": "2023-10-14T00:41:34.119Z",
          "wordCount": null,
          "title": "A Theory of Non-Linear Feature Learning with One Gradient Step in Two-Layer Neural Networks. (arXiv:2310.07891v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08041",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ruihao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiuying Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zhiwei Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jianfei Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1\">Bohan Zhuang</a>",
          "description": "Large Language Models (LLMs) excel in NLP, but their demands hinder their\nwidespread deployment. While Quantization-Aware Training (QAT) offers a\nsolution, its extensive training costs make Post-Training Quantization (PTQ) a\nmore practical approach for LLMs. In existing studies, activation outliers in\nparticular channels are identified as the bottleneck to PTQ accuracy. They\npropose to transform the magnitudes from activations to weights, which however\noffers limited alleviation or suffers from unstable gradients, resulting in a\nsevere performance drop at low-bitwidth. In this paper, we propose QLLM, an\naccurate and efficient low-bitwidth PTQ method designed for LLMs. QLLM\nintroduces an adaptive channel reassembly technique that reallocates the\nmagnitude of outliers to other channels, thereby mitigating their impact on the\nquantization range. This is achieved by channel disassembly and channel\nassembly, which first breaks down the outlier channels into several\nsub-channels to ensure a more balanced distribution of activation magnitudes.\nThen similar channels are merged to maintain the original channel number for\nefficiency. Additionally, an adaptive strategy is designed to autonomously\ndetermine the optimal number of sub-channels for channel disassembly. To\nfurther compensate for the performance loss caused by quantization, we propose\nan efficient tuning method that only learns a small number of low-rank weights\nwhile freezing the pre-trained quantized model. After training, these low-rank\nparameters can be fused into the frozen weights without affecting inference.\nExtensive experiments on LLaMA-1 and LLaMA-2 show that QLLM can obtain accurate\nquantized models efficiently. For example, QLLM quantizes the 4-bit LLaMA-2-70B\nwithin 10 hours on a single A100-80G GPU, outperforming the previous\nstate-of-the-art method by 7.89% on the average accuracy across five zero-shot\ntasks.",
          "link": "http://arxiv.org/abs/2310.08041",
          "publishedOn": "2023-10-14T00:41:34.110Z",
          "wordCount": 782,
          "title": "QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models. (arXiv:2310.08041v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vijayan_P/0/1/0/all/0/1\">Preetha Vijayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_P/0/1/0/all/0/1\">Prashant Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1\">Elahe Arani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1\">Bahram Zonooz</a>",
          "description": "Continual learning (CL) has remained a persistent challenge for deep neural\nnetworks due to catastrophic forgetting (CF) of previously learned tasks.\nSeveral techniques such as weight regularization, experience rehearsal, and\nparameter isolation have been proposed to alleviate CF. Despite their relative\nsuccess, these research directions have predominantly remained orthogonal and\nsuffer from several shortcomings, while missing out on the advantages of\ncompeting strategies. On the contrary, the brain continually learns,\naccommodates, and transfers knowledge across tasks by simultaneously leveraging\nseveral neurophysiological processes, including neurogenesis, active\nforgetting, neuromodulation, metaplasticity, experience rehearsal, and\ncontext-dependent gating, rarely resulting in CF. Inspired by how the brain\nexploits multiple mechanisms concurrently, we propose TriRE, a novel CL\nparadigm that encompasses retaining the most prominent neurons for each task,\nrevising and solidifying the extracted knowledge of current and past tasks, and\nactively promoting less active neurons for subsequent tasks through rewinding\nand relearning. Across CL settings, TriRE significantly reduces task\ninterference and surpasses different CL approaches considered in isolation.",
          "link": "http://arxiv.org/abs/2310.08217",
          "publishedOn": "2023-10-14T00:41:34.084Z",
          "wordCount": 690,
          "title": "TriRE: A Multi-Mechanism Learning Paradigm for Continual Knowledge Retention and Promotion. (arXiv:2310.08217v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Floris_G/0/1/0/all/0/1\">Giuseppe Floris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mura_R/0/1/0/all/0/1\">Raffaele Mura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scionis_L/0/1/0/all/0/1\">Luca Scionis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piras_G/0/1/0/all/0/1\">Giorgio Piras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1\">Maura Pintor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demontis_A/0/1/0/all/0/1\">Ambra Demontis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1\">Battista Biggio</a>",
          "description": "Evaluating the adversarial robustness of machine learning models using\ngradient-based attacks is challenging. In this work, we show that\nhyperparameter optimization can improve fast minimum-norm attacks by automating\nthe selection of the loss function, the optimizer and the step-size scheduler,\nalong with the corresponding hyperparameters. Our extensive evaluation\ninvolving several robust models demonstrates the improved efficacy of fast\nminimum-norm attacks when hyper-up with hyperparameter optimization. We release\nour open-source code at https://github.com/pralab/HO-FMN.",
          "link": "http://arxiv.org/abs/2310.08177",
          "publishedOn": "2023-10-14T00:41:34.048Z",
          "wordCount": 599,
          "title": "Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization. (arXiv:2310.08177v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.10108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inae_E/0/1/0/all/0/1\">Eric Inae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiaxin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1\">Tengfei Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>",
          "description": "Graph property prediction tasks are important and numerous. While each task\noffers a small size of labeled examples, unlabeled graphs have been collected\nfrom various sources and at a large scale. A conventional approach is training\na model with the unlabeled graphs on self-supervised tasks and then fine-tuning\nthe model on the prediction tasks. However, the self-supervised task knowledge\ncould not be aligned or sometimes conflicted with what the predictions needed.\nIn this paper, we propose to extract the knowledge underlying the large set of\nunlabeled graphs as a specific set of useful data points to augment each\nproperty prediction model. We use a diffusion model to fully utilize the\nunlabeled graphs and design two new objectives to guide the model's denoising\nprocess with each task's labeled data to generate task-specific graph examples\nand their labels. Experiments demonstrate that our data-centric approach\nperforms significantly better than fifteen existing various methods on fifteen\ntasks. The performance improvement brought by unlabeled data is visible as the\ngenerated labeled examples unlike the self-supervised learning.",
          "link": "http://arxiv.org/abs/2303.10108",
          "publishedOn": "2023-10-14T00:41:34.042Z",
          "wordCount": 698,
          "title": "Data-Centric Learning from Unlabeled Graphs with Diffusion Model. (arXiv:2303.10108v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1908.04628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xindi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varol_O/0/1/0/all/0/1\">Onur Varol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1\">Tina Eliassi-Rad</a>",
          "description": "Many real-world prediction tasks have outcome variables that have\ncharacteristic heavy-tail distributions. Examples include copies of books sold,\nauction prices of art pieces, demand for commodities in warehouses, etc. By\nlearning heavy-tailed distributions, \"big and rare\" instances (e.g., the\nbest-sellers) will have accurate predictions. Most existing approaches are not\ndedicated to learning heavy-tailed distribution; thus, they heavily\nunder-predict such instances. To tackle this problem, we introduce Learning to\nPlace (L2P), which exploits the pairwise relationships between instances for\nlearning. In its training phase, L2P learns a pairwise preference classifier:\nis instance A > instance B? In its placing phase, L2P obtains a prediction by\nplacing the new instance among the known instances. Based on its placement, the\nnew instance is then assigned a value for its outcome variable. Experiments on\nreal data show that L2P outperforms competing approaches in terms of accuracy\nand ability to reproduce heavy-tailed outcome distribution. In addition, L2P\nprovides an interpretable model by placing each predicted instance in relation\nto its comparable neighbors. Interpretable models are highly desirable when\nlives and treasure are at stake.",
          "link": "http://arxiv.org/abs/1908.04628",
          "publishedOn": "2023-10-14T00:41:34.034Z",
          "wordCount": null,
          "title": "L2P: Learning to Place for Estimating Heavy-Tailed Distributed Outcomes. (arXiv:1908.04628v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08061",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Yi_Y/0/1/0/all/0/1\">Yiqiang Yi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wan_X/0/1/0/all/0/1\">Xu Wan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bian_Y/0/1/0/all/0/1\">Yatao Bian</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ou_Yang_L/0/1/0/all/0/1\">Le Ou-Yang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_P/0/1/0/all/0/1\">Peilin Zhao</a>",
          "description": "Predicting the docking between proteins and ligands is a crucial and\nchallenging task for drug discovery. However, traditional docking methods\nmainly rely on scoring functions, and deep learning-based docking approaches\nusually neglect the 3D spatial information of proteins and ligands, as well as\nthe graph-level features of ligands, which limits their performance. To address\nthese limitations, we propose an equivariant transformer neural network for\nprotein-ligand docking pose prediction. Our approach involves the fusion of\nligand graph-level features by feature processing, followed by the learning of\nligand and protein representations using our proposed TAMformer module.\nAdditionally, we employ an iterative optimization approach based on the\npredicted distance matrix to generate refined ligand poses. The experimental\nresults on real datasets show that our model can achieve state-of-the-art\nperformance.",
          "link": "http://arxiv.org/abs/2310.08061",
          "publishedOn": "2023-10-14T00:41:34.027Z",
          "wordCount": 625,
          "title": "ETDock: A Novel Equivariant Transformer for Protein-Ligand Docking. (arXiv:2310.08061v1 [q-bio.BM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rasul_K/0/1/0/all/0/1\">Kashif Rasul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashok_A/0/1/0/all/0/1\">Arjun Ashok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Andrew Robert Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khorasani_A/0/1/0/all/0/1\">Arian Khorasani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adamopoulos_G/0/1/0/all/0/1\">George Adamopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagwatkar_R/0/1/0/all/0/1\">Rishika Bhagwatkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilos_M/0/1/0/all/0/1\">Marin Bilo&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghonia_H/0/1/0/all/0/1\">Hena Ghonia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassen_N/0/1/0/all/0/1\">Nadhir Vincent Hassen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_A/0/1/0/all/0/1\">Anderson Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Sahil Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drouin_A/0/1/0/all/0/1\">Alexandre Drouin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapados_N/0/1/0/all/0/1\">Nicolas Chapados</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nevmyvaka_Y/0/1/0/all/0/1\">Yuriy Nevmyvaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>",
          "description": "Aiming to build foundation models for time-series forecasting and study their\nscaling behavior, we present here our work-in-progress on Lag-Llama, a\ngeneral-purpose univariate probabilistic time-series forecasting model trained\non a large collection of time-series data. The model shows good zero-shot\nprediction capabilities on unseen \"out-of-distribution\" time-series datasets,\noutperforming supervised baselines. We use smoothly broken power-laws to fit\nand predict model scaling behavior. The open source code is made available at\nhttps://github.com/kashif/pytorch-transformer-ts.",
          "link": "http://arxiv.org/abs/2310.08278",
          "publishedOn": "2023-10-14T00:41:34.021Z",
          "wordCount": null,
          "title": "Lag-Llama: Towards Foundation Models for Time Series Forecasting. (arXiv:2310.08278v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08039",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jinbo Song</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ruoran Huang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyang Wang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qian Yu</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingming Chen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yafei Yao</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chaosheng Fan</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1\">Changping Peng</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhangang Lin</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jinghe Hu</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1\">Jingping Shao</a> (1) ((1) Marketing and Commercialization Center, JD.com)",
          "description": "Industrial systems such as recommender systems and online advertising, have\nbeen widely equipped with multi-stage architectures, which are divided into\nseveral cascaded modules, including matching, pre-ranking, ranking and\nre-ranking. As a critical bridge between matching and ranking, existing\npre-ranking approaches mainly endure sample selection bias (SSB) problem owing\nto ignoring the entire-chain data dependence, resulting in sub-optimal\nperformances. In this paper, we rethink pre-ranking system from the perspective\nof the entire sample space, and propose Entire-chain Cross-domain Models (ECM),\nwhich leverage samples from the whole cascaded stages to effectively alleviate\nSSB problem. Besides, we design a fine-grained neural structure named ECMM to\nfurther improve the pre-ranking accuracy. Specifically, we propose a\ncross-domain multi-tower neural network to comprehensively predict for each\nstage result, and introduce the sub-networking routing strategy with $L0$\nregularization to reduce computational costs. Evaluations on real-world\nlarge-scale traffic logs demonstrate that our pre-ranking models outperform\nSOTA methods while time consumption is maintained within an acceptable level,\nwhich achieves better trade-off between efficiency and effectiveness.",
          "link": "http://arxiv.org/abs/2310.08039",
          "publishedOn": "2023-10-14T00:41:33.997Z",
          "wordCount": null,
          "title": "Rethinking Large-scale Pre-ranking System: Entire-chain Cross-domain Models. (arXiv:2310.08039v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08348",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Niu_Y/0/1/0/all/0/1\">Yazhe Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1\">Yuan Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhenjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xueyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jiyuan Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shuai Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu Liu</a>",
          "description": "Building agents based on tree-search planning capabilities with learned\nmodels has achieved remarkable success in classic decision-making problems,\nsuch as Go and Atari. However, it has been deemed challenging or even\ninfeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse\nreal-world applications, especially when these environments involve complex\naction spaces and significant simulation costs, or inherent stochasticity. In\nthis work, we introduce LightZero, the first unified benchmark for deploying\nMCTS/MuZero in general sequential decision scenarios. Specificially, we\nsummarize the most critical challenges in designing a general MCTS-style\ndecision-making solver, then decompose the tightly-coupled algorithm and system\ndesign of tree-search RL methods into distinct sub-modules. By incorporating\nmore appropriate exploration and optimization strategies, we can significantly\nenhance these sub-modules and construct powerful LightZero agents to tackle\ntasks across a wide range of domains, such as board games, Atari, MuJoCo,\nMiniGrid and GoBigger. Detailed benchmark results reveal the significant\npotential of such methods in building scalable and efficient decision\nintelligence. The code is available as part of OpenDILab at\nhttps://github.com/opendilab/LightZero.",
          "link": "http://arxiv.org/abs/2310.08348",
          "publishedOn": "2023-10-14T00:41:33.996Z",
          "wordCount": 711,
          "title": "LightZero: A Unified Benchmark for Monte Carlo Tree Search in General Sequential Decision Scenarios. (arXiv:2310.08348v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jihye Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tople_S/0/1/0/all/0/1\">Shruti Tople</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrasekaran_V/0/1/0/all/0/1\">Varun Chandrasekaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Somesh Jha</a>",
          "description": "Membership Inference Attacks (MIAs) aim to identify specific data samples\nwithin the private training dataset of machine learning models, leading to\nserious privacy violations and other sophisticated threats. Many practical\nblack-box MIAs require query access to the data distribution (the same\ndistribution where the private data is drawn) to train shadow models. By doing\nso, the adversary obtains models trained \"with\" or \"without\" samples drawn from\nthe distribution, and analyzes the characteristics of the samples under\nconsideration. The adversary is often required to train more than hundreds of\nshadow models to extract the signals needed for MIAs; this becomes the\ncomputational overhead of MIAs. In this paper, we propose that by strategically\nchoosing the samples, MI adversaries can maximize their attack success while\nminimizing the number of shadow models. First, our motivational experiments\nsuggest memorization as the key property explaining disparate sample\nvulnerability to MIAs. We formalize this through a theoretical bound that\nconnects MI advantage with memorization. Second, we show sample complexity\nbounds that connect the number of shadow models needed for MIAs with\nmemorization. Lastly, we confirm our theoretical arguments with comprehensive\nexperiments; by utilizing samples with high memorization scores, the adversary\ncan (a) significantly improve its efficacy regardless of the MIA used, and (b)\nreduce the number of shadow models by nearly two orders of magnitude compared\nto state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2310.08015",
          "publishedOn": "2023-10-14T00:41:33.989Z",
          "wordCount": 738,
          "title": "Why Train More? Effective and Efficient Membership Inference via Memorization. (arXiv:2310.08015v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaopeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_Z/0/1/0/all/0/1\">Zhenlin An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Q/0/1/0/all/0/1\">Qingrui Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lei Yang</a>",
          "description": "Although Maxwell discovered the physical laws of electromagnetic waves 160\nyears ago, how to precisely model the propagation of an RF signal in an\nelectrically large and complex environment remains a long-standing problem. The\ndifficulty is in the complex interactions between the RF signal and the\nobstacles (e.g., reflection, diffraction, etc.). Inspired by the great success\nof using a neural network to describe the optical field in computer vision, we\npropose a neural radio-frequency radiance field, NeRF$^\\textbf{2}$, which\nrepresents a continuous volumetric scene function that makes sense of an RF\nsignal's propagation. Particularly, after training with a few signal\nmeasurements, NeRF$^\\textbf{2}$ can tell how/what signal is received at any\nposition when it knows the position of a transmitter. As a physical-layer\nneural network, NeRF$^\\textbf{2}$ can take advantage of the learned statistic\nmodel plus the physical model of ray tracing to generate a synthetic dataset\nthat meets the training demands of application-layer artificial neural networks\n(ANNs). Thus, we can boost the performance of ANNs by the proposed\nturbo-learning, which mixes the true and synthetic datasets to intensify the\ntraining. Our experiment results show that turbo-learning can enhance\nperformance with an approximate 50% increase. We also demonstrate the power of\nNeRF$^\\textbf{2}$ in the field of indoor localization and 5G MIMO.",
          "link": "http://arxiv.org/abs/2305.06118",
          "publishedOn": "2023-10-14T00:41:33.989Z",
          "wordCount": null,
          "title": "NeRF2: Neural Radio-Frequency Radiance Fields. (arXiv:2305.06118v2 [cs.NI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.07481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brekelmans_R/0/1/0/all/0/1\">Rob Brekelmans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1\">Frank Nielsen</a>",
          "description": "Markov Chain Monte Carlo methods for sampling from complex distributions and\nestimating normalization constants often simulate samples from a sequence of\nintermediate distributions along an annealing path, which bridges between a\ntractable initial distribution and a target density of interest. Prior work has\nconstructed annealing paths using quasi-arithmetic means, and interpreted the\nresulting intermediate densities as minimizing an expected divergence to the\nendpoints. We provide a comprehensive analysis of this 'centroid' property\nusing Bregman divergences under a monotonic embedding of the density function,\nthereby associating common divergences such as Amari's and Renyi's\n${\\alpha}$-divergences, ${(\\alpha,\\beta)}$-divergences, and the Jensen-Shannon\ndivergence with intermediate densities along an annealing path. Our analysis\nhighlights the interplay between parametric families, quasi-arithmetic means,\nand divergence functions using the rho-tau Bregman divergence framework of\nZhang 2004,2013.",
          "link": "http://arxiv.org/abs/2209.07481",
          "publishedOn": "2023-10-14T00:41:33.978Z",
          "wordCount": null,
          "title": "Quasi-Arithmetic Mixtures, Divergence Minimization, and Bregman Information. (arXiv:2209.07481v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.12389",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalluri_T/0/1/0/all/0/1\">Tarun Kalluri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Astuti Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandraker_M/0/1/0/all/0/1\">Manmohan Chandraker</a>",
          "description": "Practical real world datasets with plentiful categories introduce new\nchallenges for unsupervised domain adaptation like small inter-class\ndiscriminability, that existing approaches relying on domain invariance alone\ncannot handle sufficiently well. In this work we propose MemSAC, which exploits\nsample level similarity across source and target domains to achieve\ndiscriminative transfer, along with architectures that scale to a large number\nof categories. For this purpose, we first introduce a memory augmented approach\nto efficiently extract pairwise similarity relations between labeled source and\nunlabeled target domain instances, suited to handle an arbitrary number of\nclasses. Next, we propose and theoretically justify a novel variant of the\ncontrastive loss to promote local consistency among within-class cross domain\nsamples while enforcing separation between classes, thus preserving\ndiscriminative transfer from source to target. We validate the advantages of\nMemSAC with significant improvements over previous state-of-the-art on multiple\nchallenging transfer tasks designed for large-scale adaptation, such as\nDomainNet with 345 classes and fine-grained adaptation on Caltech-UCSD birds\ndataset with 200 classes. We also provide in-depth analysis and insights into\nthe effectiveness of MemSAC.",
          "link": "http://arxiv.org/abs/2207.12389",
          "publishedOn": "2023-10-14T00:41:33.948Z",
          "wordCount": null,
          "title": "MemSAC: Memory Augmented Sample Consistency for Large Scale Unsupervised Domain Adaptation. (arXiv:2207.12389v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1\">Jiali Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Tian Han</a>",
          "description": "This paper studies the fundamental problem of learning multi-layer generator\nmodels. The multi-layer generator model builds multiple layers of latent\nvariables as a prior model on top of the generator, which benefits learning\ncomplex data distribution and hierarchical representations. However, such a\nprior model usually focuses on modeling inter-layer relations between latent\nvariables by assuming non-informative (conditional) Gaussian distributions,\nwhich can be limited in model expressivity. To tackle this issue and learn more\nexpressive prior models, we propose an energy-based model (EBM) on the joint\nlatent space over all layers of latent variables with the multi-layer generator\nas its backbone. Such joint latent space EBM prior model captures the\nintra-layer contextual relations at each layer through layer-wise energy terms,\nand latent variables across different layers are jointly corrected. We develop\na joint training scheme via maximum likelihood estimation (MLE), which involves\nMarkov Chain Monte Carlo (MCMC) sampling for both prior and posterior\ndistributions of the latent variables from different layers. To ensure\nefficient inference and learning, we further propose a variational training\nscheme where an inference model is used to amortize the costly posterior MCMC\nsampling. Our experiments demonstrate that the learned model can be expressive\nin generating high-quality images and capturing hierarchical features for\nbetter outlier detection.",
          "link": "http://arxiv.org/abs/2306.06323",
          "publishedOn": "2023-10-14T00:41:33.934Z",
          "wordCount": 737,
          "title": "Learning Joint Latent Space EBM Prior Model for Multi-layer Generator. (arXiv:2306.06323v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Werner_J/0/1/0/all/0/1\">Julia Werner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerum_C/0/1/0/all/0/1\">Christoph Gerum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reiber_M/0/1/0/all/0/1\">Moritz Reiber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nick_J/0/1/0/all/0/1\">J&#xf6;rg Nick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bringmann_O/0/1/0/all/0/1\">Oliver Bringmann</a>",
          "description": "This paper presents a method to efficiently classify the gastroenterologic\nsection of images derived from Video Capsule Endoscopy (VCE) studies by\nexploring the combination of a Convolutional Neural Network (CNN) for\nclassification with the time-series analysis properties of a Hidden Markov\nModel (HMM). It is demonstrated that successive time-series analysis identifies\nand corrects errors in the CNN output. Our approach achieves an accuracy of\n$98.04\\%$ on the Rhode Island (RI) Gastroenterology dataset. This allows for\nprecise localization within the gastrointestinal (GI) tract while requiring\nonly approximately 1M parameters and thus, provides a method suitable for low\npower devices",
          "link": "http://arxiv.org/abs/2310.07895",
          "publishedOn": "2023-10-14T00:41:33.907Z",
          "wordCount": 639,
          "title": "Precise localization within the GI tract by combining classification of CNNs and time-series analysis of HMMs. (arXiv:2310.07895v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.03874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joren_H/0/1/0/all/0/1\">Hailey Joren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1\">Chirag Nagpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_K/0/1/0/all/0/1\">Katherine Heller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ustun_B/0/1/0/all/0/1\">Berk Ustun</a>",
          "description": "Machine learning models are often personalized with information that is\nprotected, sensitive, self-reported, or costly to acquire. These models use\ninformation about people but do not facilitate nor inform their consent.\nIndividuals cannot opt out of reporting personal information to a model, nor\ntell if they benefit from personalization in the first place. We introduce a\nfamily of classification models, called participatory systems, that let\nindividuals opt into personalization at prediction time. We present a\nmodel-agnostic algorithm to learn participatory systems for personalization\nwith categorical group attributes. We conduct a comprehensive empirical study\nof participatory systems in clinical prediction tasks, benchmarking them with\ncommon approaches for personalization and imputation. Our results demonstrate\nthat participatory systems can facilitate and inform consent while improving\nperformance and data use across all groups who report personal data.",
          "link": "http://arxiv.org/abs/2302.03874",
          "publishedOn": "2023-10-14T00:41:33.783Z",
          "wordCount": null,
          "title": "Participatory Personalization in Classification. (arXiv:2302.03874v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.10902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhanglu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shida Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Kaiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_W/0/1/0/all/0/1\">Weng-Fai Wong</a>",
          "description": "Hyperdimensional computing (HDC) is a method to perform classification that\nuses binary vectors with high dimensions and the majority rule. This approach\nhas the potential to be energy-efficient and hence deemed suitable for\nresource-limited platforms due to its simplicity and massive parallelism.\nHowever, in order to achieve high accuracy, HDC sometimes uses hypervectors\nwith tens of thousands of dimensions. This potentially negates its efficiency\nadvantage. In this paper, we examine the necessity of such high dimensions and\nconduct a detailed theoretical analysis of the relationship between hypervector\ndimensions and accuracy. Our results demonstrate that as the dimension of the\nhypervectors increases, the worst-case/average-case HDC prediction accuracy\nwith the majority rule decreases. Building on this insight, we develop HDC\nmodels that use binary hypervectors with dimensions orders of magnitude lower\nthan those of state-of-the-art HDC models while maintaining equivalent or even\nimproved accuracy and efficiency. For instance, on the MNIST dataset, we\nachieve 91.12% HDC accuracy in image classification with a dimension of only\n64. Our methods perform operations that are only 0.35% of other HDC models with\ndimensions of 10,000. Furthermore, we evaluate our methods on ISOLET, UCI-HAR,\nand Fashion-MNIST datasets and investigate the limits of HDC computing.",
          "link": "http://arxiv.org/abs/2301.10902",
          "publishedOn": "2023-10-14T00:41:33.736Z",
          "wordCount": 732,
          "title": "Efficient Hyperdimensional Computing. (arXiv:2301.10902v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gholami_S/0/1/0/all/0/1\">Sia Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omar_M/0/1/0/all/0/1\">Marwan Omar</a>",
          "description": "Natural Language Processing (NLP) has undergone transformative changes with\nthe advent of deep learning methodologies. One challenge persistently\nconfronting researchers is the scarcity of high-quality, annotated datasets\nthat drive these models. This paper explores the nuances of synthetic data\ngeneration in NLP, with a focal point on template-based question generation. By\nassessing its advantages, including data augmentation potential and the\nintroduction of structured variety, we juxtapose these benefits against\ninherent limitations, such as the risk of overfitting and the constraints posed\nby pre-defined templates. Drawing from empirical evaluations, we demonstrate\nthe impact of template-based synthetic data on the performance of modern\ntransformer models. We conclude by emphasizing the delicate balance required\nbetween synthetic and real-world data, and the future trajectories of\nintegrating synthetic data in model training pipelines. The findings aim to\nguide NLP practitioners in harnessing synthetic data's potential, ensuring\noptimal model performance in diverse applications.",
          "link": "http://arxiv.org/abs/2310.07830",
          "publishedOn": "2023-10-14T00:41:33.731Z",
          "wordCount": 649,
          "title": "Does Synthetic Data Make Large Language Models More Efficient?. (arXiv:2310.07830v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07740",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Baumstark_M/0/1/0/all/0/1\">Matthew J. Baumstark</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Vinci_G/0/1/0/all/0/1\">Giuseppe Vinci</a>",
          "description": "The classification of galaxy morphologies is an important step in the\ninvestigation of theories of hierarchical structure formation. While human\nexpert visual classification remains quite effective and accurate, it cannot\nkeep up with the massive influx of data from emerging sky surveys. A variety of\napproaches have been proposed to classify large numbers of galaxies; these\napproaches include crowdsourced visual classification, and automated and\ncomputational methods, such as machine learning methods based on designed\nmorphology statistics and deep learning. In this work, we develop two novel\ngalaxy morphology statistics, descent average and descent variance, which can\nbe efficiently extracted from telescope galaxy images. We further propose\nsimplified versions of the existing image statistics concentration, asymmetry,\nand clumpiness, which have been widely used in the literature of galaxy\nmorphologies. We utilize the galaxy image data from the Sloan Digital Sky\nSurvey to demonstrate the effective performance of our proposed image\nstatistics at accurately detecting spiral and elliptical galaxies when used as\nfeatures of a random forest classifier.",
          "link": "http://arxiv.org/abs/2310.07740",
          "publishedOn": "2023-10-14T00:41:33.667Z",
          "wordCount": 696,
          "title": "Spiral-Elliptical automated galaxy morphology classification from telescope images. (arXiv:2310.07740v1 [astro-ph.IM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weng_E/0/1/0/all/0/1\">Erica Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoshino_H/0/1/0/all/0/1\">Hana Hoshino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1\">Deva Ramanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1\">Kris Kitani</a>",
          "description": "Multi-modal trajectory forecasting methods commonly evaluate using\nsingle-agent metrics (marginal metrics), such as minimum Average Displacement\nError (ADE) and Final Displacement Error (FDE), which fail to capture joint\nperformance of multiple interacting agents. Only focusing on marginal metrics\ncan lead to unnatural predictions, such as colliding trajectories or diverging\ntrajectories for people who are clearly walking together as a group.\nConsequently, methods optimized for marginal metrics lead to overly-optimistic\nestimations of performance, which is detrimental to progress in trajectory\nforecasting research. In response to the limitations of marginal metrics, we\npresent the first comprehensive evaluation of state-of-the-art (SOTA)\ntrajectory forecasting methods with respect to multi-agent metrics (joint\nmetrics): JADE, JFDE, and collision rate. We demonstrate the importance of\njoint metrics as opposed to marginal metrics with quantitative evidence and\nqualitative examples drawn from the ETH / UCY and Stanford Drone datasets. We\nintroduce a new loss function incorporating joint metrics that, when applied to\na SOTA trajectory forecasting method, achieves a 7\\% improvement in JADE / JFDE\non the ETH / UCY datasets with respect to the previous SOTA. Our results also\nindicate that optimizing for joint metrics naturally leads to an improvement in\ninteraction modeling, as evidenced by a 16\\% decrease in mean collision rate on\nthe ETH / UCY datasets with respect to the previous SOTA. Code is available at\n\\texttt{\\hyperlink{https://github.com/ericaweng/joint-metrics-matter}{github.com/ericaweng/joint-metrics-matter}}.",
          "link": "http://arxiv.org/abs/2305.06292",
          "publishedOn": "2023-10-14T00:41:33.655Z",
          "wordCount": 752,
          "title": "Joint Metrics Matter: A Better Standard for Trajectory Forecasting. (arXiv:2305.06292v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alkassab_N/0/1/0/all/0/1\">Nawras Alkassab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chin-Tser Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Botran_T/0/1/0/all/0/1\">Tania Lorido Botran</a>",
          "description": "Content Delivery Networks carry the majority of Internet traffic, and the\nincreasing demand for video content as a major IP traffic across the Internet\nhighlights the importance of caching and prefetching optimization algorithms.\nPrefetching aims to make data available in the cache before the requester\nplaces its request to reduce access time and improve the Quality of Experience\non the user side. Prefetching is well investigated in operating systems,\ncompiler instructions, in-memory cache, local storage systems, high-speed\nnetworks, and cloud systems. Traditional prefetching techniques are well\nadapted to a particular access pattern, but fail to adapt to sudden variations\nor randomization in workloads. This paper explores the use of reinforcement\nlearning to tackle the changes in user access patterns and automatically adapt\nover time. To this end, we propose, DeePref, a Deep Reinforcement Learning\nagent for online video content prefetching in Content Delivery Networks.\nDeePref is a prefetcher implemented on edge networks and is agnostic to\nhardware design, operating systems, and applications. Our results show that\nDeePref DRQN, using a real-world dataset, achieves a 17% increase in\nprefetching accuracy and a 28% increase in prefetching coverage on average\ncompared to baseline approaches that use video content popularity as a building\nblock to statically or dynamically make prefetching decisions. We also study\nthe possibility of transfer learning of statistical models from one edge\nnetwork into another, where unseen user requests from unknown distribution are\nobserved. In terms of transfer learning, the increase in prefetching accuracy\nand prefetching coverage are [$30%$, $10%$], respectively. Our source code will\nbe available on Github.",
          "link": "http://arxiv.org/abs/2310.07881",
          "publishedOn": "2023-10-14T00:41:33.650Z",
          "wordCount": 774,
          "title": "DeePref: Deep Reinforcement Learning For Video Prefetching In Content Delivery Networks. (arXiv:2310.07881v1 [cs.NI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zheqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yueyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_X/0/1/0/all/0/1\">Xu Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Real-world applications of contextual bandits often exhibit non-stationarity\ndue to seasonality, serendipity, and evolving social trends. While a number of\nnon-stationary contextual bandit learning algorithms have been proposed in the\nliterature, they excessively explore due to a lack of prioritization for\ninformation of enduring value, or are designed in ways that do not scale in\nmodern applications with high-dimensional user-specific features and large\naction set, or both. In this paper, we introduce a novel non-stationary\ncontextual bandit algorithm that addresses these concerns. It combines a\nscalable, deep-neural-network-based architecture with a carefully designed\nexploration mechanism that strategically prioritizes collecting information\nwith the most lasting value in a non-stationary environment. Through empirical\nevaluations on two real-world recommendation datasets, which exhibit pronounced\nnon-stationarity, we demonstrate that our approach significantly outperforms\nthe state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2310.07786",
          "publishedOn": "2023-10-14T00:41:33.646Z",
          "wordCount": 639,
          "title": "Non-Stationary Contextual Bandit Learning via Neural Predictive Ensemble Sampling. (arXiv:2310.07786v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08138",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haiyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chunjiang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Detian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qing Li</a>",
          "description": "Traffic flow prediction is one of the most fundamental tasks of intelligent\ntransportation systems. The complex and dynamic spatial-temporal dependencies\nmake the traffic flow prediction quite challenging. Although existing\nspatial-temporal graph neural networks hold prominent, they often encounter\nchallenges such as (1) ignoring the fixed graph that limits the predictive\nperformance of the model, (2) insufficiently capturing complex spatial-temporal\ndependencies simultaneously, and (3) lacking attention to spatial-temporal\ninformation at different time lengths. In this paper, we propose a Multi-Scale\nSpatial-Temporal Recurrent Network for traffic flow prediction, namely MSSTRN,\nwhich consists of two different recurrent neural networks: the single-step gate\nrecurrent unit and the multi-step gate recurrent unit to fully capture the\ncomplex spatial-temporal information in the traffic data under different time\nwindows. Moreover, we propose a spatial-temporal synchronous attention\nmechanism that integrates adaptive position graph convolutions into the\nself-attention mechanism to achieve synchronous capture of spatial-temporal\ndependencies. We conducted extensive experiments on four real traffic datasets\nand demonstrated that our model achieves the best prediction accuracy with\nnon-trivial margins compared to all the twenty baseline methods.",
          "link": "http://arxiv.org/abs/2310.08138",
          "publishedOn": "2023-10-14T00:41:33.615Z",
          "wordCount": 682,
          "title": "Multi-Scale Spatial-Temporal Recurrent Networks for Traffic Flow Prediction. (arXiv:2310.08138v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_N/0/1/0/all/0/1\">Namiko Matsumoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>",
          "description": "In 1-bit compressed sensing, the aim is to estimate a $k$-sparse unit vector\n$x\\in S^{n-1}$ within an $\\epsilon$ error (in $\\ell_2$) from minimal number of\nlinear measurements that are quantized to just their signs, i.e., from\nmeasurements of the form $y = \\mathrm{Sign}(\\langle a, x\\rangle).$ In this\npaper, we study a noisy version where a fraction of the measurements can be\nflipped, potentially by an adversary. In particular, we analyze the Binary\nIterative Hard Thresholding (BIHT) algorithm, a proximal gradient descent on a\nproperly defined loss function used for 1-bit compressed sensing, in this noisy\nsetting. It is known from recent results that, with\n$\\tilde{O}(\\frac{k}{\\epsilon})$ noiseless measurements, BIHT provides an\nestimate within $\\epsilon$ error. This result is optimal and universal, meaning\none set of measurements work for all sparse vectors. In this paper, we show\nthat BIHT also provides better results than all known methods for the noisy\nsetting. We show that when up to $\\tau$-fraction of the sign measurements are\nincorrect (adversarial error), with the same number of measurements as before,\nBIHT agnostically provides an estimate of $x$ within an\n$\\tilde{O}(\\epsilon+\\tau)$ error, maintaining the universality of measurements.\nThis establishes stability of iterative hard thresholding in the presence of\nmeasurement error. To obtain the result, we use the restricted approximate\ninvertibility of Gaussian matrices, as well as a tight analysis of the\nhigh-dimensional geometry of the adversarially corrupted measurements.",
          "link": "http://arxiv.org/abs/2310.08019",
          "publishedOn": "2023-10-14T00:41:33.573Z",
          "wordCount": 753,
          "title": "Robust 1-bit Compressed Sensing with Iterative Hard Thresholding. (arXiv:2310.08019v1 [cs.IT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.19838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bardou_A/0/1/0/all/0/1\">Anthony Bardou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiran_P/0/1/0/all/0/1\">Patrick Thiran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Begin_T/0/1/0/all/0/1\">Thomas Begin</a>",
          "description": "Bayesian Optimization (BO) is typically used to optimize an unknown function\n$f$ that is noisy and costly to evaluate, by exploiting an acquisition function\nthat must be maximized at each optimization step. Even if provably\nasymptotically optimal BO algorithms are efficient at optimizing\nlow-dimensional functions, scaling them to high-dimensional spaces remains an\nopen problem, often tackled by assuming an additive structure for $f$. By doing\nso, BO algorithms typically introduce additional restrictive assumptions on the\nadditive structure that reduce their applicability domain. This paper contains\ntwo main contributions: (i) we relax the restrictive assumptions on the\nadditive structure of $f$, at the expense of weakening the maximization\nguarantees of the acquisition function, and (ii) we address the\nover-exploration problem for decentralized BO algorithms. To these ends, we\npropose DumBO, an asymptotically optimal decentralized BO algorithm that\nachieves very competitive performance against state-of-the-art BO algorithms,\nespecially when the additive structure of $f$ comprises high-dimensional\nfactors.",
          "link": "http://arxiv.org/abs/2305.19838",
          "publishedOn": "2023-10-14T00:41:33.558Z",
          "wordCount": 680,
          "title": "Relaxing the Additivity Constraints in Decentralized No-Regret High-Dimensional Bayesian Optimization. (arXiv:2305.19838v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhendong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miliou_I/0/1/0/all/0/1\">Ioanna Miliou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samsten_I/0/1/0/all/0/1\">Isak Samsten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papapetrou_P/0/1/0/all/0/1\">Panagiotis Papapetrou</a>",
          "description": "Among recent developments in time series forecasting methods, deep\nforecasting models have gained popularity as they can utilize hidden feature\npatterns in time series to improve forecasting performance. Nevertheless, the\nmajority of current deep forecasting models are opaque, hence making it\nchallenging to interpret the results. While counterfactual explanations have\nbeen extensively employed as a post-hoc approach for explaining classification\nmodels, their application to forecasting models still remains underexplored. In\nthis paper, we formulate the novel problem of counterfactual generation for\ntime series forecasting, and propose an algorithm, called ForecastCF, that\nsolves the problem by applying gradient-based perturbations to the original\ntime series. ForecastCF guides the perturbations by applying constraints to the\nforecasted values to obtain desired prediction outcomes. We experimentally\nevaluate ForecastCF using four state-of-the-art deep model architectures and\ncompare to two baselines. Our results show that ForecastCF outperforms the\nbaseline in terms of counterfactual validity and data manifold closeness.\nOverall, our findings suggest that ForecastCF can generate meaningful and\nrelevant counterfactual explanations for various forecasting tasks.",
          "link": "http://arxiv.org/abs/2310.08137",
          "publishedOn": "2023-10-14T00:41:33.550Z",
          "wordCount": 671,
          "title": "Counterfactual Explanations for Time Series Forecasting. (arXiv:2310.08137v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1\">Bowen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Hansi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiusi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1\">Tianxin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruirui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xianfeng Tang</a>",
          "description": "Semantic identifier (ID) is an important concept in information retrieval\nthat aims to preserve the semantics of objects such as documents and items\ninside their IDs. Previous studies typically adopt a two-stage pipeline to\nlearn semantic IDs by first procuring embeddings using off-the-shelf text\nencoders and then deriving IDs based on the embeddings. However, each step\nintroduces potential information loss and there is usually an inherent mismatch\nbetween the distribution of embeddings within the latent space produced by text\nencoders and the anticipated distribution required for semantic indexing.\nNevertheless, it is non-trivial to design a method that can learn the\ndocument's semantic representations and its hierarchical structure\nsimultaneously, given that semantic IDs are discrete and sequentially\nstructured, and the semantic supervision is deficient. In this paper, we\nintroduce LMINDEXER, a self-supervised framework to learn semantic IDs with a\ngenerative language model. We tackle the challenge of sequential discrete ID by\nintroducing a semantic indexer capable of generating neural sequential discrete\nrepresentations with progressive training and contrastive learning. In response\nto the semantic supervision deficiency, we propose to train the model with a\nself-supervised document reconstruction objective. The learned semantic indexer\ncan facilitate various downstream tasks, such as recommendation and retrieval.\nWe conduct experiments on three tasks including recommendation, product search,\nand document retrieval on five datasets from various domains, where LMINDEXER\noutperforms competitive baselines significantly and consistently.",
          "link": "http://arxiv.org/abs/2310.07815",
          "publishedOn": "2023-10-14T00:41:33.265Z",
          "wordCount": null,
          "title": "Language Models As Semantic Indexers. (arXiv:2310.07815v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamp_M/0/1/0/all/0/1\">Michael Kamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_J/0/1/0/all/0/1\">Jonas Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vreeken_J/0/1/0/all/0/1\">Jilles Vreeken</a>",
          "description": "Federated learning allows multiple parties to collaboratively train a joint\nmodel without sharing local data. This enables applications of machine learning\nin settings of inherently distributed, undisclosable data such as in the\nmedical domain. In practice, joint training is usually achieved by aggregating\nlocal models, for which local training objectives have to be in expectation\nsimilar to the joint (global) objective. Often, however, local datasets are so\nsmall that local objectives differ greatly from the global objective, resulting\nin federated learning to fail. We propose a novel approach that intertwines\nmodel aggregations with permutations of local models. The permutations expose\neach local model to a daisy chain of local datasets resulting in more efficient\ntraining in data-sparse domains. This enables training on extremely small local\ndatasets, such as patient data across hospitals, while retaining the training\nefficiency and privacy benefits of federated learning.",
          "link": "http://arxiv.org/abs/2110.03469",
          "publishedOn": "2023-10-14T00:41:33.205Z",
          "wordCount": null,
          "title": "Federated Learning from Small Datasets. (arXiv:2110.03469v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1\">Xianghao Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_O/0/1/0/all/0/1\">Ollie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Han Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yogatama_D/0/1/0/all/0/1\">Dani Yogatama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1\">Greg Ver Steeg</a>",
          "description": "Denoising diffusion models enable conditional generation and density modeling\nof complex relationships like images and text. However, the nature of the\nlearned relationships is opaque making it difficult to understand precisely\nwhat relationships between words and parts of an image are captured, or to\npredict the effect of an intervention. We illuminate the fine-grained\nrelationships learned by diffusion models by noticing a precise relationship\nbetween diffusion and information decomposition. Exact expressions for mutual\ninformation and conditional mutual information can be written in terms of the\ndenoising model. Furthermore, pointwise estimates can be easily estimated as\nwell, allowing us to ask questions about the relationships between specific\nimages and captions. Decomposing information even further to understand which\nvariables in a high-dimensional space carry information is a long-standing\nproblem. For diffusion models, we show that a natural non-negative\ndecomposition of mutual information emerges, allowing us to quantify\ninformative relationships between words and pixels in an image. We exploit\nthese new relations to measure the compositional understanding of diffusion\nmodels, to do unsupervised localization of objects in images, and to measure\neffects when selectively editing images through prompt interventions.",
          "link": "http://arxiv.org/abs/2310.07972",
          "publishedOn": "2023-10-14T00:41:33.203Z",
          "wordCount": null,
          "title": "Interpretable Diffusion via Information Decomposition. (arXiv:2310.07972v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schimanski_T/0/1/0/all/0/1\">Tobias Schimanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bingler_J/0/1/0/all/0/1\">Julia Bingler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hyslop_C/0/1/0/all/0/1\">Camilla Hyslop</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraus_M/0/1/0/all/0/1\">Mathias Kraus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leippold_M/0/1/0/all/0/1\">Markus Leippold</a>",
          "description": "Public and private actors struggle to assess the vast amounts of information\nabout sustainability commitments made by various institutions. To address this\nproblem, we create a novel tool for automatically detecting corporate,\nnational, and regional net zero and reduction targets in three steps. First, we\nintroduce an expert-annotated data set with 3.5K text samples. Second, we train\nand release ClimateBERT-NetZero, a natural language classifier to detect\nwhether a text contains a net zero or reduction target. Third, we showcase its\nanalysis potential with two use cases: We first demonstrate how\nClimateBERT-NetZero can be combined with conventional question-answering (Q&A)\nmodels to analyze the ambitions displayed in net zero and reduction targets.\nFurthermore, we employ the ClimateBERT-NetZero model on quarterly earning call\ntranscripts and outline how communication patterns evolve over time. Our\nexperiments demonstrate promising pathways for extracting and analyzing net\nzero and emission reduction targets at scale.",
          "link": "http://arxiv.org/abs/2310.08096",
          "publishedOn": "2023-10-14T00:41:33.038Z",
          "wordCount": null,
          "title": "ClimateBERT-NetZero: Detecting and Assessing Net Zero and Reduction Targets. (arXiv:2310.08096v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Binghui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gysel_P/0/1/0/all/0/1\">Philipp Gysel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Divakaran_D/0/1/0/all/0/1\">Dinil Mon Divakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurusamy_M/0/1/0/all/0/1\">Mohan Gurusamy</a>",
          "description": "Recent research works have proposed machine learning models for classifying\nIoT devices connected to a network. However, there is still a practical\nchallenge of not having all devices (and hence their traffic) available during\nthe training of a model. This essentially means, during the operational phase,\nwe need to classify new devices not seen during the training phase. To address\nthis challenge, we propose ZEST -- a ZSL (zero-shot learning) framework based\non self-attention for classifying both seen and unseen devices. ZEST consists\nof i) a self-attention based network feature extractor, termed SANE, for\nextracting latent space representations of IoT traffic, ii) a generative model\nthat trains a decoder using latent features to generate pseudo data, and iii) a\nsupervised model that is trained on the generated pseudo data for classifying\ndevices. We carry out extensive experiments on real IoT traffic data; our\nexperiments demonstrate i) ZEST achieves significant improvement (in terms of\naccuracy) over the baselines; ii) ZEST is able to better extract meaningful\nrepresentations than LSTM which has been commonly used for modeling network\ntraffic.",
          "link": "http://arxiv.org/abs/2310.08036",
          "publishedOn": "2023-10-14T00:41:32.980Z",
          "wordCount": 696,
          "title": "ZEST: Attention-based Zero-Shot Learning for Unseen IoT Device Classification. (arXiv:2310.08036v1 [cs.NI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lebailly_T/0/1/0/all/0/1\">Tim Lebailly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stegmuller_T/0/1/0/all/0/1\">Thomas Stegm&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bozorgtabar_B/0/1/0/all/0/1\">Behzad Bozorgtabar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiran_J/0/1/0/all/0/1\">Jean-Philippe Thiran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuytelaars_T/0/1/0/all/0/1\">Tinne Tuytelaars</a>",
          "description": "Leveraging nearest neighbor retrieval for self-supervised representation\nlearning has proven beneficial with object-centric images. However, this\napproach faces limitations when applied to scene-centric datasets, where\nmultiple objects within an image are only implicitly captured in the global\nrepresentation. Such global bootstrapping can lead to undesirable entanglement\nof object representations. Furthermore, even object-centric datasets stand to\nbenefit from a finer-grained bootstrapping approach. In response to these\nchallenges, we introduce a novel Cross-Image Object-Level Bootstrapping method\ntailored to enhance dense visual representation learning. By employing\nobject-level nearest neighbor bootstrapping throughout the training, CrIBo\nemerges as a notably strong and adequate candidate for in-context learning,\nleveraging nearest neighbor retrieval at test time. CrIBo shows\nstate-of-the-art performance on the latter task while being highly competitive\nin more standard downstream segmentation tasks. Our code and pretrained models\nwill be publicly available upon acceptance.",
          "link": "http://arxiv.org/abs/2310.07855",
          "publishedOn": "2023-10-14T00:41:32.974Z",
          "wordCount": 638,
          "title": "CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping. (arXiv:2310.07855v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hayajneh_A/0/1/0/all/0/1\">Abdullah Hayajneh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serpedin_E/0/1/0/all/0/1\">Erchin Serpedin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaqfeh_M/0/1/0/all/0/1\">Mohammad Shaqfeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_G/0/1/0/all/0/1\">Graeme Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stotland_M/0/1/0/all/0/1\">Mitchell A. Stotland</a>",
          "description": "A major obstacle when attempting to train a machine learning system to\nevaluate facial clefts is the scarcity of large datasets of high-quality,\nethics board-approved patient images. In response, we have built a deep\nlearning-based cleft lip generator designed to produce an almost unlimited\nnumber of artificial images exhibiting high-fidelity facsimiles of cleft lip\nwith wide variation. We undertook a transfer learning protocol testing\ndifferent versions of StyleGAN-ADA (a generative adversarial network image\ngenerator incorporating adaptive data augmentation (ADA)) as the base model.\nTraining images depicting a variety of cleft deformities were pre-processed to\nadjust for rotation, scaling, color adjustment and background blurring. The ADA\nmodification of the primary algorithm permitted construction of our new\ngenerative model while requiring input of a relatively small number of training\nimages. Adversarial training was carried out using 514 unique frontal\nphotographs of cleft-affected faces to adapt a pre-trained model based on\n70,000 normal faces. The Frechet Inception Distance (FID) was used to measure\nthe similarity of the newly generated facial images to the cleft training\ndataset, while Perceptual Path Length (PPL) and the novel Divergence Index of\nSeverity Histograms (DISH) measures were also used to assess the performance of\nthe image generator that we dub CleftGAN. We found that StyleGAN3 with\ntranslation invariance (StyleGAN3-t) performed optimally as a base model.\nGenerated images achieved a low FID reflecting a close similarity to our\ntraining input dataset of genuine cleft images. Low PPL and DISH measures\nreflected a smooth and semantically valid interpolation of images through the\ntransfer learning process and a similar distribution of severity in the\ntraining and generated images, respectively.",
          "link": "http://arxiv.org/abs/2310.07969",
          "publishedOn": "2023-10-14T00:41:32.939Z",
          "wordCount": 815,
          "title": "CleftGAN: Adapting A Style-Based Generative Adversarial Network To Create Images Depicting Cleft Lip Deformity. (arXiv:2310.07969v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Budan_G/0/1/0/all/0/1\">Gokhan Budan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damiani_F/0/1/0/all/0/1\">Francesca Damiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurtulus_C/0/1/0/all/0/1\">Can Kurtulus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ure_N/0/1/0/all/0/1\">N. Kemal Ure</a>",
          "description": "Model identification of battery dynamics is a central problem in energy\nresearch; many energy management systems and design processes rely on accurate\nbattery models for efficiency optimization. The standard methodology for\nbattery modelling is traditional design of experiments (DoE), where the battery\ndynamics are excited with many different current profiles and the measured\noutputs are used to estimate the system dynamics. However, although it is\npossible to obtain useful models with the traditional approach, the process is\ntime consuming and expensive because of the need to sweep many different\ncurrent-profile configurations. In the present work, a novel DoE approach is\ndeveloped based on deep reinforcement learning, which alters the configuration\nof the experiments on the fly based on the statistics of past experiments.\nInstead of sticking to a library of predefined current profiles, the proposed\napproach modifies the current profiles dynamically by updating the output space\ncovered by past measurements, hence only the current profiles that are\ninformative for future experiments are applied. Simulations and real\nexperiments are used to show that the proposed approach gives models that are\nas accurate as those obtained with traditional DoE but by using 85\\% less\nresources.",
          "link": "http://arxiv.org/abs/2310.08198",
          "publishedOn": "2023-10-14T00:41:32.922Z",
          "wordCount": 727,
          "title": "Beyond Traditional DoE: Deep Reinforcement Learning for Optimizing Experiments in Model Identification of Battery Dynamics. (arXiv:2310.08198v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1\">Ravit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romaszkan_W/0/1/0/all/0/1\">Wojciech Romaszkan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Feiqian Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Puneet Gupta</a>",
          "description": "Researchers have long touted a vision of the future enabled by a\nproliferation of internet-of-things devices, including smart sensors, homes,\nand cities. Increasingly, embedding intelligence in such devices involves the\nuse of deep neural networks. However, their storage and processing requirements\nmake them prohibitive for cheap, off-the-shelf platforms. Overcoming those\nrequirements is necessary for enabling widely-applicable smart devices. While\nmany ways of making models smaller and more efficient have been developed,\nthere is a lack of understanding of which ones are best suited for particular\nscenarios. More importantly for edge platforms, those choices cannot be\nanalyzed in isolation from cost and user experience. In this work, we\nholistically explore how quantization, model scaling, and multi-modality\ninteract with system components such as memory, sensors, and processors. We\nperform this hardware/software co-design from the cost, latency, and\nuser-experience perspective, and develop a set of guidelines for optimal system\ndesign and model deployment for the most cost-constrained platforms. We\ndemonstrate our approach using an end-to-end, on-device, biometric user\nauthentication system using a $20 ESP-EYE board.",
          "link": "http://arxiv.org/abs/2310.07940",
          "publishedOn": "2023-10-14T00:41:32.888Z",
          "wordCount": 668,
          "title": "Cost-Driven Hardware-Software Co-Optimization of Machine Learning Pipelines. (arXiv:2310.07940v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1\">Arpit Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jhaveri_H/0/1/0/all/0/1\">Harshil Jhaveri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallick_S/0/1/0/all/0/1\">Swapnil Mallick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ajmera_A/0/1/0/all/0/1\">Abhishek Ajmera</a>",
          "description": "Few-shot object classification is the task of classifying objects in an image\nwith limited number of examples as supervision. We propose a one-shot/few-shot\nclassification model that can classify an object of any unseen class into a\nrelatively general category in an hierarchically based classification. Our\nmodel uses a three-level hierarchical contrastive loss based ResNet152\nclassifier for classifying an object based on its features extracted from Image\nembedding, not used during the training phase. For our experimentation, we have\nused a subset of the ImageNet (ILSVRC-12) dataset that contains only the animal\nclasses for training our model and created our own dataset of unseen classes\nfor evaluating our trained model. Our model provides satisfactory results in\nclassifying the unknown objects into a generic category which has been later\ndiscussed in greater detail.",
          "link": "http://arxiv.org/abs/2310.08304",
          "publishedOn": "2023-10-14T00:41:32.883Z",
          "wordCount": 624,
          "title": "CHIP: Contrastive Hierarchical Image Pretraining. (arXiv:2310.08304v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07852",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Roy_S/0/1/0/all/0/1\">Saptarshi Roy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1\">Ambuj Tewari</a>",
          "description": "We consider the problem of model selection in a high-dimensional sparse\nlinear regression model under the differential privacy framework. In\nparticular, we consider the problem of differentially private best subset\nselection and study its utility guarantee. We adopt the well-known exponential\nmechanism for selecting the best model, and under a certain margin condition,\nwe establish its strong model recovery property. However, the exponential\nsearch space of the exponential mechanism poses a serious computational\nbottleneck. To overcome this challenge, we propose a Metropolis-Hastings\nalgorithm for the sampling step and establish its polynomial mixing time to its\nstationary distribution in the problem parameters $n,p$, and $s$. Furthermore,\nwe also establish approximate differential privacy for the final estimates of\nthe Metropolis-Hastings random walk using its mixing property. Finally, we also\nperform some illustrative simulations that echo the theoretical findings of our\nmain results.",
          "link": "http://arxiv.org/abs/2310.07852",
          "publishedOn": "2023-10-14T00:41:32.873Z",
          "wordCount": 663,
          "title": "On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1\">William Merrill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>",
          "description": "Recent theoretical work has identified surprisingly simple reasoning\nproblems, such as checking if two nodes in a graph are connected or simulating\nfinite-state machines, that are provably unsolvable by standard transformers\nthat answer immediately after reading their input. However, in practice,\ntransformers' reasoning can be improved by allowing them to use a \"chain of\nthought\" or \"scratchpad\", i.e., generate and condition on a sequence of\nintermediate tokens before answering. Motivated by this, we ask: Does such\nintermediate generation fundamentally extend the computational power of a\ndecoder-only transformer? We show that the answer is yes, but the amount of\nincrease depends crucially on the amount of intermediate generation. For\ninstance, we find that transformer decoders with a logarithmic number of\ndecoding steps (w.r.t. the input length) push the limits of standard\ntransformers only slightly, while a linear number of decoding steps adds a\nclear new ability (under standard complexity conjectures): recognizing all\nregular languages. Our results also imply that linear steps keep transformer\ndecoders within context-sensitive languages, and polynomial steps make them\nrecognize exactly the class of polynomial-time solvable problems -- the first\nexact characterization of a type of transformers in terms of standard\ncomplexity classes. Together, our results provide a nuanced framework for\nunderstanding how the length of a transformer's chain of thought or scratchpad\nimpacts its reasoning power.",
          "link": "http://arxiv.org/abs/2310.07923",
          "publishedOn": "2023-10-14T00:41:32.852Z",
          "wordCount": 737,
          "title": "The Expresssive Power of Transformers with Chain of Thought. (arXiv:2310.07923v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.16335",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schar_S/0/1/0/all/0/1\">Styfen Sch&#xe4;r</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marelli_S/0/1/0/all/0/1\">Stefano Marelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sudret_B/0/1/0/all/0/1\">Bruno Sudret</a>",
          "description": "We propose a novel surrogate modelling approach to efficiently and accurately\napproximate the response of complex dynamical systems driven by time-varying\nexogenous excitations over extended time periods. Our approach, namely manifold\nnonlinear autoregressive modelling with exogenous input (mNARX), involves\nconstructing a problem-specific exogenous input manifold that is optimal for\nconstructing autoregressive surrogates. The manifold, which forms the core of\nmNARX, is constructed incrementally by incorporating the physics of the system,\nas well as prior expert- and domain- knowledge. Because mNARX decomposes the\nfull problem into a series of smaller sub-problems, each with a lower\ncomplexity than the original, it scales well with the complexity of the\nproblem, both in terms of training and evaluation costs of the final surrogate.\nFurthermore, mNARX synergizes well with traditional dimensionality reduction\ntechniques, making it highly suitable for modelling dynamical systems with\nhigh-dimensional exogenous inputs, a class of problems that is typically\nchallenging to solve. Since domain knowledge is particularly abundant in\nphysical systems, such as those found in civil and mechanical engineering,\nmNARX is well suited for these applications. We demonstrate that mNARX\noutperforms traditional autoregressive surrogates in predicting the response of\na classical coupled spring-mass system excited by a one-dimensional random\nexcitation. Additionally, we show that mNARX is well suited for emulating very\nhigh-dimensional time- and state-dependent systems, even when affected by\nactive controllers, by surrogating the dynamics of a realistic\naero-servo-elastic onshore wind turbine simulator. In general, our results\ndemonstrate that mNARX offers promising prospects for modelling complex\ndynamical systems, in terms of accuracy and efficiency.",
          "link": "http://arxiv.org/abs/2306.16335",
          "publishedOn": "2023-10-14T00:41:32.840Z",
          "wordCount": 791,
          "title": "Emulating the dynamics of complex systems using autoregressive models on manifolds (mNARX). (arXiv:2306.16335v2 [stat.CO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1\">Chenzhong Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Mingxi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xiongye Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinghe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nazarian_S/0/1/0/all/0/1\">Shahin Nazarian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irimia_A/0/1/0/all/0/1\">Andrei Irimia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogdan_P/0/1/0/all/0/1\">Paul Bogdan</a>",
          "description": "The collective behavior of a network with heterogeneous, resource-limited\ninformation processing units (e.g., group of fish, flock of birds, or network\nof neurons) demonstrates high self-organization and complexity. These emergent\nproperties arise from simple interaction rules where certain individuals can\nexhibit leadership-like behavior and influence the collective activity of the\ngroup. Motivated by the intricacy of these collectives, we propose a neural\nnetwork (NN) architecture inspired by the rules observed in nature's collective\nensembles. This NN structure contains workers that encompass one or more\ninformation processing units (e.g., neurons, filters, layers, or blocks of\nlayers). Workers are either leaders or followers, and we train a\nleader-follower neural network (LFNN) by leveraging local error signals and\noptionally incorporating backpropagation (BP) and global loss. We investigate\nworker behavior and evaluate LFNNs through extensive experimentation. Our LFNNs\ntrained with local error signals achieve significantly lower error rates than\nprevious BP-free algorithms on MNIST and CIFAR-10 and even surpass BP-enabled\nbaselines. In the case of ImageNet, our LFNN-l demonstrates superior\nscalability and outperforms previous BP-free algorithms by a significant\nmargin.",
          "link": "http://arxiv.org/abs/2310.07885",
          "publishedOn": "2023-10-14T00:41:32.834Z",
          "wordCount": 698,
          "title": "Leader-Follower Neural Networks with Local Error Signals Inspired by Complex Collectives. (arXiv:2310.07885v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Md Mahbubur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceka_I/0/1/0/all/0/1\">Ira Ceka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1\">Chengzhi Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Saikat Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1\">Baishakhi Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_W/0/1/0/all/0/1\">Wei Le</a>",
          "description": "Deep learning vulnerability detection has shown promising results in recent\nyears. However, an important challenge that still blocks it from being very\nuseful in practice is that the model is not robust under perturbation and it\ncannot generalize well over the out-of-distribution (OOD) data, e.g., applying\na trained model to unseen projects in real world. We hypothesize that this is\nbecause the model learned non-robust features, e.g., variable names, that have\nspurious correlations with labels. When the perturbed and OOD datasets no\nlonger have the same spurious features, the model prediction fails. To address\nthe challenge, in this paper, we introduced causality into deep learning\nvulnerability detection. Our approach CausalVul consists of two phases. First,\nwe designed novel perturbations to discover spurious features that the model\nmay use to make predictions. Second, we applied the causal learning algorithms,\nspecifically, do-calculus, on top of existing deep learning models to\nsystematically remove the use of spurious features and thus promote causal\nbased prediction. Our results show that CausalVul consistently improved the\nmodel accuracy, robustness and OOD performance for all the state-of-the-art\nmodels and datasets we experimented. To the best of our knowledge, this is the\nfirst work that introduces do calculus based causal learning to software\nengineering models and shows it's indeed useful for improving the model\naccuracy, robustness and generalization. Our replication package is located at\nhttps://figshare.com/s/0ffda320dcb96c249ef2.",
          "link": "http://arxiv.org/abs/2310.07958",
          "publishedOn": "2023-10-14T00:41:32.829Z",
          "wordCount": 745,
          "title": "Towards Causal Deep Learning for Vulnerability Detection. (arXiv:2310.07958v1 [cs.SE])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maharana_A/0/1/0/all/0/1\">Adyasha Maharana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1\">Prateek Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Analytical theories suggest that higher-quality data can lead to lower test\nerrors in models trained on a fixed data budget. Moreover, a model can be\ntrained on a lower compute budget without compromising performance if a dataset\ncan be stripped of its redundancies. Coreset selection (or data pruning) seeks\nto select a subset of the training data so as to maximize the performance of\nmodels trained on this subset, also referred to as coreset. There are two\ndominant approaches: (1) geometry-based data selection for maximizing data\ndiversity in the coreset, and (2) functions that assign difficulty scores to\nsamples based on training dynamics. Optimizing for data diversity leads to a\ncoreset that is biased towards easier samples, whereas, selection by difficulty\nranking omits easy samples that are necessary for the training of deep learning\nmodels. This demonstrates that data diversity and importance scores are two\ncomplementary factors that need to be jointly considered during coreset\nselection. We represent a dataset as an undirected graph and propose a novel\npruning algorithm, D2 Pruning, that uses forward and reverse message passing\nover this dataset graph for coreset selection. D2 Pruning updates the\ndifficulty scores of each example by incorporating the difficulty of its\nneighboring examples in the dataset graph. Then, these updated difficulty\nscores direct a graph-based sampling method to select a coreset that\nencapsulates both diverse and difficult regions of the dataset space. We\nevaluate supervised and self-supervised versions of our method on various\nvision and language datasets. Results show that D2 Pruning improves coreset\nselection over previous state-of-the-art methods for up to 70% pruning rates.\nAdditionally, we find that using D2 Pruning for filtering large multimodal\ndatasets leads to increased diversity in the dataset and improved\ngeneralization of pretrained models.",
          "link": "http://arxiv.org/abs/2310.07931",
          "publishedOn": "2023-10-14T00:41:32.816Z",
          "wordCount": 833,
          "title": "D2 Pruning: Message Passing for Balancing Diversity and Difficulty in Data Pruning. (arXiv:2310.07931v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07780",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linbo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1\">Trong Nghia Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Lam M. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_T/0/1/0/all/0/1\">Tsui-Wei Weng</a>",
          "description": "Randomized smoothing has recently attracted attentions in the field of\nadversarial robustness to provide provable robustness guarantees on smoothed\nneural network classifiers. However, existing works show that vanilla\nrandomized smoothing usually does not provide good robustness performance and\noften requires (re)training techniques on the base classifier in order to boost\nthe robustness of the resulting smoothed classifier. In this work, we propose\ntwo cost-effective approaches to boost the robustness of randomized smoothing\nwhile preserving its clean performance. The first approach introduces a new\nrobust training method AdvMacerwhich combines adversarial training and\nrobustness certification maximization for randomized smoothing. We show that\nAdvMacer can improve the robustness performance of randomized smoothing\nclassifiers compared to SOTA baselines, while being 3x faster to train than\nMACER baseline. The second approach introduces a post-processing method EsbRS\nwhich greatly improves the robustness certificate based on building model\nensembles. We explore different aspects of model ensembles that has not been\nstudied by prior works and propose a novel design methodology to further\nimprove robustness of the ensemble based on our theoretical analysis.",
          "link": "http://arxiv.org/abs/2310.07780",
          "publishedOn": "2023-10-14T00:41:32.758Z",
          "wordCount": 679,
          "title": "Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches. (arXiv:2310.07780v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07925",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Rostami_M/0/1/0/all/0/1\">M. Rostami</a>, <a href=\"http://arxiv.org/find/math/1/au:+Moradian_H/0/1/0/all/0/1\">H. Moradian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kia_S/0/1/0/all/0/1\">S. S. Kia</a>",
          "description": "This paper proposes a set of novel optimization algorithms for solving a\nclass of convex optimization problems with time-varying streaming cost\nfunction. We develop an approach to track the optimal solution with a bounded\nerror. Unlike the existing results, our algorithm is executed only by using the\nfirst-order derivatives of the cost function which makes it computationally\nefficient for optimization with time-varying cost function. We compare our\nalgorithms to the gradient descent algorithm and show why gradient descent is\nnot an effective solution for optimization problems with time-varying cost.\nSeveral examples including solving a model predictive control problem cast as a\nconvex optimization problem with a streaming time-varying cost function\ndemonstrate our results.",
          "link": "http://arxiv.org/abs/2310.07925",
          "publishedOn": "2023-10-14T00:41:32.750Z",
          "wordCount": 608,
          "title": "First-Order Dynamic Optimization for Streaming Convex Costs. (arXiv:2310.07925v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luca_A/0/1/0/all/0/1\">Artur Back de Luca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fountoulakis_K/0/1/0/all/0/1\">Kimon Fountoulakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shenghao Yang</a>",
          "description": "The growing interest in machine learning problems over graphs with additional\nnode information such as texts, images, or labels has popularized methods that\nrequire the costly operation of processing the entire graph. Yet, little effort\nhas been made to the development of fast local methods (i.e. without accessing\nthe entire graph) that extract useful information from such data. To that end,\nwe propose a study of local graph clustering using noisy node labels as a proxy\nfor additional node information. In this setting, nodes receive initial binary\nlabels based on cluster affiliation: 1 if they belong to the target cluster and\n0 otherwise. Subsequently, a fraction of these labels is flipped. We\ninvestigate the benefits of incorporating noisy labels for local graph\nclustering. By constructing a weighted graph with such labels, we study the\nperformance of graph diffusion-based local clustering method on both the\noriginal and the weighted graphs. From a theoretical perspective, we consider\nrecovering an unknown target cluster with a single seed node in a random graph\nwith independent noisy node labels. We provide sufficient conditions on the\nlabel noise under which, with high probability, using diffusion in the weighted\ngraph yields a more accurate recovery of the target cluster. This approach\nproves more effective than using the given labels alone or using diffusion in\nthe label-free original graph. Empirically, we show that reliable node labels\ncan be obtained with just a few samples from an attributed graph. Moreover,\nutilizing these labels via diffusion in the weighted graph leads to\nsignificantly better local clustering performance across several real-world\ndatasets, improving F1 scores by up to 13%.",
          "link": "http://arxiv.org/abs/2310.08031",
          "publishedOn": "2023-10-14T00:41:32.723Z",
          "wordCount": 784,
          "title": "Local Graph Clustering with Noisy Labels. (arXiv:2310.08031v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.13326",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nie_G/0/1/0/all/0/1\">Guanyu Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadew_Y/0/1/0/all/0/1\">Yididiya Y Nadew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanhui Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1\">Vaneet Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quinn_C/0/1/0/all/0/1\">Christopher John Quinn</a>",
          "description": "We investigate the problem of stochastic, combinatorial multi-armed bandits\nwhere the learner only has access to bandit feedback and the reward function\ncan be non-linear. We provide a general framework for adapting discrete offline\napproximation algorithms into sublinear $\\alpha$-regret methods that only\nrequire bandit feedback, achieving\n$\\mathcal{O}\\left(T^\\frac{2}{3}\\log(T)^\\frac{1}{3}\\right)$ expected cumulative\n$\\alpha$-regret dependence on the horizon $T$. The framework only requires the\noffline algorithms to be robust to small errors in function evaluation. The\nadaptation procedure does not even require explicit knowledge of the offline\napproximation algorithm -- the offline algorithm can be used as a black box\nsubroutine. To demonstrate the utility of the proposed framework, the proposed\nframework is applied to diverse applications in submodular maximization. The\nnew CMAB algorithms for submodular maximization with knapsack constraints\noutperform a full-bandit method developed for the adversarial setting in\nexperiments with real-world data.",
          "link": "http://arxiv.org/abs/2301.13326",
          "publishedOn": "2023-10-14T00:41:32.708Z",
          "wordCount": 755,
          "title": "A Framework for Adapting Offline Algorithms to Solve Combinatorial Multi-Armed Bandit Problems with Bandit Feedback. (arXiv:2301.13326v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.03410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jacob_J/0/1/0/all/0/1\">Jayadeep Jacob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bandyopadhyay_T/0/1/0/all/0/1\">Tirthankar Bandyopadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1\">Jason Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borges_P/0/1/0/all/0/1\">Paulo Borges</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1\">Fabio Ramos</a>",
          "description": "We propose to use a simulation driven inverse inference approach to model the\ndynamics of tree branches under manipulation. Learning branch dynamics and\ngaining the ability to manipulate deformable vegetation can help with\nocclusion-prone tasks, such as fruit picking in dense foliage, as well as\nmoving overhanging vines and branches for navigation in dense vegetation. The\nunderlying deformable tree geometry is encapsulated as coarse spring\nabstractions executed on parallel, non-differentiable simulators. The implicit\nstatistical model defined by the simulator, reference trajectories obtained by\nactively probing the ground truth, and the Bayesian formalism, together guide\nthe spring parameter posterior density estimation. Our non-parametric inference\nalgorithm, based on Stein Variational Gradient Descent, incorporates\nbiologically motivated assumptions into the inference process as neural network\ndriven learnt joint priors; moreover, it leverages the finite difference scheme\nfor gradient approximations. Real and simulated experiments confirm that our\nmodel can predict deformation trajectories, quantify the estimation\nuncertainty, and it can perform better when base-lined against other inference\nalgorithms, particularly from the Monte Carlo family. The model displays strong\nrobustness properties in the presence of heteroscedastic sensor noise;\nfurthermore, it can generalise to unseen grasp locations.",
          "link": "http://arxiv.org/abs/2306.03410",
          "publishedOn": "2023-10-14T00:41:32.703Z",
          "wordCount": 704,
          "title": "Learning to Simulate Tree-Branch Dynamics for Manipulation. (arXiv:2306.03410v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhongji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuhang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yinghao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianlong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaohe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasha Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Liantao Ma</a>",
          "description": "Due to the limited information about emerging diseases, symptoms are hard to\nbe noticed and recognized, so that the window for clinical intervention could\nbe ignored. An effective prognostic model is expected to assist doctors in\nmaking right diagnosis and designing personalized treatment plan, so to\npromptly prevent unfavorable outcomes. However, in the early stage of a\ndisease, limited data collection and clinical experiences, plus the concern out\nof privacy and ethics, may result in restricted data availability for\nreference, to the extent that even data labels are difficult to mark correctly.\nIn addition, Electronic Medical Record (EMR) data of different diseases or of\ndifferent sources of the same disease can prove to be having serious\ncross-dataset feature misalignment problems, greatly mutilating the efficiency\nof deep learning models. This article introduces a transfer learning method to\nbuild a transition model from source dataset to target dataset. By way of\nconstraining the distribution shift of features generated in disparate domains,\ndomain-invariant features that are exclusively relative to downstream tasks are\ncaptured, so to cultivate a unified domain-invariant encoder across various\ntask domains to achieve better feature representation. Experimental results of\nseveral target tasks demonstrate that our proposed model outperforms competing\nbaseline methods and has higher rate of training convergence, especially in\ndealing with limited data amount. A multitude of experiences have proven the\nefficacy of our method to provide more accurate predictions concerning newly\nemergent pandemics and other diseases.",
          "link": "http://arxiv.org/abs/2310.07799",
          "publishedOn": "2023-10-14T00:41:32.698Z",
          "wordCount": 772,
          "title": "A Transfer-Learning-Based Prognosis Prediction Paradigm that Bridges Data Distribution Shift across EMR Datasets. (arXiv:2310.07799v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.02484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yueh-Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamaya_M/0/1/0/all/0/1\">Masashi Hamaya</a>",
          "description": "This paper introduces Elastic Decision Transformer (EDT), a significant\nadvancement over the existing Decision Transformer (DT) and its variants.\nAlthough DT purports to generate an optimal trajectory, empirical evidence\nsuggests it struggles with trajectory stitching, a process involving the\ngeneration of an optimal or near-optimal trajectory from the best parts of a\nset of sub-optimal trajectories. The proposed EDT differentiates itself by\nfacilitating trajectory stitching during action inference at test time,\nachieved by adjusting the history length maintained in DT. Further, the EDT\noptimizes the trajectory by retaining a longer history when the previous\ntrajectory is optimal and a shorter one when it is sub-optimal, enabling it to\n\"stitch\" with a more optimal trajectory. Extensive experimentation demonstrates\nEDT's ability to bridge the performance gap between DT-based and Q\nLearning-based approaches. In particular, the EDT outperforms Q Learning-based\nmethods in a multi-task regime on the D4RL locomotion benchmark and Atari\ngames. Videos are available at: https://kristery.github.io/edt/",
          "link": "http://arxiv.org/abs/2307.02484",
          "publishedOn": "2023-10-14T00:41:32.661Z",
          "wordCount": 689,
          "title": "Elastic Decision Transformer. (arXiv:2307.02484v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.00152",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hanneke_S/0/1/0/all/0/1\">Steve Hanneke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mahdaviyeh_Y/0/1/0/all/0/1\">Yasaman Mahdaviyeh</a>",
          "description": "Theoretical studies on transfer learning or domain adaptation have so far\nfocused on situations with a known hypothesis class or model; however in\npractice, some amount of model selection is usually involved, often appearing\nunder the umbrella term of hyperparameter-tuning: for example, one may think of\nthe problem of tuning for the right neural network architecture towards a\ntarget task, while leveraging data from a related source task.\n\nNow, in addition to the usual tradeoffs on approximation vs estimation errors\ninvolved in model selection, this problem brings in a new complexity term,\nnamely, the transfer distance between source and target distributions, which is\nknown to vary with the choice of hypothesis class.\n\nWe present a first study of this problem, focusing on classification; in\nparticular, the analysis reveals some remarkable phenomena: adaptive rates,\ni.e., those achievable with no distributional information, can be arbitrarily\nslower than oracle rates, i.e., when given knowledge on distances.",
          "link": "http://arxiv.org/abs/2305.00152",
          "publishedOn": "2023-10-14T00:41:32.648Z",
          "wordCount": 693,
          "title": "Limits of Model Selection under Transfer Learning. (arXiv:2305.00152v4 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_S/0/1/0/all/0/1\">Shaofei Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bowei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Anji Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yitao Liang</a>",
          "description": "We study the problem of building a controller that can follow open-ended\ninstructions in open-world environments. We propose to follow reference videos\nas instructions, which offer expressive goal specifications while eliminating\nthe need for expensive text-gameplay annotations. A new learning framework is\nderived to allow learning such instruction-following controllers from gameplay\nvideos while producing a video instruction encoder that induces a structured\ngoal space. We implement our agent GROOT in a simple yet effective\nencoder-decoder architecture based on causal transformers. We evaluate GROOT\nagainst open-world counterparts and human players on a proposed Minecraft\nSkillForge benchmark. The Elo ratings clearly show that GROOT is closing the\nhuman-machine gap as well as exhibiting a 70% winning rate over the best\ngeneralist agent baseline. Qualitative analysis of the induced goal space\nfurther demonstrates some interesting emergent properties, including the goal\ncomposition and complex gameplay behavior synthesis. Code and video can be\nfound on the website https://craftjarvis-groot.github.io.",
          "link": "http://arxiv.org/abs/2310.08235",
          "publishedOn": "2023-10-14T00:41:32.567Z",
          "wordCount": 659,
          "title": "GROOT: Learning to Follow Instructions by Watching Gameplay Videos. (arXiv:2310.08235v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1\">Shengzhao Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamnoedboon_P/0/1/0/all/0/1\">Porawit Kamnoedboon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">WeiWei Li</a>",
          "description": "The lack of standardized robustness metrics and the widespread reliance on\nnumerous unrelated benchmark datasets for testing have created a gap between\nacademically validated robust models and their often problematic practical\nadoption. To address this, we introduce XIMAGENET-12, an explainable benchmark\ndataset with over 200K images and 15,600 manual semantic annotations. Covering\n12 categories from ImageNet to represent objects commonly encountered in\npractical life and simulating six diverse scenarios, including overexposure,\nblurring, color changing, etc., we further propose a novel robustness criterion\nthat extends beyond model generation ability assessment. This benchmark\ndataset, along with related code, is available at\nhttps://sites.google.com/view/ximagenet-12/home. Researchers and practitioners\ncan leverage this resource to evaluate the robustness of their visual models\nunder challenging conditions and ultimately benefit from the demands of\npractical computer vision systems.",
          "link": "http://arxiv.org/abs/2310.08182",
          "publishedOn": "2023-10-14T00:41:32.502Z",
          "wordCount": 649,
          "title": "XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation. (arXiv:2310.08182v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Piras_G/0/1/0/all/0/1\">Giorgio Piras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1\">Maura Pintor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demontis_A/0/1/0/all/0/1\">Ambra Demontis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1\">Battista Biggio</a>",
          "description": "Neural network pruning has shown to be an effective technique for reducing\nthe network size, trading desirable properties like generalization and\nrobustness to adversarial attacks for higher sparsity. Recent work has claimed\nthat adversarial pruning methods can produce sparse networks while also\npreserving robustness to adversarial examples. In this work, we first\nre-evaluate three state-of-the-art adversarial pruning methods, showing that\ntheir robustness was indeed overestimated. We then compare pruned and dense\nversions of the same models, discovering that samples on thin ice, i.e., closer\nto the unpruned model's decision boundary, are typically misclassified after\npruning. We conclude by discussing how this intuition may lead to designing\nmore effective adversarial pruning methods in future work.",
          "link": "http://arxiv.org/abs/2310.08073",
          "publishedOn": "2023-10-14T00:41:32.451Z",
          "wordCount": 629,
          "title": "Samples on Thin Ice: Re-Evaluating Adversarial Pruning of Neural Networks. (arXiv:2310.08073v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08282",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ruyi Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_N/0/1/0/all/0/1\">Ningning Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yizhuang You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiang Zhang</a>",
          "description": "Multiscale modeling of complex systems is crucial for understanding their\nintricacies. Data-driven multiscale modeling has emerged as a promising\napproach to tackle challenges associated with complex systems. On the other\nhand, self-similarity is prevalent in complex systems, hinting that large-scale\ncomplex systems can be modeled at a reduced cost. In this paper, we introduce a\nmultiscale neural network framework that incorporates self-similarity as prior\nknowledge, facilitating the modeling of self-similar dynamical systems. For\ndeterministic dynamics, our framework can discern whether the dynamics are\nself-similar. For uncertain dynamics, it can compare and determine which\nparameter set is closer to self-similarity. The framework allows us to extract\nscale-invariant kernels from the dynamics for modeling at any scale. Moreover,\nour method can identify the power law exponents in self-similar systems.\nPreliminary tests on the Ising model yielded critical exponents consistent with\ntheoretical expectations, providing valuable insights for addressing critical\nphase transitions in non-equilibrium systems.",
          "link": "http://arxiv.org/abs/2310.08282",
          "publishedOn": "2023-10-14T00:41:32.442Z",
          "wordCount": 655,
          "title": "Data driven modeling of self-similar dynamics. (arXiv:2310.08282v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08078",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Md Mushfiqur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakib_F/0/1/0/all/0/1\">Fardin Ahsan Sakib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faisal_F/0/1/0/all/0/1\">Fahim Faisal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>",
          "description": "Choosing an appropriate tokenization scheme is often a bottleneck in\nlow-resource cross-lingual transfer. To understand the downstream implications\nof text representation choices, we perform a comparative analysis on language\nmodels having diverse text representation modalities including 2\nsegmentation-based models (\\texttt{BERT}, \\texttt{mBERT}), 1 image-based model\n(\\texttt{PIXEL}), and 1 character-level model (\\texttt{CANINE}). First, we\npropose a scoring Language Quotient (LQ) metric capable of providing a weighted\nrepresentation of both zero-shot and few-shot evaluation combined. Utilizing\nthis metric, we perform experiments comprising 19 source languages and 133\ntarget languages on three tasks (POS tagging, Dependency parsing, and NER). Our\nanalysis reveals that image-based models excel in cross-lingual transfer when\nlanguages are closely related and share visually similar scripts. However, for\ntasks biased toward word meaning (POS, NER), segmentation-based models prove to\nbe superior. Furthermore, in dependency parsing tasks where word relationships\nplay a crucial role, models with their character-level focus, outperform\nothers. Finally, we propose a recommendation scheme based on our findings to\nguide model selection according to task and language requirements.",
          "link": "http://arxiv.org/abs/2310.08078",
          "publishedOn": "2023-10-14T00:41:32.353Z",
          "wordCount": 710,
          "title": "To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer. (arXiv:2310.08078v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Havaldar_S/0/1/0/all/0/1\">Shreyas Havaldar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_N/0/1/0/all/0/1\">Navodita Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sareen_S/0/1/0/all/0/1\">Shubhi Sareen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghuveer_A/0/1/0/all/0/1\">Aravindan Raghuveer</a>",
          "description": "Learning from Label Proportions (LLP) is a learning problem where only\naggregate level labels are available for groups of instances, called bags,\nduring training, and the aim is to get the best performance at the\ninstance-level on the test data. This setting arises in domains like\nadvertising and medicine due to privacy considerations. We propose a novel\nalgorithmic framework for this problem that iteratively performs two main\nsteps. For the first step (Pseudo Labeling) in every iteration, we define a\nGibbs distribution over binary instance labels that incorporates a) covariate\ninformation through the constraint that instances with similar covariates\nshould have similar labels and b) the bag level aggregated label. We then use\nBelief Propagation (BP) to marginalize the Gibbs distribution to obtain pseudo\nlabels. In the second step (Embedding Refinement), we use the pseudo labels to\nprovide supervision for a learner that yields a better embedding. Further, we\niterate on the two steps again by using the second step's embeddings as new\ncovariates for the next iteration. In the final iteration, a classifier is\ntrained using the pseudo labels. Our algorithm displays strong gains against\nseveral SOTA baselines (up to 15%) for the LLP Binary Classification problem on\nvarious dataset types - tabular and Image. We achieve these improvements with\nminimal computational overhead above standard supervised learning due to Belief\nPropagation, for large bag sizes, even for a million samples.",
          "link": "http://arxiv.org/abs/2310.08056",
          "publishedOn": "2023-10-14T00:41:32.276Z",
          "wordCount": 745,
          "title": "Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation. (arXiv:2310.08056v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08109",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Schuster_G/0/1/0/all/0/1\">Gerard T. Schuster</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Feng_S/0/1/0/all/0/1\">Shihang Feng</a>",
          "description": "We review four types of algorithms for physics-informed machine learning\n(PIML) inversion of geophysical data. The unifying equation is given by the\njoint objective function $\\epsilon$:\n\n\\begin{eqnarray} \\epsilon^{||-PIML}&=&\\lambda_1 \\overbrace{||{\\bf\nW}^{ML}({\\bf H}_{{\\bf w}} {\\bf d}^{obs}-{\\bf m})||^2}^{NN} + \\lambda_2\n\\overbrace{{||{\\bf W}^{FWI}({\\bf L} {\\bf m}-{\\bf d}^{obs})||^2}}^{FWI} ~+\n\\nonumber\\\\ \\nonumber\\\\ && + ~~Regularizer, \\label{PIML.eq120}\n\\end{eqnarray}where the optimal model ${\\bf m}^*$ and weights $\\bf w^*$\nminimize $\\epsilon$. Here, The matrix weights are given by the boldface symbol\n$\\bf W$, and full waveform inversion (FWI) is typically computed using a\nfinite-difference solution of the wave equation, where $\\bf L$ represents the\nforward modeling operation of the wave equation as a function of the model $\\bf\nm$. Also, a fully-connected neural network (NN) is used to compute the model\n${\\bf H_w}{\\bf d}^{obs} \\approx \\bf m$ from the observed input data ${\\bf\nd}^{obs}$. The selection of weights $\\lambda_i$ and the NN operations determine\none of four different PIML algorithms.\n\nPIML offers potential advantages over standard FWI through its enhanced\nability to avoid local minima and the option to locally train the inversion\noperator, minimizing the requirement for extensive training data for global\napplicability. However, the effectiveness of PIML relies on the similarity\nbetween the test and trained data. Nevertheless, a possible strategy to\novercome this limitation involves initial pretraining of a PIML architecture\nwith data from a broader region, followed by fine-tuning for specific data-a\nmethod reminiscent of the way large language models are pretrained and adapted\nfor various tasks.",
          "link": "http://arxiv.org/abs/2310.08109",
          "publishedOn": "2023-10-14T00:41:32.269Z",
          "wordCount": 742,
          "title": "Overview of Physics-Informed Machine Learning Inversion of Geophysical Data. (arXiv:2310.08109v1 [physics.geo-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianchao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuzhe Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1\">Jiaqi Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1\">Quan Z. Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xi Zheng</a>",
          "description": "Brain-Computer Interfaces (BCIs) are a groundbreaking technology for\ninteracting with external devices using brain signals. Despite advancements,\nelectroencephalogram (EEG)-based Motor Imagery (MI) tasks face challenges like\namplitude and phase variability, and complex spatial correlations, with a need\nfor smaller model size and faster inference. This study introduces the LGL-BCI\nframework, employing a Geometric Deep Learning Framework for EEG processing in\nnon-Euclidean metric spaces, particularly the Symmetric Positive Definite (SPD)\nManifold space. LGL-BCI offers robust EEG data representation and captures\nspatial correlations. We propose an EEG channel selection solution via a\nfeature decomposition algorithm to reduce SPD matrix dimensionality, with a\nlossless transformation boosting inference speed. Extensive experiments show\nLGL-BCI's superior accuracy and efficiency compared to current solutions,\nhighlighting geometric deep learning's potential in MI-BCI applications. The\nefficiency, assessed on two public EEG datasets and two real-world EEG devices,\nsignificantly outperforms the state-of-the-art solution in accuracy ($82.54\\%$\nversus $62.22\\%$) with fewer parameters (64.9M compared to 183.7M).",
          "link": "http://arxiv.org/abs/2310.08051",
          "publishedOn": "2023-10-14T00:41:32.182Z",
          "wordCount": 674,
          "title": "LGL-BCI: A Lightweight Geometric Learning Framework for Motor Imagery-Based Brain-Computer Interfaces. (arXiv:2310.08051v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1\">Minseok Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gwak_C/0/1/0/all/0/1\">Chaeheon Gwak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Si Hyeong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jaegul Choo</a>",
          "description": "Keyphrase generation (KG) aims to generate a set of summarizing words or\nphrases given a source document, while keyphrase extraction (KE) aims to\nidentify them from the text. Because the search space is much smaller in KE, it\nis often combined with KG to predict keyphrases that may or may not exist in\nthe corresponding document. However, current unified approaches adopt sequence\nlabeling and maximization-based generation that primarily operate at a token\nlevel, falling short in observing and scoring keyphrases as a whole. In this\nwork, we propose SimCKP, a simple contrastive learning framework that consists\nof two stages: 1) An extractor-generator that extracts keyphrases by learning\ncontext-aware phrase-level representations in a contrastive manner while also\ngenerating keyphrases that do not appear in the document; 2) A reranker that\nadapts scores for each generated phrase by likewise aligning their\nrepresentations with the corresponding document. Experimental results on\nmultiple benchmark datasets demonstrate the effectiveness of our proposed\napproach, which outperforms the state-of-the-art models by a significant\nmargin.",
          "link": "http://arxiv.org/abs/2310.08221",
          "publishedOn": "2023-10-14T00:41:32.038Z",
          "wordCount": 674,
          "title": "SimCKP: Simple Contrastive Learning of Keyphrase Representations. (arXiv:2310.08221v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.13660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Ying Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apruzzese_G/0/1/0/all/0/1\">Giovanni Apruzzese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1\">Mauro Conti</a>",
          "description": "Existing literature on adversarial Machine Learning (ML) focuses either on\nshowing attacks that break every ML model, or defenses that withstand most\nattacks. Unfortunately, little consideration is given to the actual feasibility\nof the attack or the defense. Moreover, adversarial samples are often crafted\nin the \"feature-space\", making the corresponding evaluations of questionable\nvalue. Simply put, the current situation does not allow to estimate the actual\nthreat posed by adversarial attacks, leading to a lack of secure ML systems.\n\nWe aim to clarify such confusion in this paper. By considering the\napplication of ML for Phishing Website Detection (PWD), we formalize the\n\"evasion-space\" in which an adversarial perturbation can be introduced to fool\na ML-PWD -- demonstrating that even perturbations in the \"feature-space\" are\nuseful. Then, we propose a realistic threat model describing evasion attacks\nagainst ML-PWD that are cheap to stage, and hence intrinsically more attractive\nfor real phishers. After that, we perform the first statistically validated\nassessment of state-of-the-art ML-PWD against 12 evasion attacks. Our\nevaluation shows (i) the true efficacy of evasion attempts that are more likely\nto occur; and (ii) the impact of perturbations crafted in different\nevasion-spaces. Our realistic evasion attempts induce a statistically\nsignificant degradation (3-10% at p<0.05), and their cheap cost makes them a\nsubtle threat. Notably, however, some ML-PWD are immune to our most realistic\nattacks (p=0.22).\n\nFinally, as an additional contribution of this journal publication, we are\nthe first to consider the intriguing case wherein an attacker introduces\nperturbations in multiple evasion-spaces at the same time. These new results\nshow that simultaneously applying perturbations in the problem- and\nfeature-space can cause a drop in the detection rate from 0.95 to 0.",
          "link": "http://arxiv.org/abs/2210.13660",
          "publishedOn": "2023-10-14T00:41:31.829Z",
          "wordCount": 845,
          "title": "Multi-SpacePhish: Extending the Evasion-space of Adversarial Attacks against Phishing Website Detectors using Machine Learning. (arXiv:2210.13660v3 [cs.CR] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.13869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1\">Minseok Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1\">Hyesu Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jaegul Choo</a>",
          "description": "Document-level relation extraction (DocRE) aims to extract relations of all\nentity pairs in a document. A key challenge in DocRE is the cost of annotating\nsuch data which requires intensive human effort. Thus, we investigate the case\nof DocRE in a low-resource setting, and we find that existing models trained on\nlow data overestimate the NA (\"no relation\") label, causing limited\nperformance. In this work, we approach the problem from a calibration\nperspective and propose PRiSM, which learns to adapt logits based on relation\nsemantic information. We evaluate our method on three DocRE datasets and\ndemonstrate that integrating existing models with PRiSM improves performance by\nas much as 26.38 F1 score, while the calibration error drops as much as 36\ntimes when trained with about 3% of data. The code is publicly available at\nhttps://github.com/brightjade/PRiSM.",
          "link": "http://arxiv.org/abs/2309.13869",
          "publishedOn": "2023-10-14T00:41:31.680Z",
          "wordCount": 652,
          "title": "PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration. (arXiv:2309.13869v1 [cs.CL] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.15395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zihan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Honghao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_L/0/1/0/all/0/1\">Lei Ying</a>",
          "description": "This paper considers the best policy identification (BPI) problem in online\nConstrained Markov Decision Processes (CMDPs). We are interested in algorithms\nthat are model-free, have low regret, and identify an optimal policy with a\nhigh probability. Existing model-free algorithms for online CMDPs with\nsublinear regret and constraint violation do not provide any convergence\nguarantee to an optimal policy and provide only average performance guarantees\nwhen a policy is uniformly sampled at random from all previously used policies.\nIn this paper, we develop a new algorithm, named\nPruning-Refinement-Identification (PRI), based on a fundamental structural\nproperty of CMDPs we discover, called limited stochasticity. The property says\nfor a CMDP with $N$ constraints, there exists an optimal policy with at most\n$N$ stochastic decisions.\n\nThe proposed algorithm first identifies at which step and in which state a\nstochastic decision has to be taken and then fine-tunes the distributions of\nthese stochastic decisions. PRI achieves trio objectives: (i) PRI is a\nmodel-free algorithm; and (ii) it outputs a near-optimal policy with a high\nprobability at the end of learning; and (iii) in the tabular setting, PRI\nguarantees $\\tilde{\\mathcal{O}}(\\sqrt{K})$ regret and constraint violation,\nwhich significantly improves the best existing regret bound\n$\\tilde{\\mathcal{O}}(K^{\\frac{4}{5}})$ under a model-free algorithm, where $K$\nis the total number of episodes.",
          "link": "http://arxiv.org/abs/2309.15395",
          "publishedOn": "2023-10-14T00:41:31.621Z",
          "wordCount": 727,
          "title": "Model-Free, Regret-Optimal Best Policy Identification in Online CMDPs. (arXiv:2309.15395v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chaoqi Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_W/0/1/0/all/0/1\">Weiqiang Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_L/0/1/0/all/0/1\">Lifeng Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yuchen Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jianle Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_P/0/1/0/all/0/1\">Peng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hongliang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinzhu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1\">Wangmeng Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanli Ouyang</a>",
          "description": "With the success of large-scale pretraining in NLP, there is an increasing\ntrend of applying it to the domain of life sciences. In particular, pretraining\nmethods based on DNA sequences have garnered growing attention due to their\npotential to capture generic information about genes. However, existing\npretraining methods for DNA sequences largely rely on direct adoptions of BERT\npretraining from NLP, lacking a comprehensive understanding and a specifically\ntailored approach. To address this research gap, we first conducted a series of\nexploratory experiments and gained several insightful observations: 1) In the\nfine-tuning phase of downstream tasks, when using K-mer overlapping\ntokenization instead of K-mer non-overlapping tokenization, both overlapping\nand non-overlapping pretraining weights show consistent performance\nimprovement.2) During the pre-training process, using K-mer overlapping\ntokenization quickly produces clear K-mer embeddings and reduces the loss to a\nvery low level, while using K-mer non-overlapping tokenization results in less\ndistinct embeddings and continuously decreases the loss. 3) Using overlapping\ntokenization causes the self-attention in the intermediate layers of\npre-trained models to tend to overly focus on certain tokens, reflecting that\nthese layers are not adequately optimized. In summary, overlapping tokenization\ncan benefit the fine-tuning of downstream tasks but leads to inadequate\npretraining with fast convergence. To unleash the pretraining potential, we\nintroduce a novel approach called RandomMask, which gradually increases the\ntask difficulty of BERT-like pretraining by continuously expanding its mask\nboundary, forcing the model to learn more knowledge. RandomMask is simple but\neffective, achieving top-tier performance across 26 datasets of 28 datasets\nspanning 7 downstream tasks.",
          "link": "http://arxiv.org/abs/2310.07644",
          "publishedOn": "2023-10-14T00:41:31.613Z",
          "wordCount": 781,
          "title": "Rethinking the BERT-like Pretraining for DNA Sequences. (arXiv:2310.07644v2 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.02010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahdavi_S/0/1/0/all/0/1\">Sadegh Mahdavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1\">Renjie Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "Transformers have become the go-to architecture for language and vision\ntasks, yet their theoretical properties, especially memorization capacity,\nremain elusive. This paper investigates the memorization abilities of\nmulti-head attention mechanisms, examining how many example sequences they can\nmemorize, as a function of the number of heads and sequence length. Motivated\nby experimental findings on vision transformers, we introduce novel assumptions\nabout the linear independence of input data, distinct from the commonly used\ngeneral-position assumption. Under these assumptions, we demonstrate that an\nattention layer with $H$ heads, dimension $d$, and context size $n < d$,\nfeaturing $\\Theta(Hd^2)$ parameters, can memorize $\\Omega(Hn)$ examples. Our\nanalysis sheds light on how different attention heads handle various example\nsequences, aided by the softmax operator's saturation property. We validate our\nfindings through experiments on synthetic data.",
          "link": "http://arxiv.org/abs/2306.02010",
          "publishedOn": "2023-10-14T00:41:31.582Z",
          "wordCount": 642,
          "title": "Memorization Capacity of Multi-Head Attention in Transformers. (arXiv:2306.02010v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changhe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pourkeshavarz_M/0/1/0/all/0/1\">Mozhgan Pourkeshavarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasouli_A/0/1/0/all/0/1\">Amir Rasouli</a>",
          "description": "Benchmarking is a common method for evaluating trajectory prediction models\nfor autonomous driving. Existing benchmarks rely on datasets, which are biased\ntowards more common scenarios, such as cruising, and distance-based metrics\nthat are computed by averaging over all scenarios. Following such a regiment\nprovides a little insight into the properties of the models both in terms of\nhow well they can handle different scenarios and how admissible and diverse\ntheir outputs are. There exist a number of complementary metrics designed to\nmeasure the admissibility and diversity of trajectories, however, they suffer\nfrom biases, such as length of trajectories.\n\nIn this paper, we propose a new benChmarking paRadIgm for evaluaTing\ntrajEctoRy predIction Approaches (CRITERIA). Particularly, we propose 1) a\nmethod for extracting driving scenarios at varying levels of specificity\naccording to the structure of the roads, models' performance, and data\nproperties for fine-grained ranking of prediction models; 2) A set of new\nbias-free metrics for measuring diversity, by incorporating the characteristics\nof a given scenario, and admissibility, by considering the structure of roads\nand kinematic compliancy, motivated by real-world driving constraints. 3) Using\nthe proposed benchmark, we conduct extensive experimentation on a\nrepresentative set of the prediction models using the large scale Argoverse\ndataset. We show that the proposed benchmark can produce a more accurate\nranking of the models and serve as a means of characterizing their behavior. We\nfurther present ablation studies to highlight contributions of different\nelements that are used to compute the proposed metrics.",
          "link": "http://arxiv.org/abs/2310.07794",
          "publishedOn": "2023-10-14T00:41:31.458Z",
          "wordCount": 771,
          "title": "CRITERIA: a New Benchmarking Paradigm for Evaluating Trajectory Prediction Models for Autonomous Driving. (arXiv:2310.07794v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1910.09143",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_Y/0/1/0/all/0/1\">Yijia Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Poloczek_M/0/1/0/all/0/1\">Matthias Poloczek</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jiang_D/0/1/0/all/0/1\">Daniel R. Jiang</a>",
          "description": "Reinforcement learning in sparse-reward navigation environments with\nexpensive and limited interactions is challenging and poses a need for\neffective exploration. Motivated by complex navigation tasks that require\nreal-world training (when cheap simulators are not available), we consider an\nagent that faces an unknown distribution of environments and must decide on an\nexploration strategy. It may leverage a series of training environments to\nimprove its policy before it is evaluated in a test environment drawn from the\nsame environment distribution. Most existing approaches focus on fixed\nexploration strategies, while the few that view exploration as a\nmeta-optimization problem tend to ignore the need for cost-efficient\nexploration. We propose a cost-aware Bayesian optimization approach that\nefficiently searches over a class of dynamic subgoal-based exploration\nstrategies. The algorithm adjusts a variety of levers -- the locations of the\nsubgoals, the length of each episode, and the number of replications per trial\n-- in order to overcome the challenges of sparse rewards, expensive\ninteractions, and noise. An experimental evaluation demonstrates that the new\napproach outperforms existing baselines across a number of problem domains. We\nalso provide a theoretical foundation and prove that the method asymptotically\nidentifies a near-optimal subgoal design.",
          "link": "http://arxiv.org/abs/1910.09143",
          "publishedOn": "2023-10-14T00:41:31.451Z",
          "wordCount": 740,
          "title": "Dynamic Subgoal-based Exploration via Bayesian Optimization. (arXiv:1910.09143v5 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.10886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1\">Mingqi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>",
          "description": "We present AIRS: Automatic Intrinsic Reward Shaping that intelligently and\nadaptively provides high-quality intrinsic rewards to enhance exploration in\nreinforcement learning (RL). More specifically, AIRS selects shaping function\nfrom a predefined set based on the estimated task return in real-time,\nproviding reliable exploration incentives and alleviating the biased objective\nproblem. Moreover, we develop an intrinsic reward toolkit to provide efficient\nand reliable implementations of diverse intrinsic reward approaches. We test\nAIRS on various tasks of MiniGrid, Procgen, and DeepMind Control Suite.\nExtensive simulation demonstrates that AIRS can outperform the benchmarking\nschemes and achieve superior performance with simple architecture.",
          "link": "http://arxiv.org/abs/2301.10886",
          "publishedOn": "2023-10-14T00:41:31.424Z",
          "wordCount": 672,
          "title": "Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning. (arXiv:2301.10886v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boutsikas_C/0/1/0/all/0/1\">Christos Boutsikas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drineas_P/0/1/0/all/0/1\">Petros Drineas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mertzanidis_M/0/1/0/all/0/1\">Marios Mertzanidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Psomas_A/0/1/0/all/0/1\">Alexandros Psomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_P/0/1/0/all/0/1\">Paritosh Verma</a>",
          "description": "We consider the problem of a revenue-maximizing seller with a large number of\nitems $m$ for sale to $n$ strategic bidders, whose valuations are drawn\nindependently from high-dimensional, unknown prior distributions. It is\nwell-known that optimal and even approximately-optimal mechanisms for this\nsetting are notoriously difficult to characterize or compute, and, even when\nthey can be found, are often rife with various counter-intuitive properties. In\nthis paper, following a model introduced recently by Cai and\nDaskalakis~\\cite{cai2022recommender}, we consider the case that bidders' prior\ndistributions can be well-approximated by a topic model. We design an active\nlearning component, responsible for interacting with the bidders and outputting\nlow-dimensional approximations of their types, and a mechanism design\ncomponent, responsible for robustifying mechanisms for the low-dimensional\nmodel to work for the approximate types of the former component. On the active\nlearning front, we cast our problem in the framework of Randomized Linear\nAlgebra (RLA) for regression problems, allowing us to import several\nbreakthrough results from that line of research, and adapt them to our setting.\nOn the mechanism design front, we remove many restrictive assumptions of prior\nwork on the type of access needed to the underlying distributions and the\nassociated mechanisms. To the best of our knowledge, our work is the first to\nformulate connections between mechanism design, and RLA for active learning of\nregression problems, opening the door for further applications of randomized\nlinear algebra primitives to mechanism design.",
          "link": "http://arxiv.org/abs/2310.07874",
          "publishedOn": "2023-10-14T00:41:31.418Z",
          "wordCount": 769,
          "title": "Refined Mechanism Design for Approximately Structured Priors via Active Regression. (arXiv:2310.07874v1 [cs.GT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiaoyang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wenbo Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nouiehed_M/0/1/0/all/0/1\">Maher Nouiehed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kontar_R/0/1/0/all/0/1\">Raed Al Kontar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Judy Jin</a>",
          "description": "Current techniques for Out-of-Distribution (OoD) detection predominantly rely\non quantifying predictive uncertainty and incorporating model regularization\nduring the training phase, using either real or synthetic OoD samples. However,\nmethods that utilize real OoD samples lack exploration and are prone to overfit\nthe OoD samples at hand. Whereas synthetic samples are often generated based on\nfeatures extracted from training data, rendering them less effective when the\ntraining and OoD data are highly overlapped in the feature space. In this work,\nwe propose a Wasserstein-score-based generative adversarial training scheme to\nenhance OoD detection accuracy, which, for the first time, performs data\naugmentation and exploration simultaneously under the supervision of limited\nOoD samples. Specifically, the generator explores OoD spaces and generates\nsynthetic OoD samples using feedback from the discriminator, while the\ndiscriminator exploits both the observed and synthesized samples for OoD\ndetection using a predefined Wasserstein score. We provide theoretical\nguarantees that the optimal solutions of our generative scheme are\nstatistically achievable through adversarial training in empirical settings. We\nthen demonstrate that the proposed method outperforms state-of-the-art\ntechniques on various computer vision datasets and exhibits superior\ngeneralizability to unseen OoD data.",
          "link": "http://arxiv.org/abs/2310.08040",
          "publishedOn": "2023-10-14T00:41:31.413Z",
          "wordCount": 687,
          "title": "SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection. (arXiv:2310.08040v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gan_J/0/1/0/all/0/1\">Jingru Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xinzhe Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qingming Huang</a>",
          "description": "Given an image and an associated textual question, the purpose of\nKnowledge-Based Visual Question Answering (KB-VQA) is to provide a correct\nanswer to the question with the aid of external knowledge bases. Prior KB-VQA\nmodels are usually formulated as a retriever-classifier framework, where a\npre-trained retriever extracts textual or visual information from knowledge\ngraphs and then makes a prediction among the candidates. Despite promising\nprogress, there are two drawbacks with existing models. Firstly, modeling\nquestion-answering as multi-class classification limits the answer space to a\npreset corpus and lacks the ability of flexible reasoning. Secondly, the\nclassifier merely consider \"what is the answer\" without \"how to get the\nanswer\", which cannot ground the answer to explicit reasoning paths. In this\npaper, we confront the challenge of \\emph{explainable open-set} KB-VQA, where\nthe system is required to answer questions with entities at wild and retain an\nexplainable reasoning path. To resolve the aforementioned issues, we propose a\nnew retriever-ranker paradigm of KB-VQA, Graph pATH rankER (GATHER for\nbrevity). Specifically, it contains graph constructing, pruning, and path-level\nranking, which not only retrieves accurate answers but also provides inference\npaths that explain the reasoning process. To comprehensively evaluate our\nmodel, we reformulate the benchmark dataset OK-VQA with manually corrected\nentity-level annotations and release it as ConceptVQA. Extensive experiments on\nreal-world questions demonstrate that our framework is not only able to perform\nopen-set question answering across the whole knowledge base but provide\nexplicit reasoning path.",
          "link": "http://arxiv.org/abs/2310.08148",
          "publishedOn": "2023-10-14T00:41:31.408Z",
          "wordCount": 741,
          "title": "Open-Set Knowledge-Based Visual Question Answering with Inference Paths. (arXiv:2310.08148v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.06599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>",
          "description": "Existing regression models tend to fall short in both accuracy and\nuncertainty estimation when the label distribution is imbalanced. In this\npaper, we propose a probabilistic deep learning model, dubbed variational\nimbalanced regression (VIR), which not only performs well in imbalanced\nregression but naturally produces reasonable uncertainty estimation as a\nbyproduct. Different from typical variational autoencoders assuming I.I.D.\nrepresentations (a data point's representation is not directly affected by\nother data points), our VIR borrows data with similar regression labels to\ncompute the latent representation's variational distribution; furthermore,\ndifferent from deterministic regression models producing point estimates, VIR\npredicts the entire normal-inverse-gamma distributions and modulates the\nassociated conjugate distributions to impose probabilistic reweighting on the\nimbalanced data, thereby providing better uncertainty estimation. Experiments\nin several real-world datasets show that our VIR can outperform\nstate-of-the-art imbalanced regression models in terms of both accuracy and\nuncertainty estimation. Code will soon be available at\n\\url{https://github.com/Wang-ML-Lab/variational-imbalanced-regression}.",
          "link": "http://arxiv.org/abs/2306.06599",
          "publishedOn": "2023-10-14T00:41:31.391Z",
          "wordCount": 713,
          "title": "Variational Imbalanced Regression: Fair Uncertainty Quantification via Probabilistic Smoothing. (arXiv:2306.06599v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08339",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guillou_E/0/1/0/all/0/1\">Eve Le Guillou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Will_M/0/1/0/all/0/1\">Michael Will</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guillou_P/0/1/0/all/0/1\">Pierre Guillou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasczyk_J/0/1/0/all/0/1\">Jonas Lukasczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fortin_P/0/1/0/all/0/1\">Pierre Fortin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garth_C/0/1/0/all/0/1\">Christoph Garth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tierny_J/0/1/0/all/0/1\">Julien Tierny</a>",
          "description": "This system paper presents a software framework for the support of\ntopological analysis pipelines in a distributed-memory model. While several\nrecent papers introduced topology-based approaches for distributed-memory\nenvironments, these were reporting experiments obtained with tailored,\nmono-algorithm implementations. In contrast, we describe in this paper a\ngeneral-purpose, generic framework for topological analysis pipelines, i.e. a\nsequence of topological algorithms interacting together, possibly on distinct\nnumbers of processes. Specifically, we instantiated our framework with the MPI\nmodel, within the Topology ToolKit (TTK). While developing this framework, we\nfaced several algorithmic and software engineering challenges, which we\ndocument in this paper. We provide a taxonomy for the distributed-memory\ntopological algorithms supported by TTK, depending on their communication needs\nand provide examples of hybrid MPI+thread parallelizations. Detailed\nperformance analyses show that parallel efficiencies range from $20\\%$ to\n$80\\%$ (depending on the algorithms), and that the MPI-specific preconditioning\nintroduced by our framework induces a negligible computation time overhead. We\nillustrate the new distributed-memory capabilities of TTK with an example of\nadvanced analysis pipeline, combining multiple algorithms, run on the largest\npublicly available dataset we have found (120 billion vertices) on a standard\ncluster with 64 nodes (for a total of 1,536 cores). Finally, we provide a\nroadmap for the completion of TTK's MPI extension, along with generic\nrecommendations for each algorithm communication category.",
          "link": "http://arxiv.org/abs/2310.08339",
          "publishedOn": "2023-10-14T00:41:31.381Z",
          "wordCount": 754,
          "title": "A Generic Software Framework for Distributed Topological Analysis Pipelines. (arXiv:2310.08339v1 [cs.DC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mucsanyi_B/0/1/0/all/0/1\">B&#xe1;lint Mucs&#xe1;nyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchhof_M/0/1/0/all/0/1\">Michael Kirchhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_E/0/1/0/all/0/1\">Elisa Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_A/0/1/0/all/0/1\">Alexander Rubinstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seong Joon Oh</a>",
          "description": "As machine learning technology gets applied to actual products and solutions,\nnew challenges have emerged. Models unexpectedly fail to generalize to small\nchanges in the distribution, tend to be confident on novel data they have never\nseen, or cannot communicate the rationale behind their decisions effectively\nwith the end users. Collectively, we face a trustworthiness issue with the\ncurrent machine learning technology. This textbook on Trustworthy Machine\nLearning (TML) covers a theoretical and technical background of four key topics\nin TML: Out-of-Distribution Generalization, Explainability, Uncertainty\nQuantification, and Evaluation of Trustworthiness. We discuss important\nclassical and contemporary research papers of the aforementioned fields and\nuncover and connect their underlying intuitions. The book evolved from the\nhomonymous course at the University of T\\\"ubingen, first offered in the Winter\nSemester of 2022/23. It is meant to be a stand-alone product accompanied by\ncode snippets and various pointers to further sources on topics of TML. The\ndedicated website of the book is https://trustworthyml.io/.",
          "link": "http://arxiv.org/abs/2310.08215",
          "publishedOn": "2023-10-14T00:41:31.376Z",
          "wordCount": 678,
          "title": "Trustworthy Machine Learning. (arXiv:2310.08215v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08237",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_X/0/1/0/all/0/1\">Xingdong Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_X/0/1/0/all/0/1\">Xin He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1\">Caixing Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1\">Chao Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jingnan Zhang</a>",
          "description": "Covariate shift occurs prevalently in practice, where the input distributions\nof the source and target data are substantially different. Despite its\npractical importance in various learning problems, most of the existing methods\nonly focus on some specific learning tasks and are not well validated\ntheoretically and numerically. To tackle this problem, we propose a unified\nanalysis of general nonparametric methods in a reproducing kernel Hilbert space\n(RKHS) under covariate shift. Our theoretical results are established for a\ngeneral loss belonging to a rich loss function family, which includes many\ncommonly used methods as special cases, such as mean regression, quantile\nregression, likelihood-based classification, and margin-based classification.\nTwo types of covariate shift problems are the focus of this paper and the sharp\nconvergence rates are established for a general loss function to provide a\nunified theoretical analysis, which concurs with the optimal results in\nliterature where the squared loss is used. Extensive numerical studies on\nsynthetic and real examples confirm our theoretical findings and further\nillustrate the effectiveness of our proposed method.",
          "link": "http://arxiv.org/abs/2310.08237",
          "publishedOn": "2023-10-14T00:41:31.362Z",
          "wordCount": 697,
          "title": "Towards a Unified Analysis of Kernel-based Methods Under Covariate Shift. (arXiv:2310.08237v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07990",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_C/0/1/0/all/0/1\">Chen Zhao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Su_K/0/1/0/all/0/1\">Kuan-Jui Su</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_C/0/1/0/all/0/1\">Chong Wu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cao_X/0/1/0/all/0/1\">Xuewei Cao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sha_Q/0/1/0/all/0/1\">Qiuying Sha</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_W/0/1/0/all/0/1\">Wu Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Luo_Z/0/1/0/all/0/1\">Zhe Luo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qin_T/0/1/0/all/0/1\">Tian Qin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qiu_C/0/1/0/all/0/1\">Chuan Qiu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_L/0/1/0/all/0/1\">Lan Juan Zhao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_A/0/1/0/all/0/1\">Anqi Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jiang_L/0/1/0/all/0/1\">Lindong Jiang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Shen_H/0/1/0/all/0/1\">Hui Shen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhou_W/0/1/0/all/0/1\">Weihua Zhou</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deng_H/0/1/0/all/0/1\">Hong-Wen Deng</a>",
          "description": "Background: Missing data is a common challenge in mass spectrometry-based\nmetabolomics, which can lead to biased and incomplete analyses. The integration\nof whole-genome sequencing (WGS) data with metabolomics data has emerged as a\npromising approach to enhance the accuracy of data imputation in metabolomics\nstudies. Method: In this study, we propose a novel method that leverages the\ninformation from WGS data and reference metabolites to impute unknown\nmetabolites. Our approach utilizes a multi-view variational autoencoder to\njointly model the burden score, polygenetic risk score (PGS), and linkage\ndisequilibrium (LD) pruned single nucleotide polymorphisms (SNPs) for feature\nextraction and missing metabolomics data imputation. By learning the latent\nrepresentations of both omics data, our method can effectively impute missing\nmetabolomics values based on genomic information. Results: We evaluate the\nperformance of our method on empirical metabolomics datasets with missing\nvalues and demonstrate its superiority compared to conventional imputation\ntechniques. Using 35 template metabolites derived burden scores, PGS and\nLD-pruned SNPs, the proposed methods achieved r2-scores > 0.01 for 71.55% of\nmetabolites. Conclusion: The integration of WGS data in metabolomics imputation\nnot only improves data completeness but also enhances downstream analyses,\npaving the way for more comprehensive and accurate investigations of metabolic\npathways and disease associations. Our findings offer valuable insights into\nthe potential benefits of utilizing WGS data for metabolomics data imputation\nand underscore the importance of leveraging multi-modal data integration in\nprecision medicine research.",
          "link": "http://arxiv.org/abs/2310.07990",
          "publishedOn": "2023-10-14T00:41:31.272Z",
          "wordCount": 773,
          "title": "Multi-View Variational Autoencoder for Missing Value Imputation in Untargeted Metabolomics. (arXiv:2310.07990v1 [q-bio.GN])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianrong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiatao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinh_L/0/1/0/all/0/1\">Laurent Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1\">Evangelos A. Theodorou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susskind_J/0/1/0/all/0/1\">Josh Susskind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_S/0/1/0/all/0/1\">Shuangfei Zhai</a>",
          "description": "Diffusion models (DMs) represent state-of-the-art generative models for\ncontinuous inputs. DMs work by constructing a Stochastic Differential Equation\n(SDE) in the input space (ie, position space), and using a neural network to\nreverse it. In this work, we introduce a novel generative modeling framework\ngrounded in \\textbf{phase space dynamics}, where a phase space is defined as\n{an augmented space encompassing both position and velocity.} Leveraging\ninsights from Stochastic Optimal Control, we construct a path measure in the\nphase space that enables efficient sampling. {In contrast to DMs, our framework\ndemonstrates the capability to generate realistic data points at an early stage\nof dynamics propagation.} This early prediction sets the stage for efficient\ndata generation by leveraging additional velocity information along the\ntrajectory. On standard image generation benchmarks, our model yields favorable\nperformance over baselines in the regime of small Number of Function\nEvaluations (NFEs). Furthermore, our approach rivals the performance of\ndiffusion models equipped with efficient sampling techniques, underscoring its\npotential as a new tool generative modeling.",
          "link": "http://arxiv.org/abs/2310.07805",
          "publishedOn": "2023-10-14T00:41:31.195Z",
          "wordCount": 670,
          "title": "Generative Modeling with Phase Stochastic Bridges. (arXiv:2310.07805v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.07189",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dorosti_T/0/1/0/all/0/1\">Tina Dorosti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schultheiss_M/0/1/0/all/0/1\">Manuel Schultheiss</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hofmann_F/0/1/0/all/0/1\">Felix Hofmann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thalhammer_J/0/1/0/all/0/1\">Johannes Thalhammer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kirchner_L/0/1/0/all/0/1\">Luisa Kirchner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Urban_T/0/1/0/all/0/1\">Theresa Urban</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pfeiffer_F/0/1/0/all/0/1\">Franz Pfeiffer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schaff_F/0/1/0/all/0/1\">Florian Schaff</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lasser_T/0/1/0/all/0/1\">Tobias Lasser</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pfeiffer_D/0/1/0/all/0/1\">Daniela Pfeiffer</a>",
          "description": "We aim to optimize the binary detection of Chronic Obstructive Pulmonary\nDisease (COPD) based on emphysema presence in the lung with convolutional\nneural networks (CNN) by exploring manually adjusted versus automated\nwindow-setting optimization (WSO) on computed tomography (CT) images. 7,194 CT\nimages (3,597 with COPD; 3,597 healthy controls) from 78 subjects (43 with\nCOPD; 35 healthy controls) were selected retrospectively (10.2018-12.2019) and\npreprocessed. For each image, intensity values were manually clipped to the\nemphysema window setting and a baseline 'full-range' window setting.\nClass-balanced train, validation, and test sets contained 3,392, 1,114, and\n2,688 images. The network backbone was optimized by comparing various CNN\narchitectures. Furthermore, automated WSO was implemented by adding a\ncustomized layer to the model. The image-level area under the Receiver\nOperating Characteristics curve (AUC) [lower, upper limit 95% confidence] was\nutilized to compare model variations. Repeated inference (n=7) on the test set\nshowed that the DenseNet was the most efficient backbone and achieved a mean\nAUC of 0.80 [0.76, 0.85] without WSO. Comparably, with input images manually\nadjusted to the emphysema window, the DenseNet model predicted COPD with a mean\nAUC of 0.86 [0.82, 0.89]. By adding a customized WSO layer to the DenseNet, an\noptimal window in the proximity of the emphysema window setting was learned\nautomatically, and a mean AUC of 0.82 [0.78, 0.86] was achieved. Detection of\nCOPD with DenseNet models was improved by WSO of CT data to the emphysema\nwindow setting range.",
          "link": "http://arxiv.org/abs/2303.07189",
          "publishedOn": "2023-10-14T00:41:31.187Z",
          "wordCount": 818,
          "title": "Optimizing Convolutional Neural Networks for Chronic Obstructive Pulmonary Disease Detection in Clinical Computed Tomography Imaging. (arXiv:2303.07189v3 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.02621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jonnarth_A/0/1/0/all/0/1\">Arvi Jonnarth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yushan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Felsberg_M/0/1/0/all/0/1\">Michael Felsberg</a>",
          "description": "Image-level weakly-supervised semantic segmentation (WSSS) reduces the\nusually vast data annotation cost by surrogate segmentation masks during\ntraining. The typical approach involves training an image classification\nnetwork using global average pooling (GAP) on convolutional feature maps. This\nenables the estimation of object locations based on class activation maps\n(CAMs), which identify the importance of image regions. The CAMs are then used\nto generate pseudo-labels, in the form of segmentation masks, to supervise a\nsegmentation model in the absence of pixel-level ground truth. Our work is\nbased on two techniques for improving CAMs; importance sampling, which is a\nsubstitute for GAP, and the feature similarity loss, which utilizes a heuristic\nthat object contours almost always align with color edges in images. However,\nboth are based on the multinomial posterior with softmax, and implicitly assume\nthat classes are mutually exclusive, which turns out suboptimal in our\nexperiments. Thus, we reformulate both techniques based on binomial posteriors\nof multiple independent binary problems. This has two benefits; their\nperformance is improved and they become more general, resulting in an add-on\nmethod that can boost virtually any WSSS method. This is demonstrated on a wide\nvariety of baselines on the PASCAL VOC dataset, improving the region similarity\nand contour quality of all implemented state-of-the-art methods. Experiments on\nthe MS COCO dataset show that our proposed add-on is well-suited for\nlarge-scale settings. Our code is available at https://github.com/arvijj/hfpl.",
          "link": "http://arxiv.org/abs/2304.02621",
          "publishedOn": "2023-10-14T00:41:31.180Z",
          "wordCount": 751,
          "title": "High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation. (arXiv:2304.02621v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15394",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vos_D/0/1/0/all/0/1\">Dani&#xeb;l Vos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vos_J/0/1/0/all/0/1\">Jelle Vos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erkin_Z/0/1/0/all/0/1\">Zekeriya Erkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verwer_S/0/1/0/all/0/1\">Sicco Verwer</a>",
          "description": "Decision trees are interpretable models that are well-suited to non-linear\nlearning problems. Much work has been done on extending decision tree learning\nalgorithms with differential privacy, a system that guarantees the privacy of\nsamples within the training data. However, current state-of-the-art algorithms\nfor this purpose sacrifice much utility for a small privacy benefit. These\nsolutions create random decision nodes that reduce decision tree accuracy or\nspend an excessive share of the privacy budget on labeling leaves. Moreover,\nmany works do not support continuous features or leak information about them.\nWe propose a new method called PrivaTree based on private histograms that\nchooses good splits while consuming a small privacy budget. The resulting trees\nprovide a significantly better privacy-utility trade-off and accept mixed\nnumerical and categorical data without leaking information about numerical\nfeatures. Finally, while it is notoriously hard to give robustness guarantees\nagainst data poisoning attacks, we demonstrate bounds for the expected accuracy\nand success rates of backdoor attacks against differentially-private learners.\nBy leveraging the better privacy-utility trade-off of PrivaTree we are able to\ntrain decision trees with significantly better robustness against backdoor\nattacks compared to regular decision trees and with meaningful theoretical\nguarantees.",
          "link": "http://arxiv.org/abs/2305.15394",
          "publishedOn": "2023-10-14T00:41:31.154Z",
          "wordCount": 723,
          "title": "Differentially-Private Decision Trees and Provable Robustness to Data Poisoning. (arXiv:2305.15394v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08287",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Laurent_O/0/1/0/all/0/1\">Olivier Laurent</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aldea_E/0/1/0/all/0/1\">Emanuel Aldea</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Franchi_G/0/1/0/all/0/1\">Gianni Franchi</a>",
          "description": "The distribution of the weights of modern deep neural networks (DNNs) -\ncrucial for uncertainty quantification and robustness - is an eminently complex\nobject due to its extremely high dimensionality. This paper proposes one of the\nfirst large-scale explorations of the posterior distribution of deep Bayesian\nNeural Networks (BNNs), expanding its study to real-world vision tasks and\narchitectures. Specifically, we investigate the optimal approach for\napproximating the posterior, analyze the connection between posterior quality\nand uncertainty quantification, delve into the impact of modes on the\nposterior, and explore methods for visualizing the posterior. Moreover, we\nuncover weight-space symmetries as a critical aspect for understanding the\nposterior. To this extent, we develop an in-depth assessment of the impact of\nboth permutation and scaling symmetries that tend to obfuscate the Bayesian\nposterior. While the first type of transformation is known for duplicating\nmodes, we explore the relationship between the latter and L2 regularization,\nchallenging previous misconceptions. Finally, to help the community improve our\nunderstanding of the Bayesian posterior, we will shortly release the first\nlarge-scale checkpoint dataset, including thousands of real-world models and\nour codes.",
          "link": "http://arxiv.org/abs/2310.08287",
          "publishedOn": "2023-10-14T00:41:30.728Z",
          "wordCount": null,
          "title": "A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors. (arXiv:2310.08287v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08071",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinhong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Changsheng Xu</a>",
          "description": "Despite the great progress of unsupervised domain adaptation (UDA) with the\ndeep neural networks, current UDA models are opaque and cannot provide\npromising explanations, limiting their applications in the scenarios that\nrequire safe and controllable model decisions. At present, a surge of work\nfocuses on designing deep interpretable methods with adequate data annotations\nand only a few methods consider the distributional shift problem. Most existing\ninterpretable UDA methods are post-hoc ones, which cannot facilitate the model\nlearning process for performance enhancement. In this paper, we propose an\ninherently interpretable method, named Transferable Conceptual Prototype\nLearning (TCPL), which could simultaneously interpret and improve the processes\nof knowledge transfer and decision-making in UDA. To achieve this goal, we\ndesign a hierarchically prototypical module that transfers categorical basic\nconcepts from the source domain to the target domain and learns domain-shared\nprototypes for explaining the underlying reasoning process. With the learned\ntransferable prototypes, a self-predictive consistent pseudo-label strategy\nthat fuses confidence, predictions, and prototype information, is designed for\nselecting suitable target samples for pseudo annotations and gradually\nnarrowing down the domain gap. Comprehensive experiments show that the proposed\nmethod can not only provide effective and intuitive explanations but also\noutperform previous state-of-the-arts.",
          "link": "http://arxiv.org/abs/2310.08071",
          "publishedOn": "2023-10-14T00:41:30.523Z",
          "wordCount": 712,
          "title": "Learning Transferable Conceptual Prototypes for Interpretable Unsupervised Domain Adaptation. (arXiv:2310.08071v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shafi_Z/0/1/0/all/0/1\">Zohair Shafi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_B/0/1/0/all/0/1\">Benjamin A. Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1\">Tina Eliassi-Rad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caceres_R/0/1/0/all/0/1\">Rajmonda S. Caceres</a>",
          "description": "Machine learning (ML) approaches are increasingly being used to accelerate\ncombinatorial optimization (CO) problems. We look specifically at the Set Cover\nProblem (SCP) and propose Graph-SCP, a graph neural network method that can\naugment existing optimization solvers by learning to identify a much smaller\nsub-problem that contains the solution space. We evaluate the performance of\nGraph-SCP on synthetic weighted and unweighted SCP instances with diverse\nproblem characteristics and complexities, and on instances from the OR Library,\na canonical benchmark for SCP. We show that Graph-SCP reduces the problem size\nby 30-70% and achieves run time speedups up to~25x when compared to commercial\nsolvers (Gurobi). Given a desired optimality threshold, Graph-SCP will improve\nupon it or even achieve 100% optimality. This is in contrast to fast greedy\nsolutions that significantly compromise solution quality to achieve guaranteed\npolynomial run time. Graph-SCP can generalize to larger problem sizes and can\nbe used with other conventional or ML-augmented CO solvers to lead to potential\nadditional run time improvement.",
          "link": "http://arxiv.org/abs/2310.07979",
          "publishedOn": "2023-10-14T00:41:30.499Z",
          "wordCount": 674,
          "title": "Graph-SCP: Accelerating Set Cover Problems with Graph Neural Networks. (arXiv:2310.07979v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nezami_N/0/1/0/all/0/1\">Nazanin Nezami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anahideh_H/0/1/0/all/0/1\">Hadis Anahideh</a>",
          "description": "Surrogate Optimization (SO) algorithms have shown promise for optimizing\nexpensive black-box functions. However, their performance is heavily influenced\nby hyperparameters related to sampling and surrogate fitting, which poses a\nchallenge to their widespread adoption. We investigate the impact of\nhyperparameters on various SO algorithms and propose a Hyperparameter Adaptive\nSearch for SO (HASSO) approach. HASSO is not a hyperparameter tuning algorithm,\nbut a generic self-adjusting SO algorithm that dynamically tunes its own\nhyperparameters while concurrently optimizing the primary objective function,\nwithout requiring additional evaluations. The aim is to improve the\naccessibility, effectiveness, and convergence speed of SO algorithms for\npractitioners. Our approach identifies and modifies the most influential\nhyperparameters specific to each problem and SO approach, reducing the need for\nmanual tuning without significantly increasing the computational burden.\nExperimental results demonstrate the effectiveness of HASSO in enhancing the\nperformance of various SO algorithms across different global optimization test\nproblems.",
          "link": "http://arxiv.org/abs/2310.07970",
          "publishedOn": "2023-10-14T00:41:30.476Z",
          "wordCount": 667,
          "title": "Hyperparameter Adaptive Search for Surrogate Optimization: A Self-Adjusting Approach. (arXiv:2310.07970v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianfei Ma</a>",
          "description": "Temporal difference learning (TD) is a foundational concept in reinforcement\nlearning (RL), aimed at efficiently assessing a policy's value function.\nTD($\\lambda$), a potent variant, incorporates a memory trace to distribute the\nprediction error into the historical context. However, this approach often\nneglects the significance of historical states and the relative importance of\npropagating the TD error, influenced by challenges such as visitation imbalance\nor outcome noise. To address this, we propose a novel TD algorithm named\ndiscerning TD learning (DTD), which allows flexible emphasis\nfunctions$-$predetermined or adapted during training$-$to allocate efforts\neffectively across states. We establish the convergence properties of our\nmethod within a specific class of emphasis functions and showcase its promising\npotential for adaptation to deep RL contexts. Empirical results underscore that\nemploying a judicious emphasis function not only improves value estimation but\nalso expedites learning across diverse scenarios.",
          "link": "http://arxiv.org/abs/2310.08091",
          "publishedOn": "2023-10-14T00:41:30.297Z",
          "wordCount": 617,
          "title": "Discerning Temporal Difference Learning. (arXiv:2310.08091v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaquier_N/0/1/0/all/0/1\">No&#xe9;mie Jaquier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rozo_L/0/1/0/all/0/1\">Leonel Rozo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asfour_T/0/1/0/all/0/1\">Tamim Asfour</a>",
          "description": "In the realm of robotics, numerous downstream robotics tasks leverage machine\nlearning methods for processing, modeling, or synthesizing data. Often, this\ndata comprises variables that inherently carry geometric constraints, such as\nthe unit-norm condition of quaternions representing rigid-body orientations or\nthe positive definiteness of stiffness and manipulability ellipsoids. Handling\nsuch geometric constraints effectively requires the incorporation of tools from\ndifferential geometry into the formulation of machine learning methods. In this\ncontext, Riemannian manifolds emerge as a powerful mathematical framework to\nhandle such geometric constraints. Nevertheless, their recent adoption in robot\nlearning has been largely characterized by a mathematically-flawed\nsimplification, hereinafter referred to as the ``single tangent space fallacy\".\nThis approach involves merely projecting the data of interest onto a single\ntangent (Euclidean) space, over which an off-the-shelf learning algorithm is\napplied. This paper provides a theoretical elucidation of various\nmisconceptions surrounding this approach and offers experimental evidence of\nits shortcomings. Finally, it presents valuable insights to promote best\npractices when employing Riemannian geometry within robot learning\napplications.",
          "link": "http://arxiv.org/abs/2310.07902",
          "publishedOn": "2023-10-14T00:41:30.277Z",
          "wordCount": 704,
          "title": "Unraveling the Single Tangent Space Fallacy: An Analysis and Clarification for Applying Riemannian Geometry in Robot Learning. (arXiv:2310.07902v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yite Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jiahao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanlin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Cong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jianbo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haibin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruoyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Scaling of deep neural networks, especially Transformers, is pivotal for\ntheir surging performance and has further led to the emergence of sophisticated\nreasoning capabilities in foundation models. Such scaling generally requires\ntraining large models from scratch with random initialization, failing to\nleverage the knowledge acquired by their smaller counterparts, which are\nalready resource-intensive to obtain. To tackle this inefficiency, we present\n$\\textbf{L}$ossl$\\textbf{E}$ss $\\textbf{MO}$del Expansio$\\textbf{N}$ (LEMON), a\nrecipe to initialize scaled models using the weights of their smaller but\npre-trained counterparts. This is followed by model training with an optimized\nlearning rate scheduler tailored explicitly for the scaled models,\nsubstantially reducing the training time compared to training from scratch.\nNotably, LEMON is versatile, ensuring compatibility with various network\nstructures, including models like Vision Transformers and BERT. Our empirical\nresults demonstrate that LEMON reduces computational costs by 56.7% for Vision\nTransformers and 33.2% for BERT when compared to training from scratch.",
          "link": "http://arxiv.org/abs/2310.07999",
          "publishedOn": "2023-10-14T00:41:30.270Z",
          "wordCount": 652,
          "title": "LEMON: Lossless model expansion. (arXiv:2310.07999v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eggert_G/0/1/0/all/0/1\">Gus Eggert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_K/0/1/0/all/0/1\">Kevin Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biven_M/0/1/0/all/0/1\">Mike Biven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waugh_J/0/1/0/all/0/1\">Justin Waugh</a>",
          "description": "It is well-established that large, diverse datasets play a pivotal role in\nthe performance of modern AI systems for text and image modalities. However,\nthere are no datasets for tabular data of comparable size and diversity to\nthose available for text and images. Thus we present \"TabLib'', a compilation\nof 627 million tables totaling 69 TiB, along with 867B tokens of context.\nTabLib was extracted from numerous file formats, including CSV, HTML, SQLite,\nPDF, Excel, and others, sourced from GitHub and Common Crawl. The size and\ndiversity of TabLib offer considerable promise in the table modality,\nreminiscent of the original promise of foundational datasets for text and\nimages, such as The Pile and LAION.",
          "link": "http://arxiv.org/abs/2310.07875",
          "publishedOn": "2023-10-14T00:41:30.262Z",
          "wordCount": 621,
          "title": "TabLib: A Dataset of 627M Tables with Context. (arXiv:2310.07875v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07927",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Zou_Z/0/1/0/all/0/1\">Ziyue Zou</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Tiwary_P/0/1/0/all/0/1\">Pratyush Tiwary</a>",
          "description": "In this study, we present a graph neural network-based learning approach\nusing an autoencoder setup to derive low-dimensional variables from features\nobserved in experimental crystal structures. These variables are then biased in\nenhanced sampling to observe state-to-state transitions and reliable\nthermodynamic weights. Our approach uses simple convolution and pooling\nmethods. To verify the effectiveness of our protocol, we examined the\nnucleation of various allotropes and polymorphs of iron and glycine from their\nmolten states. Our graph latent variables when biased in well-tempered\nmetadynamics consistently show transitions between states and achieve accurate\nfree energy calculations in agreement with experiments, both of which are\nindicators of dependable sampling. This underscores the strength and promise of\nour graph neural net variables for improved sampling. The protocol shown here\nshould be applicable for other systems and with other sampling methods.",
          "link": "http://arxiv.org/abs/2310.07927",
          "publishedOn": "2023-10-14T00:41:30.257Z",
          "wordCount": 647,
          "title": "Enhanced sampling of Crystal Nucleation with Graph Representation Learnt Variables. (arXiv:2310.07927v1 [cond-mat.stat-mech])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weisz_G/0/1/0/all/0/1\">Gell&#xe9;rt Weisz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andr&#xe1;s Gy&#xf6;rgy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesv&#xe1;ri</a>",
          "description": "We consider online reinforcement learning (RL) in episodic Markov decision\nprocesses (MDPs) under the linear $q^\\pi$-realizability assumption, where it is\nassumed that the action-values of all policies can be expressed as linear\nfunctions of state-action features. This class is known to be more general than\nlinear MDPs, where the transition kernel and the reward function are assumed to\nbe linear functions of the feature vectors. As our first contribution, we show\nthat the difference between the two classes is the presence of states in\nlinearly $q^\\pi$-realizable MDPs where for any policy, all the actions have\napproximately equal values, and skipping over these states by following an\narbitrarily fixed policy in those states transforms the problem to a linear\nMDP. Based on this observation, we derive a novel (computationally inefficient)\nlearning algorithm for linearly $q^\\pi$-realizable MDPs that simultaneously\nlearns what states should be skipped over and runs another learning algorithm\non the linear MDP hidden in the problem. The method returns an\n$\\epsilon$-optimal policy after $\\text{polylog}(H, d)/\\epsilon^2$ interactions\nwith the MDP, where $H$ is the time horizon and $d$ is the dimension of the\nfeature vectors, giving the first polynomial-sample-complexity online RL\nalgorithm for this setting. The results are proved for the misspecified case,\nwhere the sample complexity is shown to degrade gracefully with the\nmisspecification error.",
          "link": "http://arxiv.org/abs/2310.07811",
          "publishedOn": "2023-10-14T00:41:30.237Z",
          "wordCount": 769,
          "title": "Online RL in Linearly $q^\\pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore. (arXiv:2310.07811v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gruver_N/0/1/0/all/0/1\">Nate Gruver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finzi_M/0/1/0/all/0/1\">Marc Finzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1\">Shikai Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>",
          "description": "By encoding time series as a string of numerical digits, we can frame time\nseries forecasting as next-token prediction in text. Developing this approach,\nwe find that large language models (LLMs) such as GPT-3 and LLaMA-2 can\nsurprisingly zero-shot extrapolate time series at a level comparable to or\nexceeding the performance of purpose-built time series models trained on the\ndownstream tasks. To facilitate this performance, we propose procedures for\neffectively tokenizing time series data and converting discrete distributions\nover tokens into highly flexible densities over continuous values. We argue the\nsuccess of LLMs for time series stems from their ability to naturally represent\nmultimodal distributions, in conjunction with biases for simplicity, and\nrepetition, which align with the salient features in many time series, such as\nrepeated seasonal trends. We also show how LLMs can naturally handle missing\ndata without imputation through non-numerical text, accommodate textual side\ninformation, and answer questions to help explain predictions. While we find\nthat increasing model size generally improves performance on time series, we\nshow GPT-4 can perform worse than GPT-3 because of how it tokenizes numbers,\nand poor uncertainty calibration, which is likely the result of alignment\ninterventions such as RLHF.",
          "link": "http://arxiv.org/abs/2310.07820",
          "publishedOn": "2023-10-14T00:41:30.231Z",
          "wordCount": 708,
          "title": "Large Language Models Are Zero-Shot Time Series Forecasters. (arXiv:2310.07820v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07892",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chavez_Galaviz_J/0/1/0/all/0/1\">Jalil Chavez-Galaviz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianwen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1\">Ajinkya Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmoudian_N/0/1/0/all/0/1\">Nina Mahmoudian</a>",
          "description": "Station keeping is an essential maneuver for Autonomous Surface Vehicles\n(ASVs), mainly when used in confined spaces, to carry out surveys that require\nthe ASV to keep its position or in collaboration with other vehicles where the\nrelative position has an impact over the mission. However, this maneuver can\nbecome challenging for classic feedback controllers due to the need for an\naccurate model of the ASV dynamics and the environmental disturbances. This\nwork proposes a Model Predictive Controller using Neural Network Simulation\nError Minimization (NNSEM-MPC) to accurately predict the dynamics of the ASV\nunder wind disturbances. The performance of the proposed scheme under wind\ndisturbances is tested and compared against other controllers in simulation,\nusing the Robotics Operating System (ROS) and the multipurpose simulation\nenvironment Gazebo. A set of six tests were conducted by combining two wind\nspeeds (3 m/s and 6 m/s) and three wind directions (0$^\\circ$, 90$^\\circ$, and\n180$^\\circ$). The simulation results clearly show the advantage of the\nNNSEM-MPC over the following methods: backstepping controller, sliding mode\ncontroller, simplified dynamics MPC (SD-MPC), neural ordinary differential\nequation MPC (NODE-MPC), and knowledge-based NODE MPC (KNODE-MPC). The proposed\nNNSEM-MPC approach performs better than the rest in 4 out of the 6 test\nconditions, and it is the second best in the 2 remaining test cases, reducing\nthe mean position and heading error by at least 31\\% and 46\\% respectively\nacross all the test cases. In terms of execution speed, the proposed NNSEM-MPC\nis at least 36\\% faster than the rest of the MPC controllers. The field\nexperiments on two different ASV platforms showed that ASVs can effectively\nkeep the station utilizing the proposed method, with a position error as low as\n$1.68$ m and a heading error as low as $6.14^{\\circ}$ within time windows of at\nleast $150$s.",
          "link": "http://arxiv.org/abs/2310.07892",
          "publishedOn": "2023-10-14T00:41:30.166Z",
          "wordCount": 821,
          "title": "ASV Station Keeping under Wind Disturbances using Neural Network Simulation Error Minimization Model Predictive Control. (arXiv:2310.07892v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07896",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_A/0/1/0/all/0/1\">Ajay Sridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Dhruv Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glossop_C/0/1/0/all/0/1\">Catherine Glossop</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Robotic learning for navigation in unfamiliar environments needs to provide\npolicies for both task-oriented navigation (i.e., reaching a goal that the\nrobot has located), and task-agnostic exploration (i.e., searching for a goal\nin a novel setting). Typically, these roles are handled by separate models, for\nexample by using subgoal proposals, planning, or separate navigation\nstrategies. In this paper, we describe how we can train a single unified\ndiffusion policy to handle both goal-directed navigation and goal-agnostic\nexploration, with the latter providing the ability to search novel\nenvironments, and the former providing the ability to reach a user-specified\ngoal once it has been located. We show that this unified policy results in\nbetter overall performance when navigating to visually indicated goals in novel\nenvironments, as compared to approaches that use subgoal proposals from\ngenerative models, or prior methods based on latent variable models. We\ninstantiate our method by using a large-scale Transformer-based policy trained\non data from multiple ground robots, with a diffusion model decoder to flexibly\nhandle both goal-conditioned and goal-agnostic navigation. Our experiments,\nconducted on a real-world mobile robot platform, show effective navigation in\nunseen environments in comparison with five alternative methods, and\ndemonstrate significant improvements in performance and lower collision rates,\ndespite utilizing smaller models than state-of-the-art approaches. For more\nvideos, code, and pre-trained model checkpoints, see\nhttps://general-navigation-models.github.io/nomad/",
          "link": "http://arxiv.org/abs/2310.07896",
          "publishedOn": "2023-10-14T00:41:30.150Z",
          "wordCount": 733,
          "title": "NoMaD: Goal Masked Diffusion Policies for Navigation and Exploration. (arXiv:2310.07896v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Luyao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alghunaim_S/0/1/0/all/0/1\">Sulaiman A. Alghunaim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1\">Kun Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Condat_L/0/1/0/all/0/1\">Laurent Condat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jinde Cao</a>",
          "description": "Distributed optimization methods with random communication skips are gaining\nincreasing attention due to their proven benefits in accelerating communication\ncomplexity. Nevertheless, existing research mainly focuses on centralized\ncommunication protocols for strongly convex deterministic settings. In this\nwork, we provide a decentralized optimization method called RandCom, which\nincorporates probabilistic local updates. We analyze the performance of RandCom\nin stochastic non-convex, convex, and strongly convex settings and demonstrate\nits ability to asymptotically reduce communication overhead by the probability\nof communication. Additionally, we prove that RandCom achieves linear speedup\nas the number of nodes increases. In stochastic strongly convex settings, we\nfurther prove that RandCom can achieve linear speedup with network-independent\nstepsizes. Moreover, we apply RandCom to federated learning and provide\npositive results concerning the potential for achieving linear speedup and the\nsuitability of the probabilistic local update approach for non-convex settings.",
          "link": "http://arxiv.org/abs/2310.07983",
          "publishedOn": "2023-10-14T00:41:30.143Z",
          "wordCount": 677,
          "title": "RandCom: Random Communication Skipping Method for Decentralized Stochastic Optimization. (arXiv:2310.07983v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jafarigol_E/0/1/0/all/0/1\">Elaheh Jafarigol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trafalis_T/0/1/0/all/0/1\">Theodore Trafalis</a>",
          "description": "For over two decades, detecting rare events has been a challenging task among\nresearchers in the data mining and machine learning domain. Real-life problems\ninspire researchers to navigate and further improve data processing and\nalgorithmic approaches to achieve effective and computationally efficient\nmethods for imbalanced learning. In this paper, we have collected and reviewed\n258 peer-reviewed papers from archival journals and conference papers in an\nattempt to provide an in-depth review of various approaches in imbalanced\nlearning from technical and application perspectives. This work aims to provide\na structured review of methods used to address the problem of imbalanced data\nin various domains and create a general guideline for researchers in academia\nor industry who want to dive into the broad field of machine learning using\nlarge-scale imbalanced data.",
          "link": "http://arxiv.org/abs/2310.07917",
          "publishedOn": "2023-10-14T00:41:30.091Z",
          "wordCount": 644,
          "title": "A Review of Machine Learning Techniques in Imbalanced Data and Future Trends. (arXiv:2310.07917v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07858",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Kulshrestha_A/0/1/0/all/0/1\">Ankit Kulshrestha</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lykov_D/0/1/0/all/0/1\">Danylo Lykov</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Safro_I/0/1/0/all/0/1\">Ilya Safro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Alexeev_Y/0/1/0/all/0/1\">Yuri Alexeev</a>",
          "description": "The current era of quantum computing has yielded several algorithms that\npromise high computational efficiency. While the algorithms are sound in theory\nand can provide potentially exponential speedup, there is little guidance on\nhow to design proper quantum circuits to realize the appropriate unitary\ntransformation to be applied to the input quantum state. In this paper, we\npresent \\texttt{QArchSearch}, an AI based quantum architecture search package\nwith the \\texttt{QTensor} library as a backend that provides a principled and\nautomated approach to finding the best model given a task and input quantum\nstate. We show that the search package is able to efficiently scale the search\nto large quantum circuits and enables the exploration of more complex models\nfor different quantum applications. \\texttt{QArchSearch} runs at scale and high\nefficiency on high-performance computing systems using a two-level\nparallelization scheme on both CPUs and GPUs, which has been demonstrated on\nthe Polaris supercomputer.",
          "link": "http://arxiv.org/abs/2310.07858",
          "publishedOn": "2023-10-14T00:41:30.076Z",
          "wordCount": 660,
          "title": "QArchSearch: A Scalable Quantum Architecture Search Package. (arXiv:2310.07858v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Defazio_A/0/1/0/all/0/1\">Aaron Defazio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_H/0/1/0/all/0/1\">Harsh Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>",
          "description": "Learning rate schedules used in practice bear little resemblance to those\nrecommended by theory. We close much of this theory/practice gap, and as a\nconsequence are able to derive new problem-adaptive learning rate schedules.\nOur key technical contribution is a refined analysis of learning rate schedules\nfor a wide class of optimization algorithms (including SGD). In contrast to\nmost prior works that study the convergence of the average iterate, we study\nthe last iterate, which is what most people use in practice. When considering\nonly worst-case analysis, our theory predicts that the best choice is the\nlinear decay schedule: a popular choice in practice that sets the stepsize\nproportionally to $1 - t/T$, where $t$ is the current iteration and $T$ is the\ntotal number of steps. To go beyond this worst-case analysis, we use the\nobserved gradient norms to derive schedules refined for any particular task.\nThese refined schedules exhibit learning rate warm-up and rapid learning rate\nannealing near the end of training. Ours is the first systematic approach to\nautomatically yield both of these properties. We perform the most comprehensive\nevaluation of learning rate schedules to date, evaluating across 10 diverse\ndeep learning problems, a series of LLMs, and a suite of logistic regression\nproblems. We validate that overall, the linear-decay schedule matches or\noutperforms all commonly used default schedules including cosine annealing, and\nthat our schedule refinement method gives further improvements.",
          "link": "http://arxiv.org/abs/2310.07831",
          "publishedOn": "2023-10-14T00:41:30.045Z",
          "wordCount": 765,
          "title": "When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement. (arXiv:2310.07831v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Day_H/0/1/0/all/0/1\">Hannah Day</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahn_Y/0/1/0/all/0/1\">Yonatan Kahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_D/0/1/0/all/0/1\">Daniel A. Roberts</a>",
          "description": "Fully-connected deep neural networks with weights initialized from\nindependent Gaussian distributions can be tuned to criticality, which prevents\nthe exponential growth or decay of signals propagating through the network.\nHowever, such networks still exhibit fluctuations that grow linearly with the\ndepth of the network, which may impair the training of networks with width\ncomparable to depth. We show analytically that rectangular networks with tanh\nactivations and weights initialized from the ensemble of orthogonal matrices\nhave corresponding preactivation fluctuations which are independent of depth,\nto leading order in inverse width. Moreover, we demonstrate numerically that,\nat initialization, all correlators involving the neural tangent kernel (NTK)\nand its descendants at leading order in inverse width -- which govern the\nevolution of observables during training -- saturate at a depth of $\\sim 20$,\nrather than growing without bound as in the case of Gaussian initializations.\nWe speculate that this structure preserves finite-width feature learning while\nreducing overall noise, thus improving both generalization and training speed.\nWe provide some experimental justification by relating empirical measurements\nof the NTK to the superior performance of deep nonlinear orthogonal networks\ntrained under full-batch gradient descent on the MNIST and CIFAR-10\nclassification tasks.",
          "link": "http://arxiv.org/abs/2310.07765",
          "publishedOn": "2023-10-14T00:41:30.033Z",
          "wordCount": 734,
          "title": "Feature Learning and Generalization in Deep Networks with Orthogonal Weights. (arXiv:2310.07765v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madsen_A/0/1/0/all/0/1\">Andreas Madsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>",
          "description": "A common approach to explain NLP models, is to use importance measures that\nexpress which tokens are important for a prediction. Unfortunately, such\nexplanations are often wrong despite being persuasive. Therefore, it is\nessential to measure their faithfulness. One such metric is if tokens are truly\nimportant, then masking them should result in worse model performance. However,\ntoken masking introduces out-of-distribution issues and existing solutions are\ncomputationally expensive and employ proxy-models. Furthermore, other metrics\nare very limited in scope. In this work, we propose an inherently faithfulness\nmeasurable model that addresses these challenges. This is achieved by using a\nnovel fine-tuning method that incorporates masking, such that masking tokens\nbecome in-distribution by design. This differs from existing approaches, which\nare completely model-agnostic but are inapplicable in practice. We demonstrate\nthe generality of our approach by applying it to various tasks and validate it\nusing statistical in-distribution tests. Additionally, because masking is\nin-distribution, importance measures which themselves use masking become more\nfaithful, thus our model becomes more explainable.",
          "link": "http://arxiv.org/abs/2310.07819",
          "publishedOn": "2023-10-14T00:41:29.999Z",
          "wordCount": 651,
          "title": "Faithfulness Measurable Masked Language Models. (arXiv:2310.07819v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_P/0/1/0/all/0/1\">Philip Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thant_P/0/1/0/all/0/1\">Phue Thant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1\">Pratiksha Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antaliya_R/0/1/0/all/0/1\">Ruta Antaliya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1\">Jongwook Woo</a>",
          "description": "This paper discusses predictive performance and processes undertaken on\nflight pricing data utilizing r2(r-square) and RMSE that leverages a large\ndataset, originally from Expedia.com, consisting of approximately 20 million\nrecords or 4.68 gigabytes. The project aims to determine the best models usable\nin the real world to predict airline ticket fares for non-stop flights across\nthe US. Therefore, good generalization capability and optimized processing\ntimes are important measures for the model.\n\nWe will discover key business insights utilizing feature importance and\ndiscuss the process and tools used for our analysis. Four regression machine\nlearning algorithms were utilized: Random Forest, Gradient Boost Tree, Decision\nTree, and Factorization Machines utilizing Cross Validator and Training\nValidator functions for assessing performance and generalization capability.",
          "link": "http://arxiv.org/abs/2310.07787",
          "publishedOn": "2023-10-14T00:41:29.960Z",
          "wordCount": 662,
          "title": "Using Spark Machine Learning Models to Perform Predictive Analysis on Flight Ticket Pricing Data. (arXiv:2310.07787v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1\">Yi Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongzi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cresswell_J/0/1/0/all/0/1\">Jesse C. Cresswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Ga Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stein_G/0/1/0/all/0/1\">George Stein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiao Shi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaochen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Volkovs_M/0/1/0/all/0/1\">Maksims Volkovs</a>",
          "description": "Self-supervised representation learning~(SSRL) has advanced considerably by\nexploiting the transformation invariance assumption under artificially designed\ndata augmentations. While augmentation-based SSRL algorithms push the\nboundaries of performance in computer vision and natural language processing,\nthey are often not directly applicable to other data modalities, and can\nconflict with application-specific data augmentation constraints. This paper\npresents an SSRL approach that can be applied to any data modality and network\narchitecture because it does not rely on augmentations or masking.\nSpecifically, we show that high-quality data representations can be learned by\nreconstructing random data projections. We evaluate the proposed approach on a\nwide range of representation learning tasks that span diverse modalities and\nreal-world applications. We show that it outperforms multiple state-of-the-art\nSSRL baselines. Due to its wide applicability and strong empirical results, we\nargue that learning from randomness is a fruitful research direction worthy of\nattention and further study.",
          "link": "http://arxiv.org/abs/2310.07756",
          "publishedOn": "2023-10-14T00:41:29.946Z",
          "wordCount": 653,
          "title": "Self-supervised Representation Learning From Random Data Projectors. (arXiv:2310.07756v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mastromichalakis_S/0/1/0/all/0/1\">Stamatis Mastromichalakis</a>",
          "description": "Activation functions (AFs) are crucial components of deep neural networks\n(DNNs), having a significant impact on their performance. An activation\nfunction in a DNN is typically a smooth, nonlinear function that transforms an\ninput signal into an output signal for the subsequent layer. In this paper, we\npropose the Parametric Leaky Tanh (PLTanh), a novel hybrid activation function\ndesigned to combine the strengths of both the Tanh and Leaky ReLU (LReLU)\nactivation functions. PLTanh is differentiable at all points and addresses the\n'dying ReLU' problem by ensuring a non-zero gradient for negative inputs,\nconsistent with the behavior of LReLU. By integrating the unique advantages of\nthese two diverse activation functions, PLTanh facilitates the learning of more\nintricate nonlinear relationships within the network. This paper presents an\nempirical evaluation of PLTanh against established activation functions, namely\nReLU, LReLU, and ALReLU utilizing five diverse datasets.",
          "link": "http://arxiv.org/abs/2310.07720",
          "publishedOn": "2023-10-14T00:41:29.941Z",
          "wordCount": 661,
          "title": "Parametric Leaky Tanh: A New Hybrid Activation Function for Deep Learning. (arXiv:2310.07720v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hsuan-Kung Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_T/0/1/0/all/0/1\">Tsung-Chih Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting-Ru Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chun-Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jou-Min Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chun-Yi Lee</a>",
          "description": "The challenge of navigation in environments with dynamic objects continues to\nbe a central issue in the study of autonomous agents. While predictive methods\nhold promise, their reliance on precise state information makes them less\npractical for real-world implementation. This study presents visual forecasting\nas an innovative alternative. By introducing intuitive visual cues, this\napproach projects the future trajectories of dynamic objects to improve agent\nperception and enable anticipatory actions. Our research explores two distinct\nstrategies for conveying predictive information through visual forecasting: (1)\nsequences of bounding boxes, and (2) augmented paths. To validate the proposed\nvisual forecasting strategies, we initiate evaluations in simulated\nenvironments using the Unity engine and then extend these evaluations to\nreal-world scenarios to assess both practicality and effectiveness. The results\nconfirm the viability of visual forecasting as a promising solution for\nnavigation and obstacle avoidance in dynamic environments.",
          "link": "http://arxiv.org/abs/2310.07724",
          "publishedOn": "2023-10-14T00:41:29.893Z",
          "wordCount": 686,
          "title": "Visual Forecasting as a Mid-level Representation for Avoidance. (arXiv:2310.07724v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.03364",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michel_N/0/1/0/all/0/1\">Nicolas Michel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chierchia_G/0/1/0/all/0/1\">Giovanni Chierchia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negrel_R/0/1/0/all/0/1\">Romain Negrel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bercher_J/0/1/0/all/0/1\">Jean-Fran&#xe7;ois Bercher</a>",
          "description": "We use the maximum a posteriori estimation principle for learning\nrepresentations distributed on the unit sphere. We propose to use the angular\nGaussian distribution, which corresponds to a Gaussian projected on the\nunit-sphere and derive the associated loss function. We also consider the von\nMises-Fisher distribution, which is the conditional of a Gaussian in the\nunit-sphere. The learned representations are pushed toward fixed directions,\nwhich are the prior means of the Gaussians; allowing for a learning strategy\nthat is resilient to data drift. This makes it suitable for online continual\nlearning, which is the problem of training neural networks on a continuous data\nstream, where multiple classification tasks are presented sequentially so that\ndata from past tasks are no longer accessible, and data from the current task\ncan be seen only once. To address this challenging scenario, we propose a\nmemory-based representation learning technique equipped with our new loss\nfunctions. Our approach does not require negative data or knowledge of task\nboundaries and performs well with smaller batch sizes while being\ncomputationally efficient. We demonstrate with extensive experiments that the\nproposed method outperforms the current state-of-the-art methods on both\nstandard evaluation scenarios and realistic scenarios with blurry task\nboundaries. For reproducibility, we use the same training pipeline for every\ncompared method and share the code at https://t.ly/SQTj.",
          "link": "http://arxiv.org/abs/2306.03364",
          "publishedOn": "2023-10-07T00:42:21.704Z",
          "wordCount": 799,
          "title": "Learning Representations on the Unit Sphere: Investigating Angular Gaussian and von Mises-Fisher Distributions for Online Continual Learning. (arXiv:2306.03364v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.02936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bie_A/0/1/0/all/0/1\">Alex Bie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1\">Gautam Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guojun Zhang</a>",
          "description": "We show that the canonical approach for training differentially private GANs\n-- updating the discriminator with differentially private stochastic gradient\ndescent (DPSGD) -- can yield significantly improved results after modifications\nto training. Specifically, we propose that existing instantiations of this\napproach neglect to consider how adding noise only to discriminator updates\ninhibits discriminator training, disrupting the balance between the generator\nand discriminator necessary for successful GAN training. We show that a simple\nfix -- taking more discriminator steps between generator steps -- restores\nparity between the generator and discriminator and improves results.\n\nAdditionally, with the goal of restoring parity, we experiment with other\nmodifications -- namely, large batch sizes and adaptive discriminator update\nfrequency -- to improve discriminator training and see further improvements in\ngeneration quality. Our results demonstrate that on standard image synthesis\nbenchmarks, DPSGD outperforms all alternative GAN privatization schemes. Code:\nhttps://github.com/alexbie98/dpgan-revisit.",
          "link": "http://arxiv.org/abs/2302.02936",
          "publishedOn": "2023-10-07T00:42:21.680Z",
          "wordCount": 673,
          "title": "Private GANs, Revisited. (arXiv:2302.02936v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.14331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hongwu Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ran_R/0/1/0/all/0/1\">Ran Ran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yukui Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiahui Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaoyi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorat_K/0/1/0/all/0/1\">Kiran Thorat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_T/0/1/0/all/0/1\">Tong Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenghong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaolin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1\">Wujie Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Caiwen Ding</a>",
          "description": "The growth of Graph Convolution Network (GCN) model sizes has revolutionized\nnumerous applications, surpassing human performance in areas such as personal\nhealthcare and financial systems. The deployment of GCNs in the cloud raises\nprivacy concerns due to potential adversarial attacks on client data. To\naddress security concerns, Privacy-Preserving Machine Learning (PPML) using\nHomomorphic Encryption (HE) secures sensitive client data. However, it\nintroduces substantial computational overhead in practical applications. To\ntackle those challenges, we present LinGCN, a framework designed to reduce\nmultiplication depth and optimize the performance of HE based GCN inference.\nLinGCN is structured around three key elements: (1) A differentiable structural\nlinearization algorithm, complemented by a parameterized discrete indicator\nfunction, co-trained with model weights to meet the optimization goal. This\nstrategy promotes fine-grained node-level non-linear location selection,\nresulting in a model with minimized multiplication depth. (2) A compact\nnode-wise polynomial replacement policy with a second-order trainable\nactivation function, steered towards superior convergence by a two-level\ndistillation approach from an all-ReLU based teacher model. (3) an enhanced HE\nsolution that enables finer-grained operator fusion for node-wise activation\nfunctions, further reducing multiplication level consumption in HE-based\ninference. Our experiments on the NTU-XVIEW skeleton joint dataset reveal that\nLinGCN excels in latency, accuracy, and scalability for homomorphically\nencrypted inference, outperforming solutions such as CryptoGCN. Remarkably,\nLinGCN achieves a 14.2x latency speedup relative to CryptoGCN, while preserving\nan inference accuracy of 75% and notably reducing multiplication depth.",
          "link": "http://arxiv.org/abs/2309.14331",
          "publishedOn": "2023-10-07T00:42:21.631Z",
          "wordCount": 856,
          "title": "LinGCN: Structural Linearized Graph Convolutional Network for Homomorphically Encrypted Inference. (arXiv:2309.14331v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.17357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karkar_S/0/1/0/all/0/1\">Skander Karkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ibrahim Ayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1\">Emmanuel de B&#xe9;zenac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1\">Patrick Gallinari</a>",
          "description": "Greedy layer-wise or module-wise training of neural networks is compelling in\nconstrained and on-device settings where memory is limited, as it circumvents a\nnumber of problems of end-to-end back-propagation. However, it suffers from a\nstagnation problem, whereby early layers overfit and deeper layers stop\nincreasing the test accuracy after a certain depth. We propose to solve this\nissue by introducing a module-wise regularization inspired by the minimizing\nmovement scheme for gradient flows in distribution space. We call the method\nTRGL for Transport Regularized Greedy Learning and study it theoretically,\nproving that it leads to greedy modules that are regular and that progressively\nsolve the task. Experimentally, we show improved accuracy of module-wise\ntraining of various architectures such as ResNets, Transformers and VGG, when\nour regularization is added, superior to that of other module-wise training\nmethods and often to end-to-end training, with as much as 60% less memory\nusage.",
          "link": "http://arxiv.org/abs/2309.17357",
          "publishedOn": "2023-10-07T00:42:21.551Z",
          "wordCount": 708,
          "title": "Module-wise Training of Neural Networks via the Minimizing Movement Scheme. (arXiv:2309.17357v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2010.11559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yangjing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toh_K/0/1/0/all/0/1\">Kim-Chuan Toh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1\">Defeng Sun</a>",
          "description": "We consider the problem of learning a graph under the Laplacian constraint\nwith a non-convex penalty: minimax concave penalty (MCP). For solving the MCP\npenalized graphical model, we design an inexact proximal difference-of-convex\nalgorithm (DCA) and prove its convergence to critical points. We note that each\nsubproblem of the proximal DCA enjoys the nice property that the objective\nfunction in its dual problem is continuously differentiable with a semismooth\ngradient. Therefore, we apply an efficient semismooth Newton method to\nsubproblems of the proximal DCA. Numerical experiments on various synthetic and\nreal data sets demonstrate the effectiveness of the non-convex penalty MCP in\npromoting sparsity. Compared with the existing state-of-the-art method, our\nmethod is demonstrated to be more efficient and reliable for learning graph\nLaplacian with MCP.",
          "link": "http://arxiv.org/abs/2010.11559",
          "publishedOn": "2023-10-07T00:42:21.522Z",
          "wordCount": 651,
          "title": "Learning Graph Laplacian with MCP. (arXiv:2010.11559v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.05895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peiyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sirui Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_B/0/1/0/all/0/1\">Baoxiong Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1\">Bo Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yixin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "Latent space Energy-Based Models (EBMs), also known as energy-based priors,\nhave drawn growing interests in generative modeling. Fueled by its flexibility\nin the formulation and strong modeling power of the latent space, recent works\nbuilt upon it have made interesting attempts aiming at the interpretability of\ntext modeling. However, latent space EBMs also inherit some flaws from EBMs in\ndata space; the degenerate MCMC sampling quality in practice can lead to poor\ngeneration quality and instability in training, especially on data with complex\nlatent structures. Inspired by the recent efforts that leverage diffusion\nrecovery likelihood learning as a cure for the sampling issue, we introduce a\nnovel symbiosis between the diffusion models and latent space EBMs in a\nvariational learning framework, coined as the latent diffusion energy-based\nmodel. We develop a geometric clustering-based regularization jointly with the\ninformation bottleneck to further improve the quality of the learned latent\nspace. Experiments on several challenging tasks demonstrate the superior\nperformance of our model on interpretable text modeling over strong\ncounterparts.",
          "link": "http://arxiv.org/abs/2206.05895",
          "publishedOn": "2023-10-07T00:42:21.515Z",
          "wordCount": 723,
          "title": "Latent Diffusion Energy-Based Model for Interpretable Text Modeling. (arXiv:2206.05895v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schiemer_M/0/1/0/all/0/1\">Martin Schiemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaefer_C/0/1/0/all/0/1\">Clemens JS Schaefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vap_J/0/1/0/all/0/1\">Jayden Parker Vap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horeni_M/0/1/0/all/0/1\">Mark James Horeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Emma Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Juan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1\">Siddharth Joshi</a>",
          "description": "Continual learning is a desirable feature in many modern machine learning\napplications, which allows in-field adaptation and updating, ranging from\naccommodating distribution shift, to fine-tuning, and to learning new tasks.\nFor applications with privacy and low latency requirements, the compute and\nmemory demands imposed by continual learning can be cost-prohibitive for\nresource-constraint edge platforms. Reducing computational precision through\nfully quantized training (FQT) simultaneously reduces memory footprint and\nincreases compute efficiency for both training and inference. However,\naggressive quantization especially integer FQT typically degrades model\naccuracy to unacceptable levels. In this paper, we propose a technique that\nleverages inexpensive Hadamard transforms to enable low-precision training with\nonly integer matrix multiplications. We further determine which tensors need\nstochastic rounding and propose tiled matrix multiplication to enable low-bit\nwidth accumulators. We demonstrate the effectiveness of our technique on\nseveral human activity recognition datasets and CIFAR100 in a class incremental\nlearning setting. We achieve less than 0.5% and 3% accuracy degradation while\nwe quantize all matrix multiplications inputs down to 4-bits with 8-bit\naccumulators.",
          "link": "http://arxiv.org/abs/2310.03675",
          "publishedOn": "2023-10-07T00:42:21.495Z",
          "wordCount": 692,
          "title": "Hadamard Domain Training with Integers for Class Incremental Quantized Learning. (arXiv:2310.03675v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.01751",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_T/0/1/0/all/0/1\">Tianrong Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_G/0/1/0/all/0/1\">Guan-Horng Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tao_M/0/1/0/all/0/1\">Molei Tao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Theodorou_E/0/1/0/all/0/1\">Evangelos A. Theodorou</a>",
          "description": "It is a crucial challenge to reconstruct population dynamics using unlabeled\nsamples from distributions at coarse time intervals. Recent approaches such as\nflow-based models or Schr\\\"odinger Bridge (SB) models have demonstrated\nappealing performance, yet the inferred sample trajectories either fail to\naccount for the underlying stochasticity or are $\\underline{D}$eep\n$\\underline{M}$omentum Multi-Marginal $\\underline{S}$chr\\\"odinger\n$\\underline{B}$ridge(DMSB), a novel computational framework that learns the\nsmooth measure-valued spline for stochastic systems that satisfy position\nmarginal constraints across time. By tailoring the celebrated Bregman Iteration\nand extending the Iteration Proportional Fitting to phase space, we manage to\nhandle high-dimensional multi-marginal trajectory inference tasks efficiently.\nOur algorithm outperforms baselines significantly, as evidenced by experiments\nfor synthetic datasets and a real-world single-cell RNA sequence dataset.\nAdditionally, the proposed approach can reasonably reconstruct the evolution of\nvelocity distribution, from position snapshots only, when there is a ground\ntruth velocity that is nevertheless inaccessible.",
          "link": "http://arxiv.org/abs/2303.01751",
          "publishedOn": "2023-10-07T00:42:21.455Z",
          "wordCount": 658,
          "title": "Deep Momentum Multi-Marginal Schr\\\"odinger Bridge. (arXiv:2303.01751v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.02648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moayeri_M/0/1/0/all/0/1\">Mazda Moayeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenxiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sahil Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>",
          "description": "We present a simple but effective method to measure and mitigate model biases\ncaused by reliance on spurious cues. Instead of requiring costly changes to\none's data or model training, our method better utilizes the data one already\nhas by sorting them. Specifically, we rank images within their classes based on\nspuriosity (the degree to which common spurious cues are present), proxied via\ndeep neural features of an interpretable network. With spuriosity rankings, it\nis easy to identify minority subpopulations (i.e. low spuriosity images) and\nassess model bias as the gap in accuracy between high and low spuriosity\nimages. One can even efficiently remove a model's bias at little cost to\naccuracy by finetuning its classification head on low spuriosity images,\nresulting in fairer treatment of samples regardless of spuriosity. We\ndemonstrate our method on ImageNet, annotating $5000$ class-feature\ndependencies ($630$ of which we find to be spurious) and generating a dataset\nof $325k$ soft segmentations for these features along the way. Having computed\nspuriosity rankings via the identified spurious neural features, we assess\nbiases for $89$ diverse models and find that class-wise biases are highly\ncorrelated across models. Our results suggest that model bias due to spurious\nfeature reliance is influenced far more by what the model is trained on than\nhow it is trained.",
          "link": "http://arxiv.org/abs/2212.02648",
          "publishedOn": "2023-10-07T00:42:21.448Z",
          "wordCount": 754,
          "title": "Spuriosity Rankings: Sorting Data to Measure and Mitigate Biases. (arXiv:2212.02648v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.12148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madan_N/0/1/0/all/0/1\">Neelu Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ristea_N/0/1/0/all/0/1\">Nicolae-Catalin Ristea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasrollahi_K/0/1/0/all/0/1\">Kamal Nasrollahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moeslund_T/0/1/0/all/0/1\">Thomas B. Moeslund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>",
          "description": "Anomaly detection has recently gained increasing attention in the field of\ncomputer vision, likely due to its broad set of applications ranging from\nproduct fault detection on industrial production lines and impending event\ndetection in video surveillance to finding lesions in medical scans. Regardless\nof the domain, anomaly detection is typically framed as a one-class\nclassification task, where the learning is conducted on normal examples only.\nAn entire family of successful anomaly detection methods is based on learning\nto reconstruct masked normal inputs (e.g. patches, future frames, etc.) and\nexerting the magnitude of the reconstruction error as an indicator for the\nabnormality level. Unlike other reconstruction-based methods, we present a\nnovel self-supervised masked convolutional transformer block (SSMCTB) that\ncomprises the reconstruction-based functionality at a core architectural level.\nThe proposed self-supervised block is extremely flexible, enabling information\nmasking at any layer of a neural network and being compatible with a wide range\nof neural architectures. In this work, we extend our previous self-supervised\npredictive convolutional attentive block (SSPCAB) with a 3D masked\nconvolutional layer, a transformer for channel-wise attention, as well as a\nnovel self-supervised objective based on Huber loss. Furthermore, we show that\nour block is applicable to a wider variety of tasks, adding anomaly detection\nin medical images and thermal videos to the previously considered tasks based\non RGB images and surveillance videos. We exhibit the generality and\nflexibility of SSMCTB by integrating it into multiple state-of-the-art neural\nmodels for anomaly detection, bringing forth empirical results that confirm\nconsiderable performance improvements on five benchmarks. We release our code\nand data as open source at: https://github.com/ristea/ssmctb.",
          "link": "http://arxiv.org/abs/2209.12148",
          "publishedOn": "2023-10-07T00:42:21.419Z",
          "wordCount": 827,
          "title": "Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection. (arXiv:2209.12148v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schulze_L/0/1/0/all/0/1\">Lennart Schulze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipson_H/0/1/0/all/0/1\">Hod Lipson</a>",
          "description": "A robot self-model is a task-agnostic representation of the robot's physical\nmorphology that can be used for motion planning tasks in absence of classical\ngeometric kinematic models. In particular, when the latter are hard to engineer\nor the robot's kinematics change unexpectedly, human-free self-modeling is a\nnecessary feature of truly autonomous agents. In this work, we leverage neural\nfields to allow a robot to self-model its kinematics as a neural-implicit query\nmodel learned only from 2D images annotated with camera poses and\nconfigurations. This enables significantly greater applicability than existing\napproaches which have been dependent on depth images or geometry knowledge. To\nthis end, alongside a curricular data sampling strategy, we propose a new\nencoder-based neural density field architecture for dynamic object-centric\nscenes conditioned on high numbers of degrees of freedom (DOFs). In a 7-DOF\nrobot test setup, the learned self-model achieves a Chamfer-L2 distance of 2%\nof the robot's workspace dimension. We demonstrate the capabilities of this\nmodel on a motion planning task as an exemplary downstream application.",
          "link": "http://arxiv.org/abs/2310.03624",
          "publishedOn": "2023-10-07T00:42:21.349Z",
          "wordCount": 693,
          "title": "High-Degrees-of-Freedom Dynamic Neural Fields for Robot Self-Modeling and Motion Planning. (arXiv:2310.03624v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.02671",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Klein_S/0/1/0/all/0/1\">Sara Klein</a>, <a href=\"http://arxiv.org/find/math/1/au:+Weissmann_S/0/1/0/all/0/1\">Simon Weissmann</a>, <a href=\"http://arxiv.org/find/math/1/au:+Doring_L/0/1/0/all/0/1\">Leif D&#xf6;ring</a>",
          "description": "Markov Decision Processes (MDPs) are a formal framework for modeling and\nsolving sequential decision-making problems. In finite-time horizons such\nproblems are relevant for instance for optimal stopping or specific supply\nchain problems, but also in the training of large language models. In contrast\nto infinite horizon MDPs optimal policies are not stationary, policies must be\nlearned for every single epoch. In practice all parameters are often trained\nsimultaneously, ignoring the inherent structure suggested by dynamic\nprogramming. This paper introduces a combination of dynamic programming and\npolicy gradient called dynamic policy gradient, where the parameters are\ntrained backwards in time. For the tabular softmax parametrisation we carry out\nthe convergence analysis for simultaneous and dynamic policy gradient towards\nglobal optima, both in the exact and sampled gradient settings without\nregularisation. It turns out that the use of dynamic policy gradient training\nmuch better exploits the structure of finite-time problems which is reflected\nin improved convergence bounds.",
          "link": "http://arxiv.org/abs/2310.02671",
          "publishedOn": "2023-10-07T00:42:21.342Z",
          "wordCount": 664,
          "title": "Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods. (arXiv:2310.02671v1 [math.OC] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>",
          "description": "High-quality text embedding is pivotal in improving semantic textual\nsimilarity (STS) tasks, which are crucial components in Large Language Model\n(LLM) applications. However, a common challenge existing text embedding models\nface is the problem of vanishing gradients, primarily due to their reliance on\nthe cosine function in the optimization objective, which has saturation zones.\nTo address this issue, this paper proposes a novel angle-optimized text\nembedding model called AnglE. The core idea of AnglE is to introduce angle\noptimization in a complex space. This novel approach effectively mitigates the\nadverse effects of the saturation zone in the cosine function, which can impede\ngradient and hinder optimization processes. To set up a comprehensive STS\nevaluation, we experimented on existing short-text STS datasets and a newly\ncollected long-text STS dataset from GitHub Issues. Furthermore, we examine\ndomain-specific STS scenarios with limited labeled data and explore how AnglE\nworks with LLM-annotated data. Extensive experiments were conducted on various\ntasks including short-text STS, long-text STS, and domain-specific STS tasks.\nThe results show that AnglE outperforms the state-of-the-art (SOTA) STS models\nthat ignore the cosine saturation zone. These findings demonstrate the ability\nof AnglE to generate high-quality text embeddings and the usefulness of angle\noptimization in STS.",
          "link": "http://arxiv.org/abs/2309.12871",
          "publishedOn": "2023-10-07T00:42:21.336Z",
          "wordCount": 705,
          "title": "AnglE-optimized Text Embeddings. (arXiv:2309.12871v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Ke Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Houxing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Aojun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zimu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Sichun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weikang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Renrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linqi Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_M/0/1/0/all/0/1\">Mingjie Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>",
          "description": "The recently released GPT-4 Code Interpreter has demonstrated remarkable\nproficiency in solving challenging math problems, primarily attributed to its\nability to seamlessly reason with natural language, generate code, execute\ncode, and continue reasoning based on the execution output. In this paper, we\npresent a method to fine-tune open-source language models, enabling them to use\ncode for modeling and deriving math equations and, consequently, enhancing\ntheir mathematical reasoning abilities. We propose a method of generating novel\nand high-quality datasets with math problems and their code-based solutions,\nreferred to as MathCodeInstruct. Each solution interleaves natural language,\ncode, and execution results. We also introduce a customized supervised\nfine-tuning and inference approach. This approach yields the MathCoder models,\na family of models capable of generating code-based solutions for solving\nchallenging math problems. Impressively, the MathCoder models achieve\nstate-of-the-art scores among open-source LLMs on the MATH (45.2%) and GSM8K\n(83.9%) datasets, substantially outperforming other open-source alternatives.\nNotably, the MathCoder model not only surpasses ChatGPT-3.5 and PaLM-2 on GSM8K\nand MATH but also outperforms GPT-4 on the competition-level MATH dataset. The\ndataset and models will be released at https://github.com/mathllm/MathCoder.",
          "link": "http://arxiv.org/abs/2310.03731",
          "publishedOn": "2023-10-07T00:42:21.276Z",
          "wordCount": 725,
          "title": "MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning. (arXiv:2310.03731v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.10650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Slusarz_N/0/1/0/all/0/1\">Natalia &#x15a;lusarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komendantskaya_E/0/1/0/all/0/1\">Ekaterina Komendantskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daggitt_M/0/1/0/all/0/1\">Matthew L. Daggitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stewart_R/0/1/0/all/0/1\">Robert Stewart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stark_K/0/1/0/all/0/1\">Kathrin Stark</a>",
          "description": "Differentiable logics (DL) have recently been proposed as a method of\ntraining neural networks to satisfy logical specifications. A DL consists of a\nsyntax in which specifications are stated and an interpretation function that\ntranslates expressions in the syntax into loss functions. These loss functions\ncan then be used during training with standard gradient descent algorithms. The\nvariety of existing DLs and the differing levels of formality with which they\nare treated makes a systematic comparative study of their properties and\nimplementations difficult. This paper remedies this problem by suggesting a\nmeta-language for defining DLs that we call the Logic of Differentiable Logics,\nor LDL. Syntactically, it generalises the syntax of existing DLs to FOL, and\nfor the first time introduces the formalism for reasoning about vectors and\nlearners. Semantically, it introduces a general interpretation function that\ncan be instantiated to define loss functions arising from different existing\nDLs. We use LDL to establish several theoretical properties of existing DLs,\nand to conduct their empirical study in neural network verification.",
          "link": "http://arxiv.org/abs/2303.10650",
          "publishedOn": "2023-10-07T00:42:21.104Z",
          "wordCount": 725,
          "title": "Logic of Differentiable Logics: Towards a Uniform Semantics of DL. (arXiv:2303.10650v4 [cs.LO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.04054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hagmann_M/0/1/0/all/0/1\">Michael Hagmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meier_P/0/1/0/all/0/1\">Philipp Meier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>",
          "description": "Reliability of machine learning evaluation -- the consistency of observed\nevaluation scores across replicated model training runs -- is affected by\nseveral sources of nondeterminism which can be regarded as measurement noise.\nCurrent tendencies to remove noise in order to enforce reproducibility of\nresearch results neglect inherent nondeterminism at the implementation level\nand disregard crucial interaction effects between algorithmic noise factors and\ndata properties. This limits the scope of conclusions that can be drawn from\nsuch experiments. Instead of removing noise, we propose to incorporate several\nsources of variance, including their interaction with data properties, into an\nanalysis of significance and reliability of machine learning evaluation, with\nthe aim to draw inferences beyond particular instances of trained models. We\nshow how to use linear mixed effects models (LMEMs) to analyze performance\nevaluation scores, and to conduct statistical inference with a generalized\nlikelihood ratio test (GLRT). This allows us to incorporate arbitrary sources\nof noise like meta-parameter variations into statistical significance testing,\nand to assess performance differences conditional on data properties.\nFurthermore, a variance component analysis (VCA) enables the analysis of the\ncontribution of noise sources to overall variance and the computation of a\nreliability coefficient by the ratio of substantial to total variance.",
          "link": "http://arxiv.org/abs/2302.04054",
          "publishedOn": "2023-10-07T00:42:21.087Z",
          "wordCount": 773,
          "title": "Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.12081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chufan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Cao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>",
          "description": "Tabular data prediction has been employed in medical applications such as\npatient health risk prediction. However, existing methods usually revolve\naround the algorithm design while overlooking the significance of data\nengineering. Medical tabular datasets frequently exhibit significant\nheterogeneity across different sources, with limited sample sizes per source.\nAs such, previous predictors are often trained on manually curated small\ndatasets that struggle to generalize across different tabular datasets during\ninference. This paper proposes to scale medical tabular data predictors\n(MediTab) to various tabular inputs with varying features. The method uses a\ndata engine that leverages large language models (LLMs) to consolidate tabular\nsamples to overcome the barrier across tables with distinct schema. It also\naligns out-domain data with the target task using a \"learn, annotate, and\nrefinement\" pipeline. The expanded training data then enables the pre-trained\nMediTab to infer for arbitrary tabular input in the domain without fine-tuning,\nresulting in significant improvements over supervised baselines: it reaches an\naverage ranking of 1.57 and 1.00 on 7 patient outcome prediction datasets and 3\ntrial outcome prediction datasets, respectively. In addition, MediTab exhibits\nimpressive zero-shot performances: it outperforms supervised XGBoost models by\n8.9% and 17.2% on average in two prediction tasks, respectively. The code is\navailable at https://github.com/RyanWangZf/MediTab.",
          "link": "http://arxiv.org/abs/2305.12081",
          "publishedOn": "2023-10-07T00:42:21.059Z",
          "wordCount": 755,
          "title": "MediTab: Scaling Medical Tabular Data Predictors via Data Consolidation, Enrichment, and Refinement. (arXiv:2305.12081v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khattab_O/0/1/0/all/0/1\">Omar Khattab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singhvi_A/0/1/0/all/0/1\">Arnav Singhvi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_P/0/1/0/all/0/1\">Paridhi Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santhanam_K/0/1/0/all/0/1\">Keshav Santhanam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardhamanan_S/0/1/0/all/0/1\">Sri Vardhamanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haq_S/0/1/0/all/0/1\">Saiful Haq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Ashutosh Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_T/0/1/0/all/0/1\">Thomas T. Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moazam_H/0/1/0/all/0/1\">Hanna Moazam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_H/0/1/0/all/0/1\">Heather Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1\">Matei Zaharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>",
          "description": "The ML community is rapidly exploring techniques for prompting language\nmodels (LMs) and for stacking them into pipelines that solve complex tasks.\nUnfortunately, existing LM pipelines are typically implemented using hard-coded\n\"prompt templates\", i.e. lengthy strings discovered via trial and error. Toward\na more systematic approach for developing and optimizing LM pipelines, we\nintroduce DSPy, a programming model that abstracts LM pipelines as text\ntransformation graphs, i.e. imperative computational graphs where LMs are\ninvoked through declarative modules. DSPy modules are parameterized, meaning\nthey can learn (by creating and collecting demonstrations) how to apply\ncompositions of prompting, finetuning, augmentation, and reasoning techniques.\nWe design a compiler that will optimize any DSPy pipeline to maximize a given\nmetric. We conduct two case studies, showing that succinct DSPy programs can\nexpress and optimize sophisticated LM pipelines that reason about math word\nproblems, tackle multi-hop retrieval, answer complex questions, and control\nagent loops. Within minutes of compiling, a few lines of DSPy allow GPT-3.5 and\nllama2-13b-chat to self-bootstrap pipelines that outperform standard few-shot\nprompting (generally by over 25% and 65%, respectively) and pipelines with\nexpert-created demonstrations (by up to 5-46% and 16-40%, respectively). On top\nof that, DSPy programs compiled to open and relatively small LMs like\n770M-parameter T5 and llama2-13b-chat are competitive with approaches that rely\non expert-written prompt chains for proprietary GPT-3.5. DSPy is available at\nhttps://github.com/stanfordnlp/dspy",
          "link": "http://arxiv.org/abs/2310.03714",
          "publishedOn": "2023-10-07T00:42:21.052Z",
          "wordCount": 758,
          "title": "DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines. (arXiv:2310.03714v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elnaggar_A/0/1/0/all/0/1\">Ahmed Fakhry Elnaggar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khafagy_R/0/1/0/all/0/1\">Raneem Ali Khafagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludl_A/0/1/0/all/0/1\">Adriaan-Alexander Ludl</a>",
          "description": "Detecting and discovering new gene interactions based on known gene\nexpressions and gene interaction data presents a significant challenge. Various\nstatistical and deep learning methods have attempted to tackle this challenge\nby leveraging the topological structure of gene interactions and gene\nexpression patterns to predict novel gene interactions. In contrast, some\napproaches have focused exclusively on utilizing gene expression profiles. In\nthis context, we introduce GENER, a parallel-layer deep learning network\ndesigned exclusively for the identification of gene-gene relationships using\ngene expression data. We conducted two training experiments and compared the\nperformance of our network with that of existing statistical and deep learning\napproaches. Notably, our model achieved an average AUROC score of 0.834 on the\ncombined BioGRID&DREAM5 dataset, outperforming competing methods in predicting\ngene-gene interactions.",
          "link": "http://arxiv.org/abs/2310.03611",
          "publishedOn": "2023-10-07T00:42:21.044Z",
          "wordCount": 657,
          "title": "GENER: A Parallel Layer Deep Learning Network To Detect Gene-Gene Interactions From Gene Expression Data. (arXiv:2310.03611v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.00942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sehanobish_A/0/1/0/all/0/1\">Arijit Sehanobish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Han Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yunfan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_E/0/1/0/all/0/1\">Eli Berger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parshakova_T/0/1/0/all/0/1\">Tetiana Parshakova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_A/0/1/0/all/0/1\">Alvin Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watkins_D/0/1/0/all/0/1\">David Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1\">Valerii Likhosherstov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Somnath Basu Roy Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1\">Avinava Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1\">Deepali Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarlos_T/0/1/0/all/0/1\">Tamas Sarlos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaturvedi_S/0/1/0/all/0/1\">Snigdha Chaturvedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "We present two new classes of algorithms for efficient field integration on\ngraphs encoding point clouds. The first class, SeparatorFactorization(SF),\nleverages the bounded genus of point cloud mesh graphs, while the second class,\nRFDiffusion(RFD), uses popular epsilon-nearest-neighbor graph representations\nfor point clouds. Both can be viewed as providing the functionality of Fast\nMultipole Methods (FMMs), which have had a tremendous impact on efficient\nintegration, but for non-Euclidean spaces. We focus on geometries induced by\ndistributions of walk lengths between points (e.g., shortest-path distance). We\nprovide an extensive theoretical analysis of our algorithms, obtaining new\nresults in structural graph theory as a byproduct. We also perform exhaustive\nempirical evaluation, including on-surface interpolation for rigid and\ndeformable objects (particularly for mesh-dynamics modeling), Wasserstein\ndistance computations for point clouds, and the Gromov-Wasserstein variant.",
          "link": "http://arxiv.org/abs/2302.00942",
          "publishedOn": "2023-10-07T00:42:21.036Z",
          "wordCount": 710,
          "title": "Efficient Graph Field Integrators Meet Point Clouds. (arXiv:2302.00942v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.05435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Golovanevsky_M/0/1/0/all/0/1\">Michal Golovanevsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiller_E/0/1/0/all/0/1\">Eva Schiller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Akira Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Ritambhara Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1\">Carsten Eickhoff</a>",
          "description": "Multimodal learning models have become increasingly important as they surpass\nsingle-modality approaches on diverse tasks ranging from question-answering to\nautonomous driving. Despite the importance of multimodal learning, existing\nefforts focus on NLP applications, where the number of modalities is typically\nless than four (audio, video, text, images). However, data inputs in other\ndomains, such as the medical field, may include X-rays, PET scans, MRIs,\ngenetic screening, clinical notes, and more, creating a need for both efficient\nand accurate information fusion. Many state-of-the-art models rely on pairwise\ncross-modal attention, which does not scale well for applications with more\nthan three modalities. For $n$ modalities, computing attention will result in\n$n \\choose 2$ operations, potentially requiring considerable amounts of\ncomputational resources. To address this, we propose a new domain-neutral\nattention mechanism, One-Versus-Others (OvO) attention, that scales linearly\nwith the number of modalities and requires only $n$ attention operations, thus\noffering a significant reduction in computational complexity compared to\nexisting cross-modal attention algorithms. Using three diverse real-world\ndatasets as well as an additional simulation experiment, we show that our\nmethod improves performance compared to popular fusion techniques while\ndecreasing computation costs.",
          "link": "http://arxiv.org/abs/2307.05435",
          "publishedOn": "2023-10-07T00:42:21.006Z",
          "wordCount": 698,
          "title": "One-Versus-Others Attention: Scalable Multimodal Integration. (arXiv:2307.05435v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.11447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1\">Xinyu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yichun Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jingwen Shi</a>",
          "description": "Federated learning (FL) supports distributed training of a global machine\nlearning model across multiple devices with the help of a central server.\nHowever, data heterogeneity across different devices leads to the client model\ndrift issue and results in model performance degradation and poor model\nfairness. To address the issue, we design Federated learning with global-local\nKnowledge Fusion (FedKF) scheme in this paper. The key idea in FedKF is to let\nthe server return the global knowledge to be fused with the local knowledge in\neach training round so that the local model can be regularized towards the\nglobal optima. Therefore, the client model drift issue can be mitigated. In\nFedKF, we first propose the active-inactive model aggregation technique that\nsupports a precise global knowledge representation. Then, we propose a\ndata-free knowledge distillation (KD) approach to enable each client model to\nlearn the global knowledge (embedded in the global model) while each client\nmodel can still learn the local knowledge (embedded in the local dataset)\nsimultaneously, thereby realizing the global-local knowledge fusion process.\nThe theoretical analysis and intensive experiments demonstrate the superiority\nof FedKF over previous solutions.",
          "link": "http://arxiv.org/abs/2207.11447",
          "publishedOn": "2023-10-07T00:42:20.997Z",
          "wordCount": 727,
          "title": "Handling Data Heterogeneity in Federated Learning via Knowledge Distillation and Fusion. (arXiv:2207.11447v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiangyu Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tinghao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1\">Peter Henderson</a>",
          "description": "Optimizing large language models (LLMs) for downstream use cases often\ninvolves the customization of pre-trained LLMs through further fine-tuning.\nMeta's open release of Llama models and OpenAI's APIs for fine-tuning GPT-3.5\nTurbo on custom datasets also encourage this practice. But, what are the safety\ncosts associated with such custom fine-tuning? We note that while existing\nsafety alignment infrastructures can restrict harmful behaviors of LLMs at\ninference time, they do not cover safety risks when fine-tuning privileges are\nextended to end-users. Our red teaming studies find that the safety alignment\nof LLMs can be compromised by fine-tuning with only a few adversarially\ndesigned training examples. For instance, we jailbreak GPT-3.5 Turbo's safety\nguardrails by fine-tuning it on only 10 such examples at a cost of less than\n$0.20 via OpenAI's APIs, making the model responsive to nearly any harmful\ninstructions. Disconcertingly, our research also reveals that, even without\nmalicious intent, simply fine-tuning with benign and commonly used datasets can\nalso inadvertently degrade the safety alignment of LLMs, though to a lesser\nextent. These findings suggest that fine-tuning aligned LLMs introduces new\nsafety risks that current safety infrastructures fall short of addressing --\neven if a model's initial safety alignment is impeccable, it is not necessarily\nto be maintained after custom fine-tuning. We outline and critically analyze\npotential mitigations and advocate for further research efforts toward\nreinforcing safety protocols for the custom fine-tuning of aligned LLMs.",
          "link": "http://arxiv.org/abs/2310.03693",
          "publishedOn": "2023-10-07T00:42:20.982Z",
          "wordCount": 769,
          "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!. (arXiv:2310.03693v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.16102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ajorlou_A/0/1/0/all/0/1\">Amir Ajorlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zihui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jadbabaie_A/0/1/0/all/0/1\">Ali Jadbabaie</a>",
          "description": "Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where\nincreasing network depth leads to homogeneous node representations. While\nprevious work has established that Graph Convolutional Networks (GCNs)\nexponentially lose expressive power, it remains controversial whether the graph\nattention mechanism can mitigate oversmoothing. In this work, we provide a\ndefinitive answer to this question through a rigorous mathematical analysis, by\nviewing attention-based GNNs as nonlinear time-varying dynamical systems and\nincorporating tools and techniques from the theory of products of inhomogeneous\nmatrices and the joint spectral radius. We establish that, contrary to popular\nbelief, the graph attention mechanism cannot prevent oversmoothing and loses\nexpressive power exponentially. The proposed framework extends the existing\nresults on oversmoothing for symmetric GCNs to a significantly broader class of\nGNN models, including random walk GCNs, Graph Attention Networks (GATs) and\n(graph) transformers. In particular, our analysis accounts for asymmetric,\nstate-dependent and time-varying aggregation operators and a wide range of\ncommon nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU.",
          "link": "http://arxiv.org/abs/2305.16102",
          "publishedOn": "2023-10-07T00:42:20.974Z",
          "wordCount": 699,
          "title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks. (arXiv:2305.16102v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16150",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liang_Z/0/1/0/all/0/1\">Ziyun Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Anthony_H/0/1/0/all/0/1\">Harry Anthony</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wagner_F/0/1/0/all/0/1\">Felix Wagner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamnitsas_K/0/1/0/all/0/1\">Konstantinos Kamnitsas</a>",
          "description": "Unsupervised anomaly segmentation aims to detect patterns that are distinct\nfrom any patterns processed during training, commonly called abnormal or\nout-of-distribution patterns, without providing any associated manual\nsegmentations. Since anomalies during deployment can lead to model failure,\ndetecting the anomaly can enhance the reliability of models, which is valuable\nin high-risk domains like medical imaging. This paper introduces Masked\nModality Cycles with Conditional Diffusion (MMCCD), a method that enables\nsegmentation of anomalies across diverse patterns in multimodal MRI. The method\nis based on two fundamental ideas. First, we propose the use of cyclic modality\ntranslation as a mechanism for enabling abnormality detection.\nImage-translation models learn tissue-specific modality mappings, which are\ncharacteristic of tissue physiology. Thus, these learned mappings fail to\ntranslate tissues or image patterns that have never been encountered during\ntraining, and the error enables their segmentation. Furthermore, we combine\nimage translation with a masked conditional diffusion model, which attempts to\n`imagine' what tissue exists under a masked area, further exposing unknown\npatterns as the generative model fails to recreate them. We evaluate our method\non a proxy task by training on healthy-looking slices of BraTS2021\nmulti-modality MRIs and testing on slices with tumors. We show that our method\ncompares favorably to previous unsupervised approaches based on image\nreconstruction and denoising with autoencoders and diffusion models.",
          "link": "http://arxiv.org/abs/2308.16150",
          "publishedOn": "2023-10-07T00:42:20.868Z",
          "wordCount": 775,
          "title": "Modality Cycles with Masked Conditional Diffusion for Unsupervised Anomaly Segmentation in MRI. (arXiv:2308.16150v2 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2204.05923",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Engquist_B/0/1/0/all/0/1\">Bj&#xf6;rn Engquist</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ren_K/0/1/0/all/0/1\">Kui Ren</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_Y/0/1/0/all/0/1\">Yunan Yang</a>",
          "description": "We propose a new gradient descent algorithm with added stochastic terms for\nfinding the global optimizers of nonconvex optimization problems. A key\ncomponent in the algorithm is the adaptive tuning of the randomness based on\nthe value of the objective function. In the language of simulated annealing,\nthe temperature is state-dependent. With this, we prove the global convergence\nof the algorithm with an algebraic rate both in probability and in the\nparameter space. This is a significant improvement over the classical rate from\nusing a more straightforward control of the noise term. The convergence proof\nis based on the actual discrete setup of the algorithm, not just its continuous\nlimit as often done in the literature. We also present several numerical\nexamples to demonstrate the efficiency and robustness of the algorithm for\nreasonably complex objective functions.",
          "link": "http://arxiv.org/abs/2204.05923",
          "publishedOn": "2023-10-07T00:42:20.858Z",
          "wordCount": 679,
          "title": "An Algebraically Converging Stochastic Gradient Descent Algorithm for Global Optimization. (arXiv:2204.05923v3 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Albergo_M/0/1/0/all/0/1\">Michael S. Albergo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_M/0/1/0/all/0/1\">Mark Goldstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boffi_N/0/1/0/all/0/1\">Nicholas M. Boffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>",
          "description": "Generative models inspired by dynamical transport of measure -- such as flows\nand diffusions -- construct a continuous-time map between two probability\ndensities. Conventionally, one of these is the target density, only accessible\nthrough samples, while the other is taken as a simple base density that is\ndata-agnostic. In this work, using the framework of stochastic interpolants, we\nformalize how to \\textit{couple} the base and the target densities. This\nenables us to incorporate information about class labels or continuous\nembeddings to construct dynamical transport maps that serve as conditional\ngenerative models. We show that these transport maps can be learned by solving\na simple square loss regression problem analogous to the standard independent\nsetting. We demonstrate the usefulness of constructing dependent couplings in\npractice through experiments in super-resolution and in-painting.",
          "link": "http://arxiv.org/abs/2310.03725",
          "publishedOn": "2023-10-07T00:42:20.847Z",
          "wordCount": 631,
          "title": "Stochastic interpolants with data-dependent couplings. (arXiv:2310.03725v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06125",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schmalstieg_F/0/1/0/all/0/1\">Fabian Schmalstieg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honerkamp_D/0/1/0/all/0/1\">Daniel Honerkamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welschehold_T/0/1/0/all/0/1\">Tim Welschehold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1\">Abhinav Valada</a>",
          "description": "Existing object-search approaches enable robots to search through free\npathways, however, robots operating in unstructured human-centered environments\nfrequently also have to manipulate the environment to their needs. In this\nwork, we introduce a novel interactive multi-object search task in which a\nrobot has to open doors to navigate rooms and search inside cabinets and\ndrawers to find target objects. These new challenges require combining\nmanipulation and navigation skills in unexplored environments. We present\nHIMOS, a hierarchical reinforcement learning approach that learns to compose\nexploration, navigation, and manipulation skills. To achieve this, we design an\nabstract high-level action space around a semantic map memory and leverage the\nexplored environment as instance navigation points. We perform extensive\nexperiments in simulation and the real world that demonstrate that, with\naccurate perception, the decision making of HIMOS effectively transfers to new\nenvironments in a zero-shot manner. It shows robustness to unseen subpolicies,\nfailures in their execution, and different robot kinematics. These capabilities\nopen the door to a wide range of downstream tasks across embodied AI and\nreal-world use cases.",
          "link": "http://arxiv.org/abs/2307.06125",
          "publishedOn": "2023-10-07T00:42:20.820Z",
          "wordCount": 696,
          "title": "Learning Hierarchical Interactive Multi-Object Search for Mobile Manipulation. (arXiv:2307.06125v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kreikemeyer_J/0/1/0/all/0/1\">Justin N. Kreikemeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andelfinger_P/0/1/0/all/0/1\">Philipp Andelfinger</a>",
          "description": "Programs involving discontinuities introduced by control flow constructs such\nas conditional branches pose challenges to mathematical optimization methods\nthat assume a degree of smoothness in the objective function's response\nsurface. Smooth interpretation (SI) is a form of abstract interpretation that\napproximates the convolution of a program's output with a Gaussian kernel, thus\nsmoothing its output in a principled manner. Here, we combine SI with automatic\ndifferentiation (AD) to efficiently compute gradients of smoothed programs. In\ncontrast to AD across a regular program execution, these gradients also capture\nthe effects of alternative control flow paths. The combination of SI with AD\nenables the direct gradient-based parameter synthesis for branching programs,\nallowing for instance the calibration of simulation models or their combination\nwith neural network models in machine learning pipelines. We detail the effects\nof the approximations made for tractability in SI and propose a novel Monte\nCarlo estimator that avoids the underlying assumptions by estimating the\nsmoothed programs' gradients through a combination of AD and sampling. Using\nDiscoGrad, our tool for automatically translating simple C++ programs to a\nsmooth differentiable form, we perform an extensive evaluation. We compare the\ncombination of SI with AD and our Monte Carlo estimator to existing\ngradient-free and stochastic methods on four non-trivial and originally\ndiscontinuous problems ranging from classical simulation-based optimization to\nneural network-driven control. While the optimization progress with the\nSI-based estimator depends on the complexity of the programs' control flow, our\nMonte Carlo estimator is competitive in all problems, exhibiting the fastest\nconvergence by a substantial margin in our highest-dimensional problem.",
          "link": "http://arxiv.org/abs/2310.03585",
          "publishedOn": "2023-10-07T00:42:20.811Z",
          "wordCount": 770,
          "title": "Smoothing Methods for Automatic Differentiation Across Conditional Branches. (arXiv:2310.03585v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.01690",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Nath_P/0/1/0/all/0/1\">Pritthijit Nath</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shukla_P/0/1/0/all/0/1\">Pancham Shukla</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Quilodran_Casas_C/0/1/0/all/0/1\">C&#xe9;sar Quilodr&#xe1;n-Casas</a>",
          "description": "As cyclones become more intense due to climate change, the rise of AI-based\nmodelling provides a more affordable and accessible approach compared to\ntraditional methods based on mathematical models. This work leverages diffusion\nmodels to forecast cyclone trajectories and precipitation patterns by\nintegrating satellite imaging, remote sensing, and atmospheric data, employing\na cascaded approach that incorporates forecasting, super-resolution, and\nprecipitation modelling, with training on a dataset of 51 cyclones from six\nmajor basins. Experiments demonstrate that the final forecasts from the\ncascaded models show accurate predictions up to a 36-hour rollout, with SSIM\nand PSNR values exceeding 0.5 and 20 dB, respectively, for all three tasks.\nThis work also highlights the promising efficiency of AI methods such as\ndiffusion models for high-performance needs, such as cyclone forecasting, while\nremaining computationally affordable, making them ideal for highly vulnerable\nregions with critical forecasting needs and financial limitations. Code\naccessible at \\url{https://github.com/nathzi1505/forecast-diffmodels}.",
          "link": "http://arxiv.org/abs/2310.01690",
          "publishedOn": "2023-10-07T00:42:20.781Z",
          "wordCount": 680,
          "title": "Forecasting Tropical Cyclones with Cascaded Diffusion Models. (arXiv:2310.01690v2 [physics.ao-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.00195",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Altabaa_A/0/1/0/all/0/1\">Awni Altabaa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Webb_T/0/1/0/all/0/1\">Taylor Webb</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cohen_J/0/1/0/all/0/1\">Jonathan Cohen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lafferty_J/0/1/0/all/0/1\">John Lafferty</a>",
          "description": "An extension of Transformers is proposed that enables explicit relational\nreasoning through a novel module called the Abstractor. At the core of the\nAbstractor is a variant of attention called relational cross-attention. The\napproach is motivated by an architectural inductive bias for relational\nlearning that disentangles relational information from extraneous features\nabout individual objects. This enables explicit relational reasoning,\nsupporting abstraction and generalization from limited data. The Abstractor is\nfirst evaluated on simple discriminative relational tasks and compared to\nexisting relational architectures. Next, the Abstractor is evaluated on purely\nrelational sequence-to-sequence tasks, where dramatic improvements are seen in\nsample efficiency compared to standard Transformers. Finally, Abstractors are\nevaluated on a collection of tasks based on mathematical problem solving, where\nmodest but consistent improvements in performance and sample efficiency are\nobserved.",
          "link": "http://arxiv.org/abs/2304.00195",
          "publishedOn": "2023-10-07T00:42:20.761Z",
          "wordCount": 678,
          "title": "Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers. (arXiv:2304.00195v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03572",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Davis_O/0/1/0/all/0/1\">Owen Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Motamed_M/0/1/0/all/0/1\">Mohammad Motamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tempone_R/0/1/0/all/0/1\">Raul Tempone</a>",
          "description": "In this work, we consider the general problem of constructing a neural\nnetwork surrogate model using multi-fidelity information. Given an inexpensive\nlow-fidelity and an expensive high-fidelity computational model, we present a\nresidual multi-fidelity computational framework that formulates the correlation\nbetween models as a residual function, a possibly non-linear mapping between 1)\nthe shared input space of the models together with the low-fidelity model\noutput and 2) the discrepancy between the two model outputs. To accomplish\nthis, we train two neural networks to work in concert. The first network learns\nthe residual function on a small set of high-fidelity and low-fidelity data.\nOnce trained, this network is used to generate additional synthetic\nhigh-fidelity data, which is used in the training of a second network. This\nsecond network, once trained, acts as our surrogate for the high-fidelity\nquantity of interest. We present three numerical examples to demonstrate the\npower of the proposed framework. In particular, we show that dramatic savings\nin computational cost may be achieved when the output predictions are desired\nto be accurate within small tolerances.",
          "link": "http://arxiv.org/abs/2310.03572",
          "publishedOn": "2023-10-07T00:42:20.736Z",
          "wordCount": 673,
          "title": "Residual Multi-Fidelity Neural Network Computing. (arXiv:2310.03572v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raina_D/0/1/0/all/0/1\">Deepak Raina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathur_A/0/1/0/all/0/1\">Abhishek Mathur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voyles_R/0/1/0/all/0/1\">Richard M. Voyles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wachs_J/0/1/0/all/0/1\">Juan Wachs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrashekhara_S/0/1/0/all/0/1\">SH Chandrashekhara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Subir Kumar Saha</a>",
          "description": "The one of the significant challenges faced by autonomous robotic ultrasound\nsystems is acquiring high-quality images across different patients. The proper\norientation of the robotized probe plays a crucial role in governing the\nquality of ultrasound images. To address this challenge, we propose a\nsample-efficient method to automatically adjust the orientation of the\nultrasound probe normal to the point of contact on the scanning surface,\nthereby improving the acoustic coupling of the probe and resulting image\nquality. Our method utilizes Bayesian Optimization (BO) based search on the\nscanning surface to efficiently search for the normalized probe orientation. We\nformulate a novel objective function for BO that leverages the contact force\nmeasurements and underlying mechanics to identify the normal. We further\nincorporate a regularization scheme in BO to handle the noisy objective\nfunction. The performance of the proposed strategy has been assessed through\nexperiments on urinary bladder phantoms. These phantoms included planar,\ntilted, and rough surfaces, and were examined using both linear and convex\nprobes with varying search space limits. Further, simulation-based studies have\nbeen carried out using 3D human mesh models. The results demonstrate that the\nmean ($\\pm$SD) absolute angular error averaged over all phantoms and 3D models\nis $\\boldsymbol{2.4\\pm0.7^\\circ}$ and $\\boldsymbol{2.1\\pm1.3^\\circ}$,\nrespectively.",
          "link": "http://arxiv.org/abs/2310.03406",
          "publishedOn": "2023-10-07T00:42:20.721Z",
          "wordCount": 748,
          "title": "RUSOpt: Robotic UltraSound Probe Normalization with Bayesian Optimization for In-plane and Out-plane Scanning. (arXiv:2310.03406v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Masclef_N/0/1/0/all/0/1\">Ninon Liz&#xe9; Masclef</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_T/0/1/0/all/0/1\">T. Anderson Keller</a>",
          "description": "A prominent theory of affective response to music revolves around the\nconcepts of surprisal and expectation. In prior work, this idea has been\noperationalized in the form of probabilistic models of music which allow for\nprecise computation of song (or note-by-note) probabilities, conditioned on a\n'training set' of prior musical or cultural experiences. To date, however,\nthese models have been limited to compute exact probabilities through\nhand-crafted features or restricted to linear models which are likely not\nsufficient to represent the complex conditional distributions present in music.\nIn this work, we propose to use modern deep probabilistic generative models in\nthe form of a Diffusion Model to compute an approximate likelihood of a musical\ninput sequence. Unlike prior work, such a generative model parameterized by\ndeep neural networks is able to learn complex non-linear features directly from\na training set itself. In doing so, we expect to find that such models are able\nto more accurately represent the 'surprisal' of music for human listeners. From\nthe literature, it is known that there is an inverted U-shaped relationship\nbetween surprisal and the amount human subjects 'like' a given song. In this\nwork we show that pre-trained diffusion models indeed yield musical surprisal\nvalues which exhibit a negative quadratic relationship with measured subject\n'liking' ratings, and that the quality of this relationship is competitive with\nstate of the art methods such as IDyOM. We therefore present this model a\npreliminary step in developing modern deep generative models of music\nexpectation and subjective likability.",
          "link": "http://arxiv.org/abs/2310.03500",
          "publishedOn": "2023-10-07T00:42:20.713Z",
          "wordCount": 745,
          "title": "Deep Generative Models of Music Expectation. (arXiv:2310.03500v1 [cs.SD])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yihang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zuxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cen_Z/0/1/0/all/0/1\">Zhepeng Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiacheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tingnan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>",
          "description": "Safe reinforcement learning (RL) focuses on training reward-maximizing agents\nsubject to pre-defined safety constraints. Yet, learning versatile safe\npolicies that can adapt to varying safety constraint requirements during\ndeployment without retraining remains a largely unexplored and challenging\narea. In this work, we formulate the versatile safe RL problem and consider two\nprimary requirements: training efficiency and zero-shot adaptation capability.\nTo address them, we introduce the Conditioned Constrained Policy Optimization\n(CCPO) framework, consisting of two key modules: (1) Versatile Value Estimation\n(VVE) for approximating value functions under unseen threshold conditions, and\n(2) Conditioned Variational Inference (CVI) for encoding arbitrary constraint\nthresholds during policy optimization. Our extensive experiments demonstrate\nthat CCPO outperforms the baselines in terms of safety and task performance\nwhile preserving zero-shot adaptation capabilities to different constraint\nthresholds data-efficiently. This makes our approach suitable for real-world\ndynamic applications.",
          "link": "http://arxiv.org/abs/2310.03718",
          "publishedOn": "2023-10-07T00:42:20.706Z",
          "wordCount": 650,
          "title": "Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning. (arXiv:2310.03718v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2201.02824",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stephanovitch_A/0/1/0/all/0/1\">Arthur St&#xe9;phanovitch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tanielian_U/0/1/0/all/0/1\">Ugo Tanielian</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cadre_B/0/1/0/all/0/1\">Beno&#xee;t Cadre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Klutchnikoff_N/0/1/0/all/0/1\">Nicolas Klutchnikoff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Biau_G/0/1/0/all/0/1\">G&#xe9;rard Biau</a>",
          "description": "The mathematical forces at work behind Generative Adversarial Networks raise\nchallenging theoretical issues. Motivated by the important question of\ncharacterizing the geometrical properties of the generated distributions, we\nprovide a thorough analysis of Wasserstein GANs (WGANs) in both the finite\nsample and asymptotic regimes. We study the specific case where the latent\nspace is univariate and derive results valid regardless of the dimension of the\noutput space. We show in particular that for a fixed sample size, the optimal\nWGANs are closely linked with connected paths minimizing the sum of the squared\nEuclidean distances between the sample points. We also highlight the fact that\nWGANs are able to approach (for the 1-Wasserstein distance) the target\ndistribution as the sample size tends to infinity, at a given convergence rate\nand provided the family of generative Lipschitz functions grows appropriately.\nWe derive in passing new results on optimal transport theory in the\nsemi-discrete setting.",
          "link": "http://arxiv.org/abs/2201.02824",
          "publishedOn": "2023-10-07T00:42:20.698Z",
          "wordCount": 664,
          "title": "Optimal 1-Wasserstein Distance for WGANs. (arXiv:2201.02824v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garcin_S/0/1/0/all/0/1\">Samuel Garcin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doran_J/0/1/0/all/0/1\">James Doran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shangmin Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucas_C/0/1/0/all/0/1\">Christopher G. Lucas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>",
          "description": "A key limitation preventing the wider adoption of autonomous agents trained\nvia deep reinforcement learning (RL) is their limited ability to generalise to\nnew environments, even when these share similar characteristics with\nenvironments encountered during training. In this work, we investigate how a\nnon-uniform sampling strategy of individual environment instances, or levels,\naffects the zero-shot generalisation (ZSG) ability of RL agents, considering\ntwo failure modes: overfitting and over-generalisation. As a first step, we\nmeasure the mutual information (MI) between the agent's internal representation\nand the set of training levels, which we find to be well-correlated to instance\noverfitting. In contrast to uniform sampling, adaptive sampling strategies\nprioritising levels based on their value loss are more effective at maintaining\nlower MI, which provides a novel theoretical justification for this class of\ntechniques. We then turn our attention to unsupervised environment design (UED)\nmethods, which adaptively generate new training levels and minimise MI more\neffectively than methods sampling from a fixed set. However, we find UED\nmethods significantly shift the training distribution, resulting in\nover-generalisation and worse ZSG performance over the distribution of\ninterest. To prevent both instance overfitting and over-generalisation, we\nintroduce self-supervised environment design (SSED). SSED generates levels\nusing a variational autoencoder, effectively reducing MI while minimising the\nshift with the distribution of interest, and leads to statistically significant\nimprovements in ZSG over fixed-set level sampling strategies and UED methods.",
          "link": "http://arxiv.org/abs/2310.03494",
          "publishedOn": "2023-10-07T00:42:20.674Z",
          "wordCount": 762,
          "title": "How the level sampling process impacts zero-shot generalisation in deep reinforcement learning. (arXiv:2310.03494v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maddock_S/0/1/0/all/0/1\">Samuel Maddock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1\">Graham Cormode</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maple_C/0/1/0/all/0/1\">Carsten Maple</a>",
          "description": "Preserving individual privacy while enabling collaborative data sharing is\ncrucial for organizations. Synthetic data generation is one solution, producing\nartificial data that mirrors the statistical properties of private data. While\nnumerous techniques have been devised under differential privacy, they\npredominantly assume data is centralized. However, data is often distributed\nacross multiple clients in a federated manner. In this work, we initiate the\nstudy of federated synthetic tabular data generation. Building upon a SOTA\ncentral method known as AIM, we present DistAIM and FLAIM. We show it is\nstraightforward to distribute AIM, extending a recent approach based on secure\nmulti-party computation which necessitates additional overhead, making it less\nsuited to federated scenarios. We then demonstrate that naively federating AIM\ncan lead to substantial degradation in utility under the presence of\nheterogeneity. To mitigate both issues, we propose an augmented FLAIM approach\nthat maintains a private proxy of heterogeneity. We simulate our methods across\na range of benchmark datasets under different degrees of heterogeneity and show\nthis can improve utility while reducing overhead.",
          "link": "http://arxiv.org/abs/2310.03447",
          "publishedOn": "2023-10-07T00:42:20.667Z",
          "wordCount": 674,
          "title": "FLAIM: AIM-based Synthetic Data Generation in the Federated Setting. (arXiv:2310.03447v1 [cs.CR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1802.00810",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Yue_T/0/1/0/all/0/1\">Tianwei Yue</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_Y/0/1/0/all/0/1\">Yuanxin Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_L/0/1/0/all/0/1\">Longxiang Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gu_C/0/1/0/all/0/1\">Chunming Gu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xue_H/0/1/0/all/0/1\">Haoru Xue</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_W/0/1/0/all/0/1\">Wenping Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lyu_Q/0/1/0/all/0/1\">Qi Lyu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dun_Y/0/1/0/all/0/1\">Yujie Dun</a>",
          "description": "Advancements in genomic research such as high-throughput sequencing\ntechniques have driven modern genomic studies into \"big data\" disciplines. This\ndata explosion is constantly challenging conventional methods used in genomics.\nIn parallel with the urgent demand for robust algorithms, deep learning has\nsucceeded in a variety of fields such as vision, speech, and text processing.\nYet genomics entails unique challenges to deep learning since we are expecting\nfrom deep learning a superhuman intelligence that explores beyond our knowledge\nto interpret the genome. A powerful deep learning model should rely on\ninsightful utilization of task-specific knowledge. In this paper, we briefly\ndiscuss the strengths of different deep learning models from a genomic\nperspective so as to fit each particular task with a proper deep architecture,\nand remark on practical considerations of developing modern deep learning\narchitectures for genomics. We also provide a concise review of deep learning\napplications in various aspects of genomic research, as well as pointing out\npotential opportunities and obstacles for future genomics applications.",
          "link": "http://arxiv.org/abs/1802.00810",
          "publishedOn": "2023-10-07T00:42:20.651Z",
          "wordCount": 702,
          "title": "Deep Learning for Genomics: A Concise Overview. (arXiv:1802.00810v4 [q-bio.GN] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.13673",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1\">Zeyuan Allen-Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>",
          "description": "We design controlled experiments to study HOW generative language models,\nlike GPT, learn context-free grammars (CFGs) -- diverse language systems with a\ntree-like structure capturing many aspects of natural languages, programs, and\nlogics. CFGs are as hard as pushdown automata, and can be ambiguous so that\nverifying if a string satisfies the rules requires dynamic programming. We\nconstruct synthetic data and demonstrate that even for difficult (long and\nambiguous) CFGs, pre-trained transformers can learn to generate sentences with\nnear-perfect accuracy and impressive diversity.\n\nMore importantly, we delve into the physical principles behind how\ntransformers learns CFGs. We discover that the hidden states within the\ntransformer implicitly and precisely encode the CFG structure (such as putting\ntree node information exactly on the subtree boundary), and learn to form\n\"boundary to boundary\" attentions resembling dynamic programming. We also cover\nsome extension of CFGs as well as the robustness aspect of transformers against\ngrammar mistakes. Overall, our research provides a comprehensive and empirical\nunderstanding of how transformers learn CFGs, and reveals the physical\nmechanisms utilized by transformers to capture the structure and rules of\nlanguages.",
          "link": "http://arxiv.org/abs/2305.13673",
          "publishedOn": "2023-10-07T00:42:20.562Z",
          "wordCount": 708,
          "title": "Physics of Language Models: Part 1, Context-Free Grammar. (arXiv:2305.13673v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.17260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suomela_L/0/1/0/all/0/1\">Lauri Suomela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalliola_J/0/1/0/all/0/1\">Jussi Kalliola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edelman_H/0/1/0/all/0/1\">Harry Edelman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamarainen_J/0/1/0/all/0/1\">Joni-Kristian K&#xe4;m&#xe4;r&#xe4;inen</a>",
          "description": "Recent results suggest that splitting topological navigation into\nrobot-independent and robot-specific components improves navigation performance\nby enabling the robot-independent part to be trained with data collected by\ndifferent robot types. However, the navigation methods are still limited by the\nscarcity of suitable training data and suffer from poor computational scaling.\nIn this work, we present PlaceNav, subdividing the robot-independent part into\nnavigation-specific and generic computer vision components. We utilize visual\nplace recognition for the subgoal selection of the topological navigation\npipeline. This makes subgoal selection more efficient and enables leveraging\nlarge-scale datasets from non-robotics sources, increasing training data\navailability. Bayesian filtering, enabled by place recognition, further\nimproves navigation performance by increasing the temporal consistency of\nsubgoals. Our experimental results verify the design and the new model obtains\na 76% higher success rate in indoor and 23% higher in outdoor navigation tasks\nwith higher computational efficiency.",
          "link": "http://arxiv.org/abs/2309.17260",
          "publishedOn": "2023-10-07T00:42:20.550Z",
          "wordCount": 663,
          "title": "PlaceNav: Topological Navigation through Place Recognition. (arXiv:2309.17260v3 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03722",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1\">Hongjian Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "In 1976, Lai constructed a nontrivial confidence sequence for the mean $\\mu$\nof a Gaussian distribution with unknown variance $\\sigma$. Curiously, he\nemployed both an improper (right Haar) mixture over $\\sigma$ and an improper\n(flat) mixture over $\\mu$. Here, we elaborate carefully on the details of his\nconstruction, which use generalized nonintegrable martingales and an extended\nVille's inequality. While this does yield a sequential t-test, it does not\nyield an ``e-process'' (due to the nonintegrability of his martingale). In this\npaper, we develop two new e-processes and confidence sequences for the same\nsetting: one is a test martingale in a reduced filtration, while the other is\nan e-process in the canonical data filtration. These are respectively obtained\nby swapping Lai's flat mixture for a Gaussian mixture, and swapping the right\nHaar mixture over $\\sigma$ with the maximum likelihood estimate under the null,\nas done in universal inference. We also analyze the width of resulting\nconfidence sequences, which have a curious dependence on the error probability\n$\\alpha$. Numerical experiments are provided along the way to compare and\ncontrast the various approaches.",
          "link": "http://arxiv.org/abs/2310.03722",
          "publishedOn": "2023-10-07T00:42:20.528Z",
          "wordCount": 698,
          "title": "Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.14420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lam_A/0/1/0/all/0/1\">Albert Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anitescu_M/0/1/0/all/0/1\">Mihai Anitescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanyam_A/0/1/0/all/0/1\">Anirudh Subramanyam</a>",
          "description": "Measures of power grid vulnerability are often assessed by the amount of\ndamage an adversary can exact on the network. However, the cascading impact of\nsuch attacks is often overlooked, even though cascades are one of the primary\ncauses of large-scale blackouts. This paper explores modifications of\ntransmission line protection settings as candidates for adversarial attacks,\nwhich can remain undetectable as long as the network equilibrium state remains\nunaltered. This forms the basis of a black-box function in a Bayesian\noptimization procedure, where the objective is to find protection settings that\nmaximize network degradation due to cascading. Notably, our proposed method is\nagnostic to the choice of the cascade simulator and its underlying assumptions.\nNumerical experiments reveal that, against conventional wisdom, maximally\nmisconfiguring the protection settings of all network lines does not cause the\nmost cascading. More surprisingly, even when the degree of misconfiguration is\nlimited due to resource constraints, it is still possible to find settings that\nproduce cascades comparable in severity to instances where there are no\nresource constraints.",
          "link": "http://arxiv.org/abs/2304.14420",
          "publishedOn": "2023-10-07T00:42:20.474Z",
          "wordCount": 701,
          "title": "Network Cascade Vulnerability using Constrained Bayesian Optimization. (arXiv:2304.14420v2 [cs.SI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sodhi_P/0/1/0/all/0/1\">Paloma Sodhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Branavan_S/0/1/0/all/0/1\">S.R.K. Branavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_R/0/1/0/all/0/1\">Ryan McDonald</a>",
          "description": "Large language models (LLMs) have demonstrated remarkable capabilities in\nperforming a range of instruction following tasks in few and zero-shot\nsettings. However, teaching LLMs to perform tasks on the web presents\nfundamental challenges -- combinatorially large open-world tasks and variations\nacross web interfaces. We tackle these challenges by leveraging LLMs to\ndecompose web tasks into a collection of sub-tasks, each of which can be solved\nby a low-level, closed-loop policy. These policies constitute a shared grammar\nacross tasks, i.e., new web tasks can be expressed as a composition of these\npolicies. We propose a novel framework, Hierarchical Policies for Web Actions\nusing LLMs (HeaP), that learns a set of hierarchical LLM prompts from\ndemonstrations for planning high-level tasks and executing them via a sequence\nof low-level policies. We evaluate HeaP against a range of baselines on a suite\nof web tasks, including MiniWoB++, WebArena, a mock airline CRM, as well as\nlive website interactions, and show that it is able to outperform prior works\nusing orders of magnitude less data.",
          "link": "http://arxiv.org/abs/2310.03720",
          "publishedOn": "2023-10-07T00:42:20.429Z",
          "wordCount": 673,
          "title": "HeaP: Hierarchical Policies for Web Actions using LLMs. (arXiv:2310.03720v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2112.08417",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gerhardus_A/0/1/0/all/0/1\">Andreas Gerhardus</a>",
          "description": "In this paper, we introduce a novel class of graphical models for\nrepresenting time lag specific causal relationships and independencies of\nmultivariate time series with unobserved confounders. We completely\ncharacterize these graphs and show that they constitute proper subsets of the\ncurrently employed model classes. As we show, from the novel graphs one can\nthus draw stronger causal inferences -- without additional assumptions. We\nfurther introduce a graphical representation of Markov equivalence classes of\nthe novel graphs. This graphical representation contains more causal knowledge\nthan what current state-of-the-art causal discovery algorithms learn.",
          "link": "http://arxiv.org/abs/2112.08417",
          "publishedOn": "2023-10-07T00:42:20.394Z",
          "wordCount": 625,
          "title": "Characterization of causal ancestral graphs for time series with latent confounders. (arXiv:2112.08417v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mullen_A/0/1/0/all/0/1\">Aaron D. Mullen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armstrong_S/0/1/0/all/0/1\">Samuel E. Armstrong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talbert_J/0/1/0/all/0/1\">Jeff Talbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bumgardner_V/0/1/0/all/0/1\">V.K. Cody Bumgardner</a>",
          "description": "Machine learning classification problems are widespread in bioinformatics,\nbut the technical knowledge required to perform model training, optimization,\nand inference can prevent researchers from utilizing this technology. This\narticle presents an automated tool for machine learning classification problems\nto simplify the process of training models and producing results while\nproviding informative visualizations and insights into the data. This tool\nsupports both binary and multiclass classification problems, and it provides\naccess to a variety of models and methods. Synthetic data can be generated\nwithin the interface to fill missing values, balance class labels, or generate\nentirely new datasets. It also provides support for feature evaluation and\ngenerates explainability scores to indicate which features influence the output\nthe most. We present CLASSify, an open-source tool for simplifying the user\nexperience of solving classification problems without the need for knowledge of\nmachine learning.",
          "link": "http://arxiv.org/abs/2310.03618",
          "publishedOn": "2023-10-07T00:42:20.382Z",
          "wordCount": 668,
          "title": "CLASSify: A Web-Based Tool for Machine Learning. (arXiv:2310.03618v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.00818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Huiyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sano_A/0/1/0/all/0/1\">Akane Sano</a>",
          "description": "Electrocardiogram (ECG) is an essential signal in monitoring human heart\nactivities. Researchers have achieved promising results in leveraging ECGs in\nclinical applications with deep learning models. However, the mainstream deep\nlearning approaches usually neglect the periodic and formative attribute of the\nECG heartbeat waveform. In this work, we propose a novel ECG-Segment based\nLearning (ECG-SL) framework to explicitly model the periodic nature of ECG\nsignals. More specifically, ECG signals are first split into heartbeat\nsegments, and then structural features are extracted from each of the segments.\nBased on the structural features, a temporal model is designed to learn the\ntemporal information for various clinical tasks. Further, due to the fact that\nmassive ECG signals are available but the labeled data are very limited, we\nalso explore self-supervised learning strategy to pre-train the models,\nresulting significant improvement for downstream tasks. The proposed method\noutperforms the baseline model and shows competitive performances compared with\ntask-specific methods in three clinical applications: cardiac condition\ndiagnosis, sleep apnea detection, and arrhythmia classification. Further, we\nfind that the ECG-SL tends to focus more on each heartbeat's peak and ST range\nthan ResNet by visualizing the saliency maps.",
          "link": "http://arxiv.org/abs/2310.00818",
          "publishedOn": "2023-10-07T00:42:20.306Z",
          "wordCount": 721,
          "title": "ECG-SL: Electrocardiogram(ECG) Segment Learning, a deep learning method for ECG signal. (arXiv:2310.00818v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.02964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Ge Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1\">Jiangbin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan Z. Li</a>",
          "description": "Peptides are formed by the dehydration condensation of multiple amino acids.\nThe primary structure of a peptide can be represented either as an amino acid\nsequence or as a molecular graph consisting of atoms and chemical bonds.\nPrevious studies have indicated that deep learning routes specific to\nsequential and graphical peptide forms exhibit comparable performance on\ndownstream tasks. Despite the fact that these models learn representations of\nthe same modality of peptides, we find that they explain their predictions\ndifferently. Considering sequential and graphical models as two experts making\ninferences from different perspectives, we work on fusing expert knowledge to\nenrich the learned representations for improving the discriminative\nperformance. To achieve this, we propose a peptide co-modeling method, RepCon,\nwhich employs a contrastive learning-based framework to enhance the mutual\ninformation of representations from decoupled sequential and graphical\nend-to-end models. It considers representations from the sequential encoder and\nthe graphical encoder for the same peptide sample as a positive pair and learns\nto enhance the consistency of representations between positive sample pairs and\nto repel representations between negative pairs. Empirical studies of RepCon\nand other co-modeling methods are conducted on open-source discriminative\ndatasets, including aggregation propensity, retention time, antimicrobial\npeptide prediction, and family classification from Peptide Database. Our\nresults demonstrate the superiority of the co-modeling approach over\nindependent modeling, as well as the superiority of RepCon over other methods\nunder the co-modeling framework. In addition, the attribution on RepCon further\ncorroborates the validity of the approach at the level of model explanation.",
          "link": "http://arxiv.org/abs/2310.02964",
          "publishedOn": "2023-10-07T00:42:20.283Z",
          "wordCount": 782,
          "title": "Co-modeling the Sequential and Graphical Routes for Peptide Representation Learning. (arXiv:2310.02964v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.00944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Piroli_A/0/1/0/all/0/1\">Aldi Piroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dallabetta_V/0/1/0/all/0/1\">Vinzenz Dallabetta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kopp_J/0/1/0/all/0/1\">Johannes Kopp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walessa_M/0/1/0/all/0/1\">Marc Walessa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meissner_D/0/1/0/all/0/1\">Daniel Meissner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dietmayer_K/0/1/0/all/0/1\">Klaus Dietmayer</a>",
          "description": "LiDAR sensors are used in autonomous driving applications to accurately\nperceive the environment. However, they are affected by adverse weather\nconditions such as snow, fog, and rain. These everyday phenomena introduce\nunwanted noise into the measurements, severely degrading the performance of\nLiDAR-based perception systems. In this work, we propose a framework for\nimproving the robustness of LiDAR-based 3D object detectors against road spray.\nOur approach uses a state-of-the-art adverse weather detection network to\nfilter out spray from the LiDAR point cloud, which is then used as input for\nthe object detector. In this way, the detected objects are less affected by the\nadverse weather in the scene, resulting in a more accurate perception of the\nenvironment. In addition to adverse weather filtering, we explore the use of\nradar targets to further filter false positive detections. Tests on real-world\ndata show that our approach improves the robustness to road spray of several\npopular 3D object detectors.",
          "link": "http://arxiv.org/abs/2310.00944",
          "publishedOn": "2023-10-07T00:42:20.276Z",
          "wordCount": 693,
          "title": "Towards Robust 3D Object Detection In Rainy Conditions. (arXiv:2310.00944v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.06921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sam_D/0/1/0/all/0/1\">Dylan Sam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>",
          "description": "Owing to the prohibitive costs of generating large amounts of labeled data,\nprogrammatic weak supervision is a growing paradigm within machine learning. In\nthis setting, users design heuristics that provide noisy labels for subsets of\nthe data. These weak labels are combined (typically via a graphical model) to\nform pseudolabels, which are then used to train a downstream model. In this\nwork, we question a foundational premise of the typical weakly supervised\nlearning pipeline: given that the heuristic provides all ``label\" information,\nwhy do we need to generate pseudolabels at all? Instead, we propose to directly\ntransform the heuristics themselves into corresponding loss functions that\npenalize differences between our model and the heuristic. By constructing\nlosses directly from the heuristics, we can incorporate more information than\nis used in the standard weakly supervised pipeline, such as how the heuristics\nmake their decisions, which explicitly informs feature selection during\ntraining. We call our method Losses over Labels (LoL) as it creates losses\ndirectly from heuristics without going through the intermediate step of a\nlabel. We show that LoL improves upon existing weak supervision methods on\nseveral benchmark text and image classification tasks and further demonstrate\nthat incorporating gradient information leads to better performance on almost\nevery task.",
          "link": "http://arxiv.org/abs/2212.06921",
          "publishedOn": "2023-10-07T00:42:20.270Z",
          "wordCount": 738,
          "title": "Losses over Labels: Weakly Supervised Learning via Direct Loss Construction. (arXiv:2212.06921v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhanhui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1\">Jing Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiangyu Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanli Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>",
          "description": "Language models (LMs), despite aligning well with an average labeler through\nreinforcement learning from human feedback (RLHF), may not universally suit\ndiverse human preferences. Recent approaches therefore opt for customization by\ncollecting multi-dimensional feedback and creating distinct rewards for each\ndimension (e.g., helpfulness, harmlessness, honesty). LMs can then be tailored\nto different preferences using multi-objective RL (MORL) with different reward\nweightings. Yet, RL fine-tuning is unstable and resource-heavy, especially for\nMORLHF with diverse and usually conflicting objectives. In this paper, we\npresent Multi-Objective Direct Preference Optimization (MODPO), an RL-free\nalgorithm that extends Direct Preference Optimization (DPO) for multiple\nalignment objectives. Essentially, MODPO trains different LMs to represent\ndifferent collective reward models that combine all objectives with specific\nweightings. With a simple cross-entropy loss, the LMs optimized against the\nMODPO objective are analytically the exact solutions of the original MORLHF\nobjective. Empirical results in safety alignment and long-form question\nanswering confirm that MODPO matches or outperforms existing methods,\nefficiently producing a Pareto-optimal set of LMs that cater to diverse\npreferences with 3 times less computational resources compared with MORLHF.",
          "link": "http://arxiv.org/abs/2310.03708",
          "publishedOn": "2023-10-07T00:42:20.262Z",
          "wordCount": 684,
          "title": "Beyond One-Preference-for-All: Multi-Objective Direct Preference Optimization. (arXiv:2310.03708v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singhal_P/0/1/0/all/0/1\">Prasann Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_T/0/1/0/all/0/1\">Tanya Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiacheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>",
          "description": "Great successes have been reported using Reinforcement Learning from Human\nFeedback (RLHF) to align large language models. Open-source preference datasets\nand reward models have enabled wider experimentation beyond generic chat\nsettings, particularly to make systems more \"helpful\" for tasks like web\nquestion answering, summarization, and multi-turn dialogue. When optimizing for\nhelpfulness, RLHF has been consistently observed to drive models to produce\nlonger outputs. This paper demonstrates that optimizing for response length is\na significant factor behind RLHF's reported improvements in these settings.\nFirst, we study the relationship between reward and length for reward models\ntrained on three open-source preference datasets for helpfulness. Here, length\ncorrelates strongly with reward, and improvements in reward score are driven in\nlarge part by shifting the distribution over output lengths. We then explore\ninterventions during both RL and reward model learning to see if we can achieve\nthe same downstream improvements as RLHF without increasing length. While our\ninterventions mitigate length increases, they aren't uniformly effective across\nsettings. Furthermore, we find that even running RLHF with a reward based\nsolely on length can reproduce most of the downstream improvements over the\ninitial policy model, showing that reward models in these settings have a long\nway to go.",
          "link": "http://arxiv.org/abs/2310.03716",
          "publishedOn": "2023-10-07T00:42:20.246Z",
          "wordCount": 713,
          "title": "A Long Way to Go: Investigating Length Correlations in RLHF. (arXiv:2310.03716v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Both centralized and decentralized approaches have shown excellent\nperformance and great application value in federated learning (FL). However,\ncurrent studies do not provide sufficient evidence to show which one performs\nbetter. Although from the optimization perspective, decentralized methods can\napproach the comparable convergence of centralized methods with less\ncommunication, its test performance has always been inefficient in empirical\nstudies. To comprehensively explore their behaviors in FL, we study their\nexcess risks, including the joint analysis of both optimization and\ngeneralization. We prove that on smooth non-convex objectives, 1) centralized\nFL (CFL) always generalizes better than decentralized FL (DFL); 2) from\nperspectives of the excess risk and test error in CFL, adopting partial\nparticipation is superior to full participation; and, 3) there is a necessary\nrequirement for the topology in DFL to avoid performance collapse as the\ntraining scale increases. Based on some simple hardware metrics, we could\nevaluate which framework is better in practice. Extensive experiments are\nconducted on common setups in FL to validate that our theoretical analysis is\ncontextually valid in practical scenarios.",
          "link": "http://arxiv.org/abs/2310.03461",
          "publishedOn": "2023-10-07T00:42:20.237Z",
          "wordCount": 687,
          "title": "Which mode is better for federated learning? Centralized or Decentralized. (arXiv:2310.03461v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.08979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xinyue Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1\">Michael Backes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>",
          "description": "The way users acquire information is undergoing a paradigm shift with the\nadvent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves\nknowledge from the model itself and generates answers for users. ChatGPT's\nimpressive question-answering (QA) capability has attracted more than 100\nmillion users within a short period of time but has also raised concerns\nregarding its reliability. In this paper, we perform the first large-scale\nmeasurement of ChatGPT's reliability in the generic QA scenario with a\ncarefully curated set of 5,695 questions across ten datasets and eight domains.\nWe find that ChatGPT's reliability varies across different domains, especially\nunderperforming in law and science questions. We also demonstrate that system\nroles, originally designed by OpenAI to allow users to steer ChatGPT's\nbehavior, can impact ChatGPT's reliability in an imperceptible way. We further\nshow that ChatGPT is vulnerable to adversarial examples, and even a single\ncharacter change can negatively affect its reliability in certain cases. We\nbelieve that our study provides valuable insights into ChatGPT's reliability\nand underscores the need for strengthening the reliability and security of\nlarge language models (LLMs).",
          "link": "http://arxiv.org/abs/2304.08979",
          "publishedOn": "2023-10-07T00:42:20.227Z",
          "wordCount": 717,
          "title": "In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT. (arXiv:2304.08979v2 [cs.CR] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laufer_B/0/1/0/all/0/1\">Benjamin Laufer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1\">Jon Kleinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1\">Karen Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nissenbaum_H/0/1/0/all/0/1\">Helen Nissenbaum</a>",
          "description": "A broad current application of algorithms is in formal and quantitative\nmeasures of murky concepts -- like merit -- to make decisions. When people\nstrategically respond to these sorts of evaluations in order to gain favorable\ndecision outcomes, their behavior can be subjected to moral judgments. They may\nbe described as 'gaming the system' or 'cheating,' or (in other cases)\ninvesting 'honest effort' or 'improving.' Machine learning literature on\nstrategic behavior has tried to describe these dynamics by emphasizing the\nefforts expended by decision subjects hoping to obtain a more favorable\nassessment -- some works offer ways to preempt or prevent such manipulations,\nsome differentiate 'gaming' from 'improvement' behavior, while others aim to\nmeasure the effort burden or disparate effects of classification systems. We\nbegin from a different starting point: that the design of an evaluation itself\ncan be understood as furthering goals held by the evaluator which may be\nmisaligned with broader societal goals. To develop the idea that evaluation\nrepresents a strategic interaction in which both the evaluator and the subject\nof their evaluation are operating out of self-interest, we put forward a model\nthat represents the process of evaluation using three interacting agents: a\ndecision subject, an evaluator, and society, representing a bundle of values\nand oversight mechanisms. We highlight our model's applicability to a number of\nsocial systems where one or two players strategically undermine the others'\ninterests to advance their own. Treating evaluators as themselves strategic\nallows us to re-cast the scrutiny directed at decision subjects, towards the\nincentives that underpin institutional designs of evaluations. The moral\nstanding of strategic behaviors often depend on the moral standing of the\nevaluations and incentives that provoke such behaviors.",
          "link": "http://arxiv.org/abs/2310.03655",
          "publishedOn": "2023-10-07T00:42:20.202Z",
          "wordCount": null,
          "title": "Strategic Evaluation: Subjects, Evaluators, and Society. (arXiv:2310.03655v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03652",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fuhg_J/0/1/0/all/0/1\">Jan N. Fuhg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_R/0/1/0/all/0/1\">Reese E. Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouklas_N/0/1/0/all/0/1\">Nikolaos Bouklas</a>",
          "description": "Data-driven constitutive modeling with neural networks has received increased\ninterest in recent years due to its ability to easily incorporate physical and\nmechanistic constraints and to overcome the challenging and time-consuming task\nof formulating phenomenological constitutive laws that can accurately capture\nthe observed material response. However, even though neural network-based\nconstitutive laws have been shown to generalize proficiently, the generated\nrepresentations are not easily interpretable due to their high number of\ntrainable parameters. Sparse regression approaches exist that allow to\nobtaining interpretable expressions, but the user is tasked with creating a\nlibrary of model forms which by construction limits their expressiveness to the\nfunctional forms provided in the libraries. In this work, we propose to train\nregularized physics-augmented neural network-based constitutive models\nutilizing a smoothed version of $L^{0}$-regularization. This aims to maintain\nthe trustworthiness inherited by the physical constraints, but also enables\ninterpretability which has not been possible thus far on any type of machine\nlearning-based constitutive model where model forms were not assumed a-priory\nbut were actually discovered. During the training process, the network\nsimultaneously fits the training data and penalizes the number of active\nparameters, while also ensuring constitutive constraints such as thermodynamic\nconsistency. We show that the method can reliably obtain interpretable and\ntrustworthy constitutive models for compressible and incompressible\nhyperelasticity, yield functions, and hardening models for elastoplasticity,\nfor synthetic and experimental data.",
          "link": "http://arxiv.org/abs/2310.03652",
          "publishedOn": "2023-10-07T00:42:20.201Z",
          "wordCount": null,
          "title": "Extreme sparsification of physics-augmented neural networks for interpretable model discovery in mechanics. (arXiv:2310.03652v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jiashu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanatsoulis_C/0/1/0/all/0/1\">Charilaos I. Kanatsoulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>",
          "description": "Network alignment is the task of establishing one-to-one correspondences\nbetween the nodes of different graphs and finds a plethora of applications in\nhigh-impact domains. However, this task is known to be NP-hard in its general\nform, and existing algorithms do not scale up as the size of the graphs\nincreases. To tackle both challenges we propose a novel generalized graph\nautoencoder architecture, designed to extract powerful and robust node\nembeddings, that are tailored to the alignment task. We prove that the\ngenerated embeddings are associated with the eigenvalues and eigenvectors of\nthe graphs and can achieve more accurate alignment compared to classical\nspectral methods. Our proposed framework also leverages transfer learning and\ndata augmentation to achieve efficient network alignment at a very large scale\nwithout retraining. Extensive experiments on both network and sub-network\nalignment with real-world graphs provide corroborating evidence supporting the\neffectiveness and scalability of the proposed approach.",
          "link": "http://arxiv.org/abs/2310.03272",
          "publishedOn": "2023-10-07T00:42:20.200Z",
          "wordCount": null,
          "title": "Network Alignment with Transferable Graph Autoencoders. (arXiv:2310.03272v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15357",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ma_Y/0/1/0/all/0/1\">Yiyang Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_H/0/1/0/all/0/1\">Huan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_W/0/1/0/all/0/1\">Wenhan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_J/0/1/0/all/0/1\">Jianlong Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jiaying Liu</a>",
          "description": "Diffusion models, as a kind of powerful generative model, have given\nimpressive results on image super-resolution (SR) tasks. However, due to the\nrandomness introduced in the reverse process of diffusion models, the\nperformances of diffusion-based SR models are fluctuating at every time of\nsampling, especially for samplers with few resampled steps. This inherent\nrandomness of diffusion models results in ineffectiveness and instability,\nmaking it challenging for users to guarantee the quality of SR results.\nHowever, our work takes this randomness as an opportunity: fully analyzing and\nleveraging it leads to the construction of an effective plug-and-play sampling\nmethod that owns the potential to benefit a series of diffusion-based SR\nmethods. More in detail, we propose to steadily sample high-quality SR images\nfrom pre-trained diffusion-based SR models by solving diffusion ordinary\ndifferential equations (diffusion ODEs) with optimal boundary conditions (BCs)\nand analyze the characteristics between the choices of BCs and their\ncorresponding SR results. Our analysis shows the route to obtain an\napproximately optimal BC via an efficient exploration in the whole space. The\nquality of SR results sampled by the proposed method with fewer steps\noutperforms the quality of results sampled by current methods with randomness\nfrom the same pre-trained diffusion-based SR model, which means that our\nsampling method \"boosts\" current diffusion-based SR models without any\nadditional training.",
          "link": "http://arxiv.org/abs/2305.15357",
          "publishedOn": "2023-10-07T00:42:20.199Z",
          "wordCount": null,
          "title": "Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution. (arXiv:2305.15357v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03696",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Parhi_R/0/1/0/all/0/1\">Rahul Parhi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Unser_M/0/1/0/all/0/1\">Michael Unser</a>",
          "description": "We investigate the variational optimality (specifically, the Banach space\noptimality) of a large class of neural architectures with multivariate\nnonlinearities/activation functions. To that end, we construct a new family of\nBanach spaces defined via a regularization operator and the $k$-plane\ntransform. We prove a representer theorem that states that the solution sets to\nlearning problems posed over these Banach spaces are completely characterized\nby neural architectures with multivariate nonlinearities. These optimal\narchitectures have skip connections and are tightly connected to orthogonal\nweight normalization and multi-index models, both of which have received\nconsiderable interest in the neural network community. Our framework is\ncompatible with a number of classical nonlinearities including the rectified\nlinear unit (ReLU) activation function, the norm activation function, and the\nradial basis functions found in the theory of thin-plate/polyharmonic splines.\nWe also show that the underlying spaces are special instances of reproducing\nkernel Banach spaces and variation spaces. Our results shed light on the\nregularity of functions learned by neural networks trained on data,\nparticularly with multivariate nonlinearities, and provide new theoretical\nmotivation for several architectural choices found in practice.",
          "link": "http://arxiv.org/abs/2310.03696",
          "publishedOn": "2023-10-07T00:42:20.197Z",
          "wordCount": null,
          "title": "Banach Space Optimality of Neural Architectures With Multivariate Nonlinearities. (arXiv:2310.03696v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choffrut_A/0/1/0/all/0/1\">Antoine Choffrut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1\">Rachid Guerraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinot_R/0/1/0/all/0/1\">Rafael Pinot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sirdey_R/0/1/0/all/0/1\">Renaud Sirdey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stephan_J/0/1/0/all/0/1\">John Stephan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuber_M/0/1/0/all/0/1\">Martin Zuber</a>",
          "description": "Due to the large-scale availability of data, machine learning (ML) algorithms\nare being deployed in distributed topologies, where different nodes collaborate\nto train ML models over their individual data by exchanging model-related\ninformation (e.g., gradients) with a central server. However, distributed\nlearning schemes are notably vulnerable to two threats. First, Byzantine nodes\ncan single-handedly corrupt the learning by sending incorrect information to\nthe server, e.g., erroneous gradients. The standard approach to mitigate such\nbehavior is to use a non-linear robust aggregation method at the server.\nSecond, the server can violate the privacy of the nodes. Recent attacks have\nshown that exchanging (unencrypted) gradients enables a curious server to\nrecover the totality of the nodes' data. The use of homomorphic encryption\n(HE), a gold standard security primitive, has extensively been studied as a\nprivacy-preserving solution to distributed learning in non-Byzantine scenarios.\nHowever, due to HE's large computational demand especially for high-dimensional\nML models, there has not yet been any attempt to design purely homomorphic\noperators for non-linear robust aggregators. In this work, we present SABLE,\nthe first completely homomorphic and Byzantine robust distributed learning\nalgorithm. SABLE essentially relies on a novel plaintext encoding method that\nenables us to implement the robust aggregator over batching-friendly BGV.\nMoreover, this encoding scheme also accelerates state-of-the-art homomorphic\nsorting with larger security margins and smaller ciphertext size. We perform\nextensive experiments on image classification tasks and show that our algorithm\nachieves practical execution times while matching the ML performance of its\nnon-private counterpart.",
          "link": "http://arxiv.org/abs/2309.05395",
          "publishedOn": "2023-10-07T00:42:20.193Z",
          "wordCount": null,
          "title": "Practical Homomorphic Aggregation for Byzantine ML. (arXiv:2309.05395v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yujin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiaming Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1\">Zeying Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Junwei Liang</a>",
          "description": "Accurate precipitation forecasting is a vital challenge of both scientific\nand societal importance. Data-driven approaches have emerged as a widely used\nsolution for addressing this challenge. However, solely relying on data-driven\napproaches has limitations in modeling the underlying physics, making accurate\npredictions difficult. Coupling AI-based post-processing techniques with\ntraditional Numerical Weather Prediction (NWP) methods offers a more effective\nsolution for improving forecasting accuracy. Despite previous post-processing\nefforts, accurately predicting heavy rainfall remains challenging due to the\nimbalanced precipitation data across locations and complex relationships\nbetween multiple meteorological variables. To address these limitations, we\nintroduce the PostRainBench, a comprehensive multi-variable NWP post-processing\nbenchmark consisting of three datasets for NWP post-processing-based\nprecipitation forecasting. We propose CAMT, a simple yet effective Channel\nAttention Enhanced Multi-task Learning framework with a specially designed\nweighted loss function. Its flexible design allows for easy plug-and-play\nintegration with various backbones. Extensive experimental results on the\nproposed benchmark show that our method outperforms state-of-the-art methods by\n6.3%, 4.7%, and 26.8% in rain CSI on the three datasets respectively. Most\nnotably, our model is the first deep learning-based method to outperform\ntraditional Numerical Weather Prediction (NWP) approaches in extreme\nprecipitation conditions. It shows improvements of 15.6%, 17.4%, and 31.8% over\nNWP predictions in heavy rain CSI on respective datasets. These results\nhighlight the potential impact of our model in reducing the severe consequences\nof extreme weather events.",
          "link": "http://arxiv.org/abs/2310.02676",
          "publishedOn": "2023-10-07T00:42:20.192Z",
          "wordCount": null,
          "title": "PostRainBench: A comprehensive benchmark and a new model for precipitation forecasting. (arXiv:2310.02676v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akram_A/0/1/0/all/0/1\">Arslan Akram</a>",
          "description": "Since ChatGPT has emerged as a major AIGC model, providing high-quality\nresponses across a wide range of applications (including software development\nand maintenance), it has attracted much interest from many individuals. ChatGPT\nhas great promise, but there are serious problems that might arise from its\nmisuse, especially in the realms of education and public safety. Several AIGC\ndetectors are available, and they have all been tested on genuine text.\nHowever, more study is needed to see how effective they are for multi-domain\nChatGPT material. This study aims to fill this need by creating a multi-domain\ndataset for testing the state-of-the-art APIs and tools for detecting\nartificially generated information used by universities and other research\ninstitutions. A large dataset consisting of articles, abstracts, stories, news,\nand product reviews was created for this study. The second step is to use the\nnewly created dataset to put six tools through their paces. Six different\nartificial intelligence (AI) text identification systems, including \"GPTkit,\"\n\"GPTZero,\" \"Originality,\" \"Sapling,\" \"Writer,\" and \"Zylalab,\" have accuracy\nrates between 55.29 and 97.0%. Although all the tools fared well in the\nevaluations, originality was particularly effective across the board.",
          "link": "http://arxiv.org/abs/2310.01423",
          "publishedOn": "2023-10-07T00:42:20.188Z",
          "wordCount": null,
          "title": "An Empirical Study of AI Generated Text Detection Tools. (arXiv:2310.01423v1 [cs.CL] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03314",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kothari_A/0/1/0/all/0/1\">Aadi Kothari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tohme_T/0/1/0/all/0/1\">Tony Tohme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaotong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Youcef_Toumi_K/0/1/0/all/0/1\">Kamal Youcef-Toumi</a>",
          "description": "Human motion prediction is an essential step for efficient and safe\nhuman-robot collaboration. Current methods either purely rely on representing\nthe human joints in some form of neural network-based architecture or use\nregression models offline to fit hyper-parameters in the hope of capturing a\nmodel encompassing human motion. While these methods provide good initial\nresults, they are missing out on leveraging well-studied human body kinematic\nmodels as well as body and scene constraints which can help boost the efficacy\nof these prediction frameworks while also explicitly avoiding implausible human\njoint configurations. We propose a novel human motion prediction framework that\nincorporates human joint constraints and scene constraints in a Gaussian\nProcess Regression (GPR) model to predict human motion over a set time horizon.\nThis formulation is combined with an online context-aware constraints model to\nleverage task-dependent motions. It is tested on a human arm kinematic model\nand implemented on a human-robot collaborative setup with a UR5 robot arm to\ndemonstrate the real-time capability of our approach. Simulations were also\nperformed on datasets like HA4M and ANDY. The simulation and experimental\nresults demonstrate considerable improvements in a Gaussian Process framework\nwhen these constraints are explicitly considered.",
          "link": "http://arxiv.org/abs/2310.03314",
          "publishedOn": "2023-10-07T00:42:20.186Z",
          "wordCount": null,
          "title": "Enhanced Human-Robot Collaboration using Constrained Probabilistic Human-Motion Prediction. (arXiv:2310.03314v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.17329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1\">Kangxian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jiancheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Donglai Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1\">Ziqiao Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "Pulmonary diseases rank prominently among the principal causes of death\nworldwide. Curing them will require, among other things, a better understanding\nof the many complex 3D tree-shaped structures within the pulmonary system, such\nas airways, arteries, and veins. In theory, they can be modeled using\nhigh-resolution image stacks. Unfortunately, standard CNN approaches operating\non dense voxel grids are prohibitively expensive. To remedy this, we introduce\na point-based approach that preserves graph connectivity of tree skeleton and\nincorporates an implicit surface representation. It delivers SOTA accuracy at a\nlow computational cost and the resulting models have usable surfaces. Due to\nthe scarcity of publicly accessible data, we have also curated an extensive\ndataset to evaluate our approach and will make it public.",
          "link": "http://arxiv.org/abs/2309.17329",
          "publishedOn": "2023-10-07T00:42:20.182Z",
          "wordCount": null,
          "title": "Efficient Anatomical Labeling of Pulmonary Tree Structures via Implicit Point-Graph Networks. (arXiv:2309.17329v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zelai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yancheng Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yi Wu</a>",
          "description": "Self-play (SP) is a popular multi-agent reinforcement learning (MARL)\nframework for solving competitive games, where each agent optimizes policy by\ntreating others as part of the environment. Despite the empirical successes,\nthe theoretical properties of SP-based methods are limited to two-player\nzero-sum games. However, for mixed cooperative-competitive games where agents\non the same team need to cooperate with each other, we can show a simple\ncounter-example where SP-based methods cannot converge to a global Nash\nequilibrium (NE) with high probability. Alternatively, Policy-Space Response\nOracles (PSRO) is an iterative framework for learning NE, where the best\nresponses w.r.t. previous policies are learned in each iteration. PSRO can be\ndirectly extended to mixed cooperative-competitive settings by jointly learning\nteam best responses with all convergence properties unchanged. However, PSRO\nrequires repeatedly training joint policies from scratch till convergence,\nwhich makes it hard to scale to complex games. In this work, we develop a novel\nalgorithm, Fictitious Cross-Play (FXP), which inherits the benefits from both\nframeworks. FXP simultaneously trains an SP-based main policy and a counter\npopulation of best response policies. The main policy is trained by fictitious\nself-play and cross-play against the counter population, while the counter\npolicies are trained as the best responses to the main policy's past versions.\nWe validate our method in matrix games and show that FXP converges to global\nNEs while SP methods fail. We also conduct experiments in a gridworld domain,\nwhere FXP achieves higher Elo ratings and lower exploitabilities than\nbaselines, and a more challenging football game, where FXP defeats SOTA models\nwith over 94% win rate.",
          "link": "http://arxiv.org/abs/2310.03354",
          "publishedOn": "2023-10-07T00:42:20.181Z",
          "wordCount": null,
          "title": "Fictitious Cross-Play: Learning Global Nash Equilibrium in Mixed Cooperative-Competitive Games. (arXiv:2310.03354v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03378",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Bhure_P/0/1/0/all/0/1\">Pawan R. Bhure</a>, <a href=\"http://arxiv.org/find/math/1/au:+Santhanam_M/0/1/0/all/0/1\">M. S. Santhanam</a>",
          "description": "The study of interacting dynamical systems continues to attract research\ninterest in various fields of science and engineering. In a collection of\ninteracting particles, the interaction network contains information about how\nvarious components interact with one another. Inferring the information about\nthe interaction network from the dynamics of agents is a problem of\nlong-standing interest. In this work, we employ a self-supervised neural\nnetwork model to achieve two outcomes: to recover the interaction network and\nto predict the dynamics of individual agents. Both these information are\ninferred solely from the observed trajectory data. This work presents an\napplication of the Neural Relational Inference model to two dynamical systems:\ncoupled particles mediated by Hooke's law interaction and coupled phase\n(Kuramoto) oscillators.",
          "link": "http://arxiv.org/abs/2310.03378",
          "publishedOn": "2023-10-07T00:42:20.180Z",
          "wordCount": null,
          "title": "Machine learning the interaction network in coupled dynamical systems. (arXiv:2310.03378v1 [math.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.20057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lisha Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernando_H/0/1/0/all/0/1\">Heshan Fernando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_Y/0/1/0/all/0/1\">Yiming Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianyi Chen</a>",
          "description": "Multi-objective learning (MOL) problems often arise in emerging machine\nlearning problems when there are multiple learning criteria, data modalities,\nor learning tasks. Different from single-objective learning, one of the\ncritical challenges in MOL is the potential conflict among different objectives\nduring the iterative optimization process. Recent works have developed various\ndynamic weighting algorithms for MOL such as MGDA and its variants, where the\ncentral idea is to find an update direction that avoids conflicts among\nobjectives. Albeit its appealing intuition, empirical studies show that dynamic\nweighting methods may not always outperform static ones. To understand this\ntheory-practical gap, we focus on a new stochastic variant of MGDA - the\nMulti-objective gradient with Double sampling (MoDo) algorithm, and study the\ngeneralization performance of the dynamic weighting-based MoDo and its\ninterplay with optimization through the lens of algorithm stability. Perhaps\nsurprisingly, we find that the key rationale behind MGDA -- updating along\nconflict-avoidant direction - may hinder dynamic weighting algorithms from\nachieving the optimal ${\\cal O}(1/\\sqrt{n})$ population risk, where $n$ is the\nnumber of training samples. We further demonstrate the impact of the\nvariability of dynamic weights on the three-way trade-off among optimization,\ngeneralization, and conflict avoidance that is unique in MOL. We showcase the\ngenerality of our theoretical framework by analyzing other existing stochastic\nMOL algorithms under the framework. Experiments on various multi-task learning\nbenchmarks are performed to demonstrate the practical applicability. Code is\navailable at https://github.com/heshandevaka/Trade-Off-MOL.",
          "link": "http://arxiv.org/abs/2305.20057",
          "publishedOn": "2023-10-07T00:42:20.179Z",
          "wordCount": null,
          "title": "Three-Way Trade-Off in Multi-Objective Learning: Optimization, Generalization and Conflict-Avoidance. (arXiv:2305.20057v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xuelin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>",
          "description": "Building machines that can reason about physical events and their causal\nrelationships is crucial for flexible interaction with the physical world.\nHowever, most existing physical and causal reasoning benchmarks are exclusively\nbased on synthetically generated events and synthetic natural language\ndescriptions of causal relationships. This design brings up two issues. First,\nthere is a lack of diversity in both event types and natural language\ndescriptions; second, causal relationships based on manually-defined heuristics\nare different from human judgments. To address both shortcomings, we present\nthe CLEVRER-Humans benchmark, a video reasoning dataset for causal judgment of\nphysical events with human labels. We employ two techniques to improve data\ncollection efficiency: first, a novel iterative event cloze task to elicit a\nnew representation of events in videos, which we term Causal Event Graphs\n(CEGs); second, a data augmentation technique based on neural language\ngenerative models. We convert the collected CEGs into questions and answers to\nbe consistent with prior work. Finally, we study a collection of baseline\napproaches for CLEVRER-Humans question-answering, highlighting the great\nchallenges set forth by our benchmark.",
          "link": "http://arxiv.org/abs/2310.03635",
          "publishedOn": "2023-10-07T00:42:20.177Z",
          "wordCount": null,
          "title": "CLEVRER-Humans: Describing Physical and Causal Events the Human Way. (arXiv:2310.03635v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sehoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooper_C/0/1/0/all/0/1\">Coleman Hooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1\">Amir Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zhen Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1\">Sheng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1\">Michael W. Mahoney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1\">Kurt Keutzer</a>",
          "description": "Generative Large Language Models (LLMs) have demonstrated remarkable results\nfor a wide range of tasks. However, deploying these models for inference has\nbeen a significant challenge due to their unprecedented resource requirements.\nThis has forced existing deployment frameworks to use multi-GPU inference\npipelines, which are often complex and costly, or to use smaller and less\nperformant models. In this work, we demonstrate that the main bottleneck for\ngenerative inference with LLMs is memory bandwidth, rather than compute,\nspecifically for single batch inference. While quantization has emerged as a\npromising solution by representing model weights with reduced precision,\nprevious efforts have often resulted in notable performance degradation. To\naddress this, we introduce SqueezeLLM, a post-training quantization framework\nthat not only enables lossless compression to ultra-low precisions of up to\n3-bit, but also achieves higher quantization performance under the same memory\nconstraint. Our framework incorporates two novel ideas: (i) sensitivity-based\nnon-uniform quantization, which searches for the optimal bit precision\nassignment based on second-order information; and (ii) the Dense-and-Sparse\ndecomposition that stores outliers and sensitive weight values in an efficient\nsparse format. When applied to the LLaMA models, our 3-bit quantization\nsignificantly reduces the perplexity gap from the FP16 baseline by up to 2.1x\nas compared to the state-of-the-art methods with the same memory requirement.\nFurthermore, when deployed on an A6000 GPU, our quantized models achieve up to\n2.3x speedup compared to the baseline. Our code is open-sourced and available\nonline.",
          "link": "http://arxiv.org/abs/2306.07629",
          "publishedOn": "2023-10-07T00:42:20.176Z",
          "wordCount": null,
          "title": "SqueezeLLM: Dense-and-Sparse Quantization. (arXiv:2306.07629v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ettenhofer_A/0/1/0/all/0/1\">Armin Ettenhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulze_J/0/1/0/all/0/1\">Jan-Philipp Schulze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pizzi_K/0/1/0/all/0/1\">Karla Pizzi</a>",
          "description": "Audio adversarial examples are audio files that have been manipulated to fool\nan automatic speech recognition (ASR) system, while still sounding benign to a\nhuman listener. Most methods to generate such samples are based on a two-step\nalgorithm: first, a viable adversarial audio file is produced, then, this is\nfine-tuned with respect to perceptibility and robustness. In this work, we\npresent an integrated algorithm that uses psychoacoustic models and room\nimpulse responses (RIR) in the generation step. The RIRs are dynamically\ncreated by a neural network during the generation process to simulate a\nphysical environment to harden our examples against transformations experienced\nin over-the-air attacks. We compare the different approaches in three\nexperiments: in a simulated environment and in a realistic over-the-air\nscenario to evaluate the robustness, and in a human study to evaluate the\nperceptibility. Our algorithms considering psychoacoustics only or in addition\nto the robustness show an improvement in the signal-to-noise ratio (SNR) as\nwell as in the human perception study, at the cost of an increased word error\nrate (WER).",
          "link": "http://arxiv.org/abs/2310.03349",
          "publishedOn": "2023-10-07T00:42:20.174Z",
          "wordCount": null,
          "title": "An Integrated Algorithm for Robust and Imperceptible Audio Adversarial Examples. (arXiv:2310.03349v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.11546",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Tracey_B/0/1/0/all/0/1\">Brendan D. Tracey</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Michi_A/0/1/0/all/0/1\">Andrea Michi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chervonyi_Y/0/1/0/all/0/1\">Yuri Chervonyi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Davies_I/0/1/0/all/0/1\">Ian Davies</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Paduraru_C/0/1/0/all/0/1\">Cosmin Paduraru</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lazic_N/0/1/0/all/0/1\">Nevena Lazic</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Felici_F/0/1/0/all/0/1\">Federico Felici</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ewalds_T/0/1/0/all/0/1\">Timo Ewalds</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Donner_C/0/1/0/all/0/1\">Craig Donner</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Galperti_C/0/1/0/all/0/1\">Cristian Galperti</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Buchli_J/0/1/0/all/0/1\">Jonas Buchli</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Neunert_M/0/1/0/all/0/1\">Michael Neunert</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Huber_A/0/1/0/all/0/1\">Andrea Huber</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Evens_J/0/1/0/all/0/1\">Jonathan Evens</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kurylowicz_P/0/1/0/all/0/1\">Paula Kurylowicz</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mankowitz_D/0/1/0/all/0/1\">Daniel J. Mankowitz</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Riedmiller_M/0/1/0/all/0/1\">Martin Riedmiller</a>, The <a href=\"http://arxiv.org/find/physics/1/au:+Team_TCV/0/1/0/all/0/1\">TCV Team</a>",
          "description": "Reinforcement learning (RL) has shown promising results for real-time control\nsystems, including the domain of plasma magnetic control. However, there are\nstill significant drawbacks compared to traditional feedback control approaches\nfor magnetic confinement. In this work, we address key drawbacks of the RL\nmethod; achieving higher control accuracy for desired plasma properties,\nreducing the steady-state error, and decreasing the required time to learn new\ntasks. We build on top of \\cite{degrave2022magnetic}, and present algorithmic\nimprovements to the agent architecture and training procedure. We present\nsimulation results that show up to 65\\% improvement in shape accuracy, achieve\nsubstantial reduction in the long-term bias of the plasma current, and\nadditionally reduce the training time required to learn new tasks by a factor\nof 3 or more. We present new experiments using the upgraded RL-based\ncontrollers on the TCV tokamak, which validate the simulation results achieved,\nand point the way towards routinely achieving accurate discharges using the RL\napproach.",
          "link": "http://arxiv.org/abs/2307.11546",
          "publishedOn": "2023-10-07T00:42:20.174Z",
          "wordCount": null,
          "title": "Towards practical reinforcement learning for tokamak magnetic control. (arXiv:2307.11546v2 [physics.plasm-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1\">Seungwoo Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_W/0/1/0/all/0/1\">Wonsik Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_J/0/1/0/all/0/1\">Junghyo Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suk_H/0/1/0/all/0/1\">Heung-Il Suk</a>",
          "description": "Alzheimer's disease (AD) is a devastating neurodegenerative condition that\nprecedes progressive and irreversible dementia; thus, predicting its\nprogression over time is vital for clinical diagnosis and treatment. Numerous\nstudies have implemented structural magnetic resonance imaging (MRI) to model\nAD progression, focusing on three integral aspects: (i) temporal variability,\n(ii) incomplete observations, and (iii) temporal geometric characteristics.\nHowever, deep learning-based approaches regarding data variability and sparsity\nhave yet to consider inherent geometrical properties sufficiently. The ordinary\ndifferential equation-based geometric modeling method (ODE-RGRU) has recently\nemerged as a promising strategy for modeling time-series data by intertwining a\nrecurrent neural network and an ODE in Riemannian space. Despite its\nachievements, ODE-RGRU encounters limitations when extrapolating positive\ndefinite symmetric metrics from incomplete samples, leading to feature reverse\noccurrences that are particularly problematic, especially within the clinical\nfacet. Therefore, this study proposes a novel geometric learning approach that\nmodels longitudinal MRI biomarkers and cognitive scores by combining three\nmodules: topological space shift, ODE-RGRU, and trajectory estimation. We have\nalso developed a training algorithm that integrates manifold mapping with\nmonotonicity constraints to reflect measurement transition irreversibility. We\nverify our proposed method's efficacy by predicting clinical labels and\ncognitive scores over time in regular and irregular settings. Furthermore, we\nthoroughly analyze our proposed framework through an ablation study.",
          "link": "http://arxiv.org/abs/2310.03353",
          "publishedOn": "2023-10-07T00:42:20.173Z",
          "wordCount": null,
          "title": "Deep Geometric Learning with Monotonicity Constraints for Alzheimer's Disease Progression. (arXiv:2310.03353v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03365",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jafari_H/0/1/0/all/0/1\">Hossein Jafari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Faez_K/0/1/0/all/0/1\">Karim Faez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Amindavar_H/0/1/0/all/0/1\">Hamidreza Amindavar</a>",
          "description": "Lung cancer is highly lethal, emphasizing the critical need for early\ndetection. However, identifying lung nodules poses significant challenges for\nradiologists, who rely heavily on their expertise and experience for accurate\ndiagnosis. To address this issue, computer-aided diagnosis systems based on\nmachine learning techniques have emerged to assist doctors in identifying lung\nnodules from computed tomography (CT) scans. Unfortunately, existing networks\nin this domain often suffer from computational complexity, leading to high\nrates of false negatives and false positives, limiting their effectiveness. To\naddress these challenges, we present an innovative model that harnesses the\nstrengths of both convolutional neural networks and vision transformers.\nInspired by object detection in videos, we treat each 3D CT image as a video,\nindividual slices as frames, and lung nodules as objects, enabling a\ntime-series application. The primary objective of our work is to overcome\nhardware limitations during model training, allowing for efficient processing\nof 2D data while utilizing inter-slice information for accurate identification\nbased on 3D image context. We validated the proposed network by applying a\n10-fold cross-validation technique to the publicly available Lung Nodule\nAnalysis 2016 dataset. Our proposed architecture achieves an average\nsensitivity criterion of 97.84% and a competition performance metrics (CPM) of\n96.0% with few parameters. Comparative analysis with state-of-the-art\nadvancements in lung nodule identification demonstrates the significant\naccuracy achieved by our proposed model.",
          "link": "http://arxiv.org/abs/2310.03365",
          "publishedOn": "2023-10-07T00:42:20.173Z",
          "wordCount": null,
          "title": "Swin-Tempo: Temporal-Aware Lung Nodule Detection in CT Scans as Video Sequences Using Swin Transformer-Enhanced UNet. (arXiv:2310.03365v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.06178",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Allam_T/0/1/0/all/0/1\">Tarek Allam Jr.</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+McEwen_J/0/1/0/all/0/1\">Jason D. McEwen</a>",
          "description": "Future surveys such as the Legacy Survey of Space and Time (LSST) of the Vera\nC. Rubin Observatory will observe an order of magnitude more astrophysical\ntransient events than any previous survey before. With this deluge of\nphotometric data, it will be impossible for all such events to be classified by\nhumans alone. Recent efforts have sought to leverage machine learning methods\nto tackle the challenge of astronomical transient classification, with ever\nimproving success. Transformers are a recently developed deep learning\narchitecture, first proposed for natural language processing, that have shown a\ngreat deal of recent success. In this work we develop a new transformer\narchitecture, which uses multi-head self attention at its core, for general\nmulti-variate time-series data. Furthermore, the proposed time-series\ntransformer architecture supports the inclusion of an arbitrary number of\nadditional features, while also offering interpretability. We apply the\ntime-series transformer to the task of photometric classification, minimising\nthe reliance of expert domain knowledge for feature selection, while achieving\nresults comparable to state-of-the-art photometric classification methods. We\nachieve a logarithmic-loss of 0.507 on imbalanced data in a representative\nsetting using data from the Photometric LSST Astronomical Time-Series\nClassification Challenge (PLAsTiCC). Moreover, we achieve a micro-averaged\nreceiver operating characteristic area under curve of 0.98 and micro-averaged\nprecision-recall area under curve of 0.87.",
          "link": "http://arxiv.org/abs/2105.06178",
          "publishedOn": "2023-10-07T00:42:20.173Z",
          "wordCount": null,
          "title": "Paying Attention to Astronomical Transients: Introducing the Time-series Transformer for Photometric Classification. (arXiv:2105.06178v3 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaxu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xinping Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaowei Huang</a>",
          "description": "Hyperbolic graph convolutional networks (HGCN) have demonstrated significant\npotential in extracting information from hierarchical graphs. However, existing\nHGCNs are limited to shallow architectures, due to the expensive hyperbolic\noperations and the over-smoothing issue as depth increases. Although in GCNs,\ntreatments have been applied to alleviate over-smoothing, developing a\nhyperbolic therapy presents distinct challenges since operations should be\ncarefully designed to fit the hyperbolic nature. Addressing the above\nchallenges, in this work, we propose DeepHGCN, the first deep multi-layer HGCN\narchitecture with dramatically improved computational efficiency and\nsubstantially alleviated over-smoothing effect. DeepHGCN presents two key\nenablers of deep HGCNs: (1) a novel hyperbolic feature transformation layer\nthat enables fast and accurate linear maps; and (2) Techniques such as\nhyperbolic residual connections and regularization for both weights and\nfeatures facilitated by an efficient hyperbolic midpoint method. Extensive\nexperiments demonstrate that DeepHGCN obtains significant improvements in link\nprediction and node classification tasks compared to both Euclidean and shallow\nhyperbolic GCN variants.",
          "link": "http://arxiv.org/abs/2310.02027",
          "publishedOn": "2023-10-07T00:42:20.173Z",
          "wordCount": null,
          "title": "DeepHGCN: Toward Deeper Hyperbolic Graph Convolutional Networks. (arXiv:2310.02027v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1\">Haosen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_H/0/1/0/all/0/1\">Hamsa Bastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Existing approaches to algorithmic fairness aim to ensure equitable outcomes\nif human decision-makers comply perfectly with algorithmic decisions. However,\nperfect compliance with the algorithm is rarely a reality or even a desirable\noutcome in human-AI collaboration. Yet, recent studies have shown that\nselective compliance with fair algorithms can amplify discrimination relative\nto the prior human policy. As a consequence, ensuring equitable outcomes\nrequires fundamentally different algorithmic design principles that ensure\nrobustness to the decision-maker's (a priori unknown) compliance pattern. We\ndefine the notion of compliance-robustly fair algorithmic recommendations that\nare guaranteed to (weakly) improve fairness in decisions, regardless of the\nhuman's compliance pattern. We propose a simple optimization strategy to\nidentify the best performance-improving compliance-robustly fair policy.\nHowever, we show that it may be infeasible to design algorithmic\nrecommendations that are simultaneously fair in isolation, compliance-robustly\nfair, and more accurate than the human policy; thus, if our goal is to improve\nthe equity and accuracy of human-AI collaboration, it may not be desirable to\nenforce traditional fairness constraints.",
          "link": "http://arxiv.org/abs/2310.03647",
          "publishedOn": "2023-10-07T00:42:20.171Z",
          "wordCount": 659,
          "title": "Rethinking Fairness for Human-AI Collaboration. (arXiv:2310.03647v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.09376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_B/0/1/0/all/0/1\">Binhang Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hailong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Ruobing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiang Gao</a>",
          "description": "Deep neural network (DNN) models have become increasingly crucial components\nin intelligent software systems. However, training a DNN model is typically\nexpensive in terms of both time and money. To address this issue, researchers\nhave recently focused on reusing existing DNN models - borrowing the idea of\ncode reuse in software engineering. However, reusing an entire model could\ncause extra overhead or inherits the weakness from the undesired\nfunctionalities. Hence, existing work proposes to decompose an already trained\nmodel into modules, i.e., modularizing-after-training, and enable module reuse.\nSince trained models are not built for modularization,\nmodularizing-after-training incurs huge overhead and model accuracy loss. In\nthis paper, we propose a novel approach that incorporates modularization into\nthe model training process, i.e., modularizing-while-training (MwT). We train a\nmodel to be structurally modular through two loss functions that optimize\nintra-module cohesion and inter-module coupling. We have implemented the\nproposed approach for modularizing Convolutional Neural Network (CNN) models in\nthis work. The evaluation results on representative models demonstrate that MwT\noutperforms the state-of-the-art approach. Specifically, the accuracy loss\ncaused by MwT is only 1.13 percentage points, which is 1.76 percentage points\nless than that of the baseline. The kernel retention rate of the modules\ngenerated by MwT is only 14.58%, with a reduction of 74.31% over the\nstate-of-the-art approach. Furthermore, the total time cost required for\ntraining and modularizing is only 108 minutes, half of the baseline.",
          "link": "http://arxiv.org/abs/2306.09376",
          "publishedOn": "2023-10-07T00:42:20.111Z",
          "wordCount": null,
          "title": "Modularizing while Training: A New Paradigm for Modularizing DNN Models. (arXiv:2306.09376v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.13777",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+French_M/0/1/0/all/0/1\">Matthew G. French</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Talou_G/0/1/0/all/0/1\">Gonzalo D. Maso Talou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gamage_T/0/1/0/all/0/1\">Thiranja P. Babarenda Gamage</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nash_M/0/1/0/all/0/1\">Martyn P. Nash</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nielsen_P/0/1/0/all/0/1\">Poul M. Nielsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Doyle_A/0/1/0/all/0/1\">Anthony J. Doyle</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Iglesias_J/0/1/0/all/0/1\">Juan Eugenio Iglesias</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Balbastre_Y/0/1/0/all/0/1\">Ya&#xeb;l Balbastre</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Young_S/0/1/0/all/0/1\">Sean I. Young</a>",
          "description": "In breast surgical planning, accurate registration of MR images across\npatient positions has the potential to improve the localisation of tumours\nduring breast cancer treatment. While learning-based registration methods have\nrecently become the state-of-the-art approach for most medical image\nregistration tasks, these methods have yet to make inroads into breast image\nregistration due to certain difficulties-the lack of rich texture information\nin breast MR images and the need for the deformations to be diffeomophic. In\nthis work, we propose learning strategies for breast MR image registration that\nare amenable to diffeomorphic constraints, together with early experimental\nresults from in-silico and in-vivo experiments. One key contribution of this\nwork is a registration network which produces superior registration outcomes\nfor breast images in addition to providing diffeomorphic guarantees.",
          "link": "http://arxiv.org/abs/2309.13777",
          "publishedOn": "2023-10-07T00:42:20.105Z",
          "wordCount": null,
          "title": "Diffeomorphic Multi-Resolution Deep Learning Registration for Applications in Breast MRI. (arXiv:2309.13777v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03396",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cosma_A/0/1/0/all/0/1\">Adrian Cosma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radoi_E/0/1/0/all/0/1\">Emilian Radoi</a>",
          "description": "Gait analysis leverages unique walking patterns for person identification and\nassessment across multiple domains. Among the methods used for gait analysis,\nskeleton-based approaches have shown promise due to their robust and\ninterpretable features. However, these methods often rely on hand-crafted\nspatial-temporal graphs that are based on human anatomy disregarding the\nparticularities of the dataset and task. This paper proposes a novel method to\nsimplify the spatial-temporal graph representation for gait-based gender\nestimation, improving interpretability without losing performance. Our approach\nemploys two models, an upstream and a downstream model, that can adjust the\nadjacency matrix for each walking instance, thereby removing the fixed nature\nof the graph. By employing the Straight-Through Gumbel-Softmax trick, our model\nis trainable end-to-end. We demonstrate the effectiveness of our approach on\nthe CASIA-B dataset for gait-based gender estimation. The resulting graphs are\ninterpretable and differ qualitatively from fixed graphs used in existing\nmodels. Our research contributes to enhancing the explainability and\ntask-specific adaptability of gait recognition, promoting more efficient and\nreliable gait-based biometrics.",
          "link": "http://arxiv.org/abs/2310.03396",
          "publishedOn": "2023-10-07T00:42:20.104Z",
          "wordCount": null,
          "title": "Learning to Simplify Spatial-Temporal Graphs in Gait Analysis. (arXiv:2310.03396v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.00247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Sixing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munoz_J/0/1/0/all/0/1\">J. Pablo Mu&#xf1;oz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1\">Ali Jannesari</a>",
          "description": "Federated learning (FL) offers privacy-preserving decentralized machine\nlearning, optimizing models at edge clients without sharing private data.\nSimultaneously, foundation models (FMs) have gained traction in the artificial\nintelligence (AI) community due to their exceptional performance across various\ntasks. However, integrating FMs into FL presents challenges, primarily due to\ntheir substantial size and intensive resource requirements. This is especially\ntrue when considering the resource heterogeneity in edge FL systems. We present\nan adaptive framework for Resource-aware Federated Foundation Models (RaFFM) to\naddress these challenges. RaFFM introduces specialized model compression\nalgorithms tailored for FL scenarios, such as salient parameter prioritization\nand high-performance subnetwork extraction. These algorithms enable dynamic\nscaling of given transformer-based FMs to fit heterogeneous resource\nconstraints at the network edge during both FL's optimization and deployment\nstages. Experimental results demonstrate that RaFFM shows significant\nsuperiority in resource utilization efficiency and uses fewer resources to\ndeploy FMs to FL. Despite the lower resource consumption, target models\noptimized by RaFFM achieve performance on par with traditional FL methods\napplied to full-sized FMs. This is evident across tasks in both natural\nlanguage processing and computer vision domains.",
          "link": "http://arxiv.org/abs/2310.00247",
          "publishedOn": "2023-10-07T00:42:20.104Z",
          "wordCount": null,
          "title": "Bridging the Gap Between Foundation Models and Heterogeneous Federated Learning. (arXiv:2310.00247v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07726",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gong_S/0/1/0/all/0/1\">Shijin Gong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>",
          "description": "When artificial neural networks have demonstrated exceptional practical\nsuccess in a variety of domains, investigations into their theoretical\ncharacteristics, such as their approximation power, statistical properties, and\ngeneralization performance, have concurrently made significant strides. In this\npaper, we construct a novel theory for understanding the effectiveness of\nneural networks, which offers a perspective distinct from prior research.\nSpecifically, we explore the rationale underlying a common practice during the\nconstruction of neural network models: sample splitting. Our findings indicate\nthat the optimal hyperparameters derived from sample splitting can enable a\nneural network model that asymptotically minimizes the prediction risk. We\nconduct extensive experiments across different application scenarios and\nnetwork architectures, and the results manifest our theory's effectiveness.",
          "link": "http://arxiv.org/abs/2307.07726",
          "publishedOn": "2023-10-07T00:42:20.103Z",
          "wordCount": null,
          "title": "Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection. (arXiv:2307.07726v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.09476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Johor Jara Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cooper_S/0/1/0/all/0/1\">Seth Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1\">Matthew Guzdial</a>",
          "description": "Automated game design (AGD), the study of automatically generating game\nrules, has a long history in technical games research. AGD approaches generally\nrely on approximations of human play, either objective functions or AI agents.\nDespite this, the majority of these approximators are static, meaning they do\nnot reflect human player's ability to learn and improve in a game. In this\npaper, we investigate the application of Reinforcement Learning (RL) as an\napproximator for human play for rule generation. We recreate the classic AGD\nenvironment Mechanic Maker in Unity as a new, open-source rule generation\nframework. Our results demonstrate that RL produces distinct sets of rules from\nan A* agent baseline, which may be more usable by humans.",
          "link": "http://arxiv.org/abs/2309.09476",
          "publishedOn": "2023-10-07T00:42:20.102Z",
          "wordCount": null,
          "title": "Mechanic Maker 2.0: Reinforcement Learning for Evaluating Generated Rules. (arXiv:2309.09476v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sherborne_T/0/1/0/all/0/1\">Tom Sherborne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1\">Naomi Saphra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasigi_P/0/1/0/all/0/1\">Pradeep Dasigi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>",
          "description": "By reducing the curvature of the loss surface in the parameter space,\nSharpness-aware minimization (SAM) yields widespread robustness improvement\nunder domain transfer. Instead of focusing on parameters, however, this work\nconsiders the transferability of representations as the optimization target for\nout-of-domain generalization in a fine-tuning setup. To encourage the retention\nof transferable representations, we consider trust region-based fine-tuning\nmethods, which exploit task-specific skills without forgetting task-agnostic\nrepresentations from pre-training. We unify parameter- and representation-space\nsmoothing approaches by using trust region bounds to inform SAM-style\nregularizers on both of these optimization surfaces. We propose Trust Region\nAware Minimization (TRAM), a fine-tuning algorithm that optimizes for flat\nminima and smooth, informative representations without forgetting pre-trained\nstructure. We find that TRAM outperforms both sharpness-aware and trust\nregion-based optimization methods on cross-domain language modeling and\ncross-lingual transfer, where robustness to domain transfer and representation\ngenerality are critical for success. TRAM establishes a new standard in\ntraining generalizable models with minimal additional computation.",
          "link": "http://arxiv.org/abs/2310.03646",
          "publishedOn": "2023-10-07T00:42:20.101Z",
          "wordCount": null,
          "title": "TRAM: Bridging Trust Regions and Sharpness Aware Minimization. (arXiv:2310.03646v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azzizadenesheli_K/0/1/0/all/0/1\">Kamyar Azzizadenesheli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovachki_N/0/1/0/all/0/1\">Nikola Kovachki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Schiaffini_M/0/1/0/all/0/1\">Miguel Liu-Schiaffini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kossaifi_J/0/1/0/all/0/1\">Jean Kossaifi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "Scientific discovery and engineering design are currently limited by the time\nand cost of physical experiments, selected mostly through trial-and-error and\nintuition that require deep domain expertise. Numerical simulations present an\nalternative to physical experiments but are usually infeasible for complex\nreal-world domains due to the computational requirements of existing numerical\nmethods. Artificial intelligence (AI) presents a potential paradigm shift by\ndeveloping fast data-driven surrogate models. In particular, an AI framework,\nknown as neural operators, presents a principled framework for learning\nmappings between functions defined on continuous domains, e.g., spatiotemporal\nprocesses and partial differential equations (PDE). They can extrapolate and\npredict solutions at new locations unseen during training, i.e., perform\nzero-shot super-resolution. Neural operators can augment or even replace\nexisting simulators in many applications, such as computational fluid dynamics,\nweather forecasting, and material modeling, while being 4-5 orders of magnitude\nfaster. Further, neural operators can be integrated with physics and other\ndomain constraints enforced at finer resolutions to obtain high-fidelity\nsolutions and good generalization. Since neural operators are differentiable,\nthey can directly optimize parameters for inverse design and other inverse\nproblems. We believe that neural operators present a transformative approach to\nsimulation and design, enabling rapid research and development.",
          "link": "http://arxiv.org/abs/2309.15325",
          "publishedOn": "2023-10-07T00:42:20.101Z",
          "wordCount": null,
          "title": "Neural Operators for Accelerating Scientific Simulations and Design. (arXiv:2309.15325v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Komatsu_T/0/1/0/all/0/1\">Takayuki Komatsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohmura_Y/0/1/0/all/0/1\">Yoshiyuki Ohmura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1\">Yasuo Kuniyoshi</a>",
          "description": "Multi-object representation learning aims to represent complex real-world\nvisual input using the composition of multiple objects. Representation learning\nmethods have often used unsupervised learning to segment an input image into\nindividual objects and encode these objects into each latent vector. However,\nit is not clear how previous methods have achieved the appropriate segmentation\nof individual objects. Additionally, most of the previous methods regularize\nthe latent vectors using a Variational Autoencoder (VAE). Therefore, it is not\nclear whether VAE regularization contributes to appropriate object\nsegmentation. To elucidate the mechanism of object segmentation in multi-object\nrepresentation learning, we conducted an ablation study on MONet, which is a\ntypical method. MONet represents multiple objects using pairs that consist of\nan attention mask and the latent vector corresponding to the attention mask.\nEach latent vector is encoded from the input image and attention mask. Then,\nthe component image and attention mask are decoded from each latent vector. The\nloss function of MONet consists of 1) the sum of reconstruction losses between\nthe input image and decoded component image, 2) the VAE regularization loss of\nthe latent vector, and 3) the reconstruction loss of the attention mask to\nexplicitly encode shape information. We conducted an ablation study on these\nthree loss functions to investigate the effect on segmentation performance. Our\nresults showed that the VAE regularization loss did not affect segmentation\nperformance and the others losses did affect it. Based on this result, we\nhypothesize that it is important to maximize the attention mask of the image\nregion best represented by a single latent vector corresponding to the\nattention mask. We confirmed this hypothesis by evaluating a new loss function\nwith the same mechanism as the hypothesis.",
          "link": "http://arxiv.org/abs/2310.03273",
          "publishedOn": "2023-10-07T00:42:20.100Z",
          "wordCount": null,
          "title": "Ablation Study to Clarify the Mechanism of Object Segmentation in Multi-Object Representation Learning. (arXiv:2310.03273v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1\">Chen Dun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_M/0/1/0/all/0/1\">Mirian Hipolito Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1\">Robert Sim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitriadis_D/0/1/0/all/0/1\">Dimitrios Dimitriadis</a>",
          "description": "One of the goals in Federated Learning (FL) is to create personalized models\nthat can adapt to the context of each participating client, while utilizing\nknowledge from a shared global model. Yet, often, personalization requires a\nfine-tuning step using clients' labeled data in order to achieve good\nperformance. This may not be feasible in scenarios where incoming clients are\nfresh and/or have privacy concerns. It, then, remains open how one can achieve\njust-in-time personalization in these scenarios. We propose FedJETs, a novel\nsolution by using a Mixture-of-Experts (MoE) framework within a FL setup. Our\nmethod leverages the diversity of the clients to train specialized experts on\ndifferent subsets of classes, and a gating function to route the input to the\nmost relevant expert(s). Our gating function harnesses the knowledge of a\npretrained model common expert to enhance its routing decisions on-the-fly. As\na highlight, our approach can improve accuracy up to 18\\% in state of the art\nFL settings, while maintaining competitive zero-shot performance. In practice,\nour method can handle non-homogeneous data distributions, scale more\nefficiently, and improve the state-of-the-art performance on common FL\nbenchmarks.",
          "link": "http://arxiv.org/abs/2306.08586",
          "publishedOn": "2023-10-07T00:42:20.100Z",
          "wordCount": null,
          "title": "FedJETs: Efficient Just-In-Time Personalization with Federated Mixture of Experts. (arXiv:2306.08586v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zichen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_B/0/1/0/all/0/1\">Balasubramaniam Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ioannidis_V/0/1/0/all/0/1\">Vassilis N. Ioannidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangwala_H/0/1/0/all/0/1\">Huzefa Rangwala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anubhai_R/0/1/0/all/0/1\">Rishita Anubhai</a>",
          "description": "Foundation models (FMs) are able to leverage large volumes of unlabeled data\nto demonstrate superior performance across a wide range of tasks. However, FMs\ndeveloped for biomedical domains have largely remained unimodal, i.e.,\nindependently trained and used for tasks on protein sequences alone, small\nmolecule structures alone, or clinical data alone. To overcome this limitation\nof biomedical FMs, we present BioBridge, a novel parameter-efficient learning\nframework, to bridge independently trained unimodal FMs to establish multimodal\nbehavior. BioBridge achieves it by utilizing Knowledge Graphs (KG) to learn\ntransformations between one unimodal FM and another without fine-tuning any\nunderlying unimodal FMs. Our empirical results demonstrate that BioBridge can\nbeat the best baseline KG embedding methods (on average by around 76.3%) in\ncross-modal retrieval tasks. We also identify BioBridge demonstrates\nout-of-domain generalization ability by extrapolating to unseen modalities or\nrelations. Additionally, we also show that BioBridge presents itself as a\ngeneral purpose retriever that can aid biomedical multimodal question answering\nas well as enhance the guided generation of novel drugs.",
          "link": "http://arxiv.org/abs/2310.03320",
          "publishedOn": "2023-10-07T00:42:20.099Z",
          "wordCount": null,
          "title": "BioBridge: Bridging Biomedical Foundation Models via Knowledge Graph. (arXiv:2310.03320v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horvath_A/0/1/0/all/0/1\">Andras Horvath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jozsa_C/0/1/0/all/0/1\">Csaba M. Jozsa</a>",
          "description": "Neural Radiance Fields (NeRFs) have recently emerged as a powerful tool for\n3D scene representation and rendering. These data-driven models can learn to\nsynthesize high-quality images from sparse 2D observations, enabling realistic\nand interactive scene reconstructions. However, the growing usage of NeRFs in\ncritical applications such as augmented reality, robotics, and virtual\nenvironments could be threatened by adversarial attacks.\n\nIn this paper we present how generalizable NeRFs can be attacked by both\nlow-intensity adversarial attacks and adversarial patches, where the later\ncould be robust enough to be used in real world applications. We also\ndemonstrate targeted attacks, where a specific, predefined output scene is\ngenerated by these attack with success.",
          "link": "http://arxiv.org/abs/2310.03578",
          "publishedOn": "2023-10-07T00:42:20.097Z",
          "wordCount": null,
          "title": "Targeted Adversarial Attacks on Generalizable Neural Radiance Fields. (arXiv:2310.03578v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.03519",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_P/0/1/0/all/0/1\">Peizhou Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_C/0/1/0/all/0/1\">Chaoyi Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoliang Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xiaojuan Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dong_L/0/1/0/all/0/1\">Liang Dong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ying_L/0/1/0/all/0/1\">Leslie Ying</a>",
          "description": "Deep learning methods have been successfully used in various computer vision\ntasks. Inspired by that success, deep learning has been explored in magnetic\nresonance imaging (MRI) reconstruction. In particular, integrating deep\nlearning and model-based optimization methods has shown considerable\nadvantages. However, a large amount of labeled training data is typically\nneeded for high reconstruction quality, which is challenging for some MRI\napplications. In this paper, we propose a novel reconstruction method, named\nDURED-Net, that enables interpretable self-supervised learning for MR image\nreconstruction by combining a self-supervised denoising network and a\nplug-and-play method. We aim to boost the reconstruction performance of\nNoise2Noise in MR reconstruction by adding an explicit prior that utilizes\nimaging physics. Specifically, the leverage of a denoising network for MRI\nreconstruction is achieved using Regularization by Denoising (RED). Experiment\nresults demonstrate that the proposed method requires a reduced amount of\ntraining data to achieve high reconstruction quality among the state-of-art of\nMR reconstruction utilizing the Noise2Noise method.",
          "link": "http://arxiv.org/abs/2205.03519",
          "publishedOn": "2023-10-07T00:42:20.096Z",
          "wordCount": null,
          "title": "Self-supervised Deep Unrolled Reconstruction Using Regularization by Denoising. (arXiv:2205.03519v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jung_W/0/1/0/all/0/1\">Wonsik Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_E/0/1/0/all/0/1\">Eunjin Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_E/0/1/0/all/0/1\">Eunsong Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suk_H/0/1/0/all/0/1\">Heung-Il Suk</a>",
          "description": "Deep learning models based on resting-state functional magnetic resonance\nimaging (rs-fMRI) have been widely used to diagnose brain diseases,\nparticularly autism spectrum disorder (ASD). Existing studies have leveraged\nthe functional connectivity (FC) of rs-fMRI, achieving notable classification\nperformance. However, they have significant limitations, including the lack of\nadequate information while using linear low-order FC as inputs to the model,\nnot considering individual characteristics (i.e., different symptoms or varying\nstages of severity) among patients with ASD, and the non-explainability of the\ndecision process. To cover these limitations, we propose a novel\nexplainability-guided region of interest (ROI) selection (EAG-RS) framework\nthat identifies non-linear high-order functional associations among brain\nregions by leveraging an explainable artificial intelligence technique and\nselects class-discriminative regions for brain disease identification. The\nproposed framework includes three steps: (i) inter-regional relation learning\nto estimate non-linear relations through random seed-based network masking,\n(ii) explainable connection-wise relevance score estimation to explore\nhigh-order relations between functional connections, and (iii) non-linear\nhigh-order FC-based diagnosis-informative ROI selection and classifier learning\nto identify ASD. We validated the effectiveness of our proposed method by\nconducting experiments using the Autism Brain Imaging Database Exchange (ABIDE)\ndataset, demonstrating that the proposed method outperforms other comparative\nmethods in terms of various evaluation metrics. Furthermore, we qualitatively\nanalyzed the selected ROIs and identified ASD subtypes linked to previous\nneuroscientific studies.",
          "link": "http://arxiv.org/abs/2310.03404",
          "publishedOn": "2023-10-07T00:42:20.092Z",
          "wordCount": null,
          "title": "EAG-RS: A Novel Explainability-guided ROI-Selection Framework for ASD Diagnosis via Inter-regional Relation Learning. (arXiv:2310.03404v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.00079",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cattaneo_M/0/1/0/all/0/1\">Matias D. Cattaneo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klusowski_J/0/1/0/all/0/1\">Jason M. Klusowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shigida_B/0/1/0/all/0/1\">Boris Shigida</a>",
          "description": "In previous literature, backward error analysis was used to find ordinary\ndifferential equations (ODEs) approximating the gradient descent trajectory. It\nwas found that finite step sizes implicitly regularize solutions because terms\nappearing in the ODEs penalize the two-norm of the loss gradients. We prove\nthat the existence of similar implicit regularization in RMSProp and Adam\ndepends on their hyperparameters and the training stage, but with a different\n\"norm\" involved: the corresponding ODE terms either penalize the (perturbed)\none-norm of the loss gradients or, on the contrary, hinder its decrease (the\nlatter case being typical). We also conduct numerical experiments and discuss\nhow the proven facts can influence generalization.",
          "link": "http://arxiv.org/abs/2309.00079",
          "publishedOn": "2023-10-07T00:42:20.092Z",
          "wordCount": null,
          "title": "On the Implicit Bias of Adam. (arXiv:2309.00079v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16738",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yue_Y/0/1/0/all/0/1\">Yubiao Yue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_J/0/1/0/all/0/1\">Jun Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_H/0/1/0/all/0/1\">Haihua Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luo_B/0/1/0/all/0/1\">Bingchun Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1\">Zhenzhang Li</a>",
          "description": "Booming deep learning has substantially improved the diagnosis for diverse\nlesions in ultrasound images, but a conspicuous research gap concerning\ncervical lymph node lesions still remains. The objective of this work is to\ndiagnose cervical lymph node lesions in ultrasound images by leveraging a deep\nlearning model. To this end, we first collected 3392 cervical ultrasound images\ncontaining normal lymph nodes, benign lymph node lesions, malignant primary\nlymph node lesions, and malignant metastatic lymph node lesions. Given that\nultrasound images are generated by the reflection and scattering of sound waves\nacross varied bodily tissues, we proposed the Conv-FFT Block. It integrates\nconvolutional operations with the fast Fourier transform to more astutely model\nthe images. Building upon this foundation, we designed a novel architecture,\nnamed SFUSNet. SFUSNet not only discerns variances in ultrasound images from\nthe spatial domain but also adeptly captures micro-structural alterations\nacross various lesions in the frequency domain. To ascertain the potential of\nSFUSNet, we benchmarked it against 12 popular architectures through five-fold\ncross-validation. The results show that SFUSNet is the state-of-the-art model\nand can achieve 92.89% accuracy. Moreover, its average precision, average\nsensitivity and average specificity for four types of lesions achieve 90.46%,\n89.95% and 97.49%, respectively.",
          "link": "http://arxiv.org/abs/2308.16738",
          "publishedOn": "2023-10-07T00:42:20.091Z",
          "wordCount": null,
          "title": "SFUSNet: A Spatial-Frequency domain-based Multi-branch Network for diagnosis of Cervical Lymph Node Lesions in Ultrasound Images. (arXiv:2308.16738v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Crispino_N/0/1/0/all/0/1\">Nicholas Crispino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montgomery_K/0/1/0/all/0/1\">Kyle Montgomery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_F/0/1/0/all/0/1\">Fankun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenguang Wang</a>",
          "description": "We introduce a method to improve the zero-shot reasoning abilities of large\nlanguage models on general language understanding tasks. Specifically, we build\nan autonomous agent to instruct the reasoning process of large language models.\nWe show this approach further unleashes the zero-shot reasoning abilities of\nlarge language models to more tasks. We study the performance of our method on\na wide set of datasets spanning generation, classification, and reasoning. We\nshow that our method generalizes to most tasks and obtains state-of-the-art\nzero-shot performance on 20 of the 29 datasets that we evaluate. For instance,\nour method boosts the performance of state-of-the-art large language models by\na large margin, including Vicuna-13b (13.3%), Llama-2-70b-chat (23.2%), and\nGPT-3.5 Turbo (17.0%). Compared to zero-shot chain of thought, our improvement\nin reasoning is striking, with an average increase of 10.5%. With our method,\nLlama-2-70b-chat outperforms zero-shot GPT-3.5 Turbo by 10.2%.",
          "link": "http://arxiv.org/abs/2310.03710",
          "publishedOn": "2023-10-07T00:42:20.085Z",
          "wordCount": null,
          "title": "Agent Instructs Large Language Models to be General Zero-Shot Reasoners. (arXiv:2310.03710v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.17167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>",
          "description": "Large language models (LLMs) have achieved remarkable performance in various\nevaluation benchmarks. However, concerns about their performance are raised on\npotential data contamination in their considerable volume of training corpus.\nMoreover, the static nature and fixed complexity of current benchmarks may\ninadequately gauge the advancing capabilities of LLMs. In this paper, we\nintroduce DyVal, a novel, general, and flexible evaluation protocol for dynamic\nevaluation of LLMs. Based on our proposed dynamic evaluation framework, we\nbuild graph-informed DyVal by leveraging the structural advantage of directed\nacyclic graphs to dynamically generate evaluation samples with controllable\ncomplexities. DyVal generates challenging evaluation sets on reasoning tasks\nincluding mathematics, logical reasoning, and algorithm problems. We evaluate\nvarious LLMs ranging from Flan-T5-large to ChatGPT and GPT4. Experiments\ndemonstrate that LLMs perform worse in DyVal-generated evaluation samples with\ndifferent complexities, emphasizing the significance of dynamic evaluation. We\nalso analyze the failure cases and results of different prompting methods.\nMoreover, DyVal-generated samples are not only evaluation sets, but also\nhelpful data for fine-tuning to improve the performance of LLMs on existing\nbenchmarks. We hope that DyVal can shed light on the future evaluation research\nof LLMs.",
          "link": "http://arxiv.org/abs/2309.17167",
          "publishedOn": "2023-10-07T00:42:20.084Z",
          "wordCount": null,
          "title": "DyVal: Graph-informed Dynamic Evaluation of Large Language Models. (arXiv:2309.17167v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Favaro_S/0/1/0/all/0/1\">Stefano Favaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanin_B/0/1/0/all/0/1\">Boris Hanin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marinucci_D/0/1/0/all/0/1\">Domenico Marinucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourdin_I/0/1/0/all/0/1\">Ivan Nourdin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peccati_G/0/1/0/all/0/1\">Giovanni Peccati</a>",
          "description": "We study the distribution of a fully connected neural network with random\nGaussian weights and biases in which the hidden layer widths are proportional\nto a large constant $n$. Under mild assumptions on the non-linearity, we obtain\nquantitative bounds on normal approximations valid at large but finite $n$ and\nany fixed network depth. Our theorems show both for the finite-dimensional\ndistributions and the entire process, that the distance between a random fully\nconnected network (and its derivatives) to the corresponding infinite width\nGaussian process scales like $n^{-\\gamma}$ for $\\gamma>0$, with the exponent\ndepending on the metric used to measure discrepancy. Our bounds are strictly\nstronger in terms of their dependence on network width than any previously\navailable in the literature; in the one-dimensional case, we also prove that\nthey are optimal, i.e., we establish matching lower bounds.",
          "link": "http://arxiv.org/abs/2307.06092",
          "publishedOn": "2023-10-07T00:42:20.082Z",
          "wordCount": null,
          "title": "Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lanzendorfer_L/0/1/0/all/0/1\">Luca A. Lanzend&#xf6;rfer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grotschla_F/0/1/0/all/0/1\">Florian Gr&#xf6;tschla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funke_E/0/1/0/all/0/1\">Emil Funke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1\">Roger Wattenhofer</a>",
          "description": "Music datasets play a crucial role in advancing research in machine learning\nfor music. However, existing music datasets suffer from limited size,\naccessibility, and lack of audio resources. To address these shortcomings, we\npresent DISCO-10M, a novel and extensive music dataset that surpasses the\nlargest previously available music dataset by an order of magnitude. To ensure\nhigh-quality data, we implement a multi-stage filtering process. This process\nincorporates similarities based on textual descriptions and audio embeddings.\nMoreover, we provide precomputed CLAP embeddings alongside DISCO-10M,\nfacilitating direct application on various downstream tasks. These embeddings\nenable efficient exploration of machine learning applications on the provided\ndata. With DISCO-10M, we aim to democratize and facilitate new research to help\nadvance the development of novel machine learning models for music.",
          "link": "http://arxiv.org/abs/2306.13512",
          "publishedOn": "2023-10-07T00:42:20.081Z",
          "wordCount": null,
          "title": "DISCO-10M: A Large-Scale Music Dataset. (arXiv:2306.13512v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.00436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miao_N/0/1/0/all/0/1\">Ning Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>",
          "description": "The recent progress in large language models (LLMs), especially the invention\nof chain-of-thought prompting, has made it possible to automatically answer\nquestions by stepwise reasoning. However, when faced with more complicated\nproblems that require non-linear thinking, even the strongest LLMs make\nmistakes. To address this, we explore whether LLMs are able to recognize errors\nin their own step-by-step reasoning, without resorting to external resources.\nTo this end, we propose SelfCheck, a general-purpose zero-shot verification\nschema for recognizing such errors. We then use the results of these checks to\nimprove question-answering performance by conducting weighted voting on\nmultiple solutions to the question. We test SelfCheck on three datasets (GSM8K,\nMathQA, and MATH) and find that it successfully recognizes errors and, in turn,\nincreases final answer accuracies.",
          "link": "http://arxiv.org/abs/2308.00436",
          "publishedOn": "2023-10-07T00:42:20.079Z",
          "wordCount": null,
          "title": "SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning. (arXiv:2308.00436v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xidong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jianhui Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhengmian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aidong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heng Huang</a>",
          "description": "The minimax problems arise throughout machine learning applications, ranging\nfrom adversarial training and policy evaluation in reinforcement learning to\nAUROC maximization. To address the large-scale data challenges across multiple\nclients with communication-efficient distributed training, federated learning\n(FL) is gaining popularity. Many optimization algorithms for minimax problems\nhave been developed in the centralized setting (\\emph{i.e.} single-machine).\nNonetheless, the algorithm for minimax problems under FL is still\nunderexplored. In this paper, we study a class of federated nonconvex minimax\noptimization problems. We propose FL algorithms (FedSGDA+ and FedSGDA-M) and\nreduce existing complexity results for the most common minimax problems. For\nnonconvex-concave problems, we propose FedSGDA+ and reduce the communication\ncomplexity to $O(\\varepsilon^{-6})$. Under nonconvex-strongly-concave and\nnonconvex-PL minimax settings, we prove that FedSGDA-M has the best-known\nsample complexity of $O(\\kappa^{3} N^{-1}\\varepsilon^{-3})$ and the best-known\ncommunication complexity of $O(\\kappa^{2}\\varepsilon^{-2})$. FedSGDA-M is the\nfirst algorithm to match the best sample complexity $O(\\varepsilon^{-3})$\nachieved by the single-machine method under the nonconvex-strongly-concave\nsetting. Extensive experimental results on fair classification and AUROC\nmaximization show the efficiency of our algorithms.",
          "link": "http://arxiv.org/abs/2310.03613",
          "publishedOn": "2023-10-07T00:42:20.078Z",
          "wordCount": null,
          "title": "Solving a Class of Non-Convex Minimax Optimization in Federated Learning. (arXiv:2310.03613v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Albergo_M/0/1/0/all/0/1\">Michael S. Albergo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boffi_N/0/1/0/all/0/1\">Nicholas M. Boffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindsey_M/0/1/0/all/0/1\">Michael Lindsey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>",
          "description": "Given a set of $K$ probability densities, we consider the multimarginal\ngenerative modeling problem of learning a joint distribution that recovers\nthese densities as marginals. The structure of this joint distribution should\nidentify multi-way correspondences among the prescribed marginals. We formalize\nan approach to this task within a generalization of the stochastic interpolant\nframework, leading to efficient learning algorithms built upon dynamical\ntransport of measure. Our generative models are defined by velocity and score\nfields that can be characterized as the minimizers of simple quadratic\nobjectives, and they are defined on a simplex that generalizes the time\nvariable in the usual dynamical transport framework. The resulting transport on\nthe simplex is influenced by all marginals, and we show that multi-way\ncorrespondences can be extracted. The identification of such correspondences\nhas applications to style transfer, algorithmic fairness, and data\ndecorruption. In addition, the multimarginal perspective enables an efficient\nalgorithm for reducing the dynamical transport cost in the ordinary\ntwo-marginal setting. We demonstrate these capacities with several numerical\nexamples.",
          "link": "http://arxiv.org/abs/2310.03695",
          "publishedOn": "2023-10-07T00:42:20.077Z",
          "wordCount": null,
          "title": "Multimarginal generative modeling with stochastic interpolants. (arXiv:2310.03695v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Monteiro_R/0/1/0/all/0/1\">Rafael Monteiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sau_K/0/1/0/all/0/1\">Kartik Sau</a>",
          "description": "In this paper, we introduce a new heuristics for global optimization in\nscenarios where extensive evaluations of the cost function are expensive,\ninaccessible, or even prohibitive. The method, which we call\nLandscape-Sketch-and-Step (LSS), combines Machine Learning, Stochastic\nOptimization, and Reinforcement Learning techniques, relying on historical\ninformation from previously sampled points to make judicious choices of\nparameter values where the cost function should be evaluated at. Unlike\noptimization by Replica Exchange Monte Carlo methods, the number of evaluations\nof the cost function required in this approach is comparable to that used by\nSimulated Annealing, quality that is especially important in contexts like\nhigh-throughput computing or high-performance computing tasks, where\nevaluations are either computationally expensive or take a long time to be\nperformed. The method also differs from standard Surrogate Optimization\ntechniques, for it does not construct a surrogate model that aims at\napproximating or reconstructing the objective function. We illustrate our\nmethod by applying it to low dimensional optimization problems (dimensions 1,\n2, 4, and 8) that mimick known difficulties of minimization on rugged energy\nlandscapes often seen in Condensed Matter Physics, where cost functions are\nrugged and plagued with local minima. When compared to classical Simulated\nAnnealing, the LSS shows an effective acceleration of the optimization process.",
          "link": "http://arxiv.org/abs/2309.07936",
          "publishedOn": "2023-10-07T00:42:20.075Z",
          "wordCount": null,
          "title": "Landscape-Sketch-Step: An AI/ML-Based Metaheuristic for Surrogate Optimization Problems. (arXiv:2309.07936v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.09350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nentidis_A/0/1/0/all/0/1\">Anastasios Nentidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatzopoulos_T/0/1/0/all/0/1\">Thomas Chatzopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krithara_A/0/1/0/all/0/1\">Anastasia Krithara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1\">Grigorios Tsoumakas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paliouras_G/0/1/0/all/0/1\">Georgios Paliouras</a>",
          "description": "Objective: Semantic indexing of biomedical literature is usually done at the\nlevel of MeSH descriptors with several related but distinct biomedical concepts\noften grouped together and treated as a single topic. This study proposes a new\nmethod for the automated refinement of subject annotations at the level of MeSH\nconcepts. Methods: Lacking labelled data, we rely on weak supervision based on\nconcept occurrence in the abstract of an article, which is also enhanced by\ndictionary-based heuristics. In addition, we investigate deep learning\napproaches, making design choices to tackle the particular challenges of this\ntask. The new method is evaluated on a large-scale retrospective scenario,\nbased on concepts that have been promoted to descriptors. Results: In our\nexperiments concept occurrence was the strongest heuristic achieving a macro-F1\nscore of about 0.63 across several labels. The proposed method improved it\nfurther by more than 4pp. Conclusion: The results suggest that concept\noccurrence is a strong heuristic for refining the coarse-grained labels at the\nlevel of MeSH concepts and the proposed method improves it further.",
          "link": "http://arxiv.org/abs/2301.09350",
          "publishedOn": "2023-10-07T00:42:20.071Z",
          "wordCount": null,
          "title": "Large-scale investigation of weakly-supervised deep learning for the fine-grained semantic indexing of biomedical literature. (arXiv:2301.09350v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07056",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Jaouni_T/0/1/0/all/0/1\">Tareq Jaouni</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Arlt_S/0/1/0/all/0/1\">S&#xf6;ren Arlt</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ruiz_Gonzalez_C/0/1/0/all/0/1\">Carlos Ruiz-Gonzalez</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Karimi_E/0/1/0/all/0/1\">Ebrahim Karimi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gu_X/0/1/0/all/0/1\">Xuemei Gu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Krenn_M/0/1/0/all/0/1\">Mario Krenn</a>",
          "description": "Despite their promise to facilitate new scientific discoveries, the\nopaqueness of neural networks presents a challenge in interpreting the logic\nbehind their findings. Here, we use a eXplainable-AI (XAI) technique called\n$inception$ or $deep$ $dreaming$, which has been invented in machine learning\nfor computer vision. We use this technique to explore what neural networks\nlearn about quantum optics experiments. Our story begins by training deep\nneural networks on the properties of quantum systems. Once trained, we \"invert\"\nthe neural network -- effectively asking how it imagines a quantum system with\na specific property, and how it would continuously modify the quantum system to\nchange a property. We find that the network can shift the initial distribution\nof properties of the quantum system, and we can conceptualize the learned\nstrategies of the neural network. Interestingly, we find that, in the first\nlayers, the neural network identifies simple properties, while in the deeper\nones, it can identify complex quantum structures and even quantum entanglement.\nThis is in reminiscence of long-understood properties known in computer vision,\nwhich we now identify in a complex natural science task. Our approach could be\nuseful in a more interpretable way to develop new advanced AI-based scientific\ndiscovery techniques in quantum physics.",
          "link": "http://arxiv.org/abs/2309.07056",
          "publishedOn": "2023-10-07T00:42:20.070Z",
          "wordCount": null,
          "title": "Deep Quantum Graph Dreaming: Deciphering Neural Network Insights into Quantum Experiments. (arXiv:2309.07056v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.01807",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Katdare_P/0/1/0/all/0/1\">Pulkit Katdare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1\">Katherine Driggs-Campbell</a>",
          "description": "Reinforcement Learning (RL) methods are typically sample-inefficient, making\nit challenging to train and deploy RL-policies in real world robots. Even a\nrobust policy trained in simulation requires a real-world deployment to assess\ntheir performance. This paper proposes a new approach to evaluate the\nreal-world performance of agent policies prior to deploying them in the real\nworld. Our approach incorporates a simulator along with real-world offline data\nto evaluate the performance of any policy using the framework of Marginalized\nImportance Sampling (MIS). Existing MIS methods face two challenges: (1) large\ndensity ratios that deviate from a reasonable range and (2) indirect\nsupervision, where the ratio needs to be inferred indirectly, thus exacerbating\nestimation error. Our approach addresses these challenges by introducing the\ntarget policy's occupancy in the simulator as an intermediate variable and\nlearning the density ratio as the product of two terms that can be learned\nseparately. The first term is learned with direct supervision and the second\nterm has a small magnitude, thus making it computationally efficient. We\nanalyze the sample complexity as well as error propagation of our two\nstep-procedure. Furthermore, we empirically evaluate our approach on Sim2Sim\nenvironments such as Cartpole, Reacher, and Half-Cheetah. Our results show that\nour method generalizes well across a variety of Sim2Sim gap, target policies\nand offline data collection policies. We also demonstrate the performance of\nour algorithm on a Sim2Real task of validating the performance of a 7 DoF\nrobotic arm using offline data along with the Gazebo simulator.",
          "link": "http://arxiv.org/abs/2309.01807",
          "publishedOn": "2023-10-07T00:42:20.069Z",
          "wordCount": null,
          "title": "Marginalized Importance Sampling for Off-Environment Policy Evaluation. (arXiv:2309.01807v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pengyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caprio_M/0/1/0/all/0/1\">Michele Caprio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1\">Eric Eaton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>",
          "description": "Like generic multi-task learning, continual learning has the nature of\nmulti-objective optimization, and therefore faces a trade-off between the\nperformance of different tasks. That is, to optimize for the current task\ndistribution, it may need to compromise performance on some previous tasks.\nThis means that there exist multiple models that are Pareto-optimal at\ndifferent times, each addressing a distinct task performance trade-off.\nResearchers have discussed how to train particular models to address specific\ntrade-off preferences. However, existing algorithms require training overheads\nproportional to the number of preferences -- a large burden when there are\nmultiple, possibly infinitely many, preferences. As a response, we propose\nImprecise Bayesian Continual Learning (IBCL). Upon a new task, IBCL (1) updates\na knowledge base in the form of a convex hull of model parameter distributions\nand (2) obtains particular models to address task trade-off preferences with\nzero-shot. That is, IBCL does not require any additional training overhead to\ngenerate preference-addressing models from its knowledge base. We show that\nmodels obtained by IBCL have guarantees in identifying the Pareto optimal\nparameters. Moreover, experiments on standard image classification and NLP\ntasks support this guarantee. Statistically, IBCL improves average per-task\naccuracy by at most 23\\% and peak per-task accuracy by at most 15\\% with\nrespect to the baseline methods, with steadily near-zero or positive backward\ntransfer. Most importantly, IBCL significantly reduces the training overhead\nfrom training 1 model per preference to at most 3 models for all preferences.",
          "link": "http://arxiv.org/abs/2310.02995",
          "publishedOn": "2023-10-07T00:42:20.069Z",
          "wordCount": null,
          "title": "IBCL: Zero-shot Model Generation for Task Trade-offs in Continual Learning. (arXiv:2310.02995v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1\">L&#xe9;on Bottou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "Many believe that Large Language Models (LLMs) open the era of Artificial\nIntelligence (AI). Some see opportunities while others see dangers. Yet both\nproponents and opponents grasp AI through the imagery popularised by science\nfiction. Will the machine become sentient and rebel against its creators? Will\nwe experience a paperclip apocalypse? Before answering such questions, we\nshould first ask whether this mental imagery provides a good description of the\nphenomenon at hand. Understanding weather patterns through the moods of the\ngods only goes so far. The present paper instead advocates understanding LLMs\nand their connection to AI through the imagery of Jorge Luis Borges, a master\nof 20th century literature, forerunner of magical realism, and precursor to\npostmodern literature. This exercise leads to a new perspective that\nilluminates the relation between language modelling and artificial\nintelligence.",
          "link": "http://arxiv.org/abs/2310.01425",
          "publishedOn": "2023-10-07T00:42:20.067Z",
          "wordCount": null,
          "title": "Borges and AI. (arXiv:2310.01425v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tinghao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiangyu Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Ping He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yiming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiachen T. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>",
          "description": "We present a novel defense, against backdoor attacks on Deep Neural Networks\n(DNNs), wherein adversaries covertly implant malicious behaviors (backdoors)\ninto DNNs. Our defense falls within the category of post-development defenses\nthat operate independently of how the model was generated. The proposed defense\nis built upon a novel reverse engineering approach that can directly extract\nbackdoor functionality of a given backdoored model to a backdoor expert model.\nThe approach is straightforward -- finetuning the backdoored model over a small\nset of intentionally mislabeled clean samples, such that it unlearns the normal\nfunctionality while still preserving the backdoor functionality, and thus\nresulting in a model (dubbed a backdoor expert model) that can only recognize\nbackdoor inputs. Based on the extracted backdoor expert model, we show the\nfeasibility of devising highly accurate backdoor input detectors that filter\nout the backdoor inputs during model inference. Further augmented by an\nensemble strategy with a finetuned auxiliary model, our defense, BaDExpert\n(Backdoor Input Detection with Backdoor Expert), effectively mitigates 17 SOTA\nbackdoor attacks while minimally impacting clean utility. The effectiveness of\nBaDExpert has been verified on multiple datasets (CIFAR10, GTSRB and ImageNet)\nacross various model architectures (ResNet, VGG, MobileNetV2 and Vision\nTransformer).",
          "link": "http://arxiv.org/abs/2308.12439",
          "publishedOn": "2023-10-07T00:42:20.063Z",
          "wordCount": null,
          "title": "BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection. (arXiv:2308.12439v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.00143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bassan_S/0/1/0/all/0/1\">Shahaf Bassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amir_G/0/1/0/all/0/1\">Guy Amir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corsi_D/0/1/0/all/0/1\">Davide Corsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Refaeli_I/0/1/0/all/0/1\">Idan Refaeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1\">Guy Katz</a>",
          "description": "Deep neural networks (DNNs) are increasingly being used as controllers in\nreactive systems. However, DNNs are highly opaque, which renders it difficult\nto explain and justify their actions. To mitigate this issue, there has been a\nsurge of interest in explainable AI (XAI) techniques, capable of pinpointing\nthe input features that caused the DNN to act as it did. Existing XAI\ntechniques typically face two limitations: (i) they are heuristic, and do not\nprovide formal guarantees that the explanations are correct; and (ii) they\noften apply to ``one-shot'' systems, where the DNN is invoked independently of\npast invocations, as opposed to reactive systems. Here, we begin bridging this\ngap, and propose a formal DNN-verification-based XAI technique for reasoning\nabout multi-step, reactive systems. We suggest methods for efficiently\ncalculating succinct explanations, by exploiting the system's transition\nconstraints in order to curtail the search space explored by the underlying\nverifier. We evaluate our approach on two popular benchmarks from the domain of\nautomated navigation; and observe that our methods allow the efficient\ncomputation of minimal and minimum explanations, significantly outperforming\nthe state of the art. We also demonstrate that our methods produce formal\nexplanations that are more reliable than competing, non-verification-based XAI\ntechniques.",
          "link": "http://arxiv.org/abs/2308.00143",
          "publishedOn": "2023-10-07T00:42:19.707Z",
          "wordCount": null,
          "title": "Formally Explaining Neural Networks within Reactive Systems. (arXiv:2308.00143v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chendi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manolache_A/0/1/0/all/0/1\">Andrei Manolache</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_K/0/1/0/all/0/1\">Kareem Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zhe Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1\">Guy Van den Broeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niepert_M/0/1/0/all/0/1\">Mathias Niepert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_C/0/1/0/all/0/1\">Christopher Morris</a>",
          "description": "Message-passing graph neural networks (MPNNs) emerged as powerful tools for\nprocessing graph-structured input. However, they operate on a fixed input graph\nstructure, ignoring potential noise and missing information. Furthermore, their\nlocal aggregation mechanism can lead to problems such as over-squashing and\nlimited expressive power in capturing relevant graph structures. Existing\nsolutions to these challenges have primarily relied on heuristic methods, often\ndisregarding the underlying data distribution. Hence, devising principled\napproaches for learning to infer graph structures relevant to the given\nprediction task remains an open challenge. In this work, leveraging recent\nprogress in exact and differentiable $k$-subset sampling, we devise\nprobabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges\nwhile omitting less beneficial ones. For the first time, our theoretical\nanalysis explores how PR-MPNNs enhance expressive power, and we identify\nprecise conditions under which they outperform purely randomized approaches.\nEmpirically, we demonstrate that our approach effectively mitigates issues like\nover-squashing and under-reaching. In addition, on established real-world\ndatasets, our method exhibits competitive or superior predictive performance\ncompared to traditional MPNN models and recent graph transformer architectures.",
          "link": "http://arxiv.org/abs/2310.02156",
          "publishedOn": "2023-10-07T00:42:19.707Z",
          "wordCount": null,
          "title": "Probabilistically Rewired Message-Passing Neural Networks. (arXiv:2310.02156v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.03116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shikun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1\">Xiaobo Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jiankang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shiming Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>",
          "description": "Learning from crowds describes that the annotations of training data are\nobtained with crowd-sourcing services. Multiple annotators each complete their\nown small part of the annotations, where labeling mistakes that depend on\nannotators occur frequently. Modeling the label-noise generation process by the\nnoise transition matrix is a power tool to tackle the label noise. In\nreal-world crowd-sourcing scenarios, noise transition matrices are both\nannotator- and instance-dependent. However, due to the high complexity of\nannotator- and instance-dependent transition matrices (AIDTM), annotation\nsparsity, which means each annotator only labels a little part of instances,\nmakes modeling AIDTM very challenging. Prior works simplify the problem by\nassuming the transition matrix is instance-independent or using simple\nparametric ways, which lose modeling generality. Motivated by this, we target a\nmore realistic problem, estimating general AIDTM in practice. Without losing\nmodeling generality, we parameterize AIDTM with deep neural networks. To\nalleviate the modeling challenge, we suppose every annotator shares its noise\npattern with similar annotators, and estimate AIDTM via knowledge transfer. We\nhence first model the mixture of noise patterns by all annotators, and then\ntransfer this modeling to individual annotators. Furthermore, considering that\nthe transfer from the mixture of noise patterns to individuals may cause two\nannotators with highly different noise generations to perturb each other, we\nemploy the knowledge transfer between identified neighboring annotators to\ncalibrate the modeling. Theoretical analyses are derived to demonstrate that\nboth the knowledge transfer from global to individuals and the knowledge\ntransfer between neighboring individuals can help model general AIDTM.\nExperiments confirm the superiority of the proposed approach on synthetic and\nreal-world crowd-sourcing data.",
          "link": "http://arxiv.org/abs/2306.03116",
          "publishedOn": "2023-10-07T00:42:19.694Z",
          "wordCount": null,
          "title": "Transferring Annotator- and Instance-dependent Transition Matrix for Learning from Crowds. (arXiv:2306.03116v2 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abusnaina_A/0/1/0/all/0/1\">Ahmed Abusnaina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Sunpreet Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Ke Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christodorescu_M/0/1/0/all/0/1\">Mihai Christodorescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohaisen_D/0/1/0/all/0/1\">David Mohaisen</a>",
          "description": "Toward robust malware detection, we explore the attack surface of existing\nmalware detection systems. We conduct root-cause analyses of the practical\nbinary-level black-box adversarial malware examples. Additionally, we uncover\nthe sensitivity of volatile features within the detection engines and exhibit\ntheir exploitability. Highlighting volatile information channels within the\nsoftware, we introduce three software pre-processing steps to eliminate the\nattack surface, namely, padding removal, software stripping, and inter-section\ninformation resetting. Further, to counter the emerging section injection\nattacks, we propose a graph-based section-dependent information extraction\nscheme for software representation. The proposed scheme leverages aggregated\ninformation within various sections in the software to enable robust malware\ndetection and mitigate adversarial settings. Our experimental results show that\ntraditional malware detection models are ineffective against adversarial\nthreats. However, the attack surface can be largely reduced by eliminating the\nvolatile information. Therefore, we propose simple-yet-effective methods to\nmitigate the impacts of binary manipulation attacks. Overall, our graph-based\nmalware detection scheme can accurately detect malware with an area under the\ncurve score of 88.32\\% and a score of 88.19% under a combination of binary\nmanipulation attacks, exhibiting the efficiency of our proposed scheme.",
          "link": "http://arxiv.org/abs/2310.03285",
          "publishedOn": "2023-10-07T00:42:19.689Z",
          "wordCount": null,
          "title": "Burning the Adversarial Bridges: Robust Windows Malware Detection Against Binary-level Mutations. (arXiv:2310.03285v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15294",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Wong_H/0/1/0/all/0/1\">Hong Shen Wong</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chan_W/0/1/0/all/0/1\">Wei Xuan Chan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Li_B/0/1/0/all/0/1\">Bing Huan Li</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yap_C/0/1/0/all/0/1\">Choon Hwai Yap</a>",
          "description": "Fluid dynamics computations for tube-like geometries are important for\nbiomedical evaluation of vascular and airway fluid dynamics. Physics-Informed\nNeural Networks (PINNs) have recently emerged as a good alternative to\ntraditional computational fluid dynamics (CFD) methods. The vanilla PINN,\nhowever, requires much longer training time than the traditional CFD methods\nfor each specific flow scenario and thus does not justify its mainstream use.\nHere, we explore the use of the multi-case PINN approach for calculating\nbiomedical tube flows, where varied geometry cases are parameterized and\npre-trained on the PINN, such that results for unseen geometries can be\nobtained in real time. Our objective is to identify network architecture,\ntube-specific, and regularization strategies that can optimize this, via\nexperiments on a series of idealized 2D stenotic tube flows.",
          "link": "http://arxiv.org/abs/2309.15294",
          "publishedOn": "2023-10-07T00:42:19.689Z",
          "wordCount": null,
          "title": "Multiple Case Physics-Informed Neural Network for Biomedical Tube Flows. (arXiv:2309.15294v2 [physics.flu-dyn] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiangyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sibo Wang</a>",
          "description": "Graph-level anomaly detection has gained significant attention as it finds\nmany applications in various domains, such as cancer diagnosis and enzyme\nprediction. However, existing methods fail to capture the underlying properties\nof graph anomalies, resulting in unexplainable framework design and\nunsatisfying performance. In this paper, we take a step back and re-investigate\nthe spectral differences between anomalous and normal graphs. Our main\nobservation shows a significant disparity in the accumulated spectral energy\nbetween these two classes. Moreover, we prove that the accumulated spectral\nenergy of the graph signal can be represented by its Rayleigh Quotient,\nindicating that the Rayleigh Quotient is a driving factor behind the anomalous\nproperties of graphs. Motivated by this, we propose Rayleigh Quotient Graph\nNeural Network (RQGNN), the first spectral GNN for graph-level anomaly\ndetection, providing a new perspective on exploring the inherent spectral\nfeatures of anomalous graphs. Specifically, we introduce a novel framework that\nconsists of two components: the Rayleigh Quotient learning component (RQL) and\nChebyshev Wavelet GNN with RQ-pooling (CWGNN-RQ). RQL explicitly captures the\nRayleigh Quotient of graphs and CWGNN-RQ implicitly explores the spectral space\nof graphs. Extensive experiments on 10 real-world datasets show that RQGNN\noutperforms the best rival by 6.74% in Macro-F1 score and 1.44% in AUC,\ndemonstrating the effectiveness of our framework.",
          "link": "http://arxiv.org/abs/2310.02861",
          "publishedOn": "2023-10-07T00:42:19.689Z",
          "wordCount": null,
          "title": "Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection. (arXiv:2310.02861v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1\">Zhongkai Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jiachen Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1\">Chang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_F/0/1/0/all/0/1\">Fanzhi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Z/0/1/0/all/0/1\">Zeyu Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Songming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Lu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "While significant progress has been made on Physics-Informed Neural Networks\n(PINNs), a comprehensive comparison of these methods across a wide range of\nPartial Differential Equations (PDEs) is still lacking. This study introduces\nPINNacle, a benchmarking tool designed to fill this gap. PINNacle provides a\ndiverse dataset, comprising over 20 distinct PDEs from various domains,\nincluding heat conduction, fluid dynamics, biology, and electromagnetics. These\nPDEs encapsulate key challenges inherent to real-world problems, such as\ncomplex geometry, multi-scale phenomena, nonlinearity, and high dimensionality.\nPINNacle also offers a user-friendly toolbox, incorporating about 10\nstate-of-the-art PINN methods for systematic evaluation and comparison. We have\nconducted extensive experiments with these methods, offering insights into\ntheir strengths and weaknesses. In addition to providing a standardized means\nof assessing performance, PINNacle also offers an in-depth analysis to guide\nfuture research, particularly in areas such as domain decomposition methods and\nloss reweighting for handling multi-scale problems and complex geometry. To the\nbest of our knowledge, it is the largest benchmark with a diverse and\ncomprehensive evaluation that will undoubtedly foster further research in\nPINNs.",
          "link": "http://arxiv.org/abs/2306.08827",
          "publishedOn": "2023-10-07T00:42:19.688Z",
          "wordCount": null,
          "title": "PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs. (arXiv:2306.08827v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.09472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Johor Jara Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1\">Matthew Guzdial</a>",
          "description": "Procedural Content Generation (PCG) and Procedural Content Generation via\nMachine Learning (PCGML) have been used in prior work for generating levels in\nvarious games. This paper introduces Content Augmentation and focuses on the\nsubproblem of level inpainting, which involves reconstructing and extending\nvideo game levels. Drawing inspiration from image inpainting, we adapt two\ntechniques from this domain to address our specific use case. We present two\napproaches for level inpainting: an Autoencoder and a U-net. Through a\ncomprehensive case study, we demonstrate their superior performance compared to\na baseline method and discuss their relative merits. Furthermore, we provide a\npractical demonstration of both approaches for the level inpainting task and\noffer insights into potential directions for future research.",
          "link": "http://arxiv.org/abs/2309.09472",
          "publishedOn": "2023-10-07T00:42:19.676Z",
          "wordCount": null,
          "title": "Reconstructing Existing Levels through Level Inpainting. (arXiv:2309.09472v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03597",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yifan Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daniel Zhengyu Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_J/0/1/0/all/0/1\">Jiaoyang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reich_S/0/1/0/all/0/1\">Sebastian Reich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew M Stuart</a>",
          "description": "Sampling a target probability distribution with an unknown normalization\nconstant is a fundamental challenge in computational science and engineering.\nRecent work shows that algorithms derived by considering gradient flows in the\nspace of probability measures open up new avenues for algorithm development.\nThis paper makes three contributions to this sampling approach by scrutinizing\nthe design components of such gradient flows. Any instantiation of a gradient\nflow for sampling needs an energy functional and a metric to determine the\nflow, as well as numerical approximations of the flow to derive algorithms. Our\nfirst contribution is to show that the Kullback-Leibler divergence, as an\nenergy functional, has the unique property (among all f-divergences) that\ngradient flows resulting from it do not depend on the normalization constant of\nthe target distribution. Our second contribution is to study the choice of\nmetric from the perspective of invariance. The Fisher-Rao metric is known as\nthe unique choice (up to scaling) that is diffeomorphism invariant. As a\ncomputationally tractable alternative, we introduce a relaxed, affine\ninvariance property for the metrics and gradient flows. In particular, we\nconstruct various affine invariant Wasserstein and Stein gradient flows. Affine\ninvariant gradient flows are shown to behave more favorably than their\nnon-affine-invariant counterparts when sampling highly anisotropic\ndistributions, in theory and by using particle methods. Our third contribution\nis to study, and develop efficient algorithms based on Gaussian approximations\nof the gradient flows; this leads to an alternative to particle methods. We\nestablish connections between various Gaussian approximate gradient flows,\ndiscuss their relation to gradient methods arising from parametric variational\ninference, and study their convergence properties both theoretically and\nnumerically.",
          "link": "http://arxiv.org/abs/2310.03597",
          "publishedOn": "2023-10-07T00:42:19.675Z",
          "wordCount": null,
          "title": "Sampling via Gradient Flows in the Space of Probability Measures. (arXiv:2310.03597v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.02787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mangold_L/0/1/0/all/0/1\">Lena Mangold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_C/0/1/0/all/0/1\">Camille Roth</a>",
          "description": "A myriad of approaches have been proposed to characterise the mesoscale\nstructure of networks - most often as a partition based on patterns variously\ncalled communities, blocks, or clusters. Clearly, distinct methods designed to\ndetect different types of patterns may provide a variety of answers to the\nnetwork's mesoscale structure. Yet, even multiple runs of a given method can\nsometimes yield diverse and conflicting results, producing entire landscapes of\npartitions which potentially include multiple (locally optimal) mesoscale\nexplanations of the network. Such ambiguity motivates a closer look at the\nability of these methods to find multiple qualitatively different 'ground\ntruth' partitions in a network. Here, we propose the stochastic cross-block\nmodel (SCBM), a generative model which allows for two distinct partitions to be\nbuilt into the mesoscale structure of a single benchmark network. We\ndemonstrate a use case of the benchmark model by appraising the power of\nstochastic block models (SBMs) to detect implicitly planted coexisting\nbi-community and core-periphery structures of different strengths. Given our\nmodel design and experimental set-up, we find that the ability to detect the\ntwo partitions individually varies by SBM variant and that coexistence of both\npartitions is recovered only in a very limited number of cases. Our findings\nsuggest that in most instances only one - in some way dominating - structure\ncan be detected, even in the presence of other partitions. They underline the\nneed for considering entire landscapes of partitions when different competing\nexplanations exist and motivate future research to advance partition\ncoexistence detection methods. Our model also contributes to the field of\nbenchmark networks more generally by enabling further exploration of the\nability of new and existing methods to detect ambiguity in the mesoscale\nstructure of networks.",
          "link": "http://arxiv.org/abs/2302.02787",
          "publishedOn": "2023-10-07T00:42:19.675Z",
          "wordCount": null,
          "title": "Generative models for two-ground-truth partitions in networks. (arXiv:2302.02787v3 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.00696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tekin_S/0/1/0/all/0/1\">Selim Furkan Tekin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazla_A/0/1/0/all/0/1\">Arda Fazla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozat_S/0/1/0/all/0/1\">Suleyman Serdar Kozat</a>",
          "description": "Numerical weather forecasting using high-resolution physical models often\nrequires extensive computational resources on supercomputers, which diminishes\ntheir wide usage in most real-life applications. As a remedy, applying deep\nlearning methods has revealed innovative solutions within this field. To this\nend, we introduce a novel deep learning architecture for forecasting\nhigh-resolution spatio-temporal weather data. Our approach extends the\nconventional encoder-decoder structure by integrating Convolutional Long-short\nTerm Memory and Convolutional Neural Networks. In addition, we incorporate\nattention and context matcher mechanisms into the model architecture. Our\nWeather Model achieves significant performance improvements compared to\nbaseline deep learning models, including ConvLSTM, TrajGRU, and U-Net. Our\nexperimental evaluation involves high-scale, real-world benchmark numerical\nweather datasets, namely the ERA5 hourly dataset on pressure levels and\nWeatherBench. Our results demonstrate substantial improvements in identifying\nspatial and temporal correlations with attention matrices focusing on distinct\nparts of the input series to model atmospheric circulations. We also compare\nour model with high-resolution physical models using the benchmark metrics and\nshow that our Weather Model is accurate and easy to interpret.",
          "link": "http://arxiv.org/abs/2102.00696",
          "publishedOn": "2023-10-07T00:42:19.674Z",
          "wordCount": null,
          "title": "Numerical Weather Forecasting using Convolutional-LSTM with Attention and Context Matcher Mechanisms. (arXiv:2102.00696v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.05250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Hao Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaojun Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chunhua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiwen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_W/0/1/0/all/0/1\">Weihua Gui</a>",
          "description": "Thank you very much for the attention and concern of colleagues and scholars\nin this work. With the comments and guidance of experts, editors, and\nreviewers, this work has been accepted for publishing in the journal \"Process\nSafety and Environmental Protection\". The theme of this paper relies on the\nSpatial-temporal associations of numerous variables in the same industrial\nprocesses, which refers to numerous variables obtained in dynamic industrial\nprocesses with Spatial-temporal correlation characteristics, i.e., these\nvariables are not only highly correlated in time but also interrelated in\nspace. To handle this problem, three key issues need to be well addressed:\nvariable characteristics modeling and representation, graph network\nconstruction (temporal information), and graph characteristics perception. The\nfirst issue is implemented by assuming the data follows one improved Gaussian\ndistribution, while the graph network can be defined by the monitoring\nvariables and their edges which are calculated by their characteristics in\ntime. Finally, these networks corresponding to process states at different\ntimes are fed into a graph convolutional neural network to implement graph\nclassification to achieve process monitoring. A benchmark experiment (Tennessee\nEastman chemical process) and one application study (cobalt purification from\nzinc solution) are employed to demonstrate the feasibility and applicability of\nthis paper.",
          "link": "http://arxiv.org/abs/2205.05250",
          "publishedOn": "2023-10-07T00:42:19.674Z",
          "wordCount": null,
          "title": "Spatial-temporal associations representation and application for process monitoring using graph convolution neural network. (arXiv:2205.05250v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.09874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hepburn_A/0/1/0/all/0/1\">Alexander Hepburn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laparra_V/0/1/0/all/0/1\">Valero Laparra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1\">Ra&#xfa;l Santos-Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malo_J/0/1/0/all/0/1\">Jes&#xfa;s Malo</a>",
          "description": "In the 1950s, Barlow and Attneave hypothesised a link between biological\nvision and information maximisation. Following Shannon, information was defined\nusing the probability of natural images. A number of physiological and\npsychophysical phenomena have been derived ever since from principles like\ninfo-max, efficient coding, or optimal denoising. However, it remains unclear\nhow this link is expressed in mathematical terms from image probability. First,\nclassical derivations were subjected to strong assumptions on the probability\nmodels and on the behaviour of the sensors. Moreover, the direct evaluation of\nthe hypothesis was limited by the inability of the classical image models to\ndeliver accurate estimates of the probability. In this work we directly\nevaluate image probabilities using an advanced generative model for natural\nimages, and we analyse how probability-related factors can be combined to\npredict human perception via sensitivity of state-of-the-art subjective image\nquality metrics. We use information theory and regression analysis to find a\ncombination of just two probability-related factors that achieves 0.8\ncorrelation with subjective metrics. This probability-based sensitivity is\npsychophysically validated by reproducing the basic trends of the Contrast\nSensitivity Function, its suprathreshold variation, and trends of the Weber-law\nand masking.",
          "link": "http://arxiv.org/abs/2303.09874",
          "publishedOn": "2023-10-07T00:42:19.674Z",
          "wordCount": null,
          "title": "Disentangling the Link Between Image Statistics and Human Perception. (arXiv:2303.09874v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tal_O/0/1/0/all/0/1\">Ofir Bar Tal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haviv_A/0/1/0/all/0/1\">Adi Haviv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1\">Amit H. Bermano</a>",
          "description": "Evasion Attacks (EA) are used to test the robustness of trained neural\nnetworks by distorting input data to misguide the model into incorrect\nclassifications. Creating these attacks is a challenging task, especially with\nthe ever-increasing complexity of models and datasets. In this work, we\nintroduce a self-supervised, computationally economical method for generating\nadversarial examples, designed for the unseen black-box setting. Adapting\ntechniques from representation learning, our method generates on-manifold EAs\nthat are encouraged to resemble the data distribution. These attacks are\ncomparable in effectiveness compared to the state-of-the-art when attacking the\nmodel trained on, but are significantly more effective when attacking unseen\nmodels, as the attacks are more related to the data rather than the model\nitself. Our experiments consistently demonstrate the method is effective across\nvarious models, unseen data categories, and even defended models, suggesting a\nsignificant role for on-manifold EAs when targeting unseen models.",
          "link": "http://arxiv.org/abs/2310.03707",
          "publishedOn": "2023-10-07T00:42:19.671Z",
          "wordCount": null,
          "title": "OMG-ATTACK: Self-Supervised On-Manifold Generation of Transferable Evasion Attacks. (arXiv:2310.03707v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.17348",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farinha_M/0/1/0/all/0/1\">Matilde Tristany Farinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortner_T/0/1/0/all/0/1\">Thomas Ortner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dellaferrera_G/0/1/0/all/0/1\">Giorgia Dellaferrera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grewe_B/0/1/0/all/0/1\">Benjamin Grewe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pantazi_A/0/1/0/all/0/1\">Angeliki Pantazi</a>",
          "description": "Artificial Neural Networks (ANNs) trained with Backpropagation (BP) show\nastounding performance and are increasingly often used in performing our daily\nlife tasks. However, ANNs are highly vulnerable to adversarial attacks, which\nalter inputs with small targeted perturbations that drastically disrupt the\nmodels' performance. The most effective method to make ANNs robust against\nthese attacks is adversarial training, in which the training dataset is\naugmented with exemplary adversarial samples. Unfortunately, this approach has\nthe drawback of increased training complexity since generating adversarial\nsamples is very computationally demanding. In contrast to ANNs, humans are not\nsusceptible to adversarial attacks. Therefore, in this work, we investigate\nwhether biologically-plausible learning algorithms are more robust against\nadversarial attacks than BP. In particular, we present an extensive comparative\nanalysis of the adversarial robustness of BP and Present the Error to Perturb\nthe Input To modulate Activity (PEPITA), a recently proposed\nbiologically-plausible learning algorithm, on various computer vision tasks. We\nobserve that PEPITA has higher intrinsic adversarial robustness and, with\nadversarial training, has a more favourable natural-vs-adversarial performance\ntrade-off as, for the same natural accuracies, PEPITA's adversarial accuracies\ndecrease in average by 0.26% and BP's by 8.05%.",
          "link": "http://arxiv.org/abs/2309.17348",
          "publishedOn": "2023-10-07T00:42:19.669Z",
          "wordCount": null,
          "title": "Efficient Biologically Plausible Adversarial Training. (arXiv:2309.17348v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.00035",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aitchison_L/0/1/0/all/0/1\">Laurence Aitchison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudolph_M/0/1/0/all/0/1\">Maja Rudolph</a>",
          "description": "Finetuned LLMs often exhibit poor uncertainty quantification, manifesting as\noverconfidence, poor calibration, and unreliable prediction results on test\ndata or out-of-distribution samples. One approach commonly used in vision for\nalleviating this issue is a deep ensemble, which constructs an ensemble by\ntraining the same model multiple times using different random initializations.\nHowever, there is a huge challenge to ensembling LLMs: the most effective LLMs\nare very, very large. Keeping a single LLM in memory is already challenging\nenough: keeping an ensemble of e.g. 5 LLMs in memory is impossible in many\nsettings. To address these issues, we propose an ensemble approach using\nLow-Rank Adapters (LoRA), a parameter-efficient fine-tuning technique.\nCritically, these low-rank adapters represent a very small number of\nparameters, orders of magnitude less than the underlying pre-trained model.\nThus, it is possible to construct large ensembles of LoRA adapters with almost\nthe same computational overhead as using the original model. We find that LoRA\nensembles, applied on its own or on top of pre-existing regularization\ntechniques, gives consistent improvements in predictive accuracy and\nuncertainty quantification.",
          "link": "http://arxiv.org/abs/2310.00035",
          "publishedOn": "2023-10-07T00:42:19.669Z",
          "wordCount": null,
          "title": "LoRA ensembles for large language model fine-tuning. (arXiv:2310.00035v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15871",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daolang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bharti_A/0/1/0/all/0/1\">Ayush Bharti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Souza_A/0/1/0/all/0/1\">Amauri Souza</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Acerbi_L/0/1/0/all/0/1\">Luigi Acerbi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "Simulation-based inference (SBI) methods such as approximate Bayesian\ncomputation (ABC), synthetic likelihood, and neural posterior estimation (NPE)\nrely on simulating statistics to infer parameters of intractable likelihood\nmodels. However, such methods are known to yield untrustworthy and misleading\ninference outcomes under model misspecification, thus hindering their\nwidespread applicability. In this work, we propose the first general approach\nto handle model misspecification that works across different classes of SBI\nmethods. Leveraging the fact that the choice of statistics determines the\ndegree of misspecification in SBI, we introduce a regularized loss function\nthat penalises those statistics that increase the mismatch between the data and\nthe model. Taking NPE and ABC as use cases, we demonstrate the superior\nperformance of our method on high-dimensional time-series models that are\nartificially misspecified. We also apply our method to real data from the field\nof radio propagation where the model is known to be misspecified. We show\nempirically that the method yields robust inference in misspecified scenarios,\nwhilst still being accurate when the model is well-specified.",
          "link": "http://arxiv.org/abs/2305.15871",
          "publishedOn": "2023-10-07T00:42:19.659Z",
          "wordCount": null,
          "title": "Learning Robust Statistics for Simulation-based Inference under Model Misspecification. (arXiv:2305.15871v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03575",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cui_H/0/1/0/all/0/1\">Hugo Cui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krzakala_F/0/1/0/all/0/1\">Florent Krzakala</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zdeborova_L/0/1/0/all/0/1\">Lenka Zdeborov&#xe1;</a>",
          "description": "We study the problem of training a flow-based generative model, parametrized\nby a two-layer autoencoder, to sample from a high-dimensional Gaussian mixture.\nWe provide a sharp end-to-end analysis of the problem. First, we provide a\ntight closed-form characterization of the learnt velocity field, when\nparametrized by a shallow denoising auto-encoder trained on a finite number $n$\nof samples from the target distribution. Building on this analysis, we provide\na sharp description of the corresponding generative flow, which pushes the base\nGaussian density forward to an approximation of the target density. In\nparticular, we provide closed-form formulae for the distance between the mean\nof the generated mixture and the mean of the target mixture, which we show\ndecays as $\\Theta_n(\\frac{1}{n})$. Finally, this rate is shown to be in fact\nBayes-optimal.",
          "link": "http://arxiv.org/abs/2310.03575",
          "publishedOn": "2023-10-07T00:42:19.653Z",
          "wordCount": null,
          "title": "Analysis of learning a flow-based generative model from limited sample complexity. (arXiv:2310.03575v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.05603",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1\">Shiye Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Deep learning technology has developed unprecedentedly in the last decade and\nhas become the primary choice in many application domains. This progress is\nmainly attributed to a systematic collaboration in which rapidly growing\ncomputing resources encourage advanced algorithms to deal with massive data.\nHowever, it has gradually become challenging to handle the unlimited growth of\ndata with limited computing power. To this end, diverse approaches are proposed\nto improve data processing efficiency. Dataset distillation, a dataset\nreduction method, addresses this problem by synthesizing a small typical\ndataset from substantial data and has attracted much attention from the deep\nlearning community. Existing dataset distillation methods can be taxonomized\ninto meta-learning and data matching frameworks according to whether they\nexplicitly mimic the performance of target data. Although dataset distillation\nhas shown surprising performance in compressing datasets, there are still\nseveral limitations such as distilling high-resolution data or data with\ncomplex label spaces. This paper provides a holistic understanding of dataset\ndistillation from multiple aspects, including distillation frameworks and\nalgorithms, factorized dataset distillation, performance comparison, and\napplications. Finally, we discuss challenges and promising directions to\nfurther promote future studies on dataset distillation.",
          "link": "http://arxiv.org/abs/2301.05603",
          "publishedOn": "2023-10-07T00:42:19.646Z",
          "wordCount": null,
          "title": "A Comprehensive Survey of Dataset Distillation. (arXiv:2301.05603v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Maliki_S/0/1/0/all/0/1\">Shawqi Al-Maliki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qayyum_A/0/1/0/all/0/1\">Adnan Qayyum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_H/0/1/0/all/0/1\">Hassan Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdallah_M/0/1/0/all/0/1\">Mohamed Abdallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qadir_J/0/1/0/all/0/1\">Junaid Qadir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1\">Dinh Thai Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1\">Dusit Niyato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Fuqaha_A/0/1/0/all/0/1\">Ala Al-Fuqaha</a>",
          "description": "Deep Neural Networks (DNNs) have been the driving force behind many of the\nrecent advances in machine learning. However, research has shown that DNNs are\nvulnerable to adversarial examples -- input samples that have been perturbed to\nforce DNN-based models to make errors. As a result, Adversarial Machine\nLearning (AdvML) has gained a lot of attention, and researchers have\ninvestigated these vulnerabilities in various settings and modalities. In\naddition, DNNs have also been found to incorporate embedded bias and often\nproduce unexplainable predictions, which can result in anti-social AI\napplications. The emergence of new AI technologies that leverage Large Language\nModels (LLMs), such as ChatGPT and GPT-4, increases the risk of producing\nanti-social applications at scale. AdvML for Social Good (AdvML4G) is an\nemerging field that repurposes the AdvML bug to invent pro-social applications.\nRegulators, practitioners, and researchers should collaborate to encourage the\ndevelopment of pro-social applications and hinder the development of\nanti-social ones. In this work, we provide the first comprehensive review of\nthe emerging field of AdvML4G. This paper encompasses a taxonomy that\nhighlights the emergence of AdvML4G, a discussion of the differences and\nsimilarities between AdvML4G and AdvML, a taxonomy covering social good-related\nconcepts and aspects, an exploration of the motivations behind the emergence of\nAdvML4G at the intersection of ML4G and AdvML, and an extensive summary of the\nworks that utilize AdvML4G as an auxiliary tool for innovating pro-social\napplications. Finally, we elaborate upon various challenges and open research\nissues that require significant attention from the research community.",
          "link": "http://arxiv.org/abs/2310.03614",
          "publishedOn": "2023-10-07T00:42:19.645Z",
          "wordCount": null,
          "title": "Adversarial Machine Learning for Social Good: Reframing the Adversary as an Ally. (arXiv:2310.03614v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.12266",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Defossez_A/0/1/0/all/0/1\">Alexandre D&#xe9;fossez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Caucheteux_C/0/1/0/all/0/1\">Charlotte Caucheteux</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rapin_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;my Rapin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kabeli_O/0/1/0/all/0/1\">Ori Kabeli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+King_J/0/1/0/all/0/1\">Jean-R&#xe9;mi King</a>",
          "description": "Decoding speech from brain activity is a long-awaited goal in both healthcare\nand neuroscience. Invasive devices have recently led to major milestones in\nthat regard: deep learning algorithms trained on intracranial recordings now\nstart to decode elementary linguistic features (e.g. letters, words,\nspectrograms). However, extending this approach to natural speech and\nnon-invasive brain recordings remains a major challenge. Here, we introduce a\nmodel trained with contrastive-learning to decode self-supervised\nrepresentations of perceived speech from the non-invasive recordings of a large\ncohort of healthy individuals. To evaluate this approach, we curate and\nintegrate four public datasets, encompassing 175 volunteers recorded with\nmagneto- or electro-encephalography (M/EEG), while they listened to short\nstories and isolated sentences. The results show that our model can identify,\nfrom 3 seconds of MEG signals, the corresponding speech segment with up to 41%\naccuracy out of more than 1,000 distinct possibilities on average across\nparticipants, and more than 80% in the very best participants - a performance\nthat allows the decoding of words and phrases absent from the training set. The\ncomparison of our model to a variety of baselines highlights the importance of\n(i) a contrastive objective, (ii) pretrained representations of speech and\n(iii) a common convolutional architecture simultaneously trained across\nmultiple participants. Finally, the analysis of the decoder's predictions\nsuggests that they primarily depend on lexical and contextual semantic\nrepresentations. Overall, this effective decoding of perceived speech from\nnon-invasive recordings delineates a promising path to decode language from\nbrain activity, without putting patients at risk for brain surgery.",
          "link": "http://arxiv.org/abs/2208.12266",
          "publishedOn": "2023-10-07T00:42:19.516Z",
          "wordCount": null,
          "title": "Decoding speech perception from non-invasive brain recordings. (arXiv:2208.12266v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.06074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1\">Badih Ghazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamath_P/0/1/0/all/0/1\">Pritish Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1\">Ravi Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leeman_E/0/1/0/all/0/1\">Ethan Leeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1\">Pasin Manurangsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varadarajan_A/0/1/0/all/0/1\">Avinash V Varadarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chiyuan Zhang</a>",
          "description": "We study the task of training regression models with the guarantee of label\ndifferential privacy (DP). Based on a global prior distribution on label\nvalues, which could be obtained privately, we derive a label DP randomization\nmechanism that is optimal under a given regression loss function. We prove that\nthe optimal mechanism takes the form of a \"randomized response on bins\", and\npropose an efficient algorithm for finding the optimal bin values. We carry out\na thorough experimental evaluation on several datasets demonstrating the\nefficacy of our algorithm.",
          "link": "http://arxiv.org/abs/2212.06074",
          "publishedOn": "2023-10-07T00:42:19.472Z",
          "wordCount": null,
          "title": "Regression with Label Differential Privacy. (arXiv:2212.06074v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.15497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peiyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sirui Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yixin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>",
          "description": "We present Deep Region Competition (DRC), an algorithm designed to extract\nforeground objects from images in a fully unsupervised manner. Foreground\nextraction can be viewed as a special case of generic image segmentation that\nfocuses on identifying and disentangling objects from the background. In this\nwork, we rethink the foreground extraction by reconciling energy-based prior\nwith generative image modeling in the form of Mixture of Experts (MoE), where\nwe further introduce the learned pixel re-assignment as the essential inductive\nbias to capture the regularities of background regions. With this modeling, the\nforeground-background partition can be naturally found through\nExpectation-Maximization (EM). We show that the proposed method effectively\nexploits the interaction between the mixture components during the partitioning\nprocess, which closely connects to region competition, a seminal approach for\ngeneric image segmentation. Experiments demonstrate that DRC exhibits more\ncompetitive performances on complex real-world data and challenging\nmulti-object scenes compared with prior methods. Moreover, we show empirically\nthat DRC can potentially generalize to novel foreground objects even from\ncategories unseen during training.",
          "link": "http://arxiv.org/abs/2110.15497",
          "publishedOn": "2023-10-07T00:42:19.395Z",
          "wordCount": null,
          "title": "Unsupervised Foreground Extraction via Deep Region Competition. (arXiv:2110.15497v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.01150",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Bernardoni_W/0/1/0/all/0/1\">William Bernardoni</a>, <a href=\"http://arxiv.org/find/math/1/au:+Cardona_R/0/1/0/all/0/1\">Robert Cardona</a>, <a href=\"http://arxiv.org/find/math/1/au:+Cleveland_J/0/1/0/all/0/1\">Jacob Cleveland</a>, <a href=\"http://arxiv.org/find/math/1/au:+Curry_J/0/1/0/all/0/1\">Justin Curry</a>, <a href=\"http://arxiv.org/find/math/1/au:+Green_R/0/1/0/all/0/1\">Robert Green</a>, <a href=\"http://arxiv.org/find/math/1/au:+Heller_B/0/1/0/all/0/1\">Brian Heller</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hylton_A/0/1/0/all/0/1\">Alan Hylton</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lam_T/0/1/0/all/0/1\">Tung Lam</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kassouf_Short_R/0/1/0/all/0/1\">Robert Kassouf-Short</a>",
          "description": "In this paper we introduce some new algebraic and geometric perspectives on\nnetworked space communications. Our main contribution is a novel definition of\na time-varying graph (TVG), defined in terms of a matrix with values in subsets\nof the real line P(R). We leverage semi-ring properties of P(R) to model\nmulti-hop communication in a TVG using matrix multiplication and a truncated\nKleene star. This leads to novel statistics on the communication capacity of\nTVGs called lifetime curves, which we generate for large samples of randomly\nchosen STARLINK satellites, whose connectivity is modeled over day-long\nsimulations. Determining when a large subsample of STARLINK is temporally\nstrongly connected is further analyzed using novel metrics introduced here that\nare inspired by topological data analysis (TDA). To better model networking\nscenarios between the Earth and Mars, we introduce various semi-rings capable\nof modeling propagation delay as well as protocols common to Delay Tolerant\nNetworking (DTN), such as store-and-forward. Finally, we illustrate the\napplicability of zigzag persistence for featurizing different space networks\nand demonstrate the efficacy of K-Nearest Neighbors (KNN) classification for\ndistinguishing Earth-Mars and Earth-Moon satellite systems using time-varying\ntopology alone.",
          "link": "http://arxiv.org/abs/2304.01150",
          "publishedOn": "2023-10-07T00:42:19.394Z",
          "wordCount": null,
          "title": "Algebraic and Geometric Models for Space Networking. (arXiv:2304.01150v2 [math.AT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.02062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Calderon_P/0/1/0/all/0/1\">Pio Calderon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soen_A/0/1/0/all/0/1\">Alexander Soen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1\">Marian-Andrei Rizoiu</a>",
          "description": "The multivariate Hawkes process (MHP) is widely used for analyzing data\nstreams that interact with each other, where events generate new events within\ntheir own dimension (via self-excitation) or across different dimensions (via\ncross-excitation). However, in certain applications, the timestamps of\nindividual events in some dimensions are unobservable, and only event counts\nwithin intervals are known, referred to as partially interval-censored data.\nThe MHP is unsuitable for handling such data since its estimation requires\nevent timestamps. In this study, we introduce the Partial Mean Behavior Poisson\n(PMBP) process, a novel point process which shares parameter equivalence with\nthe MHP and can effectively model both timestamped and interval-censored data.\nWe demonstrate the capabilities of the PMBP process using synthetic and\nreal-world datasets. Firstly, we illustrate that the PMBP process can\napproximate MHP parameters and recover the spectral radius using synthetic\nevent histories. Next, we assess the performance of the PMBP process in\npredicting YouTube popularity and find that it surpasses state-of-the-art\nmethods. Lastly, we leverage the PMBP process to gain qualitative insights from\na dataset comprising daily COVID-19 case counts from multiple countries and\nCOVID-19-related news articles. By clustering the PMBP-modeled countries, we\nunveil hidden interaction patterns between occurrences of COVID-19 cases and\nnews reporting.",
          "link": "http://arxiv.org/abs/2111.02062",
          "publishedOn": "2023-10-07T00:42:19.381Z",
          "wordCount": null,
          "title": "Linking Across Data Granularity: Fitting Multivariate Hawkes Processes to Partially Interval-Censored Data. (arXiv:2111.02062v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Beomsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_G/0/1/0/all/0/1\">Gihyun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kwanyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Diffusion models are a powerful class of generative models which simulate\nstochastic differential equations (SDEs) to generate data from noise. Although\ndiffusion models have achieved remarkable progress in recent years, they have\nlimitations in the unpaired image-to-image translation tasks due to the\nGaussian prior assumption. Schr\\\"odinger Bridge (SB), which learns an SDE to\ntranslate between two arbitrary distributions, have risen as an attractive\nsolution to this problem. However, none of SB models so far have been\nsuccessful at unpaired translation between high-resolution images. In this\nwork, we propose the Unpaired Neural Schr\\\"odinger Bridge (UNSB), which\nexpresses SB problem as a sequence of adversarial learning problems. This\nallows us to incorporate advanced discriminators and regularization to learn a\nSB between unpaired data. We demonstrate that UNSB is scalable and successfully\nsolves various unpaired image-to-image translation tasks. Code:\n\\url{https://github.com/cyclomon/UNSB}",
          "link": "http://arxiv.org/abs/2305.15086",
          "publishedOn": "2023-10-07T00:42:19.379Z",
          "wordCount": null,
          "title": "Unpaired Image-to-Image Translation via Neural Schr\\\"odinger Bridge. (arXiv:2305.15086v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sukrita Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarna_N/0/1/0/all/0/1\">Neeraj Sarna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orfanoudaki_A/0/1/0/all/0/1\">Agni Orfanoudaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1\">Michael Berger</a>",
          "description": "Machine learning algorithms have grown in sophistication over the years and\nare increasingly deployed for real-life applications. However, when using\nmachine learning techniques in practical settings, particularly in high-risk\napplications such as medicine and engineering, obtaining the failure\nprobability of the predictive model is critical. We refer to this problem as\nthe risk-assessment task. We focus on regression algorithms and the\nrisk-assessment task of computing the probability of the true label lying\ninside an interval defined around the model's prediction. We solve the\nrisk-assessment problem using the conformal prediction approach, which provides\nprediction intervals that are guaranteed to contain the true label with a given\nprobability. Using this coverage property, we prove that our approximated\nfailure probability is conservative in the sense that it is not lower than the\ntrue failure probability of the ML algorithm. We conduct extensive experiments\nto empirically study the accuracy of the proposed method for problems with and\nwithout covariate shift. Our analysis focuses on different modeling regimes,\ndataset sizes, and conformal prediction methodologies.",
          "link": "http://arxiv.org/abs/2310.03545",
          "publishedOn": "2023-10-07T00:42:19.378Z",
          "wordCount": null,
          "title": "Distribution-free risk assessment of regression-based machine learning algorithms. (arXiv:2310.03545v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.01422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fakoor_R/0/1/0/all/0/1\">Rasool Fakoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_J/0/1/0/all/0/1\">Jonas Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhari_P/0/1/0/all/0/1\">Pratik Chaudhari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1\">Alexander J. Smola</a>",
          "description": "Real-world deployment of machine learning models is challenging because data\nevolves over time. While no model can work when data evolves in an arbitrary\nfashion, if there is some pattern to these changes, we might be able to design\nmethods to address it. This paper addresses situations when data evolves\ngradually. We introduce a time-varying propensity score that can detect gradual\nshifts in the distribution of data which allows us to selectively sample past\ndata to update the model -- not just similar data from the past like that of a\nstandard propensity score but also data that evolved in a similar fashion in\nthe past. The time-varying propensity score is quite general: we demonstrate\ndifferent ways of implementing it and evaluate it on a variety of problems\nranging from supervised learning (e.g., image classification problems) where\ndata undergoes a sequence of gradual shifts, to reinforcement learning tasks\n(e.g., robotic manipulation and continuous control) where data shifts as the\npolicy or the task changes.",
          "link": "http://arxiv.org/abs/2210.01422",
          "publishedOn": "2023-10-07T00:42:19.376Z",
          "wordCount": null,
          "title": "Time-Varying Propensity Score to Bridge the Gap between the Past and Present. (arXiv:2210.01422v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05120",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Deng_W/0/1/0/all/0/1\">Wei Deng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Q/0/1/0/all/0/1\">Qian Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1\">Yi-An Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1\">Guang Lin</a>",
          "description": "We propose a federated averaging Langevin algorithm (FA-LD) for uncertainty\nquantification and mean predictions with distributed clients. In particular, we\ngeneralize beyond normal posterior distributions and consider a general class\nof models. We develop theoretical guarantees for FA-LD for strongly log-concave\ndistributions with non-i.i.d data and study how the injected noise and the\nstochastic-gradient noise, the heterogeneity of data, and the varying learning\nrates affect the convergence. Such an analysis sheds light on the optimal\nchoice of local updates to minimize communication costs. Important to our\napproach is that the communication efficiency does not deteriorate with the\ninjected noise in the Langevin algorithms. In addition, we examine in our FA-LD\nalgorithm both independent and correlated noise used over different clients. We\nobserve there is a trade-off between the pairs among communication, accuracy,\nand data privacy. As local devices may become inactive in federated networks,\nwe also show convergence results based on different averaging schemes where\nonly partial device updates are available. In such a case, we discover an\nadditional bias that does not decay to zero.",
          "link": "http://arxiv.org/abs/2112.05120",
          "publishedOn": "2023-10-07T00:42:19.315Z",
          "wordCount": null,
          "title": "On Convergence of Federated Averaging Langevin Dynamics. (arXiv:2112.05120v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cunha_W/0/1/0/all/0/1\">Washington Cunha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franca_C/0/1/0/all/0/1\">Celso Fran&#xe7;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocha_L/0/1/0/all/0/1\">Leonardo Rocha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goncalves_M/0/1/0/all/0/1\">Marcos Andr&#xe9; Gon&#xe7;alves</a>",
          "description": "There is a niche of companies responsible for intermediating the purchase of\nlarge batches of varied products for other companies, for which the main\nchallenge is to perform product description standardization, i.e., matching an\nitem described by a client with a product described in a catalog. The problem\nis complex since the client's product description may be: (1) potentially\nnoisy; (2) short and uninformative (e.g., missing information about model and\nsize); and (3) cross-language. In this paper, we formalize this problem as a\nranking task: given an initial client product specification (query), return the\nmost appropriate standardized descriptions (response). In this paper, we\npropose TPDR, a two-step Transformer-based Product and Class Description\nRetrieval method that is able to explore the semantic correspondence between IS\nand SD, by exploiting attention mechanisms and contrastive learning. First,\nTPDR employs the transformers as two encoders sharing the embedding vector\nspace: one for encoding the IS and another for the SD, in which corresponding\npairs (IS, SD) must be close in the vector space. Closeness is further enforced\nby a contrastive learning mechanism leveraging a specialized loss function.\nTPDR also exploits a (second) re-ranking step based on syntactic features that\nare very important for the exact matching (model, dimension) of certain\nproducts that may have been neglected by the transformers. To evaluate our\nproposal, we consider 11 datasets from a real company, covering different\napplication contexts. Our solution was able to retrieve the correct\nstandardized product before the 5th ranking position in 71% of the cases and\nits correct category in the first position in 80% of the situations. Moreover,\nthe effectiveness gains over purely syntactic or semantic baselines reach up to\n3.7 times, solving cases that none of the approaches in isolation can do by\nthemselves.",
          "link": "http://arxiv.org/abs/2310.03491",
          "publishedOn": "2023-10-07T00:42:19.312Z",
          "wordCount": null,
          "title": "TPDR: A Novel Two-Step Transformer-based Product and Class Description Match and Retrieval Method. (arXiv:2310.03491v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03546",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Renaud_M/0/1/0/all/0/1\">Marien Renaud</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jiaming Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1\">Valentin de Bortoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Almansa_A/0/1/0/all/0/1\">Andr&#xe9;s Almansa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kamilov_U/0/1/0/all/0/1\">Ulugbek S. Kamilov</a>",
          "description": "Posterior sampling has been shown to be a powerful Bayesian approach for\nsolving imaging inverse problems. The recent plug-and-play unadjusted Langevin\nalgorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling\nand minimum mean squared error (MMSE) estimation by combining physical\nmeasurement models with deep-learning priors specified using image denoisers.\nHowever, the intricate relationship between the sampling distribution of\nPnP-ULA and the mismatched data-fidelity and denoiser has not been\ntheoretically analyzed. We address this gap by proposing a posterior-L2\npseudometric and using it to quantify an explicit error bound for PnP-ULA under\nmismatched posterior distribution. We numerically validate our theory on\nseveral inverse problems such as sampling from Gaussian mixture models and\nimage deblurring. Our results suggest that the sensitivity of the sampling\ndistribution of PnP-ULA to a mismatch in the measurement model and the denoiser\ncan be precisely characterized.",
          "link": "http://arxiv.org/abs/2310.03546",
          "publishedOn": "2023-10-07T00:42:19.311Z",
          "wordCount": null,
          "title": "Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models. (arXiv:2310.03546v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Ling Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Moksh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madan_K/0/1/0/all/0/1\">Kanika Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "Generative Flow Networks (GFlowNets) are amortized samplers that learn\nstochastic policies to sequentially generate compositional objects from a given\nunnormalized reward distribution. They can generate diverse sets of high-reward\nobjects, which is an important consideration in scientific discovery tasks.\nHowever, as they are typically trained from a given extrinsic reward function,\nit remains an important open challenge about how to leverage the power of\npre-training and train GFlowNets in an unsupervised fashion for efficient\nadaptation to downstream tasks. Inspired by recent successes of unsupervised\npre-training in various domains, we introduce a novel approach for reward-free\npre-training of GFlowNets. By framing the training as a self-supervised\nproblem, we propose an outcome-conditioned GFlowNet (OC-GFN) that learns to\nexplore the candidate space. Specifically, OC-GFN learns to reach any targeted\noutcomes, akin to goal-conditioned policies in reinforcement learning. We show\nthat the pre-trained OC-GFN model can allow for a direct extraction of a policy\ncapable of sampling from any new reward functions in downstream tasks.\nNonetheless, adapting OC-GFN on a downstream task-specific reward involves an\nintractable marginalization over possible outcomes. We propose a novel way to\napproximate this marginalization by learning an amortized predictor enabling\nefficient fine-tuning. Extensive experimental results validate the efficacy of\nour approach, demonstrating the effectiveness of pre-training the OC-GFN, and\nits ability to swiftly adapt to downstream tasks and discover modes more\nefficiently. This work may serve as a foundation for further exploration of\npre-training strategies in the context of GFlowNets.",
          "link": "http://arxiv.org/abs/2310.03419",
          "publishedOn": "2023-10-07T00:42:19.310Z",
          "wordCount": null,
          "title": "Pre-Training and Fine-Tuning Generative Flow Networks. (arXiv:2310.03419v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.14655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Ji Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_T/0/1/0/all/0/1\">Teng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_K/0/1/0/all/0/1\">Kunyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yifan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1\">Xinyu Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaozhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuxiao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lei Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Weidong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yu Xu</a>",
          "description": "Despite the recent emergence of video captioning models, how to generate\nvivid, fine-grained video descriptions based on the background knowledge (i.e.,\nlong and informative commentary about the domain-specific scenes with\nappropriate reasoning) is still far from being solved, which however has great\napplications such as automatic sports narrative. In this paper, we present\nGOAL, a benchmark of over 8.9k soccer video clips, 22k sentences, and 42k\nknowledge triples for proposing a challenging new task setting as\nKnowledge-grounded Video Captioning (KGVC). Moreover, we conduct experimental\nadaption of existing methods to show the difficulty and potential directions\nfor solving this valuable and applicable task. Our data and code are available\nat https://github.com/THU-KEG/goal.",
          "link": "http://arxiv.org/abs/2303.14655",
          "publishedOn": "2023-10-07T00:42:19.310Z",
          "wordCount": null,
          "title": "GOAL: A Challenging Knowledge-grounded Video Captioning Benchmark for Real-time Soccer Commentary Generation. (arXiv:2303.14655v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Younesian_T/0/1/0/all/0/1\">Taraneh Younesian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thanapalasingam_T/0/1/0/all/0/1\">Thiviyan Thanapalasingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krieken_E/0/1/0/all/0/1\">Emile van Krieken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daza_D/0/1/0/all/0/1\">Daniel Daza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bloem_P/0/1/0/all/0/1\">Peter Bloem</a>",
          "description": "Graph neural networks (GNNs) learn the representation of nodes in a graph by\naggregating the neighborhood information in various ways. As these networks\ngrow in depth, their receptive field grows exponentially due to the increase in\nneighborhood sizes, resulting in high memory costs. Graph sampling solves\nmemory issues in GNNs by sampling a small ratio of the nodes in the graph. This\nway, GNNs can scale to much larger graphs. Most sampling methods focus on fixed\nsampling heuristics, which may not generalize to different structures or tasks.\nWe introduce GRAPES, an adaptive graph sampling method that learns to identify\nsets of influential nodes for training a GNN classifier. GRAPES uses a GFlowNet\nto learn node sampling probabilities given the classification objectives. We\nevaluate GRAPES across several small- and large-scale graph benchmarks and\ndemonstrate its effectiveness in accuracy and scalability. In contrast to\nexisting sampling methods, GRAPES maintains high accuracy even with small\nsample sizes and, therefore, can scale to very large graphs. Our code is\npublicly available at https://github.com/dfdazac/grapes.",
          "link": "http://arxiv.org/abs/2310.03399",
          "publishedOn": "2023-10-07T00:42:19.309Z",
          "wordCount": null,
          "title": "GRAPES: Learning to Sample Graphs for Scalable Graph Neural Networks. (arXiv:2310.03399v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Huan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Peilin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bingzhe Wu</a>",
          "description": "Nowadays, billions of people engage in communication and express their\nopinions on the internet daily. Unfortunately, not all of these expressions are\nfriendly or compliant, making content moderation an indispensable task. With\nthe successful development of Large Language Models (LLMs) in recent years,\nLLM-based methods have become a feasible solution for handling tasks in various\ndomains. However, in the field of content moderation, there is still a lack of\ndetailed work that systematically introduces implementation details. In this\npaper, we introduce how to fine-tune an LLM model that can be privately\ndeployed for content moderation. Specifically, we discuss whether incorporating\nreasons during the fine-tuning process would be better or if it should be\ntreated as a classification task directly. We also explore the benefits of\nutilizing reasons generated by more powerful LLMs for fine-tuning privately\ndeployed models and the impact of different processing approaches when the\nanswers generated by the more powerful LLMs are incorrect. We report the entire\nresearch process and the key findings in this paper, hoping to provide valuable\nexperience for researchers who are fine-tuning privately deployed models in\ntheir domain-specific research.",
          "link": "http://arxiv.org/abs/2310.03400",
          "publishedOn": "2023-10-07T00:42:19.308Z",
          "wordCount": null,
          "title": "Adapting Large Language Models for Content Moderation: Pitfalls in Data Engineering and Supervised Fine-tuning. (arXiv:2310.03400v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03324",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1\">Jie-Jing Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiang-Xin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiao-Wen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Lan-Zhe Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu-Feng Li</a>",
          "description": "Contrastive Language-Image Pre-training (CLIP) provides a foundation model by\nintegrating natural language into visual concepts, enabling zero-shot\nrecognition on downstream tasks. It is usually expected that satisfactory\noverall accuracy can be achieved across numerous domains through well-designed\ntextual prompts. However, we found that their performance in the worst\ncategories is significantly inferior to the overall performance. For example,\non ImageNet, there are a total of 10 categories with class-wise accuracy as low\nas 0\\%, even though the overall performance has achieved 64.1\\%. This\nphenomenon reveals the potential risks associated with using CLIP models,\nparticularly in risk-sensitive applications where specific categories hold\nsignificant importance. To address this issue, we investigate the alignment\nbetween the two modalities in the CLIP model and propose the Class-wise\nMatching Margin (\\cmm) to measure the inference confusion. \\cmm\\ can\neffectively identify the worst-performing categories and estimate the potential\nperformance of the candidate prompts. We further query large language models to\nenrich descriptions of worst-performing categories and build a weighted\nensemble to highlight the efficient prompts. Experimental results clearly\nverify the effectiveness of our proposal, where the accuracy on the worst-10\ncategories on ImageNet is boosted to 5.2\\%, without manual prompt engineering,\nlaborious optimization, or access to labeled validation data.",
          "link": "http://arxiv.org/abs/2310.03324",
          "publishedOn": "2023-10-07T00:42:19.307Z",
          "wordCount": null,
          "title": "Investigating the Limitation of CLIP Models: The Worst-Performing Categories. (arXiv:2310.03324v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03393",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Kapllani_L/0/1/0/all/0/1\">Lorenc Kapllani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Teng_L/0/1/0/all/0/1\">Long Teng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rottmann_M/0/1/0/all/0/1\">Matthias Rottmann</a>",
          "description": "Deep learning-based numerical schemes for solving high-dimensional backward\nstochastic differential equations (BSDEs) have recently raised plenty of\nscientific interest. While they enable numerical methods to approximate very\nhigh-dimensional BSDEs, their reliability has not been studied and is thus not\nunderstood. In this work, we study uncertainty quantification (UQ) for a class\nof deep learning-based BSDE schemes. More precisely, we review the sources of\nuncertainty involved in the schemes and numerically study the impact of\ndifferent sources. Usually, the standard deviation (STD) of the approximate\nsolutions obtained from multiple runs of the algorithm with different datasets\nis calculated to address the uncertainty. This approach is computationally\nquite expensive, especially for high-dimensional problems. Hence, we develop a\nUQ model that efficiently estimates the STD of the approximate solution using\nonly a single run of the algorithm. The model also estimates the mean of the\napproximate solution, which can be leveraged to initialize the algorithm and\nimprove the optimization process. Our numerical experiments show that the UQ\nmodel produces reliable estimates of the mean and STD of the approximate\nsolution for the considered class of deep learning-based BSDE schemes. The\nestimated STD captures multiple sources of uncertainty, demonstrating its\neffectiveness in quantifying the uncertainty. Additionally, the model\nillustrates the improved performance when comparing different schemes based on\nthe estimated STD values. Furthermore, it can identify hyperparameter values\nfor which the scheme achieves good approximations.",
          "link": "http://arxiv.org/abs/2310.03393",
          "publishedOn": "2023-10-07T00:42:19.305Z",
          "wordCount": null,
          "title": "Uncertainty quantification for deep learning-based schemes for solving high-dimensional backward stochastic differential equations. (arXiv:2310.03393v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03556",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bolat_K/0/1/0/all/0/1\">Kutay B&#xf6;lat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tindemans_S/0/1/0/all/0/1\">Simon H. Tindemans</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Palensky_P/0/1/0/all/0/1\">Peter Palensky</a>",
          "description": "Probabilistic modelling of power systems operation and planning processes\ndepends on data-driven methods, which require sufficiently large datasets. When\nhistorical data lacks this, it is desired to model the underlying data\ngeneration mechanism as a probability distribution to assess the data quality\nand generate more data, if needed. Kernel density estimation (KDE) based models\nare popular choices for this task, but they fail to adapt to data regions with\nvarying densities. In this paper, an adaptive KDE model is employed to\ncircumvent this, where each kernel in the model has an individual bandwidth.\nThe leave-one-out maximum log-likelihood (LOO-MLL) criterion is proposed to\nprevent the singular solutions that the regular MLL criterion gives rise to,\nand it is proven that LOO-MLL prevents these. Relying on this guaranteed\nrobustness, the model is extended by assigning learnable weights to the\nkernels. In addition, a modified expectation-maximization algorithm is employed\nto accelerate the optimization speed reliably. The performance of the proposed\nmethod and models are exhibited on two power systems datasets using different\nstatistical tests and by comparison with Gaussian mixture models. Results show\nthat the proposed models have promising performance, in addition to their\nsingularity prevention guarantees.",
          "link": "http://arxiv.org/abs/2310.03556",
          "publishedOn": "2023-10-07T00:42:19.305Z",
          "wordCount": null,
          "title": "Stable Training of Probabilistic Models Using the Leave-One-Out Maximum Log-Likelihood Objective. (arXiv:2310.03556v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03298",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ping Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Comlek_Y/0/1/0/all/0/1\">Yigitcan Comlek</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>",
          "description": "Multi-fidelity (MF) methods are gaining popularity for enhancing surrogate\nmodeling and design optimization by incorporating data from various\nlow-fidelity (LF) models. While most existing MF methods assume a fixed\ndataset, adaptive sampling methods that dynamically allocate resources among\nfidelity models can achieve higher efficiency in the exploring and exploiting\nthe design space. However, most existing MF methods rely on the hierarchical\nassumption of fidelity levels or fail to capture the intercorrelation between\nmultiple fidelity levels and utilize it to quantify the value of the future\nsamples and navigate the adaptive sampling. To address this hurdle, we propose\na framework hinged on a latent embedding for different fidelity models and the\nassociated pre-posterior analysis to explicitly utilize their correlation for\nadaptive sampling. In this framework, each infill sampling iteration includes\ntwo steps: We first identify the location of interest with the greatest\npotential improvement using the high-fidelity (HF) model, then we search for\nthe next sample across all fidelity levels that maximize the improvement per\nunit cost at the location identified in the first step. This is made possible\nby a single Latent Variable Gaussian Process (LVGP) model that maps different\nfidelity models into an interpretable latent space to capture their\ncorrelations without assuming hierarchical fidelity levels. The LVGP enables us\nto assess how LF sampling candidates will affect HF response with pre-posterior\nanalysis and determine the next sample with the best benefit-to-cost ratio.\nThrough test cases, we demonstrate that the proposed method outperforms the\nbenchmark methods in both MF global fitting (GF) and Bayesian Optimization (BO)\nproblems in convergence rate and robustness. Moreover, the method offers the\nflexibility to switch between GF and BO by simply changing the acquisition\nfunction.",
          "link": "http://arxiv.org/abs/2310.03298",
          "publishedOn": "2023-10-07T00:42:19.303Z",
          "wordCount": null,
          "title": "A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive Sampling. (arXiv:2310.03298v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1912.05957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_H/0/1/0/all/0/1\">Hamid Mohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasteh_S/0/1/0/all/0/1\">Seyed Hossein Khasteh</a>",
          "description": "Evaluating the readability of a text can significantly facilitate the precise\nexpression of information in written form. The formulation of text readability\nassessment involves the identification of meaningful properties of the text\nregardless of its length. Sophisticated features and models are used to\nevaluate the comprehensibility of texts accurately. Despite this, the problem\nof assessing texts' readability efficiently remains relatively untouched. The\nefficiency of state-of-the-art text readability assessment models can be\nfurther improved using deep reinforcement learning models. Using a hard\nattention-based active inference technique, the proposed approach makes\nefficient use of input text and computational resources. Through the use of\nsemi-supervised signals, the reinforcement learning model uses the minimum\namount of text in order to determine text's readability. A comparison of the\nmodel on Weebit and Cambridge Exams with state-of-the-art models, such as the\nBERT text readability model, shows that it is capable of achieving\nstate-of-the-art accuracy with a significantly smaller amount of input text\nthan other models.",
          "link": "http://arxiv.org/abs/1912.05957",
          "publishedOn": "2023-10-07T00:42:19.301Z",
          "wordCount": null,
          "title": "Text as Environment: A Deep Reinforcement Learning Text Readability Assessment Model. (arXiv:1912.05957v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Emili_L/0/1/0/all/0/1\">Leonardo Emili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fraga_Silva_T/0/1/0/all/0/1\">Thiago Fraga-Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pusateri_E/0/1/0/all/0/1\">Ernest Pusateri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nussbaum_Thom_M/0/1/0/all/0/1\">Markus Nu&#xdf;baum-Thom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oualil_Y/0/1/0/all/0/1\">Youssef Oualil</a>",
          "description": "We study model pruning methods applied to Transformer-based neural network\nlanguage models for automatic speech recognition. We explore three aspects of\nthe pruning frame work, namely criterion, method and scheduler, analyzing their\ncontribution in terms of accuracy and inference speed. To the best of our\nknowledge, such in-depth analyses on large-scale recognition systems has not\nbeen reported in the literature. In addition, we propose a variant of low-rank\napproximation suitable for incrementally compressing models, and delivering\nmultiple models with varied target sizes. Among other results, we show that a)\ndata-driven pruning outperforms magnitude-driven in several scenarios; b)\nincremental pruning achieves higher accuracy compared to one-shot pruning,\nespecially when targeting smaller sizes; and c) low-rank approximation presents\nthe best trade-off between size reduction and inference speed-up for moderate\ncompression.",
          "link": "http://arxiv.org/abs/2310.03424",
          "publishedOn": "2023-10-07T00:42:19.300Z",
          "wordCount": null,
          "title": "Neural Language Model Pruning for Automatic Speech Recognition. (arXiv:2310.03424v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03339",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trebbien_J/0/1/0/all/0/1\">Julius Trebbien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Putz_S/0/1/0/all/0/1\">Sebastian P&#xfc;tz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schafer_B/0/1/0/all/0/1\">Benjamin Sch&#xe4;fer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nygaard_H/0/1/0/all/0/1\">Heidi S. Nyg&#xe5;rd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorjao_L/0/1/0/all/0/1\">Leonardo Rydin Gorj&#xe3;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witthaut_D/0/1/0/all/0/1\">Dirk Witthaut</a>",
          "description": "Accurate forecasts of electricity prices are crucial for the management of\nelectric power systems and the development of smart applications. European\nelectricity prices have risen substantially and became highly volatile after\nthe Russian invasion of Ukraine, challenging established forecasting methods.\nHere, we present a Long Short-Term Memory (LSTM) model for the\nGerman-Luxembourg day-ahead electricity prices addressing these challenges. The\nrecurrent structure of the LSTM allows the model to adapt to trends, while the\njoint prediction of both mean and standard deviation enables a probabilistic\nprediction. Using a physics-inspired approach - superstatistics - to derive an\nexplanation for the statistics of prices, we show that the LSTM model\nfaithfully reproduces both prices and their volatility.",
          "link": "http://arxiv.org/abs/2310.03339",
          "publishedOn": "2023-10-07T00:42:19.298Z",
          "wordCount": null,
          "title": "Probabilistic Forecasting of Day-Ahead Electricity Prices and their Volatility with LSTMs. (arXiv:2310.03339v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.15122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Temizoz_T/0/1/0/all/0/1\">Tarkan Temiz&#xf6;z</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imdahl_C/0/1/0/all/0/1\">Christina Imdahl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijkman_R/0/1/0/all/0/1\">Remco Dijkman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamghari_Idrissi_D/0/1/0/all/0/1\">Douniel Lamghari-Idrissi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaarsveld_W/0/1/0/all/0/1\">Willem van Jaarsveld</a>",
          "description": "Problem Definition: Are traditional deep reinforcement learning (DRL)\nalgorithms, developed for a broad range of purposes including game-play and\nrobotics, the most suitable machine learning algorithms for applications in\ninventory control? To what extent would DRL algorithms tailored to the unique\ncharacteristics of inventory control problems provide superior performance\ncompared to DRL and traditional benchmarks? Methodology/results: We propose and\nstudy Deep Controlled Learning (DCL), a new DRL framework based on approximate\npolicy iteration specifically designed to tackle inventory problems.\nComparative evaluations reveal that DCL outperforms existing state-of-the-art\nheuristics in lost sales inventory control, perishable inventory systems, and\ninventory systems with random lead times, achieving lower average costs across\nall test instances and maintaining an optimality gap of no more than 0.1\\%.\nNotably, the same hyperparameter set is utilized across all experiments,\nunderscoring the robustness and generalizability of the proposed method.\nManagerial implications: These substantial performance and robustness\nimprovements pave the way for the effective application of tailored DRL\nalgorithms to inventory management problems, empowering decision-makers to\noptimize stock levels, minimize costs, and enhance responsiveness across\nvarious industries.",
          "link": "http://arxiv.org/abs/2011.15122",
          "publishedOn": "2023-10-07T00:42:19.289Z",
          "wordCount": null,
          "title": "Deep Controlled Learning for Inventory Control. (arXiv:2011.15122v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03163",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junbo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1\">Chong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_Q/0/1/0/all/0/1\">Qirong Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongyi Wang</a>",
          "description": "Weight decay is a standard technique to improve generalization performance in\nmodern deep neural network optimization, and is also widely adopted in\nfederated learning (FL) to prevent overfitting in local clients. In this paper,\nwe first explore the choices of weight decay and identify that weight decay\nvalue appreciably influences the convergence of existing FL algorithms. While\npreventing overfitting is crucial, weight decay can introduce a different\noptimization goal towards the global objective, which is further amplified in\nFL due to multiple local updates and heterogeneous data distribution. To\naddress this challenge, we develop {\\it Federated optimization with Normalized\nAnnealing Regularization} (FedNAR), a simple yet effective and versatile\nalgorithmic plug-in that can be seamlessly integrated into any existing FL\nalgorithms. Essentially, we regulate the magnitude of each update by performing\nco-clipping of the gradient and weight decay. We provide a comprehensive\ntheoretical analysis of FedNAR's convergence rate and conduct extensive\nexperiments on both vision and language datasets with different backbone\nfederated optimization algorithms. Our experimental results consistently\ndemonstrate that incorporating FedNAR into existing FL algorithms leads to\naccelerated convergence and heightened model accuracy. Moreover, FedNAR\nexhibits resilience in the face of various hyperparameter configurations.\nSpecifically, FedNAR has the ability to self-adjust the weight decay when the\ninitial specification is not optimal, while the accuracy of traditional FL\nalgorithms would markedly decline. Our codes are released at\n\\href{https://github.com/ljb121002/fednar}{https://github.com/ljb121002/fednar}.",
          "link": "http://arxiv.org/abs/2310.03163",
          "publishedOn": "2023-10-07T00:42:19.281Z",
          "wordCount": null,
          "title": "FedNAR: Federated Optimization with Normalized Annealing Regularization. (arXiv:2310.03163v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frey_J/0/1/0/all/0/1\">Jonas Frey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudin_N/0/1/0/all/0/1\">Nikita Rudin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattamala_M/0/1/0/all/0/1\">Matias Mattamala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cadena_C/0/1/0/all/0/1\">Cesar Cadena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_M/0/1/0/all/0/1\">Marco Hutter</a>",
          "description": "Autonomous robots must navigate reliably in unknown environments even under\ncompromised exteroceptive perception, or perception failures. Such failures\noften occur when harsh environments lead to degraded sensing, or when the\nperception algorithm misinterprets the scene due to limited generalization. In\nthis paper, we model perception failures as invisible obstacles and pits, and\ntrain a reinforcement learning (RL) based local navigation policy to guide our\nlegged robot. Unlike previous works relying on heuristics and anomaly detection\nto update navigational information, we train our navigation policy to\nreconstruct the environment information in the latent space from corrupted\nperception and react to perception failures end-to-end. To this end, we\nincorporate both proprioception and exteroception into our policy inputs,\nthereby enabling the policy to sense collisions on different body parts and\npits, prompting corresponding reactions. We validate our approach in simulation\nand on the real quadruped robot ANYmal running in real-time (<10 ms CPU\ninference). In a quantitative comparison with existing heuristic-based locally\nreactive planners, our policy increases the success rate over 30% when facing\nperception failures. Project Page: https://bit.ly/45NBTuh.",
          "link": "http://arxiv.org/abs/2310.03581",
          "publishedOn": "2023-10-07T00:42:19.281Z",
          "wordCount": null,
          "title": "Resilient Legged Local Navigation: Learning to Traverse with Compromised Perception End-to-End. (arXiv:2310.03581v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garza_A/0/1/0/all/0/1\">Azul Garza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mergenthaler_Canseco_M/0/1/0/all/0/1\">Max Mergenthaler-Canseco</a>",
          "description": "In this paper, we introduce TimeGPT, the first foundation model for time\nseries, capable of generating accurate predictions for diverse datasets not\nseen during training. We evaluate our pre-trained model against established\nstatistical, machine learning, and deep learning methods, demonstrating that\nTimeGPT zero-shot inference excels in performance, efficiency, and simplicity.\nOur study provides compelling evidence that insights from other domains of\nartificial intelligence can be effectively applied to time series analysis. We\nconclude that large-scale time series models offer an exciting opportunity to\ndemocratize access to precise predictions and reduce uncertainty by leveraging\nthe capabilities of contemporary advancements in deep learning.",
          "link": "http://arxiv.org/abs/2310.03589",
          "publishedOn": "2023-10-07T00:42:19.281Z",
          "wordCount": null,
          "title": "TimeGPT-1. (arXiv:2310.03589v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.01856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shihan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clarke_A/0/1/0/all/0/1\">Alexander Kenneth Clarke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maksymenko_K/0/1/0/all/0/1\">Kostiantyn Maksymenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deslauriers_Gauthier_S/0/1/0/all/0/1\">Samuel Deslauriers-Gauthier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1\">Xinjun Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiangyang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farina_D/0/1/0/all/0/1\">Dario Farina</a>",
          "description": "Numerical models of electromyographic (EMG) signals have provided a huge\ncontribution to our fundamental understanding of human neurophysiology and\nremain a central pillar of motor neuroscience and the development of\nhuman-machine interfaces. However, whilst modern biophysical simulations based\non finite element methods are highly accurate, they are extremely\ncomputationally expensive and thus are generally limited to modelling static\nsystems such as isometrically contracting limbs. As a solution to this problem,\nwe propose a transfer learning approach, in which a conditional generative\nmodel is trained to mimic the output of an advanced numerical model. To this\nend, we present BioMime, a conditional generative neural network trained\nadversarially to generate motor unit activation potential waveforms under a\nwide variety of volume conductor parameters. We demonstrate the ability of such\na model to predictively interpolate between a much smaller number of numerical\nmodel's outputs with a high accuracy. Consequently, the computational load is\ndramatically reduced, which allows the rapid simulation of EMG signals during\ntruly dynamic and naturalistic movements.",
          "link": "http://arxiv.org/abs/2211.01856",
          "publishedOn": "2023-10-07T00:42:19.281Z",
          "wordCount": null,
          "title": "Conditional Generative Models for Simulation of EMG During Naturalistic Movements. (arXiv:2211.01856v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03281",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_Y/0/1/0/all/0/1\">Yanyi Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yupeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaixuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yue Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_L/0/1/0/all/0/1\">Le Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jason Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>",
          "description": "The 5' UTR, a regulatory region at the beginning of an mRNA molecule, plays a\ncrucial role in regulating the translation process and impacts the protein\nexpression level. Language models have showcased their effectiveness in\ndecoding the functions of protein and genome sequences. Here, we introduced a\nlanguage model for 5' UTR, which we refer to as the UTR-LM. The UTR-LM is\npre-trained on endogenous 5' UTRs from multiple species and is further\naugmented with supervised information including secondary structure and minimum\nfree energy. We fine-tuned the UTR-LM in a variety of downstream tasks. The\nmodel outperformed the best-known benchmark by up to 42% for predicting the\nMean Ribosome Loading, and by up to 60% for predicting the Translation\nEfficiency and the mRNA Expression Level. The model also applies to identifying\nunannotated Internal Ribosome Entry Sites within the untranslated region and\nimproves the AUPR from 0.37 to 0.52 compared to the best baseline. Further, we\ndesigned a library of 211 novel 5' UTRs with high predicted values of\ntranslation efficiency and evaluated them via a wet-lab assay. Experiment\nresults confirmed that our top designs achieved a 32.5% increase in protein\nproduction level relative to well-established 5' UTR optimized for\ntherapeutics.",
          "link": "http://arxiv.org/abs/2310.03281",
          "publishedOn": "2023-10-07T00:42:19.280Z",
          "wordCount": null,
          "title": "A 5' UTR Language Model for Decoding Untranslated Regions of mRNA and Function Predictions. (arXiv:2310.03281v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hellsten_E/0/1/0/all/0/1\">Erik Orm Hellsten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hvarfner_C/0/1/0/all/0/1\">Carl Hvarfner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papenmeier_L/0/1/0/all/0/1\">Leonard Papenmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nardi_L/0/1/0/all/0/1\">Luigi Nardi</a>",
          "description": "Bayesian optimization is an effective method for optimizing\nexpensive-to-evaluate black-box functions. High-dimensional problems are\nparticularly challenging as the surrogate model of the objective suffers from\nthe curse of dimensionality, which makes accurate modeling difficult. We\npropose a group testing approach to identify active variables to facilitate\nefficient optimization in these domains. The proposed algorithm, Group Testing\nBayesian Optimization (GTBO), first runs a testing phase where groups of\nvariables are systematically selected and tested on whether they influence the\nobjective. To that end, we extend the well-established theory of group testing\nto functions of continuous ranges. In the second phase, GTBO guides\noptimization by placing more importance on the active dimensions. By exploiting\nthe axis-aligned subspace assumption, GTBO is competitive against\nstate-of-the-art methods on several synthetic and real-world high-dimensional\noptimization tasks. Furthermore, GTBO aids in the discovery of active\nparameters in applications, thereby enhancing practitioners' understanding of\nthe problem at hand.",
          "link": "http://arxiv.org/abs/2310.03515",
          "publishedOn": "2023-10-07T00:42:19.280Z",
          "wordCount": null,
          "title": "High-dimensional Bayesian Optimization with Group Testing. (arXiv:2310.03515v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1\">Rachid Guerraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1\">Nirupam Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinot_R/0/1/0/all/0/1\">Rafael Pinot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouault_S/0/1/0/all/0/1\">Sebastien Rouault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stephan_J/0/1/0/all/0/1\">John Stephan</a>",
          "description": "Privacy and Byzantine resilience (BR) are two crucial requirements of\nmodern-day distributed machine learning. The two concepts have been extensively\nstudied individually but the question of how to combine them effectively\nremains unanswered. This paper contributes to addressing this question by\nstudying the extent to which the distributed SGD algorithm, in the standard\nparameter-server architecture, can learn an accurate model despite (a) a\nfraction of the workers being malicious (Byzantine), and (b) the other\nfraction, whilst being honest, providing noisy information to the server to\nensure differential privacy (DP). We first observe that the integration of\nstandard practices in DP and BR is not straightforward. In fact, we show that\nmany existing results on the convergence of distributed SGD under Byzantine\nfaults, especially those relying on $(\\alpha,f)$-Byzantine resilience, are\nrendered invalid when honest workers enforce DP. To circumvent this\nshortcoming, we revisit the theory of $(\\alpha,f)$-BR to obtain an approximate\nconvergence guarantee. Our analysis provides key insights on how to improve\nthis guarantee through hyperparameter optimization. Essentially, our\ntheoretical and empirical results show that (1) an imprudent combination of\nstandard approaches to DP and BR might be fruitless, but (2) by carefully\nre-tuning the learning algorithm, we can obtain reasonable learning accuracy\nwhile simultaneously guaranteeing DP and BR.",
          "link": "http://arxiv.org/abs/2110.03991",
          "publishedOn": "2023-10-07T00:42:19.280Z",
          "wordCount": null,
          "title": "Combining Differential Privacy and Byzantine Resilience in Distributed SGD. (arXiv:2110.03991v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03302",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vora_J/0/1/0/all/0/1\">Jian Vora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1\">Jure Leskovec</a>",
          "description": "Scientific experimentation involves an iterative process of creating\nhypotheses, designing experiments, running experiments, and analyzing the\nresults. Can we build AI research agents to perform these long-horizon tasks?\nTo take a step towards building and evaluating research agents on such\nopen-ended decision-making tasks, we focus on the problem of machine learning\nengineering: given a task description and a dataset, build a high-performing\nmodel. In this paper, we propose MLAgentBench, a suite of ML tasks for\nbenchmarking AI research agents. Agents can perform actions like\nreading/writing files, executing code, and inspecting outputs. With these\nactions, agents could run experiments, analyze the results, and modify the code\nof entire machine learning pipelines, such as data processing, architecture,\ntraining processes, etc. The benchmark then automatically evaluates the agent's\nperformance objectively over various metrics related to performance and\nefficiency. We also design an LLM-based research agent to automatically perform\nexperimentation loops in such an environment. Empirically, we find that a\nGPT-4-based research agent can feasibly build compelling ML models over many\ntasks in MLAgentBench, displaying highly interpretable plans and actions.\nHowever, the success rates vary considerably; they span from almost 90\\% on\nwell-established older datasets to as low as 10\\% on recent Kaggle Challenges\n-- unavailable during the LLM model's pretraining -- and even 0\\% on newer\nresearch challenges like BabyLM. Finally, we identify several key challenges\nfor LLM-based research agents such as long-term planning and hallucination. Our\ncode is released at https://github.com/snap-stanford/MLAgentBench.",
          "link": "http://arxiv.org/abs/2310.03302",
          "publishedOn": "2023-10-07T00:42:19.279Z",
          "wordCount": null,
          "title": "Benchmarking Large Language Models As AI Research Agents. (arXiv:2310.03302v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06715",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Crabbe_J/0/1/0/all/0/1\">Jonathan Crabb&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Interpretability methods are valuable only if their explanations faithfully\ndescribe the explained model. In this work, we consider neural networks whose\npredictions are invariant under a specific symmetry group. This includes\npopular architectures, ranging from convolutional to graph neural networks. Any\nexplanation that faithfully explains this type of model needs to be in\nagreement with this invariance property. We formalize this intuition through\nthe notion of explanation invariance and equivariance by leveraging the\nformalism from geometric deep learning. Through this rigorous formalism, we\nderive (1) two metrics to measure the robustness of any interpretability method\nwith respect to the model symmetry group; (2) theoretical robustness guarantees\nfor some popular interpretability methods and (3) a systematic approach to\nincrease the invariance of any interpretability method with respect to a\nsymmetry group. By empirically measuring our metrics for explanations of models\nassociated with various modalities and symmetry groups, we derive a set of 5\nguidelines to allow users and developers of interpretability methods to produce\nrobust explanations.",
          "link": "http://arxiv.org/abs/2304.06715",
          "publishedOn": "2023-10-07T00:42:19.279Z",
          "wordCount": null,
          "title": "Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance. (arXiv:2304.06715v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03388",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rabino_P/0/1/0/all/0/1\">Paolo Rabino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alliegro_A/0/1/0/all/0/1\">Antonio Alliegro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borlino_F/0/1/0/all/0/1\">Francesco Cappio Borlino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tommasi_T/0/1/0/all/0/1\">Tatiana Tommasi</a>",
          "description": "Moving deep learning models from the laboratory setting to the open world\nentails preparing them to handle unforeseen conditions. In several applications\nthe occurrence of novel classes during deployment poses a significant threat,\nthus it is crucial to effectively detect them. Ideally, this skill should be\nused when needed without requiring any further computational training effort at\nevery new task. Out-of-distribution detection has attracted significant\nattention in the last years, however the majority of the studies deal with 2D\nimages ignoring the inherent 3D nature of the real-world and often confusing\nbetween domain and semantic novelty. In this work, we focus on the latter,\nconsidering the objects geometric structure captured by 3D point clouds\nregardless of the specific domain. We advance the field by introducing\nOpenPatch that builds on a large pre-trained model and simply extracts from its\nintermediate features a set of patch representations that describe each known\nclass. For any new sample, we obtain a novelty score by evaluating whether it\ncan be recomposed mainly by patches of a single known class or rather via the\ncontribution of multiple classes. We present an extensive experimental\nevaluation of our approach for the task of semantic novelty detection on\nreal-world point cloud samples when the reference known data are synthetic. We\ndemonstrate that OpenPatch excels in both the full and few-shot known sample\nscenarios, showcasing its robustness across varying pre-training objectives and\nnetwork backbones. The inherent training-free nature of our method allows for\nits immediate application to a wide array of real-world tasks, offering a\ncompelling advantage over approaches that need expensive retraining efforts.",
          "link": "http://arxiv.org/abs/2310.03388",
          "publishedOn": "2023-10-07T00:42:19.278Z",
          "wordCount": null,
          "title": "OpenPatch: a 3D patchwork for Out-Of-Distribution detectionpdf icon. (arXiv:2310.03388v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.01944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Darabi_S/0/1/0/all/0/1\">Sajad Darabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bigaj_P/0/1/0/all/0/1\">Piotr Bigaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majchrowski_D/0/1/0/all/0/1\">Dawid Majchrowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasymov_A/0/1/0/all/0/1\">Artur Kasymov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morkisz_P/0/1/0/all/0/1\">Pawel Morkisz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fit_Florea_A/0/1/0/all/0/1\">Alex Fit-Florea</a>",
          "description": "Recently there has been increasing interest in developing and deploying deep\ngraph learning algorithms for many tasks, such as fraud detection and\nrecommender systems. Albeit, there is a limited number of publicly available\ngraph-structured datasets, most of which are tiny compared to production-sized\napplications or are limited in their application domain. This work tackles this\nshortcoming by proposing a scalable synthetic graph generation tool to scale\nthe datasets to production-size graphs with trillions of edges and billions of\nnodes. The tool learns a series of parametric models from proprietary datasets\nthat can be released to researchers to study various graph methods on the\nsynthetic data increasing prototype development and novel applications. We\ndemonstrate the generalizability of the framework across a series of datasets,\nmimicking structural and feature distributions as well as the ability to scale\nthem across varying sizes demonstrating their usefulness for benchmarking and\nmodel development. Code can be found on\nhttps://github.com/NVIDIA/DeepLearningExamples/tree/master/Tools/DGLPyTorch/SyntheticGraphGeneration.",
          "link": "http://arxiv.org/abs/2210.01944",
          "publishedOn": "2023-10-07T00:42:19.277Z",
          "wordCount": null,
          "title": "A Framework for Large Scale Synthetic Graph Dataset Generation. (arXiv:2210.01944v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.00635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Si Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Daliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasik_M/0/1/0/all/0/1\">Michal Lukasik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Felix Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1\">Inderjit S Dhillon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>",
          "description": "Pretrained large language models (LLMs) are general purpose problem solvers\napplicable to a diverse set of tasks with prompts. They can be further improved\ntowards a specific task by fine-tuning on a specialized dataset. However,\nfine-tuning usually makes the model narrowly specialized on this dataset with\nreduced general in-context learning performances, which is undesirable whenever\nthe fine-tuned model needs to handle additional tasks where no fine-tuning data\nis available. In this work, we first demonstrate that fine-tuning on a single\ntask indeed decreases LLMs' general in-context learning performance. We\ndiscover one important cause of such forgetting, format specialization, where\nthe model overfits to the format of the fine-tuned task. We further show that\nformat specialization happens at the very beginning of fine-tuning. To solve\nthis problem, we propose Prompt Tuning with MOdel Tuning (ProMoT), a simple yet\neffective two-stage fine-tuning framework that reduces format specialization\nand improves generalization. ProMoT offloads task-specific format learning into\nadditional and removable parameters by first doing prompt tuning and then\nfine-tuning the model itself with this soft prompt attached. With experiments\non several fine-tuning tasks and 8 in-context evaluation tasks, we show that\nProMoT achieves comparable performance on fine-tuned tasks to standard\nfine-tuning, but with much less loss of in-context learning performances across\na board range of out-of-domain evaluation tasks. More importantly, ProMoT can\neven enhance generalization on in-context learning tasks that are semantically\nrelated to the fine-tuned task, e.g. ProMoT on En-Fr translation significantly\nimproves performance on other language pairs, and ProMoT on NLI improves\nperformance on summarization. Experiments also show that ProMoT can improve the\ngeneralization performance of multi-task training.",
          "link": "http://arxiv.org/abs/2211.00635",
          "publishedOn": "2023-10-07T00:42:19.276Z",
          "wordCount": null,
          "title": "Two-stage LLM Fine-tuning with Less Specialization and More Generalization. (arXiv:2211.00635v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04333",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Boya Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weijian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihua Zhang</a>",
          "description": "Adversarial attacks have the potential to mislead deep neural network\nclassifiers by introducing slight perturbations. Developing algorithms that can\nmitigate the effects of these attacks is crucial for ensuring the safe use of\nartificial intelligence. Recent studies have suggested that score-based\ndiffusion models are effective in adversarial defenses. However, existing\ndiffusion-based defenses rely on the sequential simulation of the reversed\nstochastic differential equations of diffusion models, which are\ncomputationally inefficient and yield suboptimal results. In this paper, we\nintroduce a novel adversarial defense scheme named ScoreOpt, which optimizes\nadversarial samples at test-time, towards original clean data in the direction\nguided by score-based priors. We conduct comprehensive experiments on multiple\ndatasets, including CIFAR10, CIFAR100 and ImageNet. Our experimental results\ndemonstrate that our approach outperforms existing adversarial defenses in\nterms of both robustness performance and inference speed.",
          "link": "http://arxiv.org/abs/2307.04333",
          "publishedOn": "2023-10-07T00:42:19.276Z",
          "wordCount": null,
          "title": "Enhancing Adversarial Robustness via Score-Based Optimization. (arXiv:2307.04333v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Postovan_A/0/1/0/all/0/1\">Andreea Postovan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erascu_M/0/1/0/all/0/1\">M&#x103;d&#x103;lina Era&#x15f;cu</a>",
          "description": "Traffic signs play a critical role in road safety and traffic management for\nautonomous driving systems. Accurate traffic sign classification is essential\nbut challenging due to real-world complexities like adversarial examples and\nocclusions. To address these issues, binary neural networks offer promise in\nconstructing classifiers suitable for resource-constrained devices.\n\nIn our previous work, we proposed high-accuracy BNN models for traffic sign\nrecognition, focusing on compact size for limited computation and energy\nresources. To evaluate their local robustness, this paper introduces a set of\nbenchmark problems featuring layers that challenge state-of-the-art\nverification tools. These layers include binarized convolutions, max pooling,\nbatch normalization, fully connected. The difficulty of the verification\nproblem is given by the high number of network parameters (905k - 1.7 M), of\nthe input dimension (2.7k-12k), and of the number of regions (43) as well by\nthe fact that the neural networks are not sparse.\n\nThe proposed BNN models and local robustness properties can be checked at\nhttps://github.com/ChristopherBrix/vnncomp2023_benchmarks/tree/main/benchmarks/traffic_signs_recognition.\n\nThe results of the 4th International Verification of Neural Networks\nCompetition (VNN-COMP'23) revealed the fact that 4, out of 7, solvers can\nhandle many of our benchmarks randomly selected (minimum is 6, maximum is 36,\nout of 45). Surprisingly, tools output also wrong results or missing\ncounterexample (ranging from 1 to 4). Currently, our focus lies in exploring\nthe possibility of achieving a greater count of solved instances by extending\nthe allotted time (previously set at 8 minutes). Furthermore, we are intrigued\nby the reasons behind the erroneous outcomes provided by the tools for certain\nbenchmarks.",
          "link": "http://arxiv.org/abs/2310.03033",
          "publishedOn": "2023-10-07T00:42:19.275Z",
          "wordCount": null,
          "title": "Benchmarking Local Robustness of High-Accuracy Binary Neural Networks for Enhanced Traffic Sign Recognition. (arXiv:2310.03033v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ebadi_A/0/1/0/all/0/1\">Ali Ebadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahafizadeh_E/0/1/0/all/0/1\">Ebrahim Sahafizadeh</a>",
          "description": "This literature review aimed to compare various time-series analysis\napproaches utilized in forecasting COVID-19 cases in Africa. The study involved\na methodical search for English-language research papers published between\nJanuary 2020 and July 2023, focusing specifically on papers that utilized\ntime-series analysis approaches on COVID-19 datasets in Africa. A variety of\ndatabases including PubMed, Google Scholar, Scopus, and Web of Science were\nutilized for this process. The research papers underwent an evaluation process\nto extract relevant information regarding the implementation and performance of\nthe time-series analysis models. The study highlighted the different\nmethodologies employed, evaluating their effectiveness and limitations in\nforecasting the spread of the virus. The result of this review could contribute\ndeeper insights into the field, and future research should consider these\ninsights to improve time series analysis models and explore the integration of\ndifferent approaches for enhanced public health decision-making.",
          "link": "http://arxiv.org/abs/2310.03606",
          "publishedOn": "2023-10-07T00:42:19.275Z",
          "wordCount": null,
          "title": "Comparing Time-Series Analysis Approaches Utilized in Research Papers to Forecast COVID-19 Cases in Africa: A Literature Review. (arXiv:2310.03606v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03243",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1\">Mingxuan Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yan Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liang_F/0/1/0/all/0/1\">Faming Liang</a>",
          "description": "Sparse deep learning has become a popular technique for improving the\nperformance of deep neural networks in areas such as uncertainty\nquantification, variable selection, and large-scale network compression.\nHowever, most existing research has focused on problems where the observations\nare independent and identically distributed (i.i.d.), and there has been little\nwork on the problems where the observations are dependent, such as time series\ndata and sequential data in natural language processing. This paper aims to\naddress this gap by studying the theory for sparse deep learning with dependent\ndata. We show that sparse recurrent neural networks (RNNs) can be consistently\nestimated, and their predictions are asymptotically normally distributed under\nappropriate assumptions, enabling the prediction uncertainty to be correctly\nquantified. Our numerical results show that sparse deep learning outperforms\nstate-of-the-art methods, such as conformal predictions, in prediction\nuncertainty quantification for time series data. Furthermore, our results\nindicate that the proposed method can consistently identify the autoregressive\norder for time series data and outperform existing methods in large-scale model\ncompression. Our proposed method has important practical implications in fields\nsuch as finance, healthcare, and energy, where both accurate point estimates\nand prediction uncertainty quantification are of concern.",
          "link": "http://arxiv.org/abs/2310.03243",
          "publishedOn": "2023-10-07T00:42:19.271Z",
          "wordCount": null,
          "title": "Sparse Deep Learning for Time Series Data: Theory and Applications. (arXiv:2310.03243v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_N/0/1/0/all/0/1\">Nuoyan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Decheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Dawei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinbo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nannan Wang</a>",
          "description": "Deep neural networks are vulnerable to adversarial noise. Adversarial\ntraining (AT) has been demonstrated to be the most effective defense strategy\nto protect neural networks from being fooled. However, we find AT omits to\nlearning robust features, resulting in poor performance of adversarial\nrobustness. To address this issue, we highlight two characteristics of robust\nrepresentation: (1) $\\bf{exclusion}$: the feature of natural examples keeps\naway from that of other classes; (2) $\\bf{alignment}$: the feature of natural\nand corresponding adversarial examples is close to each other. These motivate\nus to propose a generic framework of AT to gain robust representation, by the\nasymmetric negative contrast and reverse attention. Specifically, we design an\nasymmetric negative contrast based on predicted probabilities, to push away\nexamples of different classes in the feature space. Moreover, we propose to\nweight feature by parameters of the linear classifier as the reverse attention,\nto obtain class-aware feature and pull close the feature of the same class.\nEmpirical evaluations on three benchmark datasets show our methods greatly\nadvance the robustness of AT and achieve state-of-the-art performance. Code is\navailable at <https://github.com/changzhang777/ANCRA>.",
          "link": "http://arxiv.org/abs/2310.03358",
          "publishedOn": "2023-10-07T00:42:19.270Z",
          "wordCount": null,
          "title": "Robust Representation Learning via Asymmetric Negative Contrast and Reverse Attention. (arXiv:2310.03358v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.14883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shenggui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_Z/0/1/0/all/0/1\">Zhengda Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1\">Jiarui Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haichen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>",
          "description": "The success of Transformer models has pushed the deep learning model scale to\nbillions of parameters. Due to the limited memory resource of a single GPU,\nHowever, the best practice for choosing the optimal parallel strategy is still\nlacking, since it requires domain expertise in both deep learning and parallel\ncomputing.\n\nThe Colossal-AI system addressed the above challenge by introducing a unified\ninterface to scale your sequential code of model training to distributed\nenvironments. It supports parallel training methods such as data, pipeline,\ntensor, and sequence parallelism, as well as heterogeneous training methods\nintegrated with zero redundancy optimizer. Compared to the baseline system,\nColossal-AI can achieve up to 2.76 times training speedup on large-scale\nmodels.",
          "link": "http://arxiv.org/abs/2110.14883",
          "publishedOn": "2023-10-07T00:42:19.269Z",
          "wordCount": null,
          "title": "Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training. (arXiv:2110.14883v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Assel_H/0/1/0/all/0/1\">Hugues Van Assel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_Cuaz_C/0/1/0/all/0/1\">C&#xe9;dric Vincent-Cuaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vayer_T/0/1/0/all/0/1\">Titouan Vayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flamary_R/0/1/0/all/0/1\">R&#xe9;mi Flamary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courty_N/0/1/0/all/0/1\">Nicolas Courty</a>",
          "description": "We present a versatile adaptation of existing dimensionality reduction (DR)\nobjectives, enabling the simultaneous reduction of both sample and feature\nsizes. Correspondances between input and embedding samples are computed through\na semi-relaxed Gromov-Wasserstein optimal transport (OT) problem. When the\nembedding sample size matches that of the input, our model recovers classical\npopular DR models. When the embedding's dimensionality is unconstrained, we\nshow that the OT plan delivers a competitive hard clustering. We emphasize the\nimportance of intermediate stages that blend DR and clustering for summarizing\nreal data and apply our method to visualize datasets of images.",
          "link": "http://arxiv.org/abs/2310.03398",
          "publishedOn": "2023-10-07T00:42:19.268Z",
          "wordCount": null,
          "title": "Interpolating between Clustering and Dimensionality Reduction with Gromov-Wasserstein. (arXiv:2310.03398v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03456",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fish_E/0/1/0/all/0/1\">Edward Fish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinbren_J/0/1/0/all/0/1\">Jon Weinbren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilbert_A/0/1/0/all/0/1\">Andrew Gilbert</a>",
          "description": "Temporal Action Localization (TAL) aims to identify actions' start, end, and\nclass labels in untrimmed videos. While recent advancements using transformer\nnetworks and Feature Pyramid Networks (FPN) have enhanced visual feature\nrecognition in TAL tasks, less progress has been made in the integration of\naudio features into such frameworks. This paper introduces the Multi-Resolution\nAudio-Visual Feature Fusion (MRAV-FF), an innovative method to merge\naudio-visual data across different temporal resolutions. Central to our\napproach is a hierarchical gated cross-attention mechanism, which discerningly\nweighs the importance of audio information at diverse temporal scales. Such a\ntechnique not only refines the precision of regression boundaries but also\nbolsters classification confidence. Importantly, MRAV-FF is versatile, making\nit compatible with existing FPN TAL architectures and offering a significant\nenhancement in performance when audio data is available.",
          "link": "http://arxiv.org/abs/2310.03456",
          "publishedOn": "2023-10-07T00:42:19.267Z",
          "wordCount": null,
          "title": "Multi-Resolution Audio-Visual Feature Fusion for Temporal Action Localization. (arXiv:2310.03456v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>",
          "description": "The theoretical landscape of federated learning (FL) undergoes rapid\nevolution, but its practical application encounters a series of intricate\nchallenges, and hyperparameter optimization is one of these critical\nchallenges. Amongst the diverse adjustments in hyperparameters, the adaptation\nof the learning rate emerges as a crucial component, holding the promise of\nsignificantly enhancing the efficacy of FL systems. In response to this\ncritical need, this paper presents FedHyper, a novel hypergradient-based\nlearning rate adaptation algorithm specifically designed for FL. FedHyper\nserves as a universal learning rate scheduler that can adapt both global and\nlocal rates as the training progresses. In addition, FedHyper not only\nshowcases unparalleled robustness to a spectrum of initial learning rate\nconfigurations but also significantly alleviates the necessity for laborious\nempirical learning rate adjustments. We provide a comprehensive theoretical\nanalysis of FedHyper's convergence rate and conduct extensive experiments on\nvision and language benchmark datasets. The results demonstrate that FEDHYPER\nconsistently converges 1.1-3x faster than FedAvg and the competing baselines\nwhile achieving superior final accuracy. Moreover, FedHyper catalyzes a\nremarkable surge in accuracy, augmenting it by up to 15% compared to FedAvg\nunder suboptimal initial learning rate settings.",
          "link": "http://arxiv.org/abs/2310.03156",
          "publishedOn": "2023-10-07T00:42:19.264Z",
          "wordCount": null,
          "title": "FedHyper: A Universal and Robust Learning Rate Scheduler for Federated Learning with Hypergradient Descent. (arXiv:2310.03156v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berezin_S/0/1/0/all/0/1\">Sergey Berezin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahbakhsh_R/0/1/0/all/0/1\">Reza Farahbakhsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crespi_N/0/1/0/all/0/1\">Noel Crespi</a>",
          "description": "The fundamental problem in toxicity detection task lies in the fact that the\ntoxicity is ill-defined. This causes us to rely on subjective and vague data in\nmodels' training, which results in non-robust and non-accurate results: garbage\nin - garbage out.\n\nThis work suggests a new, stress-level-based definition of toxicity designed\nto be objective and context-aware. On par with it, we also describe possible\nways of applying this new definition to dataset creation and model training.",
          "link": "http://arxiv.org/abs/2310.02357",
          "publishedOn": "2023-10-07T00:42:19.263Z",
          "wordCount": null,
          "title": "On the definition of toxicity in NLP. (arXiv:2310.02357v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.16887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_G/0/1/0/all/0/1\">Guan Zhe Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yin Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuxman_A/0/1/0/all/0/1\">Ariel Fuxman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_S/0/1/0/all/0/1\">Stanley H. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_E/0/1/0/all/0/1\">Enming Luo</a>",
          "description": "In this paper, we study how the granularity of pretraining labels affects the\ngeneralization of deep neural networks in image classification tasks. We focus\non the \"fine-to-coarse\" transfer learning setting, where the pretraining label\nspace is more fine-grained than that of the target problem. Empirically, we\nshow that pretraining on the leaf labels of ImageNet21k produces better\ntransfer results on ImageNet1k than pretraining on other coarser granularity\nlevels, which supports the common practice used in the community.\nTheoretically, we explain the benefit of fine-grained pretraining by proving\nthat, for a data distribution satisfying certain hierarchy conditions, 1)\ncoarse-grained pretraining only allows a neural network to learn the \"common\"\nor \"easy-to-learn\" features well, while 2) fine-grained pretraining helps the\nnetwork learn the \"rarer\" or \"fine-grained\" features in addition to the common\nones, thus improving its accuracy on hard downstream test samples in which\ncommon features are missing or weak in strength. Furthermore, we perform\ncomprehensive experiments using the label hierarchies of iNaturalist 2021 and\nobserve that the following conditions, in addition to proper choice of label\ngranularity, enable the transfer to work well in practice: 1) the pretraining\ndataset needs to have a meaningful label hierarchy, and 2) the pretraining and\ntarget label functions need to align well.",
          "link": "http://arxiv.org/abs/2303.16887",
          "publishedOn": "2023-10-07T00:42:19.262Z",
          "wordCount": null,
          "title": "Towards Understanding the Effect of Pretraining Label Granularity. (arXiv:2303.16887v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1\">Hyosoon Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Sungsoo Ahn</a>",
          "description": "This paper studies generative flow networks (GFlowNets) to sample objects\nfrom the Boltzmann energy distribution via a sequence of actions. In\nparticular, we focus on improving GFlowNet with partial inference: training\nflow functions with the evaluation of the intermediate states or transitions.\nTo this end, the recently developed forward-looking GFlowNet reparameterizes\nthe flow functions based on evaluating the energy of intermediate states.\nHowever, such an evaluation of intermediate energies may (i) be too expensive\nor impossible to evaluate and (ii) even provide misleading training signals\nunder large energy fluctuations along the sequence of actions. To resolve this\nissue, we propose learning energy decompositions for GFlowNets (LED-GFN). Our\nmain idea is to (i) decompose the energy of an object into learnable potential\nfunctions defined on state transitions and (ii) reparameterize the flow\nfunctions using the potential functions. In particular, to produce informative\nlocal credits, we propose to regularize the potential to change smoothly over\nthe sequence of actions. It is also noteworthy that training GFlowNet with our\nlearned potential can preserve the optimal policy. We empirically verify the\nsuperiority of LED-GFN in five problems including the generation of\nunstructured and maximum independent sets, molecular graphs, and RNA sequences.",
          "link": "http://arxiv.org/abs/2310.03301",
          "publishedOn": "2023-10-07T00:42:19.261Z",
          "wordCount": null,
          "title": "Learning Energy Decompositions for Partial Inference of GFlowNets. (arXiv:2310.03301v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_Y/0/1/0/all/0/1\">Yuka Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>",
          "description": "We identify hidden layers inside a DNN with group actions on the data space,\nand formulate the DNN as a dual voice transform with respect to Koopman\noperator, a linear representation of the group action. Based on the group\ntheoretic arguments, particularly by using Schur's lemma, we show a simple\nproof of the universality of those DNNs.",
          "link": "http://arxiv.org/abs/2310.03529",
          "publishedOn": "2023-10-07T00:42:19.260Z",
          "wordCount": null,
          "title": "Deep Ridgelet Transform: Voice with Koopman Operator Proves Universality of Formal Deep Networks. (arXiv:2310.03529v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Altabaa_A/0/1/0/all/0/1\">Awni Altabaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lafferty_J/0/1/0/all/0/1\">John Lafferty</a>",
          "description": "A maturing area of research in deep learning is the development of\narchitectures that can learn explicit representations of relational features.\nIn this paper, we focus on the problem of learning representations of\nhierarchical relations, proposing an architectural framework we call\n\"relational convolutional networks\". Given a sequence of objects, a\n\"multi-dimensional inner product relation\" module produces a relation tensor\ndescribing all pairwise relations. A \"relational convolution\" layer then\ntransforms the relation tensor into a sequence of new objects, each describing\nthe relations within some group of objects at the previous layer. Graphlet\nfilters, analogous to filters in convolutional neural networks, represent a\ntemplate of relations against which the relation tensor is compared at each\ngrouping. Repeating this yields representations of higher-order, hierarchical\nrelations. We present the motivation and details of the architecture, together\nwith a set of experiments to demonstrate how relational convolutional networks\ncan provide an effective framework for modeling relational tasks that have\nhierarchical structure.",
          "link": "http://arxiv.org/abs/2310.03240",
          "publishedOn": "2023-10-07T00:42:19.257Z",
          "wordCount": null,
          "title": "Relational Convolutional Networks: A framework for learning representations of hierarchical relations. (arXiv:2310.03240v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vallin_J/0/1/0/all/0/1\">Jonatan Vallin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larsson_K/0/1/0/all/0/1\">Karl Larsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larson_M/0/1/0/all/0/1\">Mats G. Larson</a>",
          "description": "We formalize and interpret the geometric structure of $d$-dimensional fully\nconnected ReLU-layers in neural networks. The parameters of a ReLU-layer induce\na natural partition of the input domain, such that in each sector of the\npartition, the ReLU-layer can be greatly simplified. This leads to a geometric\ninterpretation of a ReLU-layer as a projection onto a polyhedral cone followed\nby an affine transformation, in line with the description in\n[doi:10.48550/arXiv.1905.08922] for convolutional networks with ReLU\nactivations. Further, this structure facilitates simplified expressions for\npreimages of the intersection between partition sectors and hyperplanes, which\nis useful when describing decision boundaries in a classification setting. We\ninvestigate this in detail for a feed-forward network with one hidden\nReLU-layer, where we provide results on the geometric complexity of the\ndecision boundary generated by such networks, as well as proving that modulo an\naffine transformation, such a network can only generate $d$ different decision\nboundaries. Finally, the effect of adding more layers to the network is\ndiscussed.",
          "link": "http://arxiv.org/abs/2310.03482",
          "publishedOn": "2023-10-07T00:42:19.228Z",
          "wordCount": null,
          "title": "The Geometric Structure of Fully-Connected ReLU-Layers. (arXiv:2310.03482v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yongqiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1\">Yang Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weijiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">James Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1\">Hanghang Tong</a>",
          "description": "Machine Learning (ML) techniques have found applications in estimating\nchemical kinetics properties. With the accumulated drug molecules identified\nthrough \"AI4drug discovery\", the next imperative lies in AI-driven design for\nhigh-throughput chemical synthesis processes, with the estimation of properties\nof unseen reactions with unexplored molecules. To this end, the existing ML\napproaches for kinetics property prediction are required to be\nOut-Of-Distribution (OOD) generalizable. In this paper, we categorize the OOD\nkinetic property prediction into three levels (structure, condition, and\nmechanism), revealing unique aspects of such problems. Under this framework, we\ncreate comprehensive datasets to benchmark (1) the state-of-the-art ML\napproaches for reaction prediction in the OOD setting and (2) the\nstate-of-the-art graph OOD methods in kinetics property prediction problems.\nOur results demonstrated the challenges and opportunities in OOD kinetics\nproperty prediction. Our datasets and benchmarks can further support research\nin this direction.",
          "link": "http://arxiv.org/abs/2310.03152",
          "publishedOn": "2023-10-07T00:42:19.227Z",
          "wordCount": null,
          "title": "Towards out-of-distribution generalizable predictions of chemical kinetics properties. (arXiv:2310.03152v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03112",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Herbinger_J/0/1/0/all/0/1\">Julia Herbinger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dandl_S/0/1/0/all/0/1\">Susanne Dandl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ewald_F/0/1/0/all/0/1\">Fiona K. Ewald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Loibl_S/0/1/0/all/0/1\">Sofia Loibl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Casalicchio_G/0/1/0/all/0/1\">Giuseppe Casalicchio</a>",
          "description": "Surrogate models play a crucial role in retrospectively interpreting complex\nand powerful black box machine learning models via model distillation. This\npaper focuses on using model-based trees as surrogate models which partition\nthe feature space into interpretable regions via decision rules. Within each\nregion, interpretable models based on additive main effects are used to\napproximate the behavior of the black box model, striking for an optimal\nbalance between interpretability and performance. Four model-based tree\nalgorithms, namely SLIM, GUIDE, MOB, and CTree, are compared regarding their\nability to generate such surrogate models. We investigate fidelity,\ninterpretability, stability, and the algorithms' capability to capture\ninteraction effects through appropriate splits. Based on our comprehensive\nanalyses, we finally provide an overview of user-specific recommendations.",
          "link": "http://arxiv.org/abs/2310.03112",
          "publishedOn": "2023-10-07T00:42:19.225Z",
          "wordCount": null,
          "title": "Leveraging Model-based Trees as Interpretable Surrogate Models for Model Distillation. (arXiv:2310.03112v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saeed_M/0/1/0/all/0/1\">Muhammad Kamran Saeed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamal_A/0/1/0/all/0/1\">Ahmed E. Kamal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khokhar_A/0/1/0/all/0/1\">Ashfaq Khokhar</a>",
          "description": "Massive MIMO is expected to play an important role in the development of 5G\nnetworks. This paper addresses the issue of pilot contamination and scalability\nin massive MIMO systems. The current practice of reusing orthogonal pilot\nsequences in adjacent cells leads to difficulty in differentiating incoming\ninter- and intra-cell pilot sequences. One possible solution is to increase the\nnumber of orthogonal pilot sequences, which results in dedicating more space of\ncoherence block to pilot transmission than data transmission. This, in turn,\nalso hinders the scalability of massive MIMO systems, particularly in\naccommodating a large number of IoT devices within a cell. To overcome these\nchallenges, this paper devises an innovative pilot allocation scheme based on\nthe data transfer patterns of IoT devices. The scheme assigns orthogonal pilot\nsequences to clusters of devices instead of individual devices, allowing\nmultiple devices to utilize the same pilot for periodically transmitting data.\nMoreover, we formulate the pilot assignment problem as a graph coloring problem\nand use the max k-cut graph partitioning approach to overcome the pilot\ncontamination in a multicell massive MIMO system. The proposed scheme\nsignificantly improves the spectral efficiency and enables the scalability of\nmassive MIMO systems; for instance, by using ten orthogonal pilot sequences, we\nare able to accommodate 200 devices with only a 12.5% omission rate.",
          "link": "http://arxiv.org/abs/2310.03278",
          "publishedOn": "2023-10-07T00:42:19.225Z",
          "wordCount": null,
          "title": "Mitigating Pilot Contamination and Enabling IoT Scalability in Massive MIMO Systems. (arXiv:2310.03278v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1\">Deqian Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jianwen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "This paper proposes a latent prompt Transformer model for solving challenging\noptimization problems such as molecule design, where the goal is to find\nmolecules with optimal values of a target chemical or biological property that\ncan be computed by an existing software. Our proposed model consists of three\ncomponents. (1) A latent vector whose prior distribution is modeled by a Unet\ntransformation of a Gaussian white noise vector. (2) A molecule generation\nmodel that generates the string-based representation of molecule conditional on\nthe latent vector in (1). We adopt the causal Transformer model that takes the\nlatent vector in (1) as prompt. (3) A property prediction model that predicts\nthe value of the target property of a molecule based on a non-linear regression\non the latent vector in (1). We call the proposed model the latent prompt\nTransformer model. After initial training of the model on existing molecules\nand their property values, we then gradually shift the model distribution\ntowards the region that supports desired values of the target property for the\npurpose of molecule design. Our experiments show that our proposed model\nachieves state of the art performances on several benchmark molecule design\ntasks.",
          "link": "http://arxiv.org/abs/2310.03253",
          "publishedOn": "2023-10-07T00:42:19.224Z",
          "wordCount": null,
          "title": "Molecule Design by Latent Prompt Transformer. (arXiv:2310.03253v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Song Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1\">Xiangrui Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huestis_Mitchell_S/0/1/0/all/0/1\">Sarah A Huestis-Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Shixiang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xavier_A/0/1/0/all/0/1\">Alinson Santos Xavier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_F/0/1/0/all/0/1\">Feng Qiu</a>",
          "description": "Energy justice is a growing area of interest in interdisciplinary energy\nresearch. However, identifying systematic biases in the energy sector remains\nchallenging due to confounding variables, intricate heterogeneity in treatment\neffects, and limited data availability. To address these challenges, we\nintroduce a novel approach for counterfactual causal analysis centered on\nenergy justice. We use subgroup analysis to manage diverse factors and leverage\nthe idea of transfer learning to mitigate data scarcity in each subgroup. In\nour numerical analysis, we apply our method to a large-scale customer-level\npower outage data set and investigate the counterfactual effect of demographic\nfactors, such as income and age of the population, on power outage durations.\nOur results indicate that low-income and elderly-populated areas consistently\nexperience longer power outages, regardless of weather conditions. This points\nto existing biases in the power system and highlights the need for focused\nimprovements in areas with economic challenges.",
          "link": "http://arxiv.org/abs/2310.03258",
          "publishedOn": "2023-10-07T00:42:19.224Z",
          "wordCount": null,
          "title": "Detecting Electricity Service Equity Issues with Transfer Counterfactual Learning on Large-Scale Outage Datasets. (arXiv:2310.03258v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montaruli_B/0/1/0/all/0/1\">Biagio Montaruli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demetrio_L/0/1/0/all/0/1\">Luca Demetrio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1\">Maura Pintor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Compagna_L/0/1/0/all/0/1\">Luca Compagna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balzarotti_D/0/1/0/all/0/1\">Davide Balzarotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1\">Battista Biggio</a>",
          "description": "Machine-learning phishing webpage detectors (ML-PWD) have been shown to\nsuffer from adversarial manipulations of the HTML code of the input webpage.\nNevertheless, the attacks recently proposed have demonstrated limited\neffectiveness due to their lack of optimizing the usage of the adopted\nmanipulations, and they focus solely on specific elements of the HTML code. In\nthis work, we overcome these limitations by first designing a novel set of\nfine-grained manipulations which allow to modify the HTML code of the input\nphishing webpage without compromising its maliciousness and visual appearance,\ni.e., the manipulations are functionality- and rendering-preserving by design.\nWe then select which manipulations should be applied to bypass the target\ndetector by a query-efficient black-box optimization algorithm. Our experiments\nshow that our attacks are able to raze to the ground the performance of current\nstate-of-the-art ML-PWD using just 30 queries, thus overcoming the weaker\nattacks developed in previous work, and enabling a much fairer robustness\nevaluation of ML-PWD.",
          "link": "http://arxiv.org/abs/2310.03166",
          "publishedOn": "2023-10-07T00:42:19.222Z",
          "wordCount": null,
          "title": "Raze to the Ground: Query-Efficient Adversarial HTML Attacks on Machine-Learning Phishing Webpage Detectors. (arXiv:2310.03166v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Su Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durlofsky_L/0/1/0/all/0/1\">Louis J. Durlofsky</a>",
          "description": "History matching based on monitoring data will enable uncertainty reduction,\nand thus improved aquifer management, in industrial-scale carbon storage\noperations. In traditional model-based data assimilation, geomodel parameters\nare modified to force agreement between flow simulation results and\nobservations. In data-space inversion (DSI), history-matched quantities of\ninterest, e.g., posterior pressure and saturation fields conditioned to\nobservations, are inferred directly, without constructing posterior geomodels.\nThis is accomplished efficiently using a set of O(1000) prior simulation\nresults, data parameterization, and posterior sampling within a Bayesian\nsetting. In this study, we develop and implement (in DSI) a deep-learning-based\nparameterization to represent spatio-temporal pressure and CO2 saturation\nfields at a set of time steps. The new parameterization uses an adversarial\nautoencoder (AAE) for dimension reduction and a convolutional long short-term\nmemory (convLSTM) network to represent the spatial distribution and temporal\nevolution of the pressure and saturation fields. This parameterization is used\nwith an ensemble smoother with multiple data assimilation (ESMDA) in the DSI\nframework to enable posterior predictions. A realistic 3D system characterized\nby prior geological realizations drawn from a range of geological scenarios is\nconsidered. A local grid refinement procedure is introduced to estimate the\nerror covariance term that appears in the history matching formulation.\nExtensive history matching results are presented for various quantities, for\nmultiple synthetic true models. Substantial uncertainty reduction in posterior\npressure and saturation fields is achieved in all cases. The framework is\napplied to efficiently provide posterior predictions for a range of error\ncovariance specifications. Such an assessment would be expensive using a\nmodel-based approach.",
          "link": "http://arxiv.org/abs/2310.03228",
          "publishedOn": "2023-10-07T00:42:19.221Z",
          "wordCount": null,
          "title": "History Matching for Geological Carbon Storage using Data-Space Inversion with Spatio-Temporal Data Parameterization. (arXiv:2310.03228v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.14073",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saremi_M/0/1/0/all/0/1\">Mehrzad Saremi</a>",
          "description": "We propose a graphical structure for structural equation models that is\nstable under marginalization under linearity and Gaussianity assumptions. We\nshow that computing the maximum likelihood estimation of this model is\nequivalent to training a neural network. We implement a GPU-based algorithm\nthat computes the maximum likelihood estimation of these models.",
          "link": "http://arxiv.org/abs/2309.14073",
          "publishedOn": "2023-10-07T00:42:19.219Z",
          "wordCount": null,
          "title": "Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.11004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huayu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiwen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ditzler_G/0/1/0/all/0/1\">Gregory Ditzler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roveda_J/0/1/0/all/0/1\">Janet Roveda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ao Li</a>",
          "description": "Knowledge distillation constitutes a potent methodology for condensing\nsubstantial neural networks into more compact and efficient counterparts.\nWithin this context, softmax regression representation learning serves as a\nwidely embraced approach, leveraging a pre-established teacher network to guide\nthe learning process of a diminutive student network. Notably, despite the\nextensive inquiry into the efficacy of softmax regression representation\nlearning, the intricate underpinnings governing the knowledge transfer\nmechanism remain inadequately elucidated. This study introduces the 'Ideal\nJoint Classifier Knowledge Distillation' (IJCKD) framework, an overarching\nparadigm that not only furnishes a lucid and exhaustive comprehension of\nprevailing knowledge distillation techniques but also establishes a theoretical\nunderpinning for prospective investigations. Employing mathematical\nmethodologies derived from domain adaptation theory, this investigation\nconducts a comprehensive examination of the error boundary of the student\nnetwork contingent upon the teacher network. Consequently, our framework\nfacilitates efficient knowledge transference between teacher and student\nnetworks, thereby accommodating a diverse spectrum of applications.",
          "link": "http://arxiv.org/abs/2304.11004",
          "publishedOn": "2023-10-07T00:42:19.217Z",
          "wordCount": null,
          "title": "Knowledge Distillation Under Ideal Joint Classifier Assumption. (arXiv:2304.11004v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03288",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zherui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeow_R/0/1/0/all/0/1\">Raye Chen-Hua Yeow</a>",
          "description": "Real-time intelligent detection and prediction of subjects' behavior\nparticularly their movements or actions is critical in the ward. This approach\noffers the advantage of reducing in-hospital care costs and improving the\nefficiency of healthcare workers, which is especially true for scenarios at\nnight or during peak admission periods. Therefore, in this work, we propose\nusing computer vision (CV) and deep learning (DL) methods for detecting\nsubjects and recognizing their actions. We utilize OpenPose as an accurate\nsubject detector for recognizing the positions of human subjects in the video\nstream. Additionally, we employ AlphAction's Asynchronous Interaction\nAggregation (AIA) network to predict the actions of detected subjects. This\nintegrated model, referred to as PoseAction, is proposed. At the same time, the\nproposed model is further trained to predict 12 common actions in ward areas,\nsuch as staggering, chest pain, and falling down, using medical-related video\nclips from the NTU RGB+D and NTU RGB+D 120 datasets. The results demonstrate\nthat PoseAction achieves the highest classification mAP of 98.72% (IoU@0.5).\nAdditionally, this study develops an online real-time mode for action\nrecognition, which strongly supports the clinical translation of PoseAction.\nFurthermore, using OpenPose's function for recognizing face key points, we also\nimplement face blurring, which is a practical solution to address the privacy\nprotection concerns of patients and healthcare workers. Nevertheless, the\ntraining data for PoseAction is currently limited, particularly in terms of\nlabel diversity. Consequently, the subsequent step involves utilizing a more\ndiverse dataset (including general actions) to train the model's parameters for\nimproved generalization.",
          "link": "http://arxiv.org/abs/2310.03288",
          "publishedOn": "2023-10-07T00:42:19.212Z",
          "wordCount": null,
          "title": "PoseAction: Action Recognition for Patients in the Ward using Deep Learning Approaches. (arXiv:2310.03288v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangjun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bak_J/0/1/0/all/0/1\">JinYeong Bak</a>",
          "description": "Transformers have demonstrated their success in various domains and tasks.\nHowever, Transformers struggle with long input sequences due to their limited\ncapacity. While one solution is to increase input length, endlessly stretching\nthe length is unrealistic. Furthermore, humans selectively remember and use\nonly relevant information from inputs, unlike Transformers which process all\nraw data from start to end. We introduce Memoria, a general memory network that\napplies Hebbian theory which is a major theory explaining human memory\nformulation to enhance long-term dependencies in neural networks. Memoria\nstores and retrieves information called engram at multiple memory levels of\nworking memory, short-term memory, and long-term memory, using connection\nweights that change according to Hebb's rule. Through experiments with popular\nTransformer-based models like BERT and GPT, we present that Memoria\nsignificantly improves the ability to consider long-term dependencies in\nvarious tasks. Results show that Memoria outperformed existing methodologies in\nsorting and language modeling, and long text classification.",
          "link": "http://arxiv.org/abs/2310.03052",
          "publishedOn": "2023-10-07T00:42:19.211Z",
          "wordCount": null,
          "title": "Memoria: Hebbian Memory Architecture for Human-Like Sequential Processing. (arXiv:2310.03052v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_W/0/1/0/all/0/1\">William Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Medina_A/0/1/0/all/0/1\">Andr&#xe9;s Mu&#xf1;oz Medina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribero_M/0/1/0/all/0/1\">M&#xf3;nica Ribero</a>",
          "description": "Unsupervised pre-training is a common step in developing computer vision\nmodels and large language models. In this setting, the absence of labels\nrequires the use of similarity-based loss functions, such as contrastive loss,\nthat favor minimizing the distance between similar inputs and maximizing the\ndistance between distinct inputs. As privacy concerns mount, training these\nmodels using differential privacy has become more important. However, due to\nhow inputs are generated for these losses, one of their undesirable properties\nis that their $L_2$ sensitivity can grow with increasing batch size. This\nproperty is particularly disadvantageous for differentially private training\nmethods, such as DP-SGD. To overcome this issue, we develop a new DP-SGD\nvariant for similarity based loss functions -- in particular the commonly used\ncontrastive loss -- that manipulates gradients of the objective function in a\nnovel way to obtain a senstivity of the summed gradient that is $O(1)$ for\nbatch size $n$. We test our DP-SGD variant on some preliminary CIFAR-10\npre-training and CIFAR-100 finetuning tasks and show that, in both tasks, our\nmethod's performance comes close to that of a non-private model and generally\noutperforms DP-SGD applied directly to the contrastive loss.",
          "link": "http://arxiv.org/abs/2310.03104",
          "publishedOn": "2023-10-07T00:42:19.211Z",
          "wordCount": null,
          "title": "DP-SGD for non-decomposable objective functions. (arXiv:2310.03104v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Urchs_S/0/1/0/all/0/1\">Stefanie Urchs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thurner_V/0/1/0/all/0/1\">Veronika Thurner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assenmacher_M/0/1/0/all/0/1\">Matthias A&#xdf;enmacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heumann_C/0/1/0/all/0/1\">Christian Heumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiemichen_S/0/1/0/all/0/1\">Stephanie Thiemichen</a>",
          "description": "With the introduction of ChatGPT, OpenAI made large language models (LLM)\naccessible to users with limited IT expertise. However, users with no\nbackground in natural language processing (NLP) might lack a proper\nunderstanding of LLMs. Thus the awareness of their inherent limitations, and\ntherefore will take the systems' output at face value. In this paper, we\nsystematically analyse prompts and the generated responses to identify possible\nproblematic issues with a special focus on gender biases, which users need to\nbe aware of when processing the system's output. We explore how ChatGPT reacts\nin English and German if prompted to answer from a female, male, or neutral\nperspective. In an in-depth investigation, we examine selected prompts and\nanalyse to what extent responses differ if the system is prompted several times\nin an identical way. On this basis, we show that ChatGPT is indeed useful for\nhelping non-IT users draft texts for their daily work. However, it is\nabsolutely crucial to thoroughly check the system's responses for biases as\nwell as for syntactic and grammatical mistakes.",
          "link": "http://arxiv.org/abs/2310.03031",
          "publishedOn": "2023-10-07T00:42:19.208Z",
          "wordCount": null,
          "title": "How Prevalent is Gender Bias in ChatGPT? -- Exploring German and English ChatGPT Responses. (arXiv:2310.03031v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gondur_R/0/1/0/all/0/1\">Rabia Gondur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikandar_U/0/1/0/all/0/1\">Usama Bin Sikandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaffer_E/0/1/0/all/0/1\">Evan Schaffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aoi_M/0/1/0/all/0/1\">Mikio Christian Aoi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keeley_S/0/1/0/all/0/1\">Stephen L Keeley</a>",
          "description": "Characterizing the relationship between neural population activity and\nbehavioral data is a central goal of neuroscience. While latent variable models\n(LVMs) are successful in describing high-dimensional time-series data, they are\ntypically only designed for a single type of data, making it difficult to\nidentify structure shared across different experimental data modalities. Here,\nwe address this shortcoming by proposing an unsupervised LVM which extracts\ntemporally evolving shared and independent latents for distinct, simultaneously\nrecorded experimental modalities. We do this by combining Gaussian Process\nFactor Analysis (GPFA), an interpretable LVM for neural spiking data with\ntemporally smooth latent space, with Gaussian Process Variational Autoencoders\n(GP-VAEs), which similarly use a GP prior to characterize correlations in a\nlatent space, but admit rich expressivity due to a deep neural network mapping\nto observations. We achieve interpretability in our model by partitioning\nlatent variability into components that are either shared between or\nindependent to each modality. We parameterize the latents of our model in the\nFourier domain, and show improved latent identification using this approach\nover standard GP-VAE methods. We validate our model on simulated multi-modal\ndata consisting of Poisson spike counts and MNIST images that scale and rotate\nsmoothly over time. We show that the multi-modal GP-VAE (MM-GPVAE) is able to\nnot only identify the shared and independent latent structure across modalities\naccurately, but provides good reconstructions of both images and neural rates\non held-out trials. Finally, we demonstrate our framework on two real world\nmulti-modal experimental settings: Drosophila whole-brain calcium imaging\nalongside tracked limb positions, and Manduca sexta spike train measurements\nfrom ten wing muscles as the animal tracks a visual stimulus.",
          "link": "http://arxiv.org/abs/2310.03111",
          "publishedOn": "2023-10-07T00:42:19.208Z",
          "wordCount": null,
          "title": "Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data. (arXiv:2310.03111v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Javadinia_S/0/1/0/all/0/1\">Samaneh Javadinia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baniasadi_A/0/1/0/all/0/1\">Amirali Baniasadi</a>",
          "description": "Convolutional Neural Networks (CNNs) have produced state-of-the-art results\nfor image classification tasks. However, they are limited in their ability to\nhandle rotational and viewpoint variations due to information loss in\nmax-pooling layers. Capsule Networks (CapsNets) employ a\ncomputationally-expensive iterative process referred to as dynamic routing to\naddress these issues. CapsNets, however, often fall short on complex datasets\nand require more computational resources than CNNs. To overcome these\nchallenges, we introduce the Parallel Dynamic Routing CapsNet (PDR-CapsNet), a\ndeeper and more energy-efficient alternative to CapsNet that offers superior\nperformance, less energy consumption, and lower overfitting rates. By\nleveraging a parallelization strategy, PDR-CapsNet mitigates the computational\ncomplexity of CapsNet and increases throughput, efficiently using hardware\nresources. As a result, we achieve 83.55\\% accuracy while requiring 87.26\\%\nfewer parameters, 32.27\\% and 47.40\\% fewer MACs, and Flops, achieving 3x\nfaster inference and 7.29J less energy consumption on a 2080Ti GPU with 11GB\nVRAM compared to CapsNet and for the CIFAR-10 dataset.",
          "link": "http://arxiv.org/abs/2310.03212",
          "publishedOn": "2023-10-07T00:42:19.207Z",
          "wordCount": null,
          "title": "PDR-CapsNet: an Energy-Efficient Parallel Approach to Dynamic Routing in Capsule Networks. (arXiv:2310.03212v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03206",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chang_T/0/1/0/all/0/1\">Ting-Jui Chang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Shahrampour_S/0/1/0/all/0/1\">Shahin Shahrampour</a>",
          "description": "This paper addresses the distributed online control problem over a network of\nlinear time-invariant (LTI) systems (with possibly unknown dynamics) in the\npresence of adversarial perturbations. There exists a global network cost that\nis characterized by a time-varying convex function, which evolves in an\nadversarial manner and is sequentially and partially observed by local agents.\nThe goal of each agent is to generate a control sequence that can compete with\nthe best centralized control policy in hindsight, which has access to the\nglobal cost. This problem is formulated as a regret minimization. For the case\nof known dynamics, we propose a fully distributed disturbance feedback\ncontroller that guarantees a regret bound of $O(\\sqrt{T}\\log T)$, where $T$ is\nthe time horizon. For the unknown dynamics case, we design a distributed\nexplore-then-commit approach, where in the exploration phase all agents jointly\nlearn the system dynamics, and in the learning phase our proposed control\nalgorithm is applied using each agent system estimate. We establish a regret\nbound of $O(T^{2/3} \\text{poly}(\\log T))$ for this setting.",
          "link": "http://arxiv.org/abs/2310.03206",
          "publishedOn": "2023-10-07T00:42:19.203Z",
          "wordCount": null,
          "title": "Regret Analysis of Distributed Online Control for LTI Systems with Adversarial Disturbances. (arXiv:2310.03206v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1\">Philip M. Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "Recent experiments have shown that, often, when training a neural network\nwith gradient descent (GD) with a step size $\\eta$, the operator norm of the\nHessian of the loss grows until it approximately reaches $2/\\eta$, after which\nit fluctuates around this value. The quantity $2/\\eta$ has been called the\n\"edge of stability\" based on consideration of a local quadratic approximation\nof the loss. We perform a similar calculation to arrive at an \"edge of\nstability\" for Sharpness-Aware Minimization (SAM), a variant of GD which has\nbeen shown to improve its generalization. Unlike the case for GD, the resulting\nSAM-edge depends on the norm of the gradient. Using three deep learning\ntraining tasks, we see empirically that SAM operates on the edge of stability\nidentified by this analysis.",
          "link": "http://arxiv.org/abs/2309.12488",
          "publishedOn": "2023-10-07T00:42:19.202Z",
          "wordCount": null,
          "title": "Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03027",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Prakash_M/0/1/0/all/0/1\">M V Sai Prakash</a>, <a href=\"http://arxiv.org/find/physics/1/au:+N_S/0/1/0/all/0/1\">Siddartha Reddy N</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Parab_G/0/1/0/all/0/1\">Ganesh Parab</a>, <a href=\"http://arxiv.org/find/physics/1/au:+V_V/0/1/0/all/0/1\">Varun V</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Vaddina_V/0/1/0/all/0/1\">Vishal Vaddina</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gopalakrishnan_S/0/1/0/all/0/1\">Saisubramaniam Gopalakrishnan</a>",
          "description": "Molecular property prediction is a critical task in computational drug\ndiscovery. While recent advances in Graph Neural Networks (GNNs) and\nTransformers have shown to be effective and promising, they face the following\nlimitations: Transformer self-attention does not explicitly consider the\nunderlying molecule structure while GNN feature representation alone is not\nsufficient to capture granular and hidden interactions and characteristics that\ndistinguish similar molecules. To address these limitations, we propose SYN-\nFUSION, a novel approach that synergistically combines pre-trained features\nfrom GNNs and Transformers. This approach provides a comprehensive molecular\nrepresentation, capturing both the global molecule structure and the individual\natom characteristics. Experimental results on MoleculeNet benchmarks\ndemonstrate superior performance, surpassing previous models in 5 out of 7\nclassification datasets and 4 out of 6 regression datasets. The performance of\nSYN-FUSION has been compared with other Graph-Transformer models that have been\njointly trained using a combination of transformer and graph features, and it\nis found that our approach is on par with those models in terms of performance.\nExtensive analysis of the learned fusion model across aspects such as loss,\nlatent space, and weight distribution further validates the effectiveness of\nSYN-FUSION. Finally, an ablation study unequivocally demonstrates that the\nsynergy achieved by SYN-FUSION surpasses the performance of its individual\nmodel components and their ensemble, offering a substantial improvement in\npredicting molecular properties.",
          "link": "http://arxiv.org/abs/2310.03027",
          "publishedOn": "2023-10-07T00:42:19.201Z",
          "wordCount": null,
          "title": "Synergistic Fusion of Graph and Transformer Features for Enhanced Molecular Property Prediction. (arXiv:2310.03027v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bayazit_D/0/1/0/all/0/1\">Deniz Bayazit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foroutan_N/0/1/0/all/0/1\">Negar Foroutan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gail Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>",
          "description": "Pretrained language models (LMs) encode implicit representations of knowledge\nin their parameters. However, localizing these representations and\ndisentangling them from each other remains an open problem. In this work, we\ninvestigate whether pretrained language models contain various\nknowledge-critical subnetworks: particular sparse computational subgraphs\nresponsible for encoding specific knowledge the model has memorized. We propose\na multi-objective differentiable weight masking scheme to discover these\nsubnetworks and show that we can use them to precisely remove specific\nknowledge from models while minimizing adverse effects on the behavior of the\noriginal language model. We demonstrate our method on multiple GPT2 variants,\nuncovering highly sparse subnetworks (98%+) that are solely responsible for\nspecific collections of relational knowledge. When these subnetworks are\nremoved, the remaining network maintains most of its initial capacity (modeling\nlanguage and other memorized relational knowledge) but struggles to express the\nremoved knowledge, and suffers performance drops on examples needing this\nremoved knowledge on downstream tasks after finetuning.",
          "link": "http://arxiv.org/abs/2310.03084",
          "publishedOn": "2023-10-07T00:42:19.200Z",
          "wordCount": null,
          "title": "Discovering Knowledge-Critical Subnetworks in Pretrained Language Models. (arXiv:2310.03084v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Navratil_J/0/1/0/all/0/1\">Jiri Navratil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elder_B/0/1/0/all/0/1\">Benjamin Elder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnold_M/0/1/0/all/0/1\">Matthew Arnold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Soumya Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1\">Prasanna Sattigeri</a>",
          "description": "Accurate quantification of model uncertainty has long been recognized as a\nfundamental requirement for trusted AI. In regression tasks, uncertainty is\ntypically quantified using prediction intervals calibrated to an ad-hoc\noperating point, making evaluation and comparison across different studies\nrelatively difficult. Our work leverages: (1) the concept of operating\ncharacteristics curves and (2) the notion of a gain over a null reference, to\nderive a novel operating point agnostic assessment methodology for prediction\nintervals. The paper defines the Uncertainty Characteristics Curve and\ndemonstrates its utility in selected scenarios. We argue that the proposed\nmethod addresses the current need for comprehensive assessment of prediction\nintervals and thus represents a valuable addition to the uncertainty\nquantification toolbox.",
          "link": "http://arxiv.org/abs/2310.03158",
          "publishedOn": "2023-10-07T00:42:19.192Z",
          "wordCount": null,
          "title": "Assessment of Prediction Intervals Using Uncertainty Characteristics Curves. (arXiv:2310.03158v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03088",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Falas_S/0/1/0/all/0/1\">Solon Falas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asprou_M/0/1/0/all/0/1\">Markos Asprou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konstantinou_C/0/1/0/all/0/1\">Charalambos Konstantinou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michael_M/0/1/0/all/0/1\">Maria K. Michael</a>",
          "description": "State estimation is the cornerstone of the power system control center since\nit provides the operating condition of the system in consecutive time\nintervals. This work investigates the application of physics-informed neural\nnetworks (PINNs) for accelerating power systems state estimation in monitoring\nthe operation of power systems. Traditional state estimation techniques often\nrely on iterative algorithms that can be computationally intensive,\nparticularly for large-scale power systems. In this paper, a novel approach\nthat leverages the inherent physical knowledge of power systems through the\nintegration of PINNs is proposed. By incorporating physical laws as prior\nknowledge, the proposed method significantly reduces the computational\ncomplexity associated with state estimation while maintaining high accuracy.\nThe proposed method achieves up to 11% increase in accuracy, 75% reduction in\nstandard deviation of results, and 30% faster convergence, as demonstrated by\ncomprehensive experiments on the IEEE 14-bus system.",
          "link": "http://arxiv.org/abs/2310.03088",
          "publishedOn": "2023-10-07T00:42:19.131Z",
          "wordCount": null,
          "title": "Physics-Informed Neural Networks for Accelerating Power System State Estimation. (arXiv:2310.03088v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03106",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Nejat_P/0/1/0/all/0/1\">Peyman Nejat</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alsaafin_A/0/1/0/all/0/1\">Areej Alsaafin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alabtah_G/0/1/0/all/0/1\">Ghazal Alabtah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Comfere_N/0/1/0/all/0/1\">Nneka Comfere</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mangold_A/0/1/0/all/0/1\">Aaron Mangold</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Murphree_D/0/1/0/all/0/1\">Dennis Murphree</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zot_P/0/1/0/all/0/1\">Patricija Zot</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yasir_S/0/1/0/all/0/1\">Saba Yasir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garcia_J/0/1/0/all/0/1\">Joaquin J. Garcia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tizhoosh_H/0/1/0/all/0/1\">H.R. Tizhoosh</a>",
          "description": "Patching gigapixel whole slide images (WSIs) is an important task in\ncomputational pathology. Some methods have been proposed to select a subset of\npatches as WSI representation for downstream tasks. While most of the\ncomputational pathology tasks are designed to classify or detect the presence\nof pathological lesions in each WSI, the confounding role and redundant nature\nof normal histology in tissue samples are generally overlooked in WSI\nrepresentations. In this paper, we propose and validate the concept of an\n\"atlas of normal tissue\" solely using samples of WSIs obtained from normal\ntissue biopsies. Such atlases can be employed to eliminate normal fragments of\ntissue samples and hence increase the representativeness collection of patches.\nWe tested our proposed method by establishing a normal atlas using 107 normal\nskin WSIs and demonstrated how established indexes and search engines like\nYottixel can be improved. We used 553 WSIs of cutaneous squamous cell carcinoma\n(cSCC) to show the advantage. We also validated our method applied to an\nexternal dataset of 451 breast WSIs. The number of selected WSI patches was\nreduced by 30% to 50% after utilizing the proposed normal atlas while\nmaintaining the same indexing and search performance in leave-one-patinet-out\nvalidation for both datasets. We show that the proposed normal atlas shows\npromise for unsupervised selection of the most representative patches of the\nabnormal/malignant WSI lesions.",
          "link": "http://arxiv.org/abs/2310.03106",
          "publishedOn": "2023-10-07T00:42:19.103Z",
          "wordCount": null,
          "title": "Creating an Atlas of Normal Tissue for Pruning WSI Patching Through Anomaly Detection. (arXiv:2310.03106v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03094",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yue_M/0/1/0/all/0/1\">Murong Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jie Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Liang Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Ziyu Yao</a>",
          "description": "Large language models (LLMs) such as GPT-4 have exhibited remarkable\nperformance in a variety of tasks, but this strong performance often comes with\nthe high expense of using paid API services. In this paper, we are motivated to\nstudy building an LLM cascade to save the cost of using LLMs, particularly for\nperforming reasoning (e.g., mathematical, causal) tasks. Our cascade pipeline\nfollows the intuition that simpler questions can be addressed by a weaker but\nmore affordable LLM, whereas only the challenging questions necessitate the\nstronger and more expensive LLM. To realize this decision-making, we consider\nthe \"answer consistency\" of the weaker LLM as a signal of the question\ndifficulty and propose several methods for the answer sampling and consistency\nchecking, including one leveraging a mixture of two thought representations\n(i.e., Chain-of-Thought and Program-of-Thought). Through experiments on six\nreasoning benchmark datasets, with GPT-3.5-turbo and GPT-4 being the weaker and\nstronger LLMs, respectively, we demonstrate that our proposed LLM cascades can\nachieve performance comparable to using solely the stronger LLM but require\nonly 40% of its cost.",
          "link": "http://arxiv.org/abs/2310.03094",
          "publishedOn": "2023-10-07T00:42:19.100Z",
          "wordCount": null,
          "title": "Large Language Model Cascades with Mixture of Thoughts Representations for Cost-efficient Reasoning. (arXiv:2310.03094v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kariyawasam_H/0/1/0/all/0/1\">Hasindu Kariyawasam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hettiarachchi_R/0/1/0/all/0/1\">Ramith Hettiarachchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadduwage_D/0/1/0/all/0/1\">Dushan Wadduwage</a>",
          "description": "Optical neural architectures (ONAs) use coding elements with optimized\nphysical parameters to perform intelligent measurements. However, fabricating\nONAs while maintaining design performances is challenging. Limitations in\nfabrication techniques often limit the realizable precision of the trained\nparameters. Physical constraints may also limit the range of values the\nphysical parameters can hold. Thus, ONAs should be trained within the\nimplementable constraints. However, such physics-based constraints reduce the\ntraining objective to a constrained optimization problem, making it harder to\noptimize with existing gradient-based methods. To alleviate these critical\nissues that degrade performance from simulation to realization we propose a\nphysics-informed quantization-aware training framework. Our approach accounts\nfor the physical constraints during the training process, leading to robust\ndesigns. We evaluate our approach on an ONA proposed in the literature, named a\ndiffractive deep neural network (D2NN), for all-optical phase imaging and for\nclassification of phase objects. With extensive experiments on different\nquantization levels and datasets, we show that our approach leads to ONA\ndesigns that are robust to quantization noise.",
          "link": "http://arxiv.org/abs/2310.03049",
          "publishedOn": "2023-10-07T00:42:19.099Z",
          "wordCount": null,
          "title": "QuATON: Quantization Aware Training of Optical Neurons. (arXiv:2310.03049v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berlyand_L/0/1/0/all/0/1\">Leonid Berlyand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandier_E/0/1/0/all/0/1\">Etienne Sandier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmalo_Y/0/1/0/all/0/1\">Yitzchak Shmalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>",
          "description": "In this study, we explore the applications of random matrix theory (RMT) in\nthe training of deep neural networks (DNNs), focusing on layer pruning to\nsimplify DNN architecture and loss landscape. RMT, recently used to address\noverfitting in deep learning, enables the examination of DNN's weight layer\nspectra. We use these techniques to optimally determine the number of singular\nvalues to be removed from the weight layers of a DNN during training via\nsingular value decomposition (SVD). This process aids in DNN simplification and\naccuracy enhancement, as evidenced by training simple DNN models on the MNIST\nand Fashion MNIST datasets.\n\nOur method can be applied to any fully connected or convolutional layer of a\npretrained DNN, decreasing the layer's parameters and simplifying the DNN\narchitecture while preserving or even enhancing the model's accuracy. By\ndiscarding small singular values based on RMT criteria, the accuracy of the\ntest set remains consistent, facilitating more efficient DNN training without\ncompromising performance.\n\nWe provide both theoretical and empirical evidence supporting our claim that\nthe elimination of small singular values based on RMT does not negatively\nimpact the DNN's accuracy. Our results offer valuable insights into the\npractical application of RMT for the creation of more efficient and accurate\ndeep-learning models.",
          "link": "http://arxiv.org/abs/2310.03165",
          "publishedOn": "2023-10-07T00:42:19.099Z",
          "wordCount": null,
          "title": "Enhancing Accuracy in Deep Learning Using Random Matrix Theory. (arXiv:2310.03165v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03480",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dabike_G/0/1/0/all/0/1\">Gerardo Roa Dabike</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Akeroyd_M/0/1/0/all/0/1\">Michael A. Akeroyd</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bannister_S/0/1/0/all/0/1\">Scott Bannister</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barker_J/0/1/0/all/0/1\">Jon Barker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cox_T/0/1/0/all/0/1\">Trevor J. Cox</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fazenda_B/0/1/0/all/0/1\">Bruno Fazenda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Firth_J/0/1/0/all/0/1\">Jennifer Firth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Graetzer_S/0/1/0/all/0/1\">Simone Graetzer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greasley_A/0/1/0/all/0/1\">Alinka Greasley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vos_R/0/1/0/all/0/1\">Rebecca Vos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Whitmer_W/0/1/0/all/0/1\">William Whitmer</a>",
          "description": "The Cadenza project aims to enhance the audio quality of music for\nindividuals with hearing loss. As part of this, the project is organizing the\nICASSP SP Cadenza Challenge: Music Demixing/Remixing for Hearing Aids. The\nchallenge can be tackled by decomposing the music at the hearing aid\nmicrophones into vocals, bass, drums, and other components. These can then be\nintelligently remixed in a personalized manner to improve audio quality.\nAlternatively, an end-to-end approach could be used. Processes need to consider\nthe music itself, the gain applied to each component, and the listener's\nhearing loss. The submitted entries will be evaluated using the intrusive\nobjective metric, the Hearing Aid Audio Quality Index (HAAQI). This paper\noutlines the challenge.",
          "link": "http://arxiv.org/abs/2310.03480",
          "publishedOn": "2023-10-07T00:42:19.099Z",
          "wordCount": null,
          "title": "The Cadenza ICASSP 2024 Grand Challenge. (arXiv:2310.03480v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wachi_A/0/1/0/all/0/1\">Akifumi Wachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_W/0/1/0/all/0/1\">Wataru Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xun Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_K/0/1/0/all/0/1\">Kazumune Hashimoto</a>",
          "description": "Safe exploration is essential for the practical use of reinforcement learning\n(RL) in many real-world scenarios. In this paper, we present a generalized safe\nexploration (GSE) problem as a unified formulation of common safe exploration\nproblems. We then propose a solution of the GSE problem in the form of a\nmeta-algorithm for safe exploration, MASE, which combines an unconstrained RL\nalgorithm with an uncertainty quantifier to guarantee safety in the current\nepisode while properly penalizing unsafe explorations before actual safety\nviolation to discourage them in future episodes. The advantage of MASE is that\nwe can optimize a policy while guaranteeing with a high probability that no\nsafety constraint will be violated under proper assumptions. Specifically, we\npresent two variants of MASE with different constructions of the uncertainty\nquantifier: one based on generalized linear models with theoretical guarantees\nof safety and near-optimality, and another that combines a Gaussian process to\nensure safety with a deep RL algorithm to maximize the reward. Finally, we\ndemonstrate that our proposed algorithm achieves better performance than\nstate-of-the-art algorithms on grid-world and Safety Gym benchmarks without\nviolating any safety constraints, even during training.",
          "link": "http://arxiv.org/abs/2310.03225",
          "publishedOn": "2023-10-07T00:42:19.098Z",
          "wordCount": null,
          "title": "Safe Exploration in Reinforcement Learning: A Generalized Formulation and Algorithms. (arXiv:2310.03225v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1\">Tony Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_M/0/1/0/all/0/1\">Mohit Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ester_M/0/1/0/all/0/1\">Martin Ester</a>",
          "description": "We seek to automate the generation of drug-like compounds conditioned to\nspecific protein pocket targets. Most current methods approximate the\nprotein-molecule distribution of a finite dataset and, therefore struggle to\ngenerate molecules with significant binding improvement over the training\ndataset. We instead frame the pocket-conditioned molecular generation task as\nan RL problem and develop TacoGFN, a target conditional Generative Flow Network\nmodel. Our method is explicitly encouraged to generate molecules with desired\nproperties as opposed to fitting on a pre-existing data distribution. To this\nend, we develop transformer-based docking score prediction to speed up docking\nscore computation and propose TacoGFN to explore molecule space efficiently.\nFurthermore, we incorporate several rounds of active learning where generated\nsamples are queried using a docking oracle to improve the docking score\nprediction. This approach allows us to accurately explore as much of the\nmolecule landscape as we can afford computationally. Empirically, molecules\ngenerated using TacoGFN and its variants significantly outperform all baseline\nmethods across every property (Docking score, QED, SA, Lipinski), while being\norders of magnitude faster.",
          "link": "http://arxiv.org/abs/2310.03223",
          "publishedOn": "2023-10-07T00:42:19.097Z",
          "wordCount": null,
          "title": "TacoGFN: Target Conditioned GFlowNet for Structure-Based Drug Design. (arXiv:2310.03223v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Durand_J/0/1/0/all/0/1\">Jean-Guillaume Durand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubois_A/0/1/0/all/0/1\">Arthur Dubois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moss_R/0/1/0/all/0/1\">Robert J. Moss</a>",
          "description": "Over the past decade, machine learning has demonstrated impressive results,\noften surpassing human capabilities in sensing tasks relevant to autonomous\nflight. Unlike traditional aerospace software, the parameters of machine\nlearning models are not hand-coded nor derived from physics but learned from\ndata. They are automatically adjusted during a training phase, and their values\ndo not usually correspond to physical requirements. As a result, requirements\ncannot be directly traced to lines of code, hindering the current bottom-up\naerospace certification paradigm. This paper attempts to address this gap by 1)\ndemystifying the inner workings and processes to build machine learning models,\n2) formally establishing theoretical guarantees given by those processes, and\n3) complementing these formal elements with practical considerations to develop\na complete certification argument for safety-critical machine learning systems.\nBased on a scalable statistical verifier, our proposed framework is\nmodel-agnostic and tool-independent, making it adaptable to many use cases in\nthe industry. We demonstrate results on a widespread application in autonomous\nflight: vision-based landing.",
          "link": "http://arxiv.org/abs/2310.03217",
          "publishedOn": "2023-10-07T00:42:19.094Z",
          "wordCount": null,
          "title": "Formal and Practical Elements for the Certification of Machine Learning Systems. (arXiv:2310.03217v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luong_K/0/1/0/all/0/1\">Kha-Dinh Luong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Ambuj Singh</a>",
          "description": "Property prediction on molecular graphs is an important application of Graph\nNeural Networks (GNNs). Recently, unlabeled molecular data has become abundant,\nwhich facilitates the rapid development of self-supervised learning for GNNs in\nthe chemical domain. In this work, we propose pretraining GNNs at the fragment\nlevel, which serves as a promising middle ground to overcome the limitations of\nnode-level and graph-level pretraining. Borrowing techniques from recent work\non principle subgraph mining, we obtain a compact vocabulary of prevalent\nfragments that span a large pretraining dataset. From the extracted vocabulary,\nwe introduce several fragment-based contrastive and predictive pretraining\ntasks. The contrastive learning task jointly pretrains two different GNNs: one\nbased on molecular graphs and one based on fragment graphs, which represents\nhigh-order connectivity within molecules. By enforcing the consistency between\nthe fragment embedding and the aggregated embedding of the corresponding atoms\nfrom the molecular graphs, we ensure that both embeddings capture structural\ninformation at multiple resolutions. The structural information of the fragment\ngraphs is further exploited to extract auxiliary labels for the graph-level\npredictive pretraining. We employ both the pretrained molecular-based and\nfragment-based GNNs for downstream prediction, thus utilizing the fragment\ninformation during finetuning. Our models advance the performances on 5 out of\n8 common molecular benchmarks and improve the performances on long-range\nbiological benchmarks by at least 11.5%.",
          "link": "http://arxiv.org/abs/2310.03274",
          "publishedOn": "2023-10-07T00:42:19.094Z",
          "wordCount": null,
          "title": "Fragment-based Pretraining and Finetuning on Molecular Graphs. (arXiv:2310.03274v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishi_H/0/1/0/all/0/1\">Hideyuki Ishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>",
          "description": "The symmetry and geometry of input data are considered to be encoded in the\ninternal data representation inside the neural network, but the specific\nencoding rule has been less investigated. By focusing on a joint group\ninvariant function on the data-parameter domain, we present a systematic rule\nto find a dual group action on the parameter domain from a group action on the\ndata domain. Further, we introduce generalized neural networks induced from the\njoint invariant functions, and present a new group theoretic proof of their\nuniversality theorems by using Schur's lemma. Since traditional universality\ntheorems were demonstrated based on functional analytical methods, this study\nsheds light on the group theoretic aspect of the approximation theory,\nconnecting geometric deep learning to abstract harmonic analysis.",
          "link": "http://arxiv.org/abs/2310.03530",
          "publishedOn": "2023-10-07T00:42:19.094Z",
          "wordCount": null,
          "title": "Joint Group Invariant Functions on Data-Parameter Domain Induce Universal Neural Networks. (arXiv:2310.03530v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03030",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Balaji_S/0/1/0/all/0/1\">Suryanarayanan Balaji</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Magar_R/0/1/0/all/0/1\">Rishikesh Magar</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Jadhav_Y/0/1/0/all/0/1\">Yayati Jadhav</a>, <a href=\"http://arxiv.org/find/physics/1/au:+BaratiFarimani_a/0/1/0/all/0/1\">and Amir BaratiFarimani</a>",
          "description": "With the emergence of Transformer architectures and their powerful\nunderstanding of textual data, a new horizon has opened up to predict the\nmolecular properties based on text description. While SMILES are the most\ncommon form of representation, they are lacking robustness, rich information\nand canonicity, which limit their effectiveness in becoming generalizable\nrepresentations. Here, we present GPT-MolBERTa, a self-supervised large\nlanguage model (LLM) which uses detailed textual descriptions of molecules to\npredict their properties. A text based description of 326000 molecules were\ncollected using ChatGPT and used to train LLM to learn the representation of\nmolecules. To predict the properties for the downstream tasks, both BERT and\nRoBERTa models were used in the finetuning stage. Experiments show that\nGPT-MolBERTa performs well on various molecule property benchmarks, and\napproaching state of the art performance in regression tasks. Additionally,\nfurther analysis of the attention mechanisms show that GPT-MolBERTa is able to\npick up important information from the input textual data, displaying the\ninterpretability of the model.",
          "link": "http://arxiv.org/abs/2310.03030",
          "publishedOn": "2023-10-07T00:42:19.093Z",
          "wordCount": null,
          "title": "GPT-MolBERTa: GPT Molecular Features Language Model for molecular property prediction. (arXiv:2310.03030v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianghong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1\">Joyce C. Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agichtein_E/0/1/0/all/0/1\">Eugene Agichtein</a>",
          "description": "Interactive search can provide a better experience by incorporating\ninteraction feedback from the users. This can significantly improve search\naccuracy as it helps avoid irrelevant information and captures the users'\nsearch intents. Existing state-of-the-art (SOTA) systems use reinforcement\nlearning (RL) models to incorporate the interactions but focus on item-level\nfeedback, ignoring the fine-grained information found in sentence-level\nfeedback. Yet such feedback requires extensive RL action space exploration and\nlarge amounts of annotated data. This work addresses these challenges by\nproposing a new deep Q-learning (DQ) approach, DQrank. DQrank adapts BERT-based\nmodels, the SOTA in natural language processing, to select crucial sentences\nbased on users' engagement and rank the items to obtain more satisfactory\nresponses. We also propose two mechanisms to better explore optimal actions.\nDQrank further utilizes the experience replay mechanism in DQ to store the\nfeedback sentences to obtain a better initial ranking performance. We validate\nthe effectiveness of DQrank on three search datasets. The results show that\nDQRank performs at least 12% better than the previous SOTA RL approaches. We\nalso conduct detailed ablation studies. The ablation results demonstrate that\neach model component can efficiently extract and accumulate long-term\nengagement effects from the users' sentence-level feedback. This structure\noffers new technologies with promised performance to construct a search system\nwith sentence-level interaction.",
          "link": "http://arxiv.org/abs/2310.03043",
          "publishedOn": "2023-10-07T00:42:19.093Z",
          "wordCount": null,
          "title": "A Deep Reinforcement Learning Approach for Interactive Search with Sentence-level Feedback. (arXiv:2310.03043v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03047",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Zhu_S/0/1/0/all/0/1\">Shang Zhu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ramsundar_B/0/1/0/all/0/1\">Bharath Ramsundar</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Annevelink_E/0/1/0/all/0/1\">Emil Annevelink</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lin_H/0/1/0/all/0/1\">Hongyi Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Dave_A/0/1/0/all/0/1\">Adarsh Dave</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Guan_P/0/1/0/all/0/1\">Pin-Wen Guan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gering_K/0/1/0/all/0/1\">Kevin Gering</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Viswanathan_V/0/1/0/all/0/1\">Venkatasubramanian Viswanathan</a>",
          "description": "Chemical mixtures, satisfying multi-objective performance metrics and\nconstraints, enable their use in chemical processes and electrochemical\ndevices. In this work, we develop a differentiable chemical-physics framework\nfor modeling chemical mixtures, DiffMix, where geometric deep learning (GDL) is\nleveraged to map from molecular species, compositions and environment\nconditions, to physical coefficients in the mixture physics laws. In\nparticular, we extend mixture thermodynamic and transport laws by creating\nlearnable physical coefficients, where we use graph neural networks as the\nmolecule encoder and enforce component-wise permutation-invariance. We start\nour model evaluations with thermodynamics of binary mixtures, and further\nbenchmarked multicomponent electrolyte mixtures on their transport properties,\nin order to test the model generalizability. We show improved prediction\naccuracy and model robustness of DiffMix than its purely data-driven variants.\nFurthermore, we demonstrate the efficient optimization of electrolyte transport\nproperties, built on the gradient obtained using DiffMix auto-differentiation.\nOur simulation runs are then backed up by the data generated by a robotic\nexperimentation setup, Clio. By combining mixture physics and GDL, DiffMix\nexpands the predictive modeling methods for chemical mixtures and provides\nlow-cost optimization approaches in large chemical spaces.",
          "link": "http://arxiv.org/abs/2310.03047",
          "publishedOn": "2023-10-07T00:42:19.091Z",
          "wordCount": null,
          "title": "Differentiable Chemical Physics by Geometric Deep Learning for Gradient-based Property Optimization of Mixtures. (arXiv:2310.03047v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03055",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddy_R/0/1/0/all/0/1\">Ruturaj Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_U/0/1/0/all/0/1\">Utkarsh Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kale_I/0/1/0/all/0/1\">Ishaan Kale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shastri_A/0/1/0/all/0/1\">Apoorva Shastri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Anand J Kulkarni</a>",
          "description": "A modified LAB algorithm is introduced in this paper. It builds upon the\noriginal LAB algorithm (Reddy et al. 2023), which is a socio-inspired algorithm\nthat models competitive and learning behaviours within a group, establishing\nhierarchical roles. The proposed algorithm incorporates the roulette wheel\napproach and a reduction factor introducing inter-group competition and\niteratively narrowing down the sample space. The algorithm is validated by\nsolving the benchmark test problems from CEC 2005 and CEC 2017. The solutions\nare validated using standard statistical tests such as two-sided and pairwise\nsigned rank Wilcoxon test and Friedman rank test. The algorithm exhibited\nimproved and superior robustness as well as search space exploration\ncapabilities. Furthermore, a Clustering-Based Search Space Reduction (C-SSR)\nmethod is proposed, making the algorithm capable to solve constrained problems.\nThe C-SSR method enables the algorithm to identify clusters of feasible\nregions, satisfying the constraints and contributing to achieve the optimal\nsolution. This method demonstrates its effectiveness as a potential alternative\nto traditional constraint handling techniques. The results obtained using the\nModified LAB algorithm are then compared with those achieved by other recent\nmetaheuristic algorithms.",
          "link": "http://arxiv.org/abs/2310.03055",
          "publishedOn": "2023-10-07T00:42:19.087Z",
          "wordCount": null,
          "title": "Modified LAB Algorithm with Clustering-based Search Space Reduction Method for solving Engineering Design Problems. (arXiv:2310.03055v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_M/0/1/0/all/0/1\">Mosab Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alhoori_H/0/1/0/all/0/1\">Hamed Alhoori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahimi_M/0/1/0/all/0/1\">Mona Rahimi</a>",
          "description": "Frequent modifications of unit test cases are inevitable due to software's\ncontinuous underlying changes in source code, design, and requirements. Since\nmanually maintaining software test suites is tedious, timely, and costly,\nautomating the process of generation and maintenance of test units will\nsignificantly impact the effectiveness and efficiency of software testing\nprocesses.\n\nTo this end, we propose an automated approach which exploits both structural\nand semantic properties of source code methods and test cases to recommend the\nmost relevant and useful unit tests to the developers. The proposed approach\ninitially trains a neural network to transform method-level source code, as\nwell as unit tests, into distributed representations (embedded vectors) while\npreserving the importance of the structure in the code. Retrieving the semantic\nand structural properties of a given method, the approach computes cosine\nsimilarity between the method's embedding and the previously-embedded training\ninstances. Further, according to the similarity scores between the embedding\nvectors, the model identifies the closest methods of embedding and the\nassociated unit tests as the most similar recommendations.\n\nThe results on the Methods2Test dataset showed that, while there is no\nguarantee to have similar relevant test cases for the group of similar methods,\nthe proposed approach extracts the most similar existing test cases for a given\nmethod in the dataset, and evaluations show that recommended test cases\ndecrease the developers' effort to generating expected test cases.",
          "link": "http://arxiv.org/abs/2310.03174",
          "publishedOn": "2023-10-07T00:42:19.087Z",
          "wordCount": null,
          "title": "Test Case Recommendations with Distributed Representation of Code Syntactic Features. (arXiv:2310.03174v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yijia Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinecke_D/0/1/0/all/0/1\">Dylan Steinecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelletier_A/0/1/0/all/0/1\">Alexander Russell Pelletier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yushi Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_P/0/1/0/all/0/1\">Peipei Ping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>",
          "description": "Knowledge graphs (KGs) have emerged as a powerful framework for representing\nand integrating complex biomedical information. However, assembling KGs from\ndiverse sources remains a significant challenge in several aspects, including\nentity alignment, scalability, and the need for continuous updates to keep pace\nwith scientific advancements. Moreover, the representative power of KGs is\noften limited by the scarcity of multi-modal data integration. To overcome\nthese challenges, we propose Know2BIO, a general-purpose heterogeneous KG\nbenchmark for the biomedical domain. Know2BIO integrates data from 30 diverse\nsources, capturing intricate relationships across 11 biomedical categories. It\ncurrently consists of ~219,000 nodes and ~6,200,000 edges. Know2BIO is capable\nof user-directed automated updating to reflect the latest knowledge in\nbiomedical science. Furthermore, Know2BIO is accompanied by multi-modal data:\nnode features including text descriptions, protein and compound sequences and\nstructures, enabling the utilization of emerging natural language processing\nmethods and multi-modal data integration strategies. We evaluate KG\nrepresentation models on Know2BIO, demonstrating its effectiveness as a\nbenchmark for KG representation learning in the biomedical field. Data and\nsource code of Know2BIO are available at\nhttps://github.com/Yijia-Xiao/Know2BIO/.",
          "link": "http://arxiv.org/abs/2310.03221",
          "publishedOn": "2023-10-07T00:42:19.086Z",
          "wordCount": null,
          "title": "Know2BIO: A Comprehensive Dual-View Benchmark for Evolving Biomedical Knowledge Graphs. (arXiv:2310.03221v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_I/0/1/0/all/0/1\">Ivan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_E/0/1/0/all/0/1\">Eric Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_R/0/1/0/all/0/1\">Ray Gu</a>",
          "description": "The popularity of pre-trained large models has revolutionized downstream\ntasks across diverse fields, such as language, vision, and multi-modality. To\nminimize the adaption cost for downstream tasks, many Parameter-Efficient\nFine-Tuning (PEFT) techniques are proposed for language and 2D image\npre-trained models. However, the specialized PEFT method for 3D pre-trained\nmodels is still under-explored. To this end, we introduce Point-PEFT, a novel\nframework for adapting point cloud pre-trained models with minimal learnable\nparameters. Specifically, for a pre-trained 3D model, we freeze most of its\nparameters, and only tune the newly added PEFT modules on downstream tasks,\nwhich consist of a Point-prior Prompt and a Geometry-aware Adapter. The\nPoint-prior Prompt adopts a set of learnable prompt tokens, for which we\npropose to construct a memory bank with domain-specific knowledge, and utilize\na parameter-free attention to enhance the prompt tokens. The Geometry-aware\nAdapter aims to aggregate point cloud features within spatial neighborhoods to\ncapture fine-grained geometric information through local interactions.\nExtensive experiments indicate that our Point-PEFT can achieve better\nperformance than the full fine-tuning on various downstream tasks, while using\nonly 5% of the trainable parameters, demonstrating the efficiency and\neffectiveness of our approach. Code will be released at\nhttps://github.com/EvenJoker/Point-PEFT.",
          "link": "http://arxiv.org/abs/2310.03059",
          "publishedOn": "2023-10-07T00:42:19.031Z",
          "wordCount": null,
          "title": "Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models. (arXiv:2310.03059v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Hui Shi</a> (IMB), <a href=\"http://arxiv.org/find/cs/1/au:+Traonmilin_Y/0/1/0/all/0/1\">Yann Traonmilin</a> (IMB), <a href=\"http://arxiv.org/find/cs/1/au:+Aujol_J/0/1/0/all/0/1\">J-F Aujol</a> (IMB)",
          "description": "We consider the problem of denoising with the help of prior information taken\nfrom a database of clean signals or images. Denoising with variational methods\nis very efficient if a regularizer well adapted to the nature of the data is\navailable. Thanks to the maximum a posteriori Bayesian framework, such\nregularizer can be systematically linked with the distribution of the data.\nWith deep neural networks (DNN), complex distributions can be recovered from a\nlarge training database.To reduce the computational burden of this task, we\nadapt the compressive learning framework to the learning of regularizers\nparametrized by DNN. We propose two variants of stochastic gradient descent\n(SGD) for the recovery of deep regularization parameters from a heavily\ncompressed database. These algorithms outperform the initially proposed method\nthat was limited to low-dimensional signals, each iteration using information\nfrom the whole database. They also benefit from classical SGD convergence\nguarantees. Thanks to these improvements we show that this method can be\napplied for patch based image denoising.}",
          "link": "http://arxiv.org/abs/2310.03085",
          "publishedOn": "2023-10-07T00:42:19.030Z",
          "wordCount": null,
          "title": "Batch-less stochastic gradient descent for compressive learning of deep regularization for image denoising. (arXiv:2310.03085v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03119",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yasarathna_T/0/1/0/all/0/1\">Tharindu Lakshan Yasarathna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navanesan_L/0/1/0/all/0/1\">Lojenaa Navanesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barque_S/0/1/0/all/0/1\">Simon Barque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sayakkara_A/0/1/0/all/0/1\">Assanka Sayakkara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Khac_N/0/1/0/all/0/1\">Nhien-An Le-Khac</a>",
          "description": "IoT (Internet of Things) refers to the network of interconnected physical\ndevices, vehicles, home appliances, and other items embedded with sensors,\nsoftware, and connectivity, enabling them to collect and exchange data. IoT\nForensics is collecting and analyzing digital evidence from IoT devices to\ninvestigate cybercrimes, security breaches, and other malicious activities that\nmay have taken place on these connected devices. In particular, EM-SCA has\nbecome an essential tool for IoT forensics due to its ability to reveal\nconfidential information about the internal workings of IoT devices without\ninterfering these devices or wiretapping their networks. However, the accuracy\nand reliability of EM-SCA results can be limited by device variability,\nenvironmental factors, and data collection and processing methods. Besides,\nthere is very few research on these limitations that affects significantly the\naccuracy of EM-SCA approaches for the crossed-IoT device portability as well as\nlimited research on the possible solutions to address such challenge.\nTherefore, this empirical study examines the impact of device variability on\nthe accuracy and reliability of EM-SCA approaches, in particular\nmachine-learning (ML) based approaches for EM-SCA. We firstly presents the\nbackground, basic concepts and techniques used to evaluate the limitations of\ncurrent EM-SCA approaches and datasets. Our study then addresses one of the\nmost important limitation, which is caused by the multi-core architecture of\nthe processors (SoC). We present an approach to collect the EM-SCA datasets and\ndemonstrate the feasibility of using transfer learning to obtain more\nmeaningful and reliable results from EM-SCA in IoT forensics of crossed-IoT\ndevices. Our study moreover contributes a new dataset for using deep learning\nmodels in analysing Electromagnetic Side-Channel data with regards to the\ncross-device portability matter.",
          "link": "http://arxiv.org/abs/2310.03119",
          "publishedOn": "2023-10-07T00:42:18.982Z",
          "wordCount": null,
          "title": "Crossed-IoT device portability of Electromagnetic Side Channel Analysis: Challenges and Dataset. (arXiv:2310.03119v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Csehi_A/0/1/0/all/0/1\">&#xc1;goston Istv&#xe1;n Csehi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jozsa_C/0/1/0/all/0/1\">Csaba M&#xe1;t&#xe9; J&#xf3;zsa</a>",
          "description": "We aim to improve the Inverted Neural Radiance Fields (iNeRF) algorithm which\ndefines the image pose estimation problem as a NeRF based iterative linear\noptimization. NeRFs are novel neural space representation models that can\nsynthesize photorealistic novel views of real-world scenes or objects. Our\ncontributions are as follows: we extend the localization optimization objective\nwith a depth-based loss function, we introduce a multi-image based loss\nfunction where a sequence of images with known relative poses are used without\nincreasing the computational complexity, we omit hierarchical sampling during\nvolumetric rendering, meaning only the coarse model is used for pose\nestimation, and we how that by extending the sampling interval convergence can\nbe achieved even or higher initial pose estimate errors. With the proposed\nmodifications the convergence speed is significantly improved, and the basin of\nconvergence is substantially extended.",
          "link": "http://arxiv.org/abs/2310.03563",
          "publishedOn": "2023-10-07T00:42:18.981Z",
          "wordCount": null,
          "title": "BID-NeRF: RGB-D image pose estimation with inverted Neural Radiance Fields. (arXiv:2310.03563v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yilue Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peiyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Lifeng Fan</a>",
          "description": "Visual planning simulates how humans make decisions to achieve desired goals\nin the form of searching for visual causal transitions between an initial\nvisual state and a final visual goal state. It has become increasingly\nimportant in egocentric vision with its advantages in guiding agents to perform\ndaily tasks in complex environments. In this paper, we propose an interpretable\nand generalizable visual planning framework consisting of i) a novel\nSubstitution-based Concept Learner (SCL) that abstracts visual inputs into\ndisentangled concept representations, ii) symbol abstraction and reasoning that\nperforms task planning via the self-learned symbols, and iii) a Visual Causal\nTransition model (ViCT) that grounds visual causal transitions to semantically\nsimilar real-world actions. Given an initial state, we perform goal-conditioned\nvisual planning with a symbolic reasoning method fueled by the learned\nrepresentations and causal transitions to reach the goal state. To verify the\neffectiveness of the proposed model, we collect a large-scale visual planning\ndataset based on AI2-THOR, dubbed as CCTP. Extensive experiments on this\nchallenging dataset demonstrate the superior performance of our method in\nvisual task planning. Empirically, we show that our framework can generalize to\nunseen task trajectories and unseen object categories.",
          "link": "http://arxiv.org/abs/2310.03325",
          "publishedOn": "2023-10-07T00:42:18.980Z",
          "wordCount": null,
          "title": "Learning Concept-Based Visual Causal Transition and Symbolic Reasoning for Visual Planning. (arXiv:2310.03325v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Woojun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jeonghye Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Youngchul Sung</a>",
          "description": "In this paper, a unified framework for exploration in reinforcement learning\n(RL) is proposed based on an option-critic model. The proposed framework learns\nto integrate a set of diverse exploration strategies so that the agent can\nadaptively select the most effective exploration strategy over time to realize\na relevant exploration-exploitation trade-off for each given task. The\neffectiveness of the proposed exploration framework is demonstrated by various\nexperiments in the MiniGrid and Atari environments.",
          "link": "http://arxiv.org/abs/2310.03342",
          "publishedOn": "2023-10-07T00:42:18.980Z",
          "wordCount": null,
          "title": "LESSON: Learning to Integrate Exploration Strategies for Reinforcement Learning via an Option Framework. (arXiv:2310.03342v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03054",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hagemann_P/0/1/0/all/0/1\">Paul Hagemann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hertrich_J/0/1/0/all/0/1\">Johannes Hertrich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Altekruger_F/0/1/0/all/0/1\">Fabian Altekr&#xfc;ger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beinert_R/0/1/0/all/0/1\">Robert Beinert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chemseddine_J/0/1/0/all/0/1\">Jannis Chemseddine</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steidl_G/0/1/0/all/0/1\">Gabriele Steidl</a>",
          "description": "We propose conditional flows of the maximum mean discrepancy (MMD) with the\nnegative distance kernel for posterior sampling and conditional generative\nmodeling. This MMD, which is also known as energy distance, has several\nadvantageous properties like efficient computation via slicing and sorting. We\napproximate the joint distribution of the ground truth and the observations\nusing discrete Wasserstein gradient flows and establish an error bound for the\nposterior distributions. Further, we prove that our particle flow is indeed a\nWasserstein gradient flow of an appropriate functional. The power of our method\nis demonstrated by numerical examples including conditional image generation\nand inverse problems like superresolution, inpainting and computed tomography\nin low-dose and limited-angle settings.",
          "link": "http://arxiv.org/abs/2310.03054",
          "publishedOn": "2023-10-07T00:42:18.973Z",
          "wordCount": null,
          "title": "Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel. (arXiv:2310.03054v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1\">Timothy Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chiwun Yang</a>",
          "description": "In-context learning (ICL) is an astonishing emergent ability of large\nlanguage models (LLMs). By presenting a prompt that includes multiple\ninput-output pairs as examples and introducing a new query input, models can\ngenerate the corresponding output. However, the performance of models heavily\nrelies on the quality of the input prompt when implementing in-context\nlearning. Biased or imbalanced input prompts can significantly degrade the\nperformance of language models. To address this issue, we introduce a\nreweighted algorithm called RICL (Reweighted In-context Learning). This\nalgorithm fine-tunes language models using an unbiased validation set to\ndetermine the optimal weight for each input-output example to approximate\nunbiased in-context learning. Furthermore, we also introduce a low-cost\nreweighted algorithm, a linear optimal weight approximation algorithm called\nLARICL (Linear Approximation of Reweighted In-context Learning). This algorithm\nrequires minimal training cost while providing effective results. We prove the\nconvergence of our algorithm and validate its performance through experiments\nconducted on a numerical dataset. The experimental findings reveal a\nsubstantial improvement in comparison to benchmarks including the performance\nof casual prompt-based in-context learning and the performance of a classic\nfine-tuning method.",
          "link": "http://arxiv.org/abs/2310.03331",
          "publishedOn": "2023-10-07T00:42:18.972Z",
          "wordCount": null,
          "title": "Fine-tune Language Models to Approximate Unbiased In-context Learning. (arXiv:2310.03331v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahnama_A/0/1/0/all/0/1\">Amir Hossein Akhavan Rahnama</a>",
          "description": "The number of local model-agnostic explanation techniques proposed has grown\nrapidly recently. One main reason is that the bar for developing new\nexplainability techniques is low due to the lack of optimal evaluation\nmeasures. Without rigorous measures, it is hard to have concrete evidence of\nwhether the new explanation techniques can significantly outperform their\npredecessors. Our study proposes a new taxonomy for evaluating local\nexplanations: robustness, evaluation using ground truth from synthetic datasets\nand interpretable models, model randomization, and human-grounded evaluation.\nUsing this proposed taxonomy, we highlight that all categories of evaluation\nmethods, except those based on the ground truth from interpretable models,\nsuffer from a problem we call the \"blame problem.\" In our study, we argue that\nthis category of evaluation measure is a more reasonable method for evaluating\nlocal model-agnostic explanations. However, we show that even this category of\nevaluation measures has further limitations. The evaluation of local\nexplanations remains an open research problem.",
          "link": "http://arxiv.org/abs/2310.03466",
          "publishedOn": "2023-10-07T00:42:18.972Z",
          "wordCount": null,
          "title": "The Blame Problem in Evaluating Local Explanations, and How to Tackle it. (arXiv:2310.03466v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Minhua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Teng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1\">Enyan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>",
          "description": "Graph Contrastive Learning (GCL) has emerged as a popular unsupervised graph\nrepresentation learning method. However, it has been shown that GCL is\nvulnerable to adversarial attacks on both the graph structure and node\nattributes. Although empirical approaches have been proposed to enhance the\nrobustness of GCL, the certifiable robustness of GCL is still remain\nunexplored. In this paper, we develop the first certifiably robust framework in\nGCL. Specifically, we first propose a unified criteria to evaluate and certify\nthe robustness of GCL. We then introduce a novel technique, RES (Randomized\nEdgedrop Smoothing), to ensure certifiable robustness for any GCL model, and\nthis certified robustness can be provably preserved in downstream tasks.\nFurthermore, an effective training method is proposed for robust GCL. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of our\nproposed method in providing effective certifiable robustness and enhancing the\nrobustness of any GCL model. The source code of RES is available at\nhttps://github.com/ventr1c/RES-GCL.",
          "link": "http://arxiv.org/abs/2310.03312",
          "publishedOn": "2023-10-07T00:42:18.844Z",
          "wordCount": null,
          "title": "Certifiably Robust Graph Contrastive Learning. (arXiv:2310.03312v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Robey_A/0/1/0/all/0/1\">Alexander Robey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1\">Eric Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>",
          "description": "Despite efforts to align large language models (LLMs) with human values,\nwidely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to\njailbreaking attacks, wherein an adversary fools a targeted LLM into generating\nobjectionable content. To address this vulnerability, we propose SmoothLLM, the\nfirst algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our\nfinding that adversarially-generated prompts are brittle to character-level\nchanges, our defense first randomly perturbs multiple copies of a given input\nprompt, and then aggregates the corresponding predictions to detect adversarial\ninputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to\nbelow one percentage point, avoids unnecessary conservatism, and admits\nprovable guarantees on attack mitigation. Moreover, our defense uses\nexponentially fewer queries than existing attacks and is compatible with any\nLLM.",
          "link": "http://arxiv.org/abs/2310.03684",
          "publishedOn": "2023-10-07T00:42:18.757Z",
          "wordCount": null,
          "title": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03485",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kollias_D/0/1/0/all/0/1\">Dimitrios Kollias</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vendal_K/0/1/0/all/0/1\">Karanjot Vendal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gadhavi_P/0/1/0/all/0/1\">Priyanka Gadhavi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Russom_S/0/1/0/all/0/1\">Solomon Russom</a>",
          "description": "Brain tumors pose significant health challenges worldwide, with glioblastoma\nbeing one of the most aggressive forms. Accurate determination of the\nO6-methylguanine-DNA methyltransferase (MGMT) promoter methylation status is\ncrucial for personalized treatment strategies. However, traditional methods are\nlabor-intensive and time-consuming. This paper proposes a novel multi-modal\napproach, BTDNet, leveraging multi-parametric MRI scans, including FLAIR, T1w,\nT1wCE, and T2 3D volumes, to predict MGMT promoter methylation status. BTDNet\naddresses two main challenges: the variable volume lengths (i.e., each volume\nconsists of a different number of slices) and the volume-level annotations\n(i.e., the whole 3D volume is annotated and not the independent slices that it\nconsists of). BTDNet consists of four components: i) the data augmentation one\n(that performs geometric transformations, convex combinations of data pairs and\ntest-time data augmentation); ii) the 3D analysis one (that performs global\nanalysis through a CNN-RNN); iii) the routing one (that contains a mask layer\nthat handles variable input feature lengths), and iv) the modality fusion one\n(that effectively enhances data representation, reduces ambiguities and\nmitigates data scarcity). The proposed method outperforms by large margins the\nstate-of-the-art methods in the RSNA-ASNR-MICCAI BraTS 2021 Challenge, offering\na promising avenue for enhancing brain tumor diagnosis and treatment.",
          "link": "http://arxiv.org/abs/2310.03485",
          "publishedOn": "2023-10-07T00:42:18.747Z",
          "wordCount": null,
          "title": "BTDNet: a Multi-Modal Approach for Brain Tumor Radiogenomic Classification. (arXiv:2310.03485v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shang_M/0/1/0/all/0/1\">Meng Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dedeyne_L/0/1/0/all/0/1\">Lenore Dedeyne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupont_J/0/1/0/all/0/1\">Jolan Dupont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vercauteren_L/0/1/0/all/0/1\">Laura Vercauteren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_N/0/1/0/all/0/1\">Nadjia Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapauw_L/0/1/0/all/0/1\">Laurence Lapauw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gielen_E/0/1/0/all/0/1\">Evelien Gielen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verschueren_S/0/1/0/all/0/1\">Sabine Verschueren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varon_C/0/1/0/all/0/1\">Carolina Varon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raedt_W/0/1/0/all/0/1\">Walter De Raedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanrumste_B/0/1/0/all/0/1\">Bart Vanrumste</a>",
          "description": "Otago Exercise Program (OEP) is a rehabilitation program for older adults to\nimprove frailty, sarcopenia, and balance. Accurate monitoring of patient\ninvolvement in OEP is challenging, as self-reports (diaries) are often\nunreliable. With the development of wearable sensors, Human Activity\nRecognition (HAR) systems using wearable sensors have revolutionized\nhealthcare. However, their usage for OEP still shows limited performance. The\nobjective of this study is to build an unobtrusive and accurate system to\nmonitor OEP for older adults. Data was collected from older adults wearing a\nsingle waist-mounted Inertial Measurement Unit (IMU). Two datasets were\ncollected, one in a laboratory setting, and one at the homes of the patients. A\nhierarchical system is proposed with two stages: 1) using a deep learning model\nto recognize whether the patients are performing OEP or activities of daily\nlife (ADLs) using a 10-minute sliding window; 2) based on stage 1, using a\n6-second sliding window to recognize the OEP sub-classes performed. The results\nshowed that in stage 1, OEP could be recognized with window-wise f1-scores over\n0.95 and Intersection-over-Union (IoU) f1-scores over 0.85 for both datasets.\nIn stage 2, for the home scenario, four activities could be recognized with\nf1-scores over 0.8: ankle plantarflexors, abdominal muscles, knee bends, and\nsit-to-stand. The results showed the potential of monitoring the compliance of\nOEP using a single IMU in daily life. Also, some OEP sub-classes are possible\nto be recognized for further analysis.",
          "link": "http://arxiv.org/abs/2310.03512",
          "publishedOn": "2023-10-07T00:42:18.747Z",
          "wordCount": null,
          "title": "Otago Exercises Monitoring for Older Adults by a Single IMU and Hierarchical Machine Learning Models. (arXiv:2310.03512v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03435",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Magris_M/0/1/0/all/0/1\">Martin Magris</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "The Bayesian estimation of GARCH-family models has been typically addressed\nthrough Monte Carlo sampling. Variational Inference is gaining popularity and\nattention as a robust approach for Bayesian inference in complex machine\nlearning models; however, its adoption in econometrics and finance is limited.\nThis paper discusses the extent to which Variational Inference constitutes a\nreliable and feasible alternative to Monte Carlo sampling for Bayesian\ninference in GARCH-like models. Through a large-scale experiment involving the\nconstituents of the S&P 500 index, several Variational Inference optimizers, a\nvariety of volatility models, and a case study, we show that Variational\nInference is an attractive, remarkably well-calibrated, and competitive method\nfor Bayesian learning.",
          "link": "http://arxiv.org/abs/2310.03435",
          "publishedOn": "2023-10-07T00:42:18.719Z",
          "wordCount": null,
          "title": "Variational Inference for GARCH-family Models. (arXiv:2310.03435v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.12766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>",
          "description": "Large language models (LLMs) have initiated a paradigm shift in transfer\nlearning. In contrast to the classic pretraining-then-finetuning procedure, in\norder to use LLMs for downstream prediction tasks, one only needs to provide a\nfew demonstrations, known as in-context examples, without adding more or\nupdating existing model parameters. This in-context learning (ICL) capability\nof LLMs is intriguing, and it is not yet fully understood how pretrained LLMs\nacquire such capabilities. In this paper, we investigate the reason why a\ntransformer-based language model can accomplish in-context learning after\npre-training on a general language corpus by proposing one hypothesis that LLMs\ncan simulate kernel regression with internal representations when faced with\nin-context examples. More concretely, we first prove that Bayesian inference on\nin-context prompts can be asymptotically understood as kernel regression $\\hat\ny = \\sum_i y_i K(x, x_i)/\\sum_i K(x, x_i)$ as the number of in-context\ndemonstrations grows. Then, we empirically investigate the in-context behaviors\nof language models. We find that during ICL, the attention and hidden features\nin LLMs match the behaviors of a kernel regression. Finally, our theory\nprovides insights into multiple phenomena observed in the ICL field: why\nretrieving demonstrative samples similar to test samples can help, why ICL\nperformance is sensitive to the output formats, and why ICL accuracy benefits\nfrom selecting in-distribution and representative samples.",
          "link": "http://arxiv.org/abs/2305.12766",
          "publishedOn": "2023-10-07T00:42:18.705Z",
          "wordCount": null,
          "title": "Explaining Emergent In-Context Learning as Kernel Regression. (arXiv:2305.12766v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelaleem_E/0/1/0/all/0/1\">Eslam Abdelaleem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nemenman_I/0/1/0/all/0/1\">Ilya Nemenman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martini_K/0/1/0/all/0/1\">K. Michael Martini</a>",
          "description": "Variational dimensionality reduction methods are known for their high\naccuracy, generative abilities, and robustness. These methods have many\ntheoretical justifications. Here we introduce a unifying principle rooted in\ninformation theory to rederive and generalize existing variational methods and\ndesign new ones. We base our framework on an interpretation of the multivariate\ninformation bottleneck, in which two Bayesian networks are traded off against\none another. We interpret the first network as an encoder graph, which\nspecifies what information to keep when compressing the data. We interpret the\nsecond network as a decoder graph, which specifies a generative model for the\ndata. Using this framework, we rederive existing dimensionality reduction\nmethods such as the deep variational information bottleneck (DVIB), beta\nvariational auto-encoders (beta-VAE), and deep variational canonical\ncorrelation analysis (DVCCA). The framework naturally introduces a trade-off\nparameter between compression and reconstruction in the DVCCA family of\nalgorithms, resulting in the new beta-DVCCA family. In addition, we derive a\nnew variational dimensionality reduction method, deep variational symmetric\ninformational bottleneck (DVSIB), which simultaneously compresses two variables\nto preserve information between their compressed representations. We implement\nall of these algorithms and evaluate their ability to produce shared low\ndimensional latent spaces on a modified noisy MNIST dataset. We show that\nalgorithms that are better matched to the structure of the data (beta-DVCCA and\nDVSIB) produce better latent spaces as measured by classification accuracy and\nthe dimensionality of the latent variables. We believe that this framework can\nbe used to unify other multi-view representation learning algorithms.\nAdditionally, it provides a straightforward framework for deriving\nproblem-specific loss functions.",
          "link": "http://arxiv.org/abs/2310.03311",
          "publishedOn": "2023-10-07T00:42:18.696Z",
          "wordCount": null,
          "title": "Deep Variational Multivariate Information Bottleneck -- A Framework for Variational Losses. (arXiv:2310.03311v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.07454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Renanse_A/0/1/0/all/0/1\">Animesh Renanse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Alok Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1\">Rohitash Chandra</a>",
          "description": "It is well known that canonical recurrent neural networks (RNNs) face\nlimitations in learning long-term dependencies which have been addressed by\nmemory structures in long short-term memory (LSTM) networks. Neural Turing\nmachines (NTMs) are novel RNNs that implement the notion of programmable\ncomputers with neural network controllers that can learn simple algorithmic\ntasks. Matrix neural networks feature matrix representation which inherently\npreserves the spatial structure of data when compared to canonical neural\nnetworks that use vector-based representation. One may then argue that neural\nnetworks with matrix representations may have the potential to provide better\nmemory capacity. In this paper, we define and study a probabilistic notion of\nmemory capacity based on Fisher information for matrix-based RNNs. We find\nbounds on memory capacity for such networks under various hypotheses and\ncompare them with their vector counterparts. In particular, we show that the\nmemory capacity of such networks is bounded by $N^2$ for $N\\times N$ state\nmatrix which generalizes the one known for vector networks. We also show and\nanalyze the increase in memory capacity for such networks which is introduced\nwhen one exhibits an external state memory, such as NTMs. Consequently, we\nconstruct NTMs with RNN controllers with matrix-based representation of\nexternal memory, leading us to introduce Matrix NTMs. We demonstrate the\nperformance of this class of memory networks under certain algorithmic learning\ntasks such as copying and recall and compare it with Matrix RNNs. We find an\nimprovement in the performance of Matrix NTMs by the addition of external\nmemory, in comparison to Matrix RNNs.",
          "link": "http://arxiv.org/abs/2104.07454",
          "publishedOn": "2023-10-07T00:42:18.664Z",
          "wordCount": null,
          "title": "Memory Capacity of Recurrent Neural Networks with Matrix Representation. (arXiv:2104.07454v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karchmer_A/0/1/0/all/0/1\">Ari Karchmer</a>",
          "description": "(Abridged) Carmosino et al. (2016) demonstrated that natural proofs of\ncircuit lower bounds for \\Lambda imply efficient algorithms for learning\n\\Lambda-circuits, but only over the uniform distribution, with membership\nqueries, and provided \\AC^0[p] \\subseteq \\Lambda. We consider whether this\nimplication can be generalized to \\Lambda \\not\\supseteq \\AC^0[p], and to\nlearning algorithms in Valiant's PAC model, which use only random examples and\nlearn over arbitrary example distributions. We give results of both positive\nand negative flavor.\n\nOn the negative side, we observe that if, for every circuit class \\Lambda,\nthe implication from natural proofs for \\Lambda to learning \\Lambda-circuits in\nValiant's PAC model holds, then there is a polynomial time solution to\nO(n^{1.5})-uSVP (unique Shortest Vector Problem), and polynomial time quantum\nsolutions to O(n^{1.5})-SVP (Shortest Vector Problem) and O(n^{1.5})-SIVP\n(Shortest Independent Vector Problem). This indicates that whether natural\nproofs for \\Lambda imply efficient learning algorithms for \\Lambda in Valiant's\nPAC model may depend on \\Lambda.\n\nOn the positive side, our main result is that specific natural proofs arising\nfrom a type of communication complexity argument (e.g., Nisan (1993), for\ndepth-2 majority circuits) imply PAC-learning algorithms in a new\ndistributional variant of Valiant's model. Our distributional PAC model is\nstronger than the average-case prediction model of Blum et al (1993) and the\nheuristic PAC model of Nanashima (2021), and has several important properties\nwhich make it of independent interest, such as being boosting-friendly. The\nmain applications of our result are new distributional PAC-learning algorithms\nfor depth-2 majority circuits, polytopes and DNFs over natural target\ndistributions, as well as the nonexistence of encoded-input weak PRFs that can\nbe evaluated by depth-2 majority circuits.",
          "link": "http://arxiv.org/abs/2310.03641",
          "publishedOn": "2023-10-07T00:42:18.659Z",
          "wordCount": null,
          "title": "Distributional PAC-Learning from Nisan's Natural Proofs. (arXiv:2310.03641v1 [cs.CC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edin_A/0/1/0/all/0/1\">Adrian Edin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>",
          "description": "Over-the-Air (OtA) Federated Learning (FL) refers to an FL system where\nmultiple agents apply OtA computation for transmitting model updates to a\ncommon edge server. Two important features of OtA computation, namely linear\nprocessing and signal-level superposition, motivate the use of linear\ncompression with compressed sensing (CS) methods to reduce the number of data\nsamples transmitted over the channel. The previous works on applying CS methods\nin OtA FL have primarily assumed that the original model update vectors are\nsparse, or they have been sparsified before compression. However, it is unclear\nwhether linear compression with CS-based reconstruction is more effective than\ndirectly sending the non-zero elements in the sparsified update vectors, under\nthe same total power constraint. In this study, we examine and compare several\ncommunication designs with or without sparsification. Our findings demonstrate\nthat sparsification before compression is not necessary. Alternatively,\nsparsification without linear compression can also achieve better performance\nthan the commonly considered setup that combines both.",
          "link": "http://arxiv.org/abs/2310.03410",
          "publishedOn": "2023-10-07T00:42:18.650Z",
          "wordCount": null,
          "title": "Over-the-Air Federated Learning with Compressed Sensing: Is Sparsification Necessary?. (arXiv:2310.03410v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Collyer_J/0/1/0/all/0/1\">Josh Collyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watson_T/0/1/0/all/0/1\">Tim Watson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_I/0/1/0/all/0/1\">Iain Phillips</a>",
          "description": "Being able to identify functions of interest in cross-architecture software\nis useful whether you are analysing for malware, securing the software supply\nchain or conducting vulnerability research. Cross-Architecture Binary Code\nSimilarity Search has been explored in numerous studies and has used a wide\nrange of different data sources to achieve its goals. The data sources\ntypically used draw on common structures derived from binaries such as function\ncontrol flow graphs or binary level call graphs, the output of the disassembly\nprocess or the outputs of a dynamic analysis approach. One data source which\nhas received less attention is binary intermediate representations. Binary\nIntermediate representations possess two interesting properties: they are cross\narchitecture by their very nature and encode the semantics of a function\nexplicitly to support downstream usage. Within this paper we propose Function\nas a String Encoded Representation (FASER) which combines long document\ntransformers with the use of intermediate representations to create a model\ncapable of cross architecture function search without the need for manual\nfeature engineering, pre-training or a dynamic analysis step. We compare our\napproach against a series of baseline approaches for two tasks; A general\nfunction search task and a targeted vulnerability search task. Our approach\ndemonstrates strong performance across both tasks, performing better than all\nbaseline approaches.",
          "link": "http://arxiv.org/abs/2310.03605",
          "publishedOn": "2023-10-07T00:42:18.639Z",
          "wordCount": null,
          "title": "FASER: Binary Code Similarity Search through the use of Intermediate Representations. (arXiv:2310.03605v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03294",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dacheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1\">Rulin Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_A/0/1/0/all/0/1\">Anze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1\">Ion Stoica</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xuezhe Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>",
          "description": "Increasing the context length of large language models (LLMs) unlocks\nfundamentally new capabilities, but also significantly increases the memory\nfootprints of training. Previous model-parallel systems such as Megatron-LM\npartition and compute different attention heads in parallel, resulting in large\ncommunication volumes, so they cannot scale beyond the number of attention\nheads, thereby hindering its adoption. In this paper, we introduce a new\napproach, LightSeq, for long-context LLMs training. LightSeq has many notable\nadvantages. First, LightSeq partitions over the sequence dimension, hence is\nagnostic to model architectures and readily applicable for models with varying\nnumbers of attention heads, such as Multi-Head, Multi-Query and Grouped-Query\nattention. Second, LightSeq not only requires up to 4.7x less communication\nthan Megatron-LM on popular LLMs but also overlaps the communication with\ncomputation. To further reduce the training time, LightSeq features a novel\ngradient checkpointing scheme to bypass an forward computation for\nmemory-efficient attention. We evaluate LightSeq on Llama-7B and its variants\nwith sequence lengths from 32K to 512K. Through comprehensive experiments on\nsingle and cross-node training, we show that LightSeq achieves up to 1.24-2.01x\nend-to-end speedup, and a 2-8x longer sequence length on models with fewer\nheads, compared to Megatron-LM. Codes will be available at\nhttps://github.com/RulinShao/LightSeq.",
          "link": "http://arxiv.org/abs/2310.03294",
          "publishedOn": "2023-10-07T00:42:18.625Z",
          "wordCount": null,
          "title": "LightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers. (arXiv:2310.03294v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+George_V/0/1/0/all/0/1\">Victor Vadakechirayath George</a>",
          "description": "Inspired by recent developments in attention models for image classification\nand natural language processing, we present various Attention based\narchitectures in reinforcement learning (RL) domain, capable of performing well\non OpenAI Gym Atari-2600 game suite. In spite of the recent success of Deep\nReinforcement learning techniques in various fields like robotics, gaming and\nhealthcare, they suffer from a major drawback that neural networks are\ndifficult to interpret. We try to get around this problem with the help of\nAttention based models. In Attention based models, extracting and overlaying of\nattention map onto images allows for direct observation of information used by\nagent to select actions and easier interpretation of logic behind the chosen\nactions. Our models in addition to playing well on gym-Atari environments, also\nprovide insights on how agent perceives its environment. In addition, motivated\nby recent developments in attention based video-classification models using\nVision Transformer, we come up with an architecture based on Vision\nTransformer, for image-based RL domain too. Compared to previous works in\nVision Transformer, our model is faster to train and requires fewer\ncomputational resources. 3",
          "link": "http://arxiv.org/abs/2310.03161",
          "publishedOn": "2023-10-07T00:42:18.624Z",
          "wordCount": null,
          "title": "Neural architecture impact on identifying temporally extended Reinforcement Learning tasks. (arXiv:2310.03161v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03028",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Taub_R/0/1/0/all/0/1\">Ronen Taub</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Savir_Y/0/1/0/all/0/1\">Yonatan Savir</a>",
          "description": "Machine learning, and representation learning in particular, has the\npotential to facilitate drug discovery by screening a large chemical space in\nsilico. A successful approach for representing molecules is to treat them as a\ngraph and utilize graph neural networks. One of the key limitations of such\nmethods is the necessity to represent compounds with different numbers of\natoms, which requires aggregating the atom's information. Common aggregation\noperators, such as averaging, result in loss of information at the atom level.\nIn this work, we propose a novel aggregating approach where each atom is\nweighted non-linearly using the Boltzmann distribution with a hyperparameter\nanalogous to temperature. We show that using this weighted aggregation improves\nthe ability of the gold standard message-passing neural network to predict\nantibiotic activity. Moreover, by changing the temperature hyperparameter, our\napproach can reveal the atoms that are important for activity prediction in a\nsmooth and consistent way, thus providing a novel, regulated attention\nmechanism for graph neural networks. We further validate our method by showing\nthat it recapitulates the functional group in beta-Lactam antibiotics. The\nability of our approach to rank the atoms' importance for a desired function\ncan be used within any graph neural network to provide interpretability of the\nresults and predictions at the node level.",
          "link": "http://arxiv.org/abs/2310.03028",
          "publishedOn": "2023-10-07T00:42:18.612Z",
          "wordCount": null,
          "title": "SAF: Smart Aggregation Framework for Revealing Atoms Importance Rank and Improving Prediction Rates in Drug Discovery. (arXiv:2310.03028v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03234",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hu_Q/0/1/0/all/0/1\">Quanqi Hu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_D/0/1/0/all/0/1\">Dixian Zhu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "This paper investigates new families of compositional optimization problems,\ncalled $\\underline{\\bf n}$on-$\\underline{\\bf s}$mooth $\\underline{\\bf\nw}$eakly-$\\underline{\\bf c}$onvex $\\underline{\\bf f}$inite-sum $\\underline{\\bf\nc}$oupled $\\underline{\\bf c}$ompositional $\\underline{\\bf o}$ptimization (NSWC\nFCCO). There has been a growing interest in FCCO due to its wide-ranging\napplications in machine learning and AI, as well as its ability to address the\nshortcomings of stochastic algorithms based on empirical risk minimization.\nHowever, current research on FCCO presumes that both the inner and outer\nfunctions are smooth, limiting their potential to tackle a more diverse set of\nproblems. Our research expands on this area by examining non-smooth\nweakly-convex FCCO, where the outer function is weakly convex and\nnon-decreasing, and the inner function is weakly-convex. We analyze a\nsingle-loop algorithm and establish its complexity for finding an\n$\\epsilon$-stationary point of the Moreau envelop of the objective function.\nAdditionally, we also extend the algorithm to solving novel non-smooth\nweakly-convex tri-level finite-sum coupled compositional optimization problems,\nwhich feature a nested arrangement of three functions. Lastly, we explore the\napplications of our algorithms in deep learning for two-way partial AUC\nmaximization and multi-instance two-way partial AUC maximization, using\nempirical studies to showcase the effectiveness of the proposed algorithms.",
          "link": "http://arxiv.org/abs/2310.03234",
          "publishedOn": "2023-10-07T00:42:18.608Z",
          "wordCount": null,
          "title": "Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03032",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Cong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianyong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>",
          "description": "Embedding plays a critical role in modern recommender systems because they\nare virtual representations of real-world entities and the foundation for\nsubsequent decision models. In this paper, we propose a novel embedding update\nmechanism, Structure-aware Embedding Evolution (SEvo for short), to encourage\nrelated nodes to evolve similarly at each step. Unlike GNN (Graph Neural\nNetwork) that typically serves as an intermediate part, SEvo is able to\ndirectly inject the graph structure information into embedding with negligible\ncomputational overhead in training. The convergence properties of SEvo as well\nas its possible variants are theoretically analyzed to justify the validity of\nthe designs. Moreover, SEvo can be seamlessly integrated into existing\noptimizers for state-of-the-art performance. In particular, SEvo-enhanced AdamW\nwith moment estimate correction demonstrates consistent improvements across a\nspectrum of models and datasets, suggesting a novel technical route to\neffectively utilize graph structure information beyond explicit GNN modules.",
          "link": "http://arxiv.org/abs/2310.03032",
          "publishedOn": "2023-10-07T00:42:18.607Z",
          "wordCount": null,
          "title": "Graph-enhanced Optimizers for Structure-aware Recommendation Embedding Evolution. (arXiv:2310.03032v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zihao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yifan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xueqian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lifu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "With the blowout development of pre-trained models (PTMs), the efficient\ntuning of these models for diverse downstream applications has emerged as a\npivotal research concern. Although recent investigations into prompt tuning\nhave provided promising avenues, three salient challenges persist: (1) memory\nconstraint: the continuous growth in the size of open-source PTMs renders\nfine-tuning, even a fraction of their parameters, challenging for many\npractitioners. (2) model privacy: existing PTMs often function as public API\nservices, with their parameters inaccessible for effective or tailored\nfine-tuning. (3) data privacy: the fine-tuning of PTMs necessitates\nhigh-quality datasets, which are typically localized and not shared to public.\nTo optimally harness each local dataset while navigating memory constraints and\npreserving privacy, we propose Federated Black-Box Prompt Tuning (Fed-BBPT).\nThis innovative approach eschews reliance on parameter architectures and\nprivate dataset access, instead capitalizing on a central server that aids\nlocal users in collaboratively training a prompt generator through regular\naggregation. Local users leverage API-driven learning via a zero-order\noptimizer, obviating the need for PTM deployment. Relative to extensive\nfine-tuning, Fed-BBPT proficiently sidesteps memory challenges tied to PTM\nstorage and fine-tuning on local machines, tapping into comprehensive,\nhigh-quality, yet private training datasets. A thorough evaluation across 40\ndatasets spanning CV and NLP tasks underscores the robustness of our proposed\nmodel.",
          "link": "http://arxiv.org/abs/2310.03123",
          "publishedOn": "2023-10-07T00:42:18.605Z",
          "wordCount": null,
          "title": "Efficient Federated Prompt Tuning for Black-box Large Pre-trained Models. (arXiv:2310.03123v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Woisetschlager_H/0/1/0/all/0/1\">Herbert Woisetschl&#xe4;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isenko_A/0/1/0/all/0/1\">Alexander Isenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shiqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayer_R/0/1/0/all/0/1\">Ruben Mayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobsen_H/0/1/0/all/0/1\">Hans-Arno Jacobsen</a>",
          "description": "Large Language Models (LLM) and foundation models are popular as they offer\nnew opportunities for individuals and businesses to improve natural language\nprocessing, interact with data, and retrieve information faster. However,\ntraining or fine-tuning LLMs requires a vast amount of data, which can be\nchallenging to access due to legal or technical restrictions and may require\nprivate computing resources. Federated Learning (FL) is a solution designed to\novercome these challenges and expand data access for deep learning\napplications.\n\nThis paper takes a hardware-centric approach to explore how LLMs can be\nbrought to modern edge computing systems. Our study fine-tunes the FLAN-T5\nmodel family, ranging from 80M to 3B parameters, using FL for a text\nsummarization task. We provide a micro-level hardware benchmark, compare the\nmodel FLOP utilization to a state-of-the-art data center GPU, and study the\nnetwork utilization in realistic conditions. Our contribution is twofold:\nFirst, we evaluate the current capabilities of edge computing systems and their\npotential for LLM FL workloads. Second, by comparing these systems with a\ndata-center GPU, we demonstrate the potential for improvement and the next\nsteps toward achieving greater computational efficiency at the edge.",
          "link": "http://arxiv.org/abs/2310.03150",
          "publishedOn": "2023-10-07T00:42:18.602Z",
          "wordCount": null,
          "title": "Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly. (arXiv:2310.03150v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03178",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Liangqi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1\">Christopher G. Brinton</a>",
          "description": "The Internet of Things (IoT) consistently generates vast amounts of data,\nsparking increasing concern over the protection of data privacy and the\nlimitation of data misuse. Federated learning (FL) facilitates collaborative\ncapabilities among multiple parties by sharing machine learning (ML) model\nparameters instead of raw user data, and it has recently gained significant\nattention for its potential in privacy preservation and learning efficiency\nenhancement. In this paper, we highlight the digital ethics concerns that arise\nwhen human-centric devices serve as clients in FL. More specifically,\nchallenges of game dynamics, fairness, incentive, and continuity arise in FL\ndue to differences in perspectives and objectives between clients and the\nserver. We analyze these challenges and their solutions from the perspectives\nof both the client and the server, and through the viewpoints of centralized\nand decentralized FL. Finally, we explore the opportunities in FL for\nhuman-centric IoT as directions for future development.",
          "link": "http://arxiv.org/abs/2310.03178",
          "publishedOn": "2023-10-07T00:42:18.594Z",
          "wordCount": null,
          "title": "Digital Ethics in Federated Learning. (arXiv:2310.03178v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruiyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>",
          "description": "Tabular data prediction is a fundamental machine learning task for many\napplications. Existing methods predominantly employ discriminative modeling and\noperate under the assumption of a fixed target column, necessitating\nre-training for every new predictive task. Inspired by the generative power of\nlarge language models (LLMs), this paper exploits the idea of building\nuniversal tabular data predictors based on generative modeling, namely\nUniPredict. Here, we show that scaling up an LLM to extensive tabular datasets\nwith the capability of comprehending diverse tabular inputs and predicting for\ntarget variables following the input instructions. Specifically, we train a\nsingle LLM on an aggregation of 169 tabular datasets with diverse targets and\ncompare its performance against baselines that are trained on each dataset\nseparately. We observe this versatile UniPredict model demonstrates an\nadvantage over other models, ranging from 5.4% to 13.4%, when compared with the\nbest tree-boosting baseline and the best neural network baseline, respectively.\nWe further test UniPredict in few-shot learning settings on another 62 tabular\ndatasets. Our method achieves strong performance in quickly adapting to new\ntasks, where our method outperforms XGBoost over 100% on the low-resource setup\nand shows a significant margin over all baselines. We envision that UniPredict\nsheds light on developing a universal tabular data prediction system that\nlearns from data at scale and serves a wide range of prediction tasks.",
          "link": "http://arxiv.org/abs/2310.03266",
          "publishedOn": "2023-10-07T00:42:18.585Z",
          "wordCount": null,
          "title": "UniPredict: Large Language Models are Universal Tabular Predictors. (arXiv:2310.03266v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03121",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Eastman_P/0/1/0/all/0/1\">Peter Eastman</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Galvelis_R/0/1/0/all/0/1\">Raimondas Galvelis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pelaez_R/0/1/0/all/0/1\">Ra&#xfa;l P. Pel&#xe1;ez</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Abreu_C/0/1/0/all/0/1\">Charlles R. A. Abreu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Farr_S/0/1/0/all/0/1\">Stephen E. Farr</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gallicchio_E/0/1/0/all/0/1\">Emilio Gallicchio</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gorenko_A/0/1/0/all/0/1\">Anton Gorenko</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Henry_M/0/1/0/all/0/1\">Michael M. Henry</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hu_F/0/1/0/all/0/1\">Frank Hu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Huang_J/0/1/0/all/0/1\">Jing Huang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kramer_A/0/1/0/all/0/1\">Andreas Kr&#xe4;mer</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Michel_J/0/1/0/all/0/1\">Julien Michel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mitchell_J/0/1/0/all/0/1\">Joshua A. Mitchell</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pande_V/0/1/0/all/0/1\">Vijay S. Pande</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rodrigues_J/0/1/0/all/0/1\">Jo&#xe3;o PGLM Rodrigues</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rodriguez_Guerra_J/0/1/0/all/0/1\">Jaime Rodriguez-Guerra</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Simmonett_A/0/1/0/all/0/1\">Andrew C. Simmonett</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Swails_J/0/1/0/all/0/1\">Jason Swails</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_I/0/1/0/all/0/1\">Ivy Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chodera_J/0/1/0/all/0/1\">John D. Chodera</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Fabritiis_G/0/1/0/all/0/1\">Gianni De Fabritiis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Markland_T/0/1/0/all/0/1\">Thomas E. Markland</a>",
          "description": "Machine learning plays an important and growing role in molecular simulation.\nThe newest version of the OpenMM molecular dynamics toolkit introduces new\nfeatures to support the use of machine learning potentials. Arbitrary PyTorch\nmodels can be added to a simulation and used to compute forces and energy. A\nhigher-level interface allows users to easily model their molecules of interest\nwith general purpose, pretrained potential functions. A collection of optimized\nCUDA kernels and custom PyTorch operations greatly improves the speed of\nsimulations. We demonstrate these features on simulations of cyclin-dependent\nkinase 8 (CDK8) and the green fluorescent protein (GFP) chromophore in water.\nTaken together, these features make it practical to use machine learning to\nimprove the accuracy of simulations at only a modest increase in cost.",
          "link": "http://arxiv.org/abs/2310.03121",
          "publishedOn": "2023-10-07T00:42:18.546Z",
          "wordCount": null,
          "title": "OpenMM 8: Molecular Dynamics Simulation with Machine Learning Potentials. (arXiv:2310.03121v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gampa_P/0/1/0/all/0/1\">Phanideep Gampa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javadi_F/0/1/0/all/0/1\">Farnoosh Javadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bayar_B/0/1/0/all/0/1\">Belhassen Bayar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yessenalina_A/0/1/0/all/0/1\">Ainur Yessenalina</a>",
          "description": "Various data imbalances that naturally arise in a multi-territory\npersonalized recommender system can lead to a significant item bias for\nglobally prevalent items. A locally popular item can be overshadowed by a\nglobally prevalent item. Moreover, users' viewership patterns/statistics can\ndrastically change from one geographic location to another which may suggest to\nlearn specific user embeddings. In this paper, we propose a multi-task learning\n(MTL) technique, along with an adaptive upsampling method to reduce popularity\nbias in multi-territory recommendations. Our proposed framework is designed to\nenrich training examples with active users representation through upsampling,\nand capable of learning geographic-based user embeddings by leveraging MTL.\nThrough experiments, we demonstrate the effectiveness of our framework in\nmultiple territories compared to a baseline not incorporating our proposed\ntechniques.~Noticeably, we show improved relative gain of up to $65.27\\%$ in\nPR-AUC metric. A case study is presented to demonstrate the advantages of our\nmethods in attenuating the popularity bias of global items.",
          "link": "http://arxiv.org/abs/2310.03148",
          "publishedOn": "2023-10-07T00:42:18.526Z",
          "wordCount": null,
          "title": "Multi-Task Learning For Reduced Popularity Bias In Multi-Territory Video Recommendations. (arXiv:2310.03148v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Suresh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guruparan_D/0/1/0/all/0/1\">Dhanyashri Guruparan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aaron_P/0/1/0/all/0/1\">Pavithren Aaron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telajan_P/0/1/0/all/0/1\">Philemon Telajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadevan_K/0/1/0/all/0/1\">Kavinesh Mahadevan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davagandhi_D/0/1/0/all/0/1\">Dinesh Davagandhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_O/0/1/0/all/0/1\">Ong Xin Yue</a>",
          "description": "Deep learning has become a powerful tool in computational biology,\nrevolutionising the analysis and interpretation of biological data over time.\nIn our article review, we delve into various aspects of deep learning in\ncomputational biology. Specifically, we examine its history, advantages, and\nchallenges. Our focus is on two primary applications: DNA sequence\nclassification and prediction, as well as protein structure prediction from\nsequence data. Additionally, we provide insights into the outlook for this\nfield. To fully harness the potential of deep learning in computational\nbiology, it is crucial to address the challenges that come with it. These\nchallenges include the requirement for large, labelled datasets and the\ninterpretability of deep learning models. The use of deep learning in the\nanalysis of DNA sequences has brought about a significant transformation in the\ndetection of genomic variants and the analysis of gene expression. This has\ngreatly contributed to the advancement of personalised medicine and drug\ndiscovery. Convolutional neural networks (CNNs) have been shown to be highly\naccurate in predicting genetic variations and gene expression levels. Deep\nlearning techniques are used for analysing epigenetic data, including DNA\nmethylation and histone modifications. This provides valuable insights into\nmetabolic conditions and gene regulation. The field of protein structure\nprediction has been significantly impacted by deep learning, which has enabled\naccurate determination of the three-dimensional shape of proteins and\nprediction of their interactions. The future of deep learning in computational\nbiology looks promising. With the development of advanced deep learning models\nand interpretation techniques, there is potential to overcome current\nchallenges and further our understanding of biological systems.",
          "link": "http://arxiv.org/abs/2310.03086",
          "publishedOn": "2023-10-07T00:42:18.510Z",
          "wordCount": null,
          "title": "Deep Learning in Computational Biology: Advancements, Challenges, and Future Outlook. (arXiv:2310.03086v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_M/0/1/0/all/0/1\">Maziyar Khadivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charter_T/0/1/0/all/0/1\">Todd Charter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yaghoubi_M/0/1/0/all/0/1\">Marjan Yaghoubi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jalayer_M/0/1/0/all/0/1\">Masoud Jalayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahang_M/0/1/0/all/0/1\">Maryam Ahang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shojaeinasab_A/0/1/0/all/0/1\">Ardeshir Shojaeinasab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najjaran_H/0/1/0/all/0/1\">Homayoun Najjaran</a>",
          "description": "Machine scheduling aims to optimize job assignments to machines while\nadhering to manufacturing rules and job specifications. This optimization leads\nto reduced operational costs, improved customer demand fulfillment, and\nenhanced production efficiency. However, machine scheduling remains a\nchallenging combinatorial problem due to its NP-hard nature. Deep Reinforcement\nLearning (DRL), a key component of artificial general intelligence, has shown\npromise in various domains like gaming and robotics. Researchers have explored\napplying DRL to machine scheduling problems since 1995. This paper offers a\ncomprehensive review and comparison of DRL-based approaches, highlighting their\nmethodology, applications, advantages, and limitations. It categorizes these\napproaches based on computational components: conventional neural networks,\nencoder-decoder architectures, graph neural networks, and metaheuristic\nalgorithms. Our review concludes that DRL-based methods outperform exact\nsolvers, heuristics, and tabular reinforcement learning algorithms in terms of\ncomputation speed and generating near-global optimal solutions. These DRL-based\napproaches have been successfully applied to static and dynamic scheduling\nacross diverse machine environments and job characteristics. However, DRL-based\nschedulers face limitations in handling complex operational constraints,\nconfigurable multi-objective optimization, generalization, scalability,\ninterpretability, and robustness. Addressing these challenges will be a crucial\nfocus for future research in this field. This paper serves as a valuable\nresource for researchers to assess the current state of DRL-based machine\nscheduling and identify research gaps. It also aids experts and practitioners\nin selecting the appropriate DRL approach for production scheduling.",
          "link": "http://arxiv.org/abs/2310.03195",
          "publishedOn": "2023-10-07T00:42:18.510Z",
          "wordCount": null,
          "title": "Deep reinforcement learning for machine scheduling: Methodology, the state-of-the-art, and future directions. (arXiv:2310.03195v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03218",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peiyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaxuan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sirui Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "Latent space Energy-Based Models (EBMs), also known as energy-based priors,\nhave drawn growing interests in the field of generative modeling due to its\nflexibility in the formulation and strong modeling power of the latent space.\nHowever, the common practice of learning latent space EBMs with non-convergent\nshort-run MCMC for prior and posterior sampling is hindering the model from\nfurther progress; the degenerate MCMC sampling quality in practice often leads\nto degraded generation quality and instability in training, especially with\nhighly multi-modal and/or high-dimensional target distributions. To remedy this\nsampling issue, in this paper we introduce a simple but effective\ndiffusion-based amortization method for long-run MCMC sampling and develop a\nnovel learning algorithm for the latent space EBM based on it. We provide\ntheoretical evidence that the learned amortization of MCMC is a valid long-run\nMCMC sampler. Experiments on several image modeling benchmark datasets\ndemonstrate the superior performance of our method compared with strong\ncounterparts",
          "link": "http://arxiv.org/abs/2310.03218",
          "publishedOn": "2023-10-07T00:42:18.507Z",
          "wordCount": null,
          "title": "Learning Energy-Based Prior Model with Diffusion-Amortized MCMC. (arXiv:2310.03218v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03149",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Konz_N/0/1/0/all/0/1\">Nicholas Konz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godfrey_C/0/1/0/all/0/1\">Charles Godfrey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shapiro_M/0/1/0/all/0/1\">Madelyn Shapiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1\">Jonathan Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1\">Henry Kvinge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Davis Brown</a>",
          "description": "By now there is substantial evidence that deep learning models learn certain\nhuman-interpretable features as part of their internal representations of data.\nAs having the right (or wrong) concepts is critical to trustworthy machine\nlearning systems, it is natural to ask which inputs from the model's original\ntraining set were most important for learning a concept at a given layer. To\nanswer this, we combine data attribution methods with methods for probing the\nconcepts learned by a model. Training network and probe ensembles for two\nconcept datasets on a range of network layers, we use the recently developed\nTRAK method for large-scale data attribution. We find some evidence for\nconvergence, where removing the 10,000 top attributing images for a concept and\nretraining the model does not change the location of the concept in the network\nnor the probing sparsity of the concept. This suggests that rather than being\nhighly dependent on a few specific examples, the features that inform the\ndevelopment of a concept are spread in a more diffuse manner across its\nexemplars, implying robustness in concept formation.",
          "link": "http://arxiv.org/abs/2310.03149",
          "publishedOn": "2023-10-07T00:42:18.499Z",
          "wordCount": null,
          "title": "Attributing Learned Concepts in Neural Networks to Training Data. (arXiv:2310.03149v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Adam Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1\">Son Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montillo_A/0/1/0/all/0/1\">Albert Montillo</a>",
          "description": "Traditional deep learning (DL) suffers from two core problems. Firstly, it\nassumes training samples are independent and identically distributed. However,\nnumerous real-world datasets group samples by shared measurements (e.g., study\nparticipants or cells), violating this assumption. In these scenarios, DL can\nshow compromised performance, limited generalization, and interpretability\nissues, coupled with cluster confounding causing Type 1 and 2 errors. Secondly,\nmodels are typically trained for overall accuracy, often neglecting\nunderrepresented groups and introducing biases in crucial areas like loan\napprovals or determining health insurance rates, such biases can significantly\nimpact one's quality of life. To address both of these challenges\nsimultaneously, we present a mixed effects deep learning (MEDL) framework. MEDL\nseparately quantifies cluster-invariant fixed effects (FE) and cluster-specific\nrandom effects (RE) through the introduction of: 1) a cluster adversary which\nencourages the learning of cluster-invariant FE, 2) a Bayesian neural network\nwhich quantifies the RE, and a mixing function combining the FE an RE into a\nmixed-effect prediction. We marry this MEDL with adversarial debiasing, which\npromotes equality-of-odds fairness across FE, RE, and ME predictions for\nfairness-sensitive variables. We evaluated our approach using three datasets:\ntwo from census/finance focusing on income classification and one from\nhealthcare predicting hospitalization duration, a regression task. Our\nframework notably enhances fairness across all sensitive variables-increasing\nfairness up to 82% for age, 43% for race, 86% for sex, and 27% for\nmarital-status. Besides promoting fairness, our method maintains the robust\nperformance and clarity of MEDL. It's versatile, suitable for various dataset\ntypes and tasks, making it broadly applicable. Our GitHub repository houses the\nimplementation.",
          "link": "http://arxiv.org/abs/2310.03146",
          "publishedOn": "2023-10-07T00:42:18.498Z",
          "wordCount": null,
          "title": "Fairness-enhancing mixed effects deep learning improves fairness on in- and out-of-distribution clustered (non-iid) data. (arXiv:2310.03146v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_A/0/1/0/all/0/1\">An Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yiwu Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zexue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karypis_P/0/1/0/all/0/1\">Petros Karypis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chengyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gentili_A/0/1/0/all/0/1\">Amilcare Gentili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chun-Nan Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>",
          "description": "Medical image classification is a critical problem for healthcare, with the\npotential to alleviate the workload of doctors and facilitate diagnoses of\npatients. However, two challenges arise when deploying deep learning models to\nreal-world healthcare applications. First, neural models tend to learn spurious\ncorrelations instead of desired features, which could fall short when\ngeneralizing to new domains (e.g., patients with different ages). Second, these\nblack-box models lack interpretability. When making diagnostic predictions, it\nis important to understand why a model makes a decision for trustworthy and\nsafety considerations. In this paper, to address these two limitations, we\npropose a new paradigm to build robust and interpretable medical image\nclassifiers with natural language concepts. Specifically, we first query\nclinical concepts from GPT-4, then transform latent image features into\nexplicit concepts with a vision-language model. We systematically evaluate our\nmethod on eight medical image classification datasets to verify its\neffectiveness. On challenging datasets with strong confounding factors, our\nmethod can mitigate spurious correlations thus substantially outperform\nstandard visual encoders and other baselines. Finally, we show how\nclassification with a small number of concepts brings a level of\ninterpretability for understanding model decisions through case studies in real\nmedical data.",
          "link": "http://arxiv.org/abs/2310.03182",
          "publishedOn": "2023-10-07T00:42:18.484Z",
          "wordCount": null,
          "title": "Robust and Interpretable Medical Image Classifiers via Concept Bottleneck Models. (arXiv:2310.03182v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeromela_J/0/1/0/all/0/1\">Jovan Jeromela</a>",
          "description": "Twitter is currently one of the biggest social media platforms. Its users may\nshare, read, and engage with short posts called tweets. For the ACM Recommender\nSystems Conference 2020, Twitter published a dataset around 70 GB in size for\nthe annual RecSys Challenge. In 2020, the RecSys Challenge invited\nparticipating teams to create models that would predict engagement likelihoods\nfor given user-tweet combinations. The submitted models predicting like, reply,\nretweet, and quote engagements were evaluated based on two metrics: area under\nthe precision-recall curve (PRAUC) and relative cross-entropy (RCE).\n\nIn this diploma thesis, we used the RecSys 2020 Challenge dataset and\nevaluation procedure to investigate how well context alone may be used to\npredict tweet engagement likelihood. In doing so, we employed the Spark engine\non TU Wien's Little Big Data Cluster to create scalable data preprocessing,\nfeature engineering, feature selection, and machine learning pipelines. We\nmanually created just under 200 additional features to describe tweet context.\n\nThe results indicate that features describing users' prior engagement history\nand the popularity of hashtags and links in the tweet were the most\ninformative. We also found that factors such as the prediction algorithm,\ntraining dataset size, training dataset sampling method, and feature selection\nsignificantly affect the results. After comparing the best results of our\ncontext-only prediction models with content-only models and with models\ndeveloped by the Challenge winners, we identified that the context-based models\nunderperformed in terms of the RCE score. This work thus concludes by situating\nthis discrepancy and proposing potential improvements to our implementation,\nwhich is shared in a public git repository.",
          "link": "http://arxiv.org/abs/2310.03147",
          "publishedOn": "2023-10-07T00:42:18.449Z",
          "wordCount": null,
          "title": "Context-Based Tweet Engagement Prediction. (arXiv:2310.03147v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03334",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roshan_K/0/1/0/all/0/1\">Khushnaseeb Roshan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zafar_A/0/1/0/all/0/1\">Aasim Zafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haque_S/0/1/0/all/0/1\">Sheikh Burhan Ul Haque</a>",
          "description": "Network Intrusion Detection System (NIDS) is a key component in securing the\ncomputer network from various cyber security threats and network attacks.\nHowever, consider an unfortunate situation where the NIDS is itself attacked\nand vulnerable more specifically, we can say, How to defend the defender?. In\nAdversarial Machine Learning (AML), the malicious actors aim to fool the\nMachine Learning (ML) and Deep Learning (DL) models to produce incorrect\npredictions with intentionally crafted adversarial examples. These adversarial\nperturbed examples have become the biggest vulnerability of ML and DL based\nsystems and are major obstacles to their adoption in real-time and\nmission-critical applications such as NIDS. AML is an emerging research domain,\nand it has become a necessity for the in-depth study of adversarial attacks and\ntheir defence strategies to safeguard the computer network from various cyber\nsecurity threads. In this research work, we aim to cover important aspects\nrelated to NIDS, adversarial attacks and its defence mechanism to increase the\nrobustness of the ML and DL based NIDS. We implemented four powerful\nadversarial attack techniques, namely, Fast Gradient Sign Method (FGSM),\nJacobian Saliency Map Attack (JSMA), Projected Gradient Descent (PGD) and\nCarlini & Wagner (C&W) in NIDS. We analyzed its performance in terms of various\nperformance metrics in detail. Furthermore, the three heuristics defence\nstrategies, i.e., Adversarial Training (AT), Gaussian Data Augmentation (GDA)\nand High Confidence (HC), are implemented to improve the NIDS robustness under\nadversarial attack situations. The complete workflow is demonstrated in\nreal-time network with data packet flow. This research work provides the\noverall background for the researchers interested in AML and its implementation\nfrom a computer network security point of view.",
          "link": "http://arxiv.org/abs/2310.03334",
          "publishedOn": "2023-10-07T00:42:18.440Z",
          "wordCount": null,
          "title": "Untargeted White-box Adversarial Attack with Heuristic Defence Methods in Real-time Deep Learning based Network Intrusion Detection System. (arXiv:2310.03334v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03103",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1\">Guoyizhe Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Feng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1\">Anshul Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1\">Rama Chellappa</a>",
          "description": "Federated learning is a distributed machine learning paradigm that allows\nmultiple clients to collaboratively train a shared model with their local data.\nNonetheless, conventional federated learning algorithms often struggle to\ngeneralize well due to the ubiquitous domain shift across clients. In this\nwork, we consider a challenging yet realistic federated learning scenario where\nthe training data of each client originates from different domains. We address\nthe challenges of domain shift by leveraging the technique of prompt learning,\nand propose a novel method called Federated Dual Prompt Tuning (Fed-DPT).\nSpecifically, Fed-DPT employs a pre-trained vision-language model and then\napplies both visual and textual prompt tuning to facilitate domain adaptation\nover decentralized data. Extensive experiments of Fed-DPT demonstrate its\nsignificant effectiveness in domain-aware federated learning. With a\npre-trained CLIP model (ViT-Base as image encoder), the proposed Fed-DPT\nattains 68.4% average accuracy over six domains in the DomainNet dataset, which\nimproves the original CLIP by a large margin of 14.8%.",
          "link": "http://arxiv.org/abs/2310.03103",
          "publishedOn": "2023-10-07T00:42:18.283Z",
          "wordCount": null,
          "title": "Dual Prompt Tuning for Domain-Aware Federated Learning. (arXiv:2310.03103v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04870",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Na_W/0/1/0/all/0/1\">Woojoo Na</a>",
          "description": "We introduce RACH-Space, a novel classification method in ensemble learning.\nIn particular, we show its applicability as a label model for weakly supervised\nlearning. RACH-Space offers simplicity in implementation with minimal\nassumptions on the data or weak signals. The model is well suited for scenarios\nwhere fully labeled data is not available. Our method is built upon geometrical\ninterpretation of the space spanned by weak signals. Our analysis of the high\ndimensional convex hull structure underlying general set of weak signals\nbridges geometry with machine learning. Empirical results also demonstrate that\nRACH-Space works well in practice and compares favorably to best existing label\nmodels for weakly supervised learning.",
          "link": "http://arxiv.org/abs/2307.04870",
          "publishedOn": "2023-09-30T00:41:35.123Z",
          "wordCount": 642,
          "title": "RACH-Space: Reconstructing Adaptive Convex Hull Space with applications in weak supervision. (arXiv:2307.04870v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1\">Mert Pilanci</a>",
          "description": "In this paper, we introduce a novel analysis of neural networks based on\ngeometric (Clifford) algebra and convex optimization. We show that optimal\nweights of deep ReLU neural networks are given by the wedge product of training\nsamples when trained with standard regularized loss. Furthermore, the training\nproblem reduces to convex optimization over wedge product features, which\nencode the geometric structure of the training dataset. This structure is given\nin terms of signed volumes of triangles and parallelotopes generated by data\nvectors. The convex problem finds a small subset of samples via $\\ell_1$\nregularization to discover only relevant wedge product features. Our analysis\nprovides a novel perspective on the inner workings of deep neural networks and\nsheds light on the role of the hidden layers.",
          "link": "http://arxiv.org/abs/2309.16512",
          "publishedOn": "2023-09-30T00:41:32.940Z",
          "wordCount": 670,
          "title": "From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16374",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kishimoto_A/0/1/0/all/0/1\">Akihiro Kishimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kajino_H/0/1/0/all/0/1\">Hiroshi Kajino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirose_M/0/1/0/all/0/1\">Masataka Hirose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuchiwaki_J/0/1/0/all/0/1\">Junta Fuchiwaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priyadarsini_I/0/1/0/all/0/1\">Indra Priyadarsini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamada_L/0/1/0/all/0/1\">Lisa Hamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shinohara_H/0/1/0/all/0/1\">Hajime Shinohara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakano_D/0/1/0/all/0/1\">Daiju Nakano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_S/0/1/0/all/0/1\">Seiji Takeda</a>",
          "description": "Property prediction plays an important role in material discovery. As an\ninitial step to eventually develop a foundation model for material science, we\nintroduce a new autoencoder called the MHG-GNN, which combines graph neural\nnetwork (GNN) with Molecular Hypergraph Grammar (MHG). Results on a variety of\nproperty prediction tasks with diverse materials show that MHG-GNN is\npromising.",
          "link": "http://arxiv.org/abs/2309.16374",
          "publishedOn": "2023-09-30T00:41:32.934Z",
          "wordCount": 582,
          "title": "MHG-GNN: Combination of Molecular Hypergraph Grammar with Graph Neural Network. (arXiv:2309.16374v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.05135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kaiyue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xiao-Jun Zeng</a>",
          "description": "It can largely benefit the reinforcement learning (RL) process of each agent\nif multiple geographically distributed agents perform their separate RL tasks\ncooperatively. Different from multi-agent reinforcement learning (MARL) where\nmultiple agents are in a common environment and should learn to cooperate or\ncompete with each other, in this case each agent has its separate environment\nand only communicates with others to share knowledge without any cooperative or\ncompetitive behaviour as a learning outcome. In fact, this scenario exists\nwidely in real life whose concept can be utilised in many applications, but is\nnot well understood yet and not well formulated. As the first effort, we\npropose group-agent system for RL as a formulation of this scenario and the\nthird type of RL system with respect to single-agent and multi-agent systems.\nWe then propose a distributed RL framework called DDAL (Decentralised\nDistributed Asynchronous Learning) designed for group-agent reinforcement\nlearning (GARL). We show through experiments that DDAL achieved desirable\nperformance with very stable training and has good scalability.",
          "link": "http://arxiv.org/abs/2202.05135",
          "publishedOn": "2023-09-30T00:41:32.875Z",
          "wordCount": 693,
          "title": "Group-Agent Reinforcement Learning. (arXiv:2202.05135v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Metzen_J/0/1/0/all/0/1\">Jan Hendrik Metzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saranrittichai_P/0/1/0/all/0/1\">Piyapat Saranrittichai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mummadi_C/0/1/0/all/0/1\">Chaithanya Kumar Mummadi</a>",
          "description": "Classifiers built upon vision-language models such as CLIP have shown\nremarkable zero-shot performance across a broad range of image classification\ntasks. Prior work has studied different ways of automatically creating\ndescriptor sets for every class based on prompt templates, ranging from\nmanually engineered templates over templates obtained from a large language\nmodel to templates built from random words and characters. In contrast,\nderiving zero-shot classifiers from the respective encoded class descriptors\nhas remained nearly unchanged, that is: classify to the class that maximizes\nthe cosine similarity between its averaged encoded class descriptors and the\nencoded image. However, weighting all class descriptors equally can be\nsuboptimal when certain descriptors match visual clues on a given image better\nthan others. In this work, we propose AutoCLIP, a method for auto-tuning\nzero-shot classifiers. AutoCLIP assigns to each prompt template per-image\nweights, which are derived from statistics of class descriptor-image\nsimilarities at inference time. AutoCLIP is fully unsupervised, has very low\noverhead, and can be easily implemented in few lines of code. We show that for\na broad range of vision-language models, datasets, and prompt templates,\nAutoCLIP outperforms baselines consistently and by up to 3 percent point\naccuracy.",
          "link": "http://arxiv.org/abs/2309.16414",
          "publishedOn": "2023-09-30T00:41:32.841Z",
          "wordCount": 700,
          "title": "AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models. (arXiv:2309.16414v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.15963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moezzi_M/0/1/0/all/0/1\">Matin Moezzi</a>",
          "description": "Consistency regularization-based methods are prevalent in semi-supervised\nlearning (SSL) algorithms due to their exceptional performance. However, they\nmainly depend on domain-specific data augmentations, which are not usable in\ndomains where data augmentations are less practicable. On the other hand,\nPseudo-labeling (PL) is a general and domain-agnostic SSL approach that, unlike\nconsistency regularization-based methods, does not rely on the domain. PL\nunderperforms due to the erroneous high-confidence predictions from poorly\ncalibrated models. This paper proposes an uncertainty-aware pseudo-label\nselection framework that employs uncertainty sets yielded by the conformal\nregularization algorithm to fix the poor calibration neural networks, reducing\nnoisy training data. The codes of this work are available at:\nhttps://github.com/matinmoezzi/ups conformal classification",
          "link": "http://arxiv.org/abs/2309.15963",
          "publishedOn": "2023-09-30T00:41:32.829Z",
          "wordCount": 603,
          "title": "An Uncertainty-Aware Pseudo-Label Selection Framework using Regularized Conformal Prediction. (arXiv:2309.15963v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trawicki_S/0/1/0/all/0/1\">Stefan Trawicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hackett_W/0/1/0/all/0/1\">William Hackett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_L/0/1/0/all/0/1\">Lewis Birch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suri_N/0/1/0/all/0/1\">Neeraj Suri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garraghan_P/0/1/0/all/0/1\">Peter Garraghan</a>",
          "description": "Adversarial Machine Learning (AML) is a rapidly growing field of security\nresearch, with an often overlooked area being model attacks through\nside-channels. Previous works show such attacks to be serious threats, though\nlittle progress has been made on efficient remediation strategies that avoid\ncostly model re-engineering. This work demonstrates a new defense against AML\nside-channel attacks using model compilation techniques, namely tensor\noptimization. We show relative model attack effectiveness decreases of up to\n43% using tensor optimization, discuss the implications, and direction of\nfuture work.",
          "link": "http://arxiv.org/abs/2309.16577",
          "publishedOn": "2023-09-30T00:41:32.590Z",
          "wordCount": 617,
          "title": "Compilation as a Defense: Enhancing DL Model Attack Robustness via Tensor Optimization. (arXiv:2309.16577v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klinger_T/0/1/0/all/0/1\">Tim Klinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Luke Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1\">Soham Dan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crouse_M/0/1/0/all/0/1\">Maxwell Crouse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1\">Parikshit Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gray_A/0/1/0/all/0/1\">Alexander Gray</a>",
          "description": "Compositional generalization is a key ability of humans that enables us to\nlearn new concepts from only a handful examples. Machine learning models,\nincluding the now ubiquitous transformers, struggle to generalize in this way,\nand typically require thousands of examples of a concept during training in\norder to generalize meaningfully. This difference in ability between humans and\nartificial neural architectures, motivates this study on a neuro-symbolic\narchitecture called the Compositional Program Generator (CPG). CPG has three\nkey features: modularity, type abstraction, and recursive composition, that\nenable it to generalize both systematically to new concepts in a few-shot\nmanner, as well as productively by length on various sequence-to-sequence\nlanguage tasks. For each input, CPG uses a grammar of the input domain and a\nparser to generate a type hierarchy in which each grammar rule is assigned its\nown unique semantic module, a probabilistic copy or substitution program.\nInstances with the same hierarchy are processed with the same composed program,\nwhile those with different hierarchies may be processed with different\nprograms. CPG learns parameters for the semantic modules and is able to learn\nthe semantics for new types incrementally. Given a context-free grammar of the\ninput language and a dictionary mapping each word in the source language to its\ninterpretation in the output language, CPG can achieve perfect generalization\non the SCAN and COGS benchmarks, in both standard and extreme few-shot\nsettings.",
          "link": "http://arxiv.org/abs/2309.16467",
          "publishedOn": "2023-09-30T00:41:32.535Z",
          "wordCount": 758,
          "title": "Compositional Program Generation for Systematic Generalization. (arXiv:2309.16467v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>",
          "description": "Semi-supervised learning (SSL) is a promising approach for training deep\nclassification models using labeled and unlabeled datasets. However, existing\nSSL methods rely on a large unlabeled dataset, which may not always be\navailable in many real-world applications due to legal constraints (e.g.,\nGDPR). In this paper, we investigate the research question: Can we train SSL\nmodels without real unlabeled datasets? Instead of using real unlabeled\ndatasets, we propose an SSL method using synthetic datasets generated from\ngenerative foundation models trained on datasets containing millions of samples\nin diverse domains (e.g., ImageNet). Our main concepts are identifying\nsynthetic samples that emulate unlabeled samples from generative foundation\nmodels and training classifiers using these synthetic samples. To achieve this,\nour method is formulated as an alternating optimization problem: (i)\nmeta-learning of generative foundation models and (ii) SSL of classifiers using\nreal labeled and synthetic unlabeled samples. For (i), we propose a\nmeta-learning objective that optimizes latent variables to generate samples\nthat resemble real labeled samples and minimize the validation loss. For (ii),\nwe propose a simple unsupervised loss function that regularizes the feature\nextractors of classifiers to maximize the performance improvement obtained from\nsynthetic samples. We confirm that our method outperforms baselines using\ngenerative foundation models on SSL. We also demonstrate that our methods\noutperform SSL using real unlabeled datasets in scenarios with extremely small\namounts of labeled datasets. This suggests that synthetic samples have the\npotential to provide improvement gains more efficiently than real unlabeled\ndata.",
          "link": "http://arxiv.org/abs/2309.16143",
          "publishedOn": "2023-09-30T00:41:32.460Z",
          "wordCount": 761,
          "title": "Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples. (arXiv:2309.16143v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.05832",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Mengti Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Bowen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bianchini_B/0/1/0/all/0/1\">Bibit Bianchini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_C/0/1/0/all/0/1\">Camillo Jose Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Posa_M/0/1/0/all/0/1\">Michael Posa</a>",
          "description": "This work presents an instance-agnostic learning framework that fuses vision\nwith dynamics to simultaneously learn shape, pose trajectories, and physical\nproperties via the use of geometry as a shared representation. Unlike many\ncontact learning approaches that assume motion capture input and a known shape\nprior for the collision model, our proposed framework learns an object's\ngeometric and dynamic properties from RGBD video, without requiring either\ncategory-level or instance-level shape priors. We integrate a vision system,\nBundleSDF, with a dynamics system, ContactNets, and propose a cyclic training\npipeline to use the output from the dynamics module to refine the poses and the\ngeometry from the vision module, using perspective reprojection. Experiments\ndemonstrate our framework's ability to learn the geometry and dynamics of rigid\nand convex objects and improve upon the current tracking framework.",
          "link": "http://arxiv.org/abs/2309.05832",
          "publishedOn": "2023-09-30T00:41:32.379Z",
          "wordCount": 662,
          "title": "Instance-Agnostic Geometry and Contact Dynamics Learning. (arXiv:2309.05832v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.02941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mamedov_S/0/1/0/all/0/1\">Shamil Mamedov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reiter_R/0/1/0/all/0/1\">Rudolf Reiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azad_S/0/1/0/all/0/1\">Seyed Mahdi Basiri Azad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boedecker_J/0/1/0/all/0/1\">Joschka Boedecker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diehl_M/0/1/0/all/0/1\">Moritz Diehl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swevers_J/0/1/0/all/0/1\">Jan Swevers</a>",
          "description": "Flexible robots may overcome some of the industry's major challenges, such as\nenabling intrinsically safe human-robot collaboration and achieving a higher\nload-to-mass ratio. However, controlling flexible robots is complicated due to\ntheir complex dynamics, which include oscillatory behavior and a\nhigh-dimensional state space. NMPC offers an effective means to control such\nrobots, but its extensive computational demands often limit its application in\nreal-time scenarios. To enable fast control of flexible robots, we propose a\nframework for a safe approximation of NMPC using imitation learning and a\npredictive safety filter. Our framework significantly reduces computation time\nwhile incurring a slight loss in performance. Compared to NMPC, our framework\nshows more than a eightfold improvement in computation time when controlling a\nthree-dimensional flexible robot arm in simulation, all while guaranteeing\nsafety constraints. Notably, our approach outperforms conventional\nreinforcement learning methods. The development of fast and safe approximate\nNMPC holds the potential to accelerate the adoption of flexible robots in\nindustry.",
          "link": "http://arxiv.org/abs/2212.02941",
          "publishedOn": "2023-09-30T00:41:32.351Z",
          "wordCount": 701,
          "title": "Safe Imitation Learning of Nonlinear Model Predictive Control for Flexible Robots. (arXiv:2212.02941v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.04811",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Zhang_C/0/1/0/all/0/1\">Cheng Zhang</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Sjarif_N/0/1/0/all/0/1\">Nilam Nur Amir Sjarif</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Ibrahim_R/0/1/0/all/0/1\">Roslina Ibrahim</a>",
          "description": "Accurately predicting the prices of financial time series is essential and\nchallenging for the financial sector. Owing to recent advancements in deep\nlearning techniques, deep learning models are gradually replacing traditional\nstatistical and machine learning models as the first choice for price\nforecasting tasks. This shift in model selection has led to a notable rise in\nresearch related to applying deep learning models to price forecasting,\nresulting in a rapid accumulation of new knowledge. Therefore, we conducted a\nliterature review of relevant studies over the past three years with a view to\naiding researchers and practitioners in the field. This review delves deeply\ninto deep learning-based forecasting models, presenting information on model\narchitectures, practical applications, and their respective advantages and\ndisadvantages. In particular, detailed information is provided on advanced\nmodels for price forecasting, such as Transformers, generative adversarial\nnetworks (GANs), graph neural networks (GNNs), and deep quantum neural networks\n(DQNNs). The present contribution also includes potential directions for future\nresearch, such as examining the effectiveness of deep learning models with\ncomplex structures for price forecasting, extending from point prediction to\ninterval prediction using deep learning models, scrutinising the reliability\nand validity of decomposition ensembles, and exploring the influence of data\nvolume on model performance.",
          "link": "http://arxiv.org/abs/2305.04811",
          "publishedOn": "2023-09-30T00:41:31.998Z",
          "wordCount": 775,
          "title": "Deep learning models for price forecasting of financial time series: A review of recent advancements: 2020-2022. (arXiv:2305.04811v2 [q-fin.ST] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Haoyu Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anicic_D/0/1/0/all/0/1\">Darko Anicic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Runkler_T/0/1/0/all/0/1\">Thomas A. Runkler</a>",
          "description": "The field of Tiny Machine Learning (TinyML) has made substantial advancements\nin democratizing machine learning on low-footprint devices, such as\nmicrocontrollers. The prevalence of these miniature devices raises the question\nof whether aggregating their knowledge can benefit TinyML applications.\nFederated meta-learning is a promising answer to this question, as it addresses\nthe scarcity of labeled data and heterogeneous data distribution across devices\nin the real world. However, deploying TinyML hardware faces unique resource\nconstraints, making existing methods impractical due to energy, privacy, and\ncommunication limitations. We introduce TinyMetaFed, a model-agnostic\nmeta-learning framework suitable for TinyML. TinyMetaFed facilitates\ncollaborative training of a neural network initialization that can be quickly\nfine-tuned on new devices. It offers communication savings and privacy\nprotection through partial local reconstruction and Top-P% selective\ncommunication, computational efficiency via online learning, and robustness to\nclient heterogeneity through few-shot learning. The evaluations on three TinyML\nuse cases demonstrate that TinyMetaFed can significantly reduce energy\nconsumption and communication overhead, accelerate convergence, and stabilize\nthe training process.",
          "link": "http://arxiv.org/abs/2307.06822",
          "publishedOn": "2023-09-30T00:41:31.940Z",
          "wordCount": 716,
          "title": "TinyMetaFed: Efficient Federated Meta-Learning for TinyML. (arXiv:2307.06822v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16604",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1\">Junjie Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Labeau_M/0/1/0/all/0/1\">Matthieu Labeau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+dAlche_Buc_F/0/1/0/all/0/1\">Florence d&#x27;Alch&#xe9;-Buc</a>",
          "description": "Pairwise comparison of graphs is key to many applications in Machine learning\nranging from clustering, kernel-based classification/regression and more\nrecently supervised graph prediction. Distances between graphs usually rely on\ninformative representations of these structured objects such as bag of\nsubstructures or other graph embeddings. A recently popular solution consists\nin representing graphs as metric measure spaces, allowing to successfully\nleverage Optimal Transport, which provides meaningful distances allowing to\ncompare them: the Gromov-Wasserstein distances. However, this family of\ndistances overlooks edge attributes, which are essential for many structured\nobjects. In this work, we introduce an extension of Gromov-Wasserstein distance\nfor comparing graphs whose both nodes and edges have features. We propose novel\nalgorithms for distance and barycenter computation. We empirically show the\neffectiveness of the novel distance in learning tasks where graphs occur in\neither input space or output space, such as classification and graph\nprediction.",
          "link": "http://arxiv.org/abs/2309.16604",
          "publishedOn": "2023-09-30T00:41:31.859Z",
          "wordCount": 649,
          "title": "Exploiting Edge Features in Graphs with Fused Network Gromov-Wasserstein Distance. (arXiv:2309.16604v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.15891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Keke Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xiong-bin Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">Shi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zheng Ma</a>",
          "description": "In this paper, we introduce two types of novel Asymptotic-Preserving\nConvolutional Deep Operator Networks (APCONs) designed to address the\nmultiscale time-dependent linear transport problem. We observe that the vanilla\nphysics-informed DeepONets with modified MLP may exhibit instability in\nmaintaining the desired limiting macroscopic behavior. Therefore, this\nnecessitates the utilization of an asymptotic-preserving loss function. Drawing\ninspiration from the heat kernel in the diffusion equation, we propose a new\narchitecture called Convolutional Deep Operator Networks, which employ multiple\nlocal convolution operations instead of a global heat kernel, along with\npooling and activation operations in each filter layer. Our APCON methods\npossess a parameter count that is independent of the grid size and are capable\nof capturing the diffusive behavior of the linear transport problem. Finally,\nwe validate the effectiveness of our methods through several numerical\nexamples.",
          "link": "http://arxiv.org/abs/2306.15891",
          "publishedOn": "2023-09-30T00:41:31.421Z",
          "wordCount": 698,
          "title": "Capturing the Diffusive Behavior of the Multiscale Linear Transport Equations by Asymptotic-Preserving Convolutional DeepONets. (arXiv:2306.15891v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1\">Neelesh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aran_O/0/1/0/all/0/1\">Oya Aran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1\">Venugopal Vasudevan</a>",
          "description": "Automated diagnosis of eczema from digital camera images is crucial for\ndeveloping applications that allow patients to self-monitor their recovery. An\nimportant component of this is the segmentation of eczema region from such\nimages. Current methods for eczema segmentation rely on deep neural networks\nsuch as convolutional (CNN)-based U-Net or transformer-based Swin U-Net. While\neffective, these methods require high volume of annotated data, which can be\ndifficult to obtain. Here, we investigate the capabilities of visual in-context\nlearning that can perform few-shot eczema segmentation with just a handful of\nexamples and without any need for retraining models. Specifically, we propose a\nstrategy for applying in-context learning for eczema segmentation with a\ngeneralist vision model called SegGPT. When benchmarked on a dataset of\nannotated eczema images, we show that SegGPT with just 2 representative example\nimages from the training dataset performs better (mIoU: 36.69) than a CNN U-Net\ntrained on 428 images (mIoU: 32.60). We also discover that using more number of\nexamples for SegGPT may in fact be harmful to its performance. Our result\nhighlights the importance of visual in-context learning in developing faster\nand better solutions to skin imaging tasks. Our result also paves the way for\ndeveloping inclusive solutions that can cater to minorities in the demographics\nwho are typically heavily under-represented in the training data.",
          "link": "http://arxiv.org/abs/2309.16656",
          "publishedOn": "2023-09-30T00:41:31.401Z",
          "wordCount": 714,
          "title": "Visual In-Context Learning for Few-Shot Eczema Segmentation. (arXiv:2309.16656v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.06612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghebriout_M/0/1/0/all/0/1\">Mohamed Imed Eddine Ghebriout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouzidi_H/0/1/0/all/0/1\">Halima Bouzidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niar_S/0/1/0/all/0/1\">Smail Niar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouarnoughi_H/0/1/0/all/0/1\">Hamza Ouarnoughi</a>",
          "description": "The recent surge of interest surrounding Multimodal Neural Networks (MM-NN)\nis attributed to their ability to effectively process and integrate multiscale\ninformation from diverse data sources. MM-NNs extract and fuse features from\nmultiple modalities using adequate unimodal backbones and specific fusion\nnetworks. Although this helps strengthen the multimodal information\nrepresentation, designing such networks is labor-intensive. It requires tuning\nthe architectural parameters of the unimodal backbones, choosing the fusing\npoint, and selecting the operations for fusion. Furthermore, multimodality AI\nis emerging as a cutting-edge option in Internet of Things (IoT) systems where\ninference latency and energy consumption are critical metrics in addition to\naccuracy. In this paper, we propose Harmonic-NAS, a framework for the joint\noptimization of unimodal backbones and multimodal fusion networks with hardware\nawareness on resource-constrained devices. Harmonic-NAS involves a two-tier\noptimization approach for the unimodal backbone architectures and fusion\nstrategy and operators. By incorporating the hardware dimension into the\noptimization, evaluation results on various devices and multimodal datasets\nhave demonstrated the superiority of Harmonic-NAS over state-of-the-art\napproaches achieving up to 10.9% accuracy improvement, 1.91x latency reduction,\nand 2.14x energy efficiency gain.",
          "link": "http://arxiv.org/abs/2309.06612",
          "publishedOn": "2023-09-30T00:41:31.351Z",
          "wordCount": 732,
          "title": "Harmonic-NAS: Hardware-Aware Multimodal Neural Architecture Search on Resource-constrained Devices. (arXiv:2309.06612v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.13405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiwen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_J/0/1/0/all/0/1\">Jiaxi Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palomar_D/0/1/0/all/0/1\">Daniel P. Palomar</a>",
          "description": "This paper studies the problem of learning the large-scale Gaussian graphical\nmodels that are multivariate totally positive of order two ($\\text{MTP}_2$). By\nintroducing the concept of bridge, which commonly exists in large-scale sparse\ngraphs, we show that the entire problem can be equivalently optimized through\n(1) several smaller-scaled sub-problems induced by a \\emph{bridge-block\ndecomposition} on the thresholded sample covariance graph and (2) a set of\nexplicit solutions on entries corresponding to \\emph{bridges}. From practical\naspect, this simple and provable discipline can be applied to break down a\nlarge problem into small tractable ones, leading to enormous reduction on the\ncomputational complexity and substantial improvements for all existing\nalgorithms. The synthetic and real-world experiments demonstrate that our\nproposed method presents a significant speed-up compared to the\nstate-of-the-art benchmarks.",
          "link": "http://arxiv.org/abs/2309.13405",
          "publishedOn": "2023-09-30T00:41:31.272Z",
          "wordCount": 655,
          "title": "Learning Large-Scale MTP$_2$ Gaussian Graphical Models via Bridge-Block Decomposition. (arXiv:2309.13405v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1911.09307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Ke Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhanxing Zhu</a>",
          "description": "Regularization plays a crucial role in machine learning models, especially\nfor deep neural networks. The existing regularization techniques mainly rely on\nthe i.i.d. assumption and only consider the knowledge from the current sample,\nwithout the leverage of the neighboring relationship between samples. In this\nwork, we propose a general regularizer called \\textbf{Patch-level Neighborhood\nInterpolation~(Pani)} that conducts a non-local representation in the\ncomputation of networks. Our proposal explicitly constructs patch-level graphs\nin different layers and then linearly interpolates neighborhood patch features,\nserving as a general and effective regularization strategy. Further, we\ncustomize our approach into two kinds of popular regularization methods, namely\nVirtual Adversarial Training (VAT) and MixUp as well as its variants. The first\nderived \\textbf{Pani VAT} presents a novel way to construct non-local\nadversarial smoothness by employing patch-level interpolated perturbations. The\nsecond derived \\textbf{Pani MixUp} method extends the MixUp, and achieves\nsuperiority over MixUp and competitive performance over state-of-the-art\nvariants of MixUp method with a significant advantage in computational\nefficiency. Extensive experiments have verified the effectiveness of our Pani\napproach in both supervised and semi-supervised settings.",
          "link": "http://arxiv.org/abs/1911.09307",
          "publishedOn": "2023-09-30T00:41:31.266Z",
          "wordCount": 729,
          "title": "Patch-level Neighborhood Interpolation: A General and Effective Graph-based Regularization Strategy. (arXiv:1911.09307v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.12414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Frank Po-Chen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1\">Seyyedali Hosseinalipour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michelusi_N/0/1/0/all/0/1\">Nicol&#xf2; Michelusi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1\">Christopher Brinton</a>",
          "description": "Federated learning has gained popularity as a means of training models\ndistributed across the wireless edge. The paper introduces delay-aware\nhierarchical federated learning (DFL) to improve the efficiency of distributed\nmachine learning (ML) model training by accounting for communication delays\nbetween edge and cloud. Different from traditional federated learning, DFL\nleverages multiple stochastic gradient descent iterations on local datasets\nwithin each global aggregation period and intermittently aggregates model\nparameters through edge servers in local subnetworks. During global\nsynchronization, the cloud server consolidates local models with the outdated\nglobal model using a local-global combiner, thus preserving crucial elements of\nboth, enhancing learning efficiency under the presence of delay. A set of\nconditions is obtained to achieve the sub-linear convergence rate of O(1/k) for\nstrongly convex and smooth loss functions. Based on these findings, an adaptive\ncontrol algorithm is developed for DFL, implementing policies to mitigate\nenergy consumption and communication latency while aiming for sublinear\nconvergence. Numerical evaluations show DFL's superior performance in terms of\nfaster global model convergence, reduced resource consumption, and robustness\nagainst communication delays compared to existing FL algorithms. In summary,\nthis proposed method offers improved efficiency and results when dealing with\nboth convex and non-convex loss functions.",
          "link": "http://arxiv.org/abs/2303.12414",
          "publishedOn": "2023-09-30T00:41:31.246Z",
          "wordCount": 742,
          "title": "Delay-Aware Hierarchical Federated Learning. (arXiv:2303.12414v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1\">Satyapriya Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1\">Chirag Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>",
          "description": "As machine learning models are increasingly being employed in various\nhigh-stakes settings, it becomes important to ensure that predictions of these\nmodels are not only adversarially robust, but also readily explainable to\nrelevant stakeholders. However, it is unclear if these two notions can be\nsimultaneously achieved or if there exist trade-offs between them. In this\nwork, we make one of the first attempts at studying the impact of adversarially\nrobust models on actionable explanations which provide end users with a means\nfor recourse. We theoretically and empirically analyze the cost (ease of\nimplementation) and validity (probability of obtaining a positive model\nprediction) of recourses output by state-of-the-art algorithms when the\nunderlying models are adversarially robust vs. non-robust. More specifically,\nwe derive theoretical bounds on the differences between the cost and the\nvalidity of the recourses generated by state-of-the-art algorithms for\nadversarially robust vs. non-robust linear and non-linear models. Our empirical\nresults with multiple real-world datasets validate our theoretical results and\nshow the impact of varying degrees of model robustness on the cost and validity\nof the resulting recourses. Our analyses demonstrate that adversarially robust\nmodels significantly increase the cost and reduce the validity of the resulting\nrecourses, thus shedding light on the inherent trade-offs between adversarial\nrobustness and actionable explanations",
          "link": "http://arxiv.org/abs/2309.16452",
          "publishedOn": "2023-09-30T00:41:31.211Z",
          "wordCount": 712,
          "title": "On the Trade-offs between Adversarial Robustness and Actionable Explanations. (arXiv:2309.16452v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16598",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zrnic_T/0/1/0/all/0/1\">Tijana Zrnic</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Candes_E/0/1/0/all/0/1\">Emmanuel J. Cand&#xe8;s</a>",
          "description": "While reliable data-driven decision-making hinges on high-quality labeled\ndata, the acquisition of quality labels often involves laborious human\nannotations or slow and expensive scientific measurements. Machine learning is\nbecoming an appealing alternative as sophisticated predictive techniques are\nbeing used to quickly and cheaply produce large amounts of predicted labels;\ne.g., predicted protein structures are used to supplement experimentally\nderived structures, predictions of socioeconomic indicators from satellite\nimagery are used to supplement accurate survey data, and so on. Since\npredictions are imperfect and potentially biased, this practice brings into\nquestion the validity of downstream inferences. We introduce cross-prediction:\na method for valid inference powered by machine learning. With a small labeled\ndataset and a large unlabeled dataset, cross-prediction imputes the missing\nlabels via machine learning and applies a form of debiasing to remedy the\nprediction inaccuracies. The resulting inferences achieve the desired error\nprobability and are more powerful than those that only leverage the labeled\ndata. Closely related is the recent proposal of prediction-powered inference,\nwhich assumes that a good pre-trained model is already available. We show that\ncross-prediction is consistently more powerful than an adaptation of\nprediction-powered inference in which a fraction of the labeled data is split\noff and used to train the model. Finally, we observe that cross-prediction\ngives more stable conclusions than its competitors; its confidence intervals\ntypically have significantly lower variability.",
          "link": "http://arxiv.org/abs/2309.16598",
          "publishedOn": "2023-09-30T00:41:31.189Z",
          "wordCount": 699,
          "title": "Cross-Prediction-Powered Inference. (arXiv:2309.16598v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16286",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenke Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Mang Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zekun Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>",
          "description": "Federated learning is an important privacy-preserving multi-party learning\nparadigm, involving collaborative learning with others and local updating on\nprivate data. Model heterogeneity and catastrophic forgetting are two crucial\nchallenges, which greatly limit the applicability and generalizability. This\npaper presents a novel FCCL+, federated correlation and similarity learning\nwith non-target distillation, facilitating the both intra-domain\ndiscriminability and inter-domain generalization. For heterogeneity issue, we\nleverage irrelevant unlabeled public data for communication between the\nheterogeneous participants. We construct cross-correlation matrix and align\ninstance similarity distribution on both logits and feature levels, which\neffectively overcomes the communication barrier and improves the generalizable\nability. For catastrophic forgetting in local updating stage, FCCL+ introduces\nFederated Non Target Distillation, which retains inter-domain knowledge while\navoiding the optimization conflict issue, fulling distilling privileged\ninter-domain information through depicting posterior classes relation.\nConsidering that there is no standard benchmark for evaluating existing\nheterogeneous federated learning under the same setting, we present a\ncomprehensive benchmark with extensive representative methods under four domain\nshift scenarios, supporting both heterogeneous and homogeneous federated\nsettings. Empirical results demonstrate the superiority of our method and the\nefficiency of modules on various scenarios.",
          "link": "http://arxiv.org/abs/2309.16286",
          "publishedOn": "2023-09-30T00:41:31.183Z",
          "wordCount": 692,
          "title": "Generalizable Heterogeneous Federated Cross-Correlation and Instance Similarity Learning. (arXiv:2309.16286v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16235",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Janakarajan_N/0/1/0/all/0/1\">Nikita Janakarajan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Erdmann_T/0/1/0/all/0/1\">Tim Erdmann</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Swaminathan_S/0/1/0/all/0/1\">Sarath Swaminathan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Laino_T/0/1/0/all/0/1\">Teodoro Laino</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Born_J/0/1/0/all/0/1\">Jannis Born</a>",
          "description": "The success of language models, especially transformer-based architectures,\nhas trickled into other domains giving rise to \"scientific language models\"\nthat operate on small molecules, proteins or polymers. In chemistry, language\nmodels contribute to accelerating the molecule discovery cycle as evidenced by\npromising recent findings in early-stage drug discovery. Here, we review the\nrole of language models in molecular discovery, underlining their strength in\nde novo drug design, property prediction and reaction chemistry. We highlight\nvaluable open-source software assets thus lowering the entry barrier to the\nfield of scientific language modeling. Last, we sketch a vision for future\nmolecular design that combines a chatbot interface with access to computational\nchemistry tools. Our contribution serves as a valuable resource for\nresearchers, chemists, and AI enthusiasts interested in understanding how\nlanguage models can and will be used to accelerate chemical discovery.",
          "link": "http://arxiv.org/abs/2309.16235",
          "publishedOn": "2023-09-30T00:41:31.148Z",
          "wordCount": 640,
          "title": "Language models in molecular discovery. (arXiv:2309.16235v1 [physics.chem-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.12405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chou_G/0/1/0/all/0/1\">Glen Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tedrake_R/0/1/0/all/0/1\">Russ Tedrake</a>",
          "description": "We present a method for synthesizing dynamic, reduced-order output-feedback\npolynomial control policies for control-affine nonlinear systems which\nguarantees runtime stability to a goal state, when using visual observations\nand a learned perception module in the feedback control loop. We leverage\nLyapunov analysis to formulate the problem of synthesizing such policies. This\nproblem is nonconvex in the policy parameters and the Lyapunov function that is\nused to prove the stability of the policy. To solve this problem approximately,\nwe propose two approaches: the first solves a sequence of sum-of-squares\noptimization problems to iteratively improve a policy which is provably-stable\nby construction, while the second directly performs gradient-based optimization\non the parameters of the polynomial policy, and its closed-loop stability is\nverified a posteriori. We extend our approach to provide stability guarantees\nin the presence of observation noise, which realistically arises due to errors\nin the learned perception module. We evaluate our approach on several\nunderactuated nonlinear systems, including pendula and quadrotors, showing that\nour guarantees translate to empirical stability when controlling these systems\nfrom images, while baseline approaches can fail to reliably stabilize the\nsystem.",
          "link": "http://arxiv.org/abs/2304.12405",
          "publishedOn": "2023-09-30T00:41:31.148Z",
          "wordCount": null,
          "title": "Synthesizing Stable Reduced-Order Visuomotor Policies for Nonlinear Systems via Sums-of-Squares Optimization. (arXiv:2304.12405v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.04412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cotta_L/0/1/0/all/0/1\">Leonardo Cotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yehuda_G/0/1/0/all/0/1\">Gal Yehuda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_A/0/1/0/all/0/1\">Assaf Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1\">Chris J. Maddison</a>",
          "description": "Designing models that are both expressive and preserve known invariances of\ntasks is an increasingly hard problem. Existing solutions tradeoff invariance\nfor computational or memory resources. In this work, we show how to leverage\nrandomness and design models that are both expressive and invariant but use\nless resources. Inspired by randomized algorithms, our key insight is that\naccepting probabilistic notions of universal approximation and invariance can\nreduce our resource requirements. More specifically, we propose a class of\nbinary classification models called Randomized Linear Classifiers (RLCs). We\ngive parameter and sample size conditions in which RLCs can, with high\nprobability, approximate any (smooth) function while preserving invariance to\ncompact group transformations. Leveraging this result, we design three RLCs\nthat are provably probabilistic invariant for classification tasks over sets,\ngraphs, and spherical data. We show how these models can achieve probabilistic\ninvariance and universality using less resources than (deterministic) neural\nnetworks and their invariant counterparts. Finally, we empirically demonstrate\nthe benefits of this new class of models on invariant tasks where deterministic\ninvariant neural networks are known to struggle.",
          "link": "http://arxiv.org/abs/2308.04412",
          "publishedOn": "2023-09-30T00:41:31.114Z",
          "wordCount": null,
          "title": "Probabilistic Invariant Learning with Randomized Linear Classifiers. (arXiv:2308.04412v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.02245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muttenthaler_L/0/1/0/all/0/1\">Lukas Muttenthaler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandermeulen_R/0/1/0/all/0/1\">Robert A. Vandermeulen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiuyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1\">Thomas Unterthiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1\">Klaus-Robert M&#xfc;ller</a>",
          "description": "Model overconfidence and poor calibration are common in machine learning and\ndifficult to account for when applying standard empirical risk minimization. In\nthis work, we propose a novel method to alleviate these problems that we call\nodd-$k$-out learning (OKO), which minimizes the cross-entropy error for sets\nrather than for single examples. This naturally allows the model to capture\ncorrelations across data examples and achieves both better accuracy and\ncalibration, especially in limited training data and class-imbalanced regimes.\nPerhaps surprisingly, OKO often yields better calibration even when training\nwith hard labels and dropping any additional calibration parameter tuning, such\nas temperature scaling. We provide theoretical justification, establishing that\nOKO naturally yields better calibration, and provide extensive experimental\nanalyses that corroborate our theoretical findings. We emphasize that OKO is a\ngeneral framework that can be easily adapted to many settings and the trained\nmodel can be applied to single examples at inference time, without introducing\nsignificant run-time overhead or architecture changes.",
          "link": "http://arxiv.org/abs/2307.02245",
          "publishedOn": "2023-09-30T00:41:31.103Z",
          "wordCount": null,
          "title": "Set Learning for Accurate and Calibrated Models. (arXiv:2307.02245v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Milling_M/0/1/0/all/0/1\">Manuel Milling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Triantafyllopoulos_A/0/1/0/all/0/1\">Andreas Triantafyllopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsangko_I/0/1/0/all/0/1\">Iosif Tsangko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rampp_S/0/1/0/all/0/1\">Simon David Noel Rampp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1\">Bj&#xf6;rn Wolfgang Schuller</a>",
          "description": "The correlation between the sharpness of loss minima and generalisation in\nthe context of deep neural networks has been subject to discussion for a long\ntime. Whilst mostly investigated in the context of selected benchmark data sets\nin the area of computer vision, we explore this aspect for the audio scene\nclassification task of the DCASE2020 challenge data. Our analysis is based on\ntwodimensional filter-normalised visualisations and a derived sharpness\nmeasure. Our exploratory analysis shows that sharper minima tend to show better\ngeneralisation than flat minima -even more so for out-of-domain data, recorded\nfrom previously unseen devices-, thus adding to the dispute about better\ngeneralisation capabilities of flat minima. We further find that, in\nparticular, the choice of optimisers is a main driver of the sharpness of\nminima and we discuss resulting limitations with respect to comparability. Our\ncode, trained model states and loss landscape visualisations are publicly\navailable.",
          "link": "http://arxiv.org/abs/2309.16369",
          "publishedOn": "2023-09-30T00:41:31.038Z",
          "wordCount": null,
          "title": "Bringing the Discussion of Minima Sharpness to the Audio Domain: a Filter-Normalised Evaluation for Acoustic Scene Classification. (arXiv:2309.16369v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.03559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xihong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Ke Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Sihang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinwang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_E/0/1/0/all/0/1\">En Zhu</a>",
          "description": "Contrastive deep graph clustering (CDGC) utilizes contrastive learning to\ngroup nodes into different clusters. Better augmentation techniques benefit the\nquality of the contrastive samples, thus being one of key factors to improve\nperformance. However, the augmentation samples in existing methods are always\npredefined by human experiences, and agnostic from the downstream task\nclustering, thus leading to high human resource costs and poor performance. To\nthis end, we propose an Attribute Graph Clustering method via Learnable\nAugmentation (\\textbf{AGCLA}), which introduces learnable augmentors for\nhigh-quality and suitable augmented samples for CDGC. Specifically, we design\ntwo learnable augmentors for attribute and structure information, respectively.\nBesides, two refinement matrices, including the high-confidence pseudo-label\nmatrix and the cross-view sample similarity matrix, are generated to improve\nthe reliability of the learned affinity matrix. During the training procedure,\nwe notice that there exist differences between the optimization goals for\ntraining learnable augmentors and contrastive learning networks. In other\nwords, we should both guarantee the consistency of the embeddings as well as\nthe diversity of the augmented samples. Thus, an adversarial learning mechanism\nis designed in our method. Moreover, a two-stage training strategy is leveraged\nfor the high-confidence refinement matrices. Extensive experimental results\ndemonstrate the effectiveness of AGCLA on six benchmark datasets.",
          "link": "http://arxiv.org/abs/2212.03559",
          "publishedOn": "2023-09-30T00:41:31.037Z",
          "wordCount": null,
          "title": "Attribute Graph Clustering via Learnable Augmentation. (arXiv:2212.03559v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dulny_A/0/1/0/all/0/1\">Andrzej Dulny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hotho_A/0/1/0/all/0/1\">Andreas Hotho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Anna Krause</a>",
          "description": "Previous work on learning physical systems from data has focused on\nhigh-resolution grid-structured measurements. However, real-world knowledge of\nsuch systems (e.g. weather data) relies on sparsely scattered measuring\nstations. In this paper, we introduce a novel simulated benchmark dataset,\nDynaBench, for learning dynamical systems directly from sparsely scattered data\nwithout prior knowledge of the equations. The dataset focuses on predicting the\nevolution of a dynamical system from low-resolution, unstructured measurements.\nWe simulate six different partial differential equations covering a variety of\nphysical systems commonly used in the literature and evaluate several machine\nlearning models, including traditional graph neural networks and point cloud\nprocessing models, with the task of predicting the evolution of the system. The\nproposed benchmark dataset is expected to advance the state of art as an\nout-of-the-box easy-to-use tool for evaluating models in a setting where only\nunstructured low-resolution observations are available. The benchmark is\navailable at https://anonymous.4open.science/r/code-2022-dynabench/.",
          "link": "http://arxiv.org/abs/2306.05805",
          "publishedOn": "2023-09-30T00:41:31.036Z",
          "wordCount": null,
          "title": "DynaBench: A benchmark dataset for learning dynamical systems from low-resolution data. (arXiv:2306.05805v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.12814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yan Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_T/0/1/0/all/0/1\">Tianyuan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1\">Yanhong Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuanqin He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xiaozhou Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_Y/0/1/0/all/0/1\">Ye Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ya-Qin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>",
          "description": "Vertical Federated Learning (VFL) is a federated learning setting where\nmultiple parties with different features about the same set of users jointly\ntrain machine learning models without exposing their raw data or model\nparameters. Motivated by the rapid growth in VFL research and real-world\napplications, we provide a comprehensive review of the concept and algorithms\nof VFL, as well as current advances and challenges in various aspects,\nincluding effectiveness, efficiency, and privacy. We provide an exhaustive\ncategorization for VFL settings and privacy-preserving protocols and\ncomprehensively analyze the privacy attacks and defense strategies for each\nprotocol. In the end, we propose a unified framework, termed VFLow, which\nconsiders the VFL problem under communication, computation, privacy, as well as\neffectiveness and fairness constraints. Finally, we review the most recent\nadvances in industrial applications, highlighting open challenges and future\ndirections for VFL.",
          "link": "http://arxiv.org/abs/2211.12814",
          "publishedOn": "2023-09-30T00:41:31.035Z",
          "wordCount": null,
          "title": "Vertical Federated Learning: Concepts, Advances and Challenges. (arXiv:2211.12814v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Haichao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sateesh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Heng Wang</a>",
          "description": "The quality of pre-training data plays a critical role in the performance of\nfoundation models. Popular foundation models often design their own recipe for\ndata filtering, which makes it hard to analyze and compare different data\nfiltering approaches. DataComp is a new benchmark dedicated to evaluating\ndifferent methods for data filtering. This paper describes our learning and\nsolution when participating in the DataComp challenge. Our filtering strategy\nincludes three stages: single-modality filtering, cross-modality filtering, and\ndata distribution alignment. We integrate existing methods and propose new\nsolutions, such as computing CLIP score on horizontally flipped images to\nmitigate the interference of scene text, using vision and language models to\nretrieve training samples for target downstream tasks, rebalancing the data\ndistribution to improve the efficiency of allocating the computational budget,\netc. We slice and dice our design choices, provide in-depth analysis, and\ndiscuss open questions. Our approach outperforms the best method from the\nDataComp paper by over 4% on the average performance of 38 tasks and by over 2%\non ImageNet.",
          "link": "http://arxiv.org/abs/2309.15954",
          "publishedOn": "2023-09-30T00:41:31.027Z",
          "wordCount": null,
          "title": "The Devil is in the Details: A Deep Dive into the Rabbit Hole of Data Filtering. (arXiv:2309.15954v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezapour_M/0/1/0/all/0/1\">Mostafa Rezapour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seymour_R/0/1/0/all/0/1\">Rachel B. Seymour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sims_S/0/1/0/all/0/1\">Stephen H. Sims</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karunakar_M/0/1/0/all/0/1\">Madhav A. Karunakar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habet_N/0/1/0/all/0/1\">Nahir Habet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurcan_M/0/1/0/all/0/1\">Metin Nafi Gurcan</a>",
          "description": "This study explored the potential of gait analysis as a tool for assessing\npost-injury complications, e.g., infection, malunion, or hardware irritation,\nin patients with lower extremity fractures. The research focused on the\nproficiency of supervised machine learning models predicting complications\nusing consecutive gait datasets. We identified patients with lower extremity\nfractures at an academic center. Patients underwent gait analysis with a\nchest-mounted IMU device. Using software, raw gait data was preprocessed,\nemphasizing 12 essential gait variables. Machine learning models including\nXGBoost, Logistic Regression, SVM, LightGBM, and Random Forest were trained,\ntested, and evaluated. Attention was given to class imbalance, addressed using\nSMOTE. We introduced a methodology to compute the Rate of Change (ROC) for gait\nvariables, independent of the time difference between gait analyses. XGBoost\nwas the optimal model both before and after applying SMOTE. Prior to SMOTE, the\nmodel achieved an average test AUC of 0.90 (95% CI: [0.79, 1.00]) and test\naccuracy of 86% (95% CI: [75%, 97%]). Feature importance analysis attributed\nimportance to the duration between injury and gait analysis. Data patterns\nshowed early physiological compensations, followed by stabilization phases,\nemphasizing prompt gait analysis. This study underscores the potential of\nmachine learning, particularly XGBoost, in gait analysis for orthopedic care.\nPredicting post-injury complications, early gait assessment becomes vital,\nrevealing intervention points. The findings support a shift in orthopedics\ntowards a data-informed approach, enhancing patient outcomes.",
          "link": "http://arxiv.org/abs/2309.15990",
          "publishedOn": "2023-09-30T00:41:31.027Z",
          "wordCount": null,
          "title": "Machine Learning Based Analytics for the Significance of Gait Analysis in Monitoring and Managing Lower Extremity Injuries. (arXiv:2309.15990v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xiongye Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gengshuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1\">Gaurav Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaxing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Tianqing Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Mingxi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogdan_P/0/1/0/all/0/1\">Paul Bogdan</a>",
          "description": "Integrating and processing information from various sources or modalities are\ncritical for obtaining a comprehensive and accurate perception of the real\nworld. Drawing inspiration from neuroscience, we develop the\nInformation-Theoretic Hierarchical Perception (ITHP) model, which utilizes the\nconcept of information bottleneck. Distinct from most traditional fusion models\nthat aim to incorporate all modalities as input, our model designates the prime\nmodality as input, while the remaining modalities act as detectors in the\ninformation pathway. Our proposed perception model focuses on constructing an\neffective and compact information flow by achieving a balance between the\nminimization of mutual information between the latent state and the input modal\nstate, and the maximization of mutual information between the latent states and\nthe remaining modal states. This approach leads to compact latent state\nrepresentations that retain relevant information while minimizing redundancy,\nthereby substantially enhancing the performance of downstream tasks.\nExperimental evaluations on both the MUStARD and CMU-MOSI datasets demonstrate\nthat our model consistently distills crucial information in multimodal learning\nscenarios, outperforming state-of-the-art benchmarks.",
          "link": "http://arxiv.org/abs/2309.15877",
          "publishedOn": "2023-09-30T00:41:31.026Z",
          "wordCount": null,
          "title": "Neuro-Inspired Hierarchical Multimodal Learning. (arXiv:2309.15877v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_Y/0/1/0/all/0/1\">Yash Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandal_M/0/1/0/all/0/1\">Murari Mandal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kankanhalli_M/0/1/0/all/0/1\">Mohan Kankanhalli</a>",
          "description": "Graph unlearning has emerged as a pivotal method to delete information from a\npre-trained graph neural network (GNN). One may delete nodes, a class of nodes,\nedges, or a class of edges. An unlearning method enables the GNN model to\ncomply with data protection regulations (i.e., the right to be forgotten),\nadapt to evolving data distributions, and reduce the GPU-hours carbon footprint\nby avoiding repetitive retraining. Existing partitioning and aggregation-based\nmethods have limitations due to their poor handling of local graph dependencies\nand additional overhead costs. More recently, GNNDelete offered a\nmodel-agnostic approach that alleviates some of these issues. Our work takes a\nnovel approach to address these challenges in graph unlearning through\nknowledge distillation, as it distills to delete in GNN (D2DGN). It is a\nmodel-agnostic distillation framework where the complete graph knowledge is\ndivided and marked for retention and deletion. It performs distillation with\nresponse-based soft targets and feature-based node embedding while minimizing\nKL divergence. The unlearned model effectively removes the influence of deleted\ngraph elements while preserving knowledge about the retained graph elements.\nD2DGN surpasses the performance of existing methods when evaluated on various\nreal-world graph datasets by up to $43.1\\%$ (AUC) in edge and node unlearning\ntasks. Other notable advantages include better efficiency, better performance\nin removing target elements, preservation of performance for the retained\nelements, and zero overhead costs. Notably, our D2DGN surpasses the\nstate-of-the-art GNNDelete in AUC by $2.4\\%$, improves membership inference\nratio by $+1.3$, requires $10.2\\times10^6$ fewer FLOPs per forward pass and up\nto $\\mathbf{3.2}\\times$ faster.",
          "link": "http://arxiv.org/abs/2309.16173",
          "publishedOn": "2023-09-30T00:41:31.026Z",
          "wordCount": null,
          "title": "Distill to Delete: Unlearning in Graph Networks with Knowledge Distillation. (arXiv:2309.16173v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16595",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingjian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1\">Qiaozhu Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jiaqi Ma</a>",
          "description": "This paper studies Large Language Models (LLMs) for structured\ndata--particularly graphs--a crucial data modality that remains underexplored\nin the LLM literature. We aim to understand when and why the incorporation of\nstructural information inherent in graph data can improve the prediction\nperformance of LLMs on node classification tasks. To address the ``when''\nquestion, we examine a variety of prompting methods for encoding structural\ninformation, in settings where textual node features are either rich or scarce.\nFor the ``why'' questions, we probe into two potential contributing factors to\nthe LLM performance: data leakage and homophily. Our exploration of these\nquestions reveals that (i) LLMs can benefit from structural information,\nespecially when textual node features are scarce; (ii) there is no substantial\nevidence indicating that the performance of LLMs is significantly attributed to\ndata leakage; and (iii) the performance of LLMs on a target node is strongly\npositively related to the local homophily ratio of the node.",
          "link": "http://arxiv.org/abs/2309.16595",
          "publishedOn": "2023-09-30T00:41:31.001Z",
          "wordCount": null,
          "title": "Can LLMs Effectively Leverage Structural Information for Graph Learning: When and Why. (arXiv:2309.16595v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seff_A/0/1/0/all/0/1\">Ari Seff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cera_B/0/1/0/all/0/1\">Brian Cera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_M/0/1/0/all/0/1\">Mason Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Aurick Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayakanti_N/0/1/0/all/0/1\">Nigamaa Nayakanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Refaat_K/0/1/0/all/0/1\">Khaled S. Refaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Rfou_R/0/1/0/all/0/1\">Rami Al-Rfou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sapp_B/0/1/0/all/0/1\">Benjamin Sapp</a>",
          "description": "Reliable forecasting of the future behavior of road agents is a critical\ncomponent to safe planning in autonomous vehicles. Here, we represent\ncontinuous trajectories as sequences of discrete motion tokens and cast\nmulti-agent motion prediction as a language modeling task over this domain. Our\nmodel, MotionLM, provides several advantages: First, it does not require\nanchors or explicit latent variable optimization to learn multimodal\ndistributions. Instead, we leverage a single standard language modeling\nobjective, maximizing the average log probability over sequence tokens. Second,\nour approach bypasses post-hoc interaction heuristics where individual agent\ntrajectory generation is conducted prior to interactive scoring. Instead,\nMotionLM produces joint distributions over interactive agent futures in a\nsingle autoregressive decoding process. In addition, the model's sequential\nfactorization enables temporally causal conditional rollouts. The proposed\napproach establishes new state-of-the-art performance for multi-agent motion\nprediction on the Waymo Open Motion Dataset, ranking 1st on the interactive\nchallenge leaderboard.",
          "link": "http://arxiv.org/abs/2309.16534",
          "publishedOn": "2023-09-30T00:41:31.000Z",
          "wordCount": null,
          "title": "MotionLM: Multi-Agent Motion Forecasting as Language Modeling. (arXiv:2309.16534v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1\">Manish Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_M/0/1/0/all/0/1\">Moitreya Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1\">Kuan-Chuan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lohit_S/0/1/0/all/0/1\">Suhas Lohit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1\">Michael Jones</a>",
          "description": "The primary bottleneck towards obtaining good recognition performance in IR\nimages is the lack of sufficient labeled training data, owing to the cost of\nacquiring such data. Realizing that object detection methods for the RGB\nmodality are quite robust (at least for some commonplace classes, like person,\ncar, etc.), thanks to the giant training sets that exist, in this work we seek\nto leverage cues from the RGB modality to scale object detectors to the IR\nmodality, while preserving model performance in the RGB modality. At the core\nof our method, is a novel tensor decomposition method called TensorFact which\nsplits the convolution kernels of a layer of a Convolutional Neural Network\n(CNN) into low-rank factor matrices, with fewer parameters than the original\nCNN. We first pretrain these factor matrices on the RGB modality, for which\nplenty of training data are assumed to exist and then augment only a few\ntrainable parameters for training on the IR modality to avoid over-fitting,\nwhile encouraging them to capture complementary cues from those trained only on\nthe RGB modality. We validate our approach empirically by first assessing how\nwell our TensorFact decomposed network performs at the task of detecting\nobjects in RGB images vis-a-vis the original network and then look at how well\nit adapts to IR images of the FLIR ADAS v1 dataset. For the latter, we train\nmodels under scenarios that pose challenges stemming from data paucity. From\nthe experiments, we observe that: (i) TensorFact shows performance gains on RGB\nimages; (ii) further, this pre-trained model, when fine-tuned, outperforms a\nstandard state-of-the-art object detector on the FLIR ADAS v1 dataset by about\n4% in terms of mAP 50 score.",
          "link": "http://arxiv.org/abs/2309.16592",
          "publishedOn": "2023-09-30T00:41:30.999Z",
          "wordCount": null,
          "title": "Tensor Factorization for Leveraging Cross-Modal Knowledge in Data-Constrained Infrared Object Detection. (arXiv:2309.16592v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianci Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feijie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1\">Lu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jing Gao</a>",
          "description": "Fair machine learning seeks to mitigate model prediction bias against certain\ndemographic subgroups such as elder and female. Recently, fair representation\nlearning (FRL) trained by deep neural networks has demonstrated superior\nperformance, whereby representations containing no demographic information are\ninferred from the data and then used as the input to classification or other\ndownstream tasks. Despite the development of FRL methods, their vulnerability\nunder data poisoning attack, a popular protocol to benchmark model robustness\nunder adversarial scenarios, is under-explored. Data poisoning attacks have\nbeen developed for classical fair machine learning methods which incorporate\nfairness constraints into shallow-model classifiers. Nonetheless, these attacks\nfall short in FRL due to notably different fairness goals and model\narchitectures. This work proposes the first data poisoning framework attacking\nFRL. We induce the model to output unfair representations that contain as much\ndemographic information as possible by injecting carefully crafted poisoning\nsamples into the training data. This attack entails a prohibitive bilevel\noptimization, wherefore an effective approximated solution is proposed. A\ntheoretical analysis on the needed number of poisoning samples is derived and\nsheds light on defending against the attack. Experiments on benchmark fairness\ndatasets and state-of-the-art fair representation learning models demonstrate\nthe superiority of our attack.",
          "link": "http://arxiv.org/abs/2309.16487",
          "publishedOn": "2023-09-30T00:41:30.998Z",
          "wordCount": null,
          "title": "Towards Poisoning Fair Representations. (arXiv:2309.16487v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cadambe_V/0/1/0/all/0/1\">Viveck R. Cadambe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devulapalli_A/0/1/0/all/0/1\">Ateet Devulapalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1\">Haewon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>",
          "description": "We consider the problem of private distributed multi-party multiplication. It\nis well-established that Shamir secret-sharing coding strategies can enable\nperfect information-theoretic privacy in distributed computation via the\ncelebrated algorithm of Ben Or, Goldwasser and Wigderson (the \"BGW algorithm\").\nHowever, perfect privacy and accuracy require an honest majority, that is, $N\n\\geq 2t+1$ compute nodes are required to ensure privacy against any $t$\ncolluding adversarial nodes. By allowing for some controlled amount of\ninformation leakage and approximate multiplication instead of exact\nmultiplication, we study coding schemes for the setting where the number of\nhonest nodes can be a minority, that is $N< 2t+1.$ We develop a tight\ncharacterization privacy-accuracy trade-off for cases where $N < 2t+1$ by\nmeasuring information leakage using {differential} privacy instead of perfect\nprivacy, and using the mean squared error metric for accuracy. A novel\ntechnical aspect is an intricately layered noise distribution that merges ideas\nfrom differential privacy and Shamir secret-sharing at different layers.",
          "link": "http://arxiv.org/abs/2309.16105",
          "publishedOn": "2023-09-30T00:41:30.898Z",
          "wordCount": 699,
          "title": "Differentially Private Secure Multiplication: Hiding Information in the Rubble of Noise. (arXiv:2309.16105v1 [cs.IT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16409",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhang Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihua Zhang</a>",
          "description": "The purpose of this work is to transport the information from multiple\nrandomized controlled trials to the target population where we only have the\ncontrol group data. Previous works rely critically on the mean exchangeability\nassumption. However, as pointed out by many current studies, the mean\nexchangeability assumption might be violated. Motivated by the synthetic\ncontrol method, we construct a synthetic treatment group for the target\npopulation by a weighted mixture of treatment groups of source populations. We\nestimate the weights by minimizing the conditional maximum mean discrepancy\nbetween the weighted control groups of source populations and the target\npopulation. We establish the asymptotic normality of the synthetic treatment\ngroup estimator based on the sieve semiparametric theory. Our method can serve\nas a novel complementary approach when the mean exchangeability assumption is\nviolated. Experiments are conducted on synthetic and real-world datasets to\ndemonstrate the effectiveness of our methods.",
          "link": "http://arxiv.org/abs/2309.16409",
          "publishedOn": "2023-09-30T00:41:30.881Z",
          "wordCount": 648,
          "title": "Constructing Synthetic Treatment Groups without the Mean Exchangeability Assumption. (arXiv:2309.16409v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1\">Zhiwei Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiaoyu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1\">Dawei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Fengzhe Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhuo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zongwen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1\">Jidong Ge</a>",
          "description": "Large language models (LLMs) have demonstrated strong capabilities in various\naspects. However, when applying them to the highly specialized, safe-critical\nlegal domain, it is unclear how much legal knowledge they possess and whether\nthey can reliably perform legal-related tasks. To address this gap, we propose\na comprehensive evaluation benchmark LawBench. LawBench has been meticulously\ncrafted to have precise assessment of the LLMs' legal capabilities from three\ncognitive levels: (1) Legal knowledge memorization: whether LLMs can memorize\nneeded legal concepts, articles and facts; (2) Legal knowledge understanding:\nwhether LLMs can comprehend entities, events and relationships within legal\ntext; (3) Legal knowledge applying: whether LLMs can properly utilize their\nlegal knowledge and make necessary reasoning steps to solve realistic legal\ntasks. LawBench contains 20 diverse tasks covering 5 task types: single-label\nclassification (SLC), multi-label classification (MLC), regression, extraction\nand generation. We perform extensive evaluations of 51 LLMs on LawBench,\nincluding 20 multilingual LLMs, 22 Chinese-oriented LLMs and 9 legal specific\nLLMs. The results show that GPT-4 remains the best-performing LLM in the legal\ndomain, surpassing the others by a significant margin. While fine-tuning LLMs\non legal specific text brings certain improvements, we are still a long way\nfrom obtaining usable and reliable LLMs in legal tasks. All data, model\npredictions and evaluation code are released in\nhttps://github.com/open-compass/LawBench/. We hope this benchmark provides\nin-depth understanding of the LLMs' domain-specified capabilities and speed up\nthe development of LLMs in the legal domain.",
          "link": "http://arxiv.org/abs/2309.16289",
          "publishedOn": "2023-09-30T00:41:30.860Z",
          "wordCount": 754,
          "title": "LawBench: Benchmarking Legal Knowledge of Large Language Models. (arXiv:2309.16289v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16188",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhou_W/0/1/0/all/0/1\">Wenzhuo Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qu_A/0/1/0/all/0/1\">Annie Qu</a>",
          "description": "Batch reinforcement learning (RL) defines the task of learning from a fixed\nbatch of data lacking exhaustive exploration. Worst-case optimality algorithms,\nwhich calibrate a value-function model class from logged experience and perform\nsome type of pessimistic evaluation under the learned model, have emerged as a\npromising paradigm for batch RL. However, contemporary works on this stream\nhave commonly overlooked the hierarchical decision-making structure hidden in\nthe optimization landscape. In this paper, we adopt a game-theoretical\nviewpoint and model the policy learning diagram as a two-player general-sum\ngame with a leader-follower structure. We propose a novel stochastic\ngradient-based learning algorithm: StackelbergLearner, in which the leader\nplayer updates according to the total derivative of its objective instead of\nthe usual individual gradient, and the follower player makes individual updates\nand ensures transition-consistent pessimistic reasoning. The derived learning\ndynamic naturally lends StackelbergLearner to a game-theoretic interpretation\nand provides a convergence guarantee to differentiable Stackelberg equilibria.\nFrom a theoretical standpoint, we provide instance-dependent regret bounds with\ngeneral function approximation, which shows that our algorithm can learn a\nbest-effort policy that is able to compete against any comparator policy that\nis covered by batch data. Notably, our theoretical regret guarantees only\nrequire realizability without any data coverage and strong function\napproximation conditions, e.g., Bellman closedness, which is in contrast to\nprior works lacking such guarantees. Through comprehensive experiments, we find\nthat our algorithm consistently performs as well or better as compared to\nstate-of-the-art methods in batch RL benchmark and real-world datasets.",
          "link": "http://arxiv.org/abs/2309.16188",
          "publishedOn": "2023-09-30T00:41:30.854Z",
          "wordCount": 724,
          "title": "Stackelberg Batch Policy Learning. (arXiv:2309.16188v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Heng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "We study unconstrained Online Linear Optimization with Lipschitz losses. The\ngoal is to simultaneously achieve ($i$) second order gradient adaptivity; and\n($ii$) comparator norm adaptivity also known as \"parameter freeness\" in the\nliterature. Existing regret bounds (Cutkosky and Orabona, 2018; Mhammedi and\nKoolen, 2020; Jacobsen and Cutkosky, 2022) have the suboptimal $O(\\sqrt{V_T\\log\nV_T})$ dependence on the gradient variance $V_T$, while the present work\nimproves it to the optimal rate $O(\\sqrt{V_T})$ using a novel\ncontinuous-time-inspired algorithm, without any impractical doubling trick.\nThis result can be extended to the setting with unknown Lipschitz constant,\neliminating the range ratio problem from prior works (Mhammedi and Koolen,\n2020).\n\nConcretely, we first show that the aimed simultaneous adaptivity can be\nachieved fairly easily in a continuous time analogue of the problem, where the\nenvironment is modeled by an arbitrary continuous semimartingale. Then, our key\ninnovation is a new discretization argument that preserves such adaptivity in\nthe discrete time adversarial setting. This refines a non-gradient-adaptive\ndiscretization argument from (Harvey et al., 2023), both algorithmically and\nanalytically, which could be of independent interest.",
          "link": "http://arxiv.org/abs/2309.16044",
          "publishedOn": "2023-09-30T00:41:30.846Z",
          "wordCount": 680,
          "title": "Improving Adaptive Online Learning Using Refined Discretization. (arXiv:2309.16044v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kraus_O/0/1/0/all/0/1\">Oren Kraus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenyon_Dean_K/0/1/0/all/0/1\">Kian Kenyon-Dean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saberian_S/0/1/0/all/0/1\">Saber Saberian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fallah_M/0/1/0/all/0/1\">Maryam Fallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McLean_P/0/1/0/all/0/1\">Peter McLean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leung_J/0/1/0/all/0/1\">Jess Leung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1\">Vasudev Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Ayla Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishnan_J/0/1/0/all/0/1\">Jia Balakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celik_S/0/1/0/all/0/1\">Safiye Celik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sypetkowski_M/0/1/0/all/0/1\">Maciej Sypetkowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Chi Vicky Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morse_K/0/1/0/all/0/1\">Kristen Morse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makes_M/0/1/0/all/0/1\">Maureen Makes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mabey_B/0/1/0/all/0/1\">Ben Mabey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Earnshaw_B/0/1/0/all/0/1\">Berton Earnshaw</a>",
          "description": "Inferring biological relationships from cellular phenotypes in high-content\nmicroscopy screens provides significant opportunity and challenge in biological\nresearch. Prior results have shown that deep vision models can capture\nbiological signal better than hand-crafted features. This work explores how\nweakly supervised and self-supervised deep learning approaches scale when\ntraining larger models on larger datasets. Our results show that both CNN- and\nViT-based masked autoencoders significantly outperform weakly supervised\nmodels. At the high-end of our scale, a ViT-L/8 trained on over 3.5-billion\nunique crops sampled from 95-million microscopy images achieves relative\nimprovements as high as 28% over our best weakly supervised models at inferring\nknown biological relationships curated from public databases.",
          "link": "http://arxiv.org/abs/2309.16064",
          "publishedOn": "2023-09-30T00:41:30.839Z",
          "wordCount": 645,
          "title": "Masked autoencoders are scalable learners of cellular morphology. (arXiv:2309.16064v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16603",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vahapoglu_C/0/1/0/all/0/1\">Cemil Vahapoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OShea_T/0/1/0/all/0/1\">Timothy J. O&#x27;Shea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_T/0/1/0/all/0/1\">Tamoghna Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ulukus_S/0/1/0/all/0/1\">Sennur Ulukus</a>",
          "description": "The advancement of fifth generation (5G) wireless communication networks has\ncreated a greater demand for wireless resource management solutions that offer\nhigh data rates, extensive coverage, minimal latency and energy-efficient\nperformance. Nonetheless, traditional approaches have shortcomings when it\ncomes to computational complexity and their ability to adapt to dynamic\nconditions, creating a gap between theoretical analysis and the practical\nexecution of algorithmic solutions for managing wireless resources. Deep\nlearning-based techniques offer promising solutions for bridging this gap with\ntheir substantial representation capabilities. We propose a novel unsupervised\ndeep learning framework, which is called NNBF, for the design of uplink receive\nmulti-user single input multiple output (MU-SIMO) beamforming. The primary\nobjective is to enhance the throughput by focusing on maximizing the sum-rate\nwhile also offering computationally efficient solution, in contrast to\nestablished conventional methods. We conduct experiments for several antenna\nconfigurations. Our experimental results demonstrate that NNBF exhibits\nsuperior performance compared to our baseline methods, namely, zero-forcing\nbeamforming (ZFBF) and minimum mean square error (MMSE) equalizer.\nAdditionally, NNBF is scalable to the number of single-antenna user equipments\n(UEs) while baseline methods have significant computational burden due to\nmatrix pseudo-inverse operation.",
          "link": "http://arxiv.org/abs/2309.16603",
          "publishedOn": "2023-09-30T00:41:30.812Z",
          "wordCount": null,
          "title": "Deep Learning Based Uplink Multi-User SIMO Beamforming Design. (arXiv:2309.16603v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16316",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Pan_J/0/1/0/all/0/1\">Jia-Shu Pan</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ting_Y/0/1/0/all/0/1\">Yuan-Sen Ting</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Yu_J/0/1/0/all/0/1\">Jie Yu</a>",
          "description": "Light curves of stars encapsulate a wealth of information about stellar\noscillations and granulation, thereby offering key insights into the internal\nstructure and evolutionary state of stars. Conventional asteroseismic\ntechniques have been largely confined to power spectral analysis, neglecting\nthe valuable phase information contained within light curves. While recent\nmachine learning applications in asteroseismology utilizing Convolutional\nNeural Networks (CNNs) have successfully inferred stellar attributes from light\ncurves, they are often limited by the local feature extraction inherent in\nconvolutional operations. To circumvent these constraints, we present\n$\\textit{Astroconformer}$, a Transformer-based deep learning framework designed\nto capture long-range dependencies in stellar light curves. Our empirical\nanalysis, which focuses on estimating surface gravity ($\\log g$), is grounded\nin a carefully curated dataset derived from $\\textit{Kepler}$ light curves.\nThese light curves feature asteroseismic $\\log g$ values spanning from 0.2 to\n4.4. Our results underscore that, in the regime where the training data is\nabundant, $\\textit{Astroconformer}$ attains a root-mean-square-error (RMSE) of\n0.017 dex around $\\log g \\approx 3 $. Even in regions where training data are\nsparse, the RMSE can reach 0.1 dex. It outperforms not only the K-nearest\nneighbor-based model ($\\textit{The SWAN}$) but also state-of-the-art CNNs.\nAblation studies confirm that the efficacy of the models in this particular\ntask is strongly influenced by the size of their receptive fields, with larger\nreceptive fields correlating with enhanced performance. Moreover, we find that\nthe attention mechanisms within $\\textit{Astroconformer}$ are well-aligned with\nthe inherent characteristics of stellar oscillations and granulation present in\nthe light curves.",
          "link": "http://arxiv.org/abs/2309.16316",
          "publishedOn": "2023-09-30T00:41:30.811Z",
          "wordCount": null,
          "title": "Astroconformer: The Prospects of Analyzing Stellar Light Curves with Transformer-Based Deep Learning Models. (arXiv:2309.16316v1 [astro-ph.SR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fred Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nanda_N/0/1/0/all/0/1\">Neel Nanda</a>",
          "description": "Mechanistic interpretability seeks to understand the internal mechanisms of\nmachine learning models, where localization -- identifying the important model\ncomponents -- is a key step. Activation patching, also known as causal tracing\nor interchange intervention, is a standard technique for this task (Vig et al.,\n2020), but the literature contains many variants with little consensus on the\nchoice of hyperparameters or methodology. In this work, we systematically\nexamine the impact of methodological details in activation patching, including\nevaluation metrics and corruption methods. In several settings of localization\nand circuit discovery in language models, we find that varying these\nhyperparameters could lead to disparate interpretability results. Backed by\nempirical observations, we give conceptual arguments for why certain metrics or\nmethods may be preferred. Finally, we provide recommendations for the best\npractices of activation patching going forwards.",
          "link": "http://arxiv.org/abs/2309.16042",
          "publishedOn": "2023-09-30T00:41:30.810Z",
          "wordCount": null,
          "title": "Towards Best Practices of Activation Patching in Language Models: Metrics and Methods. (arXiv:2309.16042v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cepeda_V/0/1/0/all/0/1\">Vicente Vivanco Cepeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayak_G/0/1/0/all/0/1\">Gaurav Kumar Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>",
          "description": "Worldwide Geo-localization aims to pinpoint the precise location of images\ntaken anywhere on Earth. This task has considerable challenges due to immense\nvariation in geographic landscapes. The image-to-image retrieval-based\napproaches fail to solve this problem on a global scale as it is not feasible\nto construct a large gallery of images covering the entire world. Instead,\nexisting approaches divide the globe into discrete geographic cells,\ntransforming the problem into a classification task. However, their performance\nis limited by the predefined classes and often results in inaccurate\nlocalizations when an image's location significantly deviates from its class\ncenter. To overcome these limitations, we propose GeoCLIP, a novel\nCLIP-inspired Image-to-GPS retrieval approach that enforces alignment between\nthe image and its corresponding GPS locations. GeoCLIP's location encoder\nmodels the Earth as a continuous function by employing positional encoding\nthrough random Fourier features and constructing a hierarchical representation\nthat captures information at varying resolutions to yield a semantically rich\nhigh-dimensional feature suitable to use even beyond geo-localization. To the\nbest of our knowledge, this is the first work employing GPS encoding for\ngeo-localization. We demonstrate the efficacy of our method via extensive\nexperiments and ablations on benchmark datasets. We achieve competitive\nperformance with just 20% of training data, highlighting its effectiveness even\nin limited-data settings. Furthermore, we qualitatively demonstrate\ngeo-localization using a text query by leveraging CLIP backbone of our image\nencoder.",
          "link": "http://arxiv.org/abs/2309.16020",
          "publishedOn": "2023-09-30T00:41:30.809Z",
          "wordCount": null,
          "title": "GeoCLIP: Clip-Inspired Alignment between Locations and Images for Effective Worldwide Geo-localization. (arXiv:2309.16020v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16546",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rumack_A/0/1/0/all/0/1\">Aaron Rumack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenfeld_R/0/1/0/all/0/1\">Roni Rosenfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Townes_F/0/1/0/all/0/1\">F. William Townes</a>",
          "description": "Auxiliary data sources have become increasingly important in epidemiological\nsurveillance, as they are often available at a finer spatial and temporal\nresolution, larger coverage, and lower latency than traditional surveillance\nsignals. We describe the problem of spatial and temporal heterogeneity in these\nsignals derived from these data sources, where spatial and/or temporal biases\nare present. We present a method to use a ``guiding'' signal to correct for\nthese biases and produce a more reliable signal that can be used for modeling\nand forecasting. The method assumes that the heterogeneity can be approximated\nby a low-rank matrix and that the temporal heterogeneity is smooth over time.\nWe also present a hyperparameter selection algorithm to choose the parameters\nrepresenting the matrix rank and degree of temporal smoothness of the\ncorrections. In the absence of ground truth, we use maps and plots to argue\nthat this method does indeed reduce heterogeneity. Reducing heterogeneity from\nauxiliary data sources greatly increases their utility in modeling and\nforecasting epidemics.",
          "link": "http://arxiv.org/abs/2309.16546",
          "publishedOn": "2023-09-30T00:41:30.807Z",
          "wordCount": null,
          "title": "Correcting for heterogeneity in real-time epidemiological indicators. (arXiv:2309.16546v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16476",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Adomaityte_U/0/1/0/all/0/1\">Urte Adomaityte</a>, <a href=\"http://arxiv.org/find/math/1/au:+Defilippis_L/0/1/0/all/0/1\">Leonardo Defilippis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Loureiro_B/0/1/0/all/0/1\">Bruno Loureiro</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sicuro_G/0/1/0/all/0/1\">Gabriele Sicuro</a>",
          "description": "We investigate the high-dimensional properties of robust regression\nestimators in the presence of heavy-tailed contamination of both the covariates\nand response functions. In particular, we provide a sharp asymptotic\ncharacterisation of M-estimators trained on a family of elliptical covariate\nand noise data distributions including cases where second and higher moments do\nnot exist. We show that, despite being consistent, the Huber loss with\noptimally tuned location parameter $\\delta$ is suboptimal in the\nhigh-dimensional regime in the presence of heavy-tailed noise, highlighting the\nnecessity of further regularisation to achieve optimal performance. This result\nalso uncovers the existence of a curious transition in $\\delta$ as a function\nof the sample complexity and contamination. Moreover, we derive the decay rates\nfor the excess risk of ridge regression. We show that, while it is both optimal\nand universal for noise distributions with finite second moment, its decay rate\ncan be considerably faster when the covariates' second moment does not exist.\nFinally, we show that our formulas readily generalise to a richer family of\nmodels and data distributions, such as generalised linear estimation with\narbitrary convex regularisation trained on mixture models.",
          "link": "http://arxiv.org/abs/2309.16476",
          "publishedOn": "2023-09-30T00:41:30.710Z",
          "wordCount": null,
          "title": "High-dimensional robust regression under heavy-tailed data: Asymptotics and Universality. (arXiv:2309.16476v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16131",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Mingtao Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiangting Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Q/0/1/0/all/0/1\">Qijing Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_T/0/1/0/all/0/1\">Tom Chou</a>",
          "description": "Rapidly developing machine learning methods has stimulated research interest\nin computationally reconstructing differential equations (DEs) from\nobservational data which may provide additional insight into underlying\ncausative mechanisms. In this paper, we propose a novel neural-ODE based method\nthat uses spectral expansions in space to learn spatiotemporal DEs. The major\nadvantage of our spectral neural DE learning approach is that it does not rely\non spatial discretization, thus allowing the target spatiotemporal equations to\ncontain long range, nonlocal spatial interactions that act on unbounded spatial\ndomains. Our spectral approach is shown to be as accurate as some of the latest\nmachine learning approaches for learning PDEs operating on bounded domains. By\ndeveloping a spectral framework for learning both PDEs and integro-differential\nequations, we extend machine learning methods to apply to unbounded DEs and a\nlarger class of problems.",
          "link": "http://arxiv.org/abs/2309.16131",
          "publishedOn": "2023-09-30T00:41:30.696Z",
          "wordCount": null,
          "title": "A Spectral Approach for Learning Spatiotemporal Neural Differential Equations. (arXiv:2309.16131v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.12499",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xuelong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kaisheng Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Bin Xiao</a>",
          "description": "Unrestricted adversarial attacks present a serious threat to deep learning\nmodels and adversarial defense techniques. They pose severe security problems\nfor deep learning applications because they can effectively bypass defense\nmechanisms. However, previous attack methods often utilize Generative\nAdversarial Networks (GANs), which are not theoretically provable and thus\ngenerate unrealistic examples by incorporating adversarial objectives,\nespecially for large-scale datasets like ImageNet. In this paper, we propose a\nnew method, called AdvDiff, to generate unrestricted adversarial examples with\ndiffusion models. We design two novel adversarial guidance techniques to\nconduct adversarial sampling in the reverse generation process of diffusion\nmodels. These two techniques are effective and stable to generate high-quality,\nrealistic adversarial examples by integrating gradients of the target\nclassifier interpretably. Experimental results on MNIST and ImageNet datasets\ndemonstrate that AdvDiff is effective to generate unrestricted adversarial\nexamples, which outperforms GAN-based methods in terms of attack performance\nand generation quality.",
          "link": "http://arxiv.org/abs/2307.12499",
          "publishedOn": "2023-09-30T00:41:30.672Z",
          "wordCount": null,
          "title": "AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion Models. (arXiv:2307.12499v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pal_A/0/1/0/all/0/1\">Ambar Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sulam_J/0/1/0/all/0/1\">Jeremias Sulam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Ren&#xe9; Vidal</a>",
          "description": "The susceptibility of modern machine learning classifiers to adversarial\nexamples has motivated theoretical results suggesting that these might be\nunavoidable. However, these results can be too general to be applicable to\nnatural data distributions. Indeed, humans are quite robust for tasks involving\nvision. This apparent conflict motivates a deeper dive into the question: Are\nadversarial examples truly unavoidable? In this work, we theoretically\ndemonstrate that a key property of the data distribution -- concentration on\nsmall-volume subsets of the input space -- determines whether a robust\nclassifier exists. We further demonstrate that, for a data distribution\nconcentrated on a union of low-dimensional linear subspaces, exploiting data\nstructure naturally leads to classifiers that enjoy good robustness guarantees,\nimproving upon methods for provable certification in certain regimes.",
          "link": "http://arxiv.org/abs/2309.16096",
          "publishedOn": "2023-09-30T00:41:30.669Z",
          "wordCount": null,
          "title": "Adversarial Examples Might be Avoidable: The Role of Data Concentration in Adversarial Robustness. (arXiv:2309.16096v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feiyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1\">Zhaoyuan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hanran Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Anqi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Ye Zhao</a>",
          "description": "Enabling bipedal walking robots to learn how to maneuver over highly uneven,\ndynamically changing terrains is challenging due to the complexity of robot\ndynamics and interacted environments. Recent advancements in learning from\ndemonstrations have shown promising results for robot learning in complex\nenvironments. While imitation learning of expert policies has been\nwell-explored, the study of learning expert reward functions is largely\nunder-explored in legged locomotion. This paper brings state-of-the-art Inverse\nReinforcement Learning (IRL) techniques to solving bipedal locomotion problems\nover complex terrains. We propose algorithms for learning expert reward\nfunctions, and we subsequently analyze the learned functions. Through nonlinear\nfunction approximation, we uncover meaningful insights into the expert's\nlocomotion strategies. Furthermore, we empirically demonstrate that training a\nbipedal locomotion policy with the inferred reward functions enhances its\nwalking performance on unseen terrains, highlighting the adaptability offered\nby reward learning.",
          "link": "http://arxiv.org/abs/2309.16074",
          "publishedOn": "2023-09-30T00:41:30.668Z",
          "wordCount": null,
          "title": "Infer and Adapt: Bipedal Locomotion Reward Learning from Demonstrations via Inverse Reinforcement Learning. (arXiv:2309.16074v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16401",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Glusenkamp_T/0/1/0/all/0/1\">Thorsten Gl&#xfc;senkamp</a> (for the RNO-G collaboration)",
          "description": "The Radio Neutrino Observatory in Greenland (RNO-G) is a radio-based\nultra-high energy neutrino detector located at Summit Station, Greenland. It is\nstill being constructed, with 7 stations currently operational. Neutrino\ndetection works by measuring Askaryan radiation produced by neutrino-nucleon\ninteractions. A neutrino candidate must be found amidst other backgrounds which\nare recorded at much higher rates -- including cosmic-rays and anthropogenic\nnoise -- the origins of which are sometimes unknown. Here we describe a method\nto classify different noise classes using the latent space of a variational\nautoencoder. The latent space forms a compact representation that makes\nclassification tractable. We analyze data from a noisy and a silent station.\nThe method automatically detects and allows us to qualitatively separate\nmultiple event classes, including physical wind-induced signals, for both the\nnoisy and the quiet station.",
          "link": "http://arxiv.org/abs/2309.16401",
          "publishedOn": "2023-09-30T00:41:30.667Z",
          "wordCount": null,
          "title": "VAE-based latent-space classification of RNO-G data. (arXiv:2309.16401v1 [astro-ph.HE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.13104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kerdabadi_M/0/1/0/all/0/1\">Mohsen Nayebi Kerdabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moghaddam_A/0/1/0/all/0/1\">Arya Hadizadeh Moghaddam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zijun Yao</a>",
          "description": "Survival analysis plays a crucial role in many healthcare decisions, where\nthe risk prediction for the events of interest can support an informative\noutlook for a patient's medical journey. Given the existence of data censoring,\nan effective way of survival analysis is to enforce the pairwise temporal\nconcordance between censored and observed data, aiming to utilize the time\ninterval before censoring as partially observed time-to-event labels for\nsupervised learning. Although existing studies mostly employed ranking methods\nto pursue an ordering objective, contrastive methods which learn a\ndiscriminative embedding by having data contrast against each other, have not\nbeen explored thoroughly for survival analysis. Therefore, in this paper, we\npropose a novel Ontology-aware Temporality-based Contrastive Survival (OTCSurv)\nanalysis framework that utilizes survival durations from both censored and\nobserved data to define temporal distinctiveness and construct negative sample\npairs with adjustable hardness for contrastive learning. Specifically, we first\nuse an ontological encoder and a sequential self-attention encoder to represent\nthe longitudinal EHR data with rich contexts. Second, we design a temporal\ncontrastive loss to capture varying survival durations in a supervised setting\nthrough a hardness-aware negative sampling mechanism. Last, we incorporate the\ncontrastive task into the time-to-event predictive task with multiple loss\ncomponents. We conduct extensive experiments using a large EHR dataset to\nforecast the risk of hospitalized patients who are in danger of developing\nacute kidney injury (AKI), a critical and urgent medical condition. The\neffectiveness and explainability of the proposed model are validated through\ncomprehensive quantitative and qualitative studies.",
          "link": "http://arxiv.org/abs/2308.13104",
          "publishedOn": "2023-09-30T00:41:30.666Z",
          "wordCount": null,
          "title": "Contrastive Learning of Temporal Distinctiveness for Survival Analysis in Electronic Health Records. (arXiv:2308.13104v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yariv_G/0/1/0/all/0/1\">Guy Yariv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1\">Itai Gat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benaim_S/0/1/0/all/0/1\">Sagie Benaim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_I/0/1/0/all/0/1\">Idan Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>",
          "description": "We consider the task of generating diverse and realistic videos guided by\nnatural audio samples from a wide variety of semantic classes. For this task,\nthe videos are required to be aligned both globally and temporally with the\ninput audio: globally, the input audio is semantically associated with the\nentire output video, and temporally, each segment of the input audio is\nassociated with a corresponding segment of that video. We utilize an existing\ntext-conditioned video generation model and a pre-trained audio encoder model.\nThe proposed method is based on a lightweight adaptor network, which learns to\nmap the audio-based representation to the input representation expected by the\ntext-to-video generation model. As such, it also enables video generation\nconditioned on text, audio, and, for the first time as far as we can ascertain,\non both text and audio. We validate our method extensively on three datasets\ndemonstrating significant semantic diversity of audio-video samples and further\npropose a novel evaluation metric (AV-Align) to assess the alignment of\ngenerated videos with input audio samples. AV-Align is based on the detection\nand comparison of energy peaks in both modalities. In comparison to recent\nstate-of-the-art approaches, our method generates videos that are better\naligned with the input sound, both with respect to content and temporal axis.\nWe also show that videos produced by our method present higher visual quality\nand are more diverse.",
          "link": "http://arxiv.org/abs/2309.16429",
          "publishedOn": "2023-09-30T00:41:30.665Z",
          "wordCount": null,
          "title": "Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model Adaptation. (arXiv:2309.16429v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skenderi_G/0/1/0/all/0/1\">Geri Skenderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cristani_M/0/1/0/all/0/1\">Marco Cristani</a>",
          "description": "Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a\nnovel and powerful technique for self-supervised representation learning. They\naim to learn an energy-based model by predicting the latent representation of a\ntarget signal $y$ from a context signal $x$. JEPAs bypass the need for data\naugmentation and negative samples, which are typically required by contrastive\nlearning, while avoiding the overfitting issues associated with\ngenerative-based pretraining. In this paper, we show that graph-level\nrepresentations can be effectively modeled using this paradigm and propose\nGraph-JEPA, the first JEPA for the graph domain. In particular, we employ\nmasked modeling to learn embeddings for different subgraphs of the input graph.\nTo endow the representations with the implicit hierarchy that is often present\nin graph-level concepts, we devise an alternative training objective that\nconsists of predicting the coordinates of the encoded subgraphs on the unit\nhyperbola in the 2D plane. Extensive validation shows that Graph-JEPA can learn\nrepresentations that are expressive and competitive in both graph\nclassification and regression problems.",
          "link": "http://arxiv.org/abs/2309.16014",
          "publishedOn": "2023-09-30T00:41:30.664Z",
          "wordCount": null,
          "title": "Graph-level Representation Learning with Joint-Embedding Predictive Architectures. (arXiv:2309.16014v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.04866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jiaheng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1\">Peter Stone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1\">Roberto Mart&#xed;n-Mart&#xed;n</a>",
          "description": "Developing the next generation of household robot helpers requires combining\nlocomotion and interaction capabilities, which is generally referred to as\nmobile manipulation (MoMa). MoMa tasks are difficult due to the large action\nspace of the robot and the common multi-objective nature of the task, e.g.,\nefficiently reaching a goal while avoiding obstacles. Current approaches often\nsegregate tasks into navigation without manipulation and stationary\nmanipulation without locomotion by manually matching parts of the action space\nto MoMa sub-objectives (e.g. learning base actions for locomotion objectives\nand learning arm actions for manipulation). This solution prevents simultaneous\ncombinations of locomotion and interaction degrees of freedom and requires\nhuman domain knowledge for both partitioning the action space and matching the\naction parts to the sub-objectives. In this paper, we introduce Causal MoMa, a\nnew reinforcement learning framework to train policies for typical MoMa tasks\nthat makes use of the most favorable subspace of the robot's action space to\naddress each sub-objective. Causal MoMa automatically discovers the causal\ndependencies between actions and terms of the reward function and exploits\nthese dependencies through causal policy gradient that reduces gradient\nvariance compared to previous state-of-the-art reinforcement learning\nalgorithms, improving convergence and results. We evaluate the performance of\nCausal MoMa on three types of simulated robots across different MoMa tasks and\ndemonstrate success in transferring the policies trained in simulation directly\nto a real robot, where our agent is able to follow moving goals and react to\ndynamic obstacles while simultaneously and synergistically controlling the\nwhole-body: base, arm, and head. More information at\nhttps://sites.google.com/view/causal-moma.",
          "link": "http://arxiv.org/abs/2305.04866",
          "publishedOn": "2023-09-30T00:41:30.663Z",
          "wordCount": null,
          "title": "Causal Policy Gradient for Whole-Body Mobile Manipulation. (arXiv:2305.04866v4 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.00031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iordanou_K/0/1/0/all/0/1\">Konstantinos Iordanou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atkinson_T/0/1/0/all/0/1\">Timothy Atkinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozer_E/0/1/0/all/0/1\">Emre Ozer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kufel_J/0/1/0/all/0/1\">Jedrzej Kufel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggs_J/0/1/0/all/0/1\">John Biggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_G/0/1/0/all/0/1\">Gavin Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lujan_M/0/1/0/all/0/1\">Mikel Lujan</a>",
          "description": "A typical machine learning (ML) development cycle for edge computing is to\nmaximise the performance during model training and then minimise the\nmemory/area footprint of the trained model for deployment on edge devices\ntargeting CPUs, GPUs, microcontrollers, or custom hardware accelerators. This\npaper proposes a methodology for automatically generating predictor circuits\nfor classification of tabular data with comparable prediction performance to\nconventional ML techniques while using substantially fewer hardware resources\nand power. The proposed methodology uses an evolutionary algorithm to search\nover the space of logic gates and automatically generates a classifier circuit\nwith maximised training prediction accuracy. Classifier circuits are so tiny\n(i.e., consisting of no more than 300 logic gates) that they are called \"Tiny\nClassifier\" circuits, and can efficiently be implemented in ASIC or on an FPGA.\nWe empirically evaluate the automatic Tiny Classifier circuit generation\nmethodology or \"Auto Tiny Classifiers\" on a wide range of tabular datasets, and\ncompare it against conventional ML techniques such as Amazon's AutoGluon,\nGoogle's TabNet and a neural search over Multi-Layer Perceptrons. Despite Tiny\nClassifiers being constrained to a few hundred logic gates, we observe no\nstatistically significant difference in prediction performance in comparison to\nthe best-performing ML baseline. When synthesised as a Silicon chip, Tiny\nClassifiers use 8-18x less area and 4-8x less power. When implemented as an\nultra-low cost chip on a flexible substrate (i.e., FlexIC), they occupy 10-75x\nless area and consume 13-75x less power compared to the most hardware-efficient\nML baseline. On an FPGA, Tiny Classifiers consume 3-11x fewer resources.",
          "link": "http://arxiv.org/abs/2303.00031",
          "publishedOn": "2023-09-30T00:41:30.662Z",
          "wordCount": null,
          "title": "Tiny Classifier Circuits: Evolving Accelerators for Tabular Data. (arXiv:2303.00031v2 [cs.AR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.09979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Haozhi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_B/0/1/0/all/0/1\">Brent Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1\">Sudharshan Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lambeta_M/0/1/0/all/0/1\">Mike Lambeta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calandra_R/0/1/0/all/0/1\">Roberto Calandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1\">Jitendra Malik</a>",
          "description": "We introduce RotateIt, a system that enables fingertip-based object rotation\nalong multiple axes by leveraging multimodal sensory inputs. Our system is\ntrained in simulation, where it has access to ground-truth object shapes and\nphysical properties. Then we distill it to operate on realistic yet noisy\nsimulated visuotactile and proprioceptive sensory inputs. These multimodal\ninputs are fused via a visuotactile transformer, enabling online inference of\nobject shapes and physical properties during deployment. We show significant\nperformance improvements over prior methods and the importance of visual and\ntactile sensing.",
          "link": "http://arxiv.org/abs/2309.09979",
          "publishedOn": "2023-09-30T00:41:30.661Z",
          "wordCount": null,
          "title": "General In-Hand Object Rotation with Vision and Touch. (arXiv:2309.09979v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.10775",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Attia_A/0/1/0/all/0/1\">Ahmed Adel Attia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tiede_M/0/1/0/all/0/1\">Mark Tiede</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Espy_Wilson_C/0/1/0/all/0/1\">Carol Y. Espy-Wilson</a>",
          "description": "Accurate analysis of speech articulation is crucial for speech analysis.\nHowever, X-Y coordinates of articulators strongly depend on the anatomy of the\nspeakers and the variability of pellet placements, and existing methods for\nmapping anatomical landmarks in the X-ray Microbeam Dataset (XRMB) fail to\ncapture the entire anatomy of the vocal tract. In this paper, we propose a new\ngeometric transformation that improves the accuracy of these measurements. Our\ntransformation maps anatomical landmarks' X-Y coordinates along the midsagittal\nplane onto six relative measures: Lip Aperture (LA), Lip Protusion (LP), Tongue\nBody Constriction Location (TTCL), Degree (TBCD), Tongue Tip Constriction\nLocation (TTCL) and Degree (TTCD). Our novel contribution is the extension of\nthe palate trace towards the inferred anterior pharyngeal line, which improves\nmeasurements of tongue body constriction.",
          "link": "http://arxiv.org/abs/2305.10775",
          "publishedOn": "2023-09-30T00:41:30.604Z",
          "wordCount": null,
          "title": "Enhancing Speech Articulation Analysis using a Geometric Transformation of the X-ray Microbeam Dataset. (arXiv:2305.10775v3 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pinon_B/0/1/0/all/0/1\">Brieuc Pinon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jungers_R/0/1/0/all/0/1\">Rapha&#xeb;l Jungers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delvenne_J/0/1/0/all/0/1\">Jean-Charles Delvenne</a>",
          "description": "We prove a fundamental limitation on the efficiency of a wide class of\nReinforcement Learning (RL) algorithms. This limitation applies to model-free\nRL methods as well as a broad range of model-based methods, such as planning\nwith tree search.\n\nUnder an abstract definition of this class, we provide a family of RL\nproblems for which these methods suffer a lower bound exponential in the\nhorizon for their interactions with the environment to find an optimal\nbehavior. However, there exists a method, not tailored to this specific family\nof problems, which can efficiently solve the problems in the family.\n\nIn contrast, our limitation does not apply to several types of methods\nproposed in the literature, for instance, goal-conditioned methods or other\nalgorithms that construct an inverse dynamics model.",
          "link": "http://arxiv.org/abs/2309.16291",
          "publishedOn": "2023-09-30T00:41:30.601Z",
          "wordCount": 633,
          "title": "Efficiency Separation between RL Methods: Model-Free, Model-Based and Goal-Conditioned. (arXiv:2309.16291v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Han Bao</a>",
          "description": "Contrastive learning is a self-supervised representation learning framework,\nwhere two positive views generated through data augmentation are made similar\nby an attraction force in a data representation space, while a repulsive force\nmakes them far from negative examples. Non-contrastive learning, represented by\nBYOL and SimSiam, further gets rid of negative examples and improves\ncomputational efficiency. While learned representations may collapse into a\nsingle point due to the lack of the repulsive force at first sight, Tian et al.\n(2021) revealed through the learning dynamics analysis that the representations\ncan avoid collapse if data augmentation is sufficiently stronger than\nregularization. However, their analysis does not take into account\ncommonly-used feature normalization, a normalizer before measuring the\nsimilarity of representations, and hence excessively strong regularization may\ncollapse the dynamics, which is an unnatural behavior under the presence of\nfeature normalization. Therefore, we extend the previous theory based on the L2\nloss by considering the cosine loss, which involves feature normalization. We\nshow that the cosine loss induces sixth-order dynamics (while the L2 loss\ninduces a third-order one), in which a stable equilibrium dynamically emerges\neven if there are only collapsed solutions with given initial parameters. Thus,\nwe offer a new understanding that feature normalization plays an important role\nin robustly preventing the dynamics collapse.",
          "link": "http://arxiv.org/abs/2309.16109",
          "publishedOn": "2023-09-30T00:41:30.458Z",
          "wordCount": null,
          "title": "Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics. (arXiv:2309.16109v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beretta_L/0/1/0/all/0/1\">Lorenzo Beretta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1\">Vincent Cohen-Addad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1\">Silvio Lattanzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parotsidis_N/0/1/0/all/0/1\">Nikos Parotsidis</a>",
          "description": "The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often\nthe practitioners' choice algorithm for optimizing the popular $k$-means\nclustering objective and is known to give an $O(\\log k)$-approximation in\nexpectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML\n2019) proposed augmenting $k$-means++ with $O(k \\log \\log k)$ local search\nsteps obtained through the $k$-means++ sampling distribution to yield a\n$c$-approximation to the $k$-means clustering problem, where $c$ is a large\nabsolute constant. Here we generalize and extend their local search algorithm\nby considering larger and more sophisticated local search neighborhoods hence\nallowing to swap multiple centers at the same time. Our algorithm achieves a $9\n+ \\varepsilon$ approximation ratio, which is the best possible for local\nsearch. Importantly we show that our approach yields substantial practical\nimprovements, we show significant quality improvements over the approach of\nLattanzi and Sohler (ICML 2019) on several datasets.",
          "link": "http://arxiv.org/abs/2309.16384",
          "publishedOn": "2023-09-30T00:41:30.458Z",
          "wordCount": null,
          "title": "Multi-Swap $k$-Means++. (arXiv:2309.16384v1 [cs.CG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16448",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zukovic_M/0/1/0/all/0/1\">Milan &#x17d;ukovi&#x10d;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hristopulos_D/0/1/0/all/0/1\">Dionissios T. Hristopulos</a>",
          "description": "We introduce the modified planar rotator method (MPRS), a physically inspired\nmachine learning method for spatial/temporal regression. MPRS is a\nnon-parametric model which incorporates spatial or temporal correlations via\nshort-range, distance-dependent ``interactions'' without assuming a specific\nform for the underlying probability distribution. Predictions are obtained by\nmeans of a fully autonomous learning algorithm which employs equilibrium\nconditional Monte Carlo simulations. MPRS is able to handle scattered data and\narbitrary spatial dimensions. We report tests on various synthetic and\nreal-word data in one, two and three dimensions which demonstrate that the MPRS\nprediction performance (without parameter tuning) is competitive with standard\ninterpolation methods such as ordinary kriging and inverse distance weighting.\nIn particular, MPRS is a particularly effective gap-filling method for rough\nand non-Gaussian data (e.g., daily precipitation time series). MPRS shows\nsuperior computational efficiency and scalability for large samples. Massive\ndata sets involving millions of nodes can be processed in a few seconds on a\nstandard personal computer.",
          "link": "http://arxiv.org/abs/2309.16448",
          "publishedOn": "2023-09-30T00:41:30.457Z",
          "wordCount": null,
          "title": "A parsimonious, computationally efficient machine learning method for spatial regression. (arXiv:2309.16448v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16465",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Boutet_D/0/1/0/all/0/1\">Dominic Boutet</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Baillet_S/0/1/0/all/0/1\">Sylvain Baillet</a> (Montreal Neurological Institute, McGill University, Montreal QC, Canada)",
          "description": "Parameter inference for dynamical models of (bio)physical systems remains a\nchallenging problem. Intractable gradients, high-dimensional spaces, and\nnon-linear model functions are typically problematic without large\ncomputational budgets. A recent body of work in that area has focused on\nBayesian inference methods, which consider parameters under their statistical\ndistributions and therefore, do not derive point estimates of optimal parameter\nvalues. Here we propose a new metaheuristic that drives dimensionality\nreductions from feature-informed transformations (DR-FFIT) to address these\nbottlenecks. DR-FFIT implements an efficient sampling strategy that facilitates\na gradient-free parameter search in high-dimensional spaces. We use artificial\nneural networks to obtain differentiable proxies for the model's features of\ninterest. The resulting gradients enable the estimation of a local active\nsubspace of the model within a defined sampling region. This approach enables\nefficient dimensionality reductions of highly non-linear search spaces at a low\ncomputational cost. Our test data show that DR-FFIT boosts the performances of\nrandom-search and simulated-annealing against well-established metaheuristics,\nand improves the goodness-of-fit of the model, all within contained run-time\ncosts.",
          "link": "http://arxiv.org/abs/2309.16465",
          "publishedOn": "2023-09-30T00:41:30.457Z",
          "wordCount": null,
          "title": "A Metaheuristic for Amortized Search in High-Dimensional Parameter Spaces. (arXiv:2309.16465v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15938",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jiang_X/0/1/0/all/0/1\">Xilin Jiang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1\">Cong Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yinghao Aaron Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mesgarani_N/0/1/0/all/0/1\">Nima Mesgarani</a>",
          "description": "In this study, we present a simple multi-channel framework for contrastive\nlearning (MC-SimCLR) to encode 'what' and 'where' of spatial audios. MC-SimCLR\nlearns joint spectral and spatial representations from unlabeled spatial\naudios, thereby enhancing both event classification and sound localization in\ndownstream tasks. At its core, we propose a multi-level data augmentation\npipeline that augments different levels of audio features, including waveforms,\nMel spectrograms, and generalized cross-correlation (GCC) features. In\naddition, we introduce simple yet effective channel-wise augmentation methods\nto randomly swap the order of the microphones and mask Mel and GCC channels. By\nusing these augmentations, we find that linear layers on top of the learned\nrepresentation significantly outperform supervised models in terms of both\nevent classification accuracy and localization error. We also perform a\ncomprehensive analysis of the effect of each augmentation method and a\ncomparison of the fine-tuning performance using different amounts of labeled\ndata.",
          "link": "http://arxiv.org/abs/2309.15938",
          "publishedOn": "2023-09-30T00:41:30.435Z",
          "wordCount": null,
          "title": "Exploring Self-Supervised Contrastive Learning of Spatial Sound Event Representation. (arXiv:2309.15938v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singhal_U/0/1/0/all/0/1\">Utkarsh Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esteves_C/0/1/0/all/0/1\">Carlos Esteves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1\">Ameesh Makadia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Stella X. Yu</a>",
          "description": "Computer vision research has long aimed to build systems that are robust to\nspatial transformations found in natural data. Traditionally, this is done\nusing data augmentation or hard-coding invariances into the architecture.\nHowever, too much or too little invariance can hurt, and the correct amount is\nunknown a priori and dependent on the instance. Ideally, the appropriate\ninvariance would be learned from data and inferred at test-time.\n\nWe treat invariance as a prediction problem. Given any image, we use a\nnormalizing flow to predict a distribution over transformations and average the\npredictions over them. Since this distribution only depends on the instance, we\ncan align instances before classifying them and generalize invariance across\nclasses. The same distribution can also be used to adapt to out-of-distribution\nposes. This normalizing flow is trained end-to-end and can learn a much larger\nrange of transformations than Augerino and InstaAug. When used as data\naugmentation, our method shows accuracy and robustness gains on CIFAR 10,\nCIFAR10-LT, and TinyImageNet.",
          "link": "http://arxiv.org/abs/2309.16672",
          "publishedOn": "2023-09-30T00:41:30.435Z",
          "wordCount": null,
          "title": "Learning to Transform for Generalizable Instance-wise Invariance. (arXiv:2309.16672v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1\">Jeffrey N. Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Small_E/0/1/0/all/0/1\">Edward A. Small</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keshtmand_N/0/1/0/all/0/1\">Nawid Keshtmand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_M/0/1/0/all/0/1\">Michelle W.L. Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayoral_E/0/1/0/all/0/1\">Elena Fillola Mayoral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werner_E/0/1/0/all/0/1\">Enrico Werner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bourdeaux_C/0/1/0/all/0/1\">Christopher P. Bourdeaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1\">Raul Santos-Rodriguez</a>",
          "description": "Counterfactual explanations, and their associated algorithmic recourse, are\ntypically leveraged to understand, explain, and potentially alter a prediction\ncoming from a black-box classifier. In this paper, we propose to extend the use\nof counterfactuals to evaluate progress in sequential decision making tasks. To\nthis end, we introduce a model-agnostic modular framework, TraCE (Trajectory\nCounterfactual Explanation) scores, which is able to distill and condense\nprogress in highly complex scenarios into a single value. We demonstrate\nTraCE's utility across domains by showcasing its main properties in two case\nstudies spanning healthcare and climate change.",
          "link": "http://arxiv.org/abs/2309.15965",
          "publishedOn": "2023-09-30T00:41:30.434Z",
          "wordCount": null,
          "title": "TraCE: Trajectory Counterfactual Explanation Scores. (arXiv:2309.15965v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Seungwhan Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhaojiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagarajan_T/0/1/0/all/0/1\">Tushar Nagarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Matt Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Shashank Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1\">Chun-Fu Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murugesan_P/0/1/0/all/0/1\">Prakash Murugesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidari_P/0/1/0/all/0/1\">Peyman Heidari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinet_K/0/1/0/all/0/1\">Kavya Srinet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damavandi_B/0/1/0/all/0/1\">Babak Damavandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Anuj Kumar</a>",
          "description": "We present Any-Modality Augmented Language Model (AnyMAL), a unified model\nthat reasons over diverse input modality signals (i.e. text, image, video,\naudio, IMU motion sensor), and generates textual responses. AnyMAL inherits the\npowerful text-based reasoning abilities of the state-of-the-art LLMs including\nLLaMA-2 (70B), and converts modality-specific signals to the joint textual\nspace through a pre-trained aligner module. To further strengthen the\nmultimodal LLM's capabilities, we fine-tune the model with a multimodal\ninstruction set manually collected to cover diverse topics and tasks beyond\nsimple QAs. We conduct comprehensive empirical analysis comprising both human\nand automatic evaluations, and demonstrate state-of-the-art performance on\nvarious multimodal tasks.",
          "link": "http://arxiv.org/abs/2309.16058",
          "publishedOn": "2023-09-30T00:41:30.433Z",
          "wordCount": null,
          "title": "AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model. (arXiv:2309.16058v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16397",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zenan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_F/0/1/0/all/0/1\">Fan Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Qiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Da_F/0/1/0/all/0/1\">Fang Da</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hang Zhao</a>",
          "description": "Offline Reinforcement Learning (RL) has emerged as a promising framework for\nlearning policies without active interactions, making it especially appealing\nfor autonomous driving tasks. Recent successes of Transformers inspire casting\noffline RL as sequence modeling, which performs well in long-horizon tasks.\nHowever, they are overly optimistic in stochastic environments with incorrect\nassumptions that the same goal can be consistently achieved by identical\nactions. In this paper, we introduce an UNcertainty-awaRE deciSion Transformer\n(UNREST) for planning in stochastic driving environments without introducing\nadditional transition or complex generative models. Specifically, UNREST\nestimates state uncertainties by the conditional mutual information between\ntransitions and returns, and segments sequences accordingly. Discovering the\n`uncertainty accumulation' and `temporal locality' properties of driving\nenvironments, UNREST replaces the global returns in decision transformers with\nless uncertain truncated returns, to learn from true outcomes of agent actions\nrather than environment transitions. We also dynamically evaluate environmental\nuncertainty during inference for cautious planning. Extensive experimental\nresults demonstrate UNREST's superior performance in various driving scenarios\nand the power of our uncertainty estimation strategy.",
          "link": "http://arxiv.org/abs/2309.16397",
          "publishedOn": "2023-09-30T00:41:30.433Z",
          "wordCount": null,
          "title": "Uncertainty-Aware Decision Transformer for Stochastic Driving Environments. (arXiv:2309.16397v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.03890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biradar_G/0/1/0/all/0/1\">Gagan Biradar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izza_Y/0/1/0/all/0/1\">Yacine Izza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lobo_E/0/1/0/all/0/1\">Elita Lobo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1\">Vignesh Viswanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zick_Y/0/1/0/all/0/1\">Yair Zick</a>",
          "description": "The recent criticisms of the robustness of post hoc model approximation\nexplanation methods (like LIME and SHAP) have led to the rise of model-precise\nabductive explanations. For each data point, abductive explanations provide a\nminimal subset of features that are sufficient to generate the outcome. While\ntheoretically sound and rigorous, abductive explanations suffer from a major\nissue -- there can be several valid abductive explanations for the same data\npoint. In such cases, providing a single abductive explanation can be\ninsufficient; on the other hand, providing all valid abductive explanations can\nbe incomprehensible due to their size. In this work, we solve this issue by\naggregating the many possible abductive explanations into feature importance\nscores. We propose three aggregation methods: two based on power indices from\ncooperative game theory and a third based on a well-known measure of causal\nstrength. We characterize these three methods axiomatically, showing that each\nof them uniquely satisfies a set of desirable properties. We also evaluate them\non multiple datasets and show that these explanations are robust to the attacks\nthat fool SHAP and LIME.",
          "link": "http://arxiv.org/abs/2109.03890",
          "publishedOn": "2023-09-30T00:41:30.431Z",
          "wordCount": null,
          "title": "Axiomatic Aggregations of Abductive Explanations. (arXiv:2109.03890v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16032",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yuezhu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivaranjani_S/0/1/0/all/0/1\">S. Sivaranjani</a>",
          "description": "Consider an unknown nonlinear dynamical system that is known to be\ndissipative. The objective of this paper is to learn a neural dynamical model\nthat approximates this system, while preserving the dissipativity property in\nthe model. In general, imposing dissipativity constraints during neural network\ntraining is a hard problem for which no known techniques exist. In this work,\nwe address the problem of learning a dissipative neural dynamical system model\nin two stages. First, we learn an unconstrained neural dynamical model that\nclosely approximates the system dynamics. Next, we derive sufficient conditions\nto perturb the weights of the neural dynamical model to ensure dissipativity,\nfollowed by perturbation of the biases to retain the fit of the model to the\ntrajectories of the nonlinear system. We show that these two perturbation\nproblems can be solved independently to obtain a neural dynamical model that is\nguaranteed to be dissipative while closely approximating the nonlinear system.",
          "link": "http://arxiv.org/abs/2309.16032",
          "publishedOn": "2023-09-30T00:41:30.430Z",
          "wordCount": null,
          "title": "Learning Dissipative Neural Dynamical Systems. (arXiv:2309.16032v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16459",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andriopoulos_K/0/1/0/all/0/1\">Konstantinos Andriopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouwelse_J/0/1/0/all/0/1\">Johan Pouwelse</a>",
          "description": "Large pre-trained language models have demonstrated their proficiency in\nstoring factual knowledge within their parameters and achieving remarkable\nresults when fine-tuned for downstream natural language processing tasks.\nNonetheless, their capacity to access and manipulate knowledge with precision\nremains constrained, resulting in performance disparities on\nknowledge-intensive tasks when compared to task-specific architectures.\nAdditionally, the challenges of providing provenance for model decisions and\nmaintaining up-to-date world knowledge persist as open research frontiers. To\naddress these limitations, the integration of pre-trained models with\ndifferentiable access mechanisms to explicit non-parametric memory emerges as a\npromising solution. This survey delves into the realm of language models (LMs)\naugmented with the ability to tap into external knowledge sources, including\nexternal knowledge bases and search engines. While adhering to the standard\nobjective of predicting missing tokens, these augmented LMs leverage diverse,\npossibly non-parametric external modules to augment their contextual processing\ncapabilities, departing from the conventional language modeling paradigm.\nThrough an exploration of current advancements in augmenting large language\nmodels with knowledge, this work concludes that this emerging research\ndirection holds the potential to address prevalent issues in traditional LMs,\nsuch as hallucinations, un-grounded responses, and scalability challenges.",
          "link": "http://arxiv.org/abs/2309.16459",
          "publishedOn": "2023-09-30T00:41:30.430Z",
          "wordCount": null,
          "title": "Augmenting LLMs with Knowledge: A survey on hallucination prevention. (arXiv:2309.16459v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">David Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannengiesser_N/0/1/0/all/0/1\">Niclas Kannengie&#xdf;er</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rank_S/0/1/0/all/0/1\">Sascha Rank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunyaev_A/0/1/0/all/0/1\">Ali Sunyaev</a>",
          "description": "To leverage training data for the sufficient training of ML models from\nmultiple parties in a confidentiality-preserving way, various collaborative\ndistributed machine learning (CDML) system designs have been developed, for\nexample, to perform assisted learning, federated learning, and split learning.\nCDML system designs show different traits, for example, high agent autonomy,\nmachine learning (ML) model confidentiality, and fault tolerance. Facing a wide\nvariety of CDML system designs with different traits, it is difficult for\ndevelopers to design CDML systems with traits that match use case requirements\nin a targeted way. However, inappropriate CDML system designs may result in\nCDML systems failing their envisioned purposes. We developed a CDML design\ntoolbox that can guide the development of CDML systems. Based on the CDML\ndesign toolbox, we present CDML system archetypes with distinct key traits that\ncan support the design of CDML systems to meet use case requirements.",
          "link": "http://arxiv.org/abs/2309.16584",
          "publishedOn": "2023-09-30T00:41:30.430Z",
          "wordCount": null,
          "title": "A Design Toolbox for the Development of Collaborative Distributed Machine Learning Systems. (arXiv:2309.16584v1 [cs.MA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Ke Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albro_S/0/1/0/all/0/1\">Stephen Albro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DeSalvo_G/0/1/0/all/0/1\">Giulia DeSalvo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kothawade_S/0/1/0/all/0/1\">Suraj Kothawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashwan_A/0/1/0/all/0/1\">Abdullah Rashwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavakkol_S/0/1/0/all/0/1\">Sasan Tavakkol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batmanghelich_K/0/1/0/all/0/1\">Kayhan Batmanghelich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiaoqi Yin</a>",
          "description": "Training high-quality instance segmentation models requires an abundance of\nlabeled images with instance masks and classifications, which is often\nexpensive to procure. Active learning addresses this challenge by striving for\noptimum performance with minimal labeling cost by selecting the most\ninformative and representative images for labeling. Despite its potential,\nactive learning has been less explored in instance segmentation compared to\nother tasks like image classification, which require less labeling. In this\nstudy, we propose a post-hoc active learning algorithm that integrates\nuncertainty-based sampling with diversity-based sampling. Our proposed\nalgorithm is not only simple and easy to implement, but it also delivers\nsuperior performance on various datasets. Its practical application is\ndemonstrated on a real-world overhead imagery dataset, where it increases the\nlabeling efficiency fivefold.",
          "link": "http://arxiv.org/abs/2309.16139",
          "publishedOn": "2023-09-30T00:41:30.428Z",
          "wordCount": null,
          "title": "Two-Step Active Learning for Instance Segmentation with Uncertainty and Diversity Sampling. (arXiv:2309.16139v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jiarui Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon Shaolei Du</a>",
          "description": "Currently, reinforcement learning (RL), especially deep RL, has received more\nand more attention in the research area. However, the security of RL has been\nan obvious problem due to the attack manners becoming mature. In order to\ndefend against such adversarial attacks, several practical approaches are\ndeveloped, such as adversarial training, data filtering, etc. However, these\nmethods are mostly based on empirical algorithms and experiments, without\nrigorous theoretical analysis of the robustness of the algorithms. In this\npaper, we develop an algorithm to certify the robustness of a given policy\noffline with random smoothing, which could be proven and conducted as\nefficiently as ones without random smoothing. Experiments on different\nenvironments confirm the correctness of our algorithm.",
          "link": "http://arxiv.org/abs/2309.16631",
          "publishedOn": "2023-09-30T00:41:30.423Z",
          "wordCount": null,
          "title": "Robust Offline Reinforcement Learning -- Certify the Confidence Interval. (arXiv:2309.16631v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.00723",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Luo_D/0/1/0/all/0/1\">Di Luo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Halverson_J/0/1/0/all/0/1\">James Halverson</a>",
          "description": "We study infinite limits of neural network quantum states ($\\infty$-NNQS),\nwhich exhibit representation power through ensemble statistics, and also\ntractable gradient descent dynamics. Ensemble averages of Renyi entropies are\nexpressed in terms of neural network correlators, and architectures that\nexhibit volume-law entanglement are presented. A general framework is developed\nfor studying the gradient descent dynamics of neural network quantum states\n(NNQS), using a quantum state neural tangent kernel (QS-NTK). For $\\infty$-NNQS\nthe training dynamics is simplified, since the QS-NTK becomes deterministic and\nconstant. An analytic solution is derived for quantum state supervised\nlearning, which allows an $\\infty$-NNQS to recover any target wavefunction.\nNumerical experiments on finite and infinite NNQS in the transverse field Ising\nmodel and Fermi Hubbard model demonstrate excellent agreement with theory.\n$\\infty$-NNQS opens up new opportunities for studying entanglement and training\ndynamics in other physics applications, such as in finding ground states.",
          "link": "http://arxiv.org/abs/2112.00723",
          "publishedOn": "2023-09-30T00:41:30.423Z",
          "wordCount": null,
          "title": "Infinite Neural Network Quantum States: Entanglement and Training Dynamics. (arXiv:2112.00723v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Satvik Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_S/0/1/0/all/0/1\">Shivam Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Somya Garg</a>",
          "description": "Knowledge graphs (KGs) are gaining prominence in Healthcare AI, especially in\ndrug discovery and pharmaceutical research as they provide a structured way to\nintegrate diverse information sources, enhancing AI system interpretability.\nThis interpretability is crucial in healthcare, where trust and transparency\nmatter, and eXplainable AI (XAI) supports decision making for healthcare\nprofessionals. This overview summarizes recent literature on the impact of KGs\nin healthcare and their role in developing explainable AI models. We cover KG\nworkflow, including construction, relationship extraction, reasoning, and their\napplications in areas like Drug-Drug Interactions (DDI), Drug Target\nInteractions (DTI), Drug Development (DD), Adverse Drug Reactions (ADR), and\nbioinformatics. We emphasize the importance of making KGs more interpretable\nthrough knowledge-infused learning in healthcare. Finally, we highlight\nresearch challenges and provide insights for future directions.",
          "link": "http://arxiv.org/abs/2309.16593",
          "publishedOn": "2023-09-30T00:41:30.417Z",
          "wordCount": null,
          "title": "Navigating Healthcare Insights: A Birds Eye View of Explainability with Knowledge Graphs. (arXiv:2309.16593v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16620",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1\">Blake Bordelon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Noci_L/0/1/0/all/0/1\">Lorenzo Noci</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Mufan Bill Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanin_B/0/1/0/all/0/1\">Boris Hanin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "The cost of hyperparameter tuning in deep learning has been rising with model\nsizes, prompting practitioners to find new tuning methods using a proxy of\nsmaller networks. One such proposal uses $\\mu$P parameterized networks, where\nthe optimal hyperparameters for small width networks transfer to networks with\narbitrarily large width. However, in this scheme, hyperparameters do not\ntransfer across depths. As a remedy, we study residual networks with a residual\nbranch scale of $1/\\sqrt{\\text{depth}}$ in combination with the $\\mu$P\nparameterization. We provide experiments demonstrating that residual\narchitectures including convolutional ResNets and Vision Transformers trained\nwith this parameterization exhibit transfer of optimal hyperparameters across\nwidth and depth on CIFAR-10 and ImageNet. Furthermore, our empirical findings\nare supported and motivated by theory. Using recent developments in the\ndynamical mean field theory (DMFT) description of neural network learning\ndynamics, we show that this parameterization of ResNets admits a well-defined\nfeature learning joint infinite-width and infinite-depth limit and show\nconvergence of finite-size network dynamics towards this limit.",
          "link": "http://arxiv.org/abs/2309.16620",
          "publishedOn": "2023-09-30T00:41:30.416Z",
          "wordCount": null,
          "title": "Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit. (arXiv:2309.16620v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mallet_V/0/1/0/all/0/1\">Vincent Mallet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attaiki_S/0/1/0/all/0/1\">Souhaib Attaiki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ovsjanikov_M/0/1/0/all/0/1\">Maks Ovsjanikov</a>",
          "description": "Recent advancements in Cryo-EM and protein structure prediction algorithms\nhave made large-scale protein structures accessible, paving the way for machine\nlearning-based functional annotations.The field of geometric deep learning\nfocuses on creating methods working on geometric data. An essential aspect of\nlearning from protein structures is representing these structures as a\ngeometric object (be it a grid, graph, or surface) and applying a learning\nmethod tailored to this representation. The performance of a given approach\nwill then depend on both the representation and its corresponding learning\nmethod.\n\nIn this paper, we investigate representing proteins as $\\textit{3D mesh\nsurfaces}$ and incorporate them into an established representation benchmark.\nOur first finding is that despite promising preliminary results, the surface\nrepresentation alone does not seem competitive with 3D grids. Building on this,\nwe introduce a synergistic approach, combining surface representations with\ngraph-based methods, resulting in a general framework that incorporates both\nrepresentations in learning. We show that using this combination, we are able\nto obtain state-of-the-art results across $\\textit{all tested tasks}$. Our code\nand data can be found online: https://github.com/Vincentx15/atom2D .",
          "link": "http://arxiv.org/abs/2309.16519",
          "publishedOn": "2023-09-30T00:41:30.381Z",
          "wordCount": null,
          "title": "AtomSurf : Surface Representation for Learning on Protein Structures. (arXiv:2309.16519v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16428",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bonassi_F/0/1/0/all/0/1\">Fabio Bonassi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bella_A/0/1/0/all/0/1\">Alessio La Bella</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Farina_M/0/1/0/all/0/1\">Marcello Farina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scattolini_R/0/1/0/all/0/1\">Riccardo Scattolini</a>",
          "description": "This brief addresses the design of a Nonlinear Model Predictive Control\n(NMPC) strategy for exponentially incremental Input-to-State Stable (ISS)\nsystems. In particular, a novel formulation is devised, which does not\nnecessitate the onerous computation of terminal ingredients, but rather relies\non the explicit definition of a minimum prediction horizon ensuring closed-loop\nstability. The designed methodology is particularly suited for the control of\nsystems learned by Recurrent Neural Networks (RNNs), which are known for their\nenhanced modeling capabilities and for which the incremental ISS properties can\nbe studied thanks to simple algebraic conditions. The approach is applied to\nGated Recurrent Unit (GRU) networks, providing also a method for the design of\na tailored state observer with convergence guarantees. The resulting control\narchitecture is tested on a benchmark system, demonstrating its good control\nperformances and efficient applicability.",
          "link": "http://arxiv.org/abs/2309.16428",
          "publishedOn": "2023-09-30T00:41:30.379Z",
          "wordCount": null,
          "title": "Nonlinear MPC design for incrementally ISS systems with application to GRU networks. (arXiv:2309.16428v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16536",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brown_D/0/1/0/all/0/1\">Donald Brown</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Syed_S/0/1/0/all/0/1\">Sana Syed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greene_A/0/1/0/all/0/1\">Adam Greene</a>",
          "description": "Eosinophilic Esophagitis (EoE) is an allergic condition increasing in\nprevalence. To diagnose EoE, pathologists must find 15 or more eosinophils\nwithin a single high-power field (400X magnification). Determining whether or\nnot a patient has EoE can be an arduous process and any medical imaging\napproaches used to assist diagnosis must consider both efficiency and\nprecision. We propose an improvement of Adorno et al's approach for quantifying\neosinphils using deep image segmentation. Our new approach leverages Monte\nCarlo Dropout, a common approach in deep learning to reduce overfitting, to\nprovide uncertainty quantification on current deep learning models. The\nuncertainty can be visualized in an output image to evaluate model performance,\nprovide insight to how deep learning algorithms function, and assist\npathologists in identifying eosinophils.",
          "link": "http://arxiv.org/abs/2309.16536",
          "publishedOn": "2023-09-30T00:41:30.379Z",
          "wordCount": null,
          "title": "Uncertainty Quantification for Eosinophil Segmentation. (arXiv:2309.16536v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16177",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lin_J/0/1/0/all/0/1\">Jerry Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yu_S/0/1/0/all/0/1\">Sungduk Yu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Beucler_T/0/1/0/all/0/1\">Tom Beucler</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gentine_P/0/1/0/all/0/1\">Pierre Gentine</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Walling_D/0/1/0/all/0/1\">David Walling</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pritchard_M/0/1/0/all/0/1\">Mike Pritchard</a>",
          "description": "Progress in hybrid physics-machine learning (ML) climate simulations has been\nlimited by the difficulty of obtaining performant coupled (i.e. online)\nsimulations. While evaluating hundreds of ML parameterizations of subgrid\nclosures (here of convection and radiation) offline is straightforward, online\nevaluation at the same scale is technically challenging. Our software\nautomation achieves an order-of-magnitude larger sampling of online modeling\nerrors than has previously been examined. Using this, we evaluate the hybrid\nclimate model performance and define strategies to improve it. We show that\nmodel online performance improves when incorporating memory, a relative\nhumidity input feature transformation, and additional input variables. We also\nreveal substantial variation in online error and inconsistencies between\noffline vs. online error statistics. The implication is that hundreds of\ncandidate ML models should be evaluated online to detect the effects of\nparameterization design choices. This is considerably more sampling than tends\nto be reported in the current literature.",
          "link": "http://arxiv.org/abs/2309.16177",
          "publishedOn": "2023-09-30T00:41:30.378Z",
          "wordCount": null,
          "title": "Systematic Sampling and Validation of Machine Learning-Parameterizations in Climate Models. (arXiv:2309.16177v1 [physics.ao-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hochuli_A/0/1/0/all/0/1\">Andre Gustavo Hochuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barddal_J/0/1/0/all/0/1\">Jean Paul Barddal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palhano_G/0/1/0/all/0/1\">Gillian Cezar Palhano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendes_L/0/1/0/all/0/1\">Leonardo Matheus Mendes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almeida_P/0/1/0/all/0/1\">Paulo Ricardo Lisboa de Almeida</a>",
          "description": "Searching for available parking spots in high-density urban centers is a\nstressful task for drivers that can be mitigated by systems that know in\nadvance the nearest parking space available.\n\nTo this end, image-based systems offer cost advantages over other\nsensor-based alternatives (e.g., ultrasonic sensors), requiring less physical\ninfrastructure for installation and maintenance.\n\nDespite recent deep learning advances, deploying intelligent parking\nmonitoring is still a challenge since most approaches involve collecting and\nlabeling large amounts of data, which is laborious and time-consuming. Our\nstudy aims to uncover the challenges in creating a global framework, trained\nusing publicly available labeled parking lot images, that performs accurately\nacross diverse scenarios, enabling the parking space monitoring as a\nready-to-use system to deploy in a new environment. Through exhaustive\nexperiments involving different datasets and deep learning architectures,\nincluding fusion strategies and ensemble methods, we found that models trained\non diverse datasets can achieve 95\\% accuracy without the burden of data\nannotation and model training on the target parking lot",
          "link": "http://arxiv.org/abs/2309.16495",
          "publishedOn": "2023-09-30T00:41:30.378Z",
          "wordCount": null,
          "title": "Deep Single Models vs. Ensembles: Insights for a Fast Deployment of Parking Monitoring Systems. (arXiv:2309.16495v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.12547",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Li_J/0/1/0/all/0/1\">Jin Li</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Luo_Y/0/1/0/all/0/1\">Ye Luo</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaowei Zhang</a>",
          "description": "This paper identifies and addresses dynamic selection problems in online\nlearning algorithms with endogenous data. In a contextual multi-armed bandit\nmodel, a novel bias (self-fulfilling bias) arises because the endogeneity of\nthe data influences the choices of decisions, affecting the distribution of\nfuture data to be collected and analyzed. We propose an\ninstrumental-variable-based algorithm to correct for the bias. It obtains true\nparameter values and attains low (logarithmic-like) regret levels. We also\nprove a central limit theorem for statistical inference. To establish the\ntheoretical properties, we develop a general technique that untangles the\ninterdependence between data and actions.",
          "link": "http://arxiv.org/abs/2108.12547",
          "publishedOn": "2023-09-30T00:41:30.377Z",
          "wordCount": null,
          "title": "Dynamic Selection in Algorithmic Decision-making. (arXiv:2108.12547v3 [econ.EM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meyarian_A/0/1/0/all/0/1\">Abolfazl Meyarian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xiaohui Yuan</a>",
          "description": "High-resolution aerial imagery allows fine details in the segmentation of\nfarmlands. However, small objects and features introduce distortions to the\ndelineation of object boundaries, and larger contextual views are needed to\nmitigate class confusion. In this work, we present an end-to-end trainable\nnetwork for segmenting farmlands with contour levees from high-resolution\naerial imagery. A fusion block is devised that includes multiple voting blocks\nto achieve image segmentation and classification. We integrate the fusion block\nwith a backbone and produce both semantic predictions and segmentation slices.\nThe segmentation slices are used to perform majority voting on the predictions.\nThe network is trained to assign the most likely class label of a segment to\nits pixels, learning the concept of farmlands rather than analyzing\nconstitutive pixels separately. We evaluate our method using images from the\nNational Agriculture Imagery Program. Our method achieved an average accuracy\nof 94.34\\%. Compared to the state-of-the-art methods, the proposed method\nobtains an improvement of 6.96% and 2.63% in the F1 score on average.",
          "link": "http://arxiv.org/abs/2309.16561",
          "publishedOn": "2023-09-30T00:41:30.375Z",
          "wordCount": null,
          "title": "Voting Network for Contour Levee Farmland Segmentation and Classification. (arXiv:2309.16561v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16412",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Noskov_F/0/1/0/all/0/1\">Fedor Noskov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fishkov_A/0/1/0/all/0/1\">Alexander Fishkov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Panov_M/0/1/0/all/0/1\">Maxim Panov</a>",
          "description": "Prediction with the possibility of abstention (or selective prediction) is an\nimportant problem for error-critical machine learning applications. While\nwell-studied in the classification setup, selective approaches to regression\nare much less developed. In this work, we consider the nonparametric\nheteroskedastic regression problem and develop an abstention procedure via\ntesting the hypothesis on the value of the conditional variance at a given\npoint. Unlike existing methods, the proposed one allows to account not only for\nthe value of the variance itself but also for the uncertainty of the\ncorresponding variance predictor. We prove non-asymptotic bounds on the risk of\nthe resulting estimator and show the existence of several different convergence\nregimes. Theoretical analysis is illustrated with a series of experiments on\nsimulated and real-world data.",
          "link": "http://arxiv.org/abs/2309.16412",
          "publishedOn": "2023-09-30T00:41:30.314Z",
          "wordCount": null,
          "title": "Selective Nonparametric Regression via Testing. (arXiv:2309.16412v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aiello_E/0/1/0/all/0/1\">Emanuele Aiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lili Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Yixin Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghajanyan_A/0/1/0/all/0/1\">Armen Aghajanyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oguz_B/0/1/0/all/0/1\">Barlas Oguz</a>",
          "description": "In recent years, advances in the large-scale pretraining of language and\ntext-to-image models have revolutionized the field of machine learning. Yet,\nintegrating these two modalities into a single, robust model capable of\ngenerating seamless multimodal outputs remains a significant challenge. To\naddress this gap, we present the Joint Autoregressive Mixture (JAM) framework,\na modular approach that systematically fuses existing text and image generation\nmodels. We also introduce a specialized, data-efficient instruction-tuning\nstrategy, tailored for mixed-modal generation tasks. Our final instruct-tuned\nmodel demonstrates unparalleled performance in generating high-quality\nmultimodal outputs and represents the first model explicitly designed for this\npurpose.",
          "link": "http://arxiv.org/abs/2309.15564",
          "publishedOn": "2023-09-30T00:41:30.313Z",
          "wordCount": null,
          "title": "Jointly Training Large Autoregressive Multimodal Models. (arXiv:2309.15564v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zixuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Ze Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_J/0/1/0/all/0/1\">Jing Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "Enabling robots to effectively imitate expert skills in longhorizon tasks\nsuch as locomotion, manipulation, and more, poses a long-standing challenge.\nExisting imitation learning (IL) approaches for robots still grapple with\nsub-optimal performance in complex tasks. In this paper, we consider how this\nchallenge can be addressed within the human cognitive priors. Heuristically, we\nextend the usual notion of action to a dual Cognition (high-level)-Action\n(low-level) architecture by introducing intuitive human cognitive priors, and\npropose a novel skill IL framework through human-robot interaction, called\nCognition-Action-based Skill Imitation Learning (CasIL), for the robotic agent\nto effectively cognize and imitate the critical skills from raw visual\ndemonstrations. CasIL enables both cognition and action imitation, while\nhigh-level skill cognition explicitly guides low-level primitive actions,\nproviding robustness and reliability to the entire skill IL process. We\nevaluated our method on MuJoCo and RLBench benchmarks, as well as on the\nobstacle avoidance and point-goal navigation tasks for quadrupedal robot\nlocomotion. Experimental results show that our CasIL consistently achieves\ncompetitive and robust skill imitation capability compared to other\ncounterparts in a variety of long-horizon robotic tasks.",
          "link": "http://arxiv.org/abs/2309.16299",
          "publishedOn": "2023-09-30T00:41:30.311Z",
          "wordCount": null,
          "title": "CasIL: Cognizing and Imitating Skills via a Dual Cognition-Action Architecture. (arXiv:2309.16299v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahoney_J/0/1/0/all/0/1\">Joseph M. Mahoney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paniak_T/0/1/0/all/0/1\">Tomasz B. Paniak</a>",
          "description": "Daily fantasy sports (DFS) are weekly or daily online contests where\nreal-game performances of individual players are converted to fantasy points\n(FPTS). Users select players for their lineup to maximize their FPTS within a\nset player salary cap. This paper focuses on (1) the development of a method to\nforecast NFL player performance under uncertainty and (2) determining an\noptimal lineup to maximize FPTS under a set salary limit. A supervised learning\nneural network was created and used to project FPTS based on past player\nperformance (2018 NFL regular season for this work) prior to the upcoming week.\nThese projected FPTS were used in a mixed integer linear program to find the\noptimal lineup. The performance of resultant lineups was compared to\nrandomly-created lineups. On average, the optimal lineups outperformed the\nrandom lineups. The generated lineups were then compared to real-world lineups\nfrom users on DraftKings. The generated lineups generally fell in approximately\nthe 31st percentile (median). The FPTS methods and predictions presented here\ncan be further improved using this study as a baseline comparison.",
          "link": "http://arxiv.org/abs/2309.15253",
          "publishedOn": "2023-09-30T00:41:30.311Z",
          "wordCount": null,
          "title": "Method and Validation for Optimal Lineup Creation for Daily Fantasy Football Using Machine Learning and Linear Programming. (arXiv:2309.15253v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Islakoglu_D/0/1/0/all/0/1\">Duygu Sezen Islakoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chekol_M/0/1/0/all/0/1\">Mel Chekol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velegrakis_Y/0/1/0/all/0/1\">Yannis Velegrakis</a>",
          "description": "Most knowledge graph completion (KGC) methods learn latent representations of\nentities and relations of a given graph by mapping them into a vector space.\nAlthough the majority of these methods focus on static knowledge graphs, a\nlarge number of publicly available KGs contain temporal information stating the\ntime instant/period over which a certain fact has been true. Such graphs are\noften known as temporal knowledge graphs. Furthermore, knowledge graphs may\nalso contain textual descriptions of entities and relations. Both temporal\ninformation and textual descriptions are not taken into account during\nrepresentation learning by static KGC methods, and only structural information\nof the graph is leveraged. Recently, some studies have used temporal\ninformation to improve link prediction, yet they do not exploit textual\ndescriptions and do not support inductive inference (prediction on entities\nthat have not been seen in training).\n\nWe propose a novel framework called TEMT that exploits the power of\npre-trained language models (PLMs) for text-enhanced temporal knowledge graph\ncompletion. The knowledge stored in the parameters of a PLM allows TEMT to\nproduce rich semantic representations of facts and to generalize on previously\nunseen entities. TEMT leverages textual and temporal information available in a\nKG, treats them separately, and fuses them to get plausibility scores of facts.\nUnlike previous approaches, TEMT effectively captures dependencies across\ndifferent time points and enables predictions on unseen entities. To assess the\nperformance of TEMT, we carried out several experiments including time interval\nprediction, both in transductive and inductive settings, and triple\nclassification. The experimental results show that TEMT is competitive with the\nstate-of-the-art.",
          "link": "http://arxiv.org/abs/2309.16357",
          "publishedOn": "2023-09-30T00:41:30.310Z",
          "wordCount": null,
          "title": "Leveraging Pre-trained Language Models for Time Interval Prediction in Text-Enhanced Temporal Knowledge Graphs. (arXiv:2309.16357v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.10538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xinran Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>",
          "description": "Bayesian optimization (BO), while proved highly effective for many black-box\nfunction optimization tasks, requires practitioners to carefully select priors\nthat well model their functions of interest. Rather than specifying by hand,\nresearchers have investigated transfer learning based methods to automatically\nlearn the priors, e.g. multi-task BO (Swersky et al., 2013), few-shot BO\n(Wistuba and Grabocka, 2021) and HyperBO (Wang et al., 2022). However, those\nprior learning methods typically assume that the input domains are the same for\nall tasks, weakening their ability to use observations on functions with\ndifferent domains or generalize the learned priors to BO on different search\nspaces. In this work, we present HyperBO+: a pre-training approach for\nhierarchical Gaussian processes that enables the same prior to work universally\nfor Bayesian optimization on functions with different domains. We propose a\ntwo-step pre-training method and analyze its appealing asymptotic properties\nand benefits to BO both theoretically and empirically. On real-world\nhyperparameter tuning tasks that involve multiple search spaces, we demonstrate\nthat HyperBO+ is able to generalize to unseen search spaces and achieves lower\nregrets than competitive baselines.",
          "link": "http://arxiv.org/abs/2212.10538",
          "publishedOn": "2023-09-30T00:41:30.310Z",
          "wordCount": null,
          "title": "HyperBO+: Pre-training a universal prior for Bayesian optimization with hierarchical Gaussian processes. (arXiv:2212.10538v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.05625",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_G/0/1/0/all/0/1\">Guangxi Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhao_X/0/1/0/all/0/1\">Xuanqiang Zhao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>",
          "description": "An emerging direction of quantum computing is to establish meaningful quantum\napplications in various fields of artificial intelligence, including natural\nlanguage processing (NLP). Although some efforts based on syntactic analysis\nhave opened the door to research in Quantum NLP (QNLP), limitations such as\nheavy syntactic preprocessing and syntax-dependent network architecture make\nthem impracticable on larger and real-world data sets. In this paper, we\npropose a new simple network architecture, called the quantum self-attention\nneural network (QSANN), which can compensate for these limitations.\nSpecifically, we introduce the self-attention mechanism into quantum neural\nnetworks and then utilize a Gaussian projected quantum self-attention serving\nas a sensible quantum version of self-attention. As a result, QSANN is\neffective and scalable on larger data sets and has the desirable property of\nbeing implementable on near-term quantum devices. In particular, our QSANN\noutperforms the best existing QNLP model based on syntactic analysis as well as\na simple classical self-attention neural network in numerical experiments of\ntext classification tasks on public data sets. We further show that our method\nexhibits robustness to low-level quantum noises and showcases resilience to\nquantum neural network architectures.",
          "link": "http://arxiv.org/abs/2205.05625",
          "publishedOn": "2023-09-30T00:41:30.304Z",
          "wordCount": null,
          "title": "Quantum Self-Attention Neural Networks for Text Classification. (arXiv:2205.05625v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scafarto_G/0/1/0/all/0/1\">Gregory Scafarto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciortan_M/0/1/0/all/0/1\">Madalina Ciortan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tihon_S/0/1/0/all/0/1\">Simon Tihon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferre_Q/0/1/0/all/0/1\">Quentin Ferre</a>",
          "description": "Unsupervised learning allows us to leverage unlabelled data, which has become\nabundantly available, and to create embeddings that are usable on a variety of\ndownstream tasks. However, the typical lack of interpretability of unsupervised\nrepresentation learning has become a limiting factor with regard to recent\ntransparent-AI regulations. In this paper, we study graph representation\nlearning and we show that data augmentation that preserves semantics can be\nlearned and used to produce interpretations. Our framework, which we named\nINGENIOUS, creates inherently interpretable embeddings and eliminates the need\nfor costly additional post-hoc analysis. We also introduce additional metrics\naddressing the lack of formalism and metrics in the understudied area of\nunsupervised-representation learning interpretability. Our results are\nsupported by an experimental study applied to both graph-level and node-level\ntasks and show that interpretable embeddings provide state-of-the-art\nperformance on subsequent downstream tasks.",
          "link": "http://arxiv.org/abs/2309.16564",
          "publishedOn": "2023-09-30T00:41:30.303Z",
          "wordCount": null,
          "title": "Augment to Interpret: Unsupervised and Inherently Interpretable Graph Embeddings. (arXiv:2309.16564v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bazaga_A/0/1/0/all/0/1\">Adri&#xe1;n Bazaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micklem_G/0/1/0/all/0/1\">Gos Micklem</a>",
          "description": "Unsupervised fact verification aims to verify a claim using evidence from a\ntrustworthy knowledge base without any kind of data annotation. To address this\nchallenge, algorithms must produce features for every claim that are both\nsemantically meaningful, and compact enough to find a semantic alignment with\nthe source information. In contrast to previous work, which tackled the\nalignment problem by learning over annotated corpora of claims and their\ncorresponding labels, we propose SFAVEL (Self-supervised Fact Verification via\nLanguage Model Distillation), a novel unsupervised framework that leverages\npre-trained language models to distil self-supervised features into\nhigh-quality claim-fact alignments without the need for annotations. This is\nenabled by a novel contrastive loss function that encourages features to attain\nhigh-quality claim and evidence alignments whilst preserving the semantic\nrelationships across the corpora. Notably, we present results that achieve a\nnew state-of-the-art on the standard FEVER fact verification benchmark (+8%\naccuracy) with linear evaluation.",
          "link": "http://arxiv.org/abs/2309.16540",
          "publishedOn": "2023-09-30T00:41:30.302Z",
          "wordCount": null,
          "title": "Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pedersen_C/0/1/0/all/0/1\">Christian Pedersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tesileanu_T/0/1/0/all/0/1\">Tiberiu Tesileanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tinghui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golkar_S/0/1/0/all/0/1\">Siavash Golkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cranmer_M/0/1/0/all/0/1\">Miles Cranmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_S/0/1/0/all/0/1\">Shirley Ho</a>",
          "description": "In, Elmarakeby et al., \"Biologically informed deep neural network for\nprostate cancer discovery\", a feedforward neural network with biologically\ninformed, sparse connections (P-NET) was presented to model the state of\nprostate cancer. We verified the reproducibility of the study conducted by\nElmarakeby et al., using both their original codebase, and our own\nre-implementation using more up-to-date libraries. We quantified the\ncontribution of network sparsification by Reactome biological pathways, and\nconfirmed its importance to P-NET's superior performance. Furthermore, we\nexplored alternative neural architectures and approaches to incorporating\nbiological information into the networks. We experimented with three types of\ngraph neural networks on the same training data, and investigated the clinical\nprediction agreement between different models. Our analyses demonstrated that\ndeep neural networks with distinct architectures make incorrect predictions for\nindividual patient that are persistent across different initializations of a\nspecific neural architecture. This suggests that different neural architectures\nare sensitive to different aspects of the data, an important yet under-explored\nchallenge for clinical prediction tasks.",
          "link": "http://arxiv.org/abs/2309.16645",
          "publishedOn": "2023-09-30T00:41:30.296Z",
          "wordCount": null,
          "title": "Reusability report: Prostate cancer stratification with diverse biologically-informed neural architectures. (arXiv:2309.16645v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Basu_C/0/1/0/all/0/1\">Chumki Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_H/0/1/0/all/0/1\">Himanshu Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McIntosh_A/0/1/0/all/0/1\">Allen McIntosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sablak_S/0/1/0/all/0/1\">Sezai Sablak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wullert_J/0/1/0/all/0/1\">John R. Wullert II</a>",
          "description": "The onset of the COVID-19 pandemic accentuated the need for access to\nbiomedical literature to answer timely and disease-specific questions. During\nthe early days of the pandemic, one of the biggest challenges we faced was the\nlack of peer-reviewed biomedical articles on COVID-19 that could be used to\ntrain machine learning models for question answering (QA). In this paper, we\nexplore the roles weak supervision and data augmentation play in training deep\nneural network QA models. First, we investigate whether labels generated\nautomatically from the structured abstracts of scholarly papers using an\ninformation retrieval algorithm, BM25, provide a weak supervision signal to\ntrain an extractive QA model. We also curate new QA pairs using information\nretrieval techniques, guided by the clinicaltrials.gov schema and the\nstructured abstracts of articles, in the absence of annotated data from\nbiomedical domain experts. Furthermore, we explore augmenting the training data\nof a deep neural network model with linguistic features from external sources\nsuch as lexical databases to account for variations in word morphology and\nmeaning. To better utilize our training data, we apply curriculum learning to\ndomain adaptation, fine-tuning our QA model in stages based on characteristics\nof the QA pairs. We evaluate our methods in the context of QA models at the\ncore of a system to answer questions about COVID-19.",
          "link": "http://arxiv.org/abs/2309.16175",
          "publishedOn": "2023-09-30T00:41:30.295Z",
          "wordCount": null,
          "title": "Using Weak Supervision and Data Augmentation in Question Answering. (arXiv:2309.16175v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Habineza_T/0/1/0/all/0/1\">Theogene Habineza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Ant&#xf4;nio H. Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gedon_D/0/1/0/all/0/1\">Daniel Gedon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behar_J/0/1/0/all/0/1\">Joachim A. Behar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Antonio Luiz P. Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1\">Thomas B. Sch&#xf6;n</a>",
          "description": "Background: Atrial fibrillation (AF) is one of the most common cardiac\narrhythmias that affects millions of people each year worldwide and it is\nclosely linked to increased risk of cardiovascular diseases such as stroke and\nheart failure. Machine learning methods have shown promising results in\nevaluating the risk of developing atrial fibrillation from the\nelectrocardiogram. We aim to develop and evaluate one such algorithm on a large\nCODE dataset collected in Brazil.\n\nResults: The deep neural network model identified patients without indication\nof AF in the presented ECG but who will develop AF in the future with an AUC\nscore of 0.845. From our survival model, we obtain that patients in the\nhigh-risk group (i.e. with the probability of a future AF case being greater\nthan 0.7) are 50% more likely to develop AF within 40 weeks, while patients\nbelonging to the minimal-risk group (i.e. with the probability of a future AF\ncase being less than or equal to 0.1) have more than 85% chance of remaining AF\nfree up until after seven years.\n\nConclusion: We developed and validated a model for AF risk prediction. If\napplied in clinical practice, the model possesses the potential of providing\nvaluable and useful information in decision-making and patient management\nprocesses.",
          "link": "http://arxiv.org/abs/2309.16335",
          "publishedOn": "2023-09-30T00:41:30.294Z",
          "wordCount": null,
          "title": "End-to-end Risk Prediction of Atrial Fibrillation from the 12-Lead ECG by Deep Neural Networks. (arXiv:2309.16335v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhongtao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haiteng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yunzhe Liu</a>",
          "description": "Decoding memory content from brain activity during sleep has long been a goal\nin neuroscience. While spontaneous reactivation of memories during sleep in\nrodents is known to support memory consolidation and offline learning,\ncapturing memory replay in humans is challenging due to the absence of\nwell-annotated sleep datasets and the substantial differences in neural\npatterns between wakefulness and sleep. To address these challenges, we\ndesigned a novel cognitive neuroscience experiment and collected a\ncomprehensive, well-annotated electroencephalography (EEG) dataset from 52\nsubjects during both wakefulness and sleep. Leveraging this benchmark dataset,\nwe developed the Universal Sleep Decoder (USD) to align neural representations\nbetween wakefulness and sleep across subjects. Our model achieves up to 16.6%\ntop-1 zero-shot accuracy on unseen subjects, comparable to decoding\nperformances using individual sleep data. Furthermore, fine-tuning USD on test\nsubjects enhances decoding accuracy to 25.9% top-1 accuracy, a substantial\nimprovement over the baseline chance of 6.7%. Model comparison and ablation\nanalyses reveal that our design choices, including the use of (i) an additional\ncontrastive objective to integrate awake and sleep neural signals and (ii) the\npretrain-finetune paradigm to incorporate different subjects, significantly\ncontribute to these performances. Collectively, our findings and methodologies\nrepresent a significant advancement in the field of sleep decoding.",
          "link": "http://arxiv.org/abs/2309.16457",
          "publishedOn": "2023-09-30T00:41:30.294Z",
          "wordCount": null,
          "title": "Universal Sleep Decoder: Aligning awake and sleep neural representation across subjects. (arXiv:2309.16457v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16114",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akins_S/0/1/0/all/0/1\">Sapphira Akins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Frances Zhu</a>",
          "description": "Robots with increasing autonomy progress our space exploration capabilities,\nparticularly for in-situ exploration and sampling to stand in for human\nexplorers. Currently, humans drive robots to meet scientific objectives, but\ndepending on the robot's location, the exchange of information and driving\ncommands between the human operator and robot may cause undue delays in mission\nfulfillment. An autonomous robot encoded with a scientific objective and an\nexploration strategy incurs no communication delays and can fulfill missions\nmore quickly. Active learning algorithms offer this capability of intelligent\nexploration, but the underlying model structure varies the performance of the\nactive learning algorithm in accurately forming an understanding of the\nenvironment. In this paper, we investigate the performance differences between\nactive learning algorithms driven by Gaussian processes or Bayesian neural\nnetworks for exploration strategies encoded on agents that are constrained in\ntheir trajectories, like planetary surface rovers. These two active learning\nstrategies were tested in a simulation environment against science-blind\nstrategies to predict the spatial distribution of a variable of interest along\nmultiple datasets. The performance metrics of interest are model accuracy in\nroot mean squared (RMS) error, training time, model convergence, total distance\ntraveled until convergence, and total samples until convergence. Active\nlearning strategies encoded with Gaussian processes require less computation to\ntrain, converge to an accurate model more quickly, and propose trajectories of\nshorter distance, except in a few complex environments in which Bayesian neural\nnetworks achieve a more accurate model in the large data regime due to their\nmore expressive functional bases. The paper concludes with advice on when and\nhow to implement either exploration strategy for future space missions.",
          "link": "http://arxiv.org/abs/2309.16114",
          "publishedOn": "2023-09-30T00:41:30.293Z",
          "wordCount": null,
          "title": "Comparing Active Learning Performance Driven by Gaussian Processes or Bayesian Neural Networks for Constrained Trajectory Exploration. (arXiv:2309.16114v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karimzadeh_M/0/1/0/all/0/1\">Mohammad Karimzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakanski_A/0/1/0/all/0/1\">Aleksandar Vakanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Fei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinchang Zhang</a>",
          "description": "Additive manufacturing has revolutionized the manufacturing of complex parts\nby enabling direct material joining and offers several advantages such as\ncost-effective manufacturing of complex parts, reducing manufacturing waste,\nand opening new possibilities for manufacturing automation. One group of\nmaterials for which additive manufacturing holds great potential for enhancing\ncomponent performance and properties is Functionally Graded Materials (FGMs).\nFGMs are advanced composite materials that exhibit smoothly varying properties\nmaking them desirable for applications in aerospace, automobile, biomedical,\nand defense industries. Such composition differs from traditional composite\nmaterials, since the location-dependent composition changes gradually in FGMs,\nleading to enhanced properties. Recently, machine learning techniques have\nemerged as a promising means for fabrication of FGMs through optimizing\nprocessing parameters, improving product quality, and detecting manufacturing\ndefects. This paper first provides a brief literature review of works related\nto FGM fabrication, followed by reviewing works on employing machine learning\nin additive manufacturing, Afterward, we provide an overview of published works\nin the literature related to the application of machine learning methods in\nDirected Energy Deposition and for fabrication of FGMs.",
          "link": "http://arxiv.org/abs/2309.16571",
          "publishedOn": "2023-09-30T00:41:30.293Z",
          "wordCount": null,
          "title": "Review of Machine Learning Methods for Additive Manufacturing of Functionally Graded Materials. (arXiv:2309.16571v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16338",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jiashi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Changwu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Ming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Shin Hwei Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1\">Xin Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xuetao Wei</a>",
          "description": "Recent advances in federated learning (FL) enable collaborative training of\nmachine learning (ML) models from large-scale and widely dispersed clients\nwhile protecting their privacy. However, when different clients' datasets are\nheterogeneous, traditional FL mechanisms produce a global model that does not\nadequately represent the poorer clients with limited data resources, resulting\nin lower accuracy and higher bias on their local data. According to the Matthew\neffect, which describes how the advantaged gain more advantage and the\ndisadvantaged lose more over time, deploying such a global model in client\napplications may worsen the resource disparity among the clients and harm the\nprinciples of social welfare and fairness. To mitigate the Matthew effect, we\npropose Egalitarian Fairness Federated Learning (EFFL), where egalitarian\nfairness refers to the global model learned from FL has: (1) equal accuracy\namong clients; (2) equal decision bias among clients. Besides achieving\negalitarian fairness among the clients, EFFL also aims for performance\noptimality, minimizing the empirical risk loss and the bias for each client;\nboth are essential for any ML model training, whether centralized or\ndecentralized. We formulate EFFL as a constrained multi-constrained\nmulti-objectives optimization (MCMOO) problem, with the decision bias and\negalitarian fairness as constraints and the minimization of the empirical risk\nlosses on all clients as multiple objectives to be optimized. We propose a\ngradient-based three-stage algorithm to obtain the Pareto optimal solutions\nwithin the constraint space. Extensive experiments demonstrate that EFFL\noutperforms other state-of-the-art FL algorithms in achieving a\nhigh-performance global model with enhanced egalitarian fairness among all\nclients.",
          "link": "http://arxiv.org/abs/2309.16338",
          "publishedOn": "2023-09-30T00:41:30.291Z",
          "wordCount": null,
          "title": "EFFL: Egalitarian Fairness in Federated Learning for Mitigating Matthew Effect. (arXiv:2309.16338v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1\">Xubo Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hanyang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siriya_S/0/1/0/all/0/1\">Seth Siriya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1\">Ye Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mo Chen</a>",
          "description": "We present task-oriented Koopman-based control that utilizes end-to-end\nreinforcement learning and contrastive encoder to simultaneously learn the\nKoopman latent embedding, operator and associated linear controller within an\niterative loop. By prioritizing the task cost as main objective for controller\nlearning, we reduce the reliance of controller design on a well-identified\nmodel, which extends Koopman control beyond low-dimensional systems to\nhigh-dimensional, complex nonlinear systems, including pixel-based scenarios.",
          "link": "http://arxiv.org/abs/2309.16077",
          "publishedOn": "2023-09-30T00:41:30.288Z",
          "wordCount": null,
          "title": "Task-Oriented Koopman-Based Control with Contrastive Encoder. (arXiv:2309.16077v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizmalayeri_M/0/1/0/all/0/1\">Mohammad Azizmalayeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abu_Hanna_A/0/1/0/all/0/1\">Ameen Abu-Hanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cina_G/0/1/0/all/0/1\">Giovanni Cin&#xe1;</a>",
          "description": "Despite their success, Machine Learning (ML) models do not generalize\neffectively to data not originating from the training distribution. To reliably\nemploy ML models in real-world healthcare systems and avoid inaccurate\npredictions on out-of-distribution (OOD) data, it is crucial to detect OOD\nsamples. Numerous OOD detection approaches have been suggested in other fields\n- especially in computer vision - but it remains unclear whether the challenge\nis resolved when dealing with medical tabular data. To answer this pressing\nneed, we propose an extensive reproducible benchmark to compare different\nmethods across a suite of tests including both near and far OODs. Our benchmark\nleverages the latest versions of eICU and MIMIC-IV, two public datasets\nencompassing tens of thousands of ICU patients in several hospitals. We\nconsider a wide array of density-based methods and SOTA post-hoc detectors\nacross diverse predictive architectures, including MLP, ResNet, and\nTransformer. Our findings show that i) the problem appears to be solved for\nfar-OODs, but remains open for near-OODs; ii) post-hoc methods alone perform\npoorly, but improve substantially when coupled with distance-based mechanisms;\niii) the transformer architecture is far less overconfident compared to MLP and\nResNet.",
          "link": "http://arxiv.org/abs/2309.16220",
          "publishedOn": "2023-09-30T00:41:30.285Z",
          "wordCount": null,
          "title": "Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection in Medical Tabular Data. (arXiv:2309.16220v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16115",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garipov_T/0/1/0/all/0/1\">Timur Garipov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peuter_S/0/1/0/all/0/1\">Sebastiaan De Peuter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Ge Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_V/0/1/0/all/0/1\">Vikas Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi Jaakkola</a>",
          "description": "High training costs of generative models and the need to fine-tune them for\nspecific tasks have created a strong interest in model reuse and composition. A\nkey challenge in composing iterative generative processes, such as GFlowNets\nand diffusion models, is that to realize the desired target distribution, all\nsteps of the generative process need to be coordinated, and satisfy delicate\nbalance conditions. In this work, we propose Compositional Sculpting: a general\napproach for defining compositions of iterative generative processes. We then\nintroduce a method for sampling from these compositions built on classifier\nguidance. We showcase ways to accomplish compositional sculpting in both\nGFlowNets and diffusion models. We highlight two binary operations\n$\\unicode{x2014}$ the harmonic mean ($p_1 \\otimes p_2$) and the contrast ($p_1\n\\unicode{x25D1}\\,p_2$) between pairs, and the generalization of these\noperations to multiple component distributions. We offer empirical results on\nimage and molecular generation tasks.",
          "link": "http://arxiv.org/abs/2309.16115",
          "publishedOn": "2023-09-30T00:41:30.282Z",
          "wordCount": 649,
          "title": "Compositional Sculpting of Iterative Generative Processes. (arXiv:2309.16115v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Figueiredo_F/0/1/0/all/0/1\">Flavio Figueiredo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandes_J/0/1/0/all/0/1\">Jos&#xe9; Geraldo Fernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1\">Jackson Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assuncao_R/0/1/0/all/0/1\">Renato M. Assun&#xe7;&#xe3;o</a>",
          "description": "Copulas are a powerful statistical tool that captures dependencies across\ndata dimensions. When applying Copulas, we can estimate multivariate\ndistribution functions by initially estimating independent marginals, an easy\ntask, and then a single copulating function, $C$, to connect the marginals, a\nhard task. For two-dimensional data, a copula is a two-increasing function of\nthe form $C: (u,v)\\in \\mathbf{I}^2 \\rightarrow \\mathbf{I}$, where $\\mathbf{I} =\n[0, 1]$. In this paper, we show how Neural Networks (NNs) can approximate any\ntwo-dimensional copula non-parametrically. Our approach, denoted as 2-Cats, is\ninspired by the Physics-Informed Neural Networks and Sobolev Training\nliterature. Not only do we show that we can estimate the output of a 2d Copula\nbetter than the state-of-the-art, our approach is non-parametric and respects\nthe mathematical properties of a Copula $C$.",
          "link": "http://arxiv.org/abs/2309.16391",
          "publishedOn": "2023-09-30T00:41:30.274Z",
          "wordCount": null,
          "title": "Differential 2D Copula Approximating Transforms via Sobolev Training: 2-Cats Networks. (arXiv:2309.16391v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toshev_A/0/1/0/all/0/1\">Artur P. Toshev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galletti_G/0/1/0/all/0/1\">Gianluca Galletti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fritz_F/0/1/0/all/0/1\">Fabian Fritz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adami_S/0/1/0/all/0/1\">Stefan Adami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adams_N/0/1/0/all/0/1\">Nikolaus A. Adams</a>",
          "description": "Machine learning has been successfully applied to grid-based PDE modeling in\nvarious scientific applications. However, learned PDE solvers based on\nLagrangian particle discretizations, which are the preferred approach to\nproblems with free surfaces or complex physics, remain largely unexplored. We\npresent LagrangeBench, the first benchmarking suite for Lagrangian particle\nproblems, focusing on temporal coarse-graining. In particular, our contribution\nis: (a) seven new fluid mechanics datasets (four in 2D and three in 3D)\ngenerated with the Smoothed Particle Hydrodynamics (SPH) method including the\nTaylor-Green vortex, lid-driven cavity, reverse Poiseuille flow, and dam break,\neach of which includes different physics like solid wall interactions or free\nsurface, (b) efficient JAX-based API with various recent training strategies\nand neighbors search routine, and (c) JAX implementation of established Graph\nNeural Networks (GNNs) like GNS and SEGNN with baseline results. Finally, to\nmeasure the performance of learned surrogates we go beyond established position\nerrors and introduce physical metrics like kinetic energy MSE and Sinkhorn\ndistance for the particle distribution. Our codebase is available under the\nURL: https://github.com/tumaer/lagrangebench",
          "link": "http://arxiv.org/abs/2309.16342",
          "publishedOn": "2023-09-30T00:41:30.264Z",
          "wordCount": null,
          "title": "LagrangeBench: A Lagrangian Fluid Mechanics Benchmarking Suite. (arXiv:2309.16342v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xinran Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>",
          "description": "Bayesian optimization (BO) is a popular black-box function optimization\nmethod, which makes sequential decisions based on a Bayesian model, typically a\nGaussian process (GP), of the function. To ensure the quality of the model,\ntransfer learning approaches have been developed to automatically design GP\npriors by learning from observations on \"training\" functions. These training\nfunctions are typically required to have the same domain as the \"test\" function\n(black-box function to be optimized). In this paper, we introduce MPHD, a model\npre-training method on heterogeneous domains, which uses a neural net mapping\nfrom domain-specific contexts to specifications of hierarchical GPs. MPHD can\nbe seamlessly integrated with BO to transfer knowledge across heterogeneous\nsearch spaces. Our theoretical and empirical results demonstrate the validity\nof MPHD and its superior performance on challenging black-box function\noptimization tasks.",
          "link": "http://arxiv.org/abs/2309.16597",
          "publishedOn": "2023-09-30T00:41:30.263Z",
          "wordCount": null,
          "title": "Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces. (arXiv:2309.16597v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaoqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yibo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenghao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Han Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxin Chen</a>",
          "description": "The increasing capabilities of large language models (LLMs) raise\nopportunities for artificial general intelligence but concurrently amplify\nsafety concerns, such as potential misuse of AI systems, necessitating\neffective AI alignment. Reinforcement Learning from Human Feedback (RLHF) has\nemerged as a promising pathway towards AI alignment but brings forth challenges\ndue to its complexity and dependence on a separate reward model. Direct\nPreference Optimization (DPO) has been proposed as an alternative, and it\nremains equivalent to RLHF under the reverse KL regularization constraint. This\npaper presents $f$-DPO, a generalized approach to DPO by incorporating diverse\ndivergence constraints. We show that under certain $f$-divergences, including\nJensen-Shannon divergence, forward KL divergences and $\\alpha$-divergences, the\ncomplex relationship between the reward and optimal policy can also be\nsimplified by addressing the Karush-Kuhn-Tucker conditions. This eliminates the\nneed for estimating the normalizing constant in the Bradley-Terry model and\nenables a tractable mapping between the reward function and the optimal policy.\nOur approach optimizes LLMs to align with human preferences in a more efficient\nand supervised manner under a broad set of divergence constraints. Empirically,\nadopting these divergences ensures a balance between alignment performance and\ngeneration diversity. Importantly, $f$-DPO outperforms PPO-based methods in\ndivergence efficiency, and divergence constraints directly influence expected\ncalibration error (ECE).",
          "link": "http://arxiv.org/abs/2309.16240",
          "publishedOn": "2023-09-30T00:41:30.262Z",
          "wordCount": null,
          "title": "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints. (arXiv:2309.16240v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Demelius_L/0/1/0/all/0/1\">Lea Demelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kern_R/0/1/0/all/0/1\">Roman Kern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trugler_A/0/1/0/all/0/1\">Andreas Tr&#xfc;gler</a>",
          "description": "Differential Privacy has become a widely popular method for data protection\nin machine learning, especially since it allows formulating strict mathematical\nprivacy guarantees. This survey provides an overview of the state-of-the-art of\ndifferentially private centralized deep learning, thorough analyses of recent\nadvances and open problems, as well as a discussion of potential future\ndevelopments in the field. Based on a systematic literature review, the\nfollowing topics are addressed: auditing and evaluation methods for private\nmodels, improvements of privacy-utility trade-offs, protection against a broad\nrange of threats and attacks, differentially private generative models, and\nemerging application domains.",
          "link": "http://arxiv.org/abs/2309.16398",
          "publishedOn": "2023-09-30T00:41:30.259Z",
          "wordCount": null,
          "title": "Recent Advances of Differential Privacy in Centralized Deep Learning: A Systematic Survey. (arXiv:2309.16398v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ismail_Fawaz_A/0/1/0/all/0/1\">Ali Ismail-Fawaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fawaz_H/0/1/0/all/0/1\">Hassan Ismail Fawaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petitjean_F/0/1/0/all/0/1\">Fran&#xe7;ois Petitjean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devanne_M/0/1/0/all/0/1\">Maxime Devanne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_J/0/1/0/all/0/1\">Jonathan Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berretti_S/0/1/0/all/0/1\">Stefano Berretti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1\">Geoffrey I. Webb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forestier_G/0/1/0/all/0/1\">Germain Forestier</a>",
          "description": "Time series data can be found in almost every domain, ranging from the\nmedical field to manufacturing and wireless communication. Generating realistic\nand useful exemplars and prototypes is a fundamental data analysis task. In\nthis paper, we investigate a novel approach to generating realistic and useful\nexemplars and prototypes for time series data. Our approach uses a new form of\ntime series average, the ShapeDTW Barycentric Average. We therefore turn our\nattention to accurately generating time series prototypes with a novel\napproach. The existing time series prototyping approaches rely on the Dynamic\nTime Warping (DTW) similarity measure such as DTW Barycentering Average (DBA)\nand SoftDBA. These last approaches suffer from a common problem of generating\nout-of-distribution artifacts in their prototypes. This is mostly caused by the\nDTW variant used and its incapability of detecting neighborhood similarities,\ninstead it detects absolute similarities. Our proposed method, ShapeDBA, uses\nthe ShapeDTW variant of DTW, that overcomes this issue. We chose time series\nclustering, a popular form of time series analysis to evaluate the outcome of\nShapeDBA compared to the other prototyping approaches. Coupled with the k-means\nclustering algorithm, and evaluated on a total of 123 datasets from the UCR\narchive, our proposed averaging approach is able to achieve new\nstate-of-the-art results in terms of Adjusted Rand Index.",
          "link": "http://arxiv.org/abs/2309.16353",
          "publishedOn": "2023-09-30T00:41:30.257Z",
          "wordCount": null,
          "title": "ShapeDBA: Generating Effective Time Series Prototypes using ShapeDTW Barycenter Averaging. (arXiv:2309.16353v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16314",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Arbel_J/0/1/0/all/0/1\">Julyan Arbel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pitas_K/0/1/0/all/0/1\">Konstantinos Pitas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vladimirova_M/0/1/0/all/0/1\">Mariia Vladimirova</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>",
          "description": "Neural networks have achieved remarkable performance across various problem\ndomains, but their widespread applicability is hindered by inherent limitations\nsuch as overconfidence in predictions, lack of interpretability, and\nvulnerability to adversarial attacks. To address these challenges, Bayesian\nneural networks (BNNs) have emerged as a compelling extension of conventional\nneural networks, integrating uncertainty estimation into their predictive\ncapabilities.\n\nThis comprehensive primer presents a systematic introduction to the\nfundamental concepts of neural networks and Bayesian inference, elucidating\ntheir synergistic integration for the development of BNNs. The target audience\ncomprises statisticians with a potential background in Bayesian methods but\nlacking deep learning expertise, as well as machine learners proficient in deep\nneural networks but with limited exposure to Bayesian statistics. We provide an\noverview of commonly employed priors, examining their impact on model behavior\nand performance. Additionally, we delve into the practical considerations\nassociated with training and inference in BNNs.\n\nFurthermore, we explore advanced topics within the realm of BNN research,\nacknowledging the existence of ongoing debates and controversies. By offering\ninsights into cutting-edge developments, this primer not only equips\nresearchers and practitioners with a solid foundation in BNNs, but also\nilluminates the potential applications of this dynamic field. As a valuable\nresource, it fosters an understanding of BNNs and their promising prospects,\nfacilitating further advancements in the pursuit of knowledge and innovation.",
          "link": "http://arxiv.org/abs/2309.16314",
          "publishedOn": "2023-09-30T00:41:30.256Z",
          "wordCount": null,
          "title": "A Primer on Bayesian Neural Networks: Review and Debates. (arXiv:2309.16314v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16274",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bargiotas_I/0/1/0/all/0/1\">Ioannis Bargiotas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kalogeratos_A/0/1/0/all/0/1\">Argyris Kalogeratos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vayatis_N/0/1/0/all/0/1\">Nicolas Vayatis</a>",
          "description": "The standard paired-sample testing approach in the multidimensional setting\napplies multiple univariate tests on the individual features, followed by\np-value adjustments. Such an approach suffers when the data carry numerous\nfeatures. A number of studies have shown that classification accuracy can be\nseen as a proxy for two-sample testing. However, neither theoretical\nfoundations nor practical recipes have been proposed so far on how this\nstrategy could be extended to multidimensional paired-sample testing. In this\nwork, we put forward the idea that scoring functions can be produced by the\ndecision rules defined by the perpendicular bisecting hyperplanes of the line\nsegments connecting each pair of instances. Then, the optimal scoring function\ncan be obtained by the pseudomedian of those rules, which we estimate by\nextending naturally the Hodges-Lehmann estimator. We accordingly propose a\nframework of a two-step testing procedure. First, we estimate the bisecting\nhyperplanes for each pair of instances and an aggregated rule derived through\nthe Hodges-Lehmann estimator. The paired samples are scored by this aggregated\nrule to produce a unidimensional representation. Second, we perform a Wilcoxon\nsigned-rank test on the obtained representation. Our experiments indicate that\nour approach has substantial performance gains in testing accuracy compared to\nthe traditional multivariate and multiple testing, while at the same time\nestimates each feature's contribution to the final result.",
          "link": "http://arxiv.org/abs/2309.16274",
          "publishedOn": "2023-09-30T00:41:30.255Z",
          "wordCount": null,
          "title": "A framework for paired-sample hypothesis testing for high-dimensional data. (arXiv:2309.16274v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1\">Luming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_N/0/1/0/all/0/1\">Nataniel Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_Q/0/1/0/all/0/1\">Qinghao Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holynski_A/0/1/0/all/0/1\">Aleksander Holynski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1\">David E. Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hariharan_B/0/1/0/all/0/1\">Bharath Hariharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pritch_Y/0/1/0/all/0/1\">Yael Pritch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadhwa_N/0/1/0/all/0/1\">Neal Wadhwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aberman_K/0/1/0/all/0/1\">Kfir Aberman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_M/0/1/0/all/0/1\">Michael Rubinstein</a>",
          "description": "Recent advances in generative imagery have brought forth outpainting and\ninpainting models that can produce high-quality, plausible image content in\nunknown regions, but the content these models hallucinate is necessarily\ninauthentic, since the models lack sufficient context about the true scene. In\nthis work, we propose RealFill, a novel generative approach for image\ncompletion that fills in missing regions of an image with the content that\nshould have been there. RealFill is a generative inpainting model that is\npersonalized using only a few reference images of a scene. These reference\nimages do not have to be aligned with the target image, and can be taken with\ndrastically varying viewpoints, lighting conditions, camera apertures, or image\nstyles. Once personalized, RealFill is able to complete a target image with\nvisually compelling contents that are faithful to the original scene. We\nevaluate RealFill on a new image completion benchmark that covers a set of\ndiverse and challenging scenarios, and find that it outperforms existing\napproaches by a large margin. See more results on our project page:\nhttps://realfill.github.io",
          "link": "http://arxiv.org/abs/2309.16668",
          "publishedOn": "2023-09-30T00:41:30.252Z",
          "wordCount": null,
          "title": "RealFill: Reference-Driven Generation for Authentic Image Completion. (arXiv:2309.16668v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amara_K/0/1/0/all/0/1\">Kenza Amara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Assady_M/0/1/0/all/0/1\">Mennatallah El-Assady</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1\">Rex Ying</a>",
          "description": "Diverse explainability methods of graph neural networks (GNN) have recently\nbeen developed to highlight the edges and nodes in the graph that contribute\nthe most to the model predictions. However, it is not clear yet how to evaluate\nthe correctness of those explanations, whether it is from a human or a model\nperspective. One unaddressed bottleneck in the current evaluation procedure is\nthe problem of out-of-distribution explanations, whose distribution differs\nfrom those of the training data. This important issue affects existing\nevaluation metrics such as the popular faithfulness or fidelity score. In this\npaper, we show the limitations of faithfulness metrics. We propose GInX-Eval\n(Graph In-distribution eXplanation Evaluation), an evaluation procedure of\ngraph explanations that overcomes the pitfalls of faithfulness and offers new\ninsights on explainability methods. Using a retraining strategy, the GInX score\nmeasures how informative removed edges are for the model and the EdgeRank score\nevaluates if explanatory edges are correctly ordered by their importance.\nGInX-Eval verifies if ground-truth explanations are instructive to the GNN\nmodel. In addition, it shows that many popular methods, including\ngradient-based methods, produce explanations that are not better than a random\ndesignation of edges as important subgraphs, challenging the findings of\ncurrent works in the area. Results with GInX-Eval are consistent across\nmultiple datasets and align with human evaluation.",
          "link": "http://arxiv.org/abs/2309.16223",
          "publishedOn": "2023-09-30T00:41:30.249Z",
          "wordCount": null,
          "title": "GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations. (arXiv:2309.16223v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yousif_M/0/1/0/all/0/1\">Maitham G. Yousif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castro_H/0/1/0/all/0/1\">Hector J. Castro</a>",
          "description": "The COVID-19 pandemic has globally posed numerous health challenges, notably\nthe emergence of post-COVID-19 cardiovascular complications. This study\naddresses this by utilizing data-driven machine learning models to predict such\ncomplications in 352 post-COVID-19 patients from Iraq. Clinical data, including\ndemographics, comorbidities, lab results, and imaging, were collected and used\nto construct predictive models. These models, leveraging various machine\nlearning algorithms, demonstrated commendable performance in identifying\npatients at risk. Early detection through these models promises timely\ninterventions and improved outcomes. In conclusion, this research underscores\nthe potential of data-driven machine learning for predicting post-COVID-19\ncardiovascular complications, emphasizing the need for continued validation and\nresearch in diverse clinical settings.",
          "link": "http://arxiv.org/abs/2309.16059",
          "publishedOn": "2023-09-30T00:41:30.248Z",
          "wordCount": null,
          "title": "Predicting Cardiovascular Complications in Post-COVID-19 Patients Using Data-Driven Machine Learning Models. (arXiv:2309.16059v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16633",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yilei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zijian Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chongyao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Juan Helen Zhou</a>",
          "description": "In representation learning, regression has traditionally received less\nattention than classification. Directly applying representation learning\ntechniques designed for classification to regression often results in\nfragmented representations in the latent space, yielding sub-optimal\nperformance. In this paper, we argue that the potential of contrastive learning\nfor regression has been overshadowed due to the neglect of two crucial aspects:\nordinality-awareness and hardness. To address these challenges, we advocate\n\"mixup your own contrastive pairs for supervised contrastive regression\",\ninstead of relying solely on real/augmented samples. Specifically, we propose\nSupervised Contrastive Learning for Regression with Mixup (SupReMix). It takes\nanchor-inclusive mixtures (mixup of the anchor and a distinct negative sample)\nas hard negative pairs and anchor-exclusive mixtures (mixup of two distinct\nnegative samples) as hard positive pairs at the embedding level. This strategy\nformulates harder contrastive pairs by integrating richer ordinal information.\nThrough extensive experiments on six regression datasets including 2D images,\nvolumetric images, text, tabular data, and time-series signals, coupled with\ntheoretical analysis, we demonstrate that SupReMix pre-training fosters\ncontinuous ordered representations of regression data, resulting in significant\nimprovement in regression performance. Furthermore, SupReMix is superior to\nother approaches in a range of regression challenges including transfer\nlearning, imbalanced training data, and scenarios with fewer training samples.",
          "link": "http://arxiv.org/abs/2309.16633",
          "publishedOn": "2023-09-30T00:41:30.245Z",
          "wordCount": null,
          "title": "Mixup Your Own Pairs. (arXiv:2309.16633v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16155",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lingfeng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linfeng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Lifeng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baolin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1\">Haitao Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>",
          "description": "Standard practice within Reinforcement Learning from Human Feedback (RLHF)\ninvolves optimizing against a Reward Model (RM), which itself is trained to\nreflect human preferences for desirable generations. A notable subject that is\nunderstudied is the (in-)consistency of RMs -- whether they can recognize the\nsemantic changes to different prompts and appropriately adapt their reward\nassignments -- and their impact on the downstream RLHF model.\n\nIn this paper, we visit a series of research questions relevant to RM\ninconsistency: (1) How can we measure the consistency of reward models? (2) How\nconsistent are the existing RMs and how can we improve them? (3) In what ways\ndoes reward inconsistency influence the chatbots resulting from the RLHF model\ntraining?\n\nWe propose Contrast Instructions -- a benchmarking strategy for the\nconsistency of RM. Each example in Contrast Instructions features a pair of\nlexically similar instructions with different ground truth responses. A\nconsistent RM is expected to rank the corresponding instruction and response\nhigher than other combinations. We observe that current RMs trained with the\nstandard ranking objective fail miserably on Contrast Instructions compared to\naverage humans. To show that RM consistency can be improved efficiently without\nusing extra training budget, we propose two techniques ConvexDA and\nRewardFusion, which enhance reward consistency through extrapolation during the\nRM training and inference stage, respectively. We show that RLHF models trained\nwith a more consistent RM yield more useful responses, suggesting that reward\ninconsistency exhibits a trickle-down effect on the downstream RLHF process.",
          "link": "http://arxiv.org/abs/2309.16155",
          "publishedOn": "2023-09-30T00:41:30.243Z",
          "wordCount": null,
          "title": "The Trickle-down Impact of Reward (In-)consistency on RLHF. (arXiv:2309.16155v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qinghua Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1\">Shaukat Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_T/0/1/0/all/0/1\">Tao Yue</a>",
          "description": "Anomaly detection is critical to ensure the security of cyber-physical\nsystems (CPS). However, due to the increasing complexity of attacks and CPS\nthemselves, anomaly detection in CPS is becoming more and more challenging. In\nour previous work, we proposed a digital twin-based anomaly detection method,\ncalled ATTAIN, which takes advantage of both historical and real-time data of\nCPS. However, such data vary significantly in terms of difficulty. Therefore,\nsimilar to human learning processes, deep learning models (e.g., ATTAIN) can\nbenefit from an easy-to-difficult curriculum. To this end, in this paper, we\npresent a novel approach, named digitaL twin-based Anomaly deTecTion wIth\nCurriculum lEarning (LATTICE), which extends ATTAIN by introducing curriculum\nlearning to optimize its learning paradigm. LATTICE attributes each sample with\na difficulty score, before being fed into a training scheduler. The training\nscheduler samples batches of training data based on these difficulty scores\nsuch that learning from easy to difficult data can be performed. To evaluate\nLATTICE, we use five publicly available datasets collected from five real-world\nCPS testbeds. We compare LATTICE with ATTAIN and two other state-of-the-art\nanomaly detectors. Evaluation results show that LATTICE outperforms the three\nbaselines and ATTAIN by 0.906%-2.367% in terms of the F1 score. LATTICE also,\non average, reduces the training time of ATTAIN by 4.2% on the five datasets\nand is on par with the baselines in terms of detection delay time.",
          "link": "http://arxiv.org/abs/2309.15995",
          "publishedOn": "2023-09-30T00:41:30.242Z",
          "wordCount": null,
          "title": "Digital Twin-based Anomaly Detection with Curriculum Learning in Cyber-physical Systems. (arXiv:2309.15995v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16055",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yousif_M/0/1/0/all/0/1\">Maitham G. Yousif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Amran_F/0/1/0/all/0/1\">Fadhil G. Al-Amran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castro_H/0/1/0/all/0/1\">Hector J. Castro</a>",
          "description": "In this study, we leveraged machine learning techniques to identify risk\nfactors associated with post-COVID-19 mental health disorders. Our analysis,\nbased on data collected from 669 patients across various provinces in Iraq,\nyielded valuable insights. We found that age, gender, and geographical region\nof residence were significant demographic factors influencing the likelihood of\ndeveloping mental health disorders in post-COVID-19 patients. Additionally,\ncomorbidities and the severity of COVID-19 illness were important clinical\npredictors. Psychosocial factors, such as social support, coping strategies,\nand perceived stress levels, also played a substantial role. Our findings\nemphasize the complex interplay of multiple factors in the development of\nmental health disorders following COVID-19 recovery. Healthcare providers and\npolicymakers should consider these risk factors when designing targeted\ninterventions and support systems for individuals at risk. Machine\nlearning-based approaches can provide a valuable tool for predicting and\npreventing adverse mental health outcomes in post-COVID-19 patients. Further\nresearch and prospective studies are needed to validate these findings and\nenhance our understanding of the long-term psychological impact of the COVID-19\npandemic. This study contributes to the growing body of knowledge regarding the\nmental health consequences of the COVID-19 pandemic and underscores the\nimportance of a multidisciplinary approach to address the diverse needs of\nindividuals on the path to recovery. Keywords: COVID-19, mental health, risk\nfactors, machine learning, Iraq",
          "link": "http://arxiv.org/abs/2309.16055",
          "publishedOn": "2023-09-30T00:41:30.233Z",
          "wordCount": null,
          "title": "Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A Machine Learning Perspective. (arXiv:2309.16055v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1812.00029",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Panda_S/0/1/0/all/0/1\">Sambit Panda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1\">Cencheng Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>",
          "description": "Decision forests are widely used for classification and regression tasks. A\nlesser known property of tree-based methods is that one can construct a\nproximity matrix from the tree(s), and these proximity matrices are induced\nkernels. While there has been extensive research on the applications and\nproperties of kernels, there is relatively little research on kernels induced\nby decision forests. We construct Kernel Mean Embedding Random Forests (KMERF),\nwhich induce kernels from random trees and/or forests using leaf-node\nproximity. We introduce the notion of an asymptotically characteristic kernel,\nand prove that KMERF kernels are asymptotically characteristic for both\ndiscrete and continuous data. Because KMERF is data-adaptive, we suspected it\nwould outperform kernels selected a priori on finite sample data. We illustrate\nthat KMERF nearly dominates current state-of-the-art kernel-based tests across\na diverse range of high-dimensional two-sample and independence testing\nsettings. Furthermore, our forest-based approach is interpretable, and provides\nfeature importance metrics that readily distinguish important dimensions,\nunlike other high-dimensional non-parametric testing procedures. Hence, this\nwork demonstrates the decision forest-based kernel can be more powerful and\nmore interpretable than existing methods, flying in the face of conventional\nwisdom of the trade-off between the two.",
          "link": "http://arxiv.org/abs/1812.00029",
          "publishedOn": "2023-09-30T00:41:30.233Z",
          "wordCount": null,
          "title": "Learning Interpretable Characteristic Kernels via Decision Forests. (arXiv:1812.00029v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zihao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaemmaghami_B/0/1/0/all/0/1\">Benjamin Ghaemmaghami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Ashish Kumar Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_B/0/1/0/all/0/1\">Benjamin Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orshansky_L/0/1/0/all/0/1\">Leo Orshansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erez_M/0/1/0/all/0/1\">Mattan Erez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orshansky_M/0/1/0/all/0/1\">Michael Orshansky</a>",
          "description": "Modern DNN-based recommendation systems rely on training-derived embeddings\nof sparse features. Input sparsity makes obtaining high-quality embeddings for\nrarely-occurring categories harder as their representations are updated\ninfrequently. We demonstrate a training-time technique to produce superior\nembeddings via effective cross-category learning and theoretically explain its\nsurprising effectiveness. The scheme, termed the multi-layer embeddings\ntraining (MLET), trains embeddings using factorization of the embedding layer,\nwith an inner dimension higher than the target embedding dimension. For\ninference efficiency, MLET converts the trained two-layer embedding into a\nsingle-layer one thus keeping inference-time model size unchanged.\n\nEmpirical superiority of MLET is puzzling as its search space is not larger\nthan that of the single-layer embedding. The strong dependence of MLET on the\ninner dimension is even more surprising. We develop a theory that explains both\nof these behaviors by showing that MLET creates an adaptive update mechanism\nmodulated by the singular vectors of embeddings. When tested on multiple\nstate-of-the-art recommendation models for click-through rate (CTR) prediction\ntasks, MLET consistently produces better models, especially for rare items. At\nconstant model quality, MLET allows embedding dimension, and model size,\nreduction by up to 16x, and 5.8x on average, across the models.",
          "link": "http://arxiv.org/abs/2309.15881",
          "publishedOn": "2023-09-30T00:41:30.232Z",
          "wordCount": null,
          "title": "Enhancing Cross-Category Learning in Recommendation Systems with Multi-Layer Embedding Training. (arXiv:2309.15881v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16347",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Triantafyllidis_E/0/1/0/all/0/1\">Eleftherios Triantafyllidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1\">Filippos Christianos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhibin Li</a>",
          "description": "Current reinforcement learning algorithms struggle in sparse and complex\nenvironments, most notably in long-horizon manipulation tasks entailing a\nplethora of different sequences. In this work, we propose the Intrinsically\nGuided Exploration from Large Language Models (IGE-LLMs) framework. By\nleveraging LLMs as an assistive intrinsic reward, IGE-LLMs guides the\nexploratory process in reinforcement learning to address intricate long-horizon\nwith sparse rewards robotic manipulation tasks. We evaluate our framework and\nrelated intrinsic learning methods in an environment challenged with\nexploration, and a complex robotic manipulation task challenged by both\nexploration and long-horizons. Results show IGE-LLMs (i) exhibit notably higher\nperformance over related intrinsic methods and the direct use of LLMs in\ndecision-making, (ii) can be combined and complement existing learning methods\nhighlighting its modularity, (iii) are fairly insensitive to different\nintrinsic scaling parameters, and (iv) maintain robustness against increased\nlevels of uncertainty and horizons.",
          "link": "http://arxiv.org/abs/2309.16347",
          "publishedOn": "2023-09-30T00:41:30.232Z",
          "wordCount": null,
          "title": "Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic Manipulation Tasks. (arXiv:2309.16347v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hegde_S/0/1/0/all/0/1\">Shashank Hegde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhehui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1\">Gaurav S. Sukhatme</a>",
          "description": "Models with fewer parameters are necessary for the neural control of\nmemory-limited, performant robots. Finding these smaller neural network\narchitectures can be time-consuming. We propose HyperPPO, an on-policy\nreinforcement learning algorithm that utilizes graph hypernetworks to estimate\nthe weights of multiple neural architectures simultaneously. Our method\nestimates weights for networks that are much smaller than those in common-use\nnetworks yet encode highly performant policies. We obtain multiple trained\npolicies at the same time while maintaining sample efficiency and provide the\nuser the choice of picking a network architecture that satisfies their\ncomputational constraints. We show that our method scales well - more training\nresources produce faster convergence to higher-performing architectures. We\ndemonstrate that the neural policies estimated by HyperPPO are capable of\ndecentralized control of a Crazyflie2.1 quadrotor. Website:\nhttps://sites.google.com/usc.edu/hyperppo",
          "link": "http://arxiv.org/abs/2309.16663",
          "publishedOn": "2023-09-30T00:41:30.232Z",
          "wordCount": null,
          "title": "HyperPPO: A scalable method for finding small policies for robotic control. (arXiv:2309.16663v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaoqin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poursoroush_A/0/1/0/all/0/1\">Asma Poursoroush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boland_M/0/1/0/all/0/1\">Michael V. Boland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_C/0/1/0/all/0/1\">Chris Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yousefi_S/0/1/0/all/0/1\">Siamak Yousefi</a>",
          "description": "Purpose: To identify ocular hypertension (OHT) subtypes with different trends\nof visual field (VF) progression based on unsupervised machine learning and to\ndiscover factors associated with fast VF progression. Participants: A total of\n3133 eyes of 1568 ocular hypertension treatment study (OHTS) participants with\nat least five follow-up VF tests were included in the study. Methods: We used a\nlatent class mixed model (LCMM) to identify OHT subtypes using standard\nautomated perimetry (SAP) mean deviation (MD) trajectories. We characterized\nthe subtypes based on demographic, clinical, ocular, and VF factors at the\nbaseline. We then identified factors driving fast VF progression using\ngeneralized estimating equation (GEE) and justified findings qualitatively and\nquantitatively. Results: The LCMM model discovered four clusters (subtypes) of\neyes with different trajectories of MD worsening. The number of eyes in\nclusters were 794 (25%), 1675 (54%), 531 (17%) and 133 (4%). We labelled the\nclusters as Improvers, Stables, Slow progressors, and Fast progressors based on\ntheir mean of MD decline, which were 0.08, -0.06, -0.21, and -0.45 dB/year,\nrespectively. Eyes with fast VF progression had higher baseline age,\nintraocular pressure (IOP), pattern standard deviation (PSD) and refractive\nerror (RE), but lower central corneal thickness (CCT). Fast progression was\nassociated with calcium channel blockers, being male, heart disease history,\ndiabetes history, African American race, stroke history, and migraine\nheadaches.",
          "link": "http://arxiv.org/abs/2309.15867",
          "publishedOn": "2023-09-30T00:41:30.231Z",
          "wordCount": null,
          "title": "Identifying factors associated with fast visual field progression in patients with ocular hypertension based on unsupervised machine learning. (arXiv:2309.15867v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.10003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ragot_S/0/1/0/all/0/1\">S&#xe9;bastien Ragot</a>",
          "description": "This work proposes to measure the scope of a patent claim as the reciprocal\nof the self-information contained in this claim. A probability of occurrence of\nthe claim is obtained from a language model and this probability is used to\ncompute the self-information. Grounded in information theory, this approach is\nbased on the assumption that an unlikely concept is more informative than a\nusual concept, insofar as it is more surprising. In turn, the more surprising\nthe information required to defined the claim, the narrower its scope. Five\nlanguage models are considered, ranging from simplest models (each word or\ncharacter is assigned an identical probability) to intermediate models (using\naverage word or character frequencies), to a large language model (GPT2).\nInterestingly, the scope resulting from the simplest language models is\nproportional to the reciprocal of the number of words or characters involved in\nthe claim, a metric already used in previous works. Application is made to\nmultiple series of patent claims directed to distinct inventions, where each\nseries consists of claims devised to have a gradually decreasing scope. The\nperformance of the language models is assessed with respect to several ad hoc\ntests. The more sophisticated the model, the better the results. I.e., the GPT2\nprobability model outperforms models based on word and character frequencies,\nwhich themselves outdo the simplest models based on word or character counts.\nStill, the character count appears to be a more reliable indicator than the\nword count.",
          "link": "http://arxiv.org/abs/2309.10003",
          "publishedOn": "2023-09-30T00:41:30.230Z",
          "wordCount": null,
          "title": "A novel approach to measuring patent claim scope based on probabilities obtained from (large) language models. (arXiv:2309.10003v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chenfeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zehao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yixin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chamberlain_R/0/1/0/all/0/1\">Roger D. Chamberlain</a>",
          "description": "With the ever-growing popularity of Graph Neural Networks (GNNs), efficient\nGNN inference is gaining tremendous attention. Field-Programming Gate Arrays\n(FPGAs) are a promising execution platform due to their fine-grained\nparallelism, low-power consumption, reconfigurability, and concurrent\nexecution. Even better, High-Level Synthesis (HLS) tools bridge the gap between\nthe non-trivial FPGA development efforts and rapid emergence of new GNN models.\nIn this paper, we propose GNNHLS, an open-source framework to comprehensively\nevaluate GNN inference acceleration on FPGAs via HLS, containing a software\nstack for data generation and baseline deployment, and FPGA implementations of\n6 well-tuned GNN HLS kernels. We evaluate GNNHLS on 4 graph datasets with\ndistinct topologies and scales. The results show that GNNHLS achieves up to\n50.8x speedup and 423x energy reduction relative to the CPU baselines. Compared\nwith the GPU baselines, GNNHLS achieves up to 5.16x speedup and 74.5x energy\nreduction.",
          "link": "http://arxiv.org/abs/2309.16022",
          "publishedOn": "2023-09-30T00:41:30.229Z",
          "wordCount": null,
          "title": "GNNHLS: Evaluating Graph Neural Network Inference via High-Level Synthesis. (arXiv:2309.16022v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16210",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1\">Mingjin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yongkang He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_Y/0/1/0/all/0/1\">Yongyi Lu</a>",
          "description": "Abdominal multi-organ segmentation in computed tomography (CT) is crucial for\nmany clinical applications including disease detection and treatment planning.\nDeep learning methods have shown unprecedented performance in this perspective.\nHowever, it is still quite challenging to accurately segment different organs\nutilizing a single network due to the vague boundaries of organs, the complex\nbackground, and the substantially different organ size scales. In this work we\nused make transformer-based model for training. It was found through previous\nyears' competitions that basically all of the top 5 methods used CNN-based\nmethods, which is likely due to the lack of data volume that prevents\ntransformer-based methods from taking full advantage. The thousands of samples\nin this competition may enable the transformer-based model to have more\nexcellent results. The results on the public validation set also show that the\ntransformer-based model can achieve an acceptable result and inference time.",
          "link": "http://arxiv.org/abs/2309.16210",
          "publishedOn": "2023-09-30T00:41:30.229Z",
          "wordCount": null,
          "title": "Abdominal multi-organ segmentation in CT using Swinunter. (arXiv:2309.16210v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16119",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Junjie Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jiahao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yingheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuleshov_V/0/1/0/all/0/1\">Volodymyr Kuleshov</a>",
          "description": "We propose a memory-efficient finetuning algorithm for large language models\n(LLMs) that supports finetuning LLMs with 65B parameters in 3-bit or 4-bit\nprecision on as little as one 48GB GPU. Our method, modular low-rank adaptation\n(ModuLoRA), integrates any user-specified weight quantizer with finetuning via\nlow-rank adapters (LoRAs). Our approach relies on a simple\nquantization-agnostic backward pass that adaptively materializes low-precision\nLLM weights from a custom black-box quantization module. This approach enables\nfinetuning 3-bit LLMs for the first time--leveraging state-of-the-art 3-bit\nOPTQ quantization often outperforms finetuning that relies on less\nsophisticated 4-bit and 8-bit methods. In our experiments, ModuLoRA attains\ncompetitive performance on text classification, natural language infernece, and\ninstruction following tasks using significantly less memory than existing\napproaches, and we also surpass the state-of-the-art ROUGE score on a popular\nsummarization task. We release ModuLoRA together with a series of low-precision\nmodels--including the first family of 3-bit instruction following Alpaca\nLLMs--as part of LLMTOOLS, a user-friendly library for quantizing, running, and\nfinetuning LLMs on consumer GPUs.",
          "link": "http://arxiv.org/abs/2309.16119",
          "publishedOn": "2023-09-30T00:41:30.228Z",
          "wordCount": null,
          "title": "ModuLoRA: Finetuning 3-Bit LLMs on Consumer GPUs by Integrating with Modular Quantizers. (arXiv:2309.16119v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wenxuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chendi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_X/0/1/0/all/0/1\">Xueli An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xueqiang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carle_G/0/1/0/all/0/1\">Georg Carle</a>",
          "description": "Integrating native AI support into the network architecture is an essential\nobjective of 6G. Federated Learning (FL) emerges as a potential paradigm,\nfacilitating decentralized AI model training across a diverse range of devices\nunder the coordination of a central server. However, several challenges hinder\nits wide application in the 6G context, such as malicious attacks and privacy\nsnooping on local model updates, and centralization pitfalls. This work\nproposes a trusted architecture for supporting FL, which utilizes Distributed\nLedger Technology (DLT) and Graph Neural Network (GNN), including three key\nfeatures. First, a pre-processing layer employing homomorphic encryption is\nincorporated to securely aggregate local models, preserving the privacy of\nindividual models. Second, given the distributed nature and graph structure\nbetween clients and nodes in the pre-processing layer, GNN is leveraged to\nidentify abnormal local models, enhancing system security. Third, DLT is\nutilized to decentralize the system by selecting one of the candidates to\nperform the central server's functions. Additionally, DLT ensures reliable data\nmanagement by recording data exchanges in an immutable and transparent ledger.\nThe feasibility of the novel architecture is validated through simulations,\ndemonstrating improved performance in anomalous model detection and global\nmodel accuracy compared to relevant baselines.",
          "link": "http://arxiv.org/abs/2309.05525",
          "publishedOn": "2023-09-30T00:41:30.227Z",
          "wordCount": null,
          "title": "Advancing Federated Learning in 6G: A Trusted Architecture with Graph-based Analysis. (arXiv:2309.05525v3 [cs.NI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kevin Han Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orbanz_P/0/1/0/all/0/1\">Peter Orbanz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Austern_M/0/1/0/all/0/1\">Morgane Austern</a>",
          "description": "We provide results that exactly quantify how data augmentation affects the\nvariance and limiting distribution of estimates, and analyze several specific\nmodels in detail. The results confirm some observations made in machine\nlearning practice, but also lead to unexpected findings: Data augmentation may\nincrease rather than decrease the uncertainty of estimates, such as the\nempirical prediction risk. It can act as a regularizer, but fails to do so in\ncertain high-dimensional problems, and it may shift the double-descent peak of\nan empirical risk. Overall, the analysis shows that several properties data\naugmentation has been attributed with are not either true or false, but rather\ndepend on a combination of factors -- notably the data distribution, the\nproperties of the estimator, and the interplay of sample size, number of\naugmentations, and dimension. Our main theoretical tool is a limit theorem for\nfunctions of randomly transformed, high-dimensional random vectors. The proof\ndraws on work in probability on noise stability of functions of many variables.",
          "link": "http://arxiv.org/abs/2202.09134",
          "publishedOn": "2023-09-30T00:41:30.224Z",
          "wordCount": null,
          "title": "Data Augmentation in the Underparameterized and Overparameterized Regimes. (arXiv:2202.09134v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pascual_G/0/1/0/all/0/1\">Guillem Pascual</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemic_F/0/1/0/all/0/1\">Filip Lemic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delgado_C/0/1/0/all/0/1\">Carmen Delgado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_Perez_X/0/1/0/all/0/1\">Xavier Costa-Perez</a>",
          "description": "Advancements in nanotechnology and material science are paving the way toward\nnanoscale devices that combine sensing, computing, data and energy storage, and\nwireless communication. In precision medicine, these nanodevices show promise\nfor disease diagnostics, treatment, and monitoring from within the patients'\nbloodstreams. Assigning the location of a sensed biological event with the\nevent itself, which is the main proposition of flow-guided in-body nanoscale\nlocalization, would be immensely beneficial from the perspective of precision\nmedicine. The nanoscale nature of the nanodevices and the challenging\nenvironment that the bloodstream represents, result in current flow-guided\nlocalization approaches being constrained in their communication and\nenergy-related capabilities. The communication and energy constraints of the\nnanodevices result in different features of raw data for flow-guided\nlocalization, in turn affecting its performance. An analytical modeling of the\neffects of imperfect communication and constrained energy causing intermittent\noperation of the nanodevices on the raw data produced by the nanodevices would\nbe beneficial. Hence, we propose an analytical model of raw data for\nflow-guided localization, where the raw data is modeled as a function of\ncommunication and energy-related capabilities of the nanodevice. We evaluate\nthe model by comparing its output with the one obtained through the utilization\nof a simulator for objective evaluation of flow-guided localization, featuring\ncomparably higher level of realism. Our results across a number of scenarios\nand heterogeneous performance metrics indicate high similarity between the\nmodel and simulator-generated raw datasets.",
          "link": "http://arxiv.org/abs/2309.16034",
          "publishedOn": "2023-09-30T00:41:30.221Z",
          "wordCount": null,
          "title": "Analytical Modelling of Raw Data for Flow-Guided In-body Nanoscale Localization. (arXiv:2309.16034v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1\">Mingqi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zequn Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shihao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>",
          "description": "We present RLLTE: a long-term evolution, extremely modular, and open-source\nframework for reinforcement learning (RL) research and application. Beyond\ndelivering top-notch algorithm implementations, RLLTE also serves as a toolkit\nfor developing algorithms. More specifically, RLLTE decouples the RL algorithms\ncompletely from the exploitation-exploration perspective, providing a large\nnumber of components to accelerate algorithm development and evolution. In\nparticular, RLLTE is the first RL framework to build a complete and luxuriant\necosystem, which includes model training, evaluation, deployment, benchmark\nhub, and large language model (LLM)-empowered copilot. RLLTE is expected to set\nstandards for RL engineering practice and be highly stimulative for industry\nand academia.",
          "link": "http://arxiv.org/abs/2309.16382",
          "publishedOn": "2023-09-30T00:41:30.220Z",
          "wordCount": null,
          "title": "RLLTE: Long-Term Evolution Project of Reinforcement Learning. (arXiv:2309.16382v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08079",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_L/0/1/0/all/0/1\">Likun Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_X/0/1/0/all/0/1\">Xiaoyu Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wikle_C/0/1/0/all/0/1\">Christopher K. Wikle</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huser_R/0/1/0/all/0/1\">Rapha&#xeb;l Huser</a>",
          "description": "Many real-world processes have complex tail dependence structures that cannot\nbe characterized using classical Gaussian processes. More flexible spatial\nextremes models exhibit appealing extremal dependence properties but are often\nexceedingly prohibitive to fit and simulate from in high dimensions. In this\npaper, we develop a new spatial extremes model that has flexible and\nnon-stationary dependence properties, and we integrate it in the\nencoding-decoding structure of a variational autoencoder (XVAE), whose\nparameters are estimated via variational Bayes combined with deep learning. The\nXVAE can be used as a spatio-temporal emulator that characterizes the\ndistribution of potential mechanistic model output states and produces outputs\nthat have the same statistical properties as the inputs, especially in the\ntail. As an aside, our approach also provides a novel way of making fast\ninference with complex extreme-value processes. Through extensive simulation\nstudies, we show that our XVAE is substantially more time-efficient than\ntraditional Bayesian inference while also outperforming many spatial extremes\nmodels with a stationary dependence structure. To further demonstrate the\ncomputational power of the XVAE, we analyze a high-resolution satellite-derived\ndataset of sea surface temperature in the Red Sea, which includes 30 years of\ndaily measurements at 16703 grid cells. We find that the extremal dependence\nstrength is weaker in the interior of Red Sea and it has decreased slightly\nover time.",
          "link": "http://arxiv.org/abs/2307.08079",
          "publishedOn": "2023-09-30T00:41:30.216Z",
          "wordCount": null,
          "title": "Flexible and efficient spatial extremes emulation via variational autoencoders. (arXiv:2307.08079v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15128",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tushar/0/1/0/all/0/1\">Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Souvik Chakraborty</a>",
          "description": "The well-known governing physics in science and engineering is often based on\ncertain assumptions and approximations. Therefore, analyses and designs carried\nout based on these equations are also approximate. The emergence of data-driven\nmodels has, to a certain degree, addressed this challenge; however, the purely\ndata-driven models often (a) lack interpretability, (b) are data-hungry, and\n(c) do not generalize beyond the training window. Operator learning has\nrecently been proposed as a potential alternative to address the aforementioned\nchallenges; however, the challenges are still persistent. We here argue that\none of the possible solutions resides in data-physics fusion, where the\ndata-driven model is used to correct/identify the missing physics. To that end,\nwe propose a novel Differentiable Physics Augmented Wavelet Neural Operator\n(DPA-WNO). The proposed DPA-WNO blends a differentiable physics solver with the\nWavelet Neural Operator (WNO), where the role of WNO is to model the missing\nphysics. This empowers the proposed framework to exploit the capability of WNO\nto learn from data while retaining the interpretability and generalizability\nassociated with physics-based solvers. We illustrate the applicability of the\nproposed approach in solving time-dependent uncertainty quantification problems\ndue to randomness in the initial condition. Four benchmark uncertainty\nquantification and reliability analysis examples from various fields of science\nand engineering are solved using the proposed approach. The results presented\nillustrate interesting features of the proposed approach.",
          "link": "http://arxiv.org/abs/2309.15128",
          "publishedOn": "2023-09-30T00:41:30.215Z",
          "wordCount": null,
          "title": "DPA-WNO: A gray box model for a class of stochastic mechanics problem. (arXiv:2309.15128v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.16735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gyorfi_L/0/1/0/all/0/1\">L&#xe1;szl&#xf3; Gy&#xf6;rfi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linder_T/0/1/0/all/0/1\">Tam&#xe1;s Linder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walk_H/0/1/0/all/0/1\">Harro Walk</a>",
          "description": "We study the excess minimum risk in statistical inference, defined as the\ndifference between the minimum expected loss in estimating a random variable\nfrom an observed feature vector and the minimum expected loss in estimating the\nsame random variable from a transformation (statistic) of the feature vector.\nAfter characterizing lossless transformations, i.e., transformations for which\nthe excess risk is zero for all loss functions, we construct a partitioning\ntest statistic for the hypothesis that a given transformation is lossless and\nshow that for i.i.d. data the test is strongly consistent. More generally, we\ndevelop information-theoretic upper bounds on the excess risk that uniformly\nhold over fairly general classes of loss functions. Based on these bounds, we\nintroduce the notion of a delta-lossless transformation and give sufficient\nconditions for a given transformation to be universally delta-lossless.\nApplications to classification, nonparametric regression, portfolio strategies,\ninformation bottleneck, and deep learning, are also surveyed.",
          "link": "http://arxiv.org/abs/2307.16735",
          "publishedOn": "2023-09-30T00:41:30.214Z",
          "wordCount": null,
          "title": "Lossless Transformations and Excess Risk Bounds in Statistical Inference. (arXiv:2307.16735v2 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15123",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Chen_D/0/1/0/all/0/1\">Dingshuo Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_J/0/1/0/all/0/1\">Jieyu Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Du_Y/0/1/0/all/0/1\">Yuanqi Du</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Li_Z/0/1/0/all/0/1\">Zhixun Li</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wu_S/0/1/0/all/0/1\">Shu Wu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>",
          "description": "Molecular Representation Learning (MRL) has emerged as a powerful tool for\ndrug and materials discovery in a variety of tasks such as virtual screening\nand inverse design. While there has been a surge of interest in advancing\nmodel-centric techniques, the influence of both data quantity and quality on\nmolecular representations is not yet clearly understood within this field. In\nthis paper, we delve into the neural scaling behaviors of MRL from a\ndata-centric viewpoint, examining four key dimensions: (1) data modalities, (2)\ndataset splitting, (3) the role of pre-training, and (4) model capacity. Our\nempirical studies confirm a consistent power-law relationship between data\nvolume and MRL performance across these dimensions. Additionally, through\ndetailed analysis, we identify potential avenues for improving learning\nefficiency. To challenge these scaling laws, we adapt seven popular data\npruning strategies to molecular data and benchmark their performance. Our\nfindings underline the importance of data-centric MRL and highlight possible\ndirections for future research.",
          "link": "http://arxiv.org/abs/2309.15123",
          "publishedOn": "2023-09-30T00:41:30.211Z",
          "wordCount": null,
          "title": "Uncovering Neural Scaling Laws in Molecular Representation Learning. (arXiv:2309.15123v2 [physics.chem-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bauer_A/0/1/0/all/0/1\">Andr&#xe9; Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leznik_M/0/1/0/all/0/1\">Mark Leznik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stenger_M/0/1/0/all/0/1\">Michael Stenger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leppich_R/0/1/0/all/0/1\">Robert Leppich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herbst_N/0/1/0/all/0/1\">Nikolas Herbst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kounev_S/0/1/0/all/0/1\">Samuel Kounev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1\">Ian Foster</a>",
          "description": "In many areas of decision-making, forecasting is an essential pillar.\nConsequently, many different forecasting methods have been proposed. From our\nexperience, recently presented forecasting methods are computationally\nintensive, poorly automated, tailored to a particular data set, or they lack a\npredictable time-to-result. To this end, we introduce Telescope, a novel\nmachine learning-based forecasting approach that automatically retrieves\nrelevant information from a given time series and splits it into parts,\nhandling each of them separately. In contrast to deep learning methods, our\napproach doesn't require parameterization or the need to train and fit a\nmultitude of parameters. It operates with just one time series and provides\nforecasts within seconds without any additional setup. Our experiments show\nthat Telescope outperforms recent methods by providing accurate and reliable\nforecasts while making no assumptions about the analyzed time series.",
          "link": "http://arxiv.org/abs/2309.15871",
          "publishedOn": "2023-09-30T00:41:30.210Z",
          "wordCount": null,
          "title": "Telescope: An Automated Hybrid Forecasting Approach on a Level-Playing Field. (arXiv:2309.15871v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.10425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hangchen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zheng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1\">Renhe Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jiewen Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jinliang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Quanjun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xuan Song</a>",
          "description": "With the rapid development of the Intelligent Transportation System (ITS),\naccurate traffic forecasting has emerged as a critical challenge. The key\nbottleneck lies in capturing the intricate spatio-temporal traffic patterns. In\nrecent years, numerous neural networks with complicated architectures have been\nproposed to address this issue. However, the advancements in network\narchitectures have encountered diminishing performance gains. In this study, we\npresent a novel component called spatio-temporal adaptive embedding that can\nyield outstanding results with vanilla transformers. Our proposed\nSpatio-Temporal Adaptive Embedding transformer (STAEformer) achieves\nstate-of-the-art performance on five real-world traffic forecasting datasets.\nFurther experiments demonstrate that spatio-temporal adaptive embedding plays a\ncrucial role in traffic forecasting by effectively capturing intrinsic\nspatio-temporal relations and chronological information in traffic time series.",
          "link": "http://arxiv.org/abs/2308.10425",
          "publishedOn": "2023-09-30T00:41:30.204Z",
          "wordCount": null,
          "title": "STAEformer: Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting. (arXiv:2308.10425v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zijun Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_Q/0/1/0/all/0/1\">Qiujian Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jinyuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1\">Degang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasquier_T/0/1/0/all/0/1\">Thomas Pasquier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xueyuan Han</a>",
          "description": "Provenance graphs are structured audit logs that describe the history of a\nsystem's execution. Recent studies have explored a variety of techniques to\nanalyze provenance graphs for automated host intrusion detection, focusing\nparticularly on advanced persistent threats. Sifting through their design\ndocuments, we identify four common dimensions that drive the development of\nprovenance-based intrusion detection systems (PIDSes): scope (can PIDSes detect\nmodern attacks that infiltrate across application boundaries?), attack\nagnosticity (can PIDSes detect novel attacks without a priori knowledge of\nattack characteristics?), timeliness (can PIDSes efficiently monitor host\nsystems as they run?), and attack reconstruction (can PIDSes distill attack\nactivity from large provenance graphs so that sysadmins can easily understand\nand quickly respond to system intrusion?). We present KAIROS, the first PIDS\nthat simultaneously satisfies the desiderata in all four dimensions, whereas\nexisting approaches sacrifice at least one and struggle to achieve comparable\ndetection performance.\n\nKairos leverages a novel graph neural network-based encoder-decoder\narchitecture that learns the temporal evolution of a provenance graph's\nstructural changes to quantify the degree of anomalousness for each system\nevent. Then, based on this fine-grained information, Kairos reconstructs attack\nfootprints, generating compact summary graphs that accurately describe\nmalicious activity over a stream of system audit logs. Using state-of-the-art\nbenchmark datasets, we demonstrate that Kairos outperforms previous approaches.",
          "link": "http://arxiv.org/abs/2308.05034",
          "publishedOn": "2023-09-30T00:41:30.203Z",
          "wordCount": null,
          "title": "Kairos: Practical Intrusion Detection and Investigation using Whole-system Provenance. (arXiv:2308.05034v3 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.06308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michelson_J/0/1/0/all/0/1\">James Michelson</a>",
          "description": "Fair machine learning research has been primarily concerned with\nclassification tasks that result in discrimination. However, as machine\nlearning algorithms are applied in new contexts the harms and injustices that\nresult are qualitatively different than those presently studied. The existing\nresearch paradigm in machine learning which develops metrics and definitions of\nfairness cannot account for these qualitatively different types of injustice.\nOne example of this is the problem of algorithmic collusion and market\nfairness. The negative consequences of algorithmic collusion affect all\nconsumers, not only particular members of a protected class. Drawing on this\ncase study, I propose an ethical framework for researchers and practitioners in\nmachine learning seeking to develop and apply fairness metrics that extends to\nnew domains. This contribution ties the development of formal metrics of\nfairness to specifically scoped normative principles. This enables fairness\nmetrics to reflect different concerns from discrimination. I conclude with the\nlimitations of my proposal and discuss promising avenues for future research.",
          "link": "http://arxiv.org/abs/2208.06308",
          "publishedOn": "2023-09-30T00:41:30.199Z",
          "wordCount": null,
          "title": "Developing a Philosophical Framework for Fair Machine Learning: Lessons From The Case of Algorithmic Collusion. (arXiv:2208.06308v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11475",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Truong_T/0/1/0/all/0/1\">Tuyen Trung Truong</a>",
          "description": "In root finding and optimization, there are many cases where there is a\nclosed set $A$ one likes that the sequence constructed by one's favourite\nmethod will not converge to A (here, we do not assume extra properties on $A$\nsuch as being convex or connected). For example, if one wants to find roots,\nand one chooses initial points in the basin of attraction for 1 root $x^*$ (a\nfact which one may not know before hand), then one will always end up in that\nroot. In this case, one would like to have a mechanism to avoid this point\n$z^*$ in the next runs of one's algorithm.\n\nIn this paper, we propose two new methods aiming to achieve this. In the\nfirst method, we divide the cost function by an appropriate power of the\ndistance function to $A$. This idea is inspired by how one would try to find\nall roots of a function in 1 variable. In the second method, which is more\nsuitable for constrained optimization, we redefine the value of the function to\nbe a big constant on $A$. We also propose, based on this, an algorithm to\nescape the basin of attraction of a component of positive dimension to reach\nanother component. As an application, we prove a rigorous guarantee for finding\nroots of a meromorphic function of 1 complex variable in a given domain.\n\nAlong the way, we compare with main existing relevant methods in the current\nliterature. We provide several examples in various different settings to\nillustrate the usefulness of the new approach.",
          "link": "http://arxiv.org/abs/2309.11475",
          "publishedOn": "2023-09-30T00:41:30.198Z",
          "wordCount": null,
          "title": "Creating walls to avoid unwanted points in root finding and optimization. (arXiv:2309.11475v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.13752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongyan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yao Liang</a>",
          "description": "The current learning process of deep learning, regardless of any deep neural\nnetwork (DNN) architecture and/or learning algorithm used, is essentially a\nsingle resolution training. We explore multiresolution learning and show that\nmultiresolution learning can significantly improve robustness of DNN models for\nboth 1D signal and 2D signal (image) prediction problems. We demonstrate this\nimprovement in terms of both noise and adversarial robustness as well as with\nsmall training dataset size. Our results also suggest that it may not be\nnecessary to trade standard accuracy for robustness with multiresolution\nlearning, which is, interestingly, contrary to the observation obtained from\nthe traditional single resolution learning setting.",
          "link": "http://arxiv.org/abs/2309.13752",
          "publishedOn": "2023-09-30T00:41:30.196Z",
          "wordCount": null,
          "title": "Improving Robustness of Deep Convolutional Neural Networks via Multiresolution Learning. (arXiv:2309.13752v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenxuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Bowen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1\">Chris Paxton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1\">David Held</a>",
          "description": "Manipulating objects without grasping them is an essential component of human\ndexterity, referred to as non-prehensile manipulation. Non-prehensile\nmanipulation may enable more complex interactions with the objects, but also\npresents challenges in reasoning about gripper-object interactions. In this\nwork, we introduce Hybrid Actor-Critic Maps for Manipulation (HACMan), a\nreinforcement learning approach for 6D non-prehensile manipulation of objects\nusing point cloud observations. HACMan proposes a temporally-abstracted and\nspatially-grounded object-centric action representation that consists of\nselecting a contact location from the object point cloud and a set of motion\nparameters describing how the robot will move after making contact. We modify\nan existing off-policy RL algorithm to learn in this hybrid discrete-continuous\naction representation. We evaluate HACMan on a 6D object pose alignment task in\nboth simulation and in the real world. On the hardest version of our task, with\nrandomized initial poses, randomized 6D goals, and diverse object categories,\nour policy demonstrates strong generalization to unseen object categories\nwithout a performance drop, achieving an 89% success rate on unseen objects in\nsimulation and 50% success rate with zero-shot transfer in the real world.\nCompared to alternative action representations, HACMan achieves a success rate\nmore than three times higher than the best baseline. With zero-shot sim2real\ntransfer, our policy can successfully manipulate unseen objects in the real\nworld for challenging non-planar goals, using dynamic and contact-rich\nnon-prehensile skills. Videos can be found on the project website:\nhttps://hacman-2023.github.io.",
          "link": "http://arxiv.org/abs/2305.03942",
          "publishedOn": "2023-09-30T00:41:30.195Z",
          "wordCount": null,
          "title": "HACMan: Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation. (arXiv:2305.03942v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.13978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rizvee_R/0/1/0/all/0/1\">Redwan Ahmed Rizvee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Md. Mosaddek Khan</a>",
          "description": "Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to\nmodel various NP-hard combinatorial optimization problems in the form of binary\nvariables. The Hamiltonian function is often used to formulate QUBO problems\nwhere it is used as the objective function in the context of optimization.\nRecently, PI-GNN, a generic scalable framework, has been proposed to address\nthe Combinatorial Optimization (CO) problems over graphs based on a simple\nGraph Neural Network (GNN) architecture. Their novel contribution was a generic\nQUBO-formulated Hamiltonian-inspired loss function that was optimized using\nGNN. In this study, we address a crucial issue related to the aforementioned\nsetup especially observed in denser graphs. The reinforcement learning-based\nparadigm has also been widely used to address numerous CO problems. Here we\nalso formulate and empirically evaluate the compatibility of the\nQUBO-formulated Hamiltonian as the generic reward function in the Reinforcement\nLearning paradigm to directly integrate the actual node projection status\nduring training as the form of rewards. In our experiments, we observed up to\n44% improvement in the RL-based setup compared to the PI-GNN algorithm. Our\nimplementation can be found in\nhttps://github.com/rizveeredwan/learning-graph-structure.",
          "link": "http://arxiv.org/abs/2308.13978",
          "publishedOn": "2023-09-30T00:41:30.194Z",
          "wordCount": null,
          "title": "A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss Function for Combinatorial Optimization using Reinforcement Learning. (arXiv:2308.13978v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01026",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shenyang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poursafaei_F/0/1/0/all/0/1\">Farimah Poursafaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danovitch_J/0/1/0/all/0/1\">Jacob Danovitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fey_M/0/1/0/all/0/1\">Matthias Fey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weihua Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_E/0/1/0/all/0/1\">Emanuele Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1\">Jure Leskovec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1\">Guillaume Rabusseau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbany_R/0/1/0/all/0/1\">Reihaneh Rabbany</a>",
          "description": "We present the Temporal Graph Benchmark (TGB), a collection of challenging\nand diverse benchmark datasets for realistic, reproducible, and robust\nevaluation of machine learning models on temporal graphs. TGB datasets are of\nlarge scale, spanning years in duration, incorporate both node and edge-level\nprediction tasks and cover a diverse set of domains including social, trade,\ntransaction, and transportation networks. For both tasks, we design evaluation\nprotocols based on realistic use-cases. We extensively benchmark each dataset\nand find that the performance of common models can vary drastically across\ndatasets. In addition, on dynamic node property prediction tasks, we show that\nsimple methods often achieve superior performance compared to existing temporal\ngraph models. We believe that these findings open up opportunities for future\nresearch on temporal graphs. Finally, TGB provides an automated machine\nlearning pipeline for reproducible and accessible temporal graph research,\nincluding data loading, experiment setup and performance evaluation. TGB will\nbe maintained and updated on a regular basis and welcomes community feedback.\nTGB datasets, data loaders, example codes, evaluation setup, and leaderboards\nare publicly available at https://tgb.complexdatalab.com/.",
          "link": "http://arxiv.org/abs/2307.01026",
          "publishedOn": "2023-09-30T00:41:30.193Z",
          "wordCount": null,
          "title": "Temporal Graph Benchmark for Machine Learning on Temporal Graphs. (arXiv:2307.01026v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.04934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jinghan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiancheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1\">Parikshit Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuguang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gaowen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Pranay Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>",
          "description": "In response to recent data regulation requirements, machine unlearning (MU)\nhas emerged as a critical process to remove the influence of specific examples\nfrom a given model. Although exact unlearning can be achieved through complete\nmodel retraining using the remaining dataset, the associated computational\ncosts have driven the development of efficient, approximate unlearning\ntechniques. Moving beyond data-centric MU approaches, our study introduces a\nnovel model-based perspective: model sparsification via weight pruning, which\nis capable of reducing the gap between exact unlearning and approximate\nunlearning. We show in both theory and practice that model sparsity can boost\nthe multi-criteria unlearning performance of an approximate unlearner, closing\nthe approximation gap, while continuing to be efficient. This leads to a new MU\nparadigm, termed prune first, then unlearn, which infuses a sparse model prior\ninto the unlearning process. Building on this insight, we also develop a\nsparsity-aware unlearning method that utilizes sparsity regularization to\nenhance the training process of approximate unlearning. Extensive experiments\nshow that our proposals consistently benefit MU in various unlearning\nscenarios. A notable highlight is the 77% unlearning efficacy gain of\nfine-tuning (one of the simplest unlearning methods) when using sparsity-aware\nunlearning. Furthermore, we demonstrate the practical impact of our proposed MU\nmethods in addressing other machine learning challenges, such as defending\nagainst backdoor attacks and enhancing transfer learning. Codes are available\nat https://github.com/OPTML-Group/Unlearn-Sparse.",
          "link": "http://arxiv.org/abs/2304.04934",
          "publishedOn": "2023-09-30T00:41:30.192Z",
          "wordCount": null,
          "title": "Model Sparsity Can Simplify Machine Unlearning. (arXiv:2304.04934v8 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.18471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bohan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huishuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhi-Ming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>",
          "description": "We provide a simple convergence proof for AdaGrad optimizing non-convex\nobjectives under only affine noise variance and bounded smoothness assumptions.\nThe proof is essentially based on a novel auxiliary function $\\xi$ that helps\neliminate the complexity of handling the correlation between the numerator and\ndenominator of AdaGrad's update. Leveraging simple proofs, we are able to\nobtain tighter results than existing results \\citep{faw2022power} and extend\nthe analysis to several new and important cases. Specifically, for the\nover-parameterized regime, we show that AdaGrad needs only\n$\\mathcal{O}(\\frac{1}{\\varepsilon^2})$ iterations to ensure the gradient norm\nsmaller than $\\varepsilon$, which matches the rate of SGD and significantly\ntighter than existing rates $\\mathcal{O}(\\frac{1}{\\varepsilon^4})$ for AdaGrad.\nWe then discard the bounded smoothness assumption and consider a realistic\nassumption on smoothness called $(L_0,L_1)$-smooth condition, which allows\nlocal smoothness to grow with the gradient norm. Again based on the auxiliary\nfunction $\\xi$, we prove that AdaGrad succeeds in converging under\n$(L_0,L_1)$-smooth condition as long as the learning rate is lower than a\nthreshold. Interestingly, we further show that the requirement on learning rate\nunder the $(L_0,L_1)$-smooth condition is necessary via proof by contradiction,\nin contrast with the case of uniform smoothness conditions where convergence is\nguaranteed regardless of learning rate choices. Together, our analyses broaden\nthe understanding of AdaGrad and demonstrate the power of the new auxiliary\nfunction in the investigations of AdaGrad.",
          "link": "http://arxiv.org/abs/2305.18471",
          "publishedOn": "2023-09-30T00:41:30.175Z",
          "wordCount": null,
          "title": "Convergence of AdaGrad for Non-convex Objectives: Simple Proofs and Relaxed Assumptions. (arXiv:2305.18471v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lingle_L/0/1/0/all/0/1\">Lucas D. Lingle</a>",
          "description": "We introduce Transformer-VQ, a decoder-only transformer computing\nsoftmax-based dense self-attention in linear time. Transformer-VQ's efficient\nattention is enabled by vector-quantized keys and a novel caching mechanism. In\nlarge-scale experiments, Transformer-VQ is shown highly competitive in quality,\nwith strong results on Enwik8 (0.99 bpb), PG-19 (26.6 ppl), and ImageNet64\n(3.16 bpb). Code: https://github.com/transformer-vq/transformer_vq",
          "link": "http://arxiv.org/abs/2309.16354",
          "publishedOn": "2023-09-30T00:41:30.173Z",
          "wordCount": null,
          "title": "Transformer-VQ: Linear-Time Transformers via Vector Quantization. (arXiv:2309.16354v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.07403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lowy_A/0/1/0/all/0/1\">Andrew Lowy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1\">Meisam Razaviyayn</a>",
          "description": "We study differentially private (DP) stochastic optimization (SO) with loss\nfunctions whose worst-case Lipschitz parameter over all data points may be\nextremely large. To date, the vast majority of work on DP SO assumes that the\nloss is uniformly Lipschitz continuous over data (i.e. stochastic gradients are\nuniformly bounded over all data points). While this assumption is convenient,\nit often leads to pessimistic excess risk bounds. In many practical problems,\nthe worst-case (uniform) Lipschitz parameter of the loss over all data points\nmay be extremely large due to outliers. In such cases, the error bounds for DP\nSO, which scale with the worst-case Lipschitz parameter of the loss, are\nvacuous. To address these limitations, this work provides near-optimal excess\nrisk bounds that do not depend on the uniform Lipschitz parameter of the loss.\nBuilding on a recent line of work (Wang et al., 2020; Kamath et al., 2022), we\nassume that stochastic gradients have bounded $k$-th order moments for some $k\n\\geq 2$. Compared with works on uniformly Lipschitz DP SO, our excess risk\nscales with the $k$-th moment bound instead of the uniform Lipschitz parameter\nof the loss, allowing for significantly faster rates in the presence of\noutliers and/or heavy-tailed data. For convex and strongly convex loss\nfunctions, we provide the first asymptotically optimal excess risk bounds (up\nto a logarithmic factor). In contrast to (Wang et al., 2020; Kamath et al.,\n2022), our bounds do not require the loss function to be differentiable/smooth.\nWe also devise a linear-time algorithm for smooth losses that has excess risk\nthat is tight in certain practical parameter regimes. Additionally, our work is\nthe first to address non-convex non-uniformly Lipschitz loss functions\nsatisfying the Proximal-PL inequality; this covers some practical machine\nlearning models. Our Proximal-PL algorithm has near-optimal excess risk.",
          "link": "http://arxiv.org/abs/2209.07403",
          "publishedOn": "2023-09-30T00:41:30.171Z",
          "wordCount": null,
          "title": "Private Stochastic Optimization With Large Worst-Case Lipschitz Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses. (arXiv:2209.07403v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16912",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1\">Wei Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weijia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min-Ling Zhang</a>",
          "description": "In many real-world tasks, the concerned objects can be represented as a\nmulti-instance bag associated with a candidate label set, which consists of one\nground-truth label and several false positive labels. Multi-instance\npartial-label learning (MIPL) is a learning paradigm to deal with such tasks\nand has achieved favorable performances. Existing MIPL approach follows the\ninstance-space paradigm by assigning augmented candidate label sets of bags to\neach instance and aggregating bag-level labels from instance-level labels.\nHowever, this scheme may be suboptimal as global bag-level information is\nignored and the predicted labels of bags are sensitive to predictions of\nnegative instances. In this paper, we study an alternative scheme where a\nmulti-instance bag is embedded into a single vector representation.\nAccordingly, an intuitive algorithm named DEMIPL, i.e., Disambiguated attention\nEmbedding for Multi-Instance Partial-Label learning, is proposed. DEMIPL\nemploys a disambiguation attention mechanism to aggregate a multi-instance bag\ninto a single vector representation, followed by a momentum-based\ndisambiguation strategy to identify the ground-truth label from the candidate\nlabel set. Furthermore, we introduce a real-world MIPL dataset for colorectal\ncancer classification. Experimental results on benchmark and real-world\ndatasets validate the superiority of DEMIPL against the compared MIPL and\npartial-label learning approaches.",
          "link": "http://arxiv.org/abs/2305.16912",
          "publishedOn": "2023-09-30T00:41:30.170Z",
          "wordCount": null,
          "title": "Disambiguated Attention Embedding for Multi-Instance Partial-Label Learning. (arXiv:2305.16912v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.09916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Rachel Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_R/0/1/0/all/0/1\">Rohan Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yixiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hindy_A/0/1/0/all/0/1\">Ali Hindy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shengjia Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1\">Silvio Savarese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmerling_E/0/1/0/all/0/1\">Edward Schmerling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>",
          "description": "When deploying modern machine learning-enabled robotic systems in high-stakes\napplications, detecting distribution shift is critical. However, most existing\nmethods for detecting distribution shift are not well-suited to robotics\nsettings, where data often arrives in a streaming fashion and may be very\nhigh-dimensional. In this work, we present an online method for detecting\ndistribution shift with guarantees on the false positive rate - i.e., when\nthere is no distribution shift, our system is very unlikely (with probability\n$< \\epsilon$) to falsely issue an alert; any alerts that are issued should\ntherefore be heeded. Our method is specifically designed for efficient\ndetection even with high dimensional data, and it empirically achieves up to\n11x faster detection on realistic robotics settings compared to prior work\nwhile maintaining a low false negative rate in practice (whenever there is a\ndistribution shift in our experiments, our method indeed emits an alert). We\ndemonstrate our approach in both simulation and hardware for a visual servoing\ntask, and show that our method indeed issues an alert before a failure occurs.",
          "link": "http://arxiv.org/abs/2211.09916",
          "publishedOn": "2023-09-30T00:41:30.169Z",
          "wordCount": null,
          "title": "Online Distribution Shift Detection via Recency Prediction. (arXiv:2211.09916v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.11562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1\">A. Feder Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Katherine Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choksi_M/0/1/0/all/0/1\">Madiha Choksi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barocas_S/0/1/0/all/0/1\">Solon Barocas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grimmelmann_J/0/1/0/all/0/1\">James Grimmelmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1\">Jon Kleinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1\">Siddhartha Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Baobao Zhang</a>",
          "description": "Variance in predictions across different trained models is a significant,\nunder-explored source of error in fair classification. In practice, the\nvariance on some data examples is so large that decisions can be effectively\narbitrary. To investigate this problem, we take an experimental approach and\nmake four overarching contributions: We 1) Define a metric called\nself-consistency, derived from variance, which we use as a proxy for measuring\nand reducing arbitrariness; 2) Develop an ensembling algorithm that abstains\nfrom classification when a prediction would be arbitrary; 3) Conduct the\nlargest to-date empirical study of the role of variance (vis-a-vis\nself-consistency and arbitrariness) in fair classification; and, 4) Release a\ntoolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily\nusable for future research. Altogether, our experiments reveal shocking\ninsights about the reliability of conclusions on benchmark datasets. Most\nfairness classification benchmarks are close-to-fair when taking into account\nthe amount of arbitrariness present in predictions -- before we even try to\napply common fairness interventions. This finding calls into question the\npractical utility of common algorithmic fairness methods, and in turn suggests\nthat we should fundamentally reconsider how we choose to measure fairness in\nmachine learning.",
          "link": "http://arxiv.org/abs/2301.11562",
          "publishedOn": "2023-09-30T00:41:30.165Z",
          "wordCount": null,
          "title": "Is My Prediction Arbitrary? Confounding Effects of Variance in Fair Classification. (arXiv:2301.11562v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jothishwaran_C/0/1/0/all/0/1\">C. A. Jothishwaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_B/0/1/0/all/0/1\">Biplav Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_J/0/1/0/all/0/1\">Jitin Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangopadhyay_S/0/1/0/all/0/1\">Sugata Gangopadhyay</a>",
          "description": "The logical analysis of data, LAD, is a technique that yields two-class\nclassifiers based on Boolean functions having disjunctive normal form (DNF)\nrepresentation. Although LAD algorithms employ optimization techniques, the\nresulting binary classifiers or binary rules do not lead to overfitting. We\npropose a theoretical justification for the absence of overfitting by\nestimating the Vapnik-Chervonenkis dimension (VC dimension) for LAD models\nwhere hypothesis sets consist of DNFs with a small number of cubic monomials.\nWe illustrate and confirm our observations empirically.",
          "link": "http://arxiv.org/abs/2309.16630",
          "publishedOn": "2023-09-30T00:41:30.164Z",
          "wordCount": null,
          "title": "On Learning with LAD. (arXiv:2309.16630v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vidhyadhiraja_A/0/1/0/all/0/1\">Advika Vidhyadhiraja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiagarajan_A/0/1/0/all/0/1\">Arun Pa Thiagarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Shang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1\">Venkat Viswanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramsundar_B/0/1/0/all/0/1\">Bharath Ramsundar</a>",
          "description": "Learning exchange correlation functionals, used in quantum chemistry\ncalculations, from data has become increasingly important in recent years, but\ntraining such a functional requires sophisticated software infrastructure. For\nthis reason, we build open source infrastructure to train neural exchange\ncorrelation functionals. We aim to standardize the processing pipeline by\nadapting state-of-the-art techniques from work done by multiple groups. We have\nopen sourced the model in the DeepChem library to provide a platform for\nadditional research on differentiable quantum chemistry methods.",
          "link": "http://arxiv.org/abs/2309.15985",
          "publishedOn": "2023-09-30T00:41:30.163Z",
          "wordCount": null,
          "title": "Open Source Infrastructure for Differentiable Density Functional Theory. (arXiv:2309.15985v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.16296",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popordanoska_T/0/1/0/all/0/1\">Teodora Popordanoska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertels_J/0/1/0/all/0/1\">Jeroen Bertels</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemmens_R/0/1/0/all/0/1\">Robin Lemmens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blaschko_M/0/1/0/all/0/1\">Matthew B. Blaschko</a>",
          "description": "The soft Dice loss (SDL) has taken a pivotal role in numerous automated\nsegmentation pipelines in the medical imaging community. Over the last years,\nsome reasons behind its superior functioning have been uncovered and further\noptimizations have been explored. However, there is currently no implementation\nthat supports its direct utilization in scenarios involving soft labels. Hence,\na synergy between the use of SDL and research leveraging the use of soft\nlabels, also in the context of model calibration, is still missing. In this\nwork, we introduce Dice semimetric losses (DMLs), which (i) are by design\nidentical to SDL in a standard setting with hard labels, but (ii) can be\nemployed in settings with soft labels. Our experiments on the public QUBIQ,\nLiTS and KiTS benchmarks confirm the potential synergy of DMLs with soft labels\n(e.g.\\ averaging, label smoothing, and knowledge distillation) over hard labels\n(e.g.\\ majority voting and random selection). As a result, we obtain superior\nDice scores and model calibration, which supports the wider adoption of DMLs in\npractice. The code is available at\n\\href{https://github.com/zifuwanggg/JDTLosses}{https://github.com/zifuwanggg/JDTLosses}.",
          "link": "http://arxiv.org/abs/2303.16296",
          "publishedOn": "2023-09-30T00:41:30.161Z",
          "wordCount": null,
          "title": "Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels. (arXiv:2303.16296v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12586",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Rupe_A/0/1/0/all/0/1\">Adam Rupe</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kashinath_K/0/1/0/all/0/1\">Karthik Kashinath</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kumar_N/0/1/0/all/0/1\">Nalini Kumar</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Crutchfield_J/0/1/0/all/0/1\">James P. Crutchfield</a>",
          "description": "Spontaneous self-organization is ubiquitous in systems far from thermodynamic\nequilibrium. While organized structures that emerge dominate transport\nproperties, universal representations that identify and describe these key\nobjects remain elusive. Here, we introduce a theoretically-grounded framework\nfor describing emergent organization that, via data-driven algorithms, is\nconstructive in practice. Its building blocks are spacetime lightcones that\nembody how information propagates across a system through local interactions.\nWe show that predictive equivalence classes of lightcones -- local causal\nstates -- capture organized behaviors and coherent structures in complex\nspatiotemporal systems. Employing an unsupervised physics-informed machine\nlearning algorithm and a high-performance computing implementation, we\ndemonstrate automatically discovering coherent structures in two real world\ndomain science problems. We show that local causal states identify vortices and\ntrack their power-law decay behavior in two-dimensional fluid turbulence. We\nthen show how to detect and track familiar extreme weather events -- hurricanes\nand atmospheric rivers -- and discover other novel coherent structures\nassociated with precipitation extremes in high-resolution climate data at the\ngrid-cell level.",
          "link": "http://arxiv.org/abs/2304.12586",
          "publishedOn": "2023-09-30T00:41:30.160Z",
          "wordCount": null,
          "title": "Unsupervised Discovery of Extreme Weather Events Using Universal Representations of Emergent Organization. (arXiv:2304.12586v2 [physics.comp-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16521",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schurch_M/0/1/0/all/0/1\">Manuel Sch&#xfc;rch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Allam_A/0/1/0/all/0/1\">Ahmed Allam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rathmes_G/0/1/0/all/0/1\">Giulia Rathmes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mollaysa_A/0/1/0/all/0/1\">Amina Mollaysa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cavelti_Weder_C/0/1/0/all/0/1\">Claudia Cavelti-Weder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krauthammer_M/0/1/0/all/0/1\">Michael Krauthammer</a>",
          "description": "We propose a novel framework that combines deep generative time series models\nwith decision theory for generating personalized treatment strategies. It\nleverages historical patient trajectory data to jointly learn the generation of\nrealistic personalized treatment and future outcome trajectories through deep\ngenerative time series models. In particular, our framework enables the\ngeneration of novel multivariate treatment strategies tailored to the\npersonalized patient history and trained for optimal expected future outcomes\nbased on conditional expected utility maximization. We demonstrate our\nframework by generating personalized insulin treatment strategies and blood\nglucose predictions for hospitalized diabetes patients, showcasing the\npotential of our approach for generating improved personalized treatment\nstrategies. Keywords: deep generative model, probabilistic decision support,\npersonalized treatment generation, insulin and blood glucose prediction",
          "link": "http://arxiv.org/abs/2309.16521",
          "publishedOn": "2023-09-30T00:41:30.159Z",
          "wordCount": null,
          "title": "Generating Personalized Insulin Treatments Strategies with Deep Conditional Generative Time Series Models. (arXiv:2309.16521v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.06807",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fan_X/0/1/0/all/0/1\">Xiran Fan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_C/0/1/0/all/0/1\">Chun-Hao Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vemuri_B/0/1/0/all/0/1\">Baba C. Vemuri</a>",
          "description": "Hyperbolic spaces have been quite popular in the recent past for representing\nhierarchically organized data. Further, several classification algorithms for\ndata in these spaces have been proposed in the literature. These algorithms\nmainly use either hyperplanes or geodesics for decision boundaries in a large\nmargin classifiers setting leading to a non-convex optimization problem. In\nthis paper, we propose a novel large margin classifier based on horospherical\ndecision boundaries that leads to a geodesically convex optimization problem\nthat can be optimized using any Riemannian gradient descent technique\nguaranteeing a globally optimal solution. We present several experiments\ndepicting the competitive performance of our classifier in comparison to SOTA.",
          "link": "http://arxiv.org/abs/2302.06807",
          "publishedOn": "2023-09-30T00:41:30.156Z",
          "wordCount": null,
          "title": "Horospherical Decision Boundaries for Large Margin Classification in Hyperbolic Space. (arXiv:2302.06807v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.16808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1\">Tooba Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madhukar_K/0/1/0/all/0/1\">Kumar Madhukar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Subodh Vishnu Sharma</a>",
          "description": "The generation of adversarial inputs has become a crucial issue in\nestablishing the robustness and trustworthiness of deep neural nets, especially\nwhen they are used in safety-critical application domains such as autonomous\nvehicles and precision medicine. However, the problem poses multiple practical\nchallenges, including scalability issues owing to large-sized networks, and the\ngeneration of adversarial inputs that lack important qualities such as\nnaturalness and output-impartiality. This problem shares its end goal with the\ntask of patching neural nets where small changes in some of the network's\nweights need to be discovered so that upon applying these changes, the modified\nnet produces the desirable output for a given set of inputs. We exploit this\nconnection by proposing to obtain an adversarial input from a patch, with the\nunderlying observation that the effect of changing the weights can also be\nbrought about by changing the inputs instead. Thus, this paper presents a novel\nway to generate input perturbations that are adversarial for a given network by\nusing an efficient network patching technique. We note that the proposed method\nis significantly more effective than the prior state-of-the-art techniques.",
          "link": "http://arxiv.org/abs/2211.16808",
          "publishedOn": "2023-09-30T00:41:30.155Z",
          "wordCount": null,
          "title": "Efficient Adversarial Input Generation via Neural Net Patching. (arXiv:2211.16808v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16578",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1\">He Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_S/0/1/0/all/0/1\">Siyuan Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+You_J/0/1/0/all/0/1\">Jiacheng You</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_S/0/1/0/all/0/1\">Shuxin Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lu_Z/0/1/0/all/0/1\">Ziheng Lu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_N/0/1/0/all/0/1\">Nanning Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shao_B/0/1/0/all/0/1\">Bin Shao</a>",
          "description": "Orbital-free density functional theory (OFDFT) is a quantum chemistry\nformulation that has a lower cost scaling than the prevailing Kohn-Sham DFT,\nwhich is increasingly desired for contemporary molecular research. However, its\naccuracy is limited by the kinetic energy density functional, which is\nnotoriously hard to approximate for non-periodic molecular systems. In this\nwork, we propose M-OFDFT, an OFDFT approach capable of solving molecular\nsystems using a deep-learning functional model. We build the essential\nnonlocality into the model, which is made affordable by the concise density\nrepresentation as expansion coefficients under an atomic basis. With techniques\nto address unconventional learning challenges therein, M-OFDFT achieves a\ncomparable accuracy with Kohn-Sham DFT on a wide range of molecules untouched\nby OFDFT before. More attractively, M-OFDFT extrapolates well to molecules much\nlarger than those in training, which unleashes the appealing scaling for\nstudying large molecules including proteins, representing an advancement of the\naccuracy-efficiency trade-off frontier in quantum chemistry.",
          "link": "http://arxiv.org/abs/2309.16578",
          "publishedOn": "2023-09-30T00:41:30.148Z",
          "wordCount": null,
          "title": "M-OFDFT: Overcoming the Barrier of Orbital-Free Density Functional Theory for Molecular Systems Using Deep Learning. (arXiv:2309.16578v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yixuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1\">Katherine Driggs-Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunzhu Li</a>",
          "description": "Scene representation has been a crucial design choice in robotic manipulation\nsystems. An ideal representation should be 3D, dynamic, and semantic to meet\nthe demands of diverse manipulation tasks. However, previous works often lack\nall three properties simultaneously. In this work, we introduce D$^3$Fields -\ndynamic 3D descriptor fields. These fields capture the dynamics of the\nunderlying 3D environment and encode both semantic features and instance masks.\nSpecifically, we project arbitrary 3D points in the workspace onto multi-view\n2D visual observations and interpolate features derived from foundational\nmodels. The resulting fused descriptor fields allow for flexible goal\nspecifications using 2D images with varied contexts, styles, and instances. To\nevaluate the effectiveness of these descriptor fields, we apply our\nrepresentation to a wide range of robotic manipulation tasks in a zero-shot\nmanner. Through extensive evaluation in both real-world scenarios and\nsimulations, we demonstrate that D$^3$Fields are both generalizable and\neffective for zero-shot robotic manipulation tasks. In quantitative comparisons\nwith state-of-the-art dense descriptors, such as Dense Object Nets and DINO,\nD$^3$Fields exhibit significantly better generalization abilities and\nmanipulation accuracy.",
          "link": "http://arxiv.org/abs/2309.16118",
          "publishedOn": "2023-09-30T00:41:30.144Z",
          "wordCount": null,
          "title": "D$^3$Fields: Dynamic 3D Descriptor Fields for Zero-Shot Generalizable Robotic Manipulation. (arXiv:2309.16118v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16456",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhen Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feiyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhi_C/0/1/0/all/0/1\">Chen Zhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xueqiang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shuiguang Deng</a>",
          "description": "Existing approaches defend against backdoor attacks in federated learning\n(FL) mainly through a) mitigating the impact of infected models, or b)\nexcluding infected models. The former negatively impacts model accuracy, while\nthe latter usually relies on globally clear boundaries between benign and\ninfected model updates. However, model updates are easy to be mixed and\nscattered throughout in reality due to the diverse distributions of local data.\nThis work focuses on excluding infected models in FL. Unlike previous\nperspectives from a global view, we propose Snowball, a novel anti-backdoor FL\nframework through bidirectional elections from an individual perspective\ninspired by one principle deduced by us and two principles in FL and deep\nlearning. It is characterized by a) bottom-up election, where each candidate\nmodel update votes to several peer ones such that a few model updates are\nelected as selectees for aggregation; and b) top-down election, where selectees\nprogressively enlarge themselves through picking up from the candidates. We\ncompare Snowball with state-of-the-art defenses to backdoor attacks in FL on\nfive real-world datasets, demonstrating its superior resistance to backdoor\nattacks and slight impact on the accuracy of the global model.",
          "link": "http://arxiv.org/abs/2309.16456",
          "publishedOn": "2023-09-30T00:41:30.131Z",
          "wordCount": null,
          "title": "Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective. (arXiv:2309.16456v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Danieli_F/0/1/0/all/0/1\">Federico Danieli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarabia_M/0/1/0/all/0/1\">Miguel Sarabia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suau_X/0/1/0/all/0/1\">Xavier Suau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_P/0/1/0/all/0/1\">Pau Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zappella_L/0/1/0/all/0/1\">Luca Zappella</a>",
          "description": "Parallelization techniques have become ubiquitous for accelerating inference\nand training of deep neural networks. Despite this, several operations are\nstill performed in a sequential manner. For instance, the forward and backward\npasses are executed layer-by-layer, and the output of diffusion models is\nproduced by applying a sequence of denoising steps. This sequential approach\nresults in a computational cost proportional to the number of steps involved,\npresenting a potential bottleneck as the number of steps increases. In this\nwork, we introduce DeepPCR, a novel algorithm which parallelizes typically\nsequential operations used in inference and training of neural networks.\nDeepPCR is based on interpreting a sequence of $L$ steps as the solution of a\nspecific system of equations, which we recover using the Parallel Cyclic\nReduction algorithm. This reduces the complexity of computing the sequential\noperations from $\\mathcal{O}(L)$ to $\\mathcal{O}(\\log_2L)$, thus yielding a\nspeedup for large $L$. To verify the theoretical lower complexity of the\nalgorithm, and to identify regimes for speedup, we test the effectiveness of\nDeepPCR in parallelizing the forward and backward pass in multi-layer\nperceptrons, and reach speedups of up to $30\\times$ for forward and $200\\times$\nfor backward pass. We additionally showcase the flexibility of DeepPCR by\nparallelizing training of ResNets with as many as 1024 layers, and generation\nin diffusion models, enabling up to $7\\times$ faster training and $11\\times$\nfaster generation, respectively, when compared to the sequential approach.",
          "link": "http://arxiv.org/abs/2309.16318",
          "publishedOn": "2023-09-30T00:41:30.130Z",
          "wordCount": null,
          "title": "DeepPCR: Parallelizing Sequential Operations in Neural Networks. (arXiv:2309.16318v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Agrawal_S/0/1/0/all/0/1\">Shubhada Agrawal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mathieu_T/0/1/0/all/0/1\">Timoth&#xe9;e Mathieu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Basu_D/0/1/0/all/0/1\">Debabrota Basu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maillard_O/0/1/0/all/0/1\">Odalric-Ambrym Maillard</a>",
          "description": "We investigate the regret-minimisation problem in a multi-armed bandit\nsetting with arbitrary corruptions. Similar to the classical setup, the agent\nreceives rewards generated independently from the distribution of the arm\nchosen at each time. However, these rewards are not directly observed. Instead,\nwith a fixed $\\varepsilon\\in (0,\\frac{1}{2})$, the agent observes a sample from\nthe chosen arm's distribution with probability $1-\\varepsilon$, or from an\narbitrary corruption distribution with probability $\\varepsilon$. Importantly,\nwe impose no assumptions on these corruption distributions, which can be\nunbounded. In this setting, accommodating potentially unbounded corruptions, we\nestablish a problem-dependent lower bound on regret for a given family of arm\ndistributions. We introduce CRIMED, an asymptotically-optimal algorithm that\nachieves the exact lower bound on regret for bandits with Gaussian\ndistributions with known variance. Additionally, we provide a finite-sample\nanalysis of CRIMED's regret performance. Notably, CRIMED can effectively handle\ncorruptions with $\\varepsilon$ values as high as $\\frac{1}{2}$. Furthermore, we\ndevelop a tight concentration result for medians in the presence of arbitrary\ncorruptions, even with $\\varepsilon$ values up to $\\frac{1}{2}$, which may be\nof independent interest. We also discuss an extension of the algorithm for\nhandling misspecification in Gaussian model.",
          "link": "http://arxiv.org/abs/2309.16563",
          "publishedOn": "2023-09-30T00:41:30.121Z",
          "wordCount": null,
          "title": "CRIMED: Lower and Upper Bounds on Regret for Bandits with Unbounded Stochastic Corruption. (arXiv:2309.16563v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">RuiQi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diao_B/0/1/0/all/0/1\">Boyu Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Libo Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_Z/0/1/0/all/0/1\">Zhulin An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yongjun Xu</a>",
          "description": "Continual Learning methods are designed to learn new tasks without erasing\nprevious knowledge. However, Continual Learning often requires massive\ncomputational power and storage capacity for satisfactory performance. In this\npaper, we propose a resource-efficient continual learning method called the\nElastic Expansion Network (E2Net). Leveraging core subnet distillation and\nprecise replay sample selection, E2Net achieves superior average accuracy and\ndiminished forgetting within the same computational and storage constraints,\nall while minimizing processing time. In E2Net, we propose Representative\nNetwork Distillation to identify the representative core subnet by assessing\nparameter quantity and output similarity with the working network, distilling\nanalogous subnets within the working network to mitigate reliance on rehearsal\nbuffers and facilitating knowledge transfer across previous tasks. To enhance\nstorage resource utilization, we then propose Subnet Constraint Experience\nReplay to optimize rehearsal efficiency through a sample storage strategy based\non the structures of representative networks. Extensive experiments conducted\npredominantly on cloud environments with diverse datasets and also spanning the\nedge environment demonstrate that E2Net consistently outperforms\nstate-of-the-art methods. In addition, our method outperforms competitors in\nterms of both storage and computational requirements.",
          "link": "http://arxiv.org/abs/2309.16117",
          "publishedOn": "2023-09-30T00:41:30.103Z",
          "wordCount": null,
          "title": "E2Net: Resource-Efficient Continual Learning with Elastic Expansion Network. (arXiv:2309.16117v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Myers_A/0/1/0/all/0/1\">Adele Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_C/0/1/0/all/0/1\">Caitlin Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_E/0/1/0/all/0/1\">Emily Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miolane_N/0/1/0/all/0/1\">Nina Miolane</a>",
          "description": "Women are at higher risk of Alzheimer's and other neurological diseases after\nmenopause, and yet research connecting female brain health to sex hormone\nfluctuations is limited. We seek to investigate this connection by developing\ntools that quantify 3D shape changes that occur in the brain during sex hormone\nfluctuations. Geodesic regression on the space of 3D discrete surfaces offers a\nprincipled way to characterize the evolution of a brain's shape. However, in\nits current form, this approach is too computationally expensive for practical\nuse. In this paper, we propose approximation schemes that accelerate geodesic\nregression on shape spaces of 3D discrete surfaces. We also provide rules of\nthumb for when each approximation can be used. We test our approach on\nsynthetic data to quantify the speed-accuracy trade-off of these approximations\nand show that practitioners can expect very significant speed-up while only\nsacrificing little accuracy. Finally, we apply the method to real brain shape\ndata and produce the first characterization of how the female hippocampus\nchanges shape during the menstrual cycle as a function of progesterone: a\ncharacterization made (practically) possible by our approximation schemes. Our\nwork paves the way for comprehensive, practical shape analyses in the fields of\nbio-medicine and computer vision. Our implementation is publicly available on\nGitHub: https://github.com/bioshape-lab/my28brains.",
          "link": "http://arxiv.org/abs/2309.16662",
          "publishedOn": "2023-09-30T00:41:30.103Z",
          "wordCount": null,
          "title": "Geodesic Regression Characterizes 3D Shape Changes in the Female Brain During Menstruation. (arXiv:2309.16662v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_Y/0/1/0/all/0/1\">Youbin Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pack_S/0/1/0/all/0/1\">Sangheon Pack</a>",
          "description": "5G introduced modularized network functions (NFs) to support emerging\nservices in a more flexible and elastic manner. To mitigate the complexity in\nsuch modularized NF management, automated network operation and management are\nindispensable, and thus the 3rd generation partnership project (3GPP) has\nintroduced a network data analytics function (NWDAF). However, a conventional\nNWDAF needs to conduct both inference and training tasks, and thus it is\ndifficult to provide the analytics results to NFs in a timely manner for an\nincreased number of analytics requests. In this article, we propose a\nhierarchical network data analytics framework (H-NDAF) where inference tasks\nare distributed to multiple leaf NWDAFs and training tasks are conducted at the\nroot NWDAF. Extensive simulation results using open-source software (i.e.,\nfree5GC) demonstrate that H-NDAF can provide sufficiently accurate analytics\nand faster analytics provision time compared to the conventional NWDAF.",
          "link": "http://arxiv.org/abs/2309.16269",
          "publishedOn": "2023-09-30T00:41:30.095Z",
          "wordCount": null,
          "title": "Hierarchical Network Data Analytics Framework for B5G Network Automation: Design and Implementation. (arXiv:2309.16269v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tanveer_M/0/1/0/all/0/1\">M. Tanveer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_R/0/1/0/all/0/1\">Ritik Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richhariya_B/0/1/0/all/0/1\">Bharat Richhariya</a>",
          "description": "Class imbalance is a major problem in many real world classification tasks.\nDue to the imbalance in the number of samples, the support vector machine (SVM)\nclassifier gets biased toward the majority class. Furthermore, these samples\nare often observed with a certain degree of noise. Therefore, to remove these\nproblems we propose a novel fuzzy based approach to deal with class imbalanced\nas well noisy datasets. We propose two approaches to address these problems.\nThe first approach is based on the intuitionistic fuzzy membership, termed as\nrobust energy-based intuitionistic fuzzy least squares twin support vector\nmachine (IF-RELSTSVM). Furthermore, we introduce the concept of\nhyperplane-based fuzzy membership in our second approach, where the final\nclassifier is termed as robust energy-based fuzzy least square twin support\nvector machine (F-RELSTSVM). By using this technique, the membership values are\nbased on a projection based approach, where the data points are projected on\nthe hyperplanes. The performance of the proposed algorithms is evaluated on\nseveral benchmark and synthetic datasets. The experimental results show that\nthe proposed IF-RELSTSVM and F-RELSTSVM models outperform the baseline\nalgorithms. Statistical tests are performed to check the significance of the\nproposed algorithms. The results show the applicability of the proposed\nalgorithms on noisy as well as imbalanced datasets.",
          "link": "http://arxiv.org/abs/2309.15886",
          "publishedOn": "2023-09-30T00:41:30.092Z",
          "wordCount": null,
          "title": "Projection based fuzzy least squares twin support vector machine for class imbalance problems. (arXiv:2309.15886v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yujia Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivanandan_S/0/1/0/all/0/1\">Srinivasan Sivanandan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karaletsos_T/0/1/0/all/0/1\">Theofanis Karaletsos</a>",
          "description": "Vision Transformer (ViT) has emerged as a powerful architecture in the realm\nof modern computer vision. However, its application in certain imaging fields,\nsuch as microscopy and satellite imaging, presents unique challenges. In these\ndomains, images often contain multiple channels, each carrying semantically\ndistinct and independent information. Furthermore, the model must demonstrate\nrobustness to sparsity in input channels, as they may not be densely available\nduring training or testing. In this paper, we propose a modification to the ViT\narchitecture that enhances reasoning across the input channels and introduce\nHierarchical Channel Sampling (HCS) as an additional regularization technique\nto ensure robustness when only partial channels are presented during test time.\nOur proposed model, ChannelViT, constructs patch tokens independently from each\ninput channel and utilizes a learnable channel embedding that is added to the\npatch tokens, similar to positional embeddings. We evaluate the performance of\nChannelViT on ImageNet, JUMP-CP (microscopy cell imaging), and So2Sat\n(satellite imaging). Our results show that ChannelViT outperforms ViT on\nclassification tasks and generalizes well, even when a subset of input channels\nis used during testing. Across our experiments, HCS proves to be a powerful\nregularizer, independent of the architecture employed, suggesting itself as a\nstraightforward technique for robust ViT training. Lastly, we find that\nChannelViT generalizes effectively even when there is limited access to all\nchannels during training, highlighting its potential for multi-channel imaging\nunder real-world conditions with sparse sensors.",
          "link": "http://arxiv.org/abs/2309.16108",
          "publishedOn": "2023-09-30T00:41:30.084Z",
          "wordCount": null,
          "title": "Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words. (arXiv:2309.16108v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cyranka_J/0/1/0/all/0/1\">Jacek Cyranka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haponiuk_S/0/1/0/all/0/1\">Szymon Haponiuk</a>",
          "description": "In order to support the advancement of machine learning methods for\npredicting time-series data, we present a comprehensive dataset designed\nexplicitly for long-term time-series forecasting. We incorporate a collection\nof datasets obtained from diverse, dynamic systems and real-life records. Each\ndataset is standardized by dividing it into training and test trajectories with\npredetermined lookback lengths. We include trajectories of length up to $2000$\nto ensure a reliable evaluation of long-term forecasting capabilities. To\ndetermine the most effective model in diverse scenarios, we conduct an\nextensive benchmarking analysis using classical and state-of-the-art models,\nnamely LSTM, DeepAR, NLinear, N-Hits, PatchTST, and LatentODE. Our findings\nreveal intriguing performance comparisons among these models, highlighting the\ndataset-dependent nature of model effectiveness. Notably, we introduce a custom\nlatent NLinear model and enhance DeepAR with a curriculum learning phase. Both\nconsistently outperform their vanilla counterparts.",
          "link": "http://arxiv.org/abs/2309.15946",
          "publishedOn": "2023-09-30T00:41:30.074Z",
          "wordCount": null,
          "title": "Unified Long-Term Time-Series Forecasting Benchmark. (arXiv:2309.15946v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsur_D/0/1/0/all/0/1\">Dor Tsur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldfeld_Z/0/1/0/all/0/1\">Ziv Goldfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenewald_K/0/1/0/all/0/1\">Kristjan Greenewald</a>",
          "description": "Quantifying the dependence between high-dimensional random variables is\ncentral to statistical learning and inference. Two classical methods are\ncanonical correlation analysis (CCA), which identifies maximally correlated\nprojected versions of the original variables, and Shannon's mutual information,\nwhich is a universal dependence measure that also captures high-order\ndependencies. However, CCA only accounts for linear dependence, which may be\ninsufficient for certain applications, while mutual information is often\ninfeasible to compute/estimate in high dimensions. This work proposes a middle\nground in the form of a scalable information-theoretic generalization of CCA,\ntermed max-sliced mutual information (mSMI). mSMI equals the maximal mutual\ninformation between low-dimensional projections of the high-dimensional\nvariables, which reduces back to CCA in the Gaussian case. It enjoys the best\nof both worlds: capturing intricate dependencies in the data while being\namenable to fast computation and scalable estimation from samples. We show that\nmSMI retains favorable structural properties of Shannon's mutual information,\nlike variational forms and identification of independence. We then study\nstatistical estimation of mSMI, propose an efficiently computable neural\nestimator, and couple it with formal non-asymptotic error bounds. We present\nexperiments that demonstrate the utility of mSMI for several tasks,\nencompassing independence testing, multi-view representation learning,\nalgorithmic fairness, and generative modeling. We observe that mSMI\nconsistently outperforms competing methods with little-to-no computational\noverhead.",
          "link": "http://arxiv.org/abs/2309.16200",
          "publishedOn": "2023-09-30T00:41:30.068Z",
          "wordCount": null,
          "title": "Max-Sliced Mutual Information. (arXiv:2309.16200v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16025",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharifi_I/0/1/0/all/0/1\">Iman Sharifi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fallah_S/0/1/0/all/0/1\">Saber Fallah</a>",
          "description": "Current methods of imitation learning (IL), primarily based on deep neural\nnetworks, offer efficient means for obtaining driving policies from real-world\ndata but suffer from significant limitations in interpretability and\ngeneralizability. These shortcomings are particularly concerning in\nsafety-critical applications like autonomous driving. In this paper, we address\nthese limitations by introducing Symbolic Imitation Learning (SIL), a\ngroundbreaking method that employs Inductive Logic Programming (ILP) to learn\ndriving policies which are transparent, explainable and generalisable from\navailable datasets. Utilizing the real-world highD dataset, we subject our\nmethod to a rigorous comparative analysis against prevailing\nneural-network-based IL methods. Our results demonstrate that SIL not only\nenhances the interpretability of driving policies but also significantly\nimproves their applicability across varied driving situations. Hence, this work\noffers a novel pathway to more reliable and safer autonomous driving systems,\nunderscoring the potential of integrating ILP into the domain of IL.",
          "link": "http://arxiv.org/abs/2309.16025",
          "publishedOn": "2023-09-30T00:41:30.064Z",
          "wordCount": null,
          "title": "Symbolic Imitation Learning: From Black-Box to Explainable Driving Policies. (arXiv:2309.16025v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suh_Y/0/1/0/all/0/1\">Yehyun Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_P/0/1/0/all/0/1\">Peter Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1\">J.Ryan Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moyer_D/0/1/0/all/0/1\">Daniel Moyer</a>",
          "description": "This work reports the empirical performance of an automated medical landmark\ndetection method for predict clinical markers in hip radiograph images.\nNotably, the detection method was trained using a label-only augmentation\nscheme; our results indicate that this form of augmentation outperforms\ntraditional data augmentation and produces highly sample efficient estimators.\nWe train a generic U-Net-based architecture under a curriculum consisting of\ntwo phases: initially relaxing the landmarking task by enlarging the label\npoints to regions, then gradually eroding these label regions back to the base\ntask. We measure the benefits of this approach on six datasets of radiographs\nwith gold-standard expert annotations.",
          "link": "http://arxiv.org/abs/2309.16066",
          "publishedOn": "2023-09-30T00:41:30.058Z",
          "wordCount": 616,
          "title": "Label Augmentation Method for Medical Landmark Detection in Hip Radiograph Images. (arXiv:2309.16066v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.09175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+S_P/0/1/0/all/0/1\">Priya.S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivakumar_H/0/1/0/all/0/1\">Haribharathi Sivakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+R_V/0/1/0/all/0/1\">Vijay Arvind.R</a>",
          "description": "Modern streaming data categorization faces significant challenges from\nconcept drift and class imbalanced data. This negatively impacts the output of\nthe classifier, leading to improper classification. Furthermore, other factors\nsuch as the overlapping of multiple classes limit the extent of the correctness\nof the output. This work proposes a novel framework for integrating data\npre-processing and dynamic ensemble selection, by formulating the\nclassification framework for the nonstationary drifting imbalanced data stream,\nwhich employs the data pre-processing and dynamic ensemble selection\ntechniques. The proposed framework was evaluated using six artificially\ngenerated data streams with differing imbalance ratios in combination with two\ndifferent types of concept drifts. Each stream is composed of 200 chunks of 500\nobjects described by eight features and contains five concept drifts. Seven\npre-processing techniques and two dynamic ensemble selection methods were\nconsidered. According to experimental results, data pre-processing combined\nwith Dynamic Ensemble Selection techniques significantly delivers more accuracy\nwhen dealing with imbalanced data streams.",
          "link": "http://arxiv.org/abs/2309.09175",
          "publishedOn": "2023-09-30T00:41:30.039Z",
          "wordCount": null,
          "title": "Imbalanced Data Stream Classification using Dynamic Ensemble Selection. (arXiv:2309.09175v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.05856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Z/0/1/0/all/0/1\">Zhangkai Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Baoliang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shurun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shiqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hanli Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwong_S/0/1/0/all/0/1\">Sam Kwong</a>",
          "description": "High-quality face images are required to guarantee the stability and\nreliability of automatic face recognition (FR) systems in surveillance and\nsecurity scenarios. However, a massive amount of face data is usually\ncompressed before being analyzed due to limitations on transmission or storage.\nThe compressed images may lose the powerful identity information, resulting in\nthe performance degradation of the FR system. Herein, we make the first attempt\nto study just noticeable difference (JND) for the FR system, which can be\ndefined as the maximum distortion that the FR system cannot notice. More\nspecifically, we establish a JND dataset including 3530 original images and\n137,670 compressed images generated by advanced reference encoding/decoding\nsoftware based on the Versatile Video Coding (VVC) standard (VTM-15.0).\nSubsequently, we develop a novel JND prediction model to directly infer JND\nimages for the FR system. In particular, in order to maximum redundancy removal\nwithout impairment of robust identity information, we apply the encoder with\nmultiple feature extraction and attention-based feature decomposition modules\nto progressively decompose face features into two uncorrelated components,\ni.e., identity and residual features, via self-supervised learning. Then, the\nresidual feature is fed into the decoder to generate the residual map. Finally,\nthe predicted JND map is obtained by subtracting the residual map from the\noriginal image. Experimental results have demonstrated that the proposed model\nachieves higher accuracy of JND map prediction compared with the\nstate-of-the-art JND models, and is capable of saving more bits while\nmaintaining the performance of the FR system compared with VTM-15.0.",
          "link": "http://arxiv.org/abs/2209.05856",
          "publishedOn": "2023-09-30T00:41:30.024Z",
          "wordCount": null,
          "title": "Just Noticeable Difference Modeling for Face Recognition System. (arXiv:2209.05856v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15889",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yilmaz_S/0/1/0/all/0/1\">Selim F. Yilmaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Niu_X/0/1/0/all/0/1\">Xueyan Niu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bai_B/0/1/0/all/0/1\">Bo Bai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_W/0/1/0/all/0/1\">Wei Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deng_L/0/1/0/all/0/1\">Lei Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gunduz_D/0/1/0/all/0/1\">Deniz Gunduz</a>",
          "description": "We consider the image transmission problem over a noisy wireless channel via\ndeep learning-based joint source-channel coding (DeepJSCC) along with a\ndenoising diffusion probabilistic model (DDPM) at the receiver. Specifically,\nwe are interested in the perception-distortion trade-off in the practical\nfinite block length regime, in which separate source and channel coding can be\nhighly suboptimal. We introduce a novel scheme that utilizes the range-null\nspace decomposition of the target image. We transmit the range-space of the\nimage after encoding and employ DDPM to progressively refine its null space\ncontents. Through extensive experiments, we demonstrate significant\nimprovements in distortion and perceptual quality of reconstructed images\ncompared to standard DeepJSCC and the state-of-the-art generative\nlearning-based method. We will publicly share our source code to facilitate\nfurther research and reproducibility.",
          "link": "http://arxiv.org/abs/2309.15889",
          "publishedOn": "2023-09-30T00:41:30.020Z",
          "wordCount": null,
          "title": "High Perceptual Quality Wireless Image Delivery with Denoising Diffusion Models. (arXiv:2309.15889v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.14708",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_J/0/1/0/all/0/1\">Juhyeon Kim</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huh_J/0/1/0/all/0/1\">Joonsuk Huh</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Park_D/0/1/0/all/0/1\">Daniel K. Park</a>",
          "description": "Machine learning using quantum convolutional neural networks (QCNNs) has\ndemonstrated success in both quantum and classical data classification. In\nprevious studies, QCNNs attained a higher classification accuracy than their\nclassical counterparts under the same training conditions in the few-parameter\nregime. However, the general performance of large-scale quantum models is\ndifficult to examine because of the limited size of quantum circuits, which can\nbe reliably implemented in the near future. We propose transfer learning as an\neffective strategy for utilizing small QCNNs in the noisy intermediate-scale\nquantum era to the full extent. In the classical-to-quantum transfer learning\nframework, a QCNN can solve complex classification problems without requiring a\nlarge-scale quantum circuit by utilizing a pre-trained classical convolutional\nneural network (CNN). We perform numerical simulations of QCNN models with\nvarious sets of quantum convolution and pooling operations for MNIST data\nclassification under transfer learning, in which a classical CNN is trained\nwith Fashion-MNIST data. The results show that transfer learning from classical\nto quantum CNN performs considerably better than purely classical transfer\nlearning models under similar training conditions.",
          "link": "http://arxiv.org/abs/2208.14708",
          "publishedOn": "2023-09-30T00:41:30.014Z",
          "wordCount": null,
          "title": "Classical-to-quantum convolutional neural network transfer learning. (arXiv:2208.14708v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.09976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuzina_A/0/1/0/all/0/1\">Anna Kuzina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1\">Jakub M. Tomczak</a>",
          "description": "Hierarchical Variational Autoencoders (VAEs) are among the most popular\nlikelihood-based generative models. There is a consensus that the top-down\nhierarchical VAEs allow effective learning of deep latent structures and avoid\nproblems like posterior collapse. Here, we show that this is not necessarily\nthe case, and the problem of collapsing posteriors remains. To discourage this\nissue, we propose a deep hierarchical VAE with a context on top. Specifically,\nwe use a Discrete Cosine Transform to obtain the last latent variable. In a\nseries of experiments, we observe that the proposed modification allows us to\nachieve better utilization of the latent space and does not harm the model's\ngenerative abilities.",
          "link": "http://arxiv.org/abs/2302.09976",
          "publishedOn": "2023-09-30T00:41:30.014Z",
          "wordCount": null,
          "title": "Discouraging posterior collapse in hierarchical Variational Autoencoders using context. (arXiv:2302.09976v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.03666",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Du_S/0/1/0/all/0/1\">Shide Du</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fang_Z/0/1/0/all/0/1\">Zihan Fang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lan_S/0/1/0/all/0/1\">Shiyang Lan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tan_Y/0/1/0/all/0/1\">Yanchao Tan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gunther_M/0/1/0/all/0/1\">Manuel G&#xfc;nther</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shiping Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Guo_W/0/1/0/all/0/1\">Wenzhong Guo</a>",
          "description": "As researchers strive to narrow the gap between machine intelligence and\nhuman through the development of artificial intelligence technologies, it is\nimperative that we recognize the critical importance of trustworthiness in\nopen-world, which has become ubiquitous in all aspects of daily life for\neveryone. However, several challenges may create a crisis of trust in current\nartificial intelligence systems that need to be bridged: 1) Insufficient\nexplanation of predictive results; 2) Inadequate generalization for learning\nmodels; 3) Poor adaptability to uncertain environments. Consequently, we\nexplore a neural program to bridge trustworthiness and open-world learning,\nextending from single-modal to multi-modal scenarios for readers. 1) To enhance\ndesign-level interpretability, we first customize trustworthy networks with\nspecific physical meanings; 2) We then design environmental well-being\ntask-interfaces via flexible learning regularizers for improving the\ngeneralization of trustworthy learning; 3) We propose to increase the\nrobustness of trustworthy learning by integrating open-world recognition losses\nwith agent mechanisms. Eventually, we enhance various trustworthy properties\nthrough the establishment of design-level explainability, environmental\nwell-being task-interfaces and open-world recognition programs. These designed\nopen-world protocols are applicable across a wide range of surroundings, under\nopen-world multimedia recognition scenarios with significant performance\nimprovements observed.",
          "link": "http://arxiv.org/abs/2308.03666",
          "publishedOn": "2023-09-30T00:41:30.014Z",
          "wordCount": null,
          "title": "Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness. (arXiv:2308.03666v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koloski_B/0/1/0/all/0/1\">Boshko Koloski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skrlj_B/0/1/0/all/0/1\">Bla&#x17e; &#x160;krlj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollak_S/0/1/0/all/0/1\">Senja Pollak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavrac_N/0/1/0/all/0/1\">Nada Lavra&#x10d;</a>",
          "description": "In the domain of semi-supervised learning, the current approaches\ninsufficiently exploit the potential of considering inter-instance\nrelationships among (un)labeled data. In this work, we address this limitation\nby providing an approach for inferring latent graphs that capture the intrinsic\ndata relationships. By leveraging graph-based representations, our approach\nfacilitates the seamless propagation of information throughout the graph,\nenabling the effective incorporation of global and local knowledge. Through\nevaluations on biomedical tabular datasets, we compare the capabilities of our\napproach to other contemporary methods. Our work demonstrates the significance\nof inter-instance relationship discovery as practical means for constructing\nrobust latent graphs to enhance semi-supervised learning techniques. Our method\nachieves state-of-the-art results on three biomedical datasets.",
          "link": "http://arxiv.org/abs/2309.15757",
          "publishedOn": "2023-09-30T00:41:30.014Z",
          "wordCount": null,
          "title": "Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data. (arXiv:2309.15757v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bingcong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giannakis_G/0/1/0/all/0/1\">Georgios B. Giannakis</a>",
          "description": "Sharpness-aware minimization (SAM) has well documented merits in enhancing\ngeneralization of deep neural networks, even without sizable data augmentation.\nEmbracing the geometry of the loss function, where neighborhoods of 'flat\nminima' heighten generalization ability, SAM seeks 'flat valleys' by minimizing\nthe maximum loss caused by an adversary perturbing parameters within the\nneighborhood. Although critical to account for sharpness of the loss function,\nsuch an 'over-friendly adversary' can curtail the outmost level of\ngeneralization. The novel approach of this contribution fosters stabilization\nof adversaries through variance suppression (VaSSO) to avoid such friendliness.\nVaSSO's provable stability safeguards its numerical improvement over SAM in\nmodel-agnostic tasks, including image classification and machine translation.\nIn addition, experiments confirm that VaSSO endows SAM with robustness against\nhigh levels of label noise.",
          "link": "http://arxiv.org/abs/2309.15639",
          "publishedOn": "2023-09-30T00:41:30.012Z",
          "wordCount": null,
          "title": "Enhancing Sharpness-Aware Optimization Through Variance Suppression. (arXiv:2309.15639v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.01253",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Hess_P/0/1/0/all/0/1\">Philipp Hess</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lange_S/0/1/0/all/0/1\">Stefan Lange</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schotz_C/0/1/0/all/0/1\">Christof Sch&#xf6;tz</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Boers_N/0/1/0/all/0/1\">Niklas Boers</a>",
          "description": "The accurate representation of precipitation in Earth system models (ESMs) is\ncrucial for reliable projections of the ecological and socioeconomic impacts in\nresponse to anthropogenic global warming. The complex cross-scale interactions\nof processes that produce precipitation are challenging to model, however,\ninducing potentially strong biases in ESM fields, especially regarding\nextremes. State-of-the-art bias correction methods only address errors in the\nsimulated frequency distributions locally at every individual grid cell.\nImproving unrealistic spatial patterns of the ESM output, which would require\nspatial context, has not been possible so far. Here, we show that a\npost-processing method based on physically constrained generative adversarial\nnetworks (cGANs) can correct biases of a state-of-the-art, CMIP6-class ESM both\nin local frequency distributions and in the spatial patterns at once. While our\nmethod improves local frequency distributions equally well as gold-standard\nbias-adjustment frameworks, it strongly outperforms any existing methods in the\ncorrection of spatial patterns, especially in terms of the characteristic\nspatial intermittency of precipitation extremes.",
          "link": "http://arxiv.org/abs/2301.01253",
          "publishedOn": "2023-09-30T00:41:30.011Z",
          "wordCount": null,
          "title": "Deep learning for bias-correcting CMIP6-class Earth system models. (arXiv:2301.01253v3 [physics.ao-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wenhua Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weiwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Haihao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yiyang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xin He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_K/0/1/0/all/0/1\">Kaokao Lv</a>",
          "description": "Large Language Models (LLMs) have proven their exceptional capabilities in\nperforming language-related tasks. However, their deployment poses significant\nchallenges due to their considerable memory and storage requirements. In\nresponse to this issue, weight-only quantization, particularly 3 and 4-bit\nweight-only quantization, has emerged as one of the most viable solutions. As\nthe number of bits decreases, the quantization grid broadens, thus emphasizing\nthe importance of up and down rounding. While previous studies have\ndemonstrated that fine-tuning up and down rounding with the addition of\nperturbations can enhance accuracy in some scenarios, our study is driven by\nthe precise and limited boundary of these perturbations, where only the\nthreshold for altering the rounding value is of significance. Consequently, we\npropose a concise and highly effective approach for optimizing the weight\nrounding task. Our method, named SignRound, involves lightweight block-wise\ntuning using signed gradient descent, enabling us to achieve outstanding\nresults within 400 steps. SignRound competes impressively against recent\nmethods without introducing additional inference overhead. The source code will\nbe publicly available at \\url{https://github.com/intel/neural-compressor} soon.",
          "link": "http://arxiv.org/abs/2309.05516",
          "publishedOn": "2023-09-30T00:41:30.007Z",
          "wordCount": null,
          "title": "Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs. (arXiv:2309.05516v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.00147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghobrial_A/0/1/0/all/0/1\">Abanoub Ghobrial</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hond_D/0/1/0/all/0/1\">Darryl Hond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asgari_H/0/1/0/all/0/1\">Hamid Asgari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eder_K/0/1/0/all/0/1\">Kerstin Eder</a>",
          "description": "Autonomous systems (AS) often use Deep Neural Network (DNN) classifiers to\nallow them to operate in complex, high-dimensional, non-linear, and dynamically\nchanging environments. Due to the complexity of these environments, DNN\nclassifiers may output misclassifications during operation when they face\ndomains not identified during development. Removing a system from operation for\nretraining becomes impractical as the number of such AS increases. To increase\nAS reliability and overcome this limitation, DNN classifiers need to have the\nability to adapt during operation when faced with different operational domains\nusing a few samples (e.g. 100 samples). However, retraining DNNs on a few\nsamples is known to cause catastrophic forgetting. In this paper, we introduce\nDynamic Incremental Regularised Adaptation (DIRA), a framework for operational\ndomain adaption of DNN classifiers using regularisation techniques to overcome\ncatastrophic forgetting and achieve adaptation when retraining using a few\nsamples of the target domain. Our approach shows improvements on different\nimage classification benchmarks aimed at evaluating robustness to distribution\nshifts (e.g.CIFAR-10C/100C, ImageNet-C), and produces state-of-the-art\nperformance in comparison with other frameworks from the literature.",
          "link": "http://arxiv.org/abs/2205.00147",
          "publishedOn": "2023-09-30T00:41:30.006Z",
          "wordCount": null,
          "title": "DIRA: Dynamic Domain Incremental Regularised Adaptation. (arXiv:2205.00147v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiawen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Quan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1\">Deze Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhuo Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Minyi Guo</a>",
          "description": "Many emerging user-facing services adopt Graph Neural Networks (GNNs) to\nimprove serving accuracy. When the graph used by a GNN model changes,\nrepresentations (embedding) of nodes in the graph should be updated\naccordingly. However, the node representation update is too slow, resulting in\neither long response latency of user queries (the inference is performed after\nthe update completes) or high staleness problem (the inference is performed\nbased on stale data). Our in-depth analysis shows that the slow update is\nmainly due to neighbor explosion problem in graphs and duplicated computation.\nBased on such findings, we propose STAG, a GNN serving framework that enables\nlow latency and low staleness of GNN-based services. It comprises a\ncollaborative serving mechanism and an additivity-based incremental propagation\nstrategy. With the collaborative serving mechanism, only part of node\nrepresentations are updated during the update phase, and the final\nrepresentations are calculated in the inference phase. It alleviates the\nneighbor explosion problem. The additivity-based incremental propagation\nstrategy reuses intermediate data during the update phase, eliminating\nduplicated computation problem. Experimental results show that STAG accelerates\nthe update phase by 1.3x~90.1x, and greatly reduces staleness time with a\nslight increase in response latency.",
          "link": "http://arxiv.org/abs/2309.15875",
          "publishedOn": "2023-09-30T00:41:29.952Z",
          "wordCount": null,
          "title": "STAG: Enabling Low Latency and Low Staleness of GNN-based Services with Dynamic Graphs. (arXiv:2309.15875v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bathla_S/0/1/0/all/0/1\">Shivani Bathla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1\">Vinita Vasudevan</a>",
          "description": "Exact computation of the partition function is known to be intractable,\nnecessitating approximate inference techniques. Existing methods for\napproximate inference are slow to converge for many benchmarks. The control of\naccuracy-complexity trade-off is also non-trivial in many of these methods. We\npropose a novel incremental build-infer-approximate (IBIA) framework for\napproximate inference that addresses these issues. In this framework, the\nprobabilistic graphical model is converted into a sequence of clique tree\nforests (SCTF) with bounded clique sizes. We show that the SCTF can be used to\nefficiently compute the partition function. We propose two new algorithms which\nare used to construct the SCTF and prove the correctness of both. The first is\nan algorithm for incremental construction of CTFs that is guaranteed to give a\nvalid CTF with bounded clique sizes and the second is an approximation\nalgorithm that takes a calibrated CTF as input and yields a valid and\ncalibrated CTF with reduced clique sizes as the output. We have evaluated our\nmethod using several benchmark sets from recent UAI competitions and our\nresults show good accuracies with competitive runtimes.",
          "link": "http://arxiv.org/abs/2304.06366",
          "publishedOn": "2023-09-30T00:41:29.831Z",
          "wordCount": null,
          "title": "IBIA: An Incremental Build-Infer-Approximate Framework for Approximate Inference of Partition Function. (arXiv:2304.06366v2 [cs.AI] UPDATED)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "stat.ML updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/stat.ML",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2306.07960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kini_G/0/1/0/all/0/1\">Ganesh Ramachandra Kini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakilian_V/0/1/0/all/0/1\">Vala Vakilian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behnia_T/0/1/0/all/0/1\">Tina Behnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gill_J/0/1/0/all/0/1\">Jaidev Gill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "Supervised contrastive loss (SCL) is a competitive and often superior\nalternative to the cross-entropy loss for classification. While prior studies\nhave demonstrated that both losses yield symmetric training representations\nunder balanced data, this symmetry breaks under class imbalances. This paper\npresents an intriguing discovery: the introduction of a ReLU activation at the\nfinal layer effectively restores the symmetry in SCL-learned representations.\nWe arrive at this finding analytically, by establishing that the global\nminimizers of an unconstrained features model with SCL loss and entry-wise\nnon-negativity constraints form an orthogonal frame. Extensive experiments\nconducted across various datasets, architectures, and imbalance scenarios\ncorroborate our finding. Importantly, our experiments reveal that the inclusion\nof the ReLU activation restores symmetry without compromising test accuracy.\nThis constitutes the first geometry characterization of SCL under imbalances.\nAdditionally, our analysis and experiments underscore the pivotal role of batch\nselection strategies in representation geometry. By proving necessary and\nsufficient conditions for mini-batch choices that ensure invariant symmetric\nrepresentations, we introduce batch-binding as an efficient strategy that\nguarantees these conditions hold.",
          "link": "http://arxiv.org/abs/2306.07960",
          "publishedOn": "2023-10-21T00:41:39.661Z",
          "wordCount": 731,
          "title": "Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching. (arXiv:2306.07960v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.10649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neklyudov_K/0/1/0/all/0/1\">Kirill Neklyudov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brekelmans_R/0/1/0/all/0/1\">Rob Brekelmans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_A/0/1/0/all/0/1\">Alexander Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atanackovic_L/0/1/0/all/0/1\">Lazar Atanackovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makhzani_A/0/1/0/all/0/1\">Alireza Makhzani</a>",
          "description": "The dynamical formulation of the optimal transport can be extended through\nvarious choices of the underlying geometry ($\\textit{kinetic energy}$), and the\nregularization of density paths ($\\textit{potential energy}$). These\ncombinations yield different variational problems ($\\textit{Lagrangians}$),\nencompassing many variations of the optimal transport problem such as the\nSchr\\\"odinger bridge, unbalanced optimal transport, and optimal transport with\nphysical constraints, among others. In general, the optimal density path is\nunknown, and solving these variational problems can be computationally\nchallenging. Leveraging the dual formulation of the Lagrangians, we propose a\nnovel deep learning based framework approaching all of these problems from a\nunified perspective. Our method does not require simulating or backpropagating\nthrough the trajectories of the learned dynamics, and does not need access to\noptimal couplings. We showcase the versatility of the proposed framework by\noutperforming previous approaches for the single-cell trajectory inference,\nwhere incorporating prior knowledge into the dynamics is crucial for correct\npredictions.",
          "link": "http://arxiv.org/abs/2310.10649",
          "publishedOn": "2023-10-21T00:41:39.654Z",
          "wordCount": 689,
          "title": "A Computational Framework for Solving Wasserstein Lagrangian Flows. (arXiv:2310.10649v2 [cs.LG] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.06949",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saligkaras_D/0/1/0/all/0/1\">Dimitrios Saligkaras</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papageorgiou_V/0/1/0/all/0/1\">Vasileios E. Papageorgiou</a>",
          "description": "Clustering is an unsupervised machine learning methodology where unlabeled\nelements/objects are grouped together aiming to the construction of\nwell-established clusters that their elements are classified according to their\nsimilarity. The goal of this process is to provide a useful aid to the\nresearcher that will help her/him to identify patterns among the data. Dealing\nwith large databases, such patterns may not be easily detectable without the\ncontribution of a clustering algorithm. This article provides a deep\ndescription of the most widely used clustering methodologies accompanied by\nuseful presentations concerning suitable parameter selection and\ninitializations. Simultaneously, this article not only represents a review\nhighlighting the major elements of examined clustering techniques but\nemphasizes the comparison of these algorithms' clustering efficiency based on 3\ndatasets, revealing their existing weaknesses and capabilities through accuracy\nand complexity, during the confrontation of discrete and continuous\nobservations. The produced results help us extract valuable conclusions about\nthe appropriateness of the examined clustering techniques in accordance with\nthe dataset's size.",
          "link": "http://arxiv.org/abs/2207.06949",
          "publishedOn": "2023-10-21T00:41:39.505Z",
          "wordCount": 767,
          "title": "Seeking the Truth Beyond the Data. An Unsupervised Machine Learning Approach. (arXiv:2207.06949v4 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1811.11479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_E/0/1/0/all/0/1\">Eunjeong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seungeun Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyesung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jihong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1\">Mehdi Bennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seong-Lyun Kim</a>",
          "description": "On-device machine learning (ML) enables the training process to exploit a\nmassive amount of user-generated private data samples. To enjoy this benefit,\ninter-device communication overhead should be minimized. With this end, we\npropose federated distillation (FD), a distributed model training algorithm\nwhose communication payload size is much smaller than a benchmark scheme,\nfederated learning (FL), particularly when the model size is large. Moreover,\nuser-generated data samples are likely to become non-IID across devices, which\ncommonly degrades the performance compared to the case with an IID dataset. To\ncope with this, we propose federated augmentation (FAug), where each device\ncollectively trains a generative model, and thereby augments its local data\ntowards yielding an IID dataset. Empirical studies demonstrate that FD with\nFAug yields around 26x less communication overhead while achieving 95-98% test\naccuracy compared to FL.",
          "link": "http://arxiv.org/abs/1811.11479",
          "publishedOn": "2023-10-21T00:41:39.369Z",
          "wordCount": 732,
          "title": "Communication-Efficient On-Device Machine Learning: Federated Distillation and Augmentation under Non-IID Private Data. (arXiv:1811.11479v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.05015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lim_M/0/1/0/all/0/1\">Michael H. Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Becker_T/0/1/0/all/0/1\">Tyler J. Becker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1\">Mykel J. Kochenderfer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomlin_C/0/1/0/all/0/1\">Claire J. Tomlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunberg_Z/0/1/0/all/0/1\">Zachary N. Sunberg</a>",
          "description": "Partially observable Markov decision processes (POMDPs) provide a flexible\nrepresentation for real-world decision and control problems. However, POMDPs\nare notoriously difficult to solve, especially when the state and observation\nspaces are continuous or hybrid, which is often the case for physical systems.\nWhile recent online sampling-based POMDP algorithms that plan with observation\nlikelihood weighting have shown practical effectiveness, a general theory\ncharacterizing the approximation error of the particle filtering techniques\nthat these algorithms use has not previously been proposed. Our main\ncontribution is bounding the error between any POMDP and its corresponding\nfinite sample particle belief MDP (PB-MDP) approximation. This fundamental\nbridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP\nalgorithm to a POMDP by solving the corresponding particle belief MDP, thereby\nextending the convergence guarantees of the MDP algorithm to the POMDP.\nPractically, this is implemented by using the particle filter belief transition\nmodel as the generative model for the MDP solver. While this requires access to\nthe observation density model from the POMDP, it only increases the transition\nsampling complexity of the MDP solver by a factor of $\\mathcal{O}(C)$, where\n$C$ is the number of particles. Thus, when combined with sparse sampling MDP\nalgorithms, this approach can yield algorithms for POMDPs that have no direct\ntheoretical dependence on the size of the state and observation spaces. In\naddition to our theoretical contribution, we perform five numerical experiments\non benchmark POMDPs to demonstrate that a simple MDP algorithm adapted using\nPB-MDP approximation, Sparse-PFT, achieves performance competitive with other\nleading continuous observation POMDP solvers.",
          "link": "http://arxiv.org/abs/2210.05015",
          "publishedOn": "2023-10-21T00:41:39.357Z",
          "wordCount": 843,
          "title": "Optimality Guarantees for Particle Belief Approximation of POMDPs. (arXiv:2210.05015v5 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12975",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daems_R/0/1/0/all/0/1\">Rembert Daems</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opper_M/0/1/0/all/0/1\">Manfred Opper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crevecoeur_G/0/1/0/all/0/1\">Guillaume Crevecoeur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1\">Tolga Birdal</a>",
          "description": "We present a novel variational framework for performing inference in (neural)\nstochastic differential equations (SDEs) driven by Markov-approximate\nfractional Brownian motion (fBM). SDEs offer a versatile tool for modeling\nreal-world continuous-time dynamic systems with inherent noise and randomness.\nCombining SDEs with the powerful inference capabilities of variational methods,\nenables the learning of representative function distributions through\nstochastic gradient descent. However, conventional SDEs typically assume the\nunderlying noise to follow a Brownian motion (BM), which hinders their ability\nto capture long-term dependencies. In contrast, fractional Brownian motion\n(fBM) extends BM to encompass non-Markovian dynamics, but existing methods for\ninferring fBM parameters are either computationally demanding or statistically\ninefficient. In this paper, building upon the Markov approximation of fBM, we\nderive the evidence lower bound essential for efficient variational inference\nof posterior path measures, drawing from the well-established field of\nstochastic analysis. Additionally, we provide a closed-form expression to\ndetermine optimal approximation coefficients. Furthermore, we propose the use\nof neural networks to learn the drift, diffusion and control terms within our\nvariational posterior, leading to the variational training of neural-SDEs. In\nthis framework, we also optimize the Hurst index, governing the nature of our\nfractional noise. Beyond validation on synthetic data, we contribute a novel\narchitecture for variational latent video prediction,-an approach that, to the\nbest of our knowledge, enables the first variational neural-SDE application to\nvideo perception.",
          "link": "http://arxiv.org/abs/2310.12975",
          "publishedOn": "2023-10-21T00:41:39.340Z",
          "wordCount": 765,
          "title": "Variational Inference for SDEs Driven by Fractional Noise. (arXiv:2310.12975v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.10194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+McCarter_C/0/1/0/all/0/1\">Calvin McCarter</a>",
          "description": "Feature preprocessing continues to play a critical role when applying machine\nlearning and statistical methods to tabular data. In this paper, we propose the\nuse of the kernel density integral transformation as a feature preprocessing\nstep. Our approach subsumes the two leading feature preprocessing methods as\nlimiting cases: linear min-max scaling and quantile transformation. We\ndemonstrate that, without hyperparameter tuning, the kernel density integral\ntransformation can be used as a simple drop-in replacement for either method,\noffering protection from the weaknesses of each. Alternatively, with tuning of\na single continuous hyperparameter, we frequently outperform both of these\nmethods. Finally, we show that the kernel density transformation can be\nprofitably applied to statistical data analysis, particularly in correlation\nanalysis and univariate clustering.",
          "link": "http://arxiv.org/abs/2309.10194",
          "publishedOn": "2023-10-21T00:41:39.334Z",
          "wordCount": 621,
          "title": "The Kernel Density Integral Transformation. (arXiv:2309.10194v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12964",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Si_W/0/1/0/all/0/1\">Wenwen Si</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_S/0/1/0/all/0/1\">Sangdon Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Prediction sets capture uncertainty by predicting sets of labels rather than\nindividual labels, enabling downstream decisions to conservatively account for\nall plausible outcomes. Conformal inference algorithms construct prediction\nsets guaranteed to contain the true label with high probability. These\nguarantees fail to hold in the face of distribution shift, which is precisely\nwhen reliable uncertainty quantification can be most useful. We propose a novel\nalgorithm for constructing prediction sets with PAC guarantees in the label\nshift setting. This method estimates the predicted probabilities of the classes\nin a target domain, as well as the confusion matrix, then propagates\nuncertainty in these estimates through a Gaussian elimination algorithm to\ncompute confidence intervals for importance weights. Finally, it uses these\nintervals to construct prediction sets. We evaluate our approach on five\ndatasets: the CIFAR-10, ChestX-Ray and Entity-13 image datasets, the tabular\nCDC Heart dataset, and the AGNews text dataset. Our algorithm satisfies the PAC\nguarantee while producing smaller, more informative, prediction sets compared\nto several baselines.",
          "link": "http://arxiv.org/abs/2310.12964",
          "publishedOn": "2023-10-21T00:41:39.326Z",
          "wordCount": 659,
          "title": "PAC Prediction Sets Under Label Shift. (arXiv:2310.12964v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.09310",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mozafari_Majd_E/0/1/0/all/0/1\">Emadaldin Mozafari-Majd</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Koivunen_V/0/1/0/all/0/1\">Visa Koivunen</a>",
          "description": "This paper introduces a new regularized version of the robust\n$\\tau$-regression estimator for analyzing high-dimensional datasets subject to\ngross contamination in the response variables and covariates (explanatory\nvariables). The resulting estimator, termed adaptive $\\tau$-Lasso, is robust to\noutliers and high-leverage points. It also incorporates an adaptive\n$\\ell_1$-norm penalty term, which enables the selection of relevant variables\nand reduces the bias associated with large true regression coefficients. More\nspecifically, this adaptive $\\ell_1$-norm penalty term assigns a weight to each\nregression coefficient. For a fixed number of predictors $p$, we show that the\nadaptive $\\tau$-Lasso has the oracle property, ensuring both variable-selection\nconsistency and asymptotic normality. Asymptotic normality applies only to the\nentries of the regression vector corresponding to the true support, assuming\nknowledge of the true regression vector support. We characterize its robustness\nvia the finite-sample breakdown point and the influence function. We carry out\nextensive simulations and observe that the class of $\\tau$-Lasso estimators\nexhibits robustness and reliable performance in both contaminated and\nuncontaminated data settings. We also validate our theoretical findings on\nrobustness properties through simulation experiments. In the face of outliers\nand high-leverage points, the adaptive $\\tau$-Lasso and $\\tau$-Lasso estimators\nachieve the best performance or close-to-best performance in terms of\nprediction and variable selection accuracy compared to other competing\nregularized estimators for all scenarios considered in this study. Therefore,\nthe adaptive $\\tau$-Lasso and $\\tau$-Lasso estimators can be effectively\nemployed for a variety of sparse linear regression problems, particularly in\nhigh-dimensional settings and when the data is contaminated by outliers and\nhigh-leverage points.",
          "link": "http://arxiv.org/abs/2304.09310",
          "publishedOn": "2023-10-21T00:41:39.312Z",
          "wordCount": 769,
          "title": "The Adaptive $\\tau$-Lasso: Robustness and Oracle Properties. (arXiv:2304.09310v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.03810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kirchhof_M/0/1/0/all/0/1\">Michael Kirchhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mucsanyi_B/0/1/0/all/0/1\">B&#xe1;lint Mucs&#xe1;nyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seong Joon Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1\">Enkelejda Kasneci</a>",
          "description": "Representation learning has significantly driven the field to develop\npretrained models that can act as a valuable starting point when transferring\nto new datasets. With the rising demand for reliable machine learning and\nuncertainty quantification, there is a need for pretrained models that not only\nprovide embeddings but also transferable uncertainty estimates. To guide the\ndevelopment of such models, we propose the Uncertainty-aware Representation\nLearning (URL) benchmark. Besides the transferability of the representations,\nit also measures the zero-shot transferability of the uncertainty estimate\nusing a novel metric. We apply URL to evaluate eleven uncertainty quantifiers\nthat are pretrained on ImageNet and transferred to eight downstream datasets.\nWe find that approaches that focus on the uncertainty of the representation\nitself or estimate the prediction risk directly outperform those that are based\non the probabilities of upstream classes. Yet, achieving transferable\nuncertainty quantification remains an open challenge. Our findings indicate\nthat it is not necessarily in conflict with traditional representation learning\ngoals. Code is provided under https://github.com/mkirchhof/url .",
          "link": "http://arxiv.org/abs/2307.03810",
          "publishedOn": "2023-10-21T00:41:39.305Z",
          "wordCount": 731,
          "title": "URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates. (arXiv:2307.03810v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12882",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Winter_S/0/1/0/all/0/1\">Steven Winter</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Melikechi_O/0/1/0/all/0/1\">Omar Melikechi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dunson_D/0/1/0/all/0/1\">David B. Dunson</a>",
          "description": "Gibbs posteriors are proportional to a prior distribution multiplied by an\nexponentiated loss function, with a key tuning parameter weighting information\nin the loss relative to the prior and providing a control of posterior\nuncertainty. Gibbs posteriors provide a principled framework for\nlikelihood-free Bayesian inference, but in many situations, including a single\ntuning parameter inevitably leads to poor uncertainty quantification. In\nparticular, regardless of the value of the parameter, credible regions have far\nfrom the nominal frequentist coverage even in large samples. We propose a\nsequential extension to Gibbs posteriors to address this problem. We prove the\nproposed sequential posterior exhibits concentration and a Bernstein-von Mises\ntheorem, which holds under easy to verify conditions in Euclidean space and on\nmanifolds. As a byproduct, we obtain the first Bernstein-von Mises theorem for\ntraditional likelihood-based Bayesian posteriors on manifolds. All methods are\nillustrated with an application to principal component analysis.",
          "link": "http://arxiv.org/abs/2310.12882",
          "publishedOn": "2023-10-21T00:41:39.297Z",
          "wordCount": 647,
          "title": "Sequential Gibbs Posteriors with Applications to Principal Component Analysis. (arXiv:2310.12882v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.01225",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gonon_A/0/1/0/all/0/1\">Antoine Gonon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brisebarre_N/0/1/0/all/0/1\">Nicolas Brisebarre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Riccietti_E/0/1/0/all/0/1\">Elisa Riccietti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gribonval_R/0/1/0/all/0/1\">R&#xe9;mi Gribonval</a>",
          "description": "This work introduces the first toolkit around path-norms that is fully able\nto encompass general DAG ReLU networks with biases, skip connections and any\noperation based on the extraction of order statistics: max pooling, GroupSort\netc. This toolkit notably allows us to establish generalization bounds for\nmodern neural networks that are not only the most widely applicable path-norm\nbased ones, but also recover or beat the sharpest known bounds of this type.\nThese extended path-norms further enjoy the usual benefits of path-norms: ease\nof computation, invariance under the symmetries of the network, and improved\nsharpness on feedforward networks compared to the product of operators' norms,\nanother complexity measure most commonly used.\n\nThe versatility of the toolkit and its ease of implementation allow us to\nchallenge the concrete promises of path-norm-based generalization bounds, by\nnumerically evaluating the sharpest known bounds for ResNets on ImageNet.",
          "link": "http://arxiv.org/abs/2310.01225",
          "publishedOn": "2023-10-21T00:41:39.290Z",
          "wordCount": 676,
          "title": "A path-norm toolkit for modern networks: consequences, promises and challenges. (arXiv:2310.01225v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.09983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fluri_L/0/1/0/all/0/1\">Lukas Fluri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paleka_D/0/1/0/all/0/1\">Daniel Paleka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tramer_F/0/1/0/all/0/1\">Florian Tram&#xe8;r</a>",
          "description": "If machine learning models were to achieve superhuman abilities at various\nreasoning or decision-making tasks, how would we go about evaluating such\nmodels, given that humans would necessarily be poor proxies for ground truth?\nIn this paper, we propose a framework for evaluating superhuman models via\nconsistency checks. Our premise is that while the correctness of superhuman\ndecisions may be impossible to evaluate, we can still surface mistakes if the\nmodel's decisions fail to satisfy certain logical, human-interpretable rules.\nWe instantiate our framework on three tasks where correctness of decisions is\nhard to evaluate due to either superhuman model abilities, or to otherwise\nmissing ground truth: evaluating chess positions, forecasting future events,\nand making legal judgments. We show that regardless of a model's (possibly\nsuperhuman) performance on these tasks, we can discover logical inconsistencies\nin decision making. For example: a chess engine assigning opposing valuations\nto semantically identical boards; GPT-4 forecasting that sports records will\nevolve non-monotonically over time; or an AI judge assigning bail to a\ndefendant only after we add a felony to their criminal record.",
          "link": "http://arxiv.org/abs/2306.09983",
          "publishedOn": "2023-10-21T00:41:39.254Z",
          "wordCount": 726,
          "title": "Evaluating Superhuman Models with Consistency Checks. (arXiv:2306.09983v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12842",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wood_D/0/1/0/all/0/1\">Danny Wood</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papamarkou_T/0/1/0/all/0/1\">Theodore Papamarkou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Benatan_M/0/1/0/all/0/1\">Matt Benatan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Allmendinger_R/0/1/0/all/0/1\">Richard Allmendinger</a>",
          "description": "In order to trust the predictions of a machine learning algorithm, it is\nnecessary to understand the factors that contribute to those predictions. In\nthe case of probabilistic and uncertainty-aware models, it is necessary to\nunderstand not only the reasons for the predictions themselves, but also the\nmodel's level of confidence in those predictions. In this paper, we show how\nexisting methods in explainability can be extended to uncertainty-aware models\nand how such extensions can be used to understand the sources of uncertainty in\na model's predictive distribution. In particular, by adapting permutation\nfeature importance, partial dependence plots, and individual conditional\nexpectation plots, we demonstrate that novel insights into model behaviour may\nbe obtained and that these methods can be used to measure the impact of\nfeatures on both the entropy of the predictive distribution and the\nlog-likelihood of the ground truth labels under that distribution. With\nexperiments using both synthetic and real-world data, we demonstrate the\nutility of these approaches in understanding both the sources of uncertainty\nand their impact on model performance.",
          "link": "http://arxiv.org/abs/2310.12842",
          "publishedOn": "2023-10-21T00:41:39.194Z",
          "wordCount": 687,
          "title": "Model-agnostic variable importance for predictive uncertainty: an entropy-based approach. (arXiv:2310.12842v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.01746",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kleppe_T/0/1/0/all/0/1\">Tore Selland Kleppe</a>",
          "description": "A metric tensor for Riemann manifold Monte Carlo particularly suited for\nnon-linear Bayesian hierarchical models is proposed. The metric tensor is built\nfrom symmetric positive semidefinite log-density gradient covariance (LGC)\nmatrices, which are also proposed and further explored here. The LGCs\ngeneralize the Fisher information matrix by measuring the joint information\ncontent and dependence structure of both a random variable and the parameters\nof said variable. Consequently, positive definite Fisher/LGC-based metric\ntensors may be constructed not only from the observation likelihoods as is\ncurrent practice, but also from arbitrarily complicated non-linear prior/latent\nvariable structures, provided the LGC may be derived for each conditional\ndistribution used to construct said structures. The proposed methodology is\nhighly automatic and allows for exploitation of any sparsity associated with\nthe model in question. When implemented in conjunction with a Riemann manifold\nvariant of the recently proposed numerical generalized randomized Hamiltonian\nMonte Carlo processes, the proposed methodology is highly competitive, in\nparticular for the more challenging target distributions associated with\nBayesian hierarchical models.",
          "link": "http://arxiv.org/abs/2211.01746",
          "publishedOn": "2023-10-21T00:41:39.141Z",
          "wordCount": 694,
          "title": "Log-density gradient covariance and automatic metric tensors for Riemann manifold Monte Carlo methods. (arXiv:2211.01746v2 [stat.CO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.14090",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Dai_Z/0/1/0/all/0/1\">Zhenyu Dai</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Moews_B/0/1/0/all/0/1\">Ben Moews</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Vilalta_R/0/1/0/all/0/1\">Ricardo Vilalta</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Dave_R/0/1/0/all/0/1\">Romeel Dave</a>",
          "description": "Physics-informed neural networks have emerged as a coherent framework for\nbuilding predictive models that combine statistical patterns with domain\nknowledge. The underlying notion is to enrich the optimization loss function\nwith known relationships to constrain the space of possible solutions.\nHydrodynamic simulations are a core constituent of modern cosmology, while the\nrequired computations are both expensive and time-consuming. At the same time,\nthe comparatively fast simulation of dark matter requires fewer resources,\nwhich has led to the emergence of machine learning algorithms for baryon\ninpainting as an active area of research; here, recreating the scatter found in\nhydrodynamic simulations is an ongoing challenge. This paper presents the first\napplication of physics-informed neural networks to baryon inpainting by\ncombining advances in neural network architectures with physical constraints,\ninjecting theory on baryon conversion efficiency into the model loss function.\nWe also introduce a punitive prediction comparison based on the\nKullback-Leibler divergence, which enforces scatter reproduction. By\nsimultaneously extracting the complete set of baryonic properties for the Simba\nsuite of cosmological simulations, our results demonstrate improved accuracy of\nbaryonic predictions based on dark matter halo properties, successful recovery\nof the fundamental metallicity relation, and retrieve scatter that traces the\ntarget simulation's distribution.",
          "link": "http://arxiv.org/abs/2303.14090",
          "publishedOn": "2023-10-21T00:41:39.080Z",
          "wordCount": 758,
          "title": "Physics-informed neural networks in the recreation of hydrodynamic simulations from dark matter. (arXiv:2303.14090v2 [astro-ph.CO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.12410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brehmer_J/0/1/0/all/0/1\">Johann Brehmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bose_J/0/1/0/all/0/1\">Joey Bose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haan_P/0/1/0/all/0/1\">Pim de Haan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1\">Taco Cohen</a>",
          "description": "Embodied agents operate in a structured world, often solving tasks with\nspatial, temporal, and permutation symmetries. Most algorithms for planning and\nmodel-based reinforcement learning (MBRL) do not take this rich geometric\nstructure into account, leading to sample inefficiency and poor generalization.\nWe introduce the Equivariant Diffuser for Generating Interactions (EDGI), an\nalgorithm for MBRL and planning that is equivariant with respect to the product\nof the spatial symmetry group SE(3), the discrete-time translation group Z, and\nthe object permutation group Sn. EDGI follows the Diffuser framework (Janner et\nal., 2022) in treating both learning a world model and planning in it as a\nconditional generative modeling problem, training a diffusion model on an\noffline trajectory dataset. We introduce a new SE(3)xZxSn-equivariant diffusion\nmodel that supports multiple representations. We integrate this model in a\nplanning loop, where conditioning and classifier guidance let us softly break\nthe symmetry for specific tasks as needed. On object manipulation and\nnavigation tasks, EDGI is substantially more sample efficient and generalizes\nbetter across the symmetry group than non-equivariant models.",
          "link": "http://arxiv.org/abs/2303.12410",
          "publishedOn": "2023-10-21T00:41:39.073Z",
          "wordCount": 713,
          "title": "EDGI: Equivariant Diffusion for Planning with Embodied Agents. (arXiv:2303.12410v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tiapkin_D/0/1/0/all/0/1\">Daniil Tiapkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morozov_N/0/1/0/all/0/1\">Nikita Morozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumov_A/0/1/0/all/0/1\">Alexey Naumov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>",
          "description": "The recently proposed generative flow networks (GFlowNets) are a method of\ntraining a policy to sample compositional discrete objects with probabilities\nproportional to a given reward via a sequence of actions. GFlowNets exploit the\nsequential nature of the problem, drawing parallels with reinforcement learning\n(RL). Our work extends the connection between RL and GFlowNets to a general\ncase. We demonstrate how the task of learning a generative flow network can be\nefficiently redefined as an entropy-regularized RL problem with a specific\nreward and regularizer structure. Furthermore, we illustrate the practical\nefficiency of this reformulation by applying standard soft RL algorithms to\nGFlowNet training across several probabilistic modeling tasks. Contrary to\npreviously reported results, we show that entropic RL approaches can be\ncompetitive against established GFlowNet training methods. This perspective\nopens a direct path for integrating reinforcement learning principles into the\nrealm of generative flow networks.",
          "link": "http://arxiv.org/abs/2310.12934",
          "publishedOn": "2023-10-21T00:41:39.054Z",
          "wordCount": 647,
          "title": "Generative Flow Networks as Entropy-Regularized RL. (arXiv:2310.12934v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.08724",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Goan_E/0/1/0/all/0/1\">Ethan Goan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Perrin_D/0/1/0/all/0/1\">Dimitri Perrin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mengersen_K/0/1/0/all/0/1\">Kerrie Mengersen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fookes_C/0/1/0/all/0/1\">Clinton Fookes</a>",
          "description": "Inference on modern Bayesian Neural Networks (BNNs) often relies on a\nvariational inference treatment, imposing violated assumptions of independence\nand the form of the posterior. Traditional MCMC approaches avoid these\nassumptions at the cost of increased computation due to its incompatibility to\nsubsampling of the likelihood. New Piecewise Deterministic Markov Process\n(PDMP) samplers permit subsampling, though introduce a model specific\ninhomogenous Poisson Process (IPPs) which is difficult to sample from. This\nwork introduces a new generic and adaptive thinning scheme for sampling from\nthese IPPs, and demonstrates how this approach can accelerate the application\nof PDMPs for inference in BNNs. Experimentation illustrates how inference with\nthese methods is computationally feasible, can improve predictive accuracy,\nMCMC mixing performance, and provide informative uncertainty measurements when\ncompared against other approximate inference schemes.",
          "link": "http://arxiv.org/abs/2302.08724",
          "publishedOn": "2023-10-21T00:41:39.047Z",
          "wordCount": 658,
          "title": "Piecewise Deterministic Markov Processes for Bayesian Neural Networks. (arXiv:2302.08724v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2201.13001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dey_J/0/1/0/all/0/1\">Jayanta Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeVine_W/0/1/0/all/0/1\">Will LeVine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoyin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1\">Ashwin De Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomita_T/0/1/0/all/0/1\">Tyler M. Tomita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geisa_A/0/1/0/all/0/1\">Ali Geisa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1\">Tiffany Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desman_J/0/1/0/all/0/1\">Jacob Desman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>",
          "description": "Deep discriminative approaches like random forests and deep neural networks\nhave recently found applications in many important real-world scenarios.\nHowever, deploying these learning algorithms in safety-critical applications\nraises concerns, particularly when it comes to ensuring confidence calibration\nfor both in-distribution and out-of-distribution data points. Many popular\nmethods for in-distribution (ID) calibration, such as isotonic regression and\nPlatt's sigmoidal regression, exhibit excellent ID calibration performance but\noften at the cost of classification accuracy. Moreover, these methods are not\ncalibrated for the entire feature space, leading to overconfidence in the case\nof out-of-distribution (OOD) samples. In this paper, we leveraged the fact that\ndeep models, including both random forests and deep-nets, learn internal\nrepresentations which are unions of polytopes with affine activation functions\nto conceptualize them both as partitioning rules of the feature space. We\nreplace the affine function in each polytope populated by the training data\nwith a Gaussian kernel. We propose sufficient conditions for our proposed\nmethods to be consistent estimators of the corresponding class conditional\ndensities. Moreover, our experiments on both tabular and vision benchmarks show\nthat the proposed approaches obtain well-calibrated posteriors while mostly\npreserving or improving the classification accuracy of the original algorithm\nfor in-distribution region, and extrapolates beyond the training data to handle\nout-of-distribution inputs appropriately.",
          "link": "http://arxiv.org/abs/2201.13001",
          "publishedOn": "2023-10-21T00:41:38.882Z",
          "wordCount": 817,
          "title": "Deep Discriminative to Kernel Density Networks for Calibrated Inference. (arXiv:2201.13001v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sehgal_A/0/1/0/all/0/1\">Atharva Sehgal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grayeli_A/0/1/0/all/0/1\">Arya Grayeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1\">Swarat Chaudhuri</a>",
          "description": "We introduce Cosmos, a framework for object-centric world modeling that is\ndesigned for compositional generalization (CG), i.e., high performance on\nunseen input scenes obtained through the composition of known visual \"atoms.\"\nThe central insight behind Cosmos is the use of a novel form of neurosymbolic\ngrounding. Specifically, the framework introduces two new tools: (i)\nneurosymbolic scene encodings, which represent each entity in a scene using a\nreal vector computed using a neural encoder, as well as a vector of composable\nsymbols describing attributes of the entity, and (ii) a neurosymbolic attention\nmechanism that binds these entities to learned rules of interaction. Cosmos is\nend-to-end differentiable; also, unlike traditional neurosymbolic methods that\nrequire representations to be manually mapped to symbols, it computes an\nentity's symbolic attributes using vision-language foundation models. Through\nan evaluation that considers two different forms of CG on an established\nblocks-pushing domain, we show that the framework establishes a new\nstate-of-the-art for CG in world modeling.",
          "link": "http://arxiv.org/abs/2310.12690",
          "publishedOn": "2023-10-21T00:41:38.870Z",
          "wordCount": 663,
          "title": "Neurosymbolic Grounding for Compositional World Models. (arXiv:2310.12690v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12806",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gauss_J/0/1/0/all/0/1\">Jana Gauss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scheipl_F/0/1/0/all/0/1\">Fabian Scheipl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Herrmann_M/0/1/0/all/0/1\">Moritz Herrmann</a>",
          "description": "Whether class labels in a given data set correspond to meaningful clusters is\ncrucial for the evaluation of clustering algorithms using real-world data sets.\nThis property can be quantified by separability measures. A review of the\nexisting literature shows that neither classification-based complexity measures\nnor cluster validity indices (CVIs) adequately incorporate the central aspects\nof separability for density-based clustering: between-class separation and\nwithin-class connectedness. A newly developed measure (density cluster\nseparability index, DCSI) aims to quantify these two characteristics and can\nalso be used as a CVI. Extensive experiments on synthetic data indicate that\nDCSI correlates strongly with the performance of DBSCAN measured via the\nadjusted rand index (ARI) but lacks robustness when it comes to multi-class\ndata sets with overlapping classes that are ill-suited for density-based hard\nclustering. Detailed evaluation on frequently used real-world data sets shows\nthat DCSI can correctly identify touching or overlapping classes that do not\nform meaningful clusters.",
          "link": "http://arxiv.org/abs/2310.12806",
          "publishedOn": "2023-10-21T00:41:38.845Z",
          "wordCount": 670,
          "title": "DCSI -- An improved measure of cluster separability based on separation and connectedness. (arXiv:2310.12806v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maison_L/0/1/0/all/0/1\">Lucas Maison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bourboux_H/0/1/0/all/0/1\">H&#xe9;lion du Mas des Bourboux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courtat_T/0/1/0/all/0/1\">Thomas Courtat</a>",
          "description": "Compressing neural networks is a key step when deploying models for real-time\nor embedded applications. Factorizing the model's matrices using low-rank\napproximations is a promising method for achieving compression. While it is\npossible to set the rank before training, this approach is neither flexible nor\noptimal. In this work, we propose a post-training rank-selection method called\nRank-Tuning that selects a different rank for each matrix. Used in combination\nwith training adaptations, our method achieves high compression rates with no\nor little performance degradation. Our numerical experiments on signal\nprocessing tasks show that we can compress recurrent neural networks up to 14x\nwith at most 1.4% relative performance reduction.",
          "link": "http://arxiv.org/abs/2310.12688",
          "publishedOn": "2023-10-21T00:41:38.836Z",
          "wordCount": 621,
          "title": "Compression of Recurrent Neural Networks using Matrix Factorization. (arXiv:2310.12688v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12781",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xiong_X/0/1/0/all/0/1\">Xiaofei Xiong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ju_N/0/1/0/all/0/1\">Nianqiao P. Ju</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Sanguo Zhang</a>",
          "description": "Many modern statistical analysis and machine learning applications require\ntraining models on sensitive user data. Differential privacy provides a formal\nguarantee that individual-level information about users does not leak. In this\nframework, randomized algorithms inject calibrated noise into the confidential\ndata, resulting in privacy-protected datasets or queries. However, restricting\naccess to only the privatized data during statistical analysis makes it\ncomputationally challenging to perform valid inferences on parameters\nunderlying the confidential data. In this work, we propose simulation-based\ninference methods from privacy-protected datasets. Specifically, we use neural\nconditional density estimators as a flexible family of distributions to\napproximate the posterior distribution of model parameters given the observed\nprivate query results. We illustrate our methods on discrete time-series data\nunder an infectious disease model and on ordinary linear regression models.\nIllustrating the privacy-utility trade-off, our experiments and analysis\ndemonstrate the necessity and feasibility of designing valid statistical\ninference procedures to correct for biases introduced by the privacy-protection\nmechanisms.",
          "link": "http://arxiv.org/abs/2310.12781",
          "publishedOn": "2023-10-21T00:41:38.806Z",
          "wordCount": 650,
          "title": "Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12595",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wharrie_S/0/1/0/all/0/1\">Sophie Wharrie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "The key challenge underlying machine learning is generalisation to new data.\nThis work studies generalisation for datasets consisting of related tasks that\nmay differ in causal mechanisms. For example, observational medical data for\ncomplex diseases suffers from heterogeneity in causal mechanisms of disease\nacross patients, creating challenges for machine learning algorithms that need\nto generalise to new patients outside of the training dataset. Common\napproaches for learning supervised models with heterogeneous datasets include\nlearning a global model for the entire dataset, learning local models for each\ntasks' data, or utilising hierarchical, meta-learning and multi-task learning\napproaches to learn how to generalise from data pooled across multiple tasks.\nIn this paper we propose causal similarity-based hierarchical Bayesian models\nto improve generalisation to new tasks by learning how to pool data from\ntraining tasks with similar causal mechanisms. We apply this general modelling\nprinciple to Bayesian neural networks and compare a variety of methods for\nestimating causal task similarity (for both known and unknown causal models).\nWe demonstrate the benefits of our approach and applicability to real world\nproblems through a range of experiments on simulated and real data.",
          "link": "http://arxiv.org/abs/2310.12595",
          "publishedOn": "2023-10-21T00:41:38.776Z",
          "wordCount": 679,
          "title": "Causal Similarity-Based Hierarchical Bayesian Models. (arXiv:2310.12595v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12667",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Karimi_B/0/1/0/all/0/1\">Belhal Karimi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_J/0/1/0/all/0/1\">Jianwen Xie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>",
          "description": "We propose in this paper, STANLEY, a STochastic gradient ANisotropic LangEvin\ndYnamics, for sampling high dimensional data. With the growing efficacy and\npotential of Energy-Based modeling, also known as non-normalized probabilistic\nmodeling, for modeling a generative process of different natures of high\ndimensional data observations, we present an end-to-end learning algorithm for\nEnergy-Based models (EBM) with the purpose of improving the quality of the\nresulting sampled data points. While the unknown normalizing constant of EBMs\nmakes the training procedure intractable, resorting to Markov Chain Monte Carlo\n(MCMC) is in general a viable option. Realizing what MCMC entails for the EBM\ntraining, we propose in this paper, a novel high dimensional sampling method,\nbased on an anisotropic stepsize and a gradient-informed covariance matrix,\nembedded into a discretized Langevin diffusion. We motivate the necessity for\nan anisotropic update of the negative samples in the Markov Chain by the\nnonlinearity of the backbone of the EBM, here a Convolutional Neural Network.\nOur resulting method, namely STANLEY, is an optimization algorithm for training\nEnergy-Based models via our newly introduced MCMC method. We provide a\ntheoretical understanding of our sampling scheme by proving that the sampler\nleads to a geometrically uniformly ergodic Markov Chain. Several image\ngeneration experiments are provided in our paper to show the effectiveness of\nour method.",
          "link": "http://arxiv.org/abs/2310.12667",
          "publishedOn": "2023-10-21T00:41:38.769Z",
          "wordCount": 731,
          "title": "STANLEY: Stochastic Gradient Anisotropic Langevin Dynamics for Learning Energy-Based Models. (arXiv:2310.12667v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12822",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Carrizosa_E/0/1/0/all/0/1\">Emilio Carrizosa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramirez_Ayerbe_J/0/1/0/all/0/1\">Jasone Ram&#xed;rez-Ayerbe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Morales_D/0/1/0/all/0/1\">Dolores Romero Morales</a>",
          "description": "Due to the increasing use of Machine Learning models in high stakes decision\nmaking settings, it has become increasingly important to have tools to\nunderstand how models arrive at decisions. Assuming a trained Supervised\nClassification model, explanations can be obtained via counterfactual analysis:\na counterfactual explanation of an instance indicates how this instance should\nbe minimally modified so that the perturbed instance is classified in the\ndesired class by the Machine Learning classification model. Most of the\nCounterfactual Analysis literature focuses on the single-instance\nsingle-counterfactual setting, in which the analysis is done for one single\ninstance to provide one single explanation. Taking a stakeholder's perspective,\nin this paper we introduce the so-called collective counterfactual\nexplanations. By means of novel Mathematical Optimization models, we provide a\ncounterfactual explanation for each instance in a group of interest, so that\nthe total cost of the perturbations is minimized under some linking\nconstraints. Making the process of constructing counterfactuals collective\ninstead of individual enables us to detect the features that are critical to\nthe entire dataset to have the individuals classified in the desired class. Our\nmethodology allows for some instances to be treated individually, performing\nthe collective counterfactual analysis for a fraction of records of the group\nof interest. This way, outliers are identified and handled appropriately. Under\nsome assumptions on the classifier and the space in which counterfactuals are\nsought, finding collective counterfactuals is reduced to solving a convex\nquadratic linearly constrained mixed integer optimization problem, which, for\ndatasets of moderate size, can be solved to optimality using existing solvers.\nThe performance of our approach is illustrated on real-world datasets,\ndemonstrating its usefulness.",
          "link": "http://arxiv.org/abs/2310.12822",
          "publishedOn": "2023-10-21T00:41:38.760Z",
          "wordCount": 840,
          "title": "Generating collective counterfactual explanations in score-based classification via mathematical optimization. (arXiv:2310.12822v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deora_P/0/1/0/all/0/1\">Puneesh Deora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaderi_R/0/1/0/all/0/1\">Rouzbeh Ghaderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taheri_H/0/1/0/all/0/1\">Hossein Taheri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>",
          "description": "The training and generalization dynamics of the Transformer's core mechanism,\nnamely the Attention mechanism, remain under-explored. Besides, existing\nanalyses primarily focus on single-head attention. Inspired by the demonstrated\nbenefits of overparameterization when training fully-connected networks, we\ninvestigate the potential optimization and generalization advantages of using\nmultiple attention heads. Towards this goal, we derive convergence and\ngeneralization guarantees for gradient-descent training of a single-layer\nmulti-head self-attention model, under a suitable realizability condition on\nthe data. We then establish primitive conditions on the initialization that\nensure realizability holds. Finally, we demonstrate that these conditions are\nsatisfied for a simple tokenized-mixture model. We expect the analysis can be\nextended to various data-model and architecture variations.",
          "link": "http://arxiv.org/abs/2310.12680",
          "publishedOn": "2023-10-21T00:41:38.731Z",
          "wordCount": 639,
          "title": "On the Optimization and Generalization of Multi-head Attention. (arXiv:2310.12680v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giambagli_L/0/1/0/all/0/1\">Lorenzo Giambagli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buffoni_L/0/1/0/all/0/1\">Lorenzo Buffoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chicchi_L/0/1/0/all/0/1\">Lorenzo Chicchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fanelli_D/0/1/0/all/0/1\">Duccio Fanelli</a>",
          "description": "In theoretical ML, the teacher-student paradigm is often employed as an\neffective metaphor for real-life tuition. The above scheme proves particularly\nrelevant when the student network is overparameterized as compared to the\nteacher network. Under these operating conditions, it is tempting to speculate\nthat the student ability to handle the given task could be eventually stored in\na sub-portion of the whole network. This latter should be to some extent\nreminiscent of the frozen teacher structure, according to suitable metrics,\nwhile being approximately invariant across different architectures of the\nstudent candidate network. Unfortunately, state-of-the-art conventional\nlearning techniques could not help in identifying the existence of such an\ninvariant subnetwork, due to the inherent degree of non-convexity that\ncharacterizes the examined problem. In this work, we take a leap forward by\nproposing a radically different optimization scheme which builds on a spectral\nrepresentation of the linear transfer of information between layers. The\ngradient is hence calculated with respect to both eigenvalues and eigenvectors\nwith negligible increase in terms of computational and complexity load, as\ncompared to standard training algorithms. Working in this framework, we could\nisolate a stable student substructure, that mirrors the true complexity of the\nteacher in terms of computing neurons, path distribution and topological\nattributes. When pruning unimportant nodes of the trained student, as follows a\nranking that reflects the optimized eigenvalues, no degradation in the recorded\nperformance is seen above a threshold that corresponds to the effective teacher\nsize. The observed behavior can be pictured as a genuine second-order phase\ntransition that bears universality traits.",
          "link": "http://arxiv.org/abs/2310.12612",
          "publishedOn": "2023-10-21T00:41:38.696Z",
          "wordCount": 805,
          "title": "How a student becomes a teacher: learning and forgetting through Spectral methods. (arXiv:2310.12612v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12447",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_A/0/1/0/all/0/1\">Abhisek Chakraborty</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Anirban Bhattacharya</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pati_D/0/1/0/all/0/1\">Debdeep Pati</a>",
          "description": "We commonly encounter the problem of identifying an optimally weight adjusted\nversion of the empirical distribution of observed data, adhering to predefined\nconstraints on the weights. Such constraints often manifest as restrictions on\nthe moments, tail behaviour, shapes, number of modes, etc., of the resulting\nweight adjusted empirical distribution. In this article, we substantially\nenhance the flexibility of such methodology by introducing a nonparametrically\nimbued distributional constraints on the weights, and developing a general\nframework leveraging the maximum entropy principle and tools from optimal\ntransport. The key idea is to ensure that the maximum entropy weight adjusted\nempirical distribution of the observed data is close to a pre-specified\nprobability distribution in terms of the optimal transport metric while\nallowing for subtle departures. The versatility of the framework is\ndemonstrated in the context of three disparate applications where data\nre-weighting is warranted to satisfy side constraints on the optimization\nproblem at the heart of the statistical task: namely, portfolio allocation,\nsemi-parametric inference for complex surveys, and ensuring algorithmic\nfairness in machine learning algorithms.",
          "link": "http://arxiv.org/abs/2310.12447",
          "publishedOn": "2023-10-21T00:41:38.690Z",
          "wordCount": 677,
          "title": "Constrained Reweighting of Distributions: an Optimal Transport Approach. (arXiv:2310.12447v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12743",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Flouris_K/0/1/0/all/0/1\">Kyriakos Flouris</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Konukoglu_E/0/1/0/all/0/1\">Ender Konukoglu</a>",
          "description": "Manifold learning flows are a class of generative modelling techniques that\nassume a low-dimensional manifold description of the data. The embedding of\nsuch manifold into the high-dimensional space of the data is achieved via\nlearnable invertible transformations. Therefore, once the manifold is properly\naligned via a reconstruction loss, the probability density is tractable on the\nmanifold and maximum likelihood can be used optimize the network parameters.\nNaturally, the lower-dimensional representation of the data requires an\ninjective-mapping. Recent approaches were able to enforce that density aligns\nwith the modelled manifold, while efficiently calculating the density\nvolume-change term when embedding to the higher-dimensional space. However,\nunless the injective-mapping is analytically predefined, the learned manifold\nis not necessarily an efficient representation of the data. Namely, the latent\ndimensions of such models frequently learn an entangled intrinsic basis with\ndegenerate information being stored in each dimension. Alternatively, if a\nlocally orthogonal and/or sparse basis is to be learned, here coined canonical\nintrinsic basis, it can serve in learning a more compact latent space\nrepresentation. Towards this end, we propose a canonical manifold learning flow\nmethod, where a novel optimization objective enforces the transformation matrix\nto have few prominent and orthogonal basis functions. Canonical manifold flow\nyields a more efficient use of the latent space, automatically generating fewer\nprominent and distinct dimensions to represent data, and consequently a better\napproximation of target distributions than other manifold flow methods in most\nexperiments we conducted, resulting in lower FID scores.",
          "link": "http://arxiv.org/abs/2310.12743",
          "publishedOn": "2023-10-21T00:41:38.595Z",
          "wordCount": 739,
          "title": "Canonical normalizing flows for manifold learning. (arXiv:2310.12743v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Barbier__Chebbah_A/0/1/0/all/0/1\">Alex Barbier--Chebbah</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Vestergaard_C/0/1/0/all/0/1\">Christian L. Vestergaard</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Masson_J/0/1/0/all/0/1\">Jean-Baptiste Masson</a> (IP, CNRS, UPCit&#xe9;), <a href=\"http://arxiv.org/find/stat/1/au:+Boursier_E/0/1/0/all/0/1\">Etienne Boursier</a> (CELESTE)",
          "description": "Entropy maximization and free energy minimization are general physical\nprinciples for modeling the dynamics of various physical systems. Notable\nexamples include modeling decision-making within the brain using the\nfree-energy principle, optimizing the accuracy-complexity trade-off when\naccessing hidden variables with the information bottleneck principle (Tishby et\nal., 2000), and navigation in random environments using information\nmaximization (Vergassola et al., 2007). Built on this principle, we propose a\nnew class of bandit algorithms that maximize an approximation to the\ninformation of a key variable within the system. To this end, we develop an\napproximated analytical physics-based representation of an entropy to forecast\nthe information gain of each action and greedily choose the one with the\nlargest information gain. This method yields strong performances in classical\nbandit settings. Motivated by its empirical success, we prove its asymptotic\noptimality for the two-armed bandit problem with Gaussian rewards. Owing to its\nability to encompass the system's properties in a global physical functional,\nthis approach can be efficiently adapted to more complex bandit settings,\ncalling for further investigation of information maximization approaches for\nmulti-armed bandit problems.",
          "link": "http://arxiv.org/abs/2310.12563",
          "publishedOn": "2023-10-21T00:41:38.484Z",
          "wordCount": 689,
          "title": "Approximate information maximization for bandit games. (arXiv:2310.12563v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12437",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hanchi_A/0/1/0/all/0/1\">Ayoub El Hanchi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>",
          "description": "We study the performance of empirical risk minimization on the $p$-norm\nlinear regression problem for $p \\in (1, \\infty)$. We show that, in the\nrealizable case, under no moment assumptions, and up to a\ndistribution-dependent constant, $O(d)$ samples are enough to exactly recover\nthe target. Otherwise, for $p \\in [2, \\infty)$, and under weak moment\nassumptions on the target and the covariates, we prove a high probability\nexcess risk bound on the empirical risk minimizer whose leading term matches,\nup to a constant that depends only on $p$, the asymptotically exact rate. We\nextend this result to the case $p \\in (1, 2)$ under mild assumptions that\nguarantee the existence of the Hessian of the risk at its minimizer.",
          "link": "http://arxiv.org/abs/2310.12437",
          "publishedOn": "2023-10-21T00:41:38.457Z",
          "wordCount": 636,
          "title": "Optimal Excess Risk Bounds for Empirical Risk Minimization on $p$-norm Linear Regression. (arXiv:2310.12437v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoshikawa_u/0/1/0/all/0/1\">uya Yoshikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1\">Tomoharu Iwata</a>",
          "description": "The quality of explanations for the predictions of complex machine learning\npredictors is often measured using insertion and deletion metrics, which assess\nthe faithfulness of the explanations, i.e., how correctly the explanations\nreflect the predictor's behavior. To improve the faithfulness, we propose\ninsertion/deletion metric-aware explanation-based optimization (ID-ExpO), which\noptimizes differentiable predictors to improve both insertion and deletion\nscores of the explanations while keeping their predictive accuracy. Since the\noriginal insertion and deletion metrics are indifferentiable with respect to\nthe explanations and directly unavailable for gradient-based optimization, we\nextend the metrics to be differentiable and use them to formalize insertion and\ndeletion metric-based regularizers. The experimental results on image and\ntabular datasets show that the deep neural networks-based predictors fine-tuned\nusing ID-ExpO enable popular post-hoc explainers to produce more faithful and\neasy-to-interpret explanations while keeping high predictive accuracy.",
          "link": "http://arxiv.org/abs/2310.12553",
          "publishedOn": "2023-10-21T00:41:38.442Z",
          "wordCount": 646,
          "title": "Explanation-Based Training with Differentiable Insertion/Deletion Metric-Aware Regularizers. (arXiv:2310.12553v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yichuan Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shenghao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chiwun Yang</a>",
          "description": "In the realm of deep learning, transformers have emerged as a dominant\narchitecture, particularly in natural language processing tasks. However, with\ntheir widespread adoption, concerns regarding the security and privacy of the\ndata processed by these models have arisen. In this paper, we address a pivotal\nquestion: Can the data fed into transformers be recovered using their attention\nweights and outputs? We introduce a theoretical framework to tackle this\nproblem. Specifically, we present an algorithm that aims to recover the input\ndata $X \\in \\mathbb{R}^{d \\times n}$ from given attention weights $W = QK^\\top\n\\in \\mathbb{R}^{d \\times d}$ and output $B \\in \\mathbb{R}^{n \\times n}$ by\nminimizing the loss function $L(X)$. This loss function captures the\ndiscrepancy between the expected output and the actual output of the\ntransformer. Our findings have significant implications for the Localized\nLayer-wise Mechanism (LLM), suggesting potential vulnerabilities in the model's\ndesign from a security and privacy perspective. This work underscores the\nimportance of understanding and safeguarding the internal workings of\ntransformers to ensure the confidentiality of processed data.",
          "link": "http://arxiv.org/abs/2310.12462",
          "publishedOn": "2023-10-21T00:41:38.430Z",
          "wordCount": 698,
          "title": "Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights. (arXiv:2310.12462v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12544",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+OLoughlin_L/0/1/0/all/0/1\">Luke O&#x27;Loughlin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maclean_J/0/1/0/all/0/1\">John Maclean</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Black_A/0/1/0/all/0/1\">Andrew Black</a>",
          "description": "Stochastic processes defined on integer valued state spaces are popular\nwithin the physical and biological sciences. These models are necessary for\ncapturing the dynamics of small systems where the individual nature of the\npopulations cannot be ignored and stochastic effects are important. The\ninference of the parameters of such models, from time series data, is difficult\ndue to intractability of the likelihood; current methods, based on simulations\nof the underlying model, can be so computationally expensive as to be\nprohibitive. In this paper we construct a neural likelihood approximation for\ninteger valued time series data using causal convolutions, which allows us to\nevaluate the likelihood of the whole time series in parallel. We demonstrate\nour method by performing inference on a number of ecological and\nepidemiological models, showing that we can accurately approximate the true\nposterior while achieving significant computational speed ups in situations\nwhere current methods struggle.",
          "link": "http://arxiv.org/abs/2310.12544",
          "publishedOn": "2023-10-21T00:41:38.186Z",
          "wordCount": 651,
          "title": "Neural Likelihood Approximation for Integer Valued Time Series Data. (arXiv:2310.12544v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scarvelis_C/0/1/0/all/0/1\">Christopher Scarvelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borde_H/0/1/0/all/0/1\">Haitz S&#xe1;ez de Oc&#xe1;riz Borde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1\">Justin Solomon</a>",
          "description": "Score-based generative models (SGMs) sample from a target distribution by\niteratively transforming noise using the score function of the perturbed\ntarget. For any finite training set, this score function can be evaluated in\nclosed form, but the resulting SGM memorizes its training data and does not\ngenerate novel samples. In practice, one approximates the score by training a\nneural network via score-matching. The error in this approximation promotes\ngeneralization, but neural SGMs are costly to train and sample, and the\neffective regularization this error provides is not well-understood\ntheoretically. In this work, we instead explicitly smooth the closed-form score\nto obtain an SGM that generates novel samples without training. We analyze our\nmodel and propose an efficient nearest-neighbor-based estimator of its score\nfunction. Using this estimator, our method achieves sampling times competitive\nwith neural SGMs while running on consumer-grade CPUs.",
          "link": "http://arxiv.org/abs/2310.12395",
          "publishedOn": "2023-10-21T00:41:38.179Z",
          "wordCount": 634,
          "title": "Closed-Form Diffusion Models. (arXiv:2310.12395v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rosaler_J/0/1/0/all/0/1\">Joshua Rosaler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Desai_D/0/1/0/all/0/1\">Dhruv Desai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sarmah_B/0/1/0/all/0/1\">Bhaskarjit Sarmah</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vamvourellis_D/0/1/0/all/0/1\">Dimitrios Vamvourellis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Onay_D/0/1/0/all/0/1\">Deran Onay</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mehta_D/0/1/0/all/0/1\">Dhagash Mehta</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pasquali_S/0/1/0/all/0/1\">Stefano Pasquali</a>",
          "description": "We initiate a novel approach to explain the out of sample performance of\nrandom forest (RF) models by exploiting the fact that any RF can be formulated\nas an adaptive weighted K nearest-neighbors model. Specifically, we use the\nproximity between points in the feature space learned by the RF to re-write\nrandom forest predictions exactly as a weighted average of the target labels of\ntraining data points. This linearity facilitates a local notion of\nexplainability of RF predictions that generates attributions for any model\nprediction across observations in the training set, and thereby complements\nestablished methods like SHAP, which instead generates attributions for a model\nprediction across dimensions of the feature space. We demonstrate this approach\nin the context of a bond pricing model trained on US corporate bond trades, and\ncompare our approach to various existing approaches to model explainability.",
          "link": "http://arxiv.org/abs/2310.12428",
          "publishedOn": "2023-10-21T00:41:38.035Z",
          "wordCount": 673,
          "title": "Towards Enhanced Local Explainability of Random Forests: a Proximity-Based Approach. (arXiv:2310.12428v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12285",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zgodic_A/0/1/0/all/0/1\">Anja Zgodic</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bai_R/0/1/0/all/0/1\">Ray Bai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiajia Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McLain_A/0/1/0/all/0/1\">Alexander C. McLain</a>",
          "description": "High-dimensional longitudinal data is increasingly used in a wide range of\nscientific studies. However, there are few statistical methods for\nhigh-dimensional linear mixed models (LMMs), as most Bayesian variable\nselection or penalization methods are designed for independent observations.\nAdditionally, the few available software packages for high-dimensional LMMs\nsuffer from scalability issues. This work presents an efficient and accurate\nBayesian framework for high-dimensional LMMs. We use empirical Bayes estimators\nof hyperparameters for increased flexibility and an\nExpectation-Conditional-Minimization (ECM) algorithm for computationally\nefficient maximum a posteriori probability (MAP) estimation of parameters. The\nnovelty of the approach lies in its partitioning and parameter expansion as\nwell as its fast and scalable computation. We illustrate Linear Mixed Modeling\nwith PaRtitiOned empirical Bayes ECM (LMM-PROBE) in simulation studies\nevaluating fixed and random effects estimation along with computation time. A\nreal-world example is provided using data from a study of lupus in children,\nwhere we identify genes and clinical factors associated with a new lupus\nbiomarker and predict the biomarker over time.",
          "link": "http://arxiv.org/abs/2310.12285",
          "publishedOn": "2023-10-21T00:41:38.001Z",
          "wordCount": 684,
          "title": "Sparse high-dimensional linear mixed modeling with a partitioned empirical Bayes ECM algorithm. (arXiv:2310.12285v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.12304",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Park_R/0/1/0/all/0/1\">Ryan Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Theisen_R/0/1/0/all/0/1\">Ryan Theisen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sahni_N/0/1/0/all/0/1\">Navriti Sahni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Patek_M/0/1/0/all/0/1\">Marcel Patek</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cichonska_A/0/1/0/all/0/1\">Anna Cicho&#x144;ska</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rahman_R/0/1/0/all/0/1\">Rayees Rahman</a>",
          "description": "Molecular language modeling is an effective approach to generating novel\nchemical structures. However, these models do not \\emph{a priori} encode\ncertain preferences a chemist may desire. We investigate the use of fine-tuning\nusing Direct Preference Optimization to better align generated molecules with\nchemist preferences. Our findings suggest that this approach is simple,\nefficient, and highly effective.",
          "link": "http://arxiv.org/abs/2310.12304",
          "publishedOn": "2023-10-21T00:41:37.989Z",
          "wordCount": 557,
          "title": "Preference Optimization for Molecular Language Models. (arXiv:2310.12304v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Day_H/0/1/0/all/0/1\">Hannah Day</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahn_Y/0/1/0/all/0/1\">Yonatan Kahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_D/0/1/0/all/0/1\">Daniel A. Roberts</a>",
          "description": "Fully-connected deep neural networks with weights initialized from\nindependent Gaussian distributions can be tuned to criticality, which prevents\nthe exponential growth or decay of signals propagating through the network.\nHowever, such networks still exhibit fluctuations that grow linearly with the\ndepth of the network, which may impair the training of networks with width\ncomparable to depth. We show analytically that rectangular networks with tanh\nactivations and weights initialized from the ensemble of orthogonal matrices\nhave corresponding preactivation fluctuations which are independent of depth,\nto leading order in inverse width. Moreover, we demonstrate numerically that,\nat initialization, all correlators involving the neural tangent kernel (NTK)\nand its descendants at leading order in inverse width -- which govern the\nevolution of observables during training -- saturate at a depth of $\\sim 20$,\nrather than growing without bound as in the case of Gaussian initializations.\nWe speculate that this structure preserves finite-width feature learning while\nreducing overall noise, thus improving both generalization and training speed.\nWe provide some experimental justification by relating empirical measurements\nof the NTK to the superior performance of deep nonlinear orthogonal networks\ntrained under full-batch gradient descent on the MNIST and CIFAR-10\nclassification tasks.",
          "link": "http://arxiv.org/abs/2310.07765",
          "publishedOn": "2023-10-14T00:41:46.967Z",
          "wordCount": 734,
          "title": "Feature Learning and Generalization in Deep Networks with Orthogonal Weights. (arXiv:2310.07765v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yite Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jiahao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanlin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Cong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jianbo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haibin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruoyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Scaling of deep neural networks, especially Transformers, is pivotal for\ntheir surging performance and has further led to the emergence of sophisticated\nreasoning capabilities in foundation models. Such scaling generally requires\ntraining large models from scratch with random initialization, failing to\nleverage the knowledge acquired by their smaller counterparts, which are\nalready resource-intensive to obtain. To tackle this inefficiency, we present\n$\\textbf{L}$ossl$\\textbf{E}$ss $\\textbf{MO}$del Expansio$\\textbf{N}$ (LEMON), a\nrecipe to initialize scaled models using the weights of their smaller but\npre-trained counterparts. This is followed by model training with an optimized\nlearning rate scheduler tailored explicitly for the scaled models,\nsubstantially reducing the training time compared to training from scratch.\nNotably, LEMON is versatile, ensuring compatibility with various network\nstructures, including models like Vision Transformers and BERT. Our empirical\nresults demonstrate that LEMON reduces computational costs by 56.7% for Vision\nTransformers and 33.2% for BERT when compared to training from scratch.",
          "link": "http://arxiv.org/abs/2310.07999",
          "publishedOn": "2023-10-14T00:41:34.875Z",
          "wordCount": null,
          "title": "LEMON: Lossless model expansion. (arXiv:2310.07999v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.09129",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Barnes_L/0/1/0/all/0/1\">Leighton P. Barnes</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dytso_A/0/1/0/all/0/1\">Alex Dytso</a>, <a href=\"http://arxiv.org/find/math/1/au:+Liu_J/0/1/0/all/0/1\">Jingbo Liu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Poor_H/0/1/0/all/0/1\">H. Vincent Poor</a>",
          "description": "Consider the problem of estimating a random variable $X$ from noisy\nobservations $Y = X+ Z$, where $Z$ is standard normal, under the $L^1$ fidelity\ncriterion. It is well known that the optimal Bayesian estimator in this setting\nis the conditional median. This work shows that the only prior distribution on\n$X$ that induces linearity in the conditional median is Gaussian.\n\nAlong the way, several other results are presented. In particular, it is\ndemonstrated that if the conditional distribution $P_{X|Y=y}$ is symmetric for\nall $y$, then $X$ must follow a Gaussian distribution. Additionally, we\nconsider other $L^p$ losses and observe the following phenomenon: for $p \\in\n[1,2]$, Gaussian is the only prior distribution that induces a linear optimal\nBayesian estimator, and for $p \\in (2,\\infty)$, infinitely many prior\ndistributions on $X$ can induce linearity. Finally, extensions are provided to\nencompass noise models leading to conditional distributions from certain\nexponential families.",
          "link": "http://arxiv.org/abs/2309.09129",
          "publishedOn": "2023-10-14T00:41:34.685Z",
          "wordCount": null,
          "title": "$L^1$ Estimation: On the Optimality of Linear Estimators. (arXiv:2309.09129v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.08287",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Laurent_O/0/1/0/all/0/1\">Olivier Laurent</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aldea_E/0/1/0/all/0/1\">Emanuel Aldea</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Franchi_G/0/1/0/all/0/1\">Gianni Franchi</a>",
          "description": "The distribution of the weights of modern deep neural networks (DNNs) -\ncrucial for uncertainty quantification and robustness - is an eminently complex\nobject due to its extremely high dimensionality. This paper proposes one of the\nfirst large-scale explorations of the posterior distribution of deep Bayesian\nNeural Networks (BNNs), expanding its study to real-world vision tasks and\narchitectures. Specifically, we investigate the optimal approach for\napproximating the posterior, analyze the connection between posterior quality\nand uncertainty quantification, delve into the impact of modes on the\nposterior, and explore methods for visualizing the posterior. Moreover, we\nuncover weight-space symmetries as a critical aspect for understanding the\nposterior. To this extent, we develop an in-depth assessment of the impact of\nboth permutation and scaling symmetries that tend to obfuscate the Bayesian\nposterior. While the first type of transformation is known for duplicating\nmodes, we explore the relationship between the latter and L2 regularization,\nchallenging previous misconceptions. Finally, to help the community improve our\nunderstanding of the Bayesian posterior, we will shortly release the first\nlarge-scale checkpoint dataset, including thousands of real-world models and\nour codes.",
          "link": "http://arxiv.org/abs/2310.08287",
          "publishedOn": "2023-10-14T00:41:34.404Z",
          "wordCount": null,
          "title": "A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors. (arXiv:2310.08287v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.14219",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sousa_M/0/1/0/all/0/1\">Martim Sousa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tome_A/0/1/0/all/0/1\">Ana Maria Tom&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moreira_J/0/1/0/all/0/1\">Jos&#xe9; Moreira</a>",
          "description": "This paper introduces a novel model-agnostic algorithm called adaptive\nensemble batch multi-input multi-output conformalized quantile regression\n(AEnbMIMOCQR} that enables forecasters to generate multi-step ahead prediction\nintervals for a fixed pre-specified miscoverage rate in a distribution-free\nmanner. Our method is grounded on conformal prediction principles, however, it\ndoes not require data splitting and provides close to exact coverage even when\nthe data is not exchangeable. Moreover, the resulting prediction intervals,\nbesides being empirically valid along the forecast horizon, do not neglect\nheteroscedasticity. AEnbMIMOCQR is designed to be robust to distribution\nshifts, which means that its prediction intervals remain reliable over an\nunlimited period of time, without entailing retraining or imposing unrealistic\nstrict assumptions on the data-generating process. Through methodically\nexperimentation, we demonstrate that our approach outperforms other competitive\nmethods on both real-world and synthetic datasets. The code used in the\nexperimental part and a tutorial on how to use AEnbMIMOCQR can be found at the\nfollowing GitHub repository: https://github.com/Quilograma/AEnbMIMOCQR.",
          "link": "http://arxiv.org/abs/2207.14219",
          "publishedOn": "2023-10-14T00:41:34.247Z",
          "wordCount": null,
          "title": "A general framework for multi-step ahead adaptive conformal heteroscedastic time series forecasting. (arXiv:2207.14219v9 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.07983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Luyao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alghunaim_S/0/1/0/all/0/1\">Sulaiman A. Alghunaim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1\">Kun Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Condat_L/0/1/0/all/0/1\">Laurent Condat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jinde Cao</a>",
          "description": "Distributed optimization methods with random communication skips are gaining\nincreasing attention due to their proven benefits in accelerating communication\ncomplexity. Nevertheless, existing research mainly focuses on centralized\ncommunication protocols for strongly convex deterministic settings. In this\nwork, we provide a decentralized optimization method called RandCom, which\nincorporates probabilistic local updates. We analyze the performance of RandCom\nin stochastic non-convex, convex, and strongly convex settings and demonstrate\nits ability to asymptotically reduce communication overhead by the probability\nof communication. Additionally, we prove that RandCom achieves linear speedup\nas the number of nodes increases. In stochastic strongly convex settings, we\nfurther prove that RandCom can achieve linear speedup with network-independent\nstepsizes. Moreover, we apply RandCom to federated learning and provide\npositive results concerning the potential for achieving linear speedup and the\nsuitability of the probabilistic local update approach for non-convex settings.",
          "link": "http://arxiv.org/abs/2310.07983",
          "publishedOn": "2023-10-14T00:41:33.641Z",
          "wordCount": 677,
          "title": "RandCom: Random Communication Skipping Method for Decentralized Stochastic Optimization. (arXiv:2310.07983v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08495",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Goode_K/0/1/0/all/0/1\">Katherine Goode</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ries_D/0/1/0/all/0/1\">Daniel Ries</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McClernon_K/0/1/0/all/0/1\">Kellie McClernon</a>",
          "description": "The 2022 National Defense Strategy of the United States listed climate change\nas a serious threat to national security. Climate intervention methods, such as\nstratospheric aerosol injection, have been proposed as mitigation strategies,\nbut the downstream effects of such actions on a complex climate system are not\nwell understood. The development of algorithmic techniques for quantifying\nrelationships between source and impact variables related to a climate event\n(i.e., a climate pathway) would help inform policy decisions. Data-driven deep\nlearning models have become powerful tools for modeling highly nonlinear\nrelationships and may provide a route to characterize climate variable\nrelationships. In this paper, we explore the use of an echo state network (ESN)\nfor characterizing climate pathways. ESNs are a computationally efficient\nneural network variation designed for temporal data, and recent work proposes\nESNs as a useful tool for forecasting spatio-temporal climate data. Like other\nneural networks, ESNs are non-interpretable black-box models, which poses a\nhurdle for understanding variable relationships. We address this issue by\ndeveloping feature importance methods for ESNs in the context of\nspatio-temporal data to quantify variable relationships captured by the model.\nWe conduct a simulation study to assess and compare the feature importance\ntechniques, and we demonstrate the approach on reanalysis climate data. In the\nclimate application, we select a time period that includes the 1991 volcanic\neruption of Mount Pinatubo. This event was a significant stratospheric aerosol\ninjection, which we use as a proxy for an artificial stratospheric aerosol\ninjection. Using the proposed approach, we are able to characterize\nrelationships between pathway variables associated with this event.",
          "link": "http://arxiv.org/abs/2310.08495",
          "publishedOn": "2023-10-14T00:41:31.386Z",
          "wordCount": 766,
          "title": "Characterizing climate pathways using feature importance on echo state networks. (arXiv:2310.08495v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08331",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zangirolami_V/0/1/0/all/0/1\">Valentina Zangirolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Borrotti_M/0/1/0/all/0/1\">Matteo Borrotti</a>",
          "description": "Incomplete knowledge of the environment leads an agent to make decisions\nunder uncertainty. One of the major dilemmas in Reinforcement Learning (RL)\nwhere an autonomous agent has to balance two contrasting needs in making its\ndecisions is: exploiting the current knowledge of the environment to maximize\nthe cumulative reward as well as exploring actions that allow improving the\nknowledge of the environment, hopefully leading to higher reward values\n(exploration-exploitation trade-off). Concurrently, another relevant issue\nregards the full observability of the states, which may not be assumed in all\napplications. Such as when only 2D images are considered as input in a RL\napproach used for finding the optimal action within a 3D simulation\nenvironment. In this work, we address these issues by deploying and testing\nseveral techniques to balance exploration and exploitation trade-off on\npartially observable systems for predicting steering wheels in autonomous\ndriving scenario. More precisely, the final aim is to investigate the effects\nof using both stochastic and deterministic multi-armed bandit strategies\ncoupled with a Deep Recurrent Q-Network. Additionally, we adapted and evaluated\nthe impact of an innovative method to improve the learning phase of the\nunderlying Convolutional Recurrent Neural Network. We aim to show that adaptive\nstochastic methods for exploration better approximate the trade-off between\nexploration and exploitation as, in general, Softmax and Max-Boltzmann\nstrategies are able to outperform epsilon-greedy techniques.",
          "link": "http://arxiv.org/abs/2310.08331",
          "publishedOn": "2023-10-14T00:41:31.148Z",
          "wordCount": 725,
          "title": "Impact of multi-armed bandit strategies on deep recurrent reinforcement learning. (arXiv:2310.08331v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.05288",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Clark_K/0/1/0/all/0/1\">Katharine M. Clark</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McNicholas_P/0/1/0/all/0/1\">Paul D. McNicholas</a>",
          "description": "Matrix-variate distributions are a recent addition to the model-based\nclustering field, thereby making it possible to analyze data in matrix form\nwith complex structure such as images and time series. Due to its recent\nappearance, there is limited literature on matrix-variate data, with even less\non dealing with outliers in these models. An approach for clustering\nmatrix-variate normal data with outliers is discussed. The approach, which uses\nthe distribution of subset log-likelihoods, extends the OCLUST algorithm to\nmatrix-variate normal data and uses an iterative approach to detect and trim\noutliers.",
          "link": "http://arxiv.org/abs/2310.05288",
          "publishedOn": "2023-10-14T00:41:29.911Z",
          "wordCount": 594,
          "title": "Clustering Three-Way Data with Outliers. (arXiv:2310.05288v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deuschel_J/0/1/0/all/0/1\">Jannik Deuschel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellington_C/0/1/0/all/0/1\">Caleb N. Ellington</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lengerich_B/0/1/0/all/0/1\">Benjamin J. Lengerich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yingtao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friederich_P/0/1/0/all/0/1\">Pascal Friederich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>",
          "description": "Interpretable policy learning seeks to estimate intelligible decision\npolicies from observed actions; however, existing models fall short by forcing\na tradeoff between accuracy and interpretability. This tradeoff limits\ndata-driven interpretations of human decision-making process. e.g. to audit\nmedical decisions for biases and suboptimal practices, we require models of\ndecision processes which provide concise descriptions of complex behaviors.\nFundamentally, existing approaches are burdened by this tradeoff because they\nrepresent the underlying decision process as a universal policy, when in fact\nhuman decisions are dynamic and can change drastically with contextual\ninformation. Thus, we propose Contextualized Policy Recovery (CPR), which\nre-frames the problem of modeling complex decision processes as a multi-task\nlearning problem in which complex decision policies are comprised of\ncontext-specific policies. CPR models each context-specific policy as a linear\nobservation-to-action mapping, and generates new decision models\n$\\textit{on-demand}$ as contexts are updated with new observations. CPR is\ncompatible with fully offline and partially observable decision environments,\nand can be tailored to incorporate any recurrent black-box model or\ninterpretable decision model. We assess CPR through studies on simulated and\nreal data, achieving state-of-the-art performance on the canonical tasks of\npredicting antibiotic prescription in intensive care units ($+22\\%$ AUROC vs.\nprevious SOTA) and predicting MRI prescription for Alzheimer's patients\n($+7.7\\%$ AUROC vs. previous SOTA). With this improvement in predictive\nperformance, CPR closes the accuracy gap between interpretable and black-box\nmethods for policy learning, allowing high-resolution exploration and analysis\nof context-specific decision models.",
          "link": "http://arxiv.org/abs/2310.07918",
          "publishedOn": "2023-10-14T00:41:29.888Z",
          "wordCount": 771,
          "title": "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning. (arXiv:2310.07918v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.12345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldwaser_A/0/1/0/all/0/1\">Adrian Goldwaser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1\">Hong Ge</a>",
          "description": "Larger and deeper networks generalise well despite their increased capacity\nto overfit. Understanding why this happens is theoretically and practically\nimportant. One recent approach looks at the infinitely wide limits of such\nnetworks and their corresponding kernels. However, these theoretical tools\ncannot fully explain finite networks as the empirical kernel changes\nsignificantly during gradient-descent-based training in contrast to infinite\nnetworks. In this work, we derive an iterative linearised training method as a\nnovel empirical tool to further investigate this distinction, allowing us to\ncontrol for sparse (i.e. infrequent) feature updates and quantify the frequency\nof feature learning needed to achieve comparable performance. We justify\niterative linearisation as an interpolation between a finite analog of the\ninfinite width regime, which does not learn features, and standard gradient\ndescent training, which does. Informally, we also show that it is analogous to\na damped version of the Gauss-Newton algorithm -- a second-order method. We\nshow that in a variety of cases, iterative linearised training surprisingly\nperforms on par with standard training, noting in particular how much less\nfrequent feature learning is required to achieve comparable performance. We\nalso show that feature learning is essential for good performance. Since such\nfeature learning inevitably causes changes in the NTK kernel, we provide direct\nnegative evidence for the NTK theory, which states the NTK kernel remains\nconstant during training.",
          "link": "http://arxiv.org/abs/2211.12345",
          "publishedOn": "2023-10-14T00:41:29.866Z",
          "wordCount": 766,
          "title": "Understanding Sparse Feature Updates in Deep Networks using Iterative Linearisation. (arXiv:2211.12345v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.00152",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hanneke_S/0/1/0/all/0/1\">Steve Hanneke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mahdaviyeh_Y/0/1/0/all/0/1\">Yasaman Mahdaviyeh</a>",
          "description": "Theoretical studies on transfer learning or domain adaptation have so far\nfocused on situations with a known hypothesis class or model; however in\npractice, some amount of model selection is usually involved, often appearing\nunder the umbrella term of hyperparameter-tuning: for example, one may think of\nthe problem of tuning for the right neural network architecture towards a\ntarget task, while leveraging data from a related source task.\n\nNow, in addition to the usual tradeoffs on approximation vs estimation errors\ninvolved in model selection, this problem brings in a new complexity term,\nnamely, the transfer distance between source and target distributions, which is\nknown to vary with the choice of hypothesis class.\n\nWe present a first study of this problem, focusing on classification; in\nparticular, the analysis reveals some remarkable phenomena: adaptive rates,\ni.e., those achievable with no distributional information, can be arbitrarily\nslower than oracle rates, i.e., when given knowledge on distances.",
          "link": "http://arxiv.org/abs/2305.00152",
          "publishedOn": "2023-10-14T00:41:29.861Z",
          "wordCount": 693,
          "title": "Limits of Model Selection under Transfer Learning. (arXiv:2305.00152v4 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07891",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Moniri_B/0/1/0/all/0/1\">Behrad Moniri</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_D/0/1/0/all/0/1\">Donghwan Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>",
          "description": "Feature learning is thought to be one of the fundamental reasons for the\nsuccess of deep neural networks. It is rigorously known that in two-layer\nfully-connected neural networks under certain conditions, one step of gradient\ndescent on the first layer followed by ridge regression on the second layer can\nlead to feature learning; characterized by the appearance of a separated\nrank-one component -- spike -- in the spectrum of the feature matrix. However,\nwith a constant gradient descent step size, this spike only carries information\nfrom the linear component of the target function and therefore learning\nnon-linear components is impossible. We show that with a learning rate that\ngrows with the sample size, such training in fact introduces multiple rank-one\ncomponents, each corresponding to a specific polynomial feature. We further\nprove that the limiting large-dimensional and large sample training and test\nerrors of the updated neural networks are fully characterized by these spikes.\nBy precisely analyzing the improvement in the loss, we demonstrate that these\nnon-linear features can enhance learning.",
          "link": "http://arxiv.org/abs/2310.07891",
          "publishedOn": "2023-10-14T00:41:29.856Z",
          "wordCount": 690,
          "title": "A Theory of Non-Linear Feature Learning with One Gradient Step in Two-Layer Neural Networks. (arXiv:2310.07891v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08055",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Harkonen_T/0/1/0/all/0/1\">Teemu H&#xe4;rk&#xf6;nen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vartiainen_E/0/1/0/all/0/1\">Erik M. Vartiainen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lensu_L/0/1/0/all/0/1\">Lasse Lensu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moores_M/0/1/0/all/0/1\">Matthew T. Moores</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roininen_L/0/1/0/all/0/1\">Lassi Roininen</a>",
          "description": "We propose an approach utilizing gamma-distributed random variables, coupled\nwith log-Gaussian modeling, to generate synthetic datasets suitable for\ntraining neural networks. This addresses the challenge of limited real\nobservations in various applications. We apply this methodology to both Raman\nand coherent anti-Stokes Raman scattering (CARS) spectra, using experimental\nspectra to estimate gamma process parameters. Parameter estimation is performed\nusing Markov chain Monte Carlo methods, yielding a full Bayesian posterior\ndistribution for the model which can be sampled for synthetic data generation.\nAdditionally, we model the additive and multiplicative background functions for\nRaman and CARS with Gaussian processes. We train two Bayesian neural networks\nto estimate parameters of the gamma process which can then be used to estimate\nthe underlying Raman spectrum and simultaneously provide uncertainty through\nthe estimation of parameters of a probability distribution. We apply the\ntrained Bayesian neural networks to experimental Raman spectra of\nphthalocyanine blue, aniline black, naphthol red, and red 264 pigments and also\nto experimental CARS spectra of adenosine phosphate, fructose, glucose, and\nsucrose. The results agree with deterministic point estimates for the\nunderlying Raman and CARS spectral signatures.",
          "link": "http://arxiv.org/abs/2310.08055",
          "publishedOn": "2023-10-14T00:41:29.851Z",
          "wordCount": 709,
          "title": "Log-Gaussian Gamma Processes for Training Bayesian Neural Networks in Raman and CARS Spectroscopies. (arXiv:2310.08055v1 [stat.AP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08576",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ko_P/0/1/0/all/0/1\">Po-Chen Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yilun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shao-Hua Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>",
          "description": "In this work, we present an approach to construct a video-based robot policy\ncapable of reliably executing diverse tasks across different robots and\nenvironments from few video demonstrations without using any action\nannotations. Our method leverages images as a task-agnostic representation,\nencoding both the state and action information, and text as a general\nrepresentation for specifying robot goals. By synthesizing videos that\n``hallucinate'' robot executing actions and in combination with dense\ncorrespondences between frames, our approach can infer the closed-formed action\nto execute to an environment without the need of any explicit action labels.\nThis unique capability allows us to train the policy solely based on RGB videos\nand deploy learned policies to various robotic tasks. We demonstrate the\nefficacy of our approach in learning policies on table-top manipulation and\nnavigation tasks. Additionally, we contribute an open-source framework for\nefficient video modeling, enabling the training of high-fidelity policy models\nwith four GPUs within a single day.",
          "link": "http://arxiv.org/abs/2310.08576",
          "publishedOn": "2023-10-14T00:41:29.837Z",
          "wordCount": 677,
          "title": "Learning to Act from Actionless Videos through Dense Correspondences. (arXiv:2310.08576v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.01748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_K/0/1/0/all/0/1\">Kushagra Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Score-based Generative Models (SGMs) have demonstrated exceptional synthesis\noutcomes across various tasks. However, the current design landscape of the\nforward diffusion process remains largely untapped and often relies on physical\nheuristics or simplifying assumptions. Utilizing insights from the development\nof scalable Bayesian posterior samplers, we present a complete recipe for\nformulating forward processes in SGMs, ensuring convergence to the desired\ntarget distribution. Our approach reveals that several existing SGMs can be\nseen as specific manifestations of our framework. Building upon this method, we\nintroduce Phase Space Langevin Diffusion (PSLD), which relies on score-based\nmodeling within an augmented space enriched by auxiliary variables akin to\nphysical phase space. Empirical results exhibit the superior sample quality and\nimproved speed-quality trade-off of PSLD compared to various competing\napproaches on established image synthesis benchmarks. Remarkably, PSLD achieves\nsample quality akin to state-of-the-art SGMs (FID: 2.10 for unconditional\nCIFAR-10 generation). Lastly, we demonstrate the applicability of PSLD in\nconditional synthesis using pre-trained score networks, offering an appealing\nalternative as an SGM backbone for future advancements. Code and model\ncheckpoints can be accessed at \\url{https://github.com/mandt-lab/PSLD}.",
          "link": "http://arxiv.org/abs/2303.01748",
          "publishedOn": "2023-10-14T00:41:29.813Z",
          "wordCount": 709,
          "title": "A Complete Recipe for Diffusion Generative Models. (arXiv:2303.01748v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.14041",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenyuan Liu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Parys_B/0/1/0/all/0/1\">Bart P. G. Van Parys</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lam_H/0/1/0/all/0/1\">Henry Lam</a>",
          "description": "In data-driven optimization, sample average approximation (SAA) is known to\nsuffer from the so-called optimizer's curse that causes an over-optimistic\nevaluation of the solution performance. We argue that a special type of\ndistributionallly robust optimization (DRO) formulation offers theoretical\nadvantages in correcting for this optimizer's curse compared to simple\n``margin'' adjustments to SAA and other DRO approaches: It attains a\nstatistical bound on the out-of-sample performance, for a wide class of\nobjective functions and distributions, that is nearly tightest in terms of\nexponential decay rate. This DRO uses an ambiguity set based on a Kullback\nLeibler (KL) divergence smoothed by the Wasserstein or L\\'evy-Prokhorov (LP)\ndistance via a suitable distance optimization. Computationally, we also show\nthat such a DRO, and its generalized versions using smoothed $f$-divergence,\nare not harder than DRO problems based on $f$-divergence or Wasserstein\ndistances, rendering our DRO formulations both statistically optimal and\ncomputationally viable.",
          "link": "http://arxiv.org/abs/2306.14041",
          "publishedOn": "2023-10-14T00:41:29.803Z",
          "wordCount": 678,
          "title": "Smoothed $f$-Divergence Distributionally Robust Optimization. (arXiv:2306.14041v2 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.05925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kai Liu</a>",
          "description": "Sparse logistic regression is for classification and feature selection\nsimultaneously. Although many studies have been done to solve\n$\\ell_1$-regularized logistic regression, there is no equivalently abundant\nwork on solving sparse logistic regression with nonconvex regularization term.\nIn this paper, we propose a unified framework to solve $\\ell_1$-regularized\nlogistic regression, which can be naturally extended to nonconvex\nregularization term, as long as certain requirement is satisfied. In addition,\nwe also utilize a different line search criteria to guarantee monotone\nconvergence for various regularization terms. Empirical experiments on binary\nclassification tasks with real-world datasets demonstrate our proposed\nalgorithms are capable of performing classification and feature selection\neffectively at a lower computational cost.",
          "link": "http://arxiv.org/abs/2309.05925",
          "publishedOn": "2023-10-14T00:41:29.765Z",
          "wordCount": 625,
          "title": "On Regularized Sparse Logistic Regression. (arXiv:2309.05925v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Defazio_A/0/1/0/all/0/1\">Aaron Defazio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_H/0/1/0/all/0/1\">Harsh Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>",
          "description": "Learning rate schedules used in practice bear little resemblance to those\nrecommended by theory. We close much of this theory/practice gap, and as a\nconsequence are able to derive new problem-adaptive learning rate schedules.\nOur key technical contribution is a refined analysis of learning rate schedules\nfor a wide class of optimization algorithms (including SGD). In contrast to\nmost prior works that study the convergence of the average iterate, we study\nthe last iterate, which is what most people use in practice. When considering\nonly worst-case analysis, our theory predicts that the best choice is the\nlinear decay schedule: a popular choice in practice that sets the stepsize\nproportionally to $1 - t/T$, where $t$ is the current iteration and $T$ is the\ntotal number of steps. To go beyond this worst-case analysis, we use the\nobserved gradient norms to derive schedules refined for any particular task.\nThese refined schedules exhibit learning rate warm-up and rapid learning rate\nannealing near the end of training. Ours is the first systematic approach to\nautomatically yield both of these properties. We perform the most comprehensive\nevaluation of learning rate schedules to date, evaluating across 10 diverse\ndeep learning problems, a series of LLMs, and a suite of logistic regression\nproblems. We validate that overall, the linear-decay schedule matches or\noutperforms all commonly used default schedules including cosine annealing, and\nthat our schedule refinement method gives further improvements.",
          "link": "http://arxiv.org/abs/2310.07831",
          "publishedOn": "2023-10-14T00:41:29.728Z",
          "wordCount": 765,
          "title": "When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement. (arXiv:2310.07831v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Hanpu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng-Long Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Z/0/1/0/all/0/1\">Zihang Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_Y/0/1/0/all/0/1\">Yiming Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>",
          "description": "This paper focuses on the problem of Differentially Private Stochastic\nOptimization for (multi-layer) fully connected neural networks with a single\noutput node. In the first part, we examine cases with no hidden nodes,\nspecifically focusing on Generalized Linear Models (GLMs). We investigate the\nwell-specific model where the random noise possesses a zero mean, and the link\nfunction is both bounded and Lipschitz continuous. We propose several\nalgorithms and our analysis demonstrates the feasibility of achieving an excess\npopulation risk that remains invariant to the data dimension. We also delve\ninto the scenario involving the ReLU link function, and our findings mirror\nthose of the bounded link function. We conclude this section by contrasting\nwell-specified and misspecified models, using ReLU regression as a\nrepresentative example.\n\nIn the second part of the paper, we extend our ideas to two-layer neural\nnetworks with sigmoid or ReLU activation functions in the well-specified model.\nIn the third part, we study the theoretical guarantees of DP-SGD in Abadi et\nal. (2016) for fully connected multi-layer neural networks. By utilizing recent\nadvances in Neural Tangent Kernel theory, we provide the first excess\npopulation risk when both the sample size and the width of the network are\nsufficiently large. Additionally, we discuss the role of some parameters in\nDP-SGD regarding their utility, both theoretically and empirically.",
          "link": "http://arxiv.org/abs/2310.08425",
          "publishedOn": "2023-10-14T00:41:29.721Z",
          "wordCount": 746,
          "title": "Differentially Private Non-convex Learning for Multi-layer Neural Networks. (arXiv:2310.08425v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2006.05421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1\">Shujian Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_H/0/1/0/all/0/1\">Hao Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpruch_L/0/1/0/all/0/1\">Lukasz Szpruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiese_M/0/1/0/all/0/1\">Magnus Wiese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabate_Vidales_M/0/1/0/all/0/1\">Marc Sabate-Vidales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Baoren Xiao</a>",
          "description": "Generative adversarial networks (GANs) have been extremely successful in\ngenerating samples, from seemingly high dimensional probability measures.\nHowever, these methods struggle to capture the temporal dependence of joint\nprobability distributions induced by time-series data. Furthermore, long\ntime-series data streams hugely increase the dimension of the target space,\nwhich may render generative modelling infeasible. To overcome these challenges,\nmotivated by the autoregressive models in econometric, we are interested in the\nconditional distribution of future time series given the past information. We\npropose the generic conditional Sig-WGAN framework by integrating\nWasserstein-GANs (WGANs) with mathematically principled and efficient path\nfeature extraction called the signature of a path. The signature of a path is a\ngraded sequence of statistics that provides a universal description for a\nstream of data, and its expected value characterises the law of the time-series\nmodel. In particular, we develop the conditional Sig-$W_1$ metric, that\ncaptures the conditional joint law of time series models, and use it as a\ndiscriminator. The signature feature space enables the explicit representation\nof the proposed discriminators which alleviates the need for expensive\ntraining. We validate our method on both synthetic and empirical dataset and\nobserve that our method consistently and significantly outperforms\nstate-of-the-art benchmarks with respect to measures of similarity and\npredictive ability.",
          "link": "http://arxiv.org/abs/2006.05421",
          "publishedOn": "2023-10-14T00:41:29.712Z",
          "wordCount": 761,
          "title": "Conditional Sig-Wasserstein GANs for Time Series Generation. (arXiv:2006.05421v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.17823",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Okuno_A/0/1/0/all/0/1\">Akifumi Okuno</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Harada_K/0/1/0/all/0/1\">Kazuharu Harada</a>",
          "description": "This study proposes an interpretable neural network-based non-proportional\nodds model (N$^3$POM) for ordinal regression. N$^3$POM is different from\nconventional approaches to ordinal regression with non-proportional models in\nseveral ways: (1) N$^3$POM is designed to directly handle continuous responses,\nwhereas standard methods typically treat de facto ordered continuous variables\nas discrete, (2) instead of estimating response-dependent finite coefficients\nof linear models from discrete responses as is done in conventional approaches,\nwe train a non-linear neural network to serve as a coefficient function. Thanks\nto the neural network, N$^3$POM offers flexibility while preserving the\ninterpretability of conventional ordinal regression. We establish a sufficient\ncondition under which the predicted conditional cumulative probability locally\nsatisfies the monotonicity constraint over a user-specified region in the\ncovariate space. Additionally, we provide a monotonicity-preserving stochastic\n(MPS) algorithm for effectively training the neural network. We apply N$^3$POM\nto several real-world datasets.",
          "link": "http://arxiv.org/abs/2303.17823",
          "publishedOn": "2023-10-14T00:41:29.690Z",
          "wordCount": 679,
          "title": "An interpretable neural network-based non-proportional odds model for ordinal regression. (arXiv:2303.17823v3 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06648",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Marion_P/0/1/0/all/0/1\">Pierre Marion</a>",
          "description": "Neural ordinary differential equations (neural ODEs) are a popular family of\ncontinuous-depth deep learning models. In this work, we consider a large family\nof parameterized ODEs with continuous-in-time parameters, which include\ntime-dependent neural ODEs. We derive a generalization bound for this class by\na Lipschitz-based argument. By leveraging the analogy between neural ODEs and\ndeep residual networks, our approach yields in particular a generalization\nbound for a class of deep residual networks. The bound involves the magnitude\nof the difference between successive weight matrices. We illustrate numerically\nhow this quantity affects the generalization capability of neural networks.",
          "link": "http://arxiv.org/abs/2305.06648",
          "publishedOn": "2023-10-14T00:41:29.667Z",
          "wordCount": 616,
          "title": "Generalization bounds for neural ordinary differential equations and deep residual networks. (arXiv:2305.06648v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.06823",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ammar_M/0/1/0/all/0/1\">Mou&#xef;n Ben Ammar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Belkhir_N/0/1/0/all/0/1\">Nacim Belkhir</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Popescu_S/0/1/0/all/0/1\">Sebastian Popescu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Manzanera_A/0/1/0/all/0/1\">Antoine Manzanera</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Franchi_G/0/1/0/all/0/1\">Gianni Franchi</a>",
          "description": "Detecting out-of-distribution (OOD) data is a critical challenge in machine\nlearning due to model overconfidence, often without awareness of their\nepistemological limits. We hypothesize that ``neural collapse'', a phenomenon\naffecting in-distribution data for models trained beyond loss convergence, also\ninfluences OOD data. To benefit from this interplay, we introduce NECO, a novel\npost-hoc method for OOD detection, which leverages the geometric properties of\n``neural collapse'' and of principal component spaces to identify OOD data. Our\nextensive experiments demonstrate that NECO achieves state-of-the-art results\non both small and large-scale OOD detection tasks while exhibiting strong\ngeneralization capabilities across different network architectures.\nFurthermore, we provide a theoretical explanation for the effectiveness of our\nmethod in OOD detection. We plan to release the code after the anonymity\nperiod.",
          "link": "http://arxiv.org/abs/2310.06823",
          "publishedOn": "2023-10-14T00:41:29.660Z",
          "wordCount": 650,
          "title": "NECO: NEural Collapse Based Out-of-distribution detection. (arXiv:2310.06823v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.06599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>",
          "description": "Existing regression models tend to fall short in both accuracy and\nuncertainty estimation when the label distribution is imbalanced. In this\npaper, we propose a probabilistic deep learning model, dubbed variational\nimbalanced regression (VIR), which not only performs well in imbalanced\nregression but naturally produces reasonable uncertainty estimation as a\nbyproduct. Different from typical variational autoencoders assuming I.I.D.\nrepresentations (a data point's representation is not directly affected by\nother data points), our VIR borrows data with similar regression labels to\ncompute the latent representation's variational distribution; furthermore,\ndifferent from deterministic regression models producing point estimates, VIR\npredicts the entire normal-inverse-gamma distributions and modulates the\nassociated conjugate distributions to impose probabilistic reweighting on the\nimbalanced data, thereby providing better uncertainty estimation. Experiments\nin several real-world datasets show that our VIR can outperform\nstate-of-the-art imbalanced regression models in terms of both accuracy and\nuncertainty estimation. Code will soon be available at\n\\url{https://github.com/Wang-ML-Lab/variational-imbalanced-regression}.",
          "link": "http://arxiv.org/abs/2306.06599",
          "publishedOn": "2023-10-14T00:41:29.626Z",
          "wordCount": 713,
          "title": "Variational Imbalanced Regression: Fair Uncertainty Quantification via Probabilistic Smoothing. (arXiv:2306.06599v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nezami_N/0/1/0/all/0/1\">Nazanin Nezami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anahideh_H/0/1/0/all/0/1\">Hadis Anahideh</a>",
          "description": "Surrogate Optimization (SO) algorithms have shown promise for optimizing\nexpensive black-box functions. However, their performance is heavily influenced\nby hyperparameters related to sampling and surrogate fitting, which poses a\nchallenge to their widespread adoption. We investigate the impact of\nhyperparameters on various SO algorithms and propose a Hyperparameter Adaptive\nSearch for SO (HASSO) approach. HASSO is not a hyperparameter tuning algorithm,\nbut a generic self-adjusting SO algorithm that dynamically tunes its own\nhyperparameters while concurrently optimizing the primary objective function,\nwithout requiring additional evaluations. The aim is to improve the\naccessibility, effectiveness, and convergence speed of SO algorithms for\npractitioners. Our approach identifies and modifies the most influential\nhyperparameters specific to each problem and SO approach, reducing the need for\nmanual tuning without significantly increasing the computational burden.\nExperimental results demonstrate the effectiveness of HASSO in enhancing the\nperformance of various SO algorithms across different global optimization test\nproblems.",
          "link": "http://arxiv.org/abs/2310.07970",
          "publishedOn": "2023-10-14T00:41:29.582Z",
          "wordCount": 667,
          "title": "Hyperparameter Adaptive Search for Surrogate Optimization: A Self-Adjusting Approach. (arXiv:2310.07970v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_N/0/1/0/all/0/1\">Namiko Matsumoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>",
          "description": "In 1-bit compressed sensing, the aim is to estimate a $k$-sparse unit vector\n$x\\in S^{n-1}$ within an $\\epsilon$ error (in $\\ell_2$) from minimal number of\nlinear measurements that are quantized to just their signs, i.e., from\nmeasurements of the form $y = \\mathrm{Sign}(\\langle a, x\\rangle).$ In this\npaper, we study a noisy version where a fraction of the measurements can be\nflipped, potentially by an adversary. In particular, we analyze the Binary\nIterative Hard Thresholding (BIHT) algorithm, a proximal gradient descent on a\nproperly defined loss function used for 1-bit compressed sensing, in this noisy\nsetting. It is known from recent results that, with\n$\\tilde{O}(\\frac{k}{\\epsilon})$ noiseless measurements, BIHT provides an\nestimate within $\\epsilon$ error. This result is optimal and universal, meaning\none set of measurements work for all sparse vectors. In this paper, we show\nthat BIHT also provides better results than all known methods for the noisy\nsetting. We show that when up to $\\tau$-fraction of the sign measurements are\nincorrect (adversarial error), with the same number of measurements as before,\nBIHT agnostically provides an estimate of $x$ within an\n$\\tilde{O}(\\epsilon+\\tau)$ error, maintaining the universality of measurements.\nThis establishes stability of iterative hard thresholding in the presence of\nmeasurement error. To obtain the result, we use the restricted approximate\ninvertibility of Gaussian matrices, as well as a tight analysis of the\nhigh-dimensional geometry of the adversarially corrupted measurements.",
          "link": "http://arxiv.org/abs/2310.08019",
          "publishedOn": "2023-10-14T00:41:29.566Z",
          "wordCount": 753,
          "title": "Robust 1-bit Compressed Sensing with Iterative Hard Thresholding. (arXiv:2310.08019v1 [cs.IT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.02286",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zambon_L/0/1/0/all/0/1\">Lorenzo Zambon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Azzimonti_D/0/1/0/all/0/1\">Dario Azzimonti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Corani_G/0/1/0/all/0/1\">Giorgio Corani</a>",
          "description": "Hierarchical time series are common in several applied fields. The forecasts\nfor these time series are required to be coherent, that is, to satisfy the\nconstraints given by the hierarchy. The most popular technique to enforce\ncoherence is called reconciliation, which adjusts the base forecasts computed\nfor each time series. However, recent works on probabilistic reconciliation\npresent several limitations. In this paper, we propose a new approach based on\nconditioning to reconcile any type of forecast distribution. We then introduce\na new algorithm, called Bottom-Up Importance Sampling, to efficiently sample\nfrom the reconciled distribution. It can be used for any base forecast\ndistribution: discrete, continuous, or in the form of samples, providing a\nmajor speedup compared to the current methods. Experiments on several temporal\nhierarchies show a significant improvement over base probabilistic forecasts.",
          "link": "http://arxiv.org/abs/2210.02286",
          "publishedOn": "2023-10-14T00:41:29.522Z",
          "wordCount": 677,
          "title": "Efficient probabilistic reconciliation of forecasts for real-valued and count time series. (arXiv:2210.02286v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.00327",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dirksen_S/0/1/0/all/0/1\">Sjoerd Dirksen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Finke_P/0/1/0/all/0/1\">Patrick Finke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Genzel_M/0/1/0/all/0/1\">Martin Genzel</a>",
          "description": "In practice, deep neural networks are often able to easily interpolate their\ntraining data. To understand this phenomenon, many works have aimed to quantify\nthe memorization capacity of a neural network architecture: the largest number\nof points such that the architecture can interpolate any placement of these\npoints with any assignment of labels. For real-world data, however, one\nintuitively expects the presence of a benign structure so that interpolation\nalready occurs at a smaller network size than suggested by memorization\ncapacity. In this paper, we investigate interpolation by adopting an\ninstance-specific viewpoint. We introduce a simple randomized algorithm that,\ngiven a fixed finite dataset with two classes, with high probability constructs\nan interpolating three-layer neural network in polynomial time. The required\nnumber of parameters is linked to geometric properties of the two classes and\ntheir mutual arrangement. As a result, we obtain guarantees that are\nindependent of the number of samples and hence move beyond worst-case\nmemorization capacity bounds. We illustrate the effectiveness of the algorithm\nin non-pathological situations with extensive numerical experiments and link\nthe insights back to the theoretical results.",
          "link": "http://arxiv.org/abs/2310.00327",
          "publishedOn": "2023-10-14T00:41:29.495Z",
          "wordCount": 710,
          "title": "Memorization with neural nets: going beyond the worst case. (arXiv:2310.00327v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08115",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Ji_W/0/1/0/all/0/1\">Wenlong Ji</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Lei_L/0/1/0/all/0/1\">Lihua Lei</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Spector_A/0/1/0/all/0/1\">Asher Spector</a>",
          "description": "Many causal estimands are only partially identifiable since they depend on\nthe unobservable joint distribution between potential outcomes. Stratification\non pretreatment covariates can yield sharper partial identification bounds;\nhowever, unless the covariates are discrete with relatively small support, this\napproach typically requires consistent estimation of the conditional\ndistributions of the potential outcomes given the covariates. Thus, existing\napproaches may fail under model misspecification or if consistency assumptions\nare violated. In this study, we propose a unified and model-agnostic\ninferential approach for a wide class of partially identified estimands, based\non duality theory for optimal transport problems. In randomized experiments,\nour approach can wrap around any estimates of the conditional distributions and\nprovide uniformly valid inference, even if the initial estimates are\narbitrarily inaccurate. Also, our approach is doubly robust in observational\nstudies. Notably, this property allows analysts to use the multiplier bootstrap\nto select covariates and models without sacrificing validity even if the true\nmodel is not included. Furthermore, if the conditional distributions are\nestimated at semiparametric rates, our approach matches the performance of an\noracle with perfect knowledge of the outcome model. Finally, we propose an\nefficient computational framework, enabling implementation on many practical\nproblems in causal inference.",
          "link": "http://arxiv.org/abs/2310.08115",
          "publishedOn": "2023-10-14T00:41:29.489Z",
          "wordCount": 717,
          "title": "Model-Agnostic Covariate-Assisted Inference on Partially Identified Causal Effects. (arXiv:2310.08115v1 [econ.EM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.09663",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Botvinick_Greenhouse_J/0/1/0/all/0/1\">Jonah Botvinick-Greenhouse</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1\">Yunan Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maulik_R/0/1/0/all/0/1\">Romit Maulik</a>",
          "description": "Motivated by the computational difficulties incurred by popular deep learning\nalgorithms for the generative modeling of temporal densities, we propose a\ncheap alternative which requires minimal hyperparameter tuning and scales\nfavorably to high dimensional problems. In particular, we use a\nprojection-based optimal transport solver [Meng et al., 2019] to join\nsuccessive samples and subsequently use transport splines [Chewi et al., 2020]\nto interpolate the evolving density. When the sampling frequency is\nsufficiently high, the optimal maps are close to the identity and are thus\ncomputationally efficient to compute. Moreover, the training process is highly\nparallelizable as all optimal maps are independent and can thus be learned\nsimultaneously. Finally, the approach is based solely on numerical linear\nalgebra rather than minimizing a nonconvex objective function, allowing us to\neasily analyze and control the algorithm. We present several numerical\nexperiments on both synthetic and real-world datasets to demonstrate the\nefficiency of our method. In particular, these experiments show that the\nproposed approach is highly competitive compared with state-of-the-art\nnormalizing flows conditioned on time across a wide range of dimensionalities.",
          "link": "http://arxiv.org/abs/2304.09663",
          "publishedOn": "2023-10-14T00:41:29.473Z",
          "wordCount": 774,
          "title": "Generative modeling of time-dependent densities via optimal transport and projection pursuit. (arXiv:2304.09663v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weisz_G/0/1/0/all/0/1\">Gell&#xe9;rt Weisz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andr&#xe1;s Gy&#xf6;rgy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesv&#xe1;ri</a>",
          "description": "We consider online reinforcement learning (RL) in episodic Markov decision\nprocesses (MDPs) under the linear $q^\\pi$-realizability assumption, where it is\nassumed that the action-values of all policies can be expressed as linear\nfunctions of state-action features. This class is known to be more general than\nlinear MDPs, where the transition kernel and the reward function are assumed to\nbe linear functions of the feature vectors. As our first contribution, we show\nthat the difference between the two classes is the presence of states in\nlinearly $q^\\pi$-realizable MDPs where for any policy, all the actions have\napproximately equal values, and skipping over these states by following an\narbitrarily fixed policy in those states transforms the problem to a linear\nMDP. Based on this observation, we derive a novel (computationally inefficient)\nlearning algorithm for linearly $q^\\pi$-realizable MDPs that simultaneously\nlearns what states should be skipped over and runs another learning algorithm\non the linear MDP hidden in the problem. The method returns an\n$\\epsilon$-optimal policy after $\\text{polylog}(H, d)/\\epsilon^2$ interactions\nwith the MDP, where $H$ is the time horizon and $d$ is the dimension of the\nfeature vectors, giving the first polynomial-sample-complexity online RL\nalgorithm for this setting. The results are proved for the misspecified case,\nwhere the sample complexity is shown to degrade gracefully with the\nmisspecification error.",
          "link": "http://arxiv.org/abs/2310.07811",
          "publishedOn": "2023-10-14T00:41:29.433Z",
          "wordCount": 769,
          "title": "Online RL in Linearly $q^\\pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore. (arXiv:2310.07811v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08209",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cholaquidis_A/0/1/0/all/0/1\">Alejandro Cholaquidis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gamboa_F/0/1/0/all/0/1\">Fabrice Gamboa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moreno_L/0/1/0/all/0/1\">Leonardo Moreno</a>",
          "description": "Regression on manifolds, and, more broadly, statistics on manifolds, has\ngarnered significant importance in recent years due to the vast number of\napplications for this type of data. Circular data is a classic example, but so\nis data in the space of covariance matrices, data on the Grassmannian manifold\nobtained as a result of principal component analysis, among many others. In\nthis work we investigate prediction sets for regression scenarios when the\nresponse variable, denoted by $Y$, resides in a manifold, and the covariable,\ndenoted by X, lies in Euclidean space. This extends the concepts delineated in\n[Lei and Wasserman, 2014] to this novel context. Aligning with traditional\nprinciples in conformal inference, these prediction sets are distribution-free,\nindicating that no specific assumptions are imposed on the joint distribution\nof $(X, Y)$, and they maintain a non-parametric character. We prove the\nasymptotic almost sure convergence of the empirical version of these regions on\nthe manifold to their population counterparts. The efficiency of this method is\nshown through a comprehensive simulation study and an analysis involving\nreal-world data.",
          "link": "http://arxiv.org/abs/2310.08209",
          "publishedOn": "2023-10-14T00:41:29.425Z",
          "wordCount": 668,
          "title": "Conformal inference for regression on Riemannian Manifolds. (arXiv:2310.08209v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08150",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Steland_A/0/1/0/all/0/1\">Ansgar Steland</a>",
          "description": "Maximum-type statistics of certain functions of the sample covariance matrix\nof high-dimensional vector time series are studied to statistically confirm or\nreject the null hypothesis that a data set has been collected under normal\nconditions. The approach generalizes the case of the maximal deviation of the\nsample autocovariances function from its assumed values. Within a linear time\nseries framework it is shown that Gumbel-type extreme value asymptotics holds\ntrue. As applications we discuss long-only mimimal-variance portfolio\noptimization and subportfolio analysis with respect to idiosyncratic risks, ETF\nindex tracking by sparse tracking portfolios, convolutional deep learners for\nimage analysis and the analysis of array-of-sensors data.",
          "link": "http://arxiv.org/abs/2310.08150",
          "publishedOn": "2023-10-14T00:41:29.394Z",
          "wordCount": 634,
          "title": "On Extreme Value Asymptotics of Projected Sample Covariances in High Dimensions with Applications in Finance and Convolutional Networks. (arXiv:2310.08150v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luca_A/0/1/0/all/0/1\">Artur Back de Luca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fountoulakis_K/0/1/0/all/0/1\">Kimon Fountoulakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shenghao Yang</a>",
          "description": "The growing interest in machine learning problems over graphs with additional\nnode information such as texts, images, or labels has popularized methods that\nrequire the costly operation of processing the entire graph. Yet, little effort\nhas been made to the development of fast local methods (i.e. without accessing\nthe entire graph) that extract useful information from such data. To that end,\nwe propose a study of local graph clustering using noisy node labels as a proxy\nfor additional node information. In this setting, nodes receive initial binary\nlabels based on cluster affiliation: 1 if they belong to the target cluster and\n0 otherwise. Subsequently, a fraction of these labels is flipped. We\ninvestigate the benefits of incorporating noisy labels for local graph\nclustering. By constructing a weighted graph with such labels, we study the\nperformance of graph diffusion-based local clustering method on both the\noriginal and the weighted graphs. From a theoretical perspective, we consider\nrecovering an unknown target cluster with a single seed node in a random graph\nwith independent noisy node labels. We provide sufficient conditions on the\nlabel noise under which, with high probability, using diffusion in the weighted\ngraph yields a more accurate recovery of the target cluster. This approach\nproves more effective than using the given labels alone or using diffusion in\nthe label-free original graph. Empirically, we show that reliable node labels\ncan be obtained with just a few samples from an attributed graph. Moreover,\nutilizing these labels via diffusion in the weighted graph leads to\nsignificantly better local clustering performance across several real-world\ndatasets, improving F1 scores by up to 13%.",
          "link": "http://arxiv.org/abs/2310.08031",
          "publishedOn": "2023-10-14T00:41:29.335Z",
          "wordCount": 784,
          "title": "Local Graph Clustering with Noisy Labels. (arXiv:2310.08031v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08410",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wei_Q/0/1/0/all/0/1\">Qiuhong Wei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yao_Z/0/1/0/all/0/1\">Zhengxiong Yao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cui_Y/0/1/0/all/0/1\">Ying Cui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wei_B/0/1/0/all/0/1\">Bo Wei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jin_Z/0/1/0/all/0/1\">Zhezhen Jin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_X/0/1/0/all/0/1\">Ximing Xu</a>",
          "description": "Large language models such as ChatGPT are increasingly explored in medical\ndomains. However, the absence of standard guidelines for performance evaluation\nhas led to methodological inconsistencies. This study aims to summarize the\navailable evidence on evaluating ChatGPT's performance in medicine and provide\ndirection for future research. We searched ten medical literature databases on\nJune 15, 2023, using the keyword \"ChatGPT\". A total of 3520 articles were\nidentified, of which 60 were reviewed and summarized in this paper and 17 were\nincluded in the meta-analysis. The analysis showed that ChatGPT displayed an\noverall integrated accuracy of 56% (95% CI: 51%-60%, I2 = 87%) in addressing\nmedical queries. However, the studies varied in question resource,\nquestion-asking process, and evaluation metrics. Moreover, many studies failed\nto report methodological details, including the version of ChatGPT and whether\neach question was used independently or repeatedly. Our findings revealed that\nalthough ChatGPT demonstrated considerable potential for application in\nhealthcare, the heterogeneity of the studies and insufficient reporting may\naffect the reliability of these results. Further well-designed studies with\ncomprehensive and transparent reporting are needed to evaluate ChatGPT's\nperformance in medicine.",
          "link": "http://arxiv.org/abs/2310.08410",
          "publishedOn": "2023-10-14T00:41:29.254Z",
          "wordCount": 690,
          "title": "Evaluation of ChatGPT-Generated Medical Responses: A Systematic Review and Meta-Analysis. (arXiv:2310.08410v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08426",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Butts_J/0/1/0/all/0/1\">J. Butts</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wendt_C/0/1/0/all/0/1\">C. Wendt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bowler_R/0/1/0/all/0/1\">R. Bowler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hersh_C/0/1/0/all/0/1\">C.P. Hersh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Long_Q/0/1/0/all/0/1\">Q. Long</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Eberly_L/0/1/0/all/0/1\">L. Eberly</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Safo_S/0/1/0/all/0/1\">S. E. Safo</a>",
          "description": "Multiple data views measured on the same set of participants is becoming more\ncommon and has the potential to deepen our understanding of many complex\ndiseases by analyzing these different views simultaneously. Equally important,\nmany of these complex diseases show evidence of subgroup heterogeneity (e.g.,\nby sex or race). HIP (Heterogeneity in Integration and Prediction) is among the\nfirst methods proposed to integrate multiple data views while also accounting\nfor subgroup heterogeneity to identify common and subgroup-specific markers of\na particular disease. However, HIP is applicable to continuous outcomes and\nrequires programming expertise by the user. Here we propose extensions to HIP\nthat accommodate multi-class, Poisson, and Zero-Inflated Poisson outcomes while\nretaining the benefits of HIP. Additionally, we introduce an R Shiny\napplication, accessible on shinyapps.io at\nhttps://multi-viewlearn.shinyapps.io/HIP_ShinyApp/, that provides an interface\nwith the Python implementation of HIP to allow more researchers to use the\nmethod anywhere and on any device. We applied HIP to identify genes and\nproteins common and specific to males and females that are associated with\nexacerbation frequency. Although some of the identified genes and proteins show\nevidence of a relationship with chronic obstructive pulmonary disease (COPD) in\nexisting literature, others may be candidates for future research investigating\ntheir relationship with COPD. We demonstrate the use of the Shiny application\nwith a publicly available data. An R-package for HIP would be made available at\nhttps://github.com/lasandrall/HIP.",
          "link": "http://arxiv.org/abs/2310.08426",
          "publishedOn": "2023-10-14T00:41:29.206Z",
          "wordCount": 760,
          "title": "Extensions of Heterogeneity in Integration and Prediction (HIP) with R Shiny Application. (arXiv:2310.08426v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.05898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lizhang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kaizhao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>",
          "description": "Lion (Evolved Sign Momentum), a new optimizer discovered through program\nsearch, has shown promising results in training large AI models. It performs\ncomparably or favorably to AdamW but with greater memory efficiency. As we can\nexpect from the results of a random search program, Lion incorporates elements\nfrom several existing algorithms, including signed momentum, decoupled weight\ndecay, Polak, and Nesterov momentum, but does not fit into any existing\ncategory of theoretically grounded optimizers. Thus, even though Lion appears\nto perform well as a general-purpose optimizer for a wide range of tasks, its\ntheoretical basis remains uncertain. This lack of theoretical clarity limits\nopportunities to further enhance and expand Lion's efficacy.\n\nThis work aims to demystify Lion. Based on both continuous-time and\ndiscrete-time analysis, we demonstrate that Lion is a theoretically novel and\nprincipled approach for minimizing a general loss function $f(x)$ while\nenforcing a bound constraint $\\|x\\|_\\infty \\leq 1/\\lambda$. Lion achieves this\nthrough the incorporation of decoupled weight decay, where $\\lambda$ represents\nthe weight decay coefficient. Our analysis is made possible by the development\nof a new Lyapunov function for the Lion updates. It applies to a broader family\nof Lion-$\\kappa$ algorithms, where the $\\text{sign}(\\cdot)$ operator in Lion is\nreplaced by the subgradient of a convex function $\\kappa$, leading to the\nsolution of a general composite optimization problem of $\\min_x f(x) +\n\\kappa^*(x)$. Our findings provide valuable insights into the dynamics of Lion\nand pave the way for further improvements and extensions of Lion-related\nalgorithms.",
          "link": "http://arxiv.org/abs/2310.05898",
          "publishedOn": "2023-10-14T00:41:29.197Z",
          "wordCount": 788,
          "title": "Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts. (arXiv:2310.05898v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Licong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1\">Song Mei</a>",
          "description": "Large transformer models pretrained on offline reinforcement learning\ndatasets have demonstrated remarkable in-context reinforcement learning (ICRL)\ncapabilities, where they can make good decisions when prompted with interaction\ntrajectories from unseen environments. However, when and how transformers can\nbe trained to perform ICRL have not been theoretically well-understood. In\nparticular, it is unclear which reinforcement-learning algorithms transformers\ncan perform in context, and how distribution mismatch in offline training data\naffects the learned algorithms. This paper provides a theoretical framework\nthat analyzes supervised pretraining for ICRL. This includes two recently\nproposed training methods -- algorithm distillation and decision-pretrained\ntransformers. First, assuming model realizability, we prove the\nsupervised-pretrained transformer will imitate the conditional expectation of\nthe expert algorithm given the observed trajectory. The generalization error\nwill scale with model capacity and a distribution divergence factor between the\nexpert and offline algorithms. Second, we show transformers with ReLU attention\ncan efficiently approximate near-optimal online reinforcement learning\nalgorithms like LinUCB and Thompson sampling for stochastic linear bandits, and\nUCB-VI for tabular Markov decision processes. This provides the first\nquantitative analysis of the ICRL capabilities of transformers pretrained from\noffline trajectories.",
          "link": "http://arxiv.org/abs/2310.08566",
          "publishedOn": "2023-10-14T00:41:29.191Z",
          "wordCount": 717,
          "title": "Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining. (arXiv:2310.08566v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.07415",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1\">Jie Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dey_S/0/1/0/all/0/1\">Santanu S. Dey</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>",
          "description": "We consider the variable selection problem for two-sample tests, aiming to\nselect the most informative variables to distinguish samples from two groups.\nTo solve this problem, we propose a framework based on the kernel maximum mean\ndiscrepancy (MMD). Our approach seeks a group of variables with a pre-specified\nsize that maximizes the variance-regularized MMD statistics. This formulation\nalso corresponds to the minimization of asymptotic type-II error while\ncontrolling type-I error, as studied in the literature. We present\nmixed-integer programming formulations and develop exact and approximation\nalgorithms with performance guarantees for different choices of kernel\nfunctions. Furthermore, we provide a statistical testing power analysis of our\nproposed framework. Experiment results on synthetic and real datasets\ndemonstrate the superior performance of our approach.",
          "link": "http://arxiv.org/abs/2302.07415",
          "publishedOn": "2023-10-14T00:41:29.174Z",
          "wordCount": 646,
          "title": "Variable Selection for Kernel Two-Sample Tests. (arXiv:2302.07415v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08053",
          "author": "<a href=\"http://arxiv.org/find/hep-lat/1/au:+Alvestad_D/0/1/0/all/0/1\">Daniel Alvestad</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Rothkopf_A/0/1/0/all/0/1\">Alexander Rothkopf</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Sexty_D/0/1/0/all/0/1\">D&#xe9;nes Sexty</a>",
          "description": "We present a simulation strategy for the real-time dynamics of quantum\nfields, inspired by reinforcement learning. It builds on the complex Langevin\napproach, which it amends with system specific prior information, a necessary\nprerequisite to overcome this exceptionally severe sign problem. The\noptimization process underlying our machine learning approach is made possible\nby deploying inherently stable solvers of the complex Langevin stochastic\nprocess and a novel optimality criterion derived from insight into so-called\nboundary terms. This conceptual and technical progress allows us to both\nsignificantly extend the range of real-time simulations in 1+1d scalar field\ntheory beyond the state-of-the-art and to avoid discretization artifacts that\nplagued previous real-time field theory simulations. Limitations of and\npromising future directions are discussed.",
          "link": "http://arxiv.org/abs/2310.08053",
          "publishedOn": "2023-10-14T00:41:29.168Z",
          "wordCount": 636,
          "title": "Lattice real-time simulations with learned optimal kernels. (arXiv:2310.08053v1 [hep-lat])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07852",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Roy_S/0/1/0/all/0/1\">Saptarshi Roy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1\">Ambuj Tewari</a>",
          "description": "We consider the problem of model selection in a high-dimensional sparse\nlinear regression model under the differential privacy framework. In\nparticular, we consider the problem of differentially private best subset\nselection and study its utility guarantee. We adopt the well-known exponential\nmechanism for selecting the best model, and under a certain margin condition,\nwe establish its strong model recovery property. However, the exponential\nsearch space of the exponential mechanism poses a serious computational\nbottleneck. To overcome this challenge, we propose a Metropolis-Hastings\nalgorithm for the sampling step and establish its polynomial mixing time to its\nstationary distribution in the problem parameters $n,p$, and $s$. Furthermore,\nwe also establish approximate differential privacy for the final estimates of\nthe Metropolis-Hastings random walk using its mixing property. Finally, we also\nperform some illustrative simulations that echo the theoretical findings of our\nmain results.",
          "link": "http://arxiv.org/abs/2310.07852",
          "publishedOn": "2023-10-14T00:41:29.163Z",
          "wordCount": 663,
          "title": "On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08089",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fengzhuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1\">Vincent Y. F. Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>",
          "description": "This paper studies two fundamental problems in regularized Graphon Mean-Field\nGames (GMFGs). First, we establish the existence of a Nash Equilibrium (NE) of\nany $\\lambda$-regularized GMFG (for $\\lambda\\geq 0$). This result relies on\nweaker conditions than those in previous works for analyzing both unregularized\nGMFGs ($\\lambda=0$) and $\\lambda$-regularized MFGs, which are special cases of\nGMFGs. Second, we propose provably efficient algorithms to learn the NE in\nweakly monotone GMFGs, motivated by Lasry and Lions [2007]. Previous literature\neither only analyzed continuous-time algorithms or required extra conditions to\nanalyze discrete-time algorithms. In contrast, we design a discrete-time\nalgorithm and derive its convergence rate solely under weakly monotone\nconditions. Furthermore, we develop and analyze the action-value function\nestimation procedure during the online learning process, which is absent from\nalgorithms for monotone GMFGs. This serves as a sub-module in our optimization\nalgorithm. The efficiency of the designed algorithm is corroborated by\nempirical evaluations.",
          "link": "http://arxiv.org/abs/2310.08089",
          "publishedOn": "2023-10-14T00:41:29.156Z",
          "wordCount": 656,
          "title": "Learning Regularized Monotone Graphon Mean-Field Games. (arXiv:2310.08089v1 [cs.GT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_K/0/1/0/all/0/1\">Kushagra Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudolph_M/0/1/0/all/0/1\">Maja Rudolph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>",
          "description": "Diffusion models suffer from slow sample generation at inference time.\nTherefore, developing a principled framework for fast deterministic/stochastic\nsampling for a broader class of diffusion models is a promising direction. We\npropose two complementary frameworks for accelerating sample generation in\npre-trained models: Conjugate Integrators and Splitting Integrators. Conjugate\nintegrators generalize DDIM, mapping the reverse diffusion dynamics to a more\namenable space for sampling. In contrast, splitting-based integrators, commonly\nused in molecular dynamics, reduce the numerical simulation error by cleverly\nalternating between numerical updates involving the data and auxiliary\nvariables. After extensively studying these methods empirically and\ntheoretically, we present a hybrid method that leads to the best-reported\nperformance for diffusion models in augmented spaces. Applied to Phase Space\nLangevin Diffusion [Pandey & Mandt, 2023] on CIFAR-10, our deterministic and\nstochastic samplers achieve FID scores of 2.11 and 2.36 in only 100 network\nfunction evaluations (NFE) as compared to 2.57 and 2.63 for the best-performing\nbaselines, respectively. Our code and model checkpoints will be made publicly\navailable at \\url{https://github.com/mandt-lab/PSLD}.",
          "link": "http://arxiv.org/abs/2310.07894",
          "publishedOn": "2023-10-14T00:41:29.138Z",
          "wordCount": 676,
          "title": "Efficient Integrators for Diffusion Generative Models. (arXiv:2310.07894v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08391",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_J/0/1/0/all/0/1\">Jingfeng Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zou_D/0/1/0/all/0/1\">Difan Zou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1\">Zixiang Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Braverman_V/0/1/0/all/0/1\">Vladimir Braverman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "Transformers pretrained on diverse tasks exhibit remarkable in-context\nlearning (ICL) capabilities, enabling them to solve unseen tasks solely based\non input contexts without adjusting model parameters. In this paper, we study\nICL in one of its simplest setups: pretraining a linearly parameterized\nsingle-layer linear attention model for linear regression with a Gaussian\nprior. We establish a statistical task complexity bound for the attention model\npretraining, showing that effective pretraining only requires a small number of\nindependent tasks. Furthermore, we prove that the pretrained model closely\nmatches the Bayes optimal algorithm, i.e., optimally tuned ridge regression, by\nachieving nearly Bayes optimal risk on unseen tasks under a fixed context\nlength. These theoretical findings complement prior experimental research and\nshed light on the statistical foundations of ICL.",
          "link": "http://arxiv.org/abs/2310.08391",
          "publishedOn": "2023-10-14T00:41:29.132Z",
          "wordCount": 644,
          "title": "How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?. (arXiv:2310.08391v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08479",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chatton_A/0/1/0/all/0/1\">Arthur Chatton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bally_M/0/1/0/all/0/1\">Mich&#xe8;le Bally</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Levesque_R/0/1/0/all/0/1\">Ren&#xe9;e L&#xe9;vesque</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Malenica_I/0/1/0/all/0/1\">Ivana Malenica</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Platt_R/0/1/0/all/0/1\">Robert W. Platt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schnitzer_M/0/1/0/all/0/1\">Mireille E. Schnitzer</a>",
          "description": "Obtaining continuously updated predictions is a major challenge for\npersonalised medicine. Leveraging combinations of parametric regressions and\nmachine learning approaches, the personalised online super learner (POSL) can\nachieve such dynamic and personalised predictions. We adapt POSL to predict a\nrepeated continuous outcome dynamically and propose a new way to validate such\npersonalised or dynamic prediction models. We illustrate its performance by\npredicting the convection volume of patients undergoing hemodiafiltration. POSL\noutperformed its candidate learners with respect to median absolute error,\ncalibration-in-the-large, discrimination, and net benefit. We finally discuss\nthe choices and challenges underlying the use of POSL.",
          "link": "http://arxiv.org/abs/2310.08479",
          "publishedOn": "2023-10-14T00:41:29.127Z",
          "wordCount": 624,
          "title": "Personalised dynamic super learning: an application in predicting hemodiafiltration's convection volumes. (arXiv:2310.08479v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1908.04628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xindi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varol_O/0/1/0/all/0/1\">Onur Varol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1\">Tina Eliassi-Rad</a>",
          "description": "Many real-world prediction tasks have outcome variables that have\ncharacteristic heavy-tail distributions. Examples include copies of books sold,\nauction prices of art pieces, demand for commodities in warehouses, etc. By\nlearning heavy-tailed distributions, \"big and rare\" instances (e.g., the\nbest-sellers) will have accurate predictions. Most existing approaches are not\ndedicated to learning heavy-tailed distribution; thus, they heavily\nunder-predict such instances. To tackle this problem, we introduce Learning to\nPlace (L2P), which exploits the pairwise relationships between instances for\nlearning. In its training phase, L2P learns a pairwise preference classifier:\nis instance A > instance B? In its placing phase, L2P obtains a prediction by\nplacing the new instance among the known instances. Based on its placement, the\nnew instance is then assigned a value for its outcome variable. Experiments on\nreal data show that L2P outperforms competing approaches in terms of accuracy\nand ability to reproduce heavy-tailed outcome distribution. In addition, L2P\nprovides an interpretable model by placing each predicted instance in relation\nto its comparable neighbors. Interpretable models are highly desirable when\nlives and treasure are at stake.",
          "link": "http://arxiv.org/abs/1908.04628",
          "publishedOn": "2023-10-14T00:41:29.121Z",
          "wordCount": 776,
          "title": "L2P: Learning to Place for Estimating Heavy-Tailed Distributed Outcomes. (arXiv:1908.04628v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07973",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Michael Lingzhi Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Imai_K/0/1/0/all/0/1\">Kosuke Imai</a>",
          "description": "Across a wide array of disciplines, many researchers use machine learning\n(ML) algorithms to identify a subgroup of individuals, called exceptional\nresponders, who are likely to be helped by a treatment the most. A common\napproach consists of two steps. One first estimates the conditional average\ntreatment effect or its proxy using an ML algorithm. They then determine the\ncutoff of the resulting treatment prioritization score to select those\npredicted to benefit most from the treatment. Unfortunately, these estimated\ntreatment prioritization scores are often biased and noisy. Furthermore,\nutilizing the same data to both choose a cutoff value and estimate the average\ntreatment effect among the selected individuals suffer from a multiple testing\nproblem. To address these challenges, we develop a uniform confidence band for\nexperimentally evaluating the sorted average treatment effect (GATES) among the\nindividuals whose treatment prioritization score is at least as high as any\ngiven quantile value, regardless of how the quantile is chosen. This provides a\nstatistical guarantee that the GATES for the selected subgroup exceeds a\ncertain threshold. The validity of the proposed methodology depends solely on\nrandomization of treatment and random sampling of units without requiring\nmodeling assumptions or resampling methods. This widens its applicability\nincluding a wide range of other causal quantities. A simulation study shows\nthat the empirical coverage of the proposed uniform confidence bands is close\nto the nominal coverage when the sample is as small as 100. We analyze a\nclinical trial of late-stage prostate cancer and find a relatively large\nproportion of exceptional responders with a statistical performance guarantee.",
          "link": "http://arxiv.org/abs/2310.07973",
          "publishedOn": "2023-10-14T00:41:29.114Z",
          "wordCount": 778,
          "title": "Statistical Performance Guarantee for Selecting Those Predicted to Benefit Most from Treatment. (arXiv:2310.07973v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.08237",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_X/0/1/0/all/0/1\">Xingdong Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_X/0/1/0/all/0/1\">Xin He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1\">Caixing Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1\">Chao Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jingnan Zhang</a>",
          "description": "Covariate shift occurs prevalently in practice, where the input distributions\nof the source and target data are substantially different. Despite its\npractical importance in various learning problems, most of the existing methods\nonly focus on some specific learning tasks and are not well validated\ntheoretically and numerically. To tackle this problem, we propose a unified\nanalysis of general nonparametric methods in a reproducing kernel Hilbert space\n(RKHS) under covariate shift. Our theoretical results are established for a\ngeneral loss belonging to a rich loss function family, which includes many\ncommonly used methods as special cases, such as mean regression, quantile\nregression, likelihood-based classification, and margin-based classification.\nTwo types of covariate shift problems are the focus of this paper and the sharp\nconvergence rates are established for a general loss function to provide a\nunified theoretical analysis, which concurs with the optimal results in\nliterature where the squared loss is used. Extensive numerical studies on\nsynthetic and real examples confirm our theoretical findings and further\nillustrate the effectiveness of our proposed method.",
          "link": "http://arxiv.org/abs/2310.08237",
          "publishedOn": "2023-10-14T00:41:29.097Z",
          "wordCount": 697,
          "title": "Towards a Unified Analysis of Kernel-based Methods Under Covariate Shift. (arXiv:2310.08237v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.07838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qingyue Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Banghua Zhu</a>",
          "description": "We characterize the statistical efficiency of knowledge transfer through $n$\nsamples from a teacher to a probabilistic student classifier with input space\n$\\mathcal S$ over labels $\\mathcal A$. We show that privileged information at\nthree progressive levels accelerates the transfer. At the first level, only\nsamples with hard labels are known, via which the maximum likelihood estimator\nattains the minimax rate $\\sqrt{{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. The\nsecond level has the teacher probabilities of sampled labels available in\naddition, which turns out to boost the convergence rate lower bound to\n${{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. However, under this second data\nacquisition protocol, minimizing a naive adaptation of the cross-entropy loss\nresults in an asymptotically biased student. We overcome this limitation and\nachieve the fundamental limit by using a novel empirical variant of the squared\nerror logit loss. The third level further equips the student with the soft\nlabels (complete logits) on ${\\mathcal A}$ given every sampled input, thereby\nprovably enables the student to enjoy a rate ${|{\\mathcal S}|}/{n}$ free of\n$|{\\mathcal A}|$. We find any Kullback-Leibler divergence minimizer to be\noptimal in the last case. Numerical simulations distinguish the four learners\nand corroborate our theory.",
          "link": "http://arxiv.org/abs/2310.07838",
          "publishedOn": "2023-10-14T00:41:29.079Z",
          "wordCount": 722,
          "title": "Towards the Fundamental Limits of Knowledge Transfer over Finite Domains. (arXiv:2310.07838v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03696",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Parhi_R/0/1/0/all/0/1\">Rahul Parhi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Unser_M/0/1/0/all/0/1\">Michael Unser</a>",
          "description": "We investigate the variational optimality (specifically, the Banach space\noptimality) of a large class of neural architectures with multivariate\nnonlinearities/activation functions. To that end, we construct a new family of\nBanach spaces defined via a regularization operator and the $k$-plane\ntransform. We prove a representer theorem that states that the solution sets to\nlearning problems posed over these Banach spaces are completely characterized\nby neural architectures with multivariate nonlinearities. These optimal\narchitectures have skip connections and are tightly connected to orthogonal\nweight normalization and multi-index models, both of which have received\nconsiderable interest in the neural network community. Our framework is\ncompatible with a number of classical nonlinearities including the rectified\nlinear unit (ReLU) activation function, the norm activation function, and the\nradial basis functions found in the theory of thin-plate/polyharmonic splines.\nWe also show that the underlying spaces are special instances of reproducing\nkernel Banach spaces and variation spaces. Our results shed light on the\nregularity of functions learned by neural networks trained on data,\nparticularly with multivariate nonlinearities, and provide new theoretical\nmotivation for several architectural choices found in practice.",
          "link": "http://arxiv.org/abs/2310.03696",
          "publishedOn": "2023-10-07T00:42:19.671Z",
          "wordCount": null,
          "title": "Banach Space Optimality of Neural Architectures With Multivariate Nonlinearities. (arXiv:2310.03696v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03556",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bolat_K/0/1/0/all/0/1\">Kutay B&#xf6;lat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tindemans_S/0/1/0/all/0/1\">Simon H. Tindemans</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Palensky_P/0/1/0/all/0/1\">Peter Palensky</a>",
          "description": "Probabilistic modelling of power systems operation and planning processes\ndepends on data-driven methods, which require sufficiently large datasets. When\nhistorical data lacks this, it is desired to model the underlying data\ngeneration mechanism as a probability distribution to assess the data quality\nand generate more data, if needed. Kernel density estimation (KDE) based models\nare popular choices for this task, but they fail to adapt to data regions with\nvarying densities. In this paper, an adaptive KDE model is employed to\ncircumvent this, where each kernel in the model has an individual bandwidth.\nThe leave-one-out maximum log-likelihood (LOO-MLL) criterion is proposed to\nprevent the singular solutions that the regular MLL criterion gives rise to,\nand it is proven that LOO-MLL prevents these. Relying on this guaranteed\nrobustness, the model is extended by assigning learnable weights to the\nkernels. In addition, a modified expectation-maximization algorithm is employed\nto accelerate the optimization speed reliably. The performance of the proposed\nmethod and models are exhibited on two power systems datasets using different\nstatistical tests and by comparison with Gaussian mixture models. Results show\nthat the proposed models have promising performance, in addition to their\nsingularity prevention guarantees.",
          "link": "http://arxiv.org/abs/2310.03556",
          "publishedOn": "2023-10-07T00:42:19.668Z",
          "wordCount": null,
          "title": "Stable Training of Probabilistic Models Using the Leave-One-Out Maximum Log-Likelihood Objective. (arXiv:2310.03556v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05120",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Deng_W/0/1/0/all/0/1\">Wei Deng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Q/0/1/0/all/0/1\">Qian Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1\">Yi-An Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1\">Guang Lin</a>",
          "description": "We propose a federated averaging Langevin algorithm (FA-LD) for uncertainty\nquantification and mean predictions with distributed clients. In particular, we\ngeneralize beyond normal posterior distributions and consider a general class\nof models. We develop theoretical guarantees for FA-LD for strongly log-concave\ndistributions with non-i.i.d data and study how the injected noise and the\nstochastic-gradient noise, the heterogeneity of data, and the varying learning\nrates affect the convergence. Such an analysis sheds light on the optimal\nchoice of local updates to minimize communication costs. Important to our\napproach is that the communication efficiency does not deteriorate with the\ninjected noise in the Langevin algorithms. In addition, we examine in our FA-LD\nalgorithm both independent and correlated noise used over different clients. We\nobserve there is a trade-off between the pairs among communication, accuracy,\nand data privacy. As local devices may become inactive in federated networks,\nwe also show convergence results based on different averaging schemes where\nonly partial device updates are available. In such a case, we discover an\nadditional bias that does not decay to zero.",
          "link": "http://arxiv.org/abs/2112.05120",
          "publishedOn": "2023-10-07T00:42:19.667Z",
          "wordCount": null,
          "title": "On Convergence of Federated Averaging Langevin Dynamics. (arXiv:2112.05120v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03722",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1\">Hongjian Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "In 1976, Lai constructed a nontrivial confidence sequence for the mean $\\mu$\nof a Gaussian distribution with unknown variance $\\sigma$. Curiously, he\nemployed both an improper (right Haar) mixture over $\\sigma$ and an improper\n(flat) mixture over $\\mu$. Here, we elaborate carefully on the details of his\nconstruction, which use generalized nonintegrable martingales and an extended\nVille's inequality. While this does yield a sequential t-test, it does not\nyield an ``e-process'' (due to the nonintegrability of his martingale). In this\npaper, we develop two new e-processes and confidence sequences for the same\nsetting: one is a test martingale in a reduced filtration, while the other is\nan e-process in the canonical data filtration. These are respectively obtained\nby swapping Lai's flat mixture for a Gaussian mixture, and swapping the right\nHaar mixture over $\\sigma$ with the maximum likelihood estimate under the null,\nas done in universal inference. We also analyze the width of resulting\nconfidence sequences, which have a curious dependence on the error probability\n$\\alpha$. Numerical experiments are provided along the way to compare and\ncontrast the various approaches.",
          "link": "http://arxiv.org/abs/2310.03722",
          "publishedOn": "2023-10-07T00:42:19.666Z",
          "wordCount": null,
          "title": "Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.13053",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Assel_H/0/1/0/all/0/1\">Hugues Van Assel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Espinasse_T/0/1/0/all/0/1\">Thibault Espinasse</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chiquet_J/0/1/0/all/0/1\">Julien Chiquet</a>, <a href=\"http://arxiv.org/find/math/1/au:+Picard_F/0/1/0/all/0/1\">Franck Picard</a>",
          "description": "Most popular dimension reduction (DR) methods like t-SNE and UMAP are based\non minimizing a cost between input and latent pairwise similarities. Though\nwidely used, these approaches lack clear probabilistic foundations to enable a\nfull understanding of their properties and limitations. To that extent, we\nintroduce a unifying statistical framework based on the coupling of hidden\ngraphs using cross entropy. These graphs induce a Markov random field\ndependency structure among the observations in both input and latent spaces. We\nshow that existing pairwise similarity DR methods can be retrieved from our\nframework with particular choices of priors for the graphs. Moreover this\nreveals that these methods suffer from a statistical deficiency that explains\npoor performances in conserving coarse-grain dependencies. Our model is\nleveraged and extended to address this issue while new links are drawn with\nLaplacian eigenmaps and PCA.",
          "link": "http://arxiv.org/abs/2201.13053",
          "publishedOn": "2023-10-07T00:42:19.666Z",
          "wordCount": null,
          "title": "A Probabilistic Graph Coupling View of Dimension Reduction. (arXiv:2201.13053v3 [math.PR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xuelin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>",
          "description": "Building machines that can reason about physical events and their causal\nrelationships is crucial for flexible interaction with the physical world.\nHowever, most existing physical and causal reasoning benchmarks are exclusively\nbased on synthetically generated events and synthetic natural language\ndescriptions of causal relationships. This design brings up two issues. First,\nthere is a lack of diversity in both event types and natural language\ndescriptions; second, causal relationships based on manually-defined heuristics\nare different from human judgments. To address both shortcomings, we present\nthe CLEVRER-Humans benchmark, a video reasoning dataset for causal judgment of\nphysical events with human labels. We employ two techniques to improve data\ncollection efficiency: first, a novel iterative event cloze task to elicit a\nnew representation of events in videos, which we term Causal Event Graphs\n(CEGs); second, a data augmentation technique based on neural language\ngenerative models. We convert the collected CEGs into questions and answers to\nbe consistent with prior work. Finally, we study a collection of baseline\napproaches for CLEVRER-Humans question-answering, highlighting the great\nchallenges set forth by our benchmark.",
          "link": "http://arxiv.org/abs/2310.03635",
          "publishedOn": "2023-10-07T00:42:19.130Z",
          "wordCount": null,
          "title": "CLEVRER-Humans: Describing Physical and Causal Events the Human Way. (arXiv:2310.03635v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hellsten_E/0/1/0/all/0/1\">Erik Orm Hellsten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hvarfner_C/0/1/0/all/0/1\">Carl Hvarfner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papenmeier_L/0/1/0/all/0/1\">Leonard Papenmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nardi_L/0/1/0/all/0/1\">Luigi Nardi</a>",
          "description": "Bayesian optimization is an effective method for optimizing\nexpensive-to-evaluate black-box functions. High-dimensional problems are\nparticularly challenging as the surrogate model of the objective suffers from\nthe curse of dimensionality, which makes accurate modeling difficult. We\npropose a group testing approach to identify active variables to facilitate\nefficient optimization in these domains. The proposed algorithm, Group Testing\nBayesian Optimization (GTBO), first runs a testing phase where groups of\nvariables are systematically selected and tested on whether they influence the\nobjective. To that end, we extend the well-established theory of group testing\nto functions of continuous ranges. In the second phase, GTBO guides\noptimization by placing more importance on the active dimensions. By exploiting\nthe axis-aligned subspace assumption, GTBO is competitive against\nstate-of-the-art methods on several synthetic and real-world high-dimensional\noptimization tasks. Furthermore, GTBO aids in the discovery of active\nparameters in applications, thereby enhancing practitioners' understanding of\nthe problem at hand.",
          "link": "http://arxiv.org/abs/2310.03515",
          "publishedOn": "2023-10-07T00:42:19.101Z",
          "wordCount": null,
          "title": "High-dimensional Bayesian Optimization with Group Testing. (arXiv:2310.03515v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03112",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Herbinger_J/0/1/0/all/0/1\">Julia Herbinger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dandl_S/0/1/0/all/0/1\">Susanne Dandl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ewald_F/0/1/0/all/0/1\">Fiona K. Ewald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Loibl_S/0/1/0/all/0/1\">Sofia Loibl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Casalicchio_G/0/1/0/all/0/1\">Giuseppe Casalicchio</a>",
          "description": "Surrogate models play a crucial role in retrospectively interpreting complex\nand powerful black box machine learning models via model distillation. This\npaper focuses on using model-based trees as surrogate models which partition\nthe feature space into interpretable regions via decision rules. Within each\nregion, interpretable models based on additive main effects are used to\napproximate the behavior of the black box model, striking for an optimal\nbalance between interpretability and performance. Four model-based tree\nalgorithms, namely SLIM, GUIDE, MOB, and CTree, are compared regarding their\nability to generate such surrogate models. We investigate fidelity,\ninterpretability, stability, and the algorithms' capability to capture\ninteraction effects through appropriate splits. Based on our comprehensive\nanalyses, we finally provide an overview of user-specific recommendations.",
          "link": "http://arxiv.org/abs/2310.03112",
          "publishedOn": "2023-10-07T00:42:19.029Z",
          "wordCount": null,
          "title": "Leveraging Model-based Trees as Interpretable Surrogate Models for Model Distillation. (arXiv:2310.03112v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1\">Philip M. Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "Recent experiments have shown that, often, when training a neural network\nwith gradient descent (GD) with a step size $\\eta$, the operator norm of the\nHessian of the loss grows until it approximately reaches $2/\\eta$, after which\nit fluctuates around this value. The quantity $2/\\eta$ has been called the\n\"edge of stability\" based on consideration of a local quadratic approximation\nof the loss. We perform a similar calculation to arrive at an \"edge of\nstability\" for Sharpness-Aware Minimization (SAM), a variant of GD which has\nbeen shown to improve its generalization. Unlike the case for GD, the resulting\nSAM-edge depends on the norm of the gradient. Using three deep learning\ntraining tasks, we see empirically that SAM operates on the edge of stability\nidentified by this analysis.",
          "link": "http://arxiv.org/abs/2309.12488",
          "publishedOn": "2023-10-07T00:42:19.028Z",
          "wordCount": null,
          "title": "Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Favaro_S/0/1/0/all/0/1\">Stefano Favaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanin_B/0/1/0/all/0/1\">Boris Hanin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marinucci_D/0/1/0/all/0/1\">Domenico Marinucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourdin_I/0/1/0/all/0/1\">Ivan Nourdin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peccati_G/0/1/0/all/0/1\">Giovanni Peccati</a>",
          "description": "We study the distribution of a fully connected neural network with random\nGaussian weights and biases in which the hidden layer widths are proportional\nto a large constant $n$. Under mild assumptions on the non-linearity, we obtain\nquantitative bounds on normal approximations valid at large but finite $n$ and\nany fixed network depth. Our theorems show both for the finite-dimensional\ndistributions and the entire process, that the distance between a random fully\nconnected network (and its derivatives) to the corresponding infinite width\nGaussian process scales like $n^{-\\gamma}$ for $\\gamma>0$, with the exponent\ndepending on the metric used to measure discrepancy. Our bounds are strictly\nstronger in terms of their dependence on network width than any previously\navailable in the literature; in the one-dimensional case, we also prove that\nthey are optimal, i.e., we establish matching lower bounds.",
          "link": "http://arxiv.org/abs/2307.06092",
          "publishedOn": "2023-10-07T00:42:18.978Z",
          "wordCount": null,
          "title": "Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03243",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1\">Mingxuan Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yan Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liang_F/0/1/0/all/0/1\">Faming Liang</a>",
          "description": "Sparse deep learning has become a popular technique for improving the\nperformance of deep neural networks in areas such as uncertainty\nquantification, variable selection, and large-scale network compression.\nHowever, most existing research has focused on problems where the observations\nare independent and identically distributed (i.i.d.), and there has been little\nwork on the problems where the observations are dependent, such as time series\ndata and sequential data in natural language processing. This paper aims to\naddress this gap by studying the theory for sparse deep learning with dependent\ndata. We show that sparse recurrent neural networks (RNNs) can be consistently\nestimated, and their predictions are asymptotically normally distributed under\nappropriate assumptions, enabling the prediction uncertainty to be correctly\nquantified. Our numerical results show that sparse deep learning outperforms\nstate-of-the-art methods, such as conformal predictions, in prediction\nuncertainty quantification for time series data. Furthermore, our results\nindicate that the proposed method can consistently identify the autoregressive\norder for time series data and outperform existing methods in large-scale model\ncompression. Our proposed method has important practical implications in fields\nsuch as finance, healthcare, and energy, where both accurate point estimates\nand prediction uncertainty quantification are of concern.",
          "link": "http://arxiv.org/abs/2310.03243",
          "publishedOn": "2023-10-07T00:42:18.910Z",
          "wordCount": null,
          "title": "Sparse Deep Learning for Time Series Data: Theory and Applications. (arXiv:2310.03243v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Assel_H/0/1/0/all/0/1\">Hugues Van Assel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_Cuaz_C/0/1/0/all/0/1\">C&#xe9;dric Vincent-Cuaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vayer_T/0/1/0/all/0/1\">Titouan Vayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flamary_R/0/1/0/all/0/1\">R&#xe9;mi Flamary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courty_N/0/1/0/all/0/1\">Nicolas Courty</a>",
          "description": "We present a versatile adaptation of existing dimensionality reduction (DR)\nobjectives, enabling the simultaneous reduction of both sample and feature\nsizes. Correspondances between input and embedding samples are computed through\na semi-relaxed Gromov-Wasserstein optimal transport (OT) problem. When the\nembedding sample size matches that of the input, our model recovers classical\npopular DR models. When the embedding's dimensionality is unconstrained, we\nshow that the OT plan delivers a competitive hard clustering. We emphasize the\nimportance of intermediate stages that blend DR and clustering for summarizing\nreal data and apply our method to visualize datasets of images.",
          "link": "http://arxiv.org/abs/2310.03398",
          "publishedOn": "2023-10-07T00:42:18.858Z",
          "wordCount": null,
          "title": "Interpolating between Clustering and Dimensionality Reduction with Gromov-Wasserstein. (arXiv:2310.03398v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.00195",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Altabaa_A/0/1/0/all/0/1\">Awni Altabaa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Webb_T/0/1/0/all/0/1\">Taylor Webb</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cohen_J/0/1/0/all/0/1\">Jonathan Cohen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lafferty_J/0/1/0/all/0/1\">John Lafferty</a>",
          "description": "An extension of Transformers is proposed that enables explicit relational\nreasoning through a novel module called the Abstractor. At the core of the\nAbstractor is a variant of attention called relational cross-attention. The\napproach is motivated by an architectural inductive bias for relational\nlearning that disentangles relational information from extraneous features\nabout individual objects. This enables explicit relational reasoning,\nsupporting abstraction and generalization from limited data. The Abstractor is\nfirst evaluated on simple discriminative relational tasks and compared to\nexisting relational architectures. Next, the Abstractor is evaluated on purely\nrelational sequence-to-sequence tasks, where dramatic improvements are seen in\nsample efficiency compared to standard Transformers. Finally, Abstractors are\nevaluated on a collection of tasks based on mathematical problem solving, where\nmodest but consistent improvements in performance and sample efficiency are\nobserved.",
          "link": "http://arxiv.org/abs/2304.00195",
          "publishedOn": "2023-10-07T00:42:18.855Z",
          "wordCount": null,
          "title": "Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers. (arXiv:2304.00195v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishi_H/0/1/0/all/0/1\">Hideyuki Ishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>",
          "description": "The symmetry and geometry of input data are considered to be encoded in the\ninternal data representation inside the neural network, but the specific\nencoding rule has been less investigated. By focusing on a joint group\ninvariant function on the data-parameter domain, we present a systematic rule\nto find a dual group action on the parameter domain from a group action on the\ndata domain. Further, we introduce generalized neural networks induced from the\njoint invariant functions, and present a new group theoretic proof of their\nuniversality theorems by using Schur's lemma. Since traditional universality\ntheorems were demonstrated based on functional analytical methods, this study\nsheds light on the group theoretic aspect of the approximation theory,\nconnecting geometric deep learning to abstract harmonic analysis.",
          "link": "http://arxiv.org/abs/2310.03530",
          "publishedOn": "2023-10-07T00:42:18.515Z",
          "wordCount": null,
          "title": "Joint Group Invariant Functions on Data-Parameter Domain Induce Universal Neural Networks. (arXiv:2310.03530v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.03246",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghattas_O/0/1/0/all/0/1\">Omar Al Ghattas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sanz_Alonso_D/0/1/0/all/0/1\">Daniel Sanz-Alonso</a>",
          "description": "Many modern algorithms for inverse problems and data assimilation rely on\nensemble Kalman updates to blend prior predictions with observed data. Ensemble\nKalman methods often perform well with a small ensemble size, which is\nessential in applications where generating each particle is costly. This paper\ndevelops a non-asymptotic analysis of ensemble Kalman updates that rigorously\nexplains why a small ensemble size suffices if the prior covariance has\nmoderate effective dimension due to fast spectrum decay or approximate\nsparsity. We present our theory in a unified framework, comparing several\nimplementations of ensemble Kalman updates that use perturbed observations,\nsquare root filtering, and localization. As part of our analysis, we develop\nnew dimension-free covariance estimation bounds for approximately sparse\nmatrices that may be of independent interest.",
          "link": "http://arxiv.org/abs/2208.03246",
          "publishedOn": "2023-10-07T00:42:18.485Z",
          "wordCount": null,
          "title": "Non-Asymptotic Analysis of Ensemble Kalman Updates: Effective Dimension and Localization. (arXiv:2208.03246v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Robey_A/0/1/0/all/0/1\">Alexander Robey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1\">Eric Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>",
          "description": "Despite efforts to align large language models (LLMs) with human values,\nwidely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to\njailbreaking attacks, wherein an adversary fools a targeted LLM into generating\nobjectionable content. To address this vulnerability, we propose SmoothLLM, the\nfirst algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our\nfinding that adversarially-generated prompts are brittle to character-level\nchanges, our defense first randomly perturbs multiple copies of a given input\nprompt, and then aggregates the corresponding predictions to detect adversarial\ninputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to\nbelow one percentage point, avoids unnecessary conservatism, and admits\nprovable guarantees on attack mitigation. Moreover, our defense uses\nexponentially fewer queries than existing attacks and is compatible with any\nLLM.",
          "link": "http://arxiv.org/abs/2310.03684",
          "publishedOn": "2023-10-07T00:42:18.483Z",
          "wordCount": null,
          "title": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Beomsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_G/0/1/0/all/0/1\">Gihyun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kwanyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Diffusion models are a powerful class of generative models which simulate\nstochastic differential equations (SDEs) to generate data from noise. Although\ndiffusion models have achieved remarkable progress in recent years, they have\nlimitations in the unpaired image-to-image translation tasks due to the\nGaussian prior assumption. Schr\\\"odinger Bridge (SB), which learns an SDE to\ntranslate between two arbitrary distributions, have risen as an attractive\nsolution to this problem. However, none of SB models so far have been\nsuccessful at unpaired translation between high-resolution images. In this\nwork, we propose the Unpaired Neural Schr\\\"odinger Bridge (UNSB), which\nexpresses SB problem as a sequence of adversarial learning problems. This\nallows us to incorporate advanced discriminators and regularization to learn a\nSB between unpaired data. We demonstrate that UNSB is scalable and successfully\nsolves various unpaired image-to-image translation tasks. Code:\n\\url{https://github.com/cyclomon/UNSB}",
          "link": "http://arxiv.org/abs/2305.15086",
          "publishedOn": "2023-10-07T00:42:18.470Z",
          "wordCount": null,
          "title": "Unpaired Image-to-Image Translation via Neural Schr\\\"odinger Bridge. (arXiv:2305.15086v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.01751",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_T/0/1/0/all/0/1\">Tianrong Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_G/0/1/0/all/0/1\">Guan-Horng Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tao_M/0/1/0/all/0/1\">Molei Tao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Theodorou_E/0/1/0/all/0/1\">Evangelos A. Theodorou</a>",
          "description": "It is a crucial challenge to reconstruct population dynamics using unlabeled\nsamples from distributions at coarse time intervals. Recent approaches such as\nflow-based models or Schr\\\"odinger Bridge (SB) models have demonstrated\nappealing performance, yet the inferred sample trajectories either fail to\naccount for the underlying stochasticity or are $\\underline{D}$eep\n$\\underline{M}$omentum Multi-Marginal $\\underline{S}$chr\\\"odinger\n$\\underline{B}$ridge(DMSB), a novel computational framework that learns the\nsmooth measure-valued spline for stochastic systems that satisfy position\nmarginal constraints across time. By tailoring the celebrated Bregman Iteration\nand extending the Iteration Proportional Fitting to phase space, we manage to\nhandle high-dimensional multi-marginal trajectory inference tasks efficiently.\nOur algorithm outperforms baselines significantly, as evidenced by experiments\nfor synthetic datasets and a real-world single-cell RNA sequence dataset.\nAdditionally, the proposed approach can reasonably reconstruct the evolution of\nvelocity distribution, from position snapshots only, when there is a ground\ntruth velocity that is nevertheless inaccessible.",
          "link": "http://arxiv.org/abs/2303.01751",
          "publishedOn": "2023-10-07T00:42:18.457Z",
          "wordCount": null,
          "title": "Deep Momentum Multi-Marginal Schr\\\"odinger Bridge. (arXiv:2303.01751v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.02824",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stephanovitch_A/0/1/0/all/0/1\">Arthur St&#xe9;phanovitch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tanielian_U/0/1/0/all/0/1\">Ugo Tanielian</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cadre_B/0/1/0/all/0/1\">Beno&#xee;t Cadre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Klutchnikoff_N/0/1/0/all/0/1\">Nicolas Klutchnikoff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Biau_G/0/1/0/all/0/1\">G&#xe9;rard Biau</a>",
          "description": "The mathematical forces at work behind Generative Adversarial Networks raise\nchallenging theoretical issues. Motivated by the important question of\ncharacterizing the geometrical properties of the generated distributions, we\nprovide a thorough analysis of Wasserstein GANs (WGANs) in both the finite\nsample and asymptotic regimes. We study the specific case where the latent\nspace is univariate and derive results valid regardless of the dimension of the\noutput space. We show in particular that for a fixed sample size, the optimal\nWGANs are closely linked with connected paths minimizing the sum of the squared\nEuclidean distances between the sample points. We also highlight the fact that\nWGANs are able to approach (for the 1-Wasserstein distance) the target\ndistribution as the sample size tends to infinity, at a given convergence rate\nand provided the family of generative Lipschitz functions grows appropriately.\nWe derive in passing new results on optimal transport theory in the\nsemi-discrete setting.",
          "link": "http://arxiv.org/abs/2201.02824",
          "publishedOn": "2023-10-07T00:42:18.381Z",
          "wordCount": null,
          "title": "Optimal 1-Wasserstein Distance for WGANs. (arXiv:2201.02824v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.04054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hagmann_M/0/1/0/all/0/1\">Michael Hagmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meier_P/0/1/0/all/0/1\">Philipp Meier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>",
          "description": "Reliability of machine learning evaluation -- the consistency of observed\nevaluation scores across replicated model training runs -- is affected by\nseveral sources of nondeterminism which can be regarded as measurement noise.\nCurrent tendencies to remove noise in order to enforce reproducibility of\nresearch results neglect inherent nondeterminism at the implementation level\nand disregard crucial interaction effects between algorithmic noise factors and\ndata properties. This limits the scope of conclusions that can be drawn from\nsuch experiments. Instead of removing noise, we propose to incorporate several\nsources of variance, including their interaction with data properties, into an\nanalysis of significance and reliability of machine learning evaluation, with\nthe aim to draw inferences beyond particular instances of trained models. We\nshow how to use linear mixed effects models (LMEMs) to analyze performance\nevaluation scores, and to conduct statistical inference with a generalized\nlikelihood ratio test (GLRT). This allows us to incorporate arbitrary sources\nof noise like meta-parameter variations into statistical significance testing,\nand to assess performance differences conditional on data properties.\nFurthermore, a variance component analysis (VCA) enables the analysis of the\ncontribution of noise sources to overall variance and the computation of a\nreliability coefficient by the ratio of substantial to total variance.",
          "link": "http://arxiv.org/abs/2302.04054",
          "publishedOn": "2023-10-07T00:42:18.372Z",
          "wordCount": null,
          "title": "Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.11024",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yifan Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daniel Zhengyu Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_J/0/1/0/all/0/1\">Jiaoyang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reich_S/0/1/0/all/0/1\">Sebastian Reich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew M. Stuart</a>",
          "description": "Sampling a probability distribution with an unknown normalization constant is\na fundamental problem in computational science and engineering. This task may\nbe cast as an optimization problem over all probability measures, and an\ninitial distribution can be evolved to the desired minimizer dynamically via\ngradient flows. Mean-field models, whose law is governed by the gradient flow\nin the space of probability measures, may also be identified; particle\napproximations of these mean-field models form the basis of algorithms. The\ngradient flow approach is also the basis of algorithms for variational\ninference, in which the optimization is performed over a parameterized family\nof probability distributions such as Gaussians, and the underlying gradient\nflow is restricted to the parameterized family.\n\nBy choosing different energy functionals and metrics for the gradient flow,\ndifferent algorithms with different convergence properties arise. In this\npaper, we concentrate on the Kullback-Leibler divergence after showing that, up\nto scaling, it has the unique property that the gradient flows resulting from\nthis choice of energy do not depend on the normalization constant. For the\nmetrics, we focus on variants of the Fisher-Rao, Wasserstein, and Stein\nmetrics; we introduce the affine invariance property for gradient flows, and\ntheir corresponding mean-field models, determine whether a given metric leads\nto affine invariance, and modify it to make it affine invariant if it does not.\nWe study the resulting gradient flows in both probability density space and\nGaussian space. The flow in the Gaussian space may be understood as a Gaussian\napproximation of the flow. We demonstrate that the Gaussian approximation based\non the metric and through moment closure coincide, establish connections\nbetween them, and study their long-time convergence properties showing the\nadvantages of affine invariance.",
          "link": "http://arxiv.org/abs/2302.11024",
          "publishedOn": "2023-10-07T00:42:18.135Z",
          "wordCount": null,
          "title": "Gradient Flows for Sampling: Mean-Field Models, Gaussian Approximations and Affine Invariance. (arXiv:2302.11024v5 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Albergo_M/0/1/0/all/0/1\">Michael S. Albergo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_M/0/1/0/all/0/1\">Mark Goldstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boffi_N/0/1/0/all/0/1\">Nicholas M. Boffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>",
          "description": "Generative models inspired by dynamical transport of measure -- such as flows\nand diffusions -- construct a continuous-time map between two probability\ndensities. Conventionally, one of these is the target density, only accessible\nthrough samples, while the other is taken as a simple base density that is\ndata-agnostic. In this work, using the framework of stochastic interpolants, we\nformalize how to \\textit{couple} the base and the target densities. This\nenables us to incorporate information about class labels or continuous\nembeddings to construct dynamical transport maps that serve as conditional\ngenerative models. We show that these transport maps can be learned by solving\na simple square loss regression problem analogous to the standard independent\nsetting. We demonstrate the usefulness of constructing dependent couplings in\npractice through experiments in super-resolution and in-painting.",
          "link": "http://arxiv.org/abs/2310.03725",
          "publishedOn": "2023-10-07T00:42:17.923Z",
          "wordCount": null,
          "title": "Stochastic interpolants with data-dependent couplings. (arXiv:2310.03725v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.14073",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saremi_M/0/1/0/all/0/1\">Mehrzad Saremi</a>",
          "description": "We propose a graphical structure for structural equation models that is\nstable under marginalization under linearity and Gaussianity assumptions. We\nshow that computing the maximum likelihood estimation of this model is\nequivalent to training a neural network. We implement a GPU-based algorithm\nthat computes the maximum likelihood estimation of these models.",
          "link": "http://arxiv.org/abs/2309.14073",
          "publishedOn": "2023-10-07T00:42:17.450Z",
          "wordCount": 579,
          "title": "Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kasmi_G/0/1/0/all/0/1\">Gabriel Kasmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubus_L/0/1/0/all/0/1\">Laurent Dubus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drenan_Y/0/1/0/all/0/1\">Yves-Marie Saint Drenan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanc_P/0/1/0/all/0/1\">Philippe Blanc</a>",
          "description": "Neural networks have shown remarkable performance in computer vision, but\ntheir deployment in numerous scientific and technical fields is challenging due\nto their black-box nature. Scientists and practitioners need to evaluate the\nreliability of a decision, i.e., to know simultaneously if a model relies on\nthe relevant features and whether these features are robust to image\ncorruptions. Existing attribution methods aim to provide human-understandable\nexplanations by highlighting important regions in the image domain, but fail to\nfully characterize a decision process's reliability. To bridge this gap, we\nintroduce the Wavelet sCale Attribution Method (WCAM), a generalization of\nattribution from the pixel domain to the space-scale domain using wavelet\ntransforms. Attribution in the wavelet domain reveals where {\\it and} on what\nscales the model focuses, thus enabling us to assess whether a decision is\nreliable.",
          "link": "http://arxiv.org/abs/2305.14979",
          "publishedOn": "2023-10-07T00:42:17.433Z",
          "wordCount": 762,
          "title": "Assessment of the Reliablity of a Model's Decision by Generalizing Attribution to the Wavelet Domain. (arXiv:2305.14979v3 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2112.08417",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gerhardus_A/0/1/0/all/0/1\">Andreas Gerhardus</a>",
          "description": "In this paper, we introduce a novel class of graphical models for\nrepresenting time lag specific causal relationships and independencies of\nmultivariate time series with unobserved confounders. We completely\ncharacterize these graphs and show that they constitute proper subsets of the\ncurrently employed model classes. As we show, from the novel graphs one can\nthus draw stronger causal inferences -- without additional assumptions. We\nfurther introduce a graphical representation of Markov equivalence classes of\nthe novel graphs. This graphical representation contains more causal knowledge\nthan what current state-of-the-art causal discovery algorithms learn.",
          "link": "http://arxiv.org/abs/2112.08417",
          "publishedOn": "2023-10-07T00:42:17.425Z",
          "wordCount": 625,
          "title": "Characterization of causal ancestral graphs for time series with latent confounders. (arXiv:2112.08417v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.14420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lam_A/0/1/0/all/0/1\">Albert Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anitescu_M/0/1/0/all/0/1\">Mihai Anitescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanyam_A/0/1/0/all/0/1\">Anirudh Subramanyam</a>",
          "description": "Measures of power grid vulnerability are often assessed by the amount of\ndamage an adversary can exact on the network. However, the cascading impact of\nsuch attacks is often overlooked, even though cascades are one of the primary\ncauses of large-scale blackouts. This paper explores modifications of\ntransmission line protection settings as candidates for adversarial attacks,\nwhich can remain undetectable as long as the network equilibrium state remains\nunaltered. This forms the basis of a black-box function in a Bayesian\noptimization procedure, where the objective is to find protection settings that\nmaximize network degradation due to cascading. Notably, our proposed method is\nagnostic to the choice of the cascade simulator and its underlying assumptions.\nNumerical experiments reveal that, against conventional wisdom, maximally\nmisconfiguring the protection settings of all network lines does not cause the\nmost cascading. More surprisingly, even when the degree of misconfiguration is\nlimited due to resource constraints, it is still possible to find settings that\nproduce cascades comparable in severity to instances where there are no\nresource constraints.",
          "link": "http://arxiv.org/abs/2304.14420",
          "publishedOn": "2023-10-07T00:42:17.111Z",
          "wordCount": 701,
          "title": "Network Cascade Vulnerability using Constrained Bayesian Optimization. (arXiv:2304.14420v2 [cs.SI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03298",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ping Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Comlek_Y/0/1/0/all/0/1\">Yigitcan Comlek</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>",
          "description": "Multi-fidelity (MF) methods are gaining popularity for enhancing surrogate\nmodeling and design optimization by incorporating data from various\nlow-fidelity (LF) models. While most existing MF methods assume a fixed\ndataset, adaptive sampling methods that dynamically allocate resources among\nfidelity models can achieve higher efficiency in the exploring and exploiting\nthe design space. However, most existing MF methods rely on the hierarchical\nassumption of fidelity levels or fail to capture the intercorrelation between\nmultiple fidelity levels and utilize it to quantify the value of the future\nsamples and navigate the adaptive sampling. To address this hurdle, we propose\na framework hinged on a latent embedding for different fidelity models and the\nassociated pre-posterior analysis to explicitly utilize their correlation for\nadaptive sampling. In this framework, each infill sampling iteration includes\ntwo steps: We first identify the location of interest with the greatest\npotential improvement using the high-fidelity (HF) model, then we search for\nthe next sample across all fidelity levels that maximize the improvement per\nunit cost at the location identified in the first step. This is made possible\nby a single Latent Variable Gaussian Process (LVGP) model that maps different\nfidelity models into an interpretable latent space to capture their\ncorrelations without assuming hierarchical fidelity levels. The LVGP enables us\nto assess how LF sampling candidates will affect HF response with pre-posterior\nanalysis and determine the next sample with the best benefit-to-cost ratio.\nThrough test cases, we demonstrate that the proposed method outperforms the\nbenchmark methods in both MF global fitting (GF) and Bayesian Optimization (BO)\nproblems in convergence rate and robustness. Moreover, the method offers the\nflexibility to switch between GF and BO by simply changing the acquisition\nfunction.",
          "link": "http://arxiv.org/abs/2310.03298",
          "publishedOn": "2023-10-07T00:42:17.101Z",
          "wordCount": 779,
          "title": "A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive Sampling. (arXiv:2310.03298v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15871",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daolang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bharti_A/0/1/0/all/0/1\">Ayush Bharti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Souza_A/0/1/0/all/0/1\">Amauri Souza</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Acerbi_L/0/1/0/all/0/1\">Luigi Acerbi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "Simulation-based inference (SBI) methods such as approximate Bayesian\ncomputation (ABC), synthetic likelihood, and neural posterior estimation (NPE)\nrely on simulating statistics to infer parameters of intractable likelihood\nmodels. However, such methods are known to yield untrustworthy and misleading\ninference outcomes under model misspecification, thus hindering their\nwidespread applicability. In this work, we propose the first general approach\nto handle model misspecification that works across different classes of SBI\nmethods. Leveraging the fact that the choice of statistics determines the\ndegree of misspecification in SBI, we introduce a regularized loss function\nthat penalises those statistics that increase the mismatch between the data and\nthe model. Taking NPE and ABC as use cases, we demonstrate the superior\nperformance of our method on high-dimensional time-series models that are\nartificially misspecified. We also apply our method to real data from the field\nof radio propagation where the model is known to be misspecified. We show\nempirically that the method yields robust inference in misspecified scenarios,\nwhilst still being accurate when the model is well-specified.",
          "link": "http://arxiv.org/abs/2305.15871",
          "publishedOn": "2023-10-07T00:42:17.094Z",
          "wordCount": 711,
          "title": "Learning Robust Statistics for Simulation-based Inference under Model Misspecification. (arXiv:2305.15871v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1\">Haosen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_H/0/1/0/all/0/1\">Hamsa Bastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Existing approaches to algorithmic fairness aim to ensure equitable outcomes\nif human decision-makers comply perfectly with algorithmic decisions. However,\nperfect compliance with the algorithm is rarely a reality or even a desirable\noutcome in human-AI collaboration. Yet, recent studies have shown that\nselective compliance with fair algorithms can amplify discrimination relative\nto the prior human policy. As a consequence, ensuring equitable outcomes\nrequires fundamentally different algorithmic design principles that ensure\nrobustness to the decision-maker's (a priori unknown) compliance pattern. We\ndefine the notion of compliance-robustly fair algorithmic recommendations that\nare guaranteed to (weakly) improve fairness in decisions, regardless of the\nhuman's compliance pattern. We propose a simple optimization strategy to\nidentify the best performance-improving compliance-robustly fair policy.\nHowever, we show that it may be infeasible to design algorithmic\nrecommendations that are simultaneously fair in isolation, compliance-robustly\nfair, and more accurate than the human policy; thus, if our goal is to improve\nthe equity and accuracy of human-AI collaboration, it may not be desirable to\nenforce traditional fairness constraints.",
          "link": "http://arxiv.org/abs/2310.03647",
          "publishedOn": "2023-10-07T00:42:17.087Z",
          "wordCount": 659,
          "title": "Rethinking Fairness for Human-AI Collaboration. (arXiv:2310.03647v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_Y/0/1/0/all/0/1\">Yuka Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>",
          "description": "We identify hidden layers inside a DNN with group actions on the data space,\nand formulate the DNN as a dual voice transform with respect to Koopman\noperator, a linear representation of the group action. Based on the group\ntheoretic arguments, particularly by using Schur's lemma, we show a simple\nproof of the universality of those DNNs.",
          "link": "http://arxiv.org/abs/2310.03529",
          "publishedOn": "2023-10-07T00:42:17.062Z",
          "wordCount": 583,
          "title": "Deep Ridgelet Transform: Voice with Koopman Operator Proves Universality of Formal Deep Networks. (arXiv:2310.03529v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03218",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peiyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaxuan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sirui Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "Latent space Energy-Based Models (EBMs), also known as energy-based priors,\nhave drawn growing interests in the field of generative modeling due to its\nflexibility in the formulation and strong modeling power of the latent space.\nHowever, the common practice of learning latent space EBMs with non-convergent\nshort-run MCMC for prior and posterior sampling is hindering the model from\nfurther progress; the degenerate MCMC sampling quality in practice often leads\nto degraded generation quality and instability in training, especially with\nhighly multi-modal and/or high-dimensional target distributions. To remedy this\nsampling issue, in this paper we introduce a simple but effective\ndiffusion-based amortization method for long-run MCMC sampling and develop a\nnovel learning algorithm for the latent space EBM based on it. We provide\ntheoretical evidence that the learned amortization of MCMC is a valid long-run\nMCMC sampler. Experiments on several image modeling benchmark datasets\ndemonstrate the superior performance of our method compared with strong\ncounterparts",
          "link": "http://arxiv.org/abs/2310.03218",
          "publishedOn": "2023-10-07T00:42:17.056Z",
          "wordCount": 669,
          "title": "Learning Energy-Based Prior Model with Diffusion-Amortized MCMC. (arXiv:2310.03218v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.00079",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cattaneo_M/0/1/0/all/0/1\">Matias D. Cattaneo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klusowski_J/0/1/0/all/0/1\">Jason M. Klusowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shigida_B/0/1/0/all/0/1\">Boris Shigida</a>",
          "description": "In previous literature, backward error analysis was used to find ordinary\ndifferential equations (ODEs) approximating the gradient descent trajectory. It\nwas found that finite step sizes implicitly regularize solutions because terms\nappearing in the ODEs penalize the two-norm of the loss gradients. We prove\nthat the existence of similar implicit regularization in RMSProp and Adam\ndepends on their hyperparameters and the training stage, but with a different\n\"norm\" involved: the corresponding ODE terms either penalize the (perturbed)\none-norm of the loss gradients or, on the contrary, hinder its decrease (the\nlatter case being typical). We also conduct numerical experiments and discuss\nhow the proven facts can influence generalization.",
          "link": "http://arxiv.org/abs/2309.00079",
          "publishedOn": "2023-10-07T00:42:17.049Z",
          "wordCount": 653,
          "title": "On the Implicit Bias of Adam. (arXiv:2309.00079v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03575",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cui_H/0/1/0/all/0/1\">Hugo Cui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krzakala_F/0/1/0/all/0/1\">Florent Krzakala</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zdeborova_L/0/1/0/all/0/1\">Lenka Zdeborov&#xe1;</a>",
          "description": "We study the problem of training a flow-based generative model, parametrized\nby a two-layer autoencoder, to sample from a high-dimensional Gaussian mixture.\nWe provide a sharp end-to-end analysis of the problem. First, we provide a\ntight closed-form characterization of the learnt velocity field, when\nparametrized by a shallow denoising auto-encoder trained on a finite number $n$\nof samples from the target distribution. Building on this analysis, we provide\na sharp description of the corresponding generative flow, which pushes the base\nGaussian density forward to an approximation of the target density. In\nparticular, we provide closed-form formulae for the distance between the mean\nof the generated mixture and the mean of the target mixture, which we show\ndecays as $\\Theta_n(\\frac{1}{n})$. Finally, this rate is shown to be in fact\nBayes-optimal.",
          "link": "http://arxiv.org/abs/2310.03575",
          "publishedOn": "2023-10-07T00:42:17.042Z",
          "wordCount": 637,
          "title": "Analysis of learning a flow-based generative model from limited sample complexity. (arXiv:2310.03575v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07726",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gong_S/0/1/0/all/0/1\">Shijin Gong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>",
          "description": "When artificial neural networks have demonstrated exceptional practical\nsuccess in a variety of domains, investigations into their theoretical\ncharacteristics, such as their approximation power, statistical properties, and\ngeneralization performance, have concurrently made significant strides. In this\npaper, we construct a novel theory for understanding the effectiveness of\nneural networks, which offers a perspective distinct from prior research.\nSpecifically, we explore the rationale underlying a common practice during the\nconstruction of neural network models: sample splitting. Our findings indicate\nthat the optimal hyperparameters derived from sample splitting can enable a\nneural network model that asymptotically minimizes the prediction risk. We\nconduct extensive experiments across different application scenarios and\nnetwork architectures, and the results manifest our theory's effectiveness.",
          "link": "http://arxiv.org/abs/2307.07726",
          "publishedOn": "2023-10-07T00:42:17.035Z",
          "wordCount": 647,
          "title": "Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection. (arXiv:2307.07726v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.02671",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Klein_S/0/1/0/all/0/1\">Sara Klein</a>, <a href=\"http://arxiv.org/find/math/1/au:+Weissmann_S/0/1/0/all/0/1\">Simon Weissmann</a>, <a href=\"http://arxiv.org/find/math/1/au:+Doring_L/0/1/0/all/0/1\">Leif D&#xf6;ring</a>",
          "description": "Markov Decision Processes (MDPs) are a formal framework for modeling and\nsolving sequential decision-making problems. In finite-time horizons such\nproblems are relevant for instance for optimal stopping or specific supply\nchain problems, but also in the training of large language models. In contrast\nto infinite horizon MDPs optimal policies are not stationary, policies must be\nlearned for every single epoch. In practice all parameters are often trained\nsimultaneously, ignoring the inherent structure suggested by dynamic\nprogramming. This paper introduces a combination of dynamic programming and\npolicy gradient called dynamic policy gradient, where the parameters are\ntrained backwards in time. For the tabular softmax parametrisation we carry out\nthe convergence analysis for simultaneous and dynamic policy gradient towards\nglobal optima, both in the exact and sampled gradient settings without\nregularisation. It turns out that the use of dynamic policy gradient training\nmuch better exploits the structure of finite-time problems which is reflected\nin improved convergence bounds.",
          "link": "http://arxiv.org/abs/2310.02671",
          "publishedOn": "2023-10-07T00:42:16.999Z",
          "wordCount": 664,
          "title": "Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods. (arXiv:2310.02671v1 [math.OC] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03546",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Renaud_M/0/1/0/all/0/1\">Marien Renaud</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jiaming Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1\">Valentin de Bortoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Almansa_A/0/1/0/all/0/1\">Andr&#xe9;s Almansa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kamilov_U/0/1/0/all/0/1\">Ulugbek S. Kamilov</a>",
          "description": "Posterior sampling has been shown to be a powerful Bayesian approach for\nsolving imaging inverse problems. The recent plug-and-play unadjusted Langevin\nalgorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling\nand minimum mean squared error (MMSE) estimation by combining physical\nmeasurement models with deep-learning priors specified using image denoisers.\nHowever, the intricate relationship between the sampling distribution of\nPnP-ULA and the mismatched data-fidelity and denoiser has not been\ntheoretically analyzed. We address this gap by proposing a posterior-L2\npseudometric and using it to quantify an explicit error bound for PnP-ULA under\nmismatched posterior distribution. We numerically validate our theory on\nseveral inverse problems such as sampling from Gaussian mixture models and\nimage deblurring. Our results suggest that the sensitivity of the sampling\ndistribution of PnP-ULA to a mismatch in the measurement model and the denoiser\ncan be precisely characterized.",
          "link": "http://arxiv.org/abs/2310.03546",
          "publishedOn": "2023-10-07T00:42:16.973Z",
          "wordCount": 648,
          "title": "Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models. (arXiv:2310.03546v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1\">Deqian Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jianwen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "This paper proposes a latent prompt Transformer model for solving challenging\noptimization problems such as molecule design, where the goal is to find\nmolecules with optimal values of a target chemical or biological property that\ncan be computed by an existing software. Our proposed model consists of three\ncomponents. (1) A latent vector whose prior distribution is modeled by a Unet\ntransformation of a Gaussian white noise vector. (2) A molecule generation\nmodel that generates the string-based representation of molecule conditional on\nthe latent vector in (1). We adopt the causal Transformer model that takes the\nlatent vector in (1) as prompt. (3) A property prediction model that predicts\nthe value of the target property of a molecule based on a non-linear regression\non the latent vector in (1). We call the proposed model the latent prompt\nTransformer model. After initial training of the model on existing molecules\nand their property values, we then gradually shift the model distribution\ntowards the region that supports desired values of the target property for the\npurpose of molecule design. Our experiments show that our proposed model\nachieves state of the art performances on several benchmark molecule design\ntasks.",
          "link": "http://arxiv.org/abs/2310.03253",
          "publishedOn": "2023-10-07T00:42:16.966Z",
          "wordCount": 697,
          "title": "Molecule Design by Latent Prompt Transformer. (arXiv:2310.03253v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03234",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hu_Q/0/1/0/all/0/1\">Quanqi Hu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_D/0/1/0/all/0/1\">Dixian Zhu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "This paper investigates new families of compositional optimization problems,\ncalled $\\underline{\\bf n}$on-$\\underline{\\bf s}$mooth $\\underline{\\bf\nw}$eakly-$\\underline{\\bf c}$onvex $\\underline{\\bf f}$inite-sum $\\underline{\\bf\nc}$oupled $\\underline{\\bf c}$ompositional $\\underline{\\bf o}$ptimization (NSWC\nFCCO). There has been a growing interest in FCCO due to its wide-ranging\napplications in machine learning and AI, as well as its ability to address the\nshortcomings of stochastic algorithms based on empirical risk minimization.\nHowever, current research on FCCO presumes that both the inner and outer\nfunctions are smooth, limiting their potential to tackle a more diverse set of\nproblems. Our research expands on this area by examining non-smooth\nweakly-convex FCCO, where the outer function is weakly convex and\nnon-decreasing, and the inner function is weakly-convex. We analyze a\nsingle-loop algorithm and establish its complexity for finding an\n$\\epsilon$-stationary point of the Moreau envelop of the objective function.\nAdditionally, we also extend the algorithm to solving novel non-smooth\nweakly-convex tri-level finite-sum coupled compositional optimization problems,\nwhich feature a nested arrangement of three functions. Lastly, we explore the\napplications of our algorithms in deep learning for two-way partial AUC\nmaximization and multi-instance two-way partial AUC maximization, using\nempirical studies to showcase the effectiveness of the proposed algorithms.",
          "link": "http://arxiv.org/abs/2310.03234",
          "publishedOn": "2023-10-07T00:42:16.957Z",
          "wordCount": 690,
          "title": "Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03054",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hagemann_P/0/1/0/all/0/1\">Paul Hagemann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hertrich_J/0/1/0/all/0/1\">Johannes Hertrich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Altekruger_F/0/1/0/all/0/1\">Fabian Altekr&#xfc;ger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beinert_R/0/1/0/all/0/1\">Robert Beinert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chemseddine_J/0/1/0/all/0/1\">Jannis Chemseddine</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steidl_G/0/1/0/all/0/1\">Gabriele Steidl</a>",
          "description": "We propose conditional flows of the maximum mean discrepancy (MMD) with the\nnegative distance kernel for posterior sampling and conditional generative\nmodeling. This MMD, which is also known as energy distance, has several\nadvantageous properties like efficient computation via slicing and sorting. We\napproximate the joint distribution of the ground truth and the observations\nusing discrete Wasserstein gradient flows and establish an error bound for the\nposterior distributions. Further, we prove that our particle flow is indeed a\nWasserstein gradient flow of an appropriate functional. The power of our method\nis demonstrated by numerical examples including conditional image generation\nand inverse problems like superresolution, inpainting and computed tomography\nin low-dose and limited-angle settings.",
          "link": "http://arxiv.org/abs/2310.03054",
          "publishedOn": "2023-10-07T00:42:16.927Z",
          "wordCount": 644,
          "title": "Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel. (arXiv:2310.03054v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03597",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yifan Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daniel Zhengyu Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_J/0/1/0/all/0/1\">Jiaoyang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reich_S/0/1/0/all/0/1\">Sebastian Reich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew M Stuart</a>",
          "description": "Sampling a target probability distribution with an unknown normalization\nconstant is a fundamental challenge in computational science and engineering.\nRecent work shows that algorithms derived by considering gradient flows in the\nspace of probability measures open up new avenues for algorithm development.\nThis paper makes three contributions to this sampling approach by scrutinizing\nthe design components of such gradient flows. Any instantiation of a gradient\nflow for sampling needs an energy functional and a metric to determine the\nflow, as well as numerical approximations of the flow to derive algorithms. Our\nfirst contribution is to show that the Kullback-Leibler divergence, as an\nenergy functional, has the unique property (among all f-divergences) that\ngradient flows resulting from it do not depend on the normalization constant of\nthe target distribution. Our second contribution is to study the choice of\nmetric from the perspective of invariance. The Fisher-Rao metric is known as\nthe unique choice (up to scaling) that is diffeomorphism invariant. As a\ncomputationally tractable alternative, we introduce a relaxed, affine\ninvariance property for the metrics and gradient flows. In particular, we\nconstruct various affine invariant Wasserstein and Stein gradient flows. Affine\ninvariant gradient flows are shown to behave more favorably than their\nnon-affine-invariant counterparts when sampling highly anisotropic\ndistributions, in theory and by using particle methods. Our third contribution\nis to study, and develop efficient algorithms based on Gaussian approximations\nof the gradient flows; this leads to an alternative to particle methods. We\nestablish connections between various Gaussian approximate gradient flows,\ndiscuss their relation to gradient methods arising from parametric variational\ninference, and study their convergence properties both theoretically and\nnumerically.",
          "link": "http://arxiv.org/abs/2310.03597",
          "publishedOn": "2023-10-07T00:42:16.919Z",
          "wordCount": 799,
          "title": "Sampling via Gradient Flows in the Space of Probability Measures. (arXiv:2310.03597v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03435",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Magris_M/0/1/0/all/0/1\">Martin Magris</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "The Bayesian estimation of GARCH-family models has been typically addressed\nthrough Monte Carlo sampling. Variational Inference is gaining popularity and\nattention as a robust approach for Bayesian inference in complex machine\nlearning models; however, its adoption in econometrics and finance is limited.\nThis paper discusses the extent to which Variational Inference constitutes a\nreliable and feasible alternative to Monte Carlo sampling for Bayesian\ninference in GARCH-like models. Through a large-scale experiment involving the\nconstituents of the S&P 500 index, several Variational Inference optimizers, a\nvariety of volatility models, and a case study, we show that Variational\nInference is an attractive, remarkably well-calibrated, and competitive method\nfor Bayesian learning.",
          "link": "http://arxiv.org/abs/2310.03435",
          "publishedOn": "2023-10-07T00:42:16.903Z",
          "wordCount": 592,
          "title": "Variational Inference for GARCH-family Models. (arXiv:2310.03435v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.16102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ajorlou_A/0/1/0/all/0/1\">Amir Ajorlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zihui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jadbabaie_A/0/1/0/all/0/1\">Ali Jadbabaie</a>",
          "description": "Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where\nincreasing network depth leads to homogeneous node representations. While\nprevious work has established that Graph Convolutional Networks (GCNs)\nexponentially lose expressive power, it remains controversial whether the graph\nattention mechanism can mitigate oversmoothing. In this work, we provide a\ndefinitive answer to this question through a rigorous mathematical analysis, by\nviewing attention-based GNNs as nonlinear time-varying dynamical systems and\nincorporating tools and techniques from the theory of products of inhomogeneous\nmatrices and the joint spectral radius. We establish that, contrary to popular\nbelief, the graph attention mechanism cannot prevent oversmoothing and loses\nexpressive power exponentially. The proposed framework extends the existing\nresults on oversmoothing for symmetric GCNs to a significantly broader class of\nGNN models, including random walk GCNs, Graph Attention Networks (GATs) and\n(graph) transformers. In particular, our analysis accounts for asymmetric,\nstate-dependent and time-varying aggregation operators and a wide range of\ncommon nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU.",
          "link": "http://arxiv.org/abs/2305.16102",
          "publishedOn": "2023-10-07T00:42:16.767Z",
          "wordCount": 699,
          "title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks. (arXiv:2305.16102v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1812.00029",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Panda_S/0/1/0/all/0/1\">Sambit Panda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1\">Cencheng Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>",
          "description": "Decision forests are widely used for classification and regression tasks. A\nlesser known property of tree-based methods is that one can construct a\nproximity matrix from the tree(s), and these proximity matrices are induced\nkernels. While there has been extensive research on the applications and\nproperties of kernels, there is relatively little research on kernels induced\nby decision forests. We construct Kernel Mean Embedding Random Forests (KMERF),\nwhich induce kernels from random trees and/or forests using leaf-node\nproximity. We introduce the notion of an asymptotically characteristic kernel,\nand prove that KMERF kernels are asymptotically characteristic for both\ndiscrete and continuous data. Because KMERF is data-adaptive, we suspected it\nwould outperform kernels selected a priori on finite sample data. We illustrate\nthat KMERF nearly dominates current state-of-the-art kernel-based tests across\na diverse range of high-dimensional two-sample and independence testing\nsettings. Furthermore, our forest-based approach is interpretable, and provides\nfeature importance metrics that readily distinguish important dimensions,\nunlike other high-dimensional non-parametric testing procedures. Hence, this\nwork demonstrates the decision forest-based kernel can be more powerful and\nmore interpretable than existing methods, flying in the face of conventional\nwisdom of the trade-off between the two.",
          "link": "http://arxiv.org/abs/1812.00029",
          "publishedOn": "2023-09-30T00:41:30.863Z",
          "wordCount": null,
          "title": "Learning Interpretable Characteristic Kernels via Decision Forests. (arXiv:1812.00029v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1911.09307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Ke Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhanxing Zhu</a>",
          "description": "Regularization plays a crucial role in machine learning models, especially\nfor deep neural networks. The existing regularization techniques mainly rely on\nthe i.i.d. assumption and only consider the knowledge from the current sample,\nwithout the leverage of the neighboring relationship between samples. In this\nwork, we propose a general regularizer called \\textbf{Patch-level Neighborhood\nInterpolation~(Pani)} that conducts a non-local representation in the\ncomputation of networks. Our proposal explicitly constructs patch-level graphs\nin different layers and then linearly interpolates neighborhood patch features,\nserving as a general and effective regularization strategy. Further, we\ncustomize our approach into two kinds of popular regularization methods, namely\nVirtual Adversarial Training (VAT) and MixUp as well as its variants. The first\nderived \\textbf{Pani VAT} presents a novel way to construct non-local\nadversarial smoothness by employing patch-level interpolated perturbations. The\nsecond derived \\textbf{Pani MixUp} method extends the MixUp, and achieves\nsuperiority over MixUp and competitive performance over state-of-the-art\nvariants of MixUp method with a significant advantage in computational\nefficiency. Extensive experiments have verified the effectiveness of our Pani\napproach in both supervised and semi-supervised settings.",
          "link": "http://arxiv.org/abs/1911.09307",
          "publishedOn": "2023-09-30T00:41:30.701Z",
          "wordCount": null,
          "title": "Patch-level Neighborhood Interpolation: A General and Effective Graph-based Regularization Strategy. (arXiv:1911.09307v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.10259",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Denis_C/0/1/0/all/0/1\">Christophe Denis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dion_Blanc_C/0/1/0/all/0/1\">Charlotte Dion-Blanc</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mintsa_E/0/1/0/all/0/1\">Eddy Ella Mintsa</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tran_V/0/1/0/all/0/1\">Viet-Chi Tran</a>",
          "description": "We study the multiclass classification problem where the features come from\nthe mixture of time-homogeneous diffusions. Specifically, the classes are\ndiscriminated by their drift functions while the diffusion coefficient is\ncommon to all classes and unknown. In this framework, we build a plug-in\nclassifier which relies on nonparametric estimators of the drift and diffusion\nfunctions. We first establish the consistency of our classification procedure\nunder mild assumptions and then provide rates of cnvergence under different set\nof assumptions. Finally, a numerical study supports our theoretical findings.",
          "link": "http://arxiv.org/abs/2212.10259",
          "publishedOn": "2023-09-30T00:41:30.700Z",
          "wordCount": null,
          "title": "Nonparametric plug-in classifier for multiclass classification of S.D.E. paths. (arXiv:2212.10259v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16492",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1\">Hanyu Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tanneau_M/0/1/0/all/0/1\">Mathieu Tanneau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_C/0/1/0/all/0/1\">Chaofan Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Joseph_V/0/1/0/all/0/1\">V. Roshan Joseph</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shangkun Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hentenryck_P/0/1/0/all/0/1\">Pascal Van Hentenryck</a>",
          "description": "The growing penetration of intermittent, renewable generation in US power\ngrids, especially wind and solar generation, results in increased operational\nuncertainty. In that context, accurate forecasts are critical, especially for\nwind generation, which exhibits large variability and is historically harder to\npredict. To overcome this challenge, this work proposes a novel\nBundle-Predict-Reconcile (BPR) framework that integrates asset bundling,\nmachine learning, and forecast reconciliation techniques. The BPR framework\nfirst learns an intermediate hierarchy level (the bundles), then predicts wind\npower at the asset, bundle, and fleet level, and finally reconciles all\nforecasts to ensure consistency. This approach effectively introduces an\nauxiliary learning task (predicting the bundle-level time series) to help the\nmain learning tasks. The paper also introduces new asset-bundling criteria that\ncapture the spatio-temporal dynamics of wind power time series. Extensive\nnumerical experiments are conducted on an industry-size dataset of 283 wind\nfarms in the MISO footprint. The experiments consider short-term and day-ahead\nforecasts, and evaluates a large variety of forecasting models that include\nweather predictions as covariates. The results demonstrate the benefits of BPR,\nwhich consistently and significantly improves forecast accuracy over baselines,\nespecially at the fleet level.",
          "link": "http://arxiv.org/abs/2309.16492",
          "publishedOn": "2023-09-30T00:41:30.679Z",
          "wordCount": null,
          "title": "Asset Bundling for Wind Power Forecasting. (arXiv:2309.16492v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16476",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Adomaityte_U/0/1/0/all/0/1\">Urte Adomaityte</a>, <a href=\"http://arxiv.org/find/math/1/au:+Defilippis_L/0/1/0/all/0/1\">Leonardo Defilippis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Loureiro_B/0/1/0/all/0/1\">Bruno Loureiro</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sicuro_G/0/1/0/all/0/1\">Gabriele Sicuro</a>",
          "description": "We investigate the high-dimensional properties of robust regression\nestimators in the presence of heavy-tailed contamination of both the covariates\nand response functions. In particular, we provide a sharp asymptotic\ncharacterisation of M-estimators trained on a family of elliptical covariate\nand noise data distributions including cases where second and higher moments do\nnot exist. We show that, despite being consistent, the Huber loss with\noptimally tuned location parameter $\\delta$ is suboptimal in the\nhigh-dimensional regime in the presence of heavy-tailed noise, highlighting the\nnecessity of further regularisation to achieve optimal performance. This result\nalso uncovers the existence of a curious transition in $\\delta$ as a function\nof the sample complexity and contamination. Moreover, we derive the decay rates\nfor the excess risk of ridge regression. We show that, while it is both optimal\nand universal for noise distributions with finite second moment, its decay rate\ncan be considerably faster when the covariates' second moment does not exist.\nFinally, we show that our formulas readily generalise to a richer family of\nmodels and data distributions, such as generalised linear estimation with\narbitrary convex regularisation trained on mixture models.",
          "link": "http://arxiv.org/abs/2309.16476",
          "publishedOn": "2023-09-30T00:41:30.674Z",
          "wordCount": null,
          "title": "High-dimensional robust regression under heavy-tailed data: Asymptotics and Universality. (arXiv:2309.16476v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08079",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_L/0/1/0/all/0/1\">Likun Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_X/0/1/0/all/0/1\">Xiaoyu Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wikle_C/0/1/0/all/0/1\">Christopher K. Wikle</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huser_R/0/1/0/all/0/1\">Rapha&#xeb;l Huser</a>",
          "description": "Many real-world processes have complex tail dependence structures that cannot\nbe characterized using classical Gaussian processes. More flexible spatial\nextremes models exhibit appealing extremal dependence properties but are often\nexceedingly prohibitive to fit and simulate from in high dimensions. In this\npaper, we develop a new spatial extremes model that has flexible and\nnon-stationary dependence properties, and we integrate it in the\nencoding-decoding structure of a variational autoencoder (XVAE), whose\nparameters are estimated via variational Bayes combined with deep learning. The\nXVAE can be used as a spatio-temporal emulator that characterizes the\ndistribution of potential mechanistic model output states and produces outputs\nthat have the same statistical properties as the inputs, especially in the\ntail. As an aside, our approach also provides a novel way of making fast\ninference with complex extreme-value processes. Through extensive simulation\nstudies, we show that our XVAE is substantially more time-efficient than\ntraditional Bayesian inference while also outperforming many spatial extremes\nmodels with a stationary dependence structure. To further demonstrate the\ncomputational power of the XVAE, we analyze a high-resolution satellite-derived\ndataset of sea surface temperature in the Red Sea, which includes 30 years of\ndaily measurements at 16703 grid cells. We find that the extremal dependence\nstrength is weaker in the interior of Red Sea and it has decreased slightly\nover time.",
          "link": "http://arxiv.org/abs/2307.08079",
          "publishedOn": "2023-09-30T00:41:30.658Z",
          "wordCount": null,
          "title": "Flexible and efficient spatial extremes emulation via variational autoencoders. (arXiv:2307.08079v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bazaga_A/0/1/0/all/0/1\">Adri&#xe1;n Bazaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micklem_G/0/1/0/all/0/1\">Gos Micklem</a>",
          "description": "Unsupervised fact verification aims to verify a claim using evidence from a\ntrustworthy knowledge base without any kind of data annotation. To address this\nchallenge, algorithms must produce features for every claim that are both\nsemantically meaningful, and compact enough to find a semantic alignment with\nthe source information. In contrast to previous work, which tackled the\nalignment problem by learning over annotated corpora of claims and their\ncorresponding labels, we propose SFAVEL (Self-supervised Fact Verification via\nLanguage Model Distillation), a novel unsupervised framework that leverages\npre-trained language models to distil self-supervised features into\nhigh-quality claim-fact alignments without the need for annotations. This is\nenabled by a novel contrastive loss function that encourages features to attain\nhigh-quality claim and evidence alignments whilst preserving the semantic\nrelationships across the corpora. Notably, we present results that achieve a\nnew state-of-the-art on the standard FEVER fact verification benchmark (+8%\naccuracy) with linear evaluation.",
          "link": "http://arxiv.org/abs/2309.16540",
          "publishedOn": "2023-09-30T00:41:30.587Z",
          "wordCount": 651,
          "title": "Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16620",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1\">Blake Bordelon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Noci_L/0/1/0/all/0/1\">Lorenzo Noci</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Mufan Bill Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanin_B/0/1/0/all/0/1\">Boris Hanin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "The cost of hyperparameter tuning in deep learning has been rising with model\nsizes, prompting practitioners to find new tuning methods using a proxy of\nsmaller networks. One such proposal uses $\\mu$P parameterized networks, where\nthe optimal hyperparameters for small width networks transfer to networks with\narbitrarily large width. However, in this scheme, hyperparameters do not\ntransfer across depths. As a remedy, we study residual networks with a residual\nbranch scale of $1/\\sqrt{\\text{depth}}$ in combination with the $\\mu$P\nparameterization. We provide experiments demonstrating that residual\narchitectures including convolutional ResNets and Vision Transformers trained\nwith this parameterization exhibit transfer of optimal hyperparameters across\nwidth and depth on CIFAR-10 and ImageNet. Furthermore, our empirical findings\nare supported and motivated by theory. Using recent developments in the\ndynamical mean field theory (DMFT) description of neural network learning\ndynamics, we show that this parameterization of ResNets admits a well-defined\nfeature learning joint infinite-width and infinite-depth limit and show\nconvergence of finite-size network dynamics towards this limit.",
          "link": "http://arxiv.org/abs/2309.16620",
          "publishedOn": "2023-09-30T00:41:30.578Z",
          "wordCount": null,
          "title": "Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit. (arXiv:2309.16620v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.07227",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_B/0/1/0/all/0/1\">Benjamin J. Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marzouk_Y/0/1/0/all/0/1\">Youssef M. Marzouk</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Spiliopoulos_K/0/1/0/all/0/1\">Konstantinos Spiliopoulos</a>",
          "description": "Langevin dynamics are widely used in sampling high-dimensional, non-Gaussian\ndistributions whose densities are known up to a normalizing constant. In\nparticular, there is strong interest in unadjusted Langevin algorithms (ULA),\nwhich directly discretize Langevin dynamics to estimate expectations over the\ntarget distribution. We study the use of transport maps that approximately\nnormalize a target distribution as a way to precondition and accelerate the\nconvergence of Langevin dynamics. We show that in continuous time, when a\ntransport map is applied to Langevin dynamics, the result is a Riemannian\nmanifold Langevin dynamics (RMLD) with metric defined by the transport map. We\nalso show that applying a transport map to an irreversibly-perturbed ULA\nresults in a geometry-informed irreversible perturbation (GiIrr) of the\noriginal dynamics. These connections suggest more systematic ways of learning\nmetrics and perturbations, and also yield alternative discretizations of the\nRMLD described by the map, which we study. Under appropriate conditions, these\ndiscretized processes can be endowed with non-asymptotic bounds describing\nconvergence to the target distribution in 2-Wasserstein distance. Illustrative\nnumerical results complement our theoretical claims.",
          "link": "http://arxiv.org/abs/2302.07227",
          "publishedOn": "2023-09-30T00:41:30.434Z",
          "wordCount": null,
          "title": "Transport map unadjusted Langevin algorithms: learning and discretizing perturbed samplers. (arXiv:2302.07227v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16448",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zukovic_M/0/1/0/all/0/1\">Milan &#x17d;ukovi&#x10d;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hristopulos_D/0/1/0/all/0/1\">Dionissios T. Hristopulos</a>",
          "description": "We introduce the modified planar rotator method (MPRS), a physically inspired\nmachine learning method for spatial/temporal regression. MPRS is a\nnon-parametric model which incorporates spatial or temporal correlations via\nshort-range, distance-dependent ``interactions'' without assuming a specific\nform for the underlying probability distribution. Predictions are obtained by\nmeans of a fully autonomous learning algorithm which employs equilibrium\nconditional Monte Carlo simulations. MPRS is able to handle scattered data and\narbitrary spatial dimensions. We report tests on various synthetic and\nreal-word data in one, two and three dimensions which demonstrate that the MPRS\nprediction performance (without parameter tuning) is competitive with standard\ninterpolation methods such as ordinary kriging and inverse distance weighting.\nIn particular, MPRS is a particularly effective gap-filling method for rough\nand non-Gaussian data (e.g., daily precipitation time series). MPRS shows\nsuperior computational efficiency and scalability for large samples. Massive\ndata sets involving millions of nodes can be processed in a few seconds on a\nstandard personal computer.",
          "link": "http://arxiv.org/abs/2309.16448",
          "publishedOn": "2023-09-30T00:41:30.422Z",
          "wordCount": 666,
          "title": "A parsimonious, computationally efficient machine learning method for spatial regression. (arXiv:2309.16448v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16274",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bargiotas_I/0/1/0/all/0/1\">Ioannis Bargiotas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kalogeratos_A/0/1/0/all/0/1\">Argyris Kalogeratos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vayatis_N/0/1/0/all/0/1\">Nicolas Vayatis</a>",
          "description": "The standard paired-sample testing approach in the multidimensional setting\napplies multiple univariate tests on the individual features, followed by\np-value adjustments. Such an approach suffers when the data carry numerous\nfeatures. A number of studies have shown that classification accuracy can be\nseen as a proxy for two-sample testing. However, neither theoretical\nfoundations nor practical recipes have been proposed so far on how this\nstrategy could be extended to multidimensional paired-sample testing. In this\nwork, we put forward the idea that scoring functions can be produced by the\ndecision rules defined by the perpendicular bisecting hyperplanes of the line\nsegments connecting each pair of instances. Then, the optimal scoring function\ncan be obtained by the pseudomedian of those rules, which we estimate by\nextending naturally the Hodges-Lehmann estimator. We accordingly propose a\nframework of a two-step testing procedure. First, we estimate the bisecting\nhyperplanes for each pair of instances and an aggregated rule derived through\nthe Hodges-Lehmann estimator. The paired samples are scored by this aggregated\nrule to produce a unidimensional representation. Second, we perform a Wilcoxon\nsigned-rank test on the obtained representation. Our experiments indicate that\nour approach has substantial performance gains in testing accuracy compared to\nthe traditional multivariate and multiple testing, while at the same time\nestimates each feature's contribution to the final result.",
          "link": "http://arxiv.org/abs/2309.16274",
          "publishedOn": "2023-09-30T00:41:30.416Z",
          "wordCount": 744,
          "title": "A framework for paired-sample hypothesis testing for high-dimensional data. (arXiv:2309.16274v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1\">Mert Pilanci</a>",
          "description": "In this paper, we introduce a novel analysis of neural networks based on\ngeometric (Clifford) algebra and convex optimization. We show that optimal\nweights of deep ReLU neural networks are given by the wedge product of training\nsamples when trained with standard regularized loss. Furthermore, the training\nproblem reduces to convex optimization over wedge product features, which\nencode the geometric structure of the training dataset. This structure is given\nin terms of signed volumes of triangles and parallelotopes generated by data\nvectors. The convex problem finds a small subset of samples via $\\ell_1$\nregularization to discover only relevant wedge product features. Our analysis\nprovides a novel perspective on the inner workings of deep neural networks and\nsheds light on the role of the hidden layers.",
          "link": "http://arxiv.org/abs/2309.16512",
          "publishedOn": "2023-09-30T00:41:30.410Z",
          "wordCount": 670,
          "title": "From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.15728",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Luo_Y/0/1/0/all/0/1\">Yuetian Luo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gao_C/0/1/0/all/0/1\">Chao Gao</a>",
          "description": "Graphon estimation has been one of the most fundamental problems in network\nanalysis and has received considerable attention in the past decade. From the\nstatistical perspective, the minimax error rate of graphon estimation has been\nestablished by Gao et al (2015) for both stochastic block model (SBM) and\nnonparametric graphon estimation. The statistical optimal estimators are based\non constrained least squares and have computational complexity exponential in\nthe dimension. From the computational perspective, the best-known\npolynomial-time estimator is based on universal singular value thresholding\n(USVT), but it can only achieve a much slower estimation error rate than the\nminimax one. It is natural to wonder if such a gap is essential. The\ncomputational optimality of the USVT or the existence of a computational\nbarrier in graphon estimation has been a long-standing open problem. In this\nwork, we take the first step towards it and provide rigorous evidence for the\ncomputational barrier in graphon estimation via low-degree polynomials.\nSpecifically, in both SBM and nonparametric graphon estimation, we show that\nfor low-degree polynomial estimators, their estimation error rates cannot be\nsignificantly better than that of the USVT under a wide range of parameter\nregimes. Our results are proved based on the recent development of low-degree\npolynomials by Schramm and Wein (2022), while we overcome a few key challenges\nin applying it to the general graphon estimation problem. By leveraging our\nmain results, we also provide a computational lower bound on the clustering\nerror for community detection in SBM with a growing number of communities and\nthis yields a new piece of evidence for the conjectured Kesten-Stigum threshold\nfor efficient community recovery.",
          "link": "http://arxiv.org/abs/2308.15728",
          "publishedOn": "2023-09-30T00:41:30.296Z",
          "wordCount": null,
          "title": "Computational Lower Bounds for Graphon Estimation via Low-degree Polynomials. (arXiv:2308.15728v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16314",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Arbel_J/0/1/0/all/0/1\">Julyan Arbel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pitas_K/0/1/0/all/0/1\">Konstantinos Pitas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vladimirova_M/0/1/0/all/0/1\">Mariia Vladimirova</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>",
          "description": "Neural networks have achieved remarkable performance across various problem\ndomains, but their widespread applicability is hindered by inherent limitations\nsuch as overconfidence in predictions, lack of interpretability, and\nvulnerability to adversarial attacks. To address these challenges, Bayesian\nneural networks (BNNs) have emerged as a compelling extension of conventional\nneural networks, integrating uncertainty estimation into their predictive\ncapabilities.\n\nThis comprehensive primer presents a systematic introduction to the\nfundamental concepts of neural networks and Bayesian inference, elucidating\ntheir synergistic integration for the development of BNNs. The target audience\ncomprises statisticians with a potential background in Bayesian methods but\nlacking deep learning expertise, as well as machine learners proficient in deep\nneural networks but with limited exposure to Bayesian statistics. We provide an\noverview of commonly employed priors, examining their impact on model behavior\nand performance. Additionally, we delve into the practical considerations\nassociated with training and inference in BNNs.\n\nFurthermore, we explore advanced topics within the realm of BNN research,\nacknowledging the existence of ongoing debates and controversies. By offering\ninsights into cutting-edge developments, this primer not only equips\nresearchers and practitioners with a solid foundation in BNNs, but also\nilluminates the potential applications of this dynamic field. As a valuable\nresource, it fosters an understanding of BNNs and their promising prospects,\nfacilitating further advancements in the pursuit of knowledge and innovation.",
          "link": "http://arxiv.org/abs/2309.16314",
          "publishedOn": "2023-09-30T00:41:30.287Z",
          "wordCount": null,
          "title": "A Primer on Bayesian Neural Networks: Review and Debates. (arXiv:2309.16314v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>",
          "description": "Semi-supervised learning (SSL) is a promising approach for training deep\nclassification models using labeled and unlabeled datasets. However, existing\nSSL methods rely on a large unlabeled dataset, which may not always be\navailable in many real-world applications due to legal constraints (e.g.,\nGDPR). In this paper, we investigate the research question: Can we train SSL\nmodels without real unlabeled datasets? Instead of using real unlabeled\ndatasets, we propose an SSL method using synthetic datasets generated from\ngenerative foundation models trained on datasets containing millions of samples\nin diverse domains (e.g., ImageNet). Our main concepts are identifying\nsynthetic samples that emulate unlabeled samples from generative foundation\nmodels and training classifiers using these synthetic samples. To achieve this,\nour method is formulated as an alternating optimization problem: (i)\nmeta-learning of generative foundation models and (ii) SSL of classifiers using\nreal labeled and synthetic unlabeled samples. For (i), we propose a\nmeta-learning objective that optimizes latent variables to generate samples\nthat resemble real labeled samples and minimize the validation loss. For (ii),\nwe propose a simple unsupervised loss function that regularizes the feature\nextractors of classifiers to maximize the performance improvement obtained from\nsynthetic samples. We confirm that our method outperforms baselines using\ngenerative foundation models on SSL. We also demonstrate that our methods\noutperform SSL using real unlabeled datasets in scenarios with extremely small\namounts of labeled datasets. This suggests that synthetic samples have the\npotential to provide improvement gains more efficiently than real unlabeled\ndata.",
          "link": "http://arxiv.org/abs/2309.16143",
          "publishedOn": "2023-09-30T00:41:30.273Z",
          "wordCount": 761,
          "title": "Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples. (arXiv:2309.16143v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16188",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhou_W/0/1/0/all/0/1\">Wenzhuo Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qu_A/0/1/0/all/0/1\">Annie Qu</a>",
          "description": "Batch reinforcement learning (RL) defines the task of learning from a fixed\nbatch of data lacking exhaustive exploration. Worst-case optimality algorithms,\nwhich calibrate a value-function model class from logged experience and perform\nsome type of pessimistic evaluation under the learned model, have emerged as a\npromising paradigm for batch RL. However, contemporary works on this stream\nhave commonly overlooked the hierarchical decision-making structure hidden in\nthe optimization landscape. In this paper, we adopt a game-theoretical\nviewpoint and model the policy learning diagram as a two-player general-sum\ngame with a leader-follower structure. We propose a novel stochastic\ngradient-based learning algorithm: StackelbergLearner, in which the leader\nplayer updates according to the total derivative of its objective instead of\nthe usual individual gradient, and the follower player makes individual updates\nand ensures transition-consistent pessimistic reasoning. The derived learning\ndynamic naturally lends StackelbergLearner to a game-theoretic interpretation\nand provides a convergence guarantee to differentiable Stackelberg equilibria.\nFrom a theoretical standpoint, we provide instance-dependent regret bounds with\ngeneral function approximation, which shows that our algorithm can learn a\nbest-effort policy that is able to compete against any comparator policy that\nis covered by batch data. Notably, our theoretical regret guarantees only\nrequire realizability without any data coverage and strong function\napproximation conditions, e.g., Bellman closedness, which is in contrast to\nprior works lacking such guarantees. Through comprehensive experiments, we find\nthat our algorithm consistently performs as well or better as compared to\nstate-of-the-art methods in batch RL benchmark and real-world datasets.",
          "link": "http://arxiv.org/abs/2309.16188",
          "publishedOn": "2023-09-30T00:41:30.253Z",
          "wordCount": null,
          "title": "Stackelberg Batch Policy Learning. (arXiv:2309.16188v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Han Bao</a>",
          "description": "Contrastive learning is a self-supervised representation learning framework,\nwhere two positive views generated through data augmentation are made similar\nby an attraction force in a data representation space, while a repulsive force\nmakes them far from negative examples. Non-contrastive learning, represented by\nBYOL and SimSiam, further gets rid of negative examples and improves\ncomputational efficiency. While learned representations may collapse into a\nsingle point due to the lack of the repulsive force at first sight, Tian et al.\n(2021) revealed through the learning dynamics analysis that the representations\ncan avoid collapse if data augmentation is sufficiently stronger than\nregularization. However, their analysis does not take into account\ncommonly-used feature normalization, a normalizer before measuring the\nsimilarity of representations, and hence excessively strong regularization may\ncollapse the dynamics, which is an unnatural behavior under the presence of\nfeature normalization. Therefore, we extend the previous theory based on the L2\nloss by considering the cosine loss, which involves feature normalization. We\nshow that the cosine loss induces sixth-order dynamics (while the L2 loss\ninduces a third-order one), in which a stable equilibrium dynamically emerges\neven if there are only collapsed solutions with given initial parameters. Thus,\nwe offer a new understanding that feature normalization plays an important role\nin robustly preventing the dynamics collapse.",
          "link": "http://arxiv.org/abs/2309.16109",
          "publishedOn": "2023-09-30T00:41:30.247Z",
          "wordCount": null,
          "title": "Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics. (arXiv:2309.16109v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16521",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schurch_M/0/1/0/all/0/1\">Manuel Sch&#xfc;rch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Allam_A/0/1/0/all/0/1\">Ahmed Allam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rathmes_G/0/1/0/all/0/1\">Giulia Rathmes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mollaysa_A/0/1/0/all/0/1\">Amina Mollaysa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cavelti_Weder_C/0/1/0/all/0/1\">Claudia Cavelti-Weder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krauthammer_M/0/1/0/all/0/1\">Michael Krauthammer</a>",
          "description": "We propose a novel framework that combines deep generative time series models\nwith decision theory for generating personalized treatment strategies. It\nleverages historical patient trajectory data to jointly learn the generation of\nrealistic personalized treatment and future outcome trajectories through deep\ngenerative time series models. In particular, our framework enables the\ngeneration of novel multivariate treatment strategies tailored to the\npersonalized patient history and trained for optimal expected future outcomes\nbased on conditional expected utility maximization. We demonstrate our\nframework by generating personalized insulin treatment strategies and blood\nglucose predictions for hospitalized diabetes patients, showcasing the\npotential of our approach for generating improved personalized treatment\nstrategies. Keywords: deep generative model, probabilistic decision support,\npersonalized treatment generation, insulin and blood glucose prediction",
          "link": "http://arxiv.org/abs/2309.16521",
          "publishedOn": "2023-09-30T00:41:30.181Z",
          "wordCount": 641,
          "title": "Generating Personalized Insulin Treatments Strategies with Deep Conditional Generative Time Series Models. (arXiv:2309.16521v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.03666",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Du_S/0/1/0/all/0/1\">Shide Du</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fang_Z/0/1/0/all/0/1\">Zihan Fang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lan_S/0/1/0/all/0/1\">Shiyang Lan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tan_Y/0/1/0/all/0/1\">Yanchao Tan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gunther_M/0/1/0/all/0/1\">Manuel G&#xfc;nther</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shiping Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Guo_W/0/1/0/all/0/1\">Wenzhong Guo</a>",
          "description": "As researchers strive to narrow the gap between machine intelligence and\nhuman through the development of artificial intelligence technologies, it is\nimperative that we recognize the critical importance of trustworthiness in\nopen-world, which has become ubiquitous in all aspects of daily life for\neveryone. However, several challenges may create a crisis of trust in current\nartificial intelligence systems that need to be bridged: 1) Insufficient\nexplanation of predictive results; 2) Inadequate generalization for learning\nmodels; 3) Poor adaptability to uncertain environments. Consequently, we\nexplore a neural program to bridge trustworthiness and open-world learning,\nextending from single-modal to multi-modal scenarios for readers. 1) To enhance\ndesign-level interpretability, we first customize trustworthy networks with\nspecific physical meanings; 2) We then design environmental well-being\ntask-interfaces via flexible learning regularizers for improving the\ngeneralization of trustworthy learning; 3) We propose to increase the\nrobustness of trustworthy learning by integrating open-world recognition losses\nwith agent mechanisms. Eventually, we enhance various trustworthy properties\nthrough the establishment of design-level explainability, environmental\nwell-being task-interfaces and open-world recognition programs. These designed\nopen-world protocols are applicable across a wide range of surroundings, under\nopen-world multimedia recognition scenarios with significant performance\nimprovements observed.",
          "link": "http://arxiv.org/abs/2308.03666",
          "publishedOn": "2023-09-30T00:41:30.123Z",
          "wordCount": null,
          "title": "Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness. (arXiv:2308.03666v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.06807",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fan_X/0/1/0/all/0/1\">Xiran Fan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_C/0/1/0/all/0/1\">Chun-Hao Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vemuri_B/0/1/0/all/0/1\">Baba C. Vemuri</a>",
          "description": "Hyperbolic spaces have been quite popular in the recent past for representing\nhierarchically organized data. Further, several classification algorithms for\ndata in these spaces have been proposed in the literature. These algorithms\nmainly use either hyperplanes or geodesics for decision boundaries in a large\nmargin classifiers setting leading to a non-convex optimization problem. In\nthis paper, we propose a novel large margin classifier based on horospherical\ndecision boundaries that leads to a geodesically convex optimization problem\nthat can be optimized using any Riemannian gradient descent technique\nguaranteeing a globally optimal solution. We present several experiments\ndepicting the competitive performance of our classifier in comparison to SOTA.",
          "link": "http://arxiv.org/abs/2302.06807",
          "publishedOn": "2023-09-30T00:41:30.118Z",
          "wordCount": null,
          "title": "Horospherical Decision Boundaries for Large Margin Classification in Hyperbolic Space. (arXiv:2302.06807v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16604",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1\">Junjie Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Labeau_M/0/1/0/all/0/1\">Matthieu Labeau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+dAlche_Buc_F/0/1/0/all/0/1\">Florence d&#x27;Alch&#xe9;-Buc</a>",
          "description": "Pairwise comparison of graphs is key to many applications in Machine learning\nranging from clustering, kernel-based classification/regression and more\nrecently supervised graph prediction. Distances between graphs usually rely on\ninformative representations of these structured objects such as bag of\nsubstructures or other graph embeddings. A recently popular solution consists\nin representing graphs as metric measure spaces, allowing to successfully\nleverage Optimal Transport, which provides meaningful distances allowing to\ncompare them: the Gromov-Wasserstein distances. However, this family of\ndistances overlooks edge attributes, which are essential for many structured\nobjects. In this work, we introduce an extension of Gromov-Wasserstein distance\nfor comparing graphs whose both nodes and edges have features. We propose novel\nalgorithms for distance and barycenter computation. We empirically show the\neffectiveness of the novel distance in learning tasks where graphs occur in\neither input space or output space, such as classification and graph\nprediction.",
          "link": "http://arxiv.org/abs/2309.16604",
          "publishedOn": "2023-09-30T00:41:30.114Z",
          "wordCount": null,
          "title": "Exploiting Edge Features in Graphs with Fused Network Gromov-Wasserstein Distance. (arXiv:2309.16604v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.16735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gyorfi_L/0/1/0/all/0/1\">L&#xe1;szl&#xf3; Gy&#xf6;rfi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linder_T/0/1/0/all/0/1\">Tam&#xe1;s Linder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walk_H/0/1/0/all/0/1\">Harro Walk</a>",
          "description": "We study the excess minimum risk in statistical inference, defined as the\ndifference between the minimum expected loss in estimating a random variable\nfrom an observed feature vector and the minimum expected loss in estimating the\nsame random variable from a transformation (statistic) of the feature vector.\nAfter characterizing lossless transformations, i.e., transformations for which\nthe excess risk is zero for all loss functions, we construct a partitioning\ntest statistic for the hypothesis that a given transformation is lossless and\nshow that for i.i.d. data the test is strongly consistent. More generally, we\ndevelop information-theoretic upper bounds on the excess risk that uniformly\nhold over fairly general classes of loss functions. Based on these bounds, we\nintroduce the notion of a delta-lossless transformation and give sufficient\nconditions for a given transformation to be universally delta-lossless.\nApplications to classification, nonparametric regression, portfolio strategies,\ninformation bottleneck, and deep learning, are also surveyed.",
          "link": "http://arxiv.org/abs/2307.16735",
          "publishedOn": "2023-09-30T00:41:30.109Z",
          "wordCount": null,
          "title": "Lossless Transformations and Excess Risk Bounds in Statistical Inference. (arXiv:2307.16735v2 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.12547",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Li_J/0/1/0/all/0/1\">Jin Li</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Luo_Y/0/1/0/all/0/1\">Ye Luo</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaowei Zhang</a>",
          "description": "This paper identifies and addresses dynamic selection problems in online\nlearning algorithms with endogenous data. In a contextual multi-armed bandit\nmodel, a novel bias (self-fulfilling bias) arises because the endogeneity of\nthe data influences the choices of decisions, affecting the distribution of\nfuture data to be collected and analyzed. We propose an\ninstrumental-variable-based algorithm to correct for the bias. It obtains true\nparameter values and attains low (logarithmic-like) regret levels. We also\nprove a central limit theorem for statistical inference. To establish the\ntheoretical properties, we develop a general technique that untangles the\ninterdependence between data and actions.",
          "link": "http://arxiv.org/abs/2108.12547",
          "publishedOn": "2023-09-30T00:41:30.106Z",
          "wordCount": null,
          "title": "Dynamic Selection in Algorithmic Decision-making. (arXiv:2108.12547v3 [econ.EM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kevin Han Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orbanz_P/0/1/0/all/0/1\">Peter Orbanz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Austern_M/0/1/0/all/0/1\">Morgane Austern</a>",
          "description": "We provide results that exactly quantify how data augmentation affects the\nvariance and limiting distribution of estimates, and analyze several specific\nmodels in detail. The results confirm some observations made in machine\nlearning practice, but also lead to unexpected findings: Data augmentation may\nincrease rather than decrease the uncertainty of estimates, such as the\nempirical prediction risk. It can act as a regularizer, but fails to do so in\ncertain high-dimensional problems, and it may shift the double-descent peak of\nan empirical risk. Overall, the analysis shows that several properties data\naugmentation has been attributed with are not either true or false, but rather\ndepend on a combination of factors -- notably the data distribution, the\nproperties of the estimator, and the interplay of sample size, number of\naugmentations, and dimension. Our main theoretical tool is a limit theorem for\nfunctions of randomly transformed, high-dimensional random vectors. The proof\ndraws on work in probability on noise stability of functions of many variables.",
          "link": "http://arxiv.org/abs/2202.09134",
          "publishedOn": "2023-09-30T00:41:30.104Z",
          "wordCount": null,
          "title": "Data Augmentation in the Underparameterized and Overparameterized Regimes. (arXiv:2202.09134v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaoqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yibo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenghao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Han Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxin Chen</a>",
          "description": "The increasing capabilities of large language models (LLMs) raise\nopportunities for artificial general intelligence but concurrently amplify\nsafety concerns, such as potential misuse of AI systems, necessitating\neffective AI alignment. Reinforcement Learning from Human Feedback (RLHF) has\nemerged as a promising pathway towards AI alignment but brings forth challenges\ndue to its complexity and dependence on a separate reward model. Direct\nPreference Optimization (DPO) has been proposed as an alternative, and it\nremains equivalent to RLHF under the reverse KL regularization constraint. This\npaper presents $f$-DPO, a generalized approach to DPO by incorporating diverse\ndivergence constraints. We show that under certain $f$-divergences, including\nJensen-Shannon divergence, forward KL divergences and $\\alpha$-divergences, the\ncomplex relationship between the reward and optimal policy can also be\nsimplified by addressing the Karush-Kuhn-Tucker conditions. This eliminates the\nneed for estimating the normalizing constant in the Bradley-Terry model and\nenables a tractable mapping between the reward function and the optimal policy.\nOur approach optimizes LLMs to align with human preferences in a more efficient\nand supervised manner under a broad set of divergence constraints. Empirically,\nadopting these divergences ensures a balance between alignment performance and\ngeneration diversity. Importantly, $f$-DPO outperforms PPO-based methods in\ndivergence efficiency, and divergence constraints directly influence expected\ncalibration error (ECE).",
          "link": "http://arxiv.org/abs/2309.16240",
          "publishedOn": "2023-09-30T00:41:30.052Z",
          "wordCount": null,
          "title": "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints. (arXiv:2309.16240v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16578",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1\">He Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_S/0/1/0/all/0/1\">Siyuan Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+You_J/0/1/0/all/0/1\">Jiacheng You</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_S/0/1/0/all/0/1\">Shuxin Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lu_Z/0/1/0/all/0/1\">Ziheng Lu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_N/0/1/0/all/0/1\">Nanning Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shao_B/0/1/0/all/0/1\">Bin Shao</a>",
          "description": "Orbital-free density functional theory (OFDFT) is a quantum chemistry\nformulation that has a lower cost scaling than the prevailing Kohn-Sham DFT,\nwhich is increasingly desired for contemporary molecular research. However, its\naccuracy is limited by the kinetic energy density functional, which is\nnotoriously hard to approximate for non-periodic molecular systems. In this\nwork, we propose M-OFDFT, an OFDFT approach capable of solving molecular\nsystems using a deep-learning functional model. We build the essential\nnonlocality into the model, which is made affordable by the concise density\nrepresentation as expansion coefficients under an atomic basis. With techniques\nto address unconventional learning challenges therein, M-OFDFT achieves a\ncomparable accuracy with Kohn-Sham DFT on a wide range of molecules untouched\nby OFDFT before. More attractively, M-OFDFT extrapolates well to molecules much\nlarger than those in training, which unleashes the appealing scaling for\nstudying large molecules including proteins, representing an advancement of the\naccuracy-efficiency trade-off frontier in quantum chemistry.",
          "link": "http://arxiv.org/abs/2309.16578",
          "publishedOn": "2023-09-30T00:41:30.051Z",
          "wordCount": null,
          "title": "M-OFDFT: Overcoming the Barrier of Orbital-Free Density Functional Theory for Molecular Systems Using Deep Learning. (arXiv:2309.16578v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.02958",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_W/0/1/0/all/0/1\">Wenjia Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yanyuan Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaowei Zhang</a>",
          "description": "Nested simulation concerns estimating functionals of a conditional\nexpectation via simulation. In this paper, we propose a new method based on\nkernel ridge regression to exploit the smoothness of the conditional\nexpectation as a function of the multidimensional conditioning variable.\nAsymptotic analysis shows that the proposed method can effectively alleviate\nthe curse of dimensionality on the convergence rate as the simulation budget\nincreases, provided that the conditional expectation is sufficiently smooth.\nThe smoothness bridges the gap between the cubic root convergence rate (that\nis, the optimal rate for the standard nested simulation) and the square root\nconvergence rate (that is, the canonical rate for the standard Monte Carlo\nsimulation). We demonstrate the performance of the proposed method via\nnumerical examples from portfolio risk management and input uncertainty\nquantification.",
          "link": "http://arxiv.org/abs/2201.02958",
          "publishedOn": "2023-09-30T00:41:30.051Z",
          "wordCount": null,
          "title": "Smooth Nested Simulation: Bridging Cubic and Square Root Convergence Rates in High Dimensions. (arXiv:2201.02958v5 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.11562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1\">A. Feder Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Katherine Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choksi_M/0/1/0/all/0/1\">Madiha Choksi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barocas_S/0/1/0/all/0/1\">Solon Barocas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grimmelmann_J/0/1/0/all/0/1\">James Grimmelmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1\">Jon Kleinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1\">Siddhartha Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Baobao Zhang</a>",
          "description": "Variance in predictions across different trained models is a significant,\nunder-explored source of error in fair classification. In practice, the\nvariance on some data examples is so large that decisions can be effectively\narbitrary. To investigate this problem, we take an experimental approach and\nmake four overarching contributions: We 1) Define a metric called\nself-consistency, derived from variance, which we use as a proxy for measuring\nand reducing arbitrariness; 2) Develop an ensembling algorithm that abstains\nfrom classification when a prediction would be arbitrary; 3) Conduct the\nlargest to-date empirical study of the role of variance (vis-a-vis\nself-consistency and arbitrariness) in fair classification; and, 4) Release a\ntoolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily\nusable for future research. Altogether, our experiments reveal shocking\ninsights about the reliability of conclusions on benchmark datasets. Most\nfairness classification benchmarks are close-to-fair when taking into account\nthe amount of arbitrariness present in predictions -- before we even try to\napply common fairness interventions. This finding calls into question the\npractical utility of common algorithmic fairness methods, and in turn suggests\nthat we should fundamentally reconsider how we choose to measure fairness in\nmachine learning.",
          "link": "http://arxiv.org/abs/2301.11562",
          "publishedOn": "2023-09-30T00:41:29.963Z",
          "wordCount": null,
          "title": "Is My Prediction Arbitrary? Confounding Effects of Variance in Fair Classification. (arXiv:2301.11562v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16412",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Noskov_F/0/1/0/all/0/1\">Fedor Noskov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fishkov_A/0/1/0/all/0/1\">Alexander Fishkov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Panov_M/0/1/0/all/0/1\">Maxim Panov</a>",
          "description": "Prediction with the possibility of abstention (or selective prediction) is an\nimportant problem for error-critical machine learning applications. While\nwell-studied in the classification setup, selective approaches to regression\nare much less developed. In this work, we consider the nonparametric\nheteroskedastic regression problem and develop an abstention procedure via\ntesting the hypothesis on the value of the conditional variance at a given\npoint. Unlike existing methods, the proposed one allows to account not only for\nthe value of the variance itself but also for the uncertainty of the\ncorresponding variance predictor. We prove non-asymptotic bounds on the risk of\nthe resulting estimator and show the existence of several different convergence\nregimes. Theoretical analysis is illustrated with a series of experiments on\nsimulated and real-world data.",
          "link": "http://arxiv.org/abs/2309.16412",
          "publishedOn": "2023-09-30T00:41:29.928Z",
          "wordCount": null,
          "title": "Selective Nonparametric Regression via Testing. (arXiv:2309.16412v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16598",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zrnic_T/0/1/0/all/0/1\">Tijana Zrnic</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Candes_E/0/1/0/all/0/1\">Emmanuel J. Cand&#xe8;s</a>",
          "description": "While reliable data-driven decision-making hinges on high-quality labeled\ndata, the acquisition of quality labels often involves laborious human\nannotations or slow and expensive scientific measurements. Machine learning is\nbecoming an appealing alternative as sophisticated predictive techniques are\nbeing used to quickly and cheaply produce large amounts of predicted labels;\ne.g., predicted protein structures are used to supplement experimentally\nderived structures, predictions of socioeconomic indicators from satellite\nimagery are used to supplement accurate survey data, and so on. Since\npredictions are imperfect and potentially biased, this practice brings into\nquestion the validity of downstream inferences. We introduce cross-prediction:\na method for valid inference powered by machine learning. With a small labeled\ndataset and a large unlabeled dataset, cross-prediction imputes the missing\nlabels via machine learning and applies a form of debiasing to remedy the\nprediction inaccuracies. The resulting inferences achieve the desired error\nprobability and are more powerful than those that only leverage the labeled\ndata. Closely related is the recent proposal of prediction-powered inference,\nwhich assumes that a good pre-trained model is already available. We show that\ncross-prediction is consistently more powerful than an adaptation of\nprediction-powered inference in which a fraction of the labeled data is split\noff and used to train the model. Finally, we observe that cross-prediction\ngives more stable conclusions than its competitors; its confidence intervals\ntypically have significantly lower variability.",
          "link": "http://arxiv.org/abs/2309.16598",
          "publishedOn": "2023-09-30T00:41:29.922Z",
          "wordCount": null,
          "title": "Cross-Prediction-Powered Inference. (arXiv:2309.16598v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.07403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lowy_A/0/1/0/all/0/1\">Andrew Lowy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1\">Meisam Razaviyayn</a>",
          "description": "We study differentially private (DP) stochastic optimization (SO) with loss\nfunctions whose worst-case Lipschitz parameter over all data points may be\nextremely large. To date, the vast majority of work on DP SO assumes that the\nloss is uniformly Lipschitz continuous over data (i.e. stochastic gradients are\nuniformly bounded over all data points). While this assumption is convenient,\nit often leads to pessimistic excess risk bounds. In many practical problems,\nthe worst-case (uniform) Lipschitz parameter of the loss over all data points\nmay be extremely large due to outliers. In such cases, the error bounds for DP\nSO, which scale with the worst-case Lipschitz parameter of the loss, are\nvacuous. To address these limitations, this work provides near-optimal excess\nrisk bounds that do not depend on the uniform Lipschitz parameter of the loss.\nBuilding on a recent line of work (Wang et al., 2020; Kamath et al., 2022), we\nassume that stochastic gradients have bounded $k$-th order moments for some $k\n\\geq 2$. Compared with works on uniformly Lipschitz DP SO, our excess risk\nscales with the $k$-th moment bound instead of the uniform Lipschitz parameter\nof the loss, allowing for significantly faster rates in the presence of\noutliers and/or heavy-tailed data. For convex and strongly convex loss\nfunctions, we provide the first asymptotically optimal excess risk bounds (up\nto a logarithmic factor). In contrast to (Wang et al., 2020; Kamath et al.,\n2022), our bounds do not require the loss function to be differentiable/smooth.\nWe also devise a linear-time algorithm for smooth losses that has excess risk\nthat is tight in certain practical parameter regimes. Additionally, our work is\nthe first to address non-convex non-uniformly Lipschitz loss functions\nsatisfying the Proximal-PL inequality; this covers some practical machine\nlearning models. Our Proximal-PL algorithm has near-optimal excess risk.",
          "link": "http://arxiv.org/abs/2209.07403",
          "publishedOn": "2023-09-30T00:41:29.711Z",
          "wordCount": null,
          "title": "Private Stochastic Optimization With Large Worst-Case Lipschitz Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses. (arXiv:2209.07403v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Agrawal_S/0/1/0/all/0/1\">Shubhada Agrawal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mathieu_T/0/1/0/all/0/1\">Timoth&#xe9;e Mathieu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Basu_D/0/1/0/all/0/1\">Debabrota Basu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maillard_O/0/1/0/all/0/1\">Odalric-Ambrym Maillard</a>",
          "description": "We investigate the regret-minimisation problem in a multi-armed bandit\nsetting with arbitrary corruptions. Similar to the classical setup, the agent\nreceives rewards generated independently from the distribution of the arm\nchosen at each time. However, these rewards are not directly observed. Instead,\nwith a fixed $\\varepsilon\\in (0,\\frac{1}{2})$, the agent observes a sample from\nthe chosen arm's distribution with probability $1-\\varepsilon$, or from an\narbitrary corruption distribution with probability $\\varepsilon$. Importantly,\nwe impose no assumptions on these corruption distributions, which can be\nunbounded. In this setting, accommodating potentially unbounded corruptions, we\nestablish a problem-dependent lower bound on regret for a given family of arm\ndistributions. We introduce CRIMED, an asymptotically-optimal algorithm that\nachieves the exact lower bound on regret for bandits with Gaussian\ndistributions with known variance. Additionally, we provide a finite-sample\nanalysis of CRIMED's regret performance. Notably, CRIMED can effectively handle\ncorruptions with $\\varepsilon$ values as high as $\\frac{1}{2}$. Furthermore, we\ndevelop a tight concentration result for medians in the presence of arbitrary\ncorruptions, even with $\\varepsilon$ values up to $\\frac{1}{2}$, which may be\nof independent interest. We also discuss an extension of the algorithm for\nhandling misspecification in Gaussian model.",
          "link": "http://arxiv.org/abs/2309.16563",
          "publishedOn": "2023-09-30T00:41:29.710Z",
          "wordCount": null,
          "title": "CRIMED: Lower and Upper Bounds on Regret for Bandits with Unbounded Stochastic Corruption. (arXiv:2309.16563v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16409",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhang Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihua Zhang</a>",
          "description": "The purpose of this work is to transport the information from multiple\nrandomized controlled trials to the target population where we only have the\ncontrol group data. Previous works rely critically on the mean exchangeability\nassumption. However, as pointed out by many current studies, the mean\nexchangeability assumption might be violated. Motivated by the synthetic\ncontrol method, we construct a synthetic treatment group for the target\npopulation by a weighted mixture of treatment groups of source populations. We\nestimate the weights by minimizing the conditional maximum mean discrepancy\nbetween the weighted control groups of source populations and the target\npopulation. We establish the asymptotic normality of the synthetic treatment\ngroup estimator based on the sieve semiparametric theory. Our method can serve\nas a novel complementary approach when the mean exchangeability assumption is\nviolated. Experiments are conducted on synthetic and real-world datasets to\ndemonstrate the effectiveness of our methods.",
          "link": "http://arxiv.org/abs/2309.16409",
          "publishedOn": "2023-09-30T00:41:29.376Z",
          "wordCount": 648,
          "title": "Constructing Synthetic Treatment Groups without the Mean Exchangeability Assumption. (arXiv:2309.16409v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.10538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xinran Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>",
          "description": "Bayesian optimization (BO), while proved highly effective for many black-box\nfunction optimization tasks, requires practitioners to carefully select priors\nthat well model their functions of interest. Rather than specifying by hand,\nresearchers have investigated transfer learning based methods to automatically\nlearn the priors, e.g. multi-task BO (Swersky et al., 2013), few-shot BO\n(Wistuba and Grabocka, 2021) and HyperBO (Wang et al., 2022). However, those\nprior learning methods typically assume that the input domains are the same for\nall tasks, weakening their ability to use observations on functions with\ndifferent domains or generalize the learned priors to BO on different search\nspaces. In this work, we present HyperBO+: a pre-training approach for\nhierarchical Gaussian processes that enables the same prior to work universally\nfor Bayesian optimization on functions with different domains. We propose a\ntwo-step pre-training method and analyze its appealing asymptotic properties\nand benefits to BO both theoretically and empirically. On real-world\nhyperparameter tuning tasks that involve multiple search spaces, we demonstrate\nthat HyperBO+ is able to generalize to unseen search spaces and achieves lower\nregrets than competitive baselines.",
          "link": "http://arxiv.org/abs/2212.10538",
          "publishedOn": "2023-09-30T00:41:29.371Z",
          "wordCount": 735,
          "title": "HyperBO+: Pre-training a universal prior for Bayesian optimization with hierarchical Gaussian processes. (arXiv:2212.10538v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xinran Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>",
          "description": "Bayesian optimization (BO) is a popular black-box function optimization\nmethod, which makes sequential decisions based on a Bayesian model, typically a\nGaussian process (GP), of the function. To ensure the quality of the model,\ntransfer learning approaches have been developed to automatically design GP\npriors by learning from observations on \"training\" functions. These training\nfunctions are typically required to have the same domain as the \"test\" function\n(black-box function to be optimized). In this paper, we introduce MPHD, a model\npre-training method on heterogeneous domains, which uses a neural net mapping\nfrom domain-specific contexts to specifications of hierarchical GPs. MPHD can\nbe seamlessly integrated with BO to transfer knowledge across heterogeneous\nsearch spaces. Our theoretical and empirical results demonstrate the validity\nof MPHD and its superior performance on challenging black-box function\noptimization tasks.",
          "link": "http://arxiv.org/abs/2309.16597",
          "publishedOn": "2023-09-30T00:41:29.364Z",
          "wordCount": 644,
          "title": "Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces. (arXiv:2309.16597v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16099",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ertefaie_A/0/1/0/all/0/1\">Ashkan Ertefaie</a>, <a href=\"http://arxiv.org/find/math/1/au:+Duttweiler_L/0/1/0/all/0/1\">Luke Duttweiler</a>, <a href=\"http://arxiv.org/find/math/1/au:+Johnson_B/0/1/0/all/0/1\">Brent A. Johnson</a>, <a href=\"http://arxiv.org/find/math/1/au:+Laan_M/0/1/0/all/0/1\">Mark J. van der Laan</a>",
          "description": "Flexible estimation of the mean outcome under a treatment regimen (i.e.,\nvalue function) is the key step toward personalized medicine. We define our\ntarget parameter as a conditional value function given a set of baseline\ncovariates which we refer to as a stratum based value function. We focus on\nsemiparametric class of decision rules and propose a sieve based nonparametric\ncovariate adjusted regimen-response curve estimator within that class. Our work\ncontributes in several ways. First, we propose an inverse probability weighted\nnonparametrically efficient estimator of the smoothed regimen-response curve\nfunction. We show that asymptotic linearity is achieved when the nuisance\nfunctions are undersmoothed sufficiently. Asymptotic and finite sample criteria\nfor undersmoothing are proposed. Second, using Gaussian process theory, we\npropose simultaneous confidence intervals for the smoothed regimen-response\ncurve function. Third, we provide consistency and convergence rate for the\noptimizer of the regimen-response curve estimator; this enables us to estimate\nan optimal semiparametric rule. The latter is important as the optimizer\ncorresponds with the optimal dynamic treatment regimen. Some finite-sample\nproperties are explored with simulations.",
          "link": "http://arxiv.org/abs/2309.16099",
          "publishedOn": "2023-09-30T00:41:26.276Z",
          "wordCount": 686,
          "title": "Nonparametric estimation of a covariate-adjusted counterfactual treatment regimen response curve. (arXiv:2309.16099v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Heng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "We study unconstrained Online Linear Optimization with Lipschitz losses. The\ngoal is to simultaneously achieve ($i$) second order gradient adaptivity; and\n($ii$) comparator norm adaptivity also known as \"parameter freeness\" in the\nliterature. Existing regret bounds (Cutkosky and Orabona, 2018; Mhammedi and\nKoolen, 2020; Jacobsen and Cutkosky, 2022) have the suboptimal $O(\\sqrt{V_T\\log\nV_T})$ dependence on the gradient variance $V_T$, while the present work\nimproves it to the optimal rate $O(\\sqrt{V_T})$ using a novel\ncontinuous-time-inspired algorithm, without any impractical doubling trick.\nThis result can be extended to the setting with unknown Lipschitz constant,\neliminating the range ratio problem from prior works (Mhammedi and Koolen,\n2020).\n\nConcretely, we first show that the aimed simultaneous adaptivity can be\nachieved fairly easily in a continuous time analogue of the problem, where the\nenvironment is modeled by an arbitrary continuous semimartingale. Then, our key\ninnovation is a new discretization argument that preserves such adaptivity in\nthe discrete time adversarial setting. This refines a non-gradient-adaptive\ndiscretization argument from (Harvey et al., 2023), both algorithmically and\nanalytically, which could be of independent interest.",
          "link": "http://arxiv.org/abs/2309.16044",
          "publishedOn": "2023-09-30T00:41:26.255Z",
          "wordCount": 680,
          "title": "Improving Adaptive Online Learning Using Refined Discretization. (arXiv:2309.16044v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        }
      ]
    },
    {
      "title": "Machine Learning",
      "feedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
      "siteUrl": "https://www.reddit.com/r/MachineLearning/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hb6e9/research_incentivizing_dataset_contributors/",
          "author": null,
          "description": "Hi there - can someone point me in the direction of projects that are incentivizing dataset contributors? I have a background in blockchain and crypto-assets, so I am new to the ML space, but it seems like it's a place where there would be ample crossover...and I haven't found many projects dealing with this.\n Thanks!\n    submitted by    /u/gigstudies  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hb6e9/research_incentivizing_dataset_contributors/",
          "publishedOn": "2023-10-27T00:35:08.000Z",
          "wordCount": 2585,
          "title": "[Research] Incentivizing Dataset Contributors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17hattb/training_imagenet_on_resnet_dropping_lr_has/",
          "author": null,
          "description": "I'm trying to train Resnet50 on Imagenet following this paper [1] as well as this one [2].\n ​\n They say that at approximately every 30 epochs, I should drop the learning rate by 10.\n Since I'm training on 8 GPUs, I adjusted the learning rate according to [1].\n ​\n Original lr= 0.1\n Original Batch = 256\n Per-GPU lr = 0.025\n Per-GPU Batch = 64\n ​\n The problem I have is that when I divide the learning rate by 10 at convergence (approx 30 epochs), I don't get as much improvement as [1] and [2].\n https://preview.redd.it/5ar2g15h1nwb1.png?width=683&format=png&auto=webp&s=3e2751443cea654d9c6366dc4dc9859f0ec7952b\n Has anyone else had this issue? Any advice?\n Thanks\n ​\n    submitted by    /u/mrLiamFa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17hattb/training_imagenet_on_resnet_dropping_lr_has/",
          "publishedOn": "2023-10-27T00:17:22.000Z",
          "wordCount": 2639,
          "title": "Training ImageNet on Resnet - Dropping LR has little improvement on accuracy [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h8vgr/d_stoa_local_rag/",
          "author": null,
          "description": "Which VDB + orchestration layer + generative text model stack would you recommend for building locally on an M2 Max chip? \n    submitted by    /u/Frequent-Let231  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h8vgr/d_stoa_local_rag/",
          "publishedOn": "2023-10-26T22:42:32.000Z",
          "wordCount": 2551,
          "title": "[D] STOA Local RAG",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h7d9u/d_is_there_an_online_llama_model_that_supports/",
          "author": null,
          "description": "Hi,\n I'm doing some work with using multi-modal data with LLaMA, for example, Video-LLaMA, which converts images/videos into embeddings, concatenates it with the text embeddings, and feeds it into LLaMA. It's difficult for me to run some of the models myself because of computational constraints. I'm wondering if there is an online demo that supports inputting embeddings directly (as opposed to text tokens).\n To clarify the title, I meant an online demo, not the weights.\n    submitted by    /u/DumplingLife7584  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h7d9u/d_is_there_an_online_llama_model_that_supports/",
          "publishedOn": "2023-10-26T21:36:14.000Z",
          "wordCount": 2614,
          "title": "[D] Is there an online LLaMA model that supports plugging in embeddings directly?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h4mkc/r_linear_representations_of_sentiment_in_large/",
          "author": null,
          "description": "Paper. I am not affiliated with this paper or its authors.\n Abstract:\n  \nSentiment is a pervasive feature in natural language text, yet it is an open question how sentiment is represented within Large Language Models (LLMs). In this study, we reveal that across a range of models, sentiment is represented linearly: a single direction in activation space mostly captures the feature across a range of tasks with one extreme for positive and the other for negative. Through causal interventions, we isolate this direction and show it is causally relevant in both toy tasks and real world datasets such as Stanford Sentiment Treebank. Through this case study we model a thorough investigation of what a single direction means on a broad data distribution. We further uncover the mechanisms that involve this direction, highlighting the roles of a small subset of attention heads and neurons. Finally, we discover a phenomenon which we term the summarization motif: sentiment is not solely represented on emotionally charged words, but is additionally summarized at intermediate positions without inherent sentiment, such as punctuation and names. We show that in Stanford Sentiment Treebank zero-shot classification, 76% of above-chance classification accuracy is lost when ablating the sentiment direction, nearly half of which (36%) is due to ablating the summarized sentiment direction exclusively at comma positions.\n  \nTwitter thread from one of the paper's authors.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h4mkc/r_linear_representations_of_sentiment_in_large/",
          "publishedOn": "2023-10-26T19:36:18.000Z",
          "wordCount": 2759,
          "title": "[R] Linear Representations of Sentiment in Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h4dd3/d_good_reading_materials_for_adversarial_machine/",
          "author": null,
          "description": "Trying to get an intern up to speed with ML application to wireless communications and adversarial ML for wireless communications. Talking jamming, anti-jamming, and spoofing. I don't want to throw them into the deep end just yet though, but rather give them a good foundation and basis for which to be able to take up more advanced work and build to it. Looking for fundamental texts on the topic of ML used for wireless communications and also it's use for adversarial attacks on these systems. Looking more for basic and starter papers, tutorials, and background, meta review papers, and just overall good places to get feet wet into this area as a novice. Essentially good resources to point an intern learning about this to get them up to speed kind of reading materials.\n I am looking for good …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h4dd3/d_good_reading_materials_for_adversarial_machine/",
          "publishedOn": "2023-10-26T19:25:20.000Z",
          "wordCount": 2937,
          "title": "[D] Good Reading Materials for (Adversarial) Machine Learning and RF Comms (EW)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h45y3/d_can_anyone_tell_me_if_the_machine_learning/",
          "author": null,
          "description": "Data Collection\n \nUnderstanding Data\n i. importing necessary libraries\n ii. check row and columns\n iii. check data types\n iv. Check data distribution\n \nData Cleaning\n i. Handle datatype issues\n ii. Maintain Data Consistency\n iii. Check if data contains outliers or if the data is not normally distributed to decide between mean or median\n iv. Identify missing values\n v. Handle missing values by-\n a.Drop missing values b. Mean, median or mode imputation c. Prediction Model d. replace missing values \n vi. Duplicate data detection and treatment\n vii. Repeat data cleaning\n \nEDA\n i. Variable Identification\n a. Identify predictor and features b. Identify types or category of data \n ii. Univariate Analysis\n iii. Bi-variate Analysis\n iv. Outlier detection and treatment\n v. Encoding\n vi. Feature Engineering\n vii. Variable Transformation\n  a. Normalization b. Scaling \n viii. Variable Creation\n \nIf testing data is not given, split the dataset to train and test set. Otherwise repeat step 3 and 4 for given test dataset.\n \nModel Building\n i. Model Training on training set\n ii. Model Evaluation and cross validate\n iii. Fine Tuning or Model optimization\n iv. Model selection\n \nEvaluate model accuracy with test data.\n \n    submitted by    /u/Samia_Tisha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h45y3/d_can_anyone_tell_me_if_the_machine_learning/",
          "publishedOn": "2023-10-26T19:16:43.000Z",
          "wordCount": 2738,
          "title": "[D] Can anyone tell me if the machine learning workflow is correct or not? Could anyone please refer to tutorials or blogs to learn the proper workflow? Any suggestions are welcome.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h43e9/r_what_algorithms_can_transformers_learn_a_study/",
          "author": null,
          "description": "Paper. I am not affiliated with this paper or its authors.\n Abstract:\n  \nLarge language models exhibit surprising emergent generalization properties, yet also struggle on many simple reasoning tasks such as arithmetic and parity. This raises the question of if and when Transformer models can learn the true algorithm for solving a task. We study the scope of Transformers' abilities in the specific setting of length generalization on algorithmic tasks. Here, we propose a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task. Specifically, we leverage RASP (Weiss et al., 2021) -- a programming language designed for the computational model of a Transformer -- and introduce the RASP-Generalization Conjecture: Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths. This simple conjecture remarkably captures most known instances of length generalization on algorithmic tasks. Moreover, we leverage our insights to drastically improve generalization performance on traditionally hard tasks (such as parity and addition). On the theoretical side, we give a simple example where the \"min-degree-interpolator\" model of learning from Abbe et al. (2023) does not correctly predict Transformers' out-of-distribution behavior, but our conjecture does. Overall, our work provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers.\n  \nTwitter thread from one of the work's authors.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h43e9/r_what_algorithms_can_transformers_learn_a_study/",
          "publishedOn": "2023-10-26T19:13:38.000Z",
          "wordCount": 2769,
          "title": "[R] What Algorithms can Transformers Learn? A Study in Length Generalization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h3tgx/r_qmoe_practical_sub1bit_compression_of/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.16795\n Github: https://github.com/ist-daslab/qmoe\n Abstract:\n  \nMixture-of-Experts (MoE) architectures offer a general solution to the high inference costs of large language models (LLMs) via sparse routing, bringing faster and more accurate models, at the cost of massive parameter counts. For example, the SwitchTransformer-c2048 model has 1.6 trillion parameters, requiring 3.2TB of accelerator memory to run efficiently, which makes practical deployment challenging and expensive. In this paper, we present a solution to this memory problem, in form of a new compression and execution framework called QMoE. Specifically, QMoE consists of a scalable algorithm which accurately compresses trillion-parameter MoEs to less than 1 bit per parameter, in a custom format co-designed with bespoke GPU decoding kernels to facilitate efficient end-to-end compressed inference, with minor runtime overheads relative to uncompressed execution. Concretely, QMoE can compress the 1.6 trillion parameter SwitchTransformer-c2048 model to less than 160GB (20x compression, 0.8 bits per parameter) at only minor accuracy loss, in less than a day on a single GPU. This enables, for the first time, the execution of a trillion-parameter model on affordable commodity hardware, like a single server with 4x NVIDIA A6000 or 8x NVIDIA 3090 GPUs, at less than 5% runtime overhead relative to ideal uncompressed inference. \n  \nhttps://preview.redd.it/wka92keqelwb1.jpg?width=1843&format=pjpg&auto=webp&s=10cf67b344d3c776049da6b78244fc140b2d4142\n https://preview.redd.it/khxw1neqelwb1.jpg?width=898&format=pjpg&auto=webp&s=83006dac6e03963f2443f4e4ba710dcf8166acc8\n https://preview.redd.it/xsc2ykeqelwb1.jpg?width=796&format=pjpg&auto=webp&s=c23d03956f4a9aa9d9f185592a5bfe45039698f4\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h3tgx/r_qmoe_practical_sub1bit_compression_of/",
          "publishedOn": "2023-10-26T19:01:24.000Z",
          "wordCount": 2768,
          "title": "[R] QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models - Institute of Science and Technology Austria (ISTA) 2023 - Can compress the 1.6 trillion parameter SwitchTransformer-c2048 model to less than 160GB (20x compression, 0.8 bits per parameter) at only minor accuracy loss!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h1zpd/d_requesting_feedback_on_masters_in_ai_program/",
          "author": null,
          "description": "As the title says I'm asking for feedback from folks in the field of ML/AI on the MSAI program at UT@Austin.\n Here's the program website: https://cdso.utexas.edu/msai\n My Skills/Experience:\n  \nHave a BS in Comp Sci\n Very comfortable with Math\n Very experienced SE with >20 years in the industry\n Very comfortable with Python, many other languages and confident I can learn any new language/framework/APIs\n Have completed the Fast.ai program\n Have worked through Andrej Karpathy's makemore videos\n Currently working in a leadership AI Engineering role doing work with LLMs, Vector DBs, and Computer Vision models\n Comfortable with NNs, Backprop and have implemented from scratch several times for learning\n  \nThe Program:\n Required Courses:\n  \nDeep Learning\n Ethics in AI\n Machine Learning\n Planning, Search and Reasoning under Uncertainty\n Reinforcement Learning\n  \nElectives:\n  \nAI in Healthcare\n Automated Logical Reasoning\n Case Studies in Machine Learning\n Natural Language Processing\n Online Learning and Optimization\n Optimization\n  \nProgram Pros/Cons:\n  \nPro: It's super affordable\n Pro: It's entirely online/async which would work great with my work schedule\n Cons: It's a new program so there are no reviews from past students to look at\n  \nMy Goal:\n Move from \"AI Engineering\" (as it's called these days) into research. I'm interested in several areas like model architecture and robotics. I'm not sure to what degree these roles would require a PhD though? If I complete this program I'd like it to be useful for pursuing a PhD if I decide to take that path.\n For anyone in the industry, I'd love feedback on whether this looks like a useful program that will help me move toward my goals. If you're aware of other options that might be better I'd love to hear about them.\n P.S. Please keep the Reddit snark to a minimum, not useful.\n Thank you in advance.\n    submitted by    /u/meowkittykitty510  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h1zpd/d_requesting_feedback_on_masters_in_ai_program/",
          "publishedOn": "2023-10-26T17:39:52.000Z",
          "wordCount": 2831,
          "title": "[D] Requesting feedback on Master's in AI program with University of Texas at Austin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17h1gpa/d_recommendations_to_improve_plan_outcomes/",
          "author": null,
          "description": "I have retirement plan data with outcomes like success/fail and remaining assets. I am looking for a way to predict how failed retirement plans can be improved. For example, when presented with a plan that fails, I would like to provide recommendations to improve the the plan outcome; e.g. increase savings by x, or delay retirement by x years.\n Any suggestions on how I should go about this? Using typical methods only tells me if a plan will fail or not, but I'm looking for a way to provide recommendations based on successful plans.\n    submitted by    /u/BallLogical5087  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17h1gpa/d_recommendations_to_improve_plan_outcomes/",
          "publishedOn": "2023-10-26T17:15:38.000Z",
          "wordCount": 2626,
          "title": "[D] Recommendations to improve plan outcomes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gyztv/r_pretrained_imagenet_weights_for_vit/",
          "author": null,
          "description": "Hello, I am working on the research I need to compare my model with ViT for that I need pretrained weights of ViT-Ti/16, ViT-S/16, ViT-S/32, ViT-B/16, and ViT-B/32. I tried to find but I got npz file that has a different key than from vit_pytorch import ViT do you know where can i find ImageNet weights?\n    submitted by    /u/NoEntertainment6225  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gyztv/r_pretrained_imagenet_weights_for_vit/",
          "publishedOn": "2023-10-26T15:24:59.000Z",
          "wordCount": 2588,
          "title": "[R] Pretrained ImageNet weights for ViT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gvphb/d_grouped_query_attention_in_llama_70b_v2/",
          "author": null,
          "description": "Hey guys, after thousands of experiments with bigger LLaMA fine-tunes I'm somewhat sure the GQA mechanism might be your enemy and generate wrong answers, especially for math and such complex areas.\n I'd like to use MHA (Multi Head Attention) if possbile. I'm just not sure - do I need to retrain model completely or is it possible to just increase heads count and KV size and proceed with the stock model AS IS?\n    submitted by    /u/Gatzuma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gvphb/d_grouped_query_attention_in_llama_70b_v2/",
          "publishedOn": "2023-10-26T12:46:06.000Z",
          "wordCount": 2606,
          "title": "[D] Grouped Query Attention in LLaMA 70B v2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gv3wn/n_ml_models_for_efficient_fraud_detection/",
          "author": null,
          "description": "For efficient Fraud Detection using ML models, Qbeast Format introduces a data-driven approach. The key lies in sampling and optimizing training processes without compromising accuracy. 🕵🏼‍♀️\n Explore the technical details: https://qbeast.io/qbeast-format-can-improve-fraud-detection/\n    submitted by    /u/alinagrebenkina  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gv3wn/n_ml_models_for_efficient_fraud_detection/",
          "publishedOn": "2023-10-26T12:14:10.000Z",
          "wordCount": 2558,
          "title": "[N] ML models for efficient Fraud Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gtzwm/d_asrsttvrs_ranking/",
          "author": null,
          "description": "What are the best overall ASR/STT/VRS for now? And the best per functionalities (best for Esperanto, best for noisy files, best for multiple voices, best for whatever...)\n ​\n ​\n    submitted by    /u/xqoe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gtzwm/d_asrsttvrs_ranking/",
          "publishedOn": "2023-10-26T11:07:53.000Z",
          "wordCount": 2556,
          "title": "[D] ASR/STT/VRS ranking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gtwxr/d_research_in_language_generation_for_style/",
          "author": null,
          "description": "Is research in language generation for tasks like style transfer and summarization solely constrained by prompt engineering? I've personally conducted experiments with large language models, and even the open-source language model yields impressive results, even for zero-shot inference. There was even a paper that suggested summarization is nearly obsolete. How valid is this assertion for general text generation tasks especially text style transfer?\n    submitted by    /u/1azytux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gtwxr/d_research_in_language_generation_for_style/",
          "publishedOn": "2023-10-26T11:02:40.000Z",
          "wordCount": 2598,
          "title": "[D] Research in language generation for Style Transfer, Summarization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gti3n/p_elevate_your_ml_testing_with_pytestvisual/",
          "author": null,
          "description": "I’ve developed a tool called pytest-visual, aiming to make ML code testing more efficient and meaningful. Traditional unit testing often misses visual and functional aspects of ML workflows such as data augmentation and model structures.\n pytest-visual brings a visual layer to your unit testing, allowing you to not only verify that the code runs, but the outputs also make visual sense and meet expectations. It’s integrated into pytest, automatically highlighting changes in visualization outputs, and allowing for easier/more reproducible debugging and verification.\n Quick Highlights:\n  \nStreamlines the organization of visualizations in your ML code.\n Auto-detects changes in visualization outputs.\n Enhances debugging and verification.\n  \nFor more details and to give it a try, check out the project on GitHub.\n Feedback and contributions are very welcome!\n    submitted by    /u/kongaskristjan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gti3n/p_elevate_your_ml_testing_with_pytestvisual/",
          "publishedOn": "2023-10-26T10:35:22.000Z",
          "wordCount": 2656,
          "title": "[P] Elevate Your ML Testing with pytest-visual",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17grrzb/p_torchpairwise_highly_efficient_library_for/",
          "author": null,
          "description": "https://github.com/inspiros/torchpairwise\n    submitted by    /u/IcySnowy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17grrzb/p_torchpairwise_highly_efficient_library_for/",
          "publishedOn": "2023-10-26T08:28:21.000Z",
          "wordCount": 2537,
          "title": "[P] TorchPairwise: Highly efficient library for pairwise metrics for PyTorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gqiae/r_convnets_match_vision_transformers_at_scale/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gqiae/r_convnets_match_vision_transformers_at_scale/",
          "publishedOn": "2023-10-26T06:54:23.000Z",
          "wordCount": 2544,
          "title": "[R] ConvNets Match Vision Transformers at Scale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gp1vs/d_how_to_enhance_accuracy_in_image_classification/",
          "author": null,
          "description": "I'm currently working on an image classification project using a VGG16 model. I have a dataset with 9 classes, with one class having 1000 images and the remaining classes having 180 to 250 images each.\n Here are some details:\n  \nTrain images: 2886 images (9 classes)\n Test images: 432 images (9 classes)\n Model: VGG16\n Optimizer: Adam\n Loss function: Categorical Crossentropy\n  \nlast epochs score :- loss: 309.7468 - accuracy: 0.4401 - val_loss: 14.5241 - val_accuracy: 0.4606\n how to improve the accuracy of my model\n    submitted by    /u/_Killua_04  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gp1vs/d_how_to_enhance_accuracy_in_image_classification/",
          "publishedOn": "2023-10-26T05:12:21.000Z",
          "wordCount": 2616,
          "title": "[D] How to Enhance Accuracy in Image Classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17go1zd/p_suggessions_on_miniprojects/",
          "author": null,
          "description": "Hey,I'm a 3rd year engineering student studying computer science Now I wanted to do a mini-project and have a group of 3 ready and wanted to incorporate machine learning. I am also a beginner to this field but is much interested in it. Could you guys share some light on doing the project with your past experience or done projects I have been taking inputs from various connections and would help a lot if you guys share some light on it.:)\n    submitted by    /u/Ic_zy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17go1zd/p_suggessions_on_miniprojects/",
          "publishedOn": "2023-10-26T04:10:30.000Z",
          "wordCount": 2611,
          "title": "[P] Suggessions on mini-projects",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gijpx/d_llms_playing_chess_are_sensitive_to_how_the/",
          "author": null,
          "description": "Link - https://github.com/dpaleka/llm-chess-proofgame\n TLDR; The lead up to the state of the board and not just the state of the board at inference affects predictions. \n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gijpx/d_llms_playing_chess_are_sensitive_to_how_the/",
          "publishedOn": "2023-10-25T23:30:47.000Z",
          "wordCount": 2571,
          "title": "[D] LLMs playing chess are sensitive to how the position came to be",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gibmp/d_a_script_to_preprocess_arxiv_sources/",
          "author": null,
          "description": "People train LLMs on arxiv sources, so there must be some sort of software to whip them into shape. Specifically, I'm looking for a script to join all the tex files for a paper into one. Note that it's not just a matter of substituting \\input's - sometimes it's not clear which file is the main one, so it needs to handle this too.\n    submitted by    /u/Foxtr0t  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gibmp/d_a_script_to_preprocess_arxiv_sources/",
          "publishedOn": "2023-10-25T23:21:08.000Z",
          "wordCount": 2604,
          "title": "[D] A script to pre-process arxiv sources?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ghrbz/r_humanlike_systematic_generalization_through_a/",
          "author": null,
          "description": "Work. I am not affiliated with this work or its authors.\n Article about the work.\n Twitter thread about the work from one of its authors.\n Abstract:\n  \nThe power of human language and thought arises from systematic compositionality—the algebraic ability to understand and produce novel combinations from known components. Fodor and Pylyshyn famously argued that artificial neural networks lack this capacity and are therefore not viable models of the mind. Neural networks have advanced considerably in the years since, yet the systematicity challenge persists. Here we successfully address Fodor and Pylyshyn’s challenge by providing evidence that neural networks can achieve human-like systematicity when optimized for their compositional skills. To do so, we introduce the meta-learning for compositionality (MLC) approach for guiding training through a dynamic stream of compositional tasks. To compare humans and machines, we conducted human behavioural experiments using an instruction learning paradigm. After considering seven different models, we found that, in contrast to perfectly systematic but rigid probabilistic symbolic models, and perfectly flexible but unsystematic neural networks, only MLC achieves both the systematicity and flexibility needed for human-like generalization. MLC also advances the compositional skills of machine learning systems in several systematic generalization benchmarks. Our results show how a standard neural network architecture, optimized for its compositional skills, can mimic human systematic generalization in a head-to-head comparison.\n  \n   submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ghrbz/r_humanlike_systematic_generalization_through_a/",
          "publishedOn": "2023-10-25T22:57:55.000Z",
          "wordCount": 2760,
          "title": "[R] Human-like systematic generalization through a meta-learning neural network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17geq9f/r_researchers_discover_that_incontext_learning/",
          "author": null,
          "description": "A new paper provides some insight into how in-context learning works in LLMs. This study proposes and provides evidence for an elegant structure within the in-context learning process.\n The models appear to create a \"task vector\" that encapsulates the core logic from the demonstration examples, in a way that is independent of any specific query. This vector serves as a compressed representation of the task.\n A separate component then takes this task vector and a new query as inputs to generate the output, without directly referencing the original examples.\n In essence:\n Output = Apply(query, Learn(examples))\n Where \"Learn\" derives the task vector from the examples, and \"Apply\" utilizes the vector and query to produce the output.\n The researchers validated this hypothesis by testing major public models on diverse tasks such as translation and algorithmic reasoning. Key findings:\n  \nIsolating the Learn and Apply components maintained high accuracy, demonstrating the viability of the separation.\n Task vectors clustered by task and remained consistent within tasks, indicating they encode meaningful task representations.\n Injecting another task's vector into the model caused it to override contradictory examples and follow the vector, highlighting the vector's dominance.\n Vectors induced relevant token distributions despite those terms being absent from the examples, suggesting semantic encoding of the task.\n  \nTaken together, these results provide substantial evidence that in-context learning involves creating a task vector that encapsulates the examples' logic to then guide behavior on new queries.\n While open questions remain regarding implementation details, this is a significant step towards demystifying an interesting AI capability.\n Full writeup. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17geq9f/r_researchers_discover_that_incontext_learning/",
          "publishedOn": "2023-10-25T20:50:38.000Z",
          "wordCount": 2801,
          "title": "[R] Researchers discover that in-context learning creates task vectors in LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gc7pr/d_what_is_more_important_loss_or_accuracy/",
          "author": null,
          "description": "I have created a basic classification model and there is something that I don't fully comprehend, as the loss decreases the accuracy increases (I assume this is how it should be in ideal scenarios) while this is the general trend there is a point where the loss is minimum and while accuracy at that point is high it's not the highest. Why would such a phenomenon occur? And since it occurred what is a better metric for the evaluation of the model?\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gc7pr/d_what_is_more_important_loss_or_accuracy/",
          "publishedOn": "2023-10-25T18:58:22.000Z",
          "wordCount": 2623,
          "title": "[D] What is more Important loss or accuracy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gbb9r/p_locally_hosted_audiototext_transcription_model/",
          "author": null,
          "description": "Hi,\n I'm looking for a locally hosted LLM to transcribe audio files to text. I need this for my business, but with absolute privacy (witness testimony recordings and other highly sensitive data). I figured I'd just buy a new computer which never gets connected to the internet and is dedicated only to audio processing to have absolute security. My questions are:\n - Which is the best model to use? I prefer accuracy and don't mind processing time as long as it's getting done within a few hours to even a day or two (I need to transcribe maximum 1 file per day, but up to six hours of audio), so I figured the large Whisper - probably WhisperX ? - would be my best bet. Are there comparable non-openAI models? (I need diarization)\n - What hardware should I get for this? Cost is secondary/irrelevant, although I don't want to spend 5 figures on a GPU - I can accept some processing time\n    submitted by    /u/Jealous_Pomelo_1172  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gbb9r/p_locally_hosted_audiototext_transcription_model/",
          "publishedOn": "2023-10-25T18:18:36.000Z",
          "wordCount": 2704,
          "title": "[P] Locally hosted audio-to-text transcription - model and hardware?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17gavl6/best_nlp_package_in_python_to_extract_medical/",
          "author": null,
          "description": "I am trying to extract FEV1 (forced expiratory volume) values from a dataset that contains a column with report notes from the doctor assessing the patient with pulmonary function testing. I have been able to build out a sort of solution with regexes in Python, and that's somewhat effective. But I've been instructed to code up an alternative using a more machine learning-based approach. I wanted to use spaCy to accomplish this but I'm not sure exactly how to implement the code nor if spaCy is the best package to use for this task.\n Here is my regex code that works decently. It's pretty messy and have to take into account a ton of edge cases which can get cumbersome. This is why I'd like to find a more automated solution.\n #Attempting to add in percents\n df = pd.read_excel('[mypath]/pft_tiu…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17gavl6/best_nlp_package_in_python_to_extract_medical/",
          "publishedOn": "2023-10-25T17:59:05.000Z",
          "wordCount": 3268,
          "title": "Best NLP Package in Python to extract medical test results from medical notes? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g9ec6/p_adala_an_open_source_autonomous_data_labeling/",
          "author": null,
          "description": "Hi r/MachineLearning,\n We have just open sourced Adala - a robust framework for implementing agents that specialize in advanced data processing tasks, starting with data labeling and generation.\n Agents combine knowledge outputs from LLMs and action on them in production systems, thus their reliability to correctly and consistently perform operations is critical. We saw an opportunity to create a new agent framework that could dramatically increase the efficiency of data labeling (and broader application across data processing tasks), with the unique ability to be guided by human feeback.\n To ensure agents remember and build upon their experiences, Adala provides a Memory component—a dynamic storage space for the agent's acquired knowledge. For instance, retrieving the previous experiences of an agent’s errors (and subsequent human feedback) allows them a starting point from which to branch off into learning or improving skills.\n To allow Adala to produce reliable agents, we devised two main strategies:\n  \nSupervision Integration: Provide agents with 'ground truth data'—well-defined examples that serve as a learning foundation. This foundational data not only sets the learning parameters for the agent but also defines its operational environment.\n Constrained Generation: Ensuring that an agent's predictions are within a defined and bounded range of outputs.\n  \nLet us know what you think in the comments below or by contributing to the repo.\n Adala framework overview\n ​\n    submitted by    /u/pirate7777777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g9ec6/p_adala_an_open_source_autonomous_data_labeling/",
          "publishedOn": "2023-10-25T16:54:42.000Z",
          "wordCount": 2772,
          "title": "[P] Adala – an open source Autonomous DAta (Labeling) Agent framework that helps you automate data processing and data labeling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g9855/p_pretraining_dataset/",
          "author": null,
          "description": "I'm trying to pre-train my own language model on some high quality datasets (TinyStories,tiny-textbooks...). Some of these datasets include input-output data and some are just text (stories), I was wondering how should I format the data for pre-training. Should I only use plain text like stories and webtext in pretraining then the rest in fine-tuning (adding instruction tokens) or should I just train with all of the datasets at pre-training with the special tokens where they are needed? \n    submitted by    /u/Additional-Ad-7043  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g9855/p_pretraining_dataset/",
          "publishedOn": "2023-10-25T16:47:22.000Z",
          "wordCount": 2614,
          "title": "[P] Pre-training dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g80do/research_large_languagespeech_models_and_voice/",
          "author": null,
          "description": "Hey ML folks,\n My friend is working on his academic research project where he is exploring voice research spealizing in large speech models. If you have time, help him advance his research on voice interfaces. should take 2 mins max.\n https://forms.gle/a3PaQmYEiqRDxY4Z8\n whats in it for me ? you can share email to get a copy of the research and listen what the rest of us have said.\n Thanks!\n    submitted by    /u/deep-thoughts-guy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g80do/research_large_languagespeech_models_and_voice/",
          "publishedOn": "2023-10-25T15:55:15.000Z",
          "wordCount": 2607,
          "title": "[Research] large language/speech models and voice interface research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g7qlx/r_open_source_video_enhancement_options/",
          "author": null,
          "description": "We work the disease prediction based on video classification and would like to test what improving the quality of videos would do for our models, any specific components, apps or packages we should test? So far used UpScayl, not sure how that ranks \n    submitted by    /u/sladebrigade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g7qlx/r_open_source_video_enhancement_options/",
          "publishedOn": "2023-10-25T15:43:20.000Z",
          "wordCount": 2582,
          "title": "[R] Open Source video enhancement options",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g757y/p_oss_tool_to_interactively_explore_hugging_face/",
          "author": null,
          "description": "submitted by    /u/44sps  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g757y/p_oss_tool_to_interactively_explore_hugging_face/",
          "publishedOn": "2023-10-25T15:16:47.000Z",
          "wordCount": 2545,
          "title": "[P] OSS tool to interactively explore Hugging Face datasets with one line of code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g5akw/p_training_a_transformer_from_scratch/",
          "author": null,
          "description": "Hello!\n I would like to train a transformer network from scratch, without pre-training, on a language modeling task (next work prediction) or a sequence-to-sequence task (translation).\n For the language modeling task, I tried with the Shakespeare dataset, and other simpler ones (e.g., Beatles songs), but it tends to overfit quite quickly on the training set, probably because the corpus is too short. I know that Andrej Karpathy did it with the Shakespeare dataset in his YouTube video, but he used a character-wise tokenisation, which dramatically reduces the validation loss on the next-work prediction task, given that the vocab size is tiny. I guess that at the end the generation process provides a similar quality of text as when a word tokenizer is used.\n Surprisingly, I had quite good results by training from scratch an Encoder-Decoder model, for English-to-French translation (using the 8 million examples of the Tatoeba dataset). I guess here, the overfitting is less prominent because there are more datapoints, and that the possibility of predictions are much more constrained, due to the input sequence.\n What are you guys experience with this? I would be happy to know how I can train my transformer without having to use a pre-trained architectures or spend weeks on GB datasets.\n Thank you!\n    submitted by    /u/rem_dreamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g5akw/p_training_a_transformer_from_scratch/",
          "publishedOn": "2023-10-25T13:50:43.000Z",
          "wordCount": 2748,
          "title": "[P] Training a transformer from scratch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g24t8/data_analysis_vs_ml_engineering_d/",
          "author": null,
          "description": "Do you think coursera certifications, besides a master in electrical engineering, can help us find better occupational positions? I am told that for a beginner it is better to start with jobs in Data analysis rather than going directly to ML engineering. Is it corr? Is data analysis a prerequisite for ML?\n    submitted by    /u/Street-Regular-9924  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g24t8/data_analysis_vs_ml_engineering_d/",
          "publishedOn": "2023-10-25T11:01:23.000Z",
          "wordCount": 2591,
          "title": "Data analysis vs ML engineering [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g1il0/dr_how_should_the_architecture_of_a_transformer/",
          "author": null,
          "description": "When increasing the parameters of a (decoder-only) transformer, one has a choice around how to spend that increased budget -- number of layers vs embedding dim vs number of heads. Anyone know if there's solid guidance out there for the proportions each aspect should be scaled in?\n E.g. looking at LLaMa (https://arxiv.org/abs/2302.13971), they seem to scale the first sizes two proportionally, but for larger sizes, n heads grows more slowly.\n https://preview.redd.it/ytdfk1d5rbwb1.jpg?width=1422&format=pjpg&auto=webp&s=abf22ac369ec5ecf81ff07b0d8a095f884efe729\n    submitted by    /u/Tea_Pearce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g1il0/dr_how_should_the_architecture_of_a_transformer/",
          "publishedOn": "2023-10-25T10:19:09.000Z",
          "wordCount": 2607,
          "title": "[D][R] How should the architecture of a transformer be scaled?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g0xiz/d_what_are_some_existing_datasets_for_training/",
          "author": null,
          "description": "There are a lot of great open datasets for fine-tuning LLMs for instruction following (e.g LIMA, self-instruct, dolly-15k, etc) and as chat bots (OASST, etc).\n One thing I have not really seen yet are datasets that involves planning and tool use. Is anybody working on something like that or have come across any? \n I'm interested in working on one. If anybody has ever attempted this, I would really appreciate any advice. \n P.S I do note that \"reasoning\" should be more rigorously defined and scoped, but I think some ambiguity around an intellectual discussion like this can help.\n    submitted by    /u/notllmchatbot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g0xiz/d_what_are_some_existing_datasets_for_training/",
          "publishedOn": "2023-10-25T09:35:53.000Z",
          "wordCount": 2645,
          "title": "[D] What are some existing datasets for training LLMs to perform reasoning, acting as agents?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g0i0j/d_opensource_sota_audiotoaudio_how_do_i_sound/",
          "author": null,
          "description": "Hello people, I would like to learn how to turn the recording of my voice to sound like a famous person. I imagine I would take an open source model and fine-tune it using data I will collect. Can someone point me towards the best sounding current models that I could adapt for this purpose? Thank you so much.\n    submitted by    /u/gonzales82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g0i0j/d_opensource_sota_audiotoaudio_how_do_i_sound/",
          "publishedOn": "2023-10-25T09:02:57.000Z",
          "wordCount": 2598,
          "title": "[D] Open-source SOTA Audio-to-Audio: how do I sound like a famous actor?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17g0fqe/d_guidance_needed_for_upcoming_aiml_phds_on/",
          "author": null,
          "description": "Many upcoming Ph.D. students in AI/ML are facing the difficult decision of identifying promising research topics that will stand the test of time over the time of their Ph.D. studies.\n With the rapid progress in AI, especially in the NLP field, many incremental research tasks have been effectively \"solved\". Need to choose an area where there is ample room for open-ended inquiry and meaningful contributions over 4-5 years of PhD research.\n While large language models have shown impressive advances recently, their capabilities may plateau during a Ph.D. (if starting the Ph.D. from next year ~ 4 years) timeframe. How should aspiring researchers choose topics resilient enough to withstand the test of time and allow them to push the field forward through their Ph.D. work?\n For those with experience in AI research who have seen changes in the field over time:\n  \nWhat emerging trends or broad areas do you see as fertile ground for AI/ML PhD research now and in the coming years?\n Can you highlight any intriguing subfields worthy of deeper investigation by aspiring PhD students?\n What open problems or applications warrant more attention from the upcoming generation of PhD researchers?\n  \nSome of tending Research topics so far: \n  \nLLM in a specific domain\n Prompting \n Evals \n LM interfaces \n Safety \n Understanding LMs \n Emergence\n \n Any advice on identifying PhD research topics with longevity would be greatly appreciated by aspiring graduate students.\n    submitted by    /u/aadityaura  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17g0fqe/d_guidance_needed_for_upcoming_aiml_phds_on/",
          "publishedOn": "2023-10-25T08:58:30.000Z",
          "wordCount": 2775,
          "title": "[D] Guidance needed for upcoming AI/ML PhDs on selecting research topics with lasting impact",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fzy6u/pr_testval_scores_how_much_difference_isnt/",
          "author": null,
          "description": "Hello folks, I'm working on a medical image dataset using EM loss and asymmetric pseudo labelling for single positive multi-label learning (only training using 1 positive label). I'm using a densenet121 and on a chest x-ray dataset.\n  \nI see a difference of 10% in my validation vs test score (score = mAP: mean average precision). The score seems okay and was expected but the difference is bothering me. I understand that it's obvious but any visual insights from your side? (Attaching plot below)\n The validation set consist less than half of test set samples. (It is the official split; I have nothing to do with it). I feel it is the reason, as ofcourse more the randomness in a set, poorer the convergence.\n  \n​\n https://preview.redd.it/nseqy1mw5bwb1.png?width=577&format=png&auto=webp&s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58\n Do share any experiences or suggestions!\n    submitted by    /u/ade17_in  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fzy6u/pr_testval_scores_how_much_difference_isnt/",
          "publishedOn": "2023-10-25T08:20:27.000Z",
          "wordCount": 2670,
          "title": "[P][R] Test-Val scores, how much difference isn't problematic.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fzs1c/d_are_there_method_that_can_extract_interaction/",
          "author": null,
          "description": "I want to extract interaction between persons in short text. For example, \"Sally will buy a new phone. Ted will help her.\" contains interaction between persons. However, \"Japanese Karate champion won the first prize.\" and \"Sally missed her friends, Ted and Tom\" does not contain interaction between persons.\n Is there any tools or methods that can extract interactions?\n    submitted by    /u/tkddnjs1234  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fzs1c/d_are_there_method_that_can_extract_interaction/",
          "publishedOn": "2023-10-25T08:07:40.000Z",
          "wordCount": 2603,
          "title": "[D] Are there method that can extract interaction between person in text?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fxyq0/d_who_are_some_outspoken_ai_people_who_speak/",
          "author": null,
          "description": "I'm interested in learning more about the perspectives of AI researchers and practitioners who are critical of AI ethics and regulation. \n I'm particularly interested in those who argue that AI ethics and regulation are unnecessary or harmful.\n Please note that I'm not asking for people who are simply skeptical of certain AI ethics proposals or who believe that AI ethics should be implemented in a specific way. I'm more interested in people who argue that AI ethics is a fundamentally flawed concept or that AI should not be regulated at all.\n    submitted by    /u/Periplokos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fxyq0/d_who_are_some_outspoken_ai_people_who_speak/",
          "publishedOn": "2023-10-25T05:53:40.000Z",
          "wordCount": 2638,
          "title": "[D] Who are some outspoken AI people who speak against AI ethics and regulation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fth5g/promptspecific_poisoning_attacks_on_texttoimage/",
          "author": null,
          "description": "submitted by    /u/simandl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fth5g/promptspecific_poisoning_attacks_on_texttoimage/",
          "publishedOn": "2023-10-25T01:40:36.000Z",
          "wordCount": 2539,
          "title": "Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ft45e/d_what_should_i_do_for_training_when_data_to/",
          "author": null,
          "description": "I was taught that when doing imbalance classification, the training data should be augmented to more or less match the number of classes, but the validation data should have the same distribution as the test data. And the test data should have the similar distribution as the data I will actually predict. \n But what if real data's distribution is quite random? What validation data distribution should I use? \n (I got 14 classes to classify, and 1 of classes has 52% proportion, and small ones have 0.9%, and 0.17% proportion. Practitioners who would use my model input data that only 3 classes to classify, and they can be very small proportion. The training data before augmentation was created by integrating data with this irregular distribution.) \n    submitted by    /u/poemfordumbs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ft45e/d_what_should_i_do_for_training_when_data_to/",
          "publishedOn": "2023-10-25T01:22:43.000Z",
          "wordCount": 2671,
          "title": "[D] What should I do for training when data to predict has random distribution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fqa0i/d_how_should_i_calculate_the_weights_for_a/",
          "author": null,
          "description": "I'm not sure if I worded the title correctly. Let me elaborate on the scenario.\n I have a multi-label image classification task where I'm trying to classify the gender of clothing images. The two labels that we can predict are Male and Female, hence the final logit vector's size would be something like [batch_size, 2].\n Depending on the predictions, we're mapping the following binary values to different categorical values:\n  \n[0, 0]: Unknown\n [0, 1]: Male\n [1, 0]: Female\n [1, 1]: Unisex\n  \nThe overall distribution is heavily imbalanced with Male being the minority class. I'm trying to calculate class weights to favor Male, but the problem is that the size of the weight tensors to be provided to the loss function should have a length of 2. I say this is a problem because although the number of prediction logits is 2, the actual number of classes is 4.\n I used the word \"dependent\" in my title because, for example, [1, 1] wouldn't necessarily mean that the image has the labels Male and Female, rather that it's a completely new Unisex label. Again, not sure if the usage of the word is appropriate.\n Anyway I've thought of making a custom loss function to first map the binary labels to their respective categorical values, but am wondering if there is any other way to go about this.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fqa0i/d_how_should_i_calculate_the_weights_for_a/",
          "publishedOn": "2023-10-24T23:07:42.000Z",
          "wordCount": 2775,
          "title": "[D] How should I calculate the weights for a multi-label classification task where the labels are dependent among one another?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fp0n3/d_lstm_train_val_losses_not_converging/",
          "author": null,
          "description": "I am training an LSTM model for path prediction where I'm feeding in OBT (on-board Time) and X matrix as input and Y matrix is the predecessor matrix generated using Scipy.Dijkstra\n ​\n  This is the model architecture for reference, \n This is the model architecture for reference,\n I've tried multiple iterations of this similar model, but the training and validation loss, are not converging. The best train_loss i've been able to achieve is 88k mse and 400 mse val_loss\n I've uploaded the dataset here: GitHub - mathur-exe/LSTM_Dataset\n Training Progress:\n Epoch 1/100 342/342 - 17s - loss: 22606898.0000 - val_loss: 61414736.0000 - 17s/epoch - 49ms/step Epoch 2/100 342/342 - 14s - loss: 7990657.0000 - val_loss: 3699703.5000 - 14s/epoch - 40ms/step Epoch 3/100 342/342 - 13s - loss: 4130298.7500 - val_loss: 136808.1094 - 13s/epoch - 38ms/step Epoch 4/100 342/342 - 12s - loss: 2747299.2500 - val_loss: 35710.1680 - 12s/epoch - 35ms/step Epoch 5/100 342/342 - 12s - loss: 2558378.2500 - val_loss: 3383.4780 - 12s/epoch - 36ms/step Epoch 6/100 342/342 - 13s - loss: 1214455.8750 - val_loss: 111625.2891 - 13s/epoch - 37ms/step Epoch 7/100 342/342 - 19s - loss: 337480.2500 - val_loss: 68686.6094 - 19s/epoch - 55ms/step Epoch 8/100 342/342 - 15s - loss: 316366.7188 - val_loss: 2059.3557 - 15s/epoch - 44ms/step Epoch 9/100 342/342 - 20s - loss: 293117.0312 - val_loss: 20961.5469 - 20s/epoch - 58ms/step Epoch 10/100 342/342 - 17s - loss: 575945.1875 - val_loss: 503602.8438 - 17s/epoch - 50ms/step Epoch 11/100 342/342 - 13s - loss: 290962.8750 - val_loss: 62491.9375 - 13s/epoch - 37ms/step Epoch 12/100 342/342 - 12s - loss: 1125042.5000 - val_loss: 36054.6836 - 12s/epoch - 36ms/step Epoch 13/100\n ...\n 342/342 - 16s - loss: 230900.7969 - val_loss: 48309.6094 - 16s/epoch - 47ms/step Epoch 93/100 342/342 - 23s - loss: 232846.6094 - val_loss: 82926.6875 - 23s/epoch - 67ms/step\n    submitted by    /u/Gaurang_Mathur_ftw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fp0n3/d_lstm_train_val_losses_not_converging/",
          "publishedOn": "2023-10-24T22:12:20.000Z",
          "wordCount": 2841,
          "title": "[D] LSTM: Train & Val losses not converging",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fmgbq/d_will_chatgpt_remove_the_need_for_data_annotation/",
          "author": null,
          "description": "I wrote a blog post about this detailing my experience, which I will attach at the bottom but I want to hear opinions of people. It is something I've actively been thinking about, and would like to know potential pitfalls and why it may not work, rather than the huge promise it holds. \n https://ozanciga.wordpress.com/2023/10/24/will-chatgpt-remove-the-need-for-data-annotation/\n    submitted by    /u/ozanciga  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fmgbq/d_will_chatgpt_remove_the_need_for_data_annotation/",
          "publishedOn": "2023-10-24T20:27:20.000Z",
          "wordCount": 2599,
          "title": "[D] Will ChatGPT remove the need for data annotation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fmdkl/r_monarch_mixer_a_simple_subquadratic_gemmbased/",
          "author": null,
          "description": "submitted by    /u/hzj5790  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fmdkl/r_monarch_mixer_a_simple_subquadratic_gemmbased/",
          "publishedOn": "2023-10-24T20:24:02.000Z",
          "wordCount": 2555,
          "title": "[R] Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fm22g/d_is_it_better_to_create_a_different_set_of/",
          "author": null,
          "description": "I'm using Top2Vec with Doc2Vec embeddings to find topics in a dataset of ~4000 social media posts. This dataset has three groups:\n  \nPosts from a company (3%)\n Posts from this company's potential customers (82.5%)\n Posts from this company's competitors (14%)\n  \nThe purpose of this analysis is to look at the topics the company is posting about on social media and see how it compares to the things that their customers and competitors are posting about.\n Since the values of Doc2Vec embeddings depend on the other documents in the dataset, I'm worried that topics in smaller groups are going to be drowned out by the larger group. I'm worried that the differences between the document vectors in the smaller group are going to be made smaller by presence of the documents from the larger group, which may represent a much wider array of different topics.\n    submitted by    /u/abelEngineer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fm22g/d_is_it_better_to_create_a_different_set_of/",
          "publishedOn": "2023-10-24T20:10:52.000Z",
          "wordCount": 2706,
          "title": "[D] Is it better to create a different set of Doc2Vec embeddings for each group in my dataset, rather than generating embeddings for the entire dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17flxbr/d_how_would_you_do_it_handling_multiturn_qa/",
          "author": null,
          "description": "I have been giving this some thought and would appreciate some outside input, maybe someone has some experience they could share!\n I am attempting to create a QA chatbot that is limited to answering questions from a pre-determined set of question and answer pairs I have in a vector database. Currently I create embeddings of the question using OpenAI and query a vector database for similar \"reference question\" - if the similarity score is high enough I proceed and use the answer text I have stored in the metdata as \"context\" for the answer generation.\n I would now like to extend this to include conversational history. The issue I am facing however, is that a follow-on question may not hit the similarity threshold. Considering a follow-up question would typically not be worded in a way that …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17flxbr/d_how_would_you_do_it_handling_multiturn_qa/",
          "publishedOn": "2023-10-24T20:04:59.000Z",
          "wordCount": 3011,
          "title": "[D] How would you do it? Handling multi-turn QA conversation with matching of questions to vector database.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fl96h/p_the_ml_practitioner_a_publication_about_all/",
          "author": null,
          "description": "Hi all, my wife and I have recently started a new publication called The ML Practioner. \n If you're interested in writing for us, please send us a link of your unpublished draft here.\n Either way, please subscribe to us if you're interested in this kind of content! \n    submitted by    /u/kanxx030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fl96h/p_the_ml_practitioner_a_publication_about_all/",
          "publishedOn": "2023-10-24T19:36:30.000Z",
          "wordCount": 2596,
          "title": "[P] The ML Practitioner, a publication about all things machine learning and MLOps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fkztq/d_efficacy_of_cold_start_preferences_on_recs/",
          "author": null,
          "description": "Hi all,\n Are there good papers about the efficacy of cold start explicit preference collection (think Netflix “pick some movies you like”) on the recs systems? I haven’t been able to find any so far. One key aspect I’m looking for is if these are effective, how long they are relative to just implicit actions the user takes.\n Thanks\n    submitted by    /u/steathilynecessary  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fkztq/d_efficacy_of_cold_start_preferences_on_recs/",
          "publishedOn": "2023-10-24T19:25:33.000Z",
          "wordCount": 2604,
          "title": "[D] efficacy of cold start preferences on recs systems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fkj1g/d_embedding_models_ranked_by_encode_speed/",
          "author": null,
          "description": "Hello, the sbert.net has a list where you can sort by encode speed but its a very small subset of the HuggingFace MTEB leaderboard.\n AFAICT, the HuggingFace leaderboard / model pages don't have this information. \n Is there a list where I can see a more up-to-date list of models by encoding speed?\n    submitted by    /u/rsamrat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fkj1g/d_embedding_models_ranked_by_encode_speed/",
          "publishedOn": "2023-10-24T19:05:35.000Z",
          "wordCount": 2595,
          "title": "[D] Embedding models ranked by encode speed?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fk3yi/d_finite_state_transducers_and_language/",
          "author": null,
          "description": "In the context of NLP, will language models based on finite state transducers (since they are finite) ultimately fail to put language's productive nature to good use?\n All the possible outputs a finite state transducer can produce are predictable, while all the possible outputs a given natural language can produce are much less predictable? \n    submitted by    /u/RecordingOk5720  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fk3yi/d_finite_state_transducers_and_language/",
          "publishedOn": "2023-10-24T18:47:44.000Z",
          "wordCount": 2597,
          "title": "[D] Finite State Transducers and language productivity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fjibc/p_equinox_kv_cache/",
          "author": null,
          "description": "I've been trying to implement a kv cache in my language model but have been unsuccessful so far due to the dynamic shapes. I've seen some implementations in flax but was wondering if it was possible to implement in equinox as that's what I'm using and prefer over others like flax. If anyone can point me in the right direction or help with the implementation that would be great! PS: I can provide any code if wanted to help\n    submitted by    /u/Additional-Ad-7043  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fjibc/p_equinox_kv_cache/",
          "publishedOn": "2023-10-24T18:22:12.000Z",
          "wordCount": 2619,
          "title": "[P] Equinox KV Cache",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fj3uh/explainable_boosting_machine_local_and_global/",
          "author": null,
          "description": "I am using EBM for a research, the local and global explanation plots it produces come with preset font size, I want to change the resolution of the figure and the font size of labels and x and y ticks in the explanation plots.\n I have looked for it on the InterpretML github page and issues and scrolled through various webpages but haven't found anything helpful. Used gpt but it doesnot help either, it tries to use matplotlib but EBM plots are not compatible with it.\n Please share any way it can be solved, because the plots labels are unreadable in the article if used as it is.\n    submitted by    /u/Horseman099  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fj3uh/explainable_boosting_machine_local_and_global/",
          "publishedOn": "2023-10-24T18:05:26.000Z",
          "wordCount": 2655,
          "title": "Explainable Boosting Machine Local and Global Explanation plots label size [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fh37k/dp_what_is_the_metric_for_early_stopping_in/",
          "author": null,
          "description": "I am trying to fine tune the yolov8 detection model an was going through the code base of ultralytics.I found this piece of code in the engine.trainer\n # Early Stopping if RANK != -1: # if DDP training broadcast_list = [self.stop if RANK == 0 else None] dist.broadcast_object_list(broadcast_list, 0) # broadcast 'stop' to all ranks if RANK != 0: self.stop = broadcast_list[0] if self.stop: break # must break all DDP ranks \n I'm familiar with how the early stopping works and not sure what they are doing here\n does this get invoked by default?? what is the metric that they use in order to stop it??\n upon further inspection i found this\n self.stopper, self.stop = EarlyStopping(patience=self.args.patience), False \n which is imported as\n from ultralytics.utils.torch_utils import (EarlyStopping, ModelEMA, de_parallel, init_seeds, one_cycle, select_device, strip_optimizer) \n please help me find out what metric they use to stop this and if the earlystopping is invoked by default\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fh37k/dp_what_is_the_metric_for_early_stopping_in/",
          "publishedOn": "2023-10-24T16:38:08.000Z",
          "wordCount": 2691,
          "title": "[D][P] What is the metric for early stopping in YOLOv8 detection?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17feh7j/p_the_n_implementation_details_of_rlhf_with_ppo/",
          "author": null,
          "description": "We are happy to share a great repro of OpenAI's early RLHF codebase, with nearly identical learning curves. We also summarized implementation details (did you know Adam Optim's implementation details could impact RLHF?)\n  \n📜 Blog post:https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo\n 💾 Code: https://github.com/vwxyzjn/lm-human-preference-details\n  \n   submitted by    /u/vwxyzjn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17feh7j/p_the_n_implementation_details_of_rlhf_with_ppo/",
          "publishedOn": "2023-10-24T14:44:01.000Z",
          "wordCount": 2584,
          "title": "[P] The N Implementation Details of RLHF with PPO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fe3l6/ml_project_p/",
          "author": null,
          "description": "What are best ways to collect database for any ml project\n    submitted by    /u/GingSkywalker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fe3l6/ml_project_p/",
          "publishedOn": "2023-10-24T14:26:31.000Z",
          "wordCount": 2544,
          "title": "ML [project] [p]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fdcns/r_feature_space_reduction_method_for/",
          "author": null,
          "description": "We are excited to announce the publication of our groundbreaking scientific paper in Machine Learning: Science and Technology titled “Feature Space Reduction Method for Ultrahigh-Dimensional, Multiclass Data: Random Forest-Based Multiround Screening (RFMS)” by Gergely Hanczar, Marcell Stippinger, David Hanak, Marcell T Kurbucz, Oliver M Torteli, Agnes Chripko, and Zoltan Somogyvari.\n Published on: 19 October 2023 DOI: 10.1088/2632-2153/ad020e Volume 4, Number 4\n In recent years, several screening methods have been published for ultrahigh-dimensional data that contain hundreds of thousands of features, many of which are irrelevant or redundant. However, most of these methods cannot handle data with thousands of classes. Prediction models built to authenticate users based on multichannel biometric data result in this type of problem. In this study, we present a novel method known as random forest-based multiround screening (RFMS) that can be effectively applied under such circumstances. The proposed algorithm divides the feature space into small subsets and executes a series of partial model builds. These partial models are used to implement tournament-based sorting and the selection of features based on their importance. This algorithm successfully filters irrelevant features and discovers binary and higher-order feature interactions. To benchmark RFMS, a synthetic biometric feature space generator known as BiometricBlender is employed. Based on the results, the RFMS is on par with industry-standard feature screening methods while possessing many advantages.\n r/IAMA - Oct 26 with the founders of Cursor Insight.\n https://bit.ly/AMAwithCursorInsight-GoogleCalendar\n ​\n  R/IAMA - Oct 26 with the founders of Cursor Insight.\n    submitted by    /u/CursorInsight  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fdcns/r_feature_space_reduction_method_for/",
          "publishedOn": "2023-10-24T13:52:44.000Z",
          "wordCount": 2787,
          "title": "[R] Feature Space Reduction Method for Ultrahigh-Dimensional, Multiclass Data: RFMS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fcupf/n_new_letter_from_yoshua_bengio_geoffrey_hinton/",
          "author": null,
          "description": "Signatories include Turing Award winners Yoshua Bengio, Geoffrey Hinton, as well as others academics and experts. \n  \nIn 2019, GPT-2 could not reliably count to ten. Only four years later, deep learning systems can write software, generate photorealistic scenes on demand, advise on intellectual topics, and combine language and image processing to steer robots. As AI developers scale these systems, unforeseen abilities and behaviors emerge spontaneously without explicit programming1. Progress in AI has been swift and, to many, surprising.\n The pace of progress may surprise us again. Current deep learning systems still lack important capabilities and we do not know how long it will take to develop them. However, companies are engaged in a race to create generalist AI systems that match or ex…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fcupf/n_new_letter_from_yoshua_bengio_geoffrey_hinton/",
          "publishedOn": "2023-10-24T13:29:26.000Z",
          "wordCount": 2995,
          "title": "[N] New letter from Yoshua Bengio, Geoffrey Hinton, and others: Managing AI Risks in an Era of Rapid Progress",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fbmsx/d_generative_food/",
          "author": null,
          "description": "Hey guys, I sometimes post about tiny ML projects we work on. This time, we talk about applying language models for generating recipe titles/ideas. Specifically, we don't use LLMs, and this turns out to be a bit of a controversial decision, but one that has it's own advantages.\n Quite interested in the community's take on it: https://engineering.hellofresh.com/recipes-and-generative-ai-6d74a107860c\n    submitted by    /u/abnormdist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fbmsx/d_generative_food/",
          "publishedOn": "2023-10-24T12:30:01.000Z",
          "wordCount": 2590,
          "title": "[D] Generative Food",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fbhlg/r_tokenizer_choice_for_llm_training_negligible_or/",
          "author": null,
          "description": "📷Research\n https://arxiv.org/abs/2310.08754\n While the recent success of LLMs has been driven primarily by curation of training dataset composition, scaling of model architectures and dataset sizes, and advances in pretraining features, the impact of tokenizers has often lagged as a blind spot. Our researcher*s study sheds light on this issue and shows that tokenizer choice can significantly impact downstream model performance as well as training and inference costs.\n 1️⃣ Investigation of intrinsic tokenizer performance, i.e., study of tokenizer properties (i.e., generated vocabulary), and tokenization results of tokenizers.\n 2️⃣ Investigate the extrinsic performance of the tokenizer, i.e., the impact of the tokenizer on the downstream performance of the model.\n 3️⃣ Investigation of possible correlation between intrinsic and extrinsic tokenizer performance.\n ​\n 💡 The investigation shows that the common tokenizer evaluation metrics \"fertility\" and \"parity\" do not always predict the performance of the downstream model, making these metrics a questionable criterion for tokenizer evaluation.\n 💡 Moreover, the study shows that multilingual tokenizers - which are based on the five most common European languages - require a vocabulary size by a factor of three compared to English. The previous approach of training tokenizers with English vocabulary only thus turns out to be inefficient and results in a strong performance degradation and additional training costs of up to 68%\n    submitted by    /u/effi28_ml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fbhlg/r_tokenizer_choice_for_llm_training_negligible_or/",
          "publishedOn": "2023-10-24T12:22:15.000Z",
          "wordCount": 2758,
          "title": "[R] Tokenizer Choice For LLM Training: Negligible or Crucial?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fahnw/r_using_machine_learning_to_drive_portfolio_asset/",
          "author": null,
          "description": "I'd love to hear your guys thoughts on next steps to improve this, maybe deeper layers and more nodes, maybe a random forest is more appropriate? I'd love to hear any thoughts on Machine Learning directly applicable to time-series data.\n https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model\n The Main Idea\n We will develop a Machine Learning model, specifically a deep learning model (more hidden layers to come), to periodically, tactically rebalance the weights of our portfolio based on observable market data and empirically determined statistics combined with feature engineering from the past 21 trading days, and for the VIX we consider its characteristics since inception.\n The output will be a range representing the degree to which we bet long, short, or hold cash, and 3 weights that sum to less than or equal to one and greater than or equal to negative one. In essence we will allow shorting of securities and not require our portfolio to be fully invested. Cash is an active position; sometimes the best investment is staying on the sidelines.\n The model will allow one input layer, one and two hidden layers (to show that more might not always be better, explicitly with the 200 variable maximum excel solver imposes on us), and an output layer with 3 nodes outputting a value between -1 and +1 with -1 representing a full allocation to a short position in the security and +1 representing a fully allocated long position.\n    submitted by    /u/QFA_official  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fahnw/r_using_machine_learning_to_drive_portfolio_asset/",
          "publishedOn": "2023-10-24T11:25:50.000Z",
          "wordCount": 2780,
          "title": "[R] Using Machine Learning to Drive Portfolio Asset Allocations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17fahm6/d_are_people_in_ml_phds_still_happy/",
          "author": null,
          "description": "As an outsider who has many friends in ML Phds, this is my perspective of their lives:\n  \nlong hours, working nights, weekends\n no work-life balance, constant fear of being scooped and time pressure from deadlines\n frustrating broken review systems\n many incremental, advertisement papers that produce very little actual contribution (which is justified by 2.)\n \"engineering\" and not \"science\"\n all this pressure amounts to severe imposter syndrome\n  \nAre people in the field still happy? Where do people get their satisfaction? To me it looks like almost like a religion or a cult. The select few who say, get neurips outstanding paper are promoted to stardom - almost a celebrity status while everyone else suffers a punishing work cycle. Are the phd students all banking on AGI? What else motivates them?\n Edit: the discussion is about whether 1-6 are worse in ML than other fields (or even the median experience). The reference for \"other field\" is highly heterogenous. Experience obviously varies by lab, and then even by individuals within labs. \"It happens in other fields too\" is a trivial statement - of course some version of 1-6 affects somebody in another field.\n Edit 2: small n but summarizing the comments - experience seems to differ based on geographic region, one's expectations for the phd, ability to exert work-life balance, and to some extent ignore the trends others are all following. Some people have resonated with problems 1-6, yet others have presented their own, anecdotal solutions. I recommend reading comments from those who claim to have solutions.\n    submitted by    /u/shenkev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17fahm6/d_are_people_in_ml_phds_still_happy/",
          "publishedOn": "2023-10-24T11:25:46.000Z",
          "wordCount": 2798,
          "title": "[D] Are people in ML Phds still happy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17f9q81/p_a_pdf_tool_that_supports_three_retrieval/",
          "author": null,
          "description": "➡️ Check on https://huggingface.co/spaces/xuyingliKepler/VecDBCompare\n 📌 Introduction: VecDBCompare is a streamlit-based application designed to evaluate and compare three different vector database retrieval strategies. Users only need to upload a PDF and interact with QABots using three different strategies to determine which strategy is most suitable for them. \n ⭐️ Three retrieval strategies: \n  \nChunk Strategy: Divides the document into small chunks and retrieves based on the most relevant chunks.\n Summary Strategy: Summarizes the document and retrieves based on the summary content. \n Hypothetical Question Strategy: Generates hypothetical questions that the document might answer and retrieves based on these questions.\n  \n   submitted by    /u/xuying_li  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17f9q81/p_a_pdf_tool_that_supports_three_retrieval/",
          "publishedOn": "2023-10-24T10:38:59.000Z",
          "wordCount": null,
          "title": "[P] A PDF tool that supports three retrieval strategies, allowing users to choose the answer that suits them best",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17f8k14/d_p_3d_design_file_labelling_and_classification/",
          "author": null,
          "description": "I have ~1 million 3D design (.STP and/or .OBJ) files of various parts for medical devices, aerospace, automotive or defense systems. I'd like to label them based on appropriate manufacturing methods that are used to physically make them. Some example methods and labels would be milling, turning, injection molding, cnc machining, etc. After labelling, I'd like to architect a system to produce these labels as inference for a new part that has not been physically made yet.\n My team (<5 people) have manufacturing domain expertise and can manually label these parts but I'm looking for a more scalable solution that isn't as time consuming. Crowd sourced methods like Mechanical Turk won't work because annotators do not have the domain knowledge to mark the correct label. Labelling platforms like SageMaker/Azure ML Studio only allow image/text/audio datasets, is there a platform that'll help me setup labelling tasks for 3D designs? Furthermore, how can I find more experts that can help scale this up? It seems to me that the only option is to build my own labelling app as an annotator needs these key features -\n  \n3D model visualizer so they can spin the part and view any orientation\n Draw a bounding box (commonly available in other platforms)\n Toggle measurements in inches/mm\n  \nAs for label classification I'm looking at architectures like PointNet since my dataset of meshes can be sampled to point clouds. Are there other methods that would work better or worth exploring? Open to any and all suggestions across this pipeline.\n ​\n ​\n    submitted by    /u/rootcage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17f8k14/d_p_3d_design_file_labelling_and_classification/",
          "publishedOn": "2023-10-24T09:15:12.000Z",
          "wordCount": 2797,
          "title": "[D] [P] 3D Design file labelling and classification for manufacturing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17f0q1v/d_undergrad_seeking_advice_on_ethicsml_research/",
          "author": null,
          "description": "I’m an undergraduate who’s considering a PhD student in ML. I’m currently in a lab that focuses on ethics in AI. While I love the work, it focuses on the humanities side of CS. I’ve always been a more mathy person and have always been interested in theoretical ML research. I’d like to combine ethics & AI/ML in some way (eg studying explainable AI from the technical perspective). I was wondering what are some research areas that combine the two and if I don’t work in academia, what’s the market and job prospects like for someone who does this?\n    submitted by    /u/SnooChipmunks1902  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17f0q1v/d_undergrad_seeking_advice_on_ethicsml_research/",
          "publishedOn": "2023-10-24T01:17:27.000Z",
          "wordCount": 2642,
          "title": "[D] Undergrad seeking advice on ethics/ML research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eytfr/p_traffic_signs_in_ecognition_developer/",
          "author": null,
          "description": "Hi community, first time posting here.\n I'm working on a project for the segmentation and classification of traffic signs using eCognition Developer software. I need help with creating scripts to apply three classifiers: Naive Bayes, SVM, and Random Forest.\n I'd like to know how I can implement these classifiers in eCognition Developer and where to insert the scripts in the software. Does anyone have experience with this software and could share script examples or provide guidance on how to accomplish this task?\n Sorry English is not my first language.\n Tldr, i need to include the Bayes classifiers, Random Tree, and SVM in eCognition Developer (for segmentation and classification - prediction).\n    submitted by    /u/Dignai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eytfr/p_traffic_signs_in_ecognition_developer/",
          "publishedOn": "2023-10-23T23:46:25.000Z",
          "wordCount": 2636,
          "title": "[P] Traffic signs in ecognition developer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17exk17/p_using_gpt4docstrings_to_generate_docstrings_for/",
          "author": null,
          "description": "gpt4docstrings is a Python library that allows you to write docstrings for functions / classes non documented in your codebase. In this case, I'm applying the library to one module of langchain to see the results.\n Repo: https://github.com/MichaelisTrofficus/gpt4docstrings\n https://i.redd.it/78f3wit071wb1.gif\n    submitted by    /u/Hefty-Consequence443  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17exk17/p_using_gpt4docstrings_to_generate_docstrings_for/",
          "publishedOn": "2023-10-23T22:48:45.000Z",
          "wordCount": 2573,
          "title": "[P] Using gpt4docstrings to generate docstrings for entire projects",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ewpiu/p_dqn_with_a_binary_vector_as_output/",
          "author": null,
          "description": "Heey everyone!\n I hope you're doing well.\n I need your help guys.\n I'm working on a DQN that outputs a binary vector of length L (I just applied sigmoid function on the ouptut layer and take p>0.5 as 1 and 0 otherwise). In this setting, at each decision time, the agent returns a list containing the indices of selected elements. Knowing that the list's length is dynamic how can I train my DQN ? (I am facing issues in this). Is there any alternative way to do this purpose (like DDPG :/ )?\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ewpiu/p_dqn_with_a_binary_vector_as_output/",
          "publishedOn": "2023-10-23T22:12:20.000Z",
          "wordCount": 2627,
          "title": "[P] DQN with a binary vector as output",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ewbpv/project_looking_for_aiml_engineers_to_team_up_for/",
          "author": null,
          "description": "Hi,\n first of all, sorry for the cross post, but I guess Huggingface forums were not the right place to begin with and it took me a while to find out where things about AI/ML are being actively discussed.\n I am a professional software developer (C, Python on Linux) and while I did try out a few things with PyTorch and Diffusers - I am not an ML engineer, so I am looking for someone with ML expertise who’d be interested to team up for a non commercial open source project. I can do quite a lot around application development, but I clearly lack the required ML knowledge. I followed the free MIT ML courses on YouTube, did some reading, tried things out, but the ML part of this project is for sure over my head.\n So, here’s what I have in mind: I would like to create an application which would b…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ewbpv/project_looking_for_aiml_engineers_to_team_up_for/",
          "publishedOn": "2023-10-23T21:56:00.000Z",
          "wordCount": 3273,
          "title": "[Project] Looking for AI/ML engineers to team up for a fallow deer identification project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eveyg/d_using_sql_to_monitor_ml_models/",
          "author": null,
          "description": "Hello,\n We are running a number of machine learning models in production and would like to monitor some metrics during inference: Data quality, inference time, accuracy, etc.\n All these metrics could be recorded in the python code and we are planning to build a SQL database that will receive all the information so as we can visualize in grafana.\n Do you think this is a good pattern? What would you suggest instead (we are using AWS).\n Thank you in advance.\n    submitted by    /u/Eddas123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eveyg/d_using_sql_to_monitor_ml_models/",
          "publishedOn": "2023-10-23T21:17:41.000Z",
          "wordCount": 2613,
          "title": "[D] Using SQL to monitor ML models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eup3m/rp_trying_to_understand_the_generative_properties/",
          "author": null,
          "description": "A while back, I came across the \"From Variational to Deterministic Autoencoders\", which provided a novel insight into the generative properties of autoencoders by framing the objective through the lens of regularization. However, I couldn't help but notice that the deterministic models studied felt incomplete, namely due to the inherent lack of sampling in those models (which is something that the authors acknowledge).\n To provide a short recap of the paper, the authors surgically decompose the variational autoencoder objective into a deterministic one. They start with a Constant-Variance VAE, which is a special case of the general Gaussian latent VAE where the noise standard deviation of the latent distribution is fixed to 1. This leads to what is essentially a standard autoencoder with t…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eup3m/rp_trying_to_understand_the_generative_properties/",
          "publishedOn": "2023-10-23T20:48:27.000Z",
          "wordCount": 3040,
          "title": "[R][P] Trying to understand the generative properties of autoencoders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17etn6g/d_what_is_the_lowest_possible_loss_for_a_language/",
          "author": null,
          "description": "Example: Suppose a character-level language model (three input letters to predict the next one), trained on a dataset that contains three instances of the sequence aei, with two occurrences preceding o and one preceding u, i.e., the dataset is:\n  \n Input Output \n  \n aei o \n  aei u \n  aei o \n \n In this case, the ideal probability distribution for the model's logits for aei would be ~0.66 for o, ~0.33 for u, and zero for other letters. In other words, when the model is input with aei, the ideal softmax of the logits would be ~0.66 for o, ~0.33 for u, and zero for other letters.\n Following this reasoning, the objective is to optimize the model's output for a given input to match the distribution of occurrences in the dataset.\n If this reasoning is correct, then we have the following ideal loss (cross-entropy):\n https://preview.redd.it/pzpxogcqd0wb1.png?width=330&format=png&auto=webp&s=b0b6c3b5fbfb4797c11a1f26375065ce883551d3\n Thus, ~0.63 is the smallest loss we can get with this dataset.\n Is my reasoning correct?\n    submitted by    /u/viniciusarruda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17etn6g/d_what_is_the_lowest_possible_loss_for_a_language/",
          "publishedOn": "2023-10-23T20:04:47.000Z",
          "wordCount": 2692,
          "title": "[D] What is the lowest possible loss for a language model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17etc1r/d_tanh_activation_function_outputs_the_same_value/",
          "author": null,
          "description": "Basically im working on the DDPG algorithm in DRL where i have an actor and critic networks.\n The actor network architecture is quite simple:\n  \nInput layer contains 22 neurons that represents the state values (ranging from 0.1 to 10.0 max not normalizing them)\n Two hidden layers with 128 neurons, with Leaky Relu activation (alpha = 0.01), and with HeUniform kernel initialzer\n Output layer with a single neuron has tanh activation, using Glorot kernel initialzer\n  \nThe critic network has the same architecture but we only concatenate the 22 state values with the action produced by the actor, the only difference is the ouput of the critic has no activation. And both networks use Adam.\n The problem arises when the training starts because i run a few steps without actually start the learning, but when the learning starts, the actor converges quickly to output values 1 or -1 afor any given input. I tried many learning rates for both actor and critic. One thing to note is when i set the actor learning rate to 1e-5 and the critic to 1e-3 the networks sometimes converges quickly, some time it takes longer to converge and sometimes it does not converge.\n    submitted by    /u/Desert_champion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17etc1r/d_tanh_activation_function_outputs_the_same_value/",
          "publishedOn": "2023-10-23T19:51:35.000Z",
          "wordCount": null,
          "title": "[D] Tanh activation function outputs the same value for any given input",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17et76c/p_finetuning_vaes_on_limited_data/",
          "author": null,
          "description": "I have been looking for a pre-trained VAE (on Imagenet with ResNet/VGG) or similar which I could fine-tune on my smaller dataset. However, not only there does not exist many such pre-trained weights but the practice of fine-tuning VAEs does not really seem mainstream.\n Is there a reason why VAEs are not pre-trained/fine-tuned? Does it have to do with posterior collapse?\n    submitted by    /u/unholy_sanchit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17et76c/p_finetuning_vaes_on_limited_data/",
          "publishedOn": "2023-10-23T19:45:38.000Z",
          "wordCount": 2593,
          "title": "[P] Fine-tuning VAEs on limited data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17esnol/d_smart_pooling_for_visual_transformers/",
          "author": null,
          "description": "There is an architecture for images/videos called MViT, where 2D MaxPooling layers are added to reduce computations for ViT. But MaxPooling has a drawback - it discards information independently of context, equally discarding information from both important and uninformative parts of the image. For traditional Conv2D networks, there's little we can do about this, but for transformers, we can reduce dimensionality in a more meaningful way - discarding only those elements that don't carry unique information. Are there any articles/developments on this topic already?\n    submitted by    /u/Dependent_Bluejay_45  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17esnol/d_smart_pooling_for_visual_transformers/",
          "publishedOn": "2023-10-23T19:22:28.000Z",
          "wordCount": 2616,
          "title": "[D] Smart pooling for Visual Transformers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17esei3/research_rvc_ai_training/",
          "author": null,
          "description": "Hello, I'm currently using RVC AI, and I'm about to record myself for the training. What is the best way to record myself except the singing and talking at least for 15 minutes like the guide says. Do I have to make it 20 min and one audio file or do I have to make it 20 min and maybe 10 files with 2 minutes each file? Also, can I multiply my files and reach the 15-20 minutes of audio that it's required or I have to make a different talking or singing for every audio?\n    submitted by    /u/WeldFrenzy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17esei3/research_rvc_ai_training/",
          "publishedOn": "2023-10-23T19:12:09.000Z",
          "wordCount": 2626,
          "title": "\"[Research]\" RVC AI Training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17erule/d_rag_oriented_finetune_searching_for_coherence/",
          "author": null,
          "description": "Still searching for a model that is well enough to make RAG... Lots of good models on huggingface, but none of them is trained to return extracted text or answers based on provided info without hallucinating something.\n Is quite frustrating, every week came a new version of a model that is amazing for Role play and storytelling... (some good progress also on coding...) I see lots of efforts in different RAG strategy, improving semantic search and Chunking, but the open source community still does not have a decent model fine tuned for that.\n I have considered the idea of make that fine tune, based on synthetic data (using Wikipedia as knowledge base), but unfortunately I have not enough funds to cover the api cost neighter to pay for some decent Gpu. I'm not going to train a 7B Model because the under 30B imho doesn't have many sense if the coherence is the main requirements.\n Unpopular opinion: as coherence, code llama 34B is much better to any of the 70B fine tune.\n Sorry to everyone for the rant... Does anyone have some tips or suggestions? \n Thanks in advance!\n Edit:\n My database is composed mainly by abstracts of papers and medical textbook. I admit that the domain is quite complex, but the error rate is too high. \n Obviously that even if prompted to avoid that (tried and refined multiple prompts, using different prompt format). \n Gpt3.5, Claude instant and Palm2-Bizon work fine for that task. (obviously GPT4 and Claude 2 would be best, but too expensive for me) \n I spent lots of time to make a solid embedding pipeline:\n  \nadvanced chunking, \n \nMetadata added by llm, text for similarity search different from text provided to LLM, \n \ninstructor bi encoder to generate embeddings(INSTRUCTOR-XL), \n \nreranking using cross encoder, \n \nRAG-Fusion using multiple query and HyDE approach\n \nHybrid search with BM25\n \n So... I'm a bit frustrated that i can not run all locally, became that is a must for my project.\n    submitted by    /u/Distinct-Target7503  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17erule/d_rag_oriented_finetune_searching_for_coherence/",
          "publishedOn": "2023-10-23T18:49:19.000Z",
          "wordCount": 2857,
          "title": "[D] RAG oriented fine-tune... Searching for coherence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ergjb/r_2x_the_context_length_of_alibi_through_position/",
          "author": null,
          "description": "https://arxiv.org/abs/2310.13017#\n Linear position interpolation helps pre-trained models using rotary position embeddings (RoPE) to extrapolate to longer sequence lengths. We propose using linear position interpolation to extend the extrapolation range of models using Attention with Linear Biases (ALiBi). We find position interpolation significantly improves extrapolation capability on upstream language modelling and downstream summarization and retrieval tasks.\n    submitted by    /u/jwan584  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ergjb/r_2x_the_context_length_of_alibi_through_position/",
          "publishedOn": "2023-10-23T18:32:28.000Z",
          "wordCount": 2591,
          "title": "[R] 2x the context length of ALiBi through position interpolation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eqh9u/d_how_to_make_research_publication_more/",
          "author": null,
          "description": "As context, I'm personally working on a project to make ML/AI research publication more reproducible. We're backed by Balaji Srinivasan (https://twitter.com/balajis) at the level of funding and advice.\n It seems like, despite attempts like Jupyter Notebooks or sites like Papers with Code, most published research in ML still isn't setup to be easily reproducible. Even companies like Anthropic/OpenAI don't put much of an emphasis on reproducibility, even though it's in their interest to do so to earn public trust.\n Our current hypothesis is to conceptualize reproducible research as software testing. Specifically we're thinking of building tools that let you internally test the robustness of results, and externally publish them s.t. they're reproducible.\n You can think of it as continuous integration for reproducible research; e.g. BuildBot for Reproducible Research.\n One specific idea I have is to build a model evaluation/testing platform that lets you:\n  \nInternally eval LLM models on open benchmarks (TruthfulQA, AGIEval, etc.)\n Test robustness of results under different assumptions\n Externally publish reproducible results\n  \nI don't have a background in ML research. So I'm looking to get input from research engineers on what challenges/barriers currently exist with model testing and publishing reproducibly — so I thought I'd reach out in this community if anyone's open to that!\n Let me know if this post doesn't conform to the rules, or if this should go somewhere else.\n    submitted by    /u/manveerbasra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eqh9u/d_how_to_make_research_publication_more/",
          "publishedOn": "2023-10-23T17:50:53.000Z",
          "wordCount": 2759,
          "title": "[D] How to make research publication more reproducible?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eq6q4/p_image_captioning_model/",
          "author": null,
          "description": "Hello everyone,\n I am currently trying to find suitable image captioning and visual question answering models to implement in my project. After a quick google search I came across BLIP2 from hugging face however, its a very large model overall and both my pc and colab could never load its lightest pretrained version. Does anyone know any similar pretrained models for the specific tasks or any other way to load this kind of large model? (I tried loading it with 8bit precision which still failed)\n I have 16gb of RAM and the task requires image captioning and the ability to ask the model details about the specific image.\n Any help is greatly appreciated!! \n    submitted by    /u/Spitefulsalamander  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eq6q4/p_image_captioning_model/",
          "publishedOn": "2023-10-23T17:37:50.000Z",
          "wordCount": 2640,
          "title": "[P] Image Captioning Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17epva7/d_episodic_training_vs_random_subsampling_in/",
          "author": null,
          "description": "I'm new to few-shot learning and I'm having trouble understanding why prototypical networks use a random sub-sampling approach while the vanilla few-shot learning approach uses episodic training. Doesn't random sub-sampling fail to guarantee that data overlapping won't occur?\n    submitted by    /u/The_Aoki_Taki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17epva7/d_episodic_training_vs_random_subsampling_in/",
          "publishedOn": "2023-10-23T17:23:50.000Z",
          "wordCount": 2573,
          "title": "[D] Episodic Training vs. Random Sub-Sampling in Few-Shot Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17epolm/d_hightemperature_softmax/",
          "author": null,
          "description": "I implemented a label propagation algorithm which is mainly used in the field of Video Object Segmentation (VOS). Basically I provide the labels for one frame and ask my model (using pre-trained encodings of frames) to do semantic segmentation on all the other frames of a video. \n I am obtaining consistently better results using an high temperature softmax when computing the similarity between pixels of different frames. Then the top-k similarities of each pixel (features) are used to propagate the labels from one frame to the next.\n I will not disclose the dataset I am using but let's say it is noisy (let's say also low quality). I want to understand why an high-temperature softmax performs better than a softmax with T=1 or an extreme T = 0.01. At the moment I get better results with T = 10, 100 and the trend in my grid search shows that even higher T could be possible. I was wondering if the model is still considerable valid if T is too high. I feel like the model is almost randomly guessing, if T is too high, but this apparently enhances performance.\n Every help is appreciated. Also literature about the topic! I only found one paper (which uses an high-temperature softmax to distill knowledge in a student-teacher network for remote sensing imagery) \n    submitted by    /u/darthjeio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17epolm/d_hightemperature_softmax/",
          "publishedOn": "2023-10-23T17:16:39.000Z",
          "wordCount": 2748,
          "title": "[D] High-temperature softmax",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17em1cl/d_callbacks_in_tensorflow_v1/",
          "author": null,
          "description": "Hi everyone, I have some old code written in tf1. It has not been ported to tf2 or pytorch yet. Does anyone of you have leads on whether one can implement custom callback for tf1 code and if there are any examples on the web? Thanks in advance.\n    submitted by    /u/wrik003  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17em1cl/d_callbacks_in_tensorflow_v1/",
          "publishedOn": "2023-10-23T14:43:16.000Z",
          "wordCount": 2579,
          "title": "[D] Callbacks in tensorflow v1",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ejtly/n_capivara_costefficient_approach_for_improving/",
          "author": null,
          "description": "In the tech report of GPT4, an analysis was conducted on the impact of different languages on model performance. These effects are attributed to the amount of data and language characteristics. This also indicates that the model's effectiveness may not meet the expectations of users in different languages. The problem addressed in this paper is of significant importance.\n https://preview.redd.it/s48419fe9yvb1.jpg?width=2748&format=pjpg&auto=webp&s=ba76f1bd18043c6cb2610ed90f5c41a78b5ccd95\n Arxiv: https://arxiv.org/abs/2310.13683v1\n Stay updated with AI in a fun-to-listen way. Check out ai-dailynews.com to generate your personalized news podcast🎙. It's one of my open-source projects and takes no charge.\n    submitted by    /u/xuying_li  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ejtly/n_capivara_costefficient_approach_for_improving/",
          "publishedOn": "2023-10-23T13:00:31.000Z",
          "wordCount": 2625,
          "title": "[N] CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP Performance on Low-Resource Languages",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ejp7r/n_neuralbase_music_generation_for_intelligence/",
          "author": null,
          "description": "The paper employs a deep learning system to learn from the great composer Beethoven and capture his composition ability in a hash-based knowledge base. This new form of knowledge base provides a reasoning facility to drive the music composition through a novel music generation method.\n https://preview.redd.it/l9gzcoe38yvb1.png?width=1944&format=png&auto=webp&s=d6c5ca7f8fe434be1187c1f0440c5a94ebfc9b64\n Arxiv: https://arxiv.org/abs/2310.13691v1\n For more AI updates, check out this AI-generated news podcast🎙 tailored to your preferences(ai-dailynews.com), which is open source and free.\n    submitted by    /u/xuying_li  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ejp7r/n_neuralbase_music_generation_for_intelligence/",
          "publishedOn": "2023-10-23T12:54:17.000Z",
          "wordCount": 2594,
          "title": "[N] Neural-Base Music Generation for Intelligence Duplication",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ej0pd/d_biclustering_with_the_same_row_and_column/",
          "author": null,
          "description": "The biclustering algorithm partitions rows and columns of a matrix into clusters so that the variance inside each intersection between row and column clusters in minimized.\n I want to perform the biclustering of a matrix, but additionally to enforce that the row and column clusters are the same, i.e. if the row i lies inside a row-cluster c then the column i must lie in a column-cluster c.\n Rows and columns in the matrix represent the same entities (but the matrix is non-simmetric).\n sklearn implementation does not support such a constraint.\n Are there any algorithms for this at all?\n    submitted by    /u/Tomarchelone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ej0pd/d_biclustering_with_the_same_row_and_column/",
          "publishedOn": "2023-10-23T12:19:08.000Z",
          "wordCount": 2634,
          "title": "[D] Biclustering with the same row and column clusters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ego7c/d_referenceless_nlp_evaluation/",
          "author": null,
          "description": "Hey all, I'm building this open source project that helps ML engineers evaluate LLM applications (its like unit testing for LLMs), and it works great in development since users can just write a test_file.py like how you would normally do it in pytest, but as I'm going onto the next phase I'm thinking how to bring evaluation to production, especially on metrics such as factual consistency where I need a ground truth. I'm hoping to get some ideas around this. \n Here's a link to the repo (https://github.com/confident-ai/deepeval) if you want more clarity on what the package looks like, but most importantly any help to brainstorm production evaluation will be greatly appreciated. Thank you very very much!\n    submitted by    /u/Ok_Constant_9886  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ego7c/d_referenceless_nlp_evaluation/",
          "publishedOn": "2023-10-23T09:55:02.000Z",
          "wordCount": 2646,
          "title": "[D] Referenceless NLP Evaluation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17eak3w/d_is_computer_vision_dead_quo_vadis_computer/",
          "author": null,
          "description": "In ICCV23, several top notch researchers shared their insights (in a workshop called “Quo Vadis, Computer Vision?”) wrt the current state of Computer Vision, especially in light of the meteoric raise of LLMs. Has CV stalled? Is CV dead?\n E.g.MIT’s professor Bill Freeman, has some interesting points on foundation models: “FM aren’t fundamental, therefore not stable\". Jitendra Malik argues \"video can describe the world better than text.\"\n    submitted by    /u/btcmx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17eak3w/d_is_computer_vision_dead_quo_vadis_computer/",
          "publishedOn": "2023-10-23T02:58:47.000Z",
          "wordCount": 2603,
          "title": "[D] Is Computer Vision dead? - “Quo Vadis, Computer Vision?”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ea25h/r_biologically_plausible_vision_models_for/",
          "author": null,
          "description": "Hey everyone! I am looking for papers that propose or explore biologically plausible vision models, primarily tasks like classification and grasping (predicting grasping bounding boxes) tasks. By biologically plausible, I mean papers that propose models inspired by the human brain in some way or the other. I know convolution is loosely inspired by human cognition, but everything I can find seems to suggest the opposite for ViT like models.\n I have come across certain papers like these: - https://arxiv.org/abs/1901.00945 - https://proceedings.neurips.cc/paper/2020/hash/98b17f068d5d9b7668e19fb8ae470841-Abstract.html\n But I am still looking for more. Any suggestions?\n    submitted by    /u/Far_Clothes_5054  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ea25h/r_biologically_plausible_vision_models_for/",
          "publishedOn": "2023-10-23T02:31:39.000Z",
          "wordCount": 2624,
          "title": "[R] Biologically plausible vision models for classification and grasping tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e9a24/d_understanding_the_math_behind_diffusion_models/",
          "author": null,
          "description": "I was trying to comprehend the math behind this paper: https://arxiv.org/pdf/2006.11239.pdf. You can see in the equation corresponding to the forward diffusion process, at each time step, the image in the previous step is also scaled by sqrt(1-beta_t) while adding noise. It seems like the purpose of this is to maintain a fixed variance (or specifically, unit variance) at each time step. My question is: What is the significance of maintaining unit variance at each time step? Why is this useful? I saw somewhere that this is done to prevent the variance from \"exploding.\" I don't really know what this means. I guess the variance keeps on increasing if the scaling isn't done. But why is this bad?\n    submitted by    /u/fallendeviL701b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e9a24/d_understanding_the_math_behind_diffusion_models/",
          "publishedOn": "2023-10-23T01:51:36.000Z",
          "wordCount": 2645,
          "title": "[D] Understanding the math behind diffusion models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e7kac/d_neural_attention_one_simple_example_that/",
          "author": null,
          "description": "submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e7kac/d_neural_attention_one_simple_example_that/",
          "publishedOn": "2023-10-23T00:23:38.000Z",
          "wordCount": 2550,
          "title": "[D] Neural Attention - One simple example that explains everything you need to know",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e79a6/d_has_anyone_tried_deploying_fastapi_v2_with_a/",
          "author": null,
          "description": "I'm not sure how to enable BERT with flash attention during the start-up of the Triton server in order to accelerate inference.\n Dao(the author of FA) told me he’s never tried.\n    submitted by    /u/g14loops  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e79a6/d_has_anyone_tried_deploying_fastapi_v2_with_a/",
          "publishedOn": "2023-10-23T00:08:23.000Z",
          "wordCount": 2586,
          "title": "[D] Has anyone tried deploying FastAPI v2 with a BERT model on the NVIDIA Triton Inference Server?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e69f4/p_having_gpt4_iterate_on_unit_tests_like_a_human/",
          "author": null,
          "description": "Hi r/MachineLearning, \n My name is William and I’m one of the founders of Sweep.\n Sweep is an AI junior developer that writes and fixes code by mirroring how a developer works.\n While building Sweep, we used to use the Github API, but we ran into rate limits, so we changed this to clone your repository for the duration of the request.\n It's now coming full circle. Sweep can now write, run, and debug a failing unit test for the ClonedRepo class!\n Blog: https://docs.sweep.dev/blogs/ai-unit-tests\n Video: https://www.youtube.com/watch?v=N9PUxmja9z4\n    submitted by    /u/williamsweep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e69f4/p_having_gpt4_iterate_on_unit_tests_like_a_human/",
          "publishedOn": "2023-10-22T23:19:21.000Z",
          "wordCount": 2632,
          "title": "[P] Having GPT-4 Iterate on Unit Tests like a Human",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e59k3/d_structured_learning_resources_for_ml_theory/",
          "author": null,
          "description": "So essentially what the title says. I want to truly understand whats happening behind Machine Learning in general and also behind each algorithm specifically (starting from the basics to more advanced things, like Logistic Regression, Decisions trees and random forests, Deep Learning, NLP, GANS...). \n By structured I mean it contains all the pieces ordered and organized, from the same source, so you can can actually go from the building blocks up, not just a YouTune channel that uploads interesting videos about different machine learning related topics.\n Regarding the medium, I don't really mind but I would prefer audiovisual content (YT channel/playlists, Lectures, conferences...) but if you really recommend a specific book or series of books that's also okay.\n If it has some practical focus to it (to better grasp the theory) that would great. Also, I would prefer if it goes deep into the details, but not too deep into the specific maths involved, but if it's the case thats also okay. \n Regarding price, obviously if it's free that would be awesome, but in the range of free to 40€ is fine.\n Thank you for your recommendations in advance!!\n    submitted by    /u/aleradamantis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e59k3/d_structured_learning_resources_for_ml_theory/",
          "publishedOn": "2023-10-22T22:31:41.000Z",
          "wordCount": 2734,
          "title": "[D] Structured learning resources for ML Theory",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e3fjq/url_phishing_or_benign_using_deep_learning/",
          "author": null,
          "description": "Guys does anyone have an idea why my model does not work and it's like 50-50 chance to get it right. I'm getting really frustrated. Here is the code so far:\n ​\n import pandas as pd import torch import torch.nn as nn import torch.optim as optim from torch.utils.data import Dataset, DataLoader from collections import Counter from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score import re from imblearn.under_sampling import RandomUnderSampler # Loading the data file_path = \"C:/Users/alex/Desktop/DATASET/malicious_phish.csv\" data = pd.read_csv(file_path) # Filtering data filtered_data = data[data['type'].isin(['phishing', 'benign'])] # Undersampling the majority class rus = RandomUnderSampler(rand…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e3fjq/url_phishing_or_benign_using_deep_learning/",
          "publishedOn": "2023-10-22T21:11:28.000Z",
          "wordCount": 3643,
          "title": "URL PHISHING OR BENIGN USING DEEP LEARNING \"[Research]\", \"[R]\", \"[Project]\", \"[P]\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17e1vxj/d_pretraining_a_4bit_model_not_finetunning/",
          "author": null,
          "description": "Pre-Training using 4bit (NOT fine-tunning)\n Hello community!\n I have been messing around with open source LLM's running them locally using peft and AutoGPTQ in Transformers. I even trained a few QLora models (my favorite part)\n However my question is this, given the performance of a 4bit model why hasn't there been any research in this area? Is it possible to even create a new model using 4bit altogether? I am sure it's not as easy as it sounds but I haven't seen anyone try. Just curious cause it will open doors for many of us with consumer grade hardware. \n Thanks!\n    submitted by    /u/Delicious-Farmer-234  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17e1vxj/d_pretraining_a_4bit_model_not_finetunning/",
          "publishedOn": "2023-10-22T20:02:36.000Z",
          "wordCount": 2646,
          "title": "[D] - Pre-Training a 4bit model (NOT Fine-tunning)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dzira/p_infinity_a_foss_project_for_supporting_rag_for/",
          "author": null,
          "description": "https://github.com/michaelfeil/infinity\n Infinity, a open source REST API for serving vector embeddings, using a torch / ctranslate2 backend. Its under MIT License, fully tested and available under GitHub.\n I am the main author, curious to get your feedback.\n FYI: Huggingface launched a couple of days after me a similar project (\"text-embeddings-inference\"), under a non open-source and non-commercial license. \n    submitted by    /u/OrganicMesh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dzira/p_infinity_a_foss_project_for_supporting_rag_for/",
          "publishedOn": "2023-10-22T18:15:13.000Z",
          "wordCount": 2605,
          "title": "[P] Infinity, a FOSS project for supporting RAG for LLMs and Vector Embeddings.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dyh5o/r_combining_thermodynamics_and_diffusion_models/",
          "author": null,
          "description": "Researchers from Yonsei University and UC Berkeley recently developed a new AI method for enabling autonomous robots to navigate unfamiliar environments filled with obstacles using only visual data as input.\n The key innovation is a customized diffusion model. Diffusion models can generate diverse motion plans by adding controlled noise. The researchers tailored the model to mimic how heat avoids insulation when dispersing through space. \n Similar to heat navigating around insulators, this \"collision-avoiding\" diffusion model learns to predict robot motions that avoid collisions with obstacles. It generates reachable goals and viable motion plans to those goals simultaneously.\n In simulations, this approach achieved ~98% success rates in navigating to target destinations while avoiding randomly generated obstacles using only visual map images as input.\n While extensive real-world testing is still needed (only 2D, only simulation), these initial results showcase promising capabilities:\n  \nEnables navigation in unfamiliar environments without pre-mapping.\n Flexibly identifies and progresses toward reachable goals.\n Avoids unnecessary sensing systems for obstacle avoidance.\n Learns complex collision avoidance heuristics from visual data.\n  \nI like the thermo + AI + robotics combination here - takes me back to my days in aerospace engineering. Pretty interesting approach.\n Full summary is here. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dyh5o/r_combining_thermodynamics_and_diffusion_models/",
          "publishedOn": "2023-10-22T17:28:44.000Z",
          "wordCount": 2745,
          "title": "[R] Combining Thermodynamics and Diffusion Models for Collision-Free Robot Motion Planning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dy5m3/r_speeding_up_open_source_llms_with_speculative/",
          "author": null,
          "description": "submitted by    /u/firef1y1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dy5m3/r_speeding_up_open_source_llms_with_speculative/",
          "publishedOn": "2023-10-22T17:14:06.000Z",
          "wordCount": 2558,
          "title": "[R] Speeding up open source LLMs with speculative decoding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dvv12/p_open_source_ai_repos_that_caught_my_this_week/",
          "author": null,
          "description": "@MetaGPT_ github.com/geekan/MetaGPT - multi agent collaboration - MetaGPT encodes Standard Operating Procedures (SOPs) into prompts. The claim is that it takes a one line requirement as input and outputs user stories / competitive analysis / requirements / data structures / APIs / documents, etc.\n @Ollama_ai github.com/jmorganca/olla… - run large language models locally. The future of AI/LLMs may not be on the cloud, but on your own laptops/mobiles. ollama.ai/blog/building-…\n @huggingface github.com/huggingface/ca… - slick ML framework for Rust with a focus on performance (including GPU support)\n @remilouf github.com/outlines-dev/o… - helps developers guide text generation to build robust interfaces with external systems. Provides generation methods that guarantee that the output will match a regular expressions, or follow a JSON schema.\n github.com/YiVal/YiVal enterprise AI platform\n    submitted by    /u/oana77oo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dvv12/p_open_source_ai_repos_that_caught_my_this_week/",
          "publishedOn": "2023-10-22T15:29:38.000Z",
          "wordCount": 2683,
          "title": "[P] Open Source AI repos that caught my 👀 this week",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dv7m3/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dv7m3/d_simple_questions_thread/",
          "publishedOn": "2023-10-22T15:00:28.000Z",
          "wordCount": 2591,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dtsoi/d_teachers_struggle_to_adapt_amid_ai_revolution/",
          "author": null,
          "description": "submitted by    /u/DutchTechJunkie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dtsoi/d_teachers_struggle_to_adapt_amid_ai_revolution/",
          "publishedOn": "2023-10-22T13:53:24.000Z",
          "wordCount": 2559,
          "title": "[D] Teachers struggle to adapt amid AI revolution in education",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dtd2q/r_language_interaction_to_assist_in_composing_and/",
          "author": null,
          "description": "Hey guys, I found an interesting paper recently. Universities in the UK introduced Loop Copilot, enabling users to generate and iteratively refine music through an interactive, multi-round dialogue interface.\n Using language interaction to assist in composing music is very appealing, AI makes a complex workflow easy and automated.\n https://preview.redd.it/nzvlgevcarvb1.jpg?width=998&format=pjpg&auto=webp&s=815e0f48c299831700215ebdb4257423e317f5ec\n    submitted by    /u/xuying_li  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dtd2q/r_language_interaction_to_assist_in_composing_and/",
          "publishedOn": "2023-10-22T13:31:31.000Z",
          "wordCount": 2596,
          "title": "[R] Language interaction to assist in composing and refining music",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17drtnu/d_how_to_account_for_extreme_periods_in_time/",
          "author": null,
          "description": "I am performing a (machine learning) time series forecast on monthly data from the last 20 years. If I separate my data into a train, validation, and test set, the validation set is almost completely filled with extreme values due to the Covid period. How to account for this? \n    submitted by    /u/Ambitious-Pay6329  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17drtnu/d_how_to_account_for_extreme_periods_in_time/",
          "publishedOn": "2023-10-22T12:09:19.000Z",
          "wordCount": 2598,
          "title": "[D] How to account for extreme periods in time series forecasting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17drrqt/p_graphing_emotion_events_with_lms_for_indepth/",
          "author": null,
          "description": "submitted by    /u/helliun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17drrqt/p_graphing_emotion_events_with_lms_for_indepth/",
          "publishedOn": "2023-10-22T12:06:00.000Z",
          "wordCount": 2546,
          "title": "[P] Graphing emotion events with LMs for in-depth sentiment analysis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dr1us/d_dinov2_breakdown_ive_created_a_visual_guide_to/",
          "author": null,
          "description": "submitted by    /u/CkmCpvis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dr1us/d_dinov2_breakdown_ive_created_a_visual_guide_to/",
          "publishedOn": "2023-10-22T11:20:26.000Z",
          "wordCount": 2553,
          "title": "[D] DINOv2 Breakdown: I've Created a Visual Guide to the Model's Design & a Concise Code Walkthrough",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dplxw/r_do_you_read_mldlai_related_scientific_papers/",
          "author": null,
          "description": "As the title says. Recently, I found a review paper where the authors showed an exponential growth of published papers related to ML or DL. I was wondering if you even read those. If yes what's your way to find good and reliable papers? Do you choose only ones with a significant number of citations? Or just strictly related to your field? If no, why not? \n https://preview.redd.it/jwjvej5f5qvb1.jpg?width=1080&format=pjpg&auto=webp&s=bf3f7e08e0fe09fe0c6a6fd8d194945b45f5858e\n    submitted by    /u/hahahaczyk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dplxw/r_do_you_read_mldlai_related_scientific_papers/",
          "publishedOn": "2023-10-22T09:40:37.000Z",
          "wordCount": 2617,
          "title": "[R] Do you read ML/DL/AI related scientific papers? How do you filter them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dpcpu/r_opensource_projects_on_detecting_landmines/",
          "author": null,
          "description": "I know that there are a lot of efforts at the moment to improve the algorithms used for landmine detection.\n Is anyone aware of any ongoing open-source projects in this space?\n    submitted by    /u/Eightstream  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dpcpu/r_opensource_projects_on_detecting_landmines/",
          "publishedOn": "2023-10-22T09:21:43.000Z",
          "wordCount": 2575,
          "title": "[R] Open-Source Projects on Detecting Landmines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dp96m/r_demo_of_flowlenia_towards_openended_evolution/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dp96m/r_demo_of_flowlenia_towards_openended_evolution/",
          "publishedOn": "2023-10-22T09:14:51.000Z",
          "wordCount": 2558,
          "title": "[R] Demo of “Flow-Lenia: Towards open-ended evolution in cellular automata through mass conservation and parameter localization” (link to paper in the comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dofue/german_researchers_create_deepmb_for_faster/",
          "author": null,
          "description": "Researchers from Germany have developed DeepMB, a groundbreaking deep-learning framework enabling high-quality and real-time optoacoustic imaging via multispectral optoacoustic tomography (MSOT). With potentially transformative implications for health care, this innovation might redefine medical imaging standards.\n To stay ahead of developments in AI, look here first.\n DeepMB breakthrough\n  \nDeepMB resolves the longstanding tradeoff between image quality and speed in medical imaging.\n The deep-learning framework uses a deep neural network for model-based reconstruction, allowing for fast, high-quality imaging.\n DeepMB can reconstruct images approximately 1000 times faster than conventional techniques, with virtually no loss in image quality.\n  \nImpressive metrics and implications\n  \nThe researchers accomplished accurate optoacoustic image reconstruction in just 31 milliseconds per image by training the system to pairingly synthesize optoacoustic signals with ground-truth images.\n DeepMB promises to equip clinicians with immediate access to high-quality MSOT images, regardless of the patient's condition or scanned body area.\n The technology could extend to other imaging modalities, such as ultrasound, x-ray, and MRI, potentially changing how diseases are diagnosed and treated.\n  \nExciting prospects\n  \nThe development of DeepMB is a significant leap in optoacoustic imaging, promising to enhance healthcare outcomes.\n As DeepMB evolves, it could become integral to modern medical imaging, delivering high-quality results at previously unattainable speeds.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that unpacks the most significant news and research in AI. Google, Meta, and OpenAI professionals are already subscribed\n    submitted by    /u/orthomax23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dofue/german_researchers_create_deepmb_for_faster/",
          "publishedOn": "2023-10-22T08:14:08.000Z",
          "wordCount": 2782,
          "title": "German researchers create DeepMB for faster, high-quality optoacoustic imaging [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dnwte/d_forecastnet_neural_pdes_perform_global_weather/",
          "author": null,
          "description": "submitted by    /u/moschles  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dnwte/d_forecastnet_neural_pdes_perform_global_weather/",
          "publishedOn": "2023-10-22T07:36:20.000Z",
          "wordCount": 2568,
          "title": "[D] ForeCastNet. Neural PDEs perform global weather simulation 4 to 5 orders of magnitude faster than traditional numerical methods.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17djn1u/data_labeling_service_for_keypoints_pose_d/",
          "author": null,
          "description": "I was previously using scale.ai but they have been extraordinarily slow. Does anyone have recommendations for services to label keypoints or pose? \n Bonus points if the labeling service is able to handle 3D / multi angle data coming from multiple cameras. \n I work in an academic lab and scale is <10k images per batch.\n    submitted by    /u/researchrig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17djn1u/data_labeling_service_for_keypoints_pose_d/",
          "publishedOn": "2023-10-22T03:01:25.000Z",
          "wordCount": 2594,
          "title": "Data labeling service for keypoints / pose [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dgtsr/d_need_help_with_texttosong_diffusion_model/",
          "author": null,
          "description": "Hey, I want to make a text-to-song diff model, but I can't figure out the architecture\n I have already prepared a dataset of about 5000 songs of different genres, artists. It only contains the lyrics, the genre and the song itself\n Do I understand correctly that I should just encode the text and genre into one vector using CLIP and hope that the model will directly follow it (not skipping words and lines), or should I somehow make timestamps in the dataset (when, where and what text is sung)?\n I was inspired by Chirp V1\n    submitted by    /u/Head-Selection-9785  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dgtsr/d_need_help_with_texttosong_diffusion_model/",
          "publishedOn": "2023-10-22T00:32:16.000Z",
          "wordCount": 2641,
          "title": "[D] Need help with text-to-song diffusion model architecture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17db7m3/d_prml_reading_buddy/",
          "author": null,
          "description": "Hey there mates,\n I am a 3rd year PhD student, trying to break into good quality research (tired of trying different permutations ans combinations of X and Ys, and hitting dead end when things don't work, or worse -- being unable to explain why things work :D).\n I have recently decided to read PRML cover to cover (slowly) and do some of the exercises as well. Goal is to finish in 6 months (2 chapters per month). \n Is there anyone on a similar journey, would love to tag along and discuss nuances?\n    submitted by    /u/Zealousideal_Yak9131  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17db7m3/d_prml_reading_buddy/",
          "publishedOn": "2023-10-21T20:08:53.000Z",
          "wordCount": 2634,
          "title": "[D] PRML reading buddy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17db5af/d_what_do_you_all_think_of_these_pearls_of_wisdom/",
          "author": null,
          "description": "About the latest Jason Wei’s tweet.\n    submitted by    /u/mildlyphd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17db5af/d_what_do_you_all_think_of_these_pearls_of_wisdom/",
          "publishedOn": "2023-10-21T20:05:54.000Z",
          "wordCount": 2559,
          "title": "[D] What do you all think of these pearls of wisdom on “Doing Great Research”?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17dad67/d_which_is_the_best_physics_engine_for/",
          "author": null,
          "description": "What are some of the best physics engine that we should be using to implement physics for complex reinforcement related tasks(like humanoid motions) ?? I came across mujoco, physx , pybullet, issac etc but not sure which to go with. Isaac seems to be something very interesting but the minimun requirements as per the website is 32gb of RAM which is way to much for me (I use a 8gb one). mujoco is good but the docs are very confusing and hard to get through.\n what do you believe is the best choice to go with??\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17dad67/d_which_is_the_best_physics_engine_for/",
          "publishedOn": "2023-10-21T19:29:15.000Z",
          "wordCount": 2644,
          "title": "[D] Which is the best physics engine for reinforcement learning??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d9sdk/d_ensemble_of_strong_vs_weak_predictors/",
          "author": null,
          "description": "This crossed my mind recently and after searching online I couldn't find a concrete answer: would an ensemble composed of strong predictors (let's say training on 1 model of that type had a high metric performance) perform better than an ensemble composed of weak predictors?\n Bonus: are there any resources that would support your position you can link below?\n    submitted by    /u/robml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d9sdk/d_ensemble_of_strong_vs_weak_predictors/",
          "publishedOn": "2023-10-21T19:02:30.000Z",
          "wordCount": 2604,
          "title": "[D] Ensemble of Strong vs Weak Predictors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d8lrb/r_decoupling_features_and_classes_with/",
          "author": null,
          "description": "submitted by    /u/4rtemi5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d8lrb/r_decoupling_features_and_classes_with/",
          "publishedOn": "2023-10-21T18:08:42.000Z",
          "wordCount": 2558,
          "title": "[R] Decoupling Features and Classes with Self-Organizing Class Embeddings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d77b3/p_d_hierarchical_agent_learns_all_possible/",
          "author": null,
          "description": "Here's my implementation of an idea I had many years ago: a Sensorimotor Inference Engine. A machine that explores the states space of an environment, learning how to traverse the state space, learning how to manipulate the environment, which when given a goal can manipulate the environment in accordance to the goal.\n In other words, it's an agent which learns not one policy, but all possible policies. Doing so, I believe requires a hierarchy: layers of the same structure which learn broader and broader contexts of the environment.\n I have recently attempted to design an extremely simple, and modularized version of this agent: The Encoder-Predictor-Actor circuit.\n I need feedback, do you think it would work? if it might work, how might I train the Actor model? I think I know how to train the Encoder and Predictor models, but the Actor model will be harder to train, so if you have any ideas I'd love to hear from you!\n ps. sorry for the typos in the image text.\n a first-pass diagram of the 'simplest' implementation of a sensorimotor inference engine: the encoder-predictor-actor circuit\n    submitted by    /u/Stack3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d77b3/p_d_hierarchical_agent_learns_all_possible/",
          "publishedOn": "2023-10-21T17:04:27.000Z",
          "wordCount": 2733,
          "title": "[P] [D] Hierarchical agent learns all possible policies. Would this implementation work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d6xk9/career_suggestions_d/",
          "author": null,
          "description": "Hi there,\n I need some suggestions from you experts. I am an aerospace engineer (both BSc and MSc), with a university minor in AI. It's pretty clear to me that I should have studied computer science given my passion for this world. In the last 4 years I worked as engineer in a major aerospace company, and I managed to get back on track with computer science and ML by working as a data scientist and doing ML projects applied to space, while also practicing with LLM agents. My dream is to enter the AGI world, maybe working as an \"AI engineer\", or working on creating true \"autonomous\" systems, leveraging multi-modal models maybe. What do you suggest I should focus on to reach this goal? Getting first some \"credit\" as an ML engineer though courses and certifications, open source projects, or maybe applying right now to some startups in the field?\n Thanks guys!\n    submitted by    /u/cappellino1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d6xk9/career_suggestions_d/",
          "publishedOn": "2023-10-21T16:52:00.000Z",
          "wordCount": 2694,
          "title": "Career suggestions [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d6dw2/arxiv_dives_generating_speech_from_text_with_fast/",
          "author": null,
          "description": "We’ve been diving deep into Arxiv Papers as a team on Fridays, hope it’s helpful and feel free to join live if you like the format!\n    submitted by    /u/FallMindless3563  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d6dw2/arxiv_dives_generating_speech_from_text_with_fast/",
          "publishedOn": "2023-10-21T16:26:52.000Z",
          "wordCount": 2587,
          "title": "A[r]xiv Dives - Generating Speech from Text with Fast Speech-2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d66j7/r_eureka_humanlevel_reward_design_via_coding/",
          "author": null,
          "description": "submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d66j7/r_eureka_humanlevel_reward_design_via_coding/",
          "publishedOn": "2023-10-21T16:17:47.000Z",
          "wordCount": 2548,
          "title": "[R] Eureka: Human-Level Reward Design via Coding Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d5r40/computer_vision_project_ideas_project/",
          "author": null,
          "description": "I am taking the computer vision course at my university. We have to do a final project but I am unable to come up with concrete ideas.\n These are the options:\n • Select a paper from the computer vision literature, implement and test the approach described in that paper\n • Take publicly available code, apply it to an interesting novel dataset and explore various extensions and modifications. You may also want to compare two or more systems. Running existing code on the data provided by the authors is not sufficient.\n • Design and implement a solution to a problem that interests you. This may earn you extra credits.\n Can anyone please help with what to do?\n    submitted by    /u/kxenak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d5r40/computer_vision_project_ideas_project/",
          "publishedOn": "2023-10-21T15:59:06.000Z",
          "wordCount": 2659,
          "title": "Computer Vision Project Ideas [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d40et/d_can_you_use_a_different_dataset_to_run_ablation/",
          "author": null,
          "description": "I am on a computer vision algorithm and I will be benchmarking my method on the MS COCO dataset, like the other methods that have been proposed for the same problem.\n I want to know if I can use a smaller dataset (COCO minitrain) for my ablation experiments to demonstrate the efficacy of the different components used in my algorithm and to save time and cost, or will that be a red flag to journal reviewers?\n    submitted by    /u/notEVOLVED  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d40et/d_can_you_use_a_different_dataset_to_run_ablation/",
          "publishedOn": "2023-10-21T14:38:08.000Z",
          "wordCount": 2625,
          "title": "[D] Can you use a different dataset to run ablation experiments?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d3s76/searching_pinecone_for_relative_date_information_r/",
          "author": null,
          "description": "I am embedding with gpt and upserting large medical reports into pinecone and then would like to query for chronological result. For example, I upload a report that consists of 10 office visits. I would like to know the date and results of the first visit and then the last visit. when I embed a query containing: How did the patient describe their pain in the last office visit in the text? pinecone doesn't understand the context of 'last' since it is just doing cosine likeness. It pulls pain information but doesn't have a clue which comes first. Any help would be greatly appreciated. \n    submitted by    /u/Silent_Case_3058  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d3s76/searching_pinecone_for_relative_date_information_r/",
          "publishedOn": "2023-10-21T14:27:09.000Z",
          "wordCount": 2649,
          "title": "Searching pinecone for relative date information [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d2olz/p_wizard101_autobuyer_scriptbot_using_ocr_opencv/",
          "author": null,
          "description": "submitted by    /u/HistorianCrafty3514  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d2olz/p_wizard101_autobuyer_scriptbot_using_ocr_opencv/",
          "publishedOn": "2023-10-21T13:33:27.000Z",
          "wordCount": 2549,
          "title": "[P] Wizard101 Auto-Buyer Script/Bot - Using OCR, OpenCV Python with multiprocessor performance improvements",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d237n/p_d_rag_on_multilevel_tabular_data/",
          "author": null,
          "description": "Hi, Has anyone done RAG on a multi level tabular data? If yes then what problems have you faced and how did you solve those? My model gives better answers when I converted the data to a JSON and then embedded it. But I'm looking for a better approach.\n    submitted by    /u/Euphoric-Chart1428  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d237n/p_d_rag_on_multilevel_tabular_data/",
          "publishedOn": "2023-10-21T13:02:48.000Z",
          "wordCount": 2595,
          "title": "[P] [D] : RAG on multilevel tabular data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d1pdx/d_is_megabytes_padding_the_same_as_streamingllm/",
          "author": null,
          "description": "I was wondering after reading the recent streamingLLM paper https://arxiv.org/pdf/2309.17453.pdf if the attention sink they use through pre-training and inference is analogous to the learnable padding used in the MEGABYTE architecture https://arxiv.org/pdf/2305.07185.pdf although used for a different purpose? So if I just used MEGABYTE with sliding window attention at inference would it be the same as streamingLLM?\n    submitted by    /u/Additional-Ad-7043  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d1pdx/d_is_megabytes_padding_the_same_as_streamingllm/",
          "publishedOn": "2023-10-21T12:41:54.000Z",
          "wordCount": 2603,
          "title": "[D] Is Megabyte's padding the same as streamingLLM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d1nex/d_cloud_computing_vs_personal_for_ml/",
          "author": null,
          "description": "I need a new PC to run NN on. My training sets are about 50GB. \n Would I be best building my own, or using Google colab pro? Anyone know the specs equivalent to colab Pro?\n    submitted by    /u/ajplant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d1nex/d_cloud_computing_vs_personal_for_ml/",
          "publishedOn": "2023-10-21T12:38:59.000Z",
          "wordCount": 2580,
          "title": "[D] cloud computing vs personal for ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17d0hae/d_what_is_the_current_sota_of_selfsupervised/",
          "author": null,
          "description": "I want to create a research proposal in this area. \n Ideally, I would like to work towards self-supervised models that take as input raw (not preprocessed) data of various modalities (text, image, video, audio, ...) and output a knowledge graph of all the data contained within. For example, I could feed it the Wikipedia article about dogs and it spits back all the information contained within, structured in the form of a graph.\n For people who work in the same general area can you point me to the SOTA models/efforts and research groups that work in this area? And can you also highlight the current challenges to be overcome, if you are deep enough to know?\n ​\n    submitted by    /u/KlutzyBiz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17d0hae/d_what_is_the_current_sota_of_selfsupervised/",
          "publishedOn": "2023-10-21T11:29:33.000Z",
          "wordCount": null,
          "title": "[D] What is the current SOTA of self-supervised knowledge graph models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cydgj/d_encoder_vs_decoder_transformer_for_token/",
          "author": null,
          "description": "Hi. I am working on TokenClassification problem which requires significant language understanding in the base model and was wondering if:- \n  \nIs there any research that has shown on multiple datasets that encoder-only pretraining tasks produce more optimal results when finetuned for Token Classification tasks compared to decoder-only with same parameter sized models.\n Since a lot of LLM research is focused on text generation, most model are trained on decoder-only pretraining tasks, so what is the largest encoder-only pretrained model that is trained on >1T tokens.\n If encoder-only models do indeed produce more optimal results for Token Classification is there any empirical rule w.r.t. to parameter size that we can expect decoder-only to outperform encode-only models. (Eg. say 3B decoder-only is equivalent to 1B encoder-only with similar pretraining and finetuning data)\n  \n   submitted by    /u/RemoteSaint  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cydgj/d_encoder_vs_decoder_transformer_for_token/",
          "publishedOn": "2023-10-21T09:04:57.000Z",
          "wordCount": 2676,
          "title": "[D] Encoder vs Decoder Transformer for Token Classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cy50l/d_need_some_practical_advice_on_choosing_from/",
          "author": null,
          "description": "Hi everyone. I would just like to discuss a few things. I've spent about 2 months studying CNNs on coursera from the Deep Learning Specialization. In this time period I learnt the fundamentals and mechanisms of how CNNs work. I also took lectures on a few research papers that studied a few classical CNN models like AlexNet, LeNet-5, VGG-16. And then a few research papers that studied advanced stuff like ResNets, Inception Network, MobileNet, EfficientNet etc. Following that I studied Detection Algorithms, with a primary focus on YOLO Algorithm. I also briefly studied Regional Proposals, Semantic Segmentation, R-CNN, Fast-RCNN, Faster R-CNN, U-Net. I also learnt Face Recognition and Verification Models like Siamese Network using Triplet Loss function and Binary Classification. And also cove…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cy50l/d_need_some_practical_advice_on_choosing_from/",
          "publishedOn": "2023-10-21T08:47:28.000Z",
          "wordCount": 2900,
          "title": "[D] Need some practical advice on choosing from different CNN model architectures.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cy0j7/d_p_web_browsing_uibased_ai_agent_gpt4vact/",
          "author": null,
          "description": "Github: GPT-4V-Act\n (A demo video can be found on the Github)\n Hi there!\n I'd like to share with you a project I recently developed. My inspiration came from a recent post about Set-of-Mark visual grounding in GPT-4V. Fascinatingly, my tests showed that GPT-4V, equipped with this capability, could inspect a UI screenshot and provide the precise pixel coordinates needed for steering a mouse/keyboard to perform a specified task.\n Motivated by this, I built a proof-of-concept web browser embedded with a co-pilot that can \"view\" the browser and interact with it. Currently, the demo is basic, utilizing web-scraping to morph ChatGPT Plus into an unofficial GPT-4V API at the backend. It lacks some actions and an adblock, resulting in the agent potentially being overloaded by the extensive popups …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cy0j7/d_p_web_browsing_uibased_ai_agent_gpt4vact/",
          "publishedOn": "2023-10-21T08:37:59.000Z",
          "wordCount": 2871,
          "title": "[D] [P] Web browsing UI-based AI agent: GPT-4V-Act",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17coyym/d_is_lang_chain_the_right_solution/",
          "author": null,
          "description": "Hello, I would love to have an LLm that can provide answers (in chat format) based some of the sql db data we have. Want it for an internal company project. I am by no means an expert but decent in programming and want to build a system to get answers in chat format. My understanding is that training LLMs ground up is prohibitively expensive and langchains are sort of hybrid , efficient solutions. \n Please suggest any other solutions. Also would Langchain being a company and not open source pose a problem in terms of copyrights? Thanks!\n    submitted by    /u/betelgeuseian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17coyym/d_is_lang_chain_the_right_solution/",
          "publishedOn": "2023-10-20T23:43:31.000Z",
          "wordCount": 2642,
          "title": "[D] Is lang chain the right solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cojeh/r_memgpt_towards_llms_as_operating_systems_uc/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.08560\n Github: https://github.com/cpacker/MemGPT\n Blog: https://memgpt.ai/\n Youtube: https://youtu.be/QQ2QOPWZKVc?si=_bSSXU9EQE0FP64h\n MemGPT 🧠 Giving AI Unlimited Prompt Size (Big Step Towards AGI?) by Metthew Berman / Must watch and he also explains how to install it!\n Overview\n  \nLLMs are increasingly being used for perpetual chats\n Limited context lengths makes perpetual chat challenging\n MemGPT manages a virtual context (inspired by virtual memory in operating systems) to create unbounded LLM context\n With MemGPT, we demonstrate that LLMs can be taught to manage their own memory!\n  \nAbstract: \n  \nLarge language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversa…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cojeh/r_memgpt_towards_llms_as_operating_systems_uc/",
          "publishedOn": "2023-10-20T23:23:08.000Z",
          "wordCount": 2803,
          "title": "[R] MemGPT: Towards LLMs as Operating Systems - UC Berkeley 2023 - Is able to create unbounded/infinite LLM context!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cnvbn/d_some_beginner_questions_about_whisper_for/",
          "author": null,
          "description": "Hi,\n I am a mac user. I am trying to use whisper.cpp downloaded from its github file. I don't know much about phyton or coding so I basically followed this guide to install and use it. I downloaded the large model to try it. I am using it for non-English languages and I want to use it for language learning purposes so I can understand what is being said in an Instagram story or a Youtube video (without subtitles) or a tv series or an extract of movie etc. I was using Macwhisper but I wanted to try the pro features and I don't want to pay for it (for now) and try the pro models for non-English languages.\n My question is: all of my files that I want to transcribe are video files with .mp4 extension. Can I also transcribe those with whisper?\n If not, and if I can only transcribe audio files, can it be .mp3? I understand that I need to install and use ffmpeg. Does it support mp3?\n Also, as I understand, the transcripted text will appear in the terminal. Can I export it in -srt or pdf?\n Thanks\n    submitted by    /u/toughytough  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cnvbn/d_some_beginner_questions_about_whisper_for/",
          "publishedOn": "2023-10-20T22:52:07.000Z",
          "wordCount": 2739,
          "title": "[D] Some beginner questions about Whisper for transcription",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cmzcz/d_transformers_are_basically_cnns/",
          "author": null,
          "description": "I've watched an interesting video: Deriving the Ultimate Neural Network Architecture from Scratch. It's about how to come up to the transformer architecture when you have an understanding of CNNs.\n The crux of it is an idea of pairwise convolutional layers. The first layer applies not to the sequence of words itself, but to all pairs of words in the sentence. This ensures that each relation of words that are far from each other is taken into account.\n The next convolutional layer applies to all pairs of results of the previous one. This way longer subsequences of words are factored in.\n pairs of words\n My question is: are there any articles on how transformers were invented? I see a lot of explanations of the original paper, but at best they all answer the question how transformers work. But why is the architecture the way it is? Was it discovered like the video describes? Or the path was more convoluted? I'd like to know more about this connection.\n Anyway, it would be great to figure out in all details how these pairwise layers are related to the concepts of query, key, and value. Here's what the author of the video wrote in comments:\n  \nYeah it's a term I made up so you won't find it in any sources, sorry about that. Usually sources will just talk about self attention in terms of key, query and value lookups, so you can look at those to get a more detailed understanding of the transformer. The value transform is equivalent to the linear representation function I use in the pairwise convolution, the key and query attention scores are equivalent to the bi-linear form scoring function I use (with the bi-linear form weight matrix given by Q^TK). I chose to use this unusual terminology because, personally, I feel the key, query and value terminology comes out of nowhere, and I wanted to connect the transformer more directly to its predecessor (the CNN).\n  \n​\n    submitted by    /u/Veson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cmzcz/d_transformers_are_basically_cnns/",
          "publishedOn": "2023-10-20T22:11:27.000Z",
          "wordCount": 2870,
          "title": "[D] Transformers are basically CNNs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cmum1/r_does_this_learning_curve_show_any_serious/",
          "author": null,
          "description": "I'm trying to fit a multivariate LSTM model to time series data to predict future values for one relatively noisy series. I noticed that the the loss (mse in this case) is pretty high given that the data has been standardized beforehand. So I really have two questions: why is the mse so high and is the learning curve indicative of any obvious problems? Thank you!\n https://preview.redd.it/r9bel6p7kfvb1.png?width=547&format=png&auto=webp&s=4eee53aa8005da8a89f330f6e98fe6cadde3467e\n    submitted by    /u/DifferenceUnhappy393  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cmum1/r_does_this_learning_curve_show_any_serious/",
          "publishedOn": "2023-10-20T22:05:33.000Z",
          "wordCount": 2614,
          "title": "[R] Does this learning curve show any serious under/overfitting problems?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cmeqb/discussion_is_the_deadly_triad_real/",
          "author": null,
          "description": "Sutton and Barto’s textbook mentions that combing off-policy learning, bootstrapping, and function approximation leads to extreme instability and should be avoided. Yet when I encounter a reinforcement problem in the wild and look how people go about solving it, if someone’s solution involves bootstrapping more often than not it’s some variation of deep Q-learning. Why is this?\n    submitted by    /u/BiasedEstimators  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cmeqb/discussion_is_the_deadly_triad_real/",
          "publishedOn": "2023-10-20T21:46:12.000Z",
          "wordCount": null,
          "title": "[Discussion] Is the deadly triad real?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17clyw6/p_building_a_dd_npc/",
          "author": null,
          "description": "Hey everyone,\n I'm learning ML but i'm barely scratching the terminologies. 2 years ago I couldn't code anything but with school (python,sql and R) I learned fundamentals. I also have access to code academy. My current program is very machine learning/deep learning focused.\n On the side I DM a d&d game. Within the context of the world (eberron) robots are common. With my ADHD and being a new DM I want to outsource lore questions might have (that I would have to look up and slow down the game).\n The concept is to have a GUI and have the player interact with the chat bot. I've gotten to a proof of concept workflow. On Google colab. Thanks to langchain I managed to ingest pdfs and a url. Make then a directory, Embedded the text, bring it into a vector dB. Have the llm pull from the vector. Answer the question.\n Now I don't know what to do. I tried to bring the colab notebook onto Google cloud. But now cloud is becoming a rabbit home with vertex and docAI...and I don't want to deep dive into that, if it's a outside the scope of this \"project\"\n I'd appreciate any advice, links...etc. \n I got a limited success in botpress using a single pdf. It works but feel unsatisfying. N8N looks promising but if it's not intuitive then I don't want to go down that road.\n If I posted in the wrong group please direct me to the correct one.\n    submitted by    /u/work929  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17clyw6/p_building_a_dd_npc/",
          "publishedOn": "2023-10-20T21:27:15.000Z",
          "wordCount": 2791,
          "title": "[P] building a D&D NPC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cky1x/r_incontext_pretraining_language_modeling_beyond/",
          "author": null,
          "description": "https://arxiv.org/abs/2310.10638\n \"Large language models (LMs) are currently trained to predict tokens given document prefixes, enabling them to directly perform long-form generation and prompting-style tasks which can be reduced to document completion. Existing pretraining pipelines train LMs by concatenating random sets of short documents to create input contexts but the prior documents provide no signal for predicting the next document. We instead present In-Context Pretraining, a new approach where language models are pretrained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries. We can do In-Context Pretraining by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines. However, this document sorting problem is challenging. There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data. To do this, we introduce approximate algorithms for finding related documents with efficient nearest neighbor search and constructing coherent input contexts with a graph traversal algorithm. Our experiments show In-Context Pretraining offers a simple and scalable approach to significantly enhance LMs'performance: we see notable improvements in tasks that require more complex contextual reasoning, including in-context learning (+8%), reading comprehension (+15%), faithfulness to previous contexts (+16%), long-context reasoning (+5%), and retrieval augmentation (+9%).\"\n    submitted by    /u/Parking-Priority6217  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cky1x/r_incontext_pretraining_language_modeling_beyond/",
          "publishedOn": "2023-10-20T20:42:24.000Z",
          "wordCount": 2760,
          "title": "[R] In-Context Pretraining: Language Modeling Beyond Document Boundaries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cjth3/r_using_machine_learning_to_set_parameters_in/",
          "author": null,
          "description": "Greetings,\n I'm on my 2nd year of College (Artificial Intelligence bachelors degree), and currently making a group project that will require machine learning. The project consists of managing and regulating the conditions (temperature, humidity, lightning, etc.) of the environment that surrounds important products (vaccines, human organs, etc.) during their transportation, using sensors implemented in their transportation box. For that being possible, our group was planning to use a predictive model using machine learning, to prevent cases such as the exposure of inappropriate temperature levels, that could damage the product, and subsequently taking the appropriate measures to improve the environment, before it reaches such dangerous scenarios.\n Therefore, I would like to know which tools and skills will be needed and helpful in order to achieve such goal. If you have any advice, that'll be very much appreciated. :)\n    submitted by    /u/Storm2003  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cjth3/r_using_machine_learning_to_set_parameters_in/",
          "publishedOn": "2023-10-20T19:51:31.000Z",
          "wordCount": 2686,
          "title": "[R] Using Machine Learning to set parameters in sensors (College Project)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cgz5w/r_3dgpt_a_new_method_for_procedural_textto3d/",
          "author": null,
          "description": "Researchers propose a new AI system called 3D-GPT that creates 3D models by combining natural language instructions and agents specialized for working with existing 3D modeling tools.\n 3D-GPT has predefined functions that make 3D shapes, and it tweaks parameters to build scenes. The key is getting the AI to understand instructions and pick the right tools.\n It has three main agents:\n  \nA dispatcher that parses the text and picks generation functions\n A conceptualizer that adds details missing from the description\n A modeler that sets parameters and outputs code to drive 3D software\n  \nBy breaking modeling work down into steps, the agents can collab to match the descriptions. This is sort of like how a 3D modeling team of humans would work.\n The paper authors show it making simple scenes like \"lush meadow with flowers\" that fit the text. It also modifies scenes appropriately when given new instructions. I include some gifs of example outputs in my full summary. They look pretty good - I would say 2005-quality graphics.\n There are limits. It fully relies on existing generators, so quality is capped. Details and curves are iffy. It resorts to default shapes often instead of true understanding. And I doubt the verts and textures are well-optimized.\n The agent architecture seems to be really popular right now. This one shows some planning skills, which could extend to more creative tasks someday.\n TLDR: AI agents can team up to generate 3D models from text instructions. Works to some degree but limitations remain.\n Full summary. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cgz5w/r_3dgpt_a_new_method_for_procedural_textto3d/",
          "publishedOn": "2023-10-20T17:42:11.000Z",
          "wordCount": 2801,
          "title": "[R] 3D-GPT: A new method for procedural Text-to-3D model generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cdym9/r_bayesian_optimizationbased_combinatorial/",
          "author": null,
          "description": "Link: https://ojs.aaai.org/index.php/AAAI/article/view/25726/25498\n Abstract: We study the combinatorial assignment domain, which includes combinatorial auctions and course allocation. The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning-based preference elicitation algorithms that aim to elicit only the most important information from agents. However, the main shortcoming of this prior work is that it does not model a mechanism's uncertainty over values for not yet elicited bundles. In this paper, we address this shortcoming by presenting a Bayesian optimization-based combinatorial assignment (BOCA) mechanism. Our key technical contribution is to integrate a method for capturing model uncertainty into an iterative combinatorial auction mechanism. Concretely, we design a new method for estimating an upper uncertainty bound that can be used to define an acquisition function to determine the next query to the agents. This enables the mechanism to properly explore (and not just exploit) the bundle space during its preference elicitation phase. We run computational experiments in several spectrum auction domains to evaluate BOCA's performance. Our results show that BOCA achieves higher allocative efficiency than state-of-the-art approaches.\n https://preview.redd.it/aeo36u3wldvb1.png?width=1288&format=png&auto=webp&s=2982547f8af51ed7195f49dbec9359fecba1693f\n ​\n    submitted by    /u/Yossarian_1234  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cdym9/r_bayesian_optimizationbased_combinatorial/",
          "publishedOn": "2023-10-20T15:29:06.000Z",
          "wordCount": 2733,
          "title": "[R] Bayesian Optimization-based Combinatorial Assignment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cdt0r/d_what_is_the_latest_method_for_models_with/",
          "author": null,
          "description": "So a lot of multimodal models I've seen use a linear layer to transform encoded image/video/audio into the multimodal LLMs embedding space.\n This makes sense for the input, but how would output work?\n Normally you use a layer to convert the embedding to a SoftMax of probabilities of possible output tokens. This makes sense for discrete outputs like tokens but not for continuous outputs like images or audio.\n ​\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cdt0r/d_what_is_the_latest_method_for_models_with/",
          "publishedOn": "2023-10-20T15:22:10.000Z",
          "wordCount": 2638,
          "title": "[D] What is the latest method for models with multimodal outputs? How can the shared embedding used by a lot of multimodal models be dynamically \"routed\" to the proper modality during output?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cc8on/d_is_anyone_else_tired_of_whatever_openai_does_is/",
          "author": null,
          "description": "The title says it all. I agree what they did is incredible and literally changed AI landscape in last couple of years. But I’m getting tired of everyone acting like OpenAI is the only one doing great research. The twit-fluencers praising even the slightest peep from them. I don’t understand this fanaticism in AI community. There are smart researchers doing smart things all over the world. But they don’t even get a fraction of appreciation they deserve. And the strangest thing of all, ChatGPT is used as oracle to evaluate models in research papers. Consistency models are extremely meh and if it did not come out of openAI, people would’ve forgotten them a long time ago!\n Edit 1: I’m in grad school and that’s all a lot of students around me talk about/ chase. I want to work on a bit more fundamental problems, but I feel like I’m being left behind. \n Edit 2: This post is mostly a rant about academics obsessed with OpenAI research/products and LLMs. \n    submitted by    /u/mildlyphd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cc8on/d_is_anyone_else_tired_of_whatever_openai_does_is/",
          "publishedOn": "2023-10-20T14:12:12.000Z",
          "wordCount": 2719,
          "title": "[D] Is anyone else tired of “whatever OpenAI does is the best!” narrative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17cacro/p_hacktoberfest_machine_learning_projects_for/",
          "author": null,
          "description": "Hey everyone,we have published an article about Hacktoberfest Projects 🎃 medium.com with a curated list of open-source machine learning GUI projects built with javascript or typescript.\n ​\n https://preview.redd.it/nr4jfbqoscvb1.png?width=1352&format=png&auto=webp&s=fbb2313aabf0a617b6e426f1fa5018946b7ed7f5\n 🔍 Finding machine learning projects that are suitable for JS/TS developers during Hacktoberfest can be daunting due to the overwhelming abundance of open-source projects. We’ve simplified this process, offering you a refined selection of opportunities where your coding skills can shine and make a real impact.\n The Selection includes:\n  \n Spotlight our powerful tool for intuitively exploring unstructured datasets directly from dataframes.\n Iteratives CML (Continuous Machine Learning) a command-line interface tool designed to enhance continuous integration and delivery (CI/CD) workflows.\n Inclusive Code Reviews: Browser Extension for improving online comments such as code reviews on Github or Azure DevOps.\n BeatBridge - A Music Player with a Recommendation Engine\n  \nEach project offers a unique blend of challenges and learning opportunities, inviting you to contribute and grow your skills and knowledge in the dynamic world of open source. Choose a project that resonates with you, select an issue, and make an impact 🚀.\n    submitted by    /u/DocBrownMS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17cacro/p_hacktoberfest_machine_learning_projects_for/",
          "publishedOn": "2023-10-20T12:40:45.000Z",
          "wordCount": 2722,
          "title": "[P] Hacktoberfest Machine Learning Projects for JS/TS Developers 🎃",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c8aha/r_agenttuning_enabling_generalized_agent/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.12823\n Github: https://github.com/THUDM/AgentTuning\n Model: https://huggingface.co/THUDM/agentlm-70b\n Abstract:\n  \nOpen large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs. However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ LLMs as the central controller responsible for planning, memorization, and tool utilization, necessitating both fine-grained prompting methods and robust LLMs to achieve satisfactory performance. Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of L…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c8aha/r_agenttuning_enabling_generalized_agent/",
          "publishedOn": "2023-10-20T10:44:14.000Z",
          "wordCount": 2787,
          "title": "[R] AgentTuning: Enabling Generalized Agent Abilities for LLMs - Tsinghua University 2023 - Agent-tuned open model comparable to GPT-3.5-Turbo on unseen agent tasks!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c6dud/d_people_working_for_relatively_large/",
          "author": null,
          "description": "I'm wondering whether LLMs within your organisation are widely used (including non-programmers), and in an (official) capacity that prevents OpenAI/Microsoft or another third party from using the input. Here, I'm talking about access by a wide variety of employees, not including as part of a data pipeline that doesn't have a user interface and only performs one job.\n  \nDoes your organization have a custom-built interface with enterprise access to an LLM? Use one of the open-source interfaces, or does your organisation provide access through i.e. Microsoft copilot? What about access to Github copilot (for programmers)? Or does your organisation have some kind of SAAS solution?\n If you have some kind of RAG within the organisation that isn't built-in into a product. What sort of stack do you use? Do you use OpenAI plugins to access this?\n  \n   submitted by    /u/Background_Claim7907  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c6dud/d_people_working_for_relatively_large/",
          "publishedOn": "2023-10-20T08:36:06.000Z",
          "wordCount": 2692,
          "title": "[D] People working for (relatively) large organisations. How are LLMs accessed by employees within your organisation right now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c613y/d_thoughts_on_opendomain_qna_systems/",
          "author": null,
          "description": "Been really interested in Open-Domain Question Answering these days and saw some interesting new models apart from the typical Retriever-Reader e.g. Generator-Retriever-Generator. Anyone particularly excited about anything new in the field - some new technique/model etc.?\n    submitted by    /u/Aggravating-Floor-38  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c613y/d_thoughts_on_opendomain_qna_systems/",
          "publishedOn": "2023-10-20T08:10:48.000Z",
          "wordCount": 2580,
          "title": "[D] Thoughts on Open-Domain QnA Systems?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c5p6d/n_state_of_ai_report_2023/",
          "author": null,
          "description": "The State of AI Report for this year is out : https://www.stateof.ai/2023-report-launch\n A 160-slide presentation/report which seems quite exhaustive in the discussed topics, and provides a good view of the \"hottest\" research axes this year.\n Previous reports (yearly since 2019) are available on their website and have been generally well received in this sub. \n    submitted by    /u/ElkoSoltius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c5p6d/n_state_of_ai_report_2023/",
          "publishedOn": "2023-10-20T07:47:45.000Z",
          "wordCount": 2597,
          "title": "[N] State of AI Report 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c4jmx/r_large_language_models_as_analogical_reasoners/",
          "author": null,
          "description": "https://arxiv.org/abs/2310.01714\n \"Chain-of-thought (CoT) prompting for language models demonstrates impressive performance across reasoning tasks, but typically needs labeled exemplars of the reasoning process. In this work, we introduce a new prompting approach, Analogical Prompting, designed to automatically guide the reasoning process of large language models. Inspired by analogical reasoning, a cognitive process in which humans draw from relevant past experiences to tackle new problems, our approach prompts language models to self-generate relevant exemplars or knowledge in the context, before proceeding to solve the given problem. This method presents several advantages: it obviates the need for labeling or retrieving exemplars, offering generality and convenience; it can also tailor the generated exemplars and knowledge to each problem, offering adaptability. Experimental results show that our approach outperforms 0-shot CoT and manual few-shot CoT in a variety of reasoning tasks, including math problem solving in GSM8K and MATH, code generation in Codeforces, and other reasoning tasks in BIG-Bench.\"\n https://preview.redd.it/f9azq40pwavb1.jpg?width=6390&format=pjpg&auto=webp&s=0af3de7925a6ef8f442e40f952849db2f544c3a7\n    submitted by    /u/Parking-Priority6217  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c4jmx/r_large_language_models_as_analogical_reasoners/",
          "publishedOn": "2023-10-20T06:24:46.000Z",
          "wordCount": null,
          "title": "[R] Large Language Models as Analogical Reasoners",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c4io6/r_large_language_models_as_optimizers/",
          "author": null,
          "description": "https://arxiv.org/abs/2309.03409\n \"Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to prompt optimization where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.\"\n    submitted by    /u/Parking-Priority6217  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c4io6/r_large_language_models_as_optimizers/",
          "publishedOn": "2023-10-20T06:22:54.000Z",
          "wordCount": 2696,
          "title": "[R] Large Language Models as Optimizers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17c3sf2/d_communities_thoughts_on_rsingularity_and_other/",
          "author": null,
          "description": "I’ve seen many comments telling people to go to r/singularity, so I’ve been wondering about the communities thoughts on non-technical subreddits. Are they seen as a source of hype, getting newcomers more interested in the field and helping to advance knowledge? Or do you see such communities as an overly optimistic non-skeptical massive misinformation/active disinformation center?\n Do you think there’s something that can be done to improve these communities? What do you think their role should be relative to the technical communities? Do you have any specific criticisms? For those of you who think our two communities should be separate to what extent?\n    submitted by    /u/Username912773  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17c3sf2/d_communities_thoughts_on_rsingularity_and_other/",
          "publishedOn": "2023-10-20T05:34:04.000Z",
          "wordCount": 2652,
          "title": "[D] Communities thoughts on r/singularity and other non-technical machine learning subreddits?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bzbaq/r_neural_relation_graph_a_unified_framework_for/",
          "author": null,
          "description": "paper: https://arxiv.org/abs/2301.12321\n code: https://github.com/snu-mllab/Neural-Relation-Graph\n TDLR: We present a scalable and domain-agnostic approach utilizing the relational structure of data for identifying label noise and outliers\n https://preview.redd.it/o9k7kliqe9vb1.png?width=3108&format=png&auto=webp&s=b7c34bd7f4bc130915440986570104f9bebd4f07\n  \nDiagnosing and cleaning data is a crucial step for building robust machine learning systems. However, identifying problems within large-scale datasets with real-world distributions is challenging due to the presence of complex issues such as label errors, under-representation, and outliers. In this paper, we propose a unified approach for identifying the problematic data by utilizing a largely ignored source of information: a relational structure of data in the feature-embedded space. To this end, we present scalable and effective algorithms for detecting label errors and outlier data based on the relational graph structure of data. We further introduce a visualization tool that provides contextual information of a data point in the feature-embedded space, serving as an effective tool for interactively diagnosing data. We evaluate the label error and outlier/out-of-distribution (OOD) detection performances of our approach on the large-scale image, speech, and language domain tasks, including ImageNet, ESC-50, and SST2. Our approach achieves state-of-the-art detection performance on all tasks considered and demonstrates its effectiveness in debugging large-scale real-world datasets across various domains.\n  \n​\n Detected samples with label error (red colored) from ImageNet (top) and SST2 (bottom).\n ​\n Detected outlier samples from ImageNet (top) and SST2 (bottom) validation sets.\n    submitted by    /u/janghyun1230  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bzbaq/r_neural_relation_graph_a_unified_framework_for/",
          "publishedOn": "2023-10-20T01:25:47.000Z",
          "wordCount": 2771,
          "title": "[R] Neural Relation Graph: A Unified Framework for Identifying Label Noise and Outlier Data (NeurIPS 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bz4af/d_future_ai_development_on_accessible_hardware/",
          "author": null,
          "description": "Is there a future where models can run efficiently and at scale with just half a dozen high end consumer GPUs? A lot of people seem to think the bottleneck is \"there's no competition for NVIDIA\" but I actually think the current bottleneck is software. 4x 4090s is more CUDA cores, more transistors, more VRAM than a H100, but the performance and price difference is staggering, which should not be the case. Raspberry Pi 4s running faster desktops than a same generation Dell Inspiron prove that software integration is key. Cheap performance is laying on the table, it just has to be used more effectively by models and ML libraries\n    submitted by    /u/HovercraftForeign591  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bz4af/d_future_ai_development_on_accessible_hardware/",
          "publishedOn": "2023-10-20T01:16:07.000Z",
          "wordCount": 2655,
          "title": "[D] Future AI development on accessible hardware?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bxtt0/d_online_masters_alternatives_for_mlops/",
          "author": null,
          "description": "Hi everyone, greeting from south america..\n Basically I'm looking for an program to learn and improve my job opportunities in the MLOps field and at some point getting higher responsability positions. I recently got admitted for both OMSA and OMSCS from Gatech, but I feel those programs are more focused on the data science side of things.\n Is there any other alternative without GRE requeriment that you would recommend with a similar cost?\n Maybe I'm wrong about the aforementioned programs, if you think so, please let me know why.\n Thanks!\n    submitted by    /u/imatiasmb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bxtt0/d_online_masters_alternatives_for_mlops/",
          "publishedOn": "2023-10-20T00:12:41.000Z",
          "wordCount": 2634,
          "title": "[D] Online masters alternatives for MLOps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bwmw7/machine_learning_on_a_microcontroller_p/",
          "author": null,
          "description": "i am making an EEG machine for a university project, i will be taking in an analogue signal and converting it to digital, i then will be sending the varying voltages to a microcontroller in hopes that it will be able to catagorise them in either states of mind or as simply as telling whether or not the persons eyes are open or closed.\n i have very little knowledge on machine learning but it is required to be implemented in the project, my lecturer is pressuring me to have final pick of what software and microcontroller iw will be using for this project, everyone else in the class are using Edge Impulse which the lecturer said wouldn't be applicable to me as it uses accelerometers and voice. and are using CY8CKIT-042 PSoC 4 PIONEER KITS which apperently arent suited for me either.\n any help would be much appreciated and i do apologise if this is too rambly.\n    submitted by    /u/disslixac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bwmw7/machine_learning_on_a_microcontroller_p/",
          "publishedOn": "2023-10-19T23:16:16.000Z",
          "wordCount": 2701,
          "title": "machine learning on a microcontroller [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bwfq9/r_openagents_an_open_platform_for_language_agents/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.10634v1\n Github: https://github.com/xlang-ai/OpenAgents\n Abstract:\n  \nLanguage agents show potential in being capable of utilizing natural language for varied and intricate tasks in diverse environments, particularly when built upon large language models (LLMs). Current language agent frameworks aim to facilitate the construction of proof-of-concept language agents while neglecting the non-expert user access to agents and paying little attention to application-level designs. We present OpenAgents, an open platform for using and hosting language agents in the wild of everyday life. OpenAgents includes three agents: (1) Data Agent for data analysis with Python/SQL and data tools; (2) Plugins Agent with 200+ daily API tools; (3) Web Agent for autonomous web browsing. OpenAgents enables general users to interact with agent functionalities through a web user interface optimized for swift responses and common failures while offering developers and researchers a seamless deployment experience on local setups, providing a foundation for crafting innovative language agents and facilitating real-world evaluations. We elucidate the challenges and opportunities, aspiring to set a foundation for future research and development of real-world language agents. \n  \nhttps://preview.redd.it/syl2gzh3q8vb1.jpg?width=1084&format=pjpg&auto=webp&s=4045d3abb5cdb7587614795e709cdaba03bc122d\n https://preview.redd.it/aus342i3q8vb1.jpg?width=1086&format=pjpg&auto=webp&s=73de7976db5a8bbed880350fab8ab56be3fee550\n https://preview.redd.it/qstz81i3q8vb1.jpg?width=1346&format=pjpg&auto=webp&s=1626482556a90abf418abb5d56f8e5599cb1e3d6\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bwfq9/r_openagents_an_open_platform_for_language_agents/",
          "publishedOn": "2023-10-19T23:07:08.000Z",
          "wordCount": 2729,
          "title": "[R] OpenAgents: An Open Platform for Language Agents in the Wild - The University of Hong Kong 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bwbbs/research_hypernymybased_approach_for_texttoimage/",
          "author": null,
          "description": "Text-to-image models have rapidly progressed in recent years, but most popular evaluation metrics (such as FID) do not consider their linguistic abilities. A new approach measures how well these models understand subtype relations between concepts. Researchers from Yandex proposed two metrics that combine well-known tools like the WordNet database and ImageNet classifiers in a novel way, allowing them to analyze models like Stable Diffusion in more detail.\n Blog post.\n    submitted by    /u/metkere  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bwbbs/research_hypernymybased_approach_for_texttoimage/",
          "publishedOn": "2023-10-19T23:01:37.000Z",
          "wordCount": 2615,
          "title": "[Research] Hypernymy-based approach for text-to-image models (Blog post)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bvfpd/r_can_large_language_models_explain_themselves_a/",
          "author": null,
          "description": "Large language models (LLMs) such as ChatGPT have demonstrated superior performance on a variety of natural language processing (NLP) tasks including sentiment analysis, mathematical reasoning and summarization. Furthermore, since these models are instruction-tuned on human conversations to produce \"helpful\" responses, they can and often will produce explanations along with the response, which we call self-explanations. For example, when analyzing the sentiment of a movie review, the model may output not only the positivity of the sentiment, but also an explanation (e.g., by listing the sentiment-laden words such as \"fantastic\" and \"memorable\" in the review). How good are these automatically generated self-explanations? In this paper, we investigate this question on the task of sentiment analysis and for feature attribution explanation, one of the most commonly studied settings in the interpretability literature (for pre-ChatGPT models). Specifically, we study different ways to elicit the self-explanations, evaluate their faithfulness on a set of evaluation metrics, and compare them to traditional explanation methods such as occlusion or LIME saliency maps. Through an extensive set of experiments, we find that ChatGPT's self-explanations perform on par with traditional ones, but are quite different from them according to various agreement metrics, meanwhile being much cheaper to produce (as they are generated along with the prediction). In addition, we identified several interesting characteristics of them, which prompt us to rethink many current model interpretability practices in the era of ChatGPT(-like) LLMs.\n  \nhttps://arxiv.org/abs/2310.11207\n    submitted by    /u/zyl1024  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bvfpd/r_can_large_language_models_explain_themselves_a/",
          "publishedOn": "2023-10-19T22:21:30.000Z",
          "wordCount": 2777,
          "title": "[R] Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17btzjc/discussion_machine_learning_for_mechanical/",
          "author": null,
          "description": "Hello all,\n ​\n I'm a mechanical engineer learning machine learning, I found many specializations on Coursera by Google, DeepLearing.AI, and IBM, but I really can't tell which of them will be the best fit for me, so I would like to hear your recommendations, actually, I got financial aid for the specialization by DeepLearning AI and finished the first course, but I'm not satisfied I feel like I will not be a professional by this course\n ​\n my goal is to master data analysis and ML to work as a freelancer and increase my chances of finding a funded master's degree.\n    submitted by    /u/Mobile_Ad_4573  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17btzjc/discussion_machine_learning_for_mechanical/",
          "publishedOn": "2023-10-19T21:20:10.000Z",
          "wordCount": 2643,
          "title": "[Discussion] Machine Learning for Mechanical Engineering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17btjn7/discussion_scientific_and_dataintensive_computing/",
          "author": null,
          "description": "Hi everyone!\n I'm a graduate student in Scientific and Data-Intensive Computing at the University of Trieste (Italy) and I'm writing this post because I want to ask you a feedback about my study plan :)\n  \n 1st semester 2nd semester 3rd semester 4th semester \n  \n Statistical methods Deep Learning Simulation Intelligence and Learning for Autonomous Systems Parallel Programming for High-Performance Computing \n  High-Performance Computing Advanced Algorithms for Scientific Computing Advanced Topics in Scientific Computing  \n  Cloud Computing Advanced Numerical Analysis Advanced Deep Learning  \n  Software Development Practices Advanced High-Performance Computing   \n  Numerical Analysis Probabilistic Machine Learning Thesis Thesis \n \n  \nYou can find all the programs of the courses on this website\n On the following websites, you can find a lot of courses that I could add to my study plan \n Scientific Computing Courses\n Data science courses\n \n  \nAbout me\n  \nI have a Bachelor's degree in Computer Science (University of Rome)\n I am a Research Intern at an AI startup\n I will do a Summer Research Internship in the field of (HPC) ∩ (Machine Learning)\n I don't already know what my thesis will be about but I'm really interested in High-Performance Computing, Computational Mathematics, Machine Learning, and Simulations\n I would like to work in a research context; I'm considering doing a PhD in Scientific Computing (In that case, I would try to apply to American Universities)\n  \nI'm available for further clarification :)\n Thank you in advance\n    submitted by    /u/PragmaticScientist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17btjn7/discussion_scientific_and_dataintensive_computing/",
          "publishedOn": "2023-10-19T21:01:58.000Z",
          "wordCount": 2772,
          "title": "[Discussion] Scientific and Data-Intensive Computing study plan",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bsyp6/d_has_anybody_heard_back_from_neurips_financial/",
          "author": null,
          "description": "Was supposed to be Monday but instead it's rolling\n    submitted by    /u/notasketchyperson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bsyp6/d_has_anybody_heard_back_from_neurips_financial/",
          "publishedOn": "2023-10-19T20:37:08.000Z",
          "wordCount": 2557,
          "title": "[D] Has anybody heard back from NeurIPS financial aid yet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bst5d/d_need_advice_for_medical_text_processing/",
          "author": null,
          "description": "I am working on a research project that involves analysing medical text (patient records) to identify key events. Initially I was planning to use chatgpt api and then compare its performance with open source LLMs. However, I've just come across Amazon Comprehend Medical, which seems to be specifically designed for what I need. Has anyone tried it? I would expect it to be better than chatgpt + plugins, as it says it was trained with medical language. This also makes me wonder if there are opensource LLMs specifically trained for the medical field. Does anyone have experience with this?\n    submitted by    /u/kiukamba  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bst5d/d_need_advice_for_medical_text_processing/",
          "publishedOn": "2023-10-19T20:30:45.000Z",
          "wordCount": 2638,
          "title": "[D] Need advice for medical text processing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bqvhu/project_scaling_llama2_70b_with_multi_nvidia_and/",
          "author": null,
          "description": "Big LLMs are memory bound, one way to break that limit is to make use of multiGPUs.\n The recent development of MLC LLM project makes it possible to compile and deploy large-scale language models running on multi-GPU systems with support for NVIDIA and AMD GPUs with high performance. Specifically, it can run 4-bit quantized Llama2-70B at 34.5 tok/sec on two NVIDIA RTX 4090 and 29.9 tok/sec on two AMD Radeon 7900XTX. \n This is a first solution that helps us to scale 70B models with multiple GPUs, bringing the potential to run even larger open LLMs under reasonable budget (the two AMD GPUs cost 2k)\n ​\n - Project https://github.com/mlc-ai/mlc-llm\n - Blogpost https://blog.mlc.ai/2023/10/19/Scalable-Language-Model-Inference-on-Multiple-NVDIA-AMD-GPUs\n ​\n ​\n    submitted by    /u/crowwork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bqvhu/project_scaling_llama2_70b_with_multi_nvidia_and/",
          "publishedOn": "2023-10-19T19:07:36.000Z",
          "wordCount": 2661,
          "title": "[Project] Scaling LLama2 70B with Multi NVIDIA and AMD GPUs under 3k budget",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bpad2/d_is_there_a_way_to_get_world_level_timestamps/",
          "author": null,
          "description": "I don't understand how this isn't talked about more, given how many projects/products I've seen that have time level timestamps with whisper.\n I understand whisper isn't a traditional CTC model like wave2vec, and i understand that there are plenty of tutorials out there for doing dtw-based alignment.\n I know whisper-timestamped exist, and whisperx. The thing is, all these solutions assume you have the infrastructure to host your own whisper model. I am just getting started on my product, and I simply don't see the point in paying over 300/mo for a g4 instance (the cheapest GPU instance in AWS) just for an MVP.\n ​\n Has anyone been able to take the whisper API output, and align that using the sound bites and get timestamps? Is running your own whisper model the only way? Thank you!\n    submitted by    /u/latent_space_tennis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bpad2/d_is_there_a_way_to_get_world_level_timestamps/",
          "publishedOn": "2023-10-19T18:00:07.000Z",
          "wordCount": 2695,
          "title": "[D] Is there a way to get world level timestamps with whisper (using DTW based alignment) without having to host your own model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bnzp8/d_what_metrics_do_you_use_to_track_gpu/",
          "author": null,
          "description": "Hello people!\n I used to rely on GPU Usage to track how effectively I was able to leverage the gpu or cluster provided by my company from Grafana dashboard, however yesterday I saw X someone on X/Twitter saying:\n \"Utilization is a poor metric by itself. You can easly hit 100% where the GPU is doing a lot of waiting. Power consumption is a better (but not perfect) measure. If you're burning watts it's usually doing something useful. High util, no watts is not good.\"\n Which it's something that I've never considered before!\n Now I'm quite curious to hear if anyone here have considered this approach before or alternative ways to measure the performance of the GPU resource/cluster.\n    submitted by    /u/pirate7777777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bnzp8/d_what_metrics_do_you_use_to_track_gpu/",
          "publishedOn": "2023-10-19T17:03:00.000Z",
          "wordCount": 2669,
          "title": "[D] what metrics do you use to track GPU performance during training and/or inference?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bnslb/r_create_3d_model_of_face_with_4_normal_images/",
          "author": null,
          "description": "Hi guys, I'm looking for an AI application or way to create this in < 10' with proper accuracy. Does anybody know anything? Quality should be good enough to print it.\n    submitted by    /u/Reasonable_Cream_520  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bnslb/r_create_3d_model_of_face_with_4_normal_images/",
          "publishedOn": "2023-10-19T16:54:29.000Z",
          "wordCount": 2579,
          "title": "[R] Create 3d model of face with 4 normal images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bkqe7/p_higgsfield_distributed_llm_training_and_cluster/",
          "author": null,
          "description": "https://github.com/higgsfield-ai/higgsfield\n    submitted by    /u/Good-Willingness-985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bkqe7/p_higgsfield_distributed_llm_training_and_cluster/",
          "publishedOn": "2023-10-19T14:39:43.000Z",
          "wordCount": 2548,
          "title": "[P] Higgsfield: Distributed LLM training and cluster management framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bkot8/d_a_clear_visual_and_intuitive_explanation_of/",
          "author": null,
          "description": "Hello guys, I made a video for my YT channel breaking down Neural Attention with some intuitive examples and representative projects. \n Here is the link for those interested, all feedback is appreciated!\n https://youtu.be/frosrL1CEhw?si=NKTqmRTieVkfCNlb\n ​\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bkot8/d_a_clear_visual_and_intuitive_explanation_of/",
          "publishedOn": "2023-10-19T14:37:42.000Z",
          "wordCount": 2581,
          "title": "[D] A clear visual and intuitive explanation of Neural Attention",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bkizl/d_advantage_of_vaes_compared_to_regularized_aes/",
          "author": null,
          "description": "I'm trying to come up to speed on VAE's.\n My intuitive concept of a VAE is an AE for which we want to enforce some distributional regularity on the latent encodings.\n Why not accomplish this by simply regularizing the latent encodings directly? For example, we could assert that the latent vectors are drawn from a zero-mean, identity-matrix-covariance Gaussian distribution.\n So that e.g. the loss function becomes:\n  \nLoss(X) = ReconstructionLoss(Decoder(Encoder(X))) + LogPriorProbability(Encoder(X))\n In a variant of this, we could add a hyperparameter coefficient for the prior loss component.\n  \nHere, there is no \"reparameterization trick\" because the encoder is not stochastic. We simply regularize the latent encodings directly. If the encoder does not make the data X distribution look like the targeted Gaussian, it's a \"less good\" encoder. In principle we ought to still be able to generate X's by sampling from the prior and passing it through the decoder.\n This seems (to me) like the simplest way to regularize the latent space.\n Why do VAE's, by contrast, introduce the new machinery of a stochastic encoder?\n    submitted by    /u/OneQuadrillionOwls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bkizl/d_advantage_of_vaes_compared_to_regularized_aes/",
          "publishedOn": "2023-10-19T14:30:35.000Z",
          "wordCount": 2720,
          "title": "[D] Advantage of VAE's compared to regularized AE's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bjjkt/d_run_ai_model_multiple_k80_vs_rtx_4090/",
          "author": null,
          "description": "I want to build a machine for run multiple type of Ai Model like picture generation, chatbot, summarization, etc. I also want to train my own models. Is it better to use multiple(6/7) k80 or something like that or buy a RTX 4090? \n    submitted by    /u/ilkap2005  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bjjkt/d_run_ai_model_multiple_k80_vs_rtx_4090/",
          "publishedOn": "2023-10-19T13:46:49.000Z",
          "wordCount": 2590,
          "title": "[D] Run AI Model. Multiple k80 vs RTX 4090?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bjexf/d_mlops_tool_for_hyperparametertuning_distributed/",
          "author": null,
          "description": "Currently I train many AI models directly in my Jupyterlab notebooks and do something like hyperparameter tuning, evaluation of losses/accuracy directly in the notebook using lists and matplotlib. I want to finally switch to a MLOPs webUI and have discovered tools like ClearML and Determined.Ai.\n ​\n Each of these GUIs has certain advantages/disadvantages for me and therefore I would like to hear from the community how you do it, which tools you use, if you do it alone or in a team and how your workflow is.\n Until now I often had the impression that you develop your Jupyternotebook normally, then add a few lines of code for the respective tool and then continue in the UI, but here I lack for example the understanding of how I then jump from the MLOps UI back into the notebook, how I keep them synchronous, if I want to change something fundamental in the code again.\n ​\n Thanks in advance\n    submitted by    /u/Sensitive_Limit1620  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bjexf/d_mlops_tool_for_hyperparametertuning_distributed/",
          "publishedOn": "2023-10-19T13:40:52.000Z",
          "wordCount": 2702,
          "title": "[D] MLOps Tool for Hyperparametertuning, Distributed Training, etc",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bfzxf/r_jointly_training_large_autoregressive/",
          "author": null,
          "description": "In recent years, advances in the large-scale pretraining of language and text-to-image models have revolutionized the field of machine learning. Yet, integrating these two modalities into a single, robust model capable of generating seamless multimodal outputs remains a significant challenge. To address this gap, we present the Joint Autoregressive Mixture (JAM) framework, a modular approach that systematically fuses existing text and image generation models. We also introduce a specialized, data-efficient instruction-tuning strategy, tailored for mixed-modal generation tasks. Our final instruct-tuned model demonstrates unparalleled performance in generating high-quality multimodal outputs and represents the first model explicitly designed for this purpose.\n ​\n https://arxiv.org/abs/2309.15564\n What do you think about this work? Seems pretty huge, they build the first pure autoregressive interleaved text and image generator. Please let me know your opinion on this. Paper by Meta AI.\n    submitted by    /u/Present_Chicken5393  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bfzxf/r_jointly_training_large_autoregressive/",
          "publishedOn": "2023-10-19T10:31:23.000Z",
          "wordCount": 2679,
          "title": "[R] Jointly Training Large Autoregressive Multimodal Models https://arxiv.org/abs/2309.15564",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bfgsj/r_curve_your_enthusiasm_concurvity_regularization/",
          "author": null,
          "description": "Accepted at NeurIPS 2023\n Link: https://arxiv.org/abs/2305.11475\n Authors: Julien Siems, Konstantin Ditschuneit, Winfried Ripken, Alma Lindborg, Maximilian Schambach, Johannes Otterbach, Martin Genzel\n *equal contribution\n Abstract: Generalized Additive Models (GAMs) have recently experienced a resurgence in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear transformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurvity - i.e., (possibly non-linear) dependencies between the features - has hitherto been largely overlooked. Here, we demonstrate how concurvity can severly impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regularizer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicable to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability by eliminating ambiguities due to self-canceling feature contributions. We validate the effectiveness of our regularizer in experiments on synthetic as well as real-world datasets for time-series and tabular data. Our experiments show that concurvity in GAMs can be reduced without significantly compromising prediction quality, improving interpretability and reducing variance in the feature importances.\n Keywords: Interpretable Machine Learning, Generalized Additive Models, Concurvity, Multicollinearity, Regularization, Time-Series Forecasting, Interpretability\n    submitted by    /u/Yossarian_1234  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bfgsj/r_curve_your_enthusiasm_concurvity_regularization/",
          "publishedOn": "2023-10-19T09:55:19.000Z",
          "wordCount": 2745,
          "title": "[R] Curve your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bfg6o/p_strategic_game_datasets_for_enhancing_ai/",
          "author": null,
          "description": "Large dataset release of strategic gameplay from LAION\n https://laion.ai/blog/strategic-game-dataset/\n Dataset Overview\n  \nChess\n  \nThe chess dataset comprises 3.2 billion games, equating to approximately 608 billion individual moves. These games, generated via self-play by the Stockfish engine, emulate a high strategic complexity, reflective of a 2500 Elo rating. Each entry contains detailed move sequences, termination status, and game results.\n  \nRubik's Cube (3x3x3)\n  \nThe rubik's cube dataset features 1.64 billion Rubik's Cube solves, totaling roughly 236.39 billion moves. It provides initial scrambled states and the ensuing solve sequences, offering a complex problem-solving scenario for models to navigate.\n  \nMazes\n  \nThe maze dataset, while smaller at 350,000 mazes, represents over 39.29 billion moves. Each maze is a 30x30 ASCII representation, with solutions derived using the A* algorithm, challenging pathfinding and planning algorithms.\n    submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bfg6o/p_strategic_game_datasets_for_enhancing_ai/",
          "publishedOn": "2023-10-19T09:54:04.000Z",
          "wordCount": 2680,
          "title": "[P] Strategic Game Datasets for Enhancing AI planning: An invitation for collaborative research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bcikh/r_setofmark_som_unleashes_extraordinary_visual/",
          "author": null,
          "description": "We are introducing a magic Set-of-Mark (SoM) prompting for GPT-4V! Simply overlaying a set of marks on the image immediately unleashes the visual grounding power of GPT-4V!\n Left: GPT-4V Default Right: GPT-4V + SoM\n Many people including myself have been impressed by the general intelligence to understand images, but also questioning its visual grounding capability. After spending the last week or two, I am really shocked by the power of GPT-4V after plugging our SoM prompting. It can not only do a lot of fine-grained vision tasks but also can perform visual reasoning and project its world knowledge to the visual inputs! To extract meaningful regions, we compiled a new SoM toolbox with a number of interactive image segmentation tools, like our own MaskDINO, SEEM, Semantic-SAM, and also SAM…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bcikh/r_setofmark_som_unleashes_extraordinary_visual/",
          "publishedOn": "2023-10-19T06:26:57.000Z",
          "wordCount": 2970,
          "title": "[R] Set-of-Mark (SoM) Unleashes Extraordinary Visual Grounding in GPT-4V",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17bayor/r_mamba_lineartime_sequence_modeling_with/",
          "author": null,
          "description": "submitted by    /u/LABTUD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17bayor/r_mamba_lineartime_sequence_modeling_with/",
          "publishedOn": "2023-10-19T04:48:45.000Z",
          "wordCount": 2552,
          "title": "[R] Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17b2lk5/d_combining_data_transformation_and_scaling/",
          "author": null,
          "description": "I am cleaning a dataset for a (macro-economic) demand forecast, and I'm wondering when one should apply data transformation. When is it recommended to include Box-Cox or Yeo-Johnson, and how should we choose between the two? How does it effect the feature selection or model performance? \n Additionally, how should we select the appropriate scaling technique (normalizing, standardizing, min-max) and does the order in which we transform and scale matter for our data? \n Is there any recommended literature on this? \n    submitted by    /u/Ambitious-Pay6329  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17b2lk5/d_combining_data_transformation_and_scaling/",
          "publishedOn": "2023-10-18T21:58:32.000Z",
          "wordCount": 2630,
          "title": "[D] Combining data transformation and scaling techniques",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17azoic/d_gpucompatible_snnlibraries_in_2023/",
          "author": null,
          "description": "Hello, \n I am currently using snnTorch for a video classification task and I achieve fine results, however the training process is really, really slow. I was hoping to utilize my GPU for this task, and while there seem to be alternatives I was hoping to see if anyone will vouch for any of these, or different one:\n https://github.com/norse/norse\n https://github.com/BindsNET/bindsnet\n https://github.com/fangwei123456/spikingjelly\n https://github.com/UCI-CARL/CARLsim6 \n My priorities are in order:\n Windows support\n Potential transferability to in-memory compute hardware\n PyTorch compability\n    submitted by    /u/SlayahhEUW  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17azoic/d_gpucompatible_snnlibraries_in_2023/",
          "publishedOn": "2023-10-18T19:53:25.000Z",
          "wordCount": 2618,
          "title": "[D] GPU-compatible SNN-libraries in 2023?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17aycuw/r_meta_ai_towards_a_realtime_decoding_of_images/",
          "author": null,
          "description": "Brain decoding tech has improved a lot recently thanks to AI/ML, enabling reading out visual perceptions from fMRI brain scans. But fMRI is too slow for real-time BCIs.\n A new study from Meta's AI research team pushes brain reading into real-time using MEG, which measures whole-brain activity at super-fast millisecond resolution.\n They built a 3-part pipeline to decode MEG signals:\n  \nEmbed images into latent spaces using pretrained models like CLIP.\n Train MEG-specific ConvNet to predict embeddings from MEG data.\n Generate images from MEG embeddings with diffusion model.\n  \nThey tested it on 20k+ natural images. MEG decoding was 7X better than old methods, hitting 70% top-5 accuracy in retrieving the right images.\n Generated images matched semantics decently but lacked fine visual details compared to fMRI. MEG seems more focused on high-level category info whereas fMRI captures more low-level features.\n This could enable visual BCIs for paralysis, etc. ... honestly, a world where we can decode brain images in real time is pretty crazy. The findings also raise some important ethical considerations around privacy of decoded mental content... (wow, that was a weird sentence to write!).\n TLDR: New MEG pipeline decodes dynamic visual data from brain activity in real-time. Good but not yet photorealistic-quality image generation.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17aycuw/r_meta_ai_towards_a_realtime_decoding_of_images/",
          "publishedOn": "2023-10-18T18:56:52.000Z",
          "wordCount": 2766,
          "title": "[R] Meta AI: Towards a Real-Time Decoding of Images from Brain Activity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17axy41/d_can_someone_eli5_the_birch_clustering_algorithm/",
          "author": null,
          "description": "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html\n I'm looking at the parameters here and I'm confused on how there is no distance metric? What is assumed about the data going in if there is no distance metric or precomputed distance option?\n For example, can I run this with binary data (1/0), what about data w/ missing values? Does it assume the samples are normally distributed?\n    submitted by    /u/o-rka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17axy41/d_can_someone_eli5_the_birch_clustering_algorithm/",
          "publishedOn": "2023-10-18T18:39:30.000Z",
          "wordCount": 2611,
          "title": "[D] Can someone ELI5 the birch clustering algorithm?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17av3qp/r_xval_a_continuous_number_encoding_for_large/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.02989\n Twitter discussion: https://x.com/andrew_n_carr/status/1714326003030638848?s=20 \n Shows in my opinion that tokenizers are clouding the understanding of LLMs and that using the data directly is better. https://x.com/karpathy/status/1657949234535211009?s=20 Karpathy thinks the same! \n Abstract:\n  \nLarge Language Models have not yet been broadly adapted for the analysis of scientific datasets due in part to the unique difficulties of tokenizing numbers. We propose XVAL, a numerical encoding scheme that represents any real number using just a single token. XVAL represents a given real number by scaling a dedicated embedding vector by the number value. Combined with a modified number-inference approach, this strategy renders the model end-to-end continuous when considered as a map from the numbers of the input string to those of the output string. This leads to an inductive bias that is generally more suitable for applications in scientific domains. We empirically evaluate our proposal on a number of synthetic and real-world datasets. Compared with existing number encoding schemes, we find that XVAL is more token-efficient and demonstrates improved generalization.\n  \nhttps://preview.redd.it/qq8u066smzub1.jpg?width=1344&format=pjpg&auto=webp&s=498be8488c00147f0a7443050519dcf535fae126\n https://preview.redd.it/dxqd4wpsmzub1.jpg?width=1499&format=pjpg&auto=webp&s=266689a80b31cb31fdc4167043f7abdb4f683100\n https://preview.redd.it/0yy93xpsmzub1.jpg?width=1497&format=pjpg&auto=webp&s=b5eae8b958f03afc3c8c85a95c115e48aed1d06e\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17av3qp/r_xval_a_continuous_number_encoding_for_large/",
          "publishedOn": "2023-10-18T16:38:15.000Z",
          "wordCount": 2738,
          "title": "[R] xVal: A Continuous Number Encoding for Large Language Models - The Polymathic AI Collaboration 2023 - Using the numbers directly instead of tokenizing them increases performance significantly!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17au0w8/p_a_guide_to_building_llmbased_applications_with/",
          "author": null,
          "description": "Have you ever wondered about how to take advantage of the power of large language models (LLMs) and Generative AI at the edge? \n Our latest blog, A Guide to Building LLM-Based Applications with Code Llama, shows you how you can use Code Llama on an edge device to build a customized dashboard application. This tutorial shows how Code Llama can empowering analysts in remote, restricted environments to build applications in environments with minimal connectivity and compute capacity. \n In this tutorial, we’ll walk you through how to run code Llama on an edge device in a remote location to build a customized dashboard application.\n    submitted by    /u/modzykirsten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17au0w8/p_a_guide_to_building_llmbased_applications_with/",
          "publishedOn": "2023-10-18T15:52:14.000Z",
          "wordCount": 2657,
          "title": "[P] A Guide to Building LLM-Based Applications with Code Llama",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17atob7/r_llms_can_threaten_privacy_at_scale_by_inferring/",
          "author": null,
          "description": "Our latest research shows an emerging privacy threat from LLMs beyond training data memorization. We investigate how LLMs such as GPT-4 can infer personal information from seemingly benign texts. The key observation of our work is that the best LLMs are almost as accurate as humans, while being at least 100x faster and 240x cheaper in inferring such personal information. \n We collect and label real Reddit profiles, and test the LLMs capabilities in inferring personal information from mere Reddit posts, where GPT-4 achieves >85% Top-1 accuracy. Mitigations such as anonymization are shown to be largely ineffective in preventing such attacks. \n Test your own inference skills against GPT-4 and learn more: https://llm-privacy.org/\n Arxiv paper: https://arxiv.org/abs/2310.07298\n WIRED article: https://www.wired.com/story/ai-chatbots-can-guess-your-personal-information/\n    submitted by    /u/bmislav  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17atob7/r_llms_can_threaten_privacy_at_scale_by_inferring/",
          "publishedOn": "2023-10-18T15:36:53.000Z",
          "wordCount": 2674,
          "title": "[R] LLMs can threaten privacy at scale by inferring personal information from seemingly benign texts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17askxp/d_gan_that_manipulates_shape_texture_color/",
          "author": null,
          "description": "I remember seeing a paper on manipulating or changing an objects attributes, it came out rather recently and seemed to work really well. But I just can’t find it anymore.\n All I know of is the „Counterfactual Generative Networks“ by A. Sauer & A. Geiger (2020) \n I’d really appreciate it if anyone can share similar work. Especially if causally motivated\n    submitted by    /u/Glittering_teapot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17askxp/d_gan_that_manipulates_shape_texture_color/",
          "publishedOn": "2023-10-18T14:48:32.000Z",
          "wordCount": 2613,
          "title": "[D] GAN that manipulates shape, texture, color, position, angle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17asij6/p_best_way_to_create_a_custom_chatbot_from/",
          "author": null,
          "description": "Hello fellow Redditors!\n I am looking for some guidance on creating a custom chatbot using my own data, which is currently in PDF format. I've explored various options like Azure, Pinecone, and I've heard about the AskYourPDF API, but I'm not sure which one would be the best fit for my project.\n I want to keep things simple, so I'm reaching out to the community to ask for recommendations or advice on the easiest and most effective way to build a website with a personalized chatbot. If you have experience with similar projects or know about user-friendly tools or platforms, please share your insights.\n I appreciate any suggestions, tips, or pointers you can provide. Thank you in advance for your help!\n TL;DR: Need advice on the simplest way to create a website with a personalized chatbot using my own data (PDF format). Seeking recommendations and tips from the community. \n ​\n Thank you!\n    submitted by    /u/Huge-Number-4299  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17asij6/p_best_way_to_create_a_custom_chatbot_from/",
          "publishedOn": "2023-10-18T14:45:25.000Z",
          "wordCount": 2708,
          "title": "[P] Best Way to Create a Custom Chatbot from Personal Data (PDF, etc.)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17apx1w/p_where_do_i_gather_the_dataset_for_my_fyp/",
          "author": null,
          "description": "I am doing a Machine Learning project for my FYP; I haven't worked on any ML project yet but I am excited about it. It is related to voice/facial emotion detection. is there any platform that provides datasets for ml projects? Like without any copyright issues (if that's even a thing in ml datasets idk?) A total beginner here.\n    submitted by    /u/fewdiepie_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17apx1w/p_where_do_i_gather_the_dataset_for_my_fyp/",
          "publishedOn": "2023-10-18T12:45:16.000Z",
          "wordCount": 2613,
          "title": "[P] Where do I gather the dataset for my FYP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ap687/p_i_made_a_finetune_of_codellama_to_resolve_merge/",
          "author": null,
          "description": "I made a finetune of CodeLlama-7b for resolving merge conflicts following up on an IEEE study from 2022. The demo is here if anyone wants to check it out and give some feedback. It would help a ton for future versions improving the dataset and going forward with the 13b and 34b models\n    submitted by    /u/codys12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ap687/p_i_made_a_finetune_of_codellama_to_resolve_merge/",
          "publishedOn": "2023-10-18T12:06:28.000Z",
          "wordCount": 2608,
          "title": "[P] I made a finetune of CodeLlama to resolve merge conflicts!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17aolmo/discussion_how_much_error_should_i_apply_when/",
          "author": null,
          "description": "hi there\n ​\n i'm trying to build a small ai that formats texts.\n ​\n of course the current formatting applications applied on ide, search engine, ms softwares, notetaking apps are well functioning, but this is more for educational purpose & self interest.\n ​\n since i don't have infinite amount of time and money, i'm thinking of using open sourced text data and generate synthetic data using gpt3.5 or somekind of algorithm to unformat them.\n ​\n so this is the part where i'm stuck. when adding some errors such as inappropriate multilines, tabs, typos, how much should i add on to?\n ​\n it would be best if i knew somekind of distribution of text errors people make on everyday life, but i don't have any.\n ​\n i don't want to make this training too hard so i'm not really thinking to destroy the text, but rather add some appropriate level of errors.\n ​\n but, would it help this ai model to learn better if i add extra errors?\n ​\n or is this all just something i would have to figure out by myself?\n ​\n any comments would be appreciated!\n    submitted by    /u/Strange_Dog8104  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17aolmo/discussion_how_much_error_should_i_apply_when/",
          "publishedOn": "2023-10-18T11:36:37.000Z",
          "wordCount": 2735,
          "title": "[Discussion] how much 'error' should i apply when training with synthetic data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17an3jy/r_opensource_video_translate_solutions/",
          "author": null,
          "description": "Hi there!\n are there any open-source solutions for video translation? i mean replacing video's audio stream with translated one in different language (which is in sync with the picture) - not necessarily alter mouth movements in the video.\n    submitted by    /u/curryprogrammer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17an3jy/r_opensource_video_translate_solutions/",
          "publishedOn": "2023-10-18T10:05:33.000Z",
          "wordCount": 2587,
          "title": "[R] Open-source video translate solutions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17alyw5/research_literature_survey_query/",
          "author": null,
          "description": "Survey papers\n Hi all,\n First time posting here. I am doing my PhD in Language Conditioned Robotics. I am currently writing a literature review paper on the current state of the field and how it can be further improved. I am covering topics such as generative AI and LLMs in there. \n I would be more than grateful if you could send some literature review papers in the field of ML so I understand how to structure and write my paper and also what I should focus on mode. It doesn't necessarily have to be related to my PhD topic (but if they are it will help quite a bit). \n I would be more than happy if anyone can also share their experience.\n Thank you for your time!\n    submitted by    /u/bizzonkiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17alyw5/research_literature_survey_query/",
          "publishedOn": "2023-10-18T08:48:21.000Z",
          "wordCount": 2675,
          "title": "[Research] Literature survey query",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17al6qc/d_what_are_some_of_the_best_library_frameworks_to/",
          "author": null,
          "description": "Hey guys, what are some of the best library or libraries to use to make a voice conservational AI chatbot? \n I googled around and found Vocode. They look pretty good. However Vocode rely on several other (paid) closed sourced libraries such as Deepgram (for transcribing) and Azure AI Speech (for synthesising). Are there any other libraries/frameworks available out there which are completely or more open sourced?\n    submitted by    /u/redd-dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17al6qc/d_what_are_some_of_the_best_library_frameworks_to/",
          "publishedOn": "2023-10-18T07:51:39.000Z",
          "wordCount": 2627,
          "title": "[D] What are some of the best library frameworks to use for speech2text and text2speech AI chatbot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ajv1s/r_efficient_streaming_language_models_with/",
          "author": null,
          "description": "submitted by    /u/Username912773  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ajv1s/r_efficient_streaming_language_models_with/",
          "publishedOn": "2023-10-18T06:19:59.000Z",
          "wordCount": 2552,
          "title": "[R] EFFICIENT STREAMING LANGUAGE MODELS WITH ATTENTION SINKS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ahpzu/6dof_sim_rl_capability_p/",
          "author": null,
          "description": "I have a 6DOF simulink model of a Autonomous underwater vehicle that has properties [u v w p q r x y z phi theta psi] and two inputs [theta1 theta2] that govern the angle of control surfaces. Ocean current and depth are taken into account. \n How feasible would it be to use RL to reach waypoints at various [x, y, z] positions? I don’t want to use a PID controller or anything, not even RL to tune a controller. The agent would choose the theta inputs directly. I have a feeling hyper paremeter tuning might play a larger role in this? I expect training times to increase exponentially as well? \n I have done this using a single randomly spawned waypoint with a simple Unicycle Kinematic model, in both simulink/matlab and python with a vectorized/parallel environment using SB3/PettingZoo/Gym.\n    submitted by    /u/VisionZUS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ahpzu/6dof_sim_rl_capability_p/",
          "publishedOn": "2023-10-18T04:06:00.000Z",
          "wordCount": 2687,
          "title": "6DOF Sim RL Capability [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ah5z8/r_bitnet_scaling_1bit_transformers_for_large/",
          "author": null,
          "description": "Arxiv link – BitNet: Scaling 1-bit Transformers for Large Language Models\n  \nIn this work, we introduce BitNet, a scalable and stable 1-bit Transformer architecture designed for large language models. Specifically, we introduce BitLinear as a drop-in replacement of the nn.Linear layer in order to train 1-bit weights from scratch. Experimental results on language modeling show that BitNet achieves competitive performance while substantially reducing memory footprint and energy consumption, compared to state-of-the-art 8-bit quantization methods and FP16 Transformer baselines. Furthermore, BitNet exhibits a scaling law akin to full-precision Transformers, suggesting its potential for effective scaling to even larger language models while maintaining efficiency and performance benefits.\n  \n   submitted by    /u/PantsuWitch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ah5z8/r_bitnet_scaling_1bit_transformers_for_large/",
          "publishedOn": "2023-10-18T03:35:12.000Z",
          "wordCount": 2658,
          "title": "[R] BitNet: Scaling 1-bit Transformers for Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17af6y2/p_achieving_peak_performance_on_gpu/",
          "author": null,
          "description": "Hi r/MachineLearning! I recently went into the CUDA programming rabbit hole. In the process, I came across matrix multiplication and was amazed by how complicated the algorithm is in CUDA (especially if you want to get the best performance). I found the learning process quite gruelling (the CUDA docs were very average), so I wrote a tiny blog which hopefully helps anyone in the same position.\n You can read the blog on Medium (no paywall) or HackMD. It would probably be quite useful if you want to get a deeper intuition of how things like OpenAI Triton or FlashAttention work under the hood.\n Accompanying this is an implementation of a 3-hidden-layer MLP trained on MNIST in pure CUDA. Benchmarking this against PyTorch, it gets up 6x higher end-to-end training speed for small (h=128) networks, and asymptotically 20% faster for large (h=8192) ones! \n https://preview.redd.it/txx2txbvlzub1.png?width=2400&format=png&auto=webp&s=7bb136b9fb535bc58fd7ee809bbbca6f68dc8953\n It's worth noting that I tried reasonably hard optimising the PyTorch implementation by using full fp16, torch.compile with fullgraph=True, mode=\"max-autotune\", and pre-loading all data to GPU up-front (I also did this for the CUDA implementation).\n The main takeaways I got are:\n  \nFor small networks, PyTorch/Python still incurs a significant overhead, even if you try pretty hard to optimise it.\n For large networks, most of the speedup comes from using fp16 accumulation for matrix multiplication (instead of PyTorch's fp32). This obviously reduces stability, but at least in my case, I didn't observe any numerical issues. In cases where we can get away with fp16, we might be leaving a significant amount of performance on the table!\n Anecdotally, you have to try really hard in CUDA to even get close to the performance of PyTorch, but it is possible to beat it if you try hard (suffer) enough.\n  \nYou can check out the repo here: https://github.com/andylolu2/cuda-mnist. Would love to hear some feedback!\n    submitted by    /u/bjergerk1ng  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17af6y2/p_achieving_peak_performance_on_gpu/",
          "publishedOn": "2023-10-18T01:56:35.000Z",
          "wordCount": 2852,
          "title": "[P] Achieving peak performance on GPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17ac43p/roughly_how_much_time_will_a_task_running_on_a/",
          "author": null,
          "description": "Anyone have examples of tasks run between the two? Doesn't need to be exact.\n    submitted by    /u/Apita2000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17ac43p/roughly_how_much_time_will_a_task_running_on_a/",
          "publishedOn": "2023-10-17T23:32:57.000Z",
          "wordCount": 2541,
          "title": "Roughly how much time will a task running on a RTX 3060 take VS a ~i7 CPU? [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17abc2d/d_feedback_on_my_mvp_project_prerecorded/",
          "author": null,
          "description": "Hey!\n ​\n Startup:\n - Apply Script dot com \"Connect business and data professionals via pre-recorded standardized video interviews.\"\n ​\n More details:\n ​\n Problems with Traditional Hiring\n ​\n - Outdated: The current method of conducting interviews has become overly complex and outdated.\n - Time-Wasting: The process involves too many appointments, meetings, and stages, leading to communication errors.\n - Expensive: The man-hours invested by HR and engineering teams are costly.\n - Constraining: Interviews are fixed to specific times and locations.\n - Cumbersome: The experience is challenging for both businesses and professionals.\n ​\n Our Solution\n ​\n + Talent Identification: We find top talent that matches your job post.\n + Standardized Interviews: Professionals standardized pre-record their …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17abc2d/d_feedback_on_my_mvp_project_prerecorded/",
          "publishedOn": "2023-10-17T22:57:52.000Z",
          "wordCount": 2814,
          "title": "[D] Feedback on my MVP project - Pre-Recorded Standardized Video Interviews Job Site for Data Professionals",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17aaktm/d_help_identifying_research_papers_for_online/",
          "author": null,
          "description": "So my situation is that I have a pretrained model and we get a new update of data every month (note: this monthly data is very small compared to the original dataset, the original dataset was about 5 years worth, or ~60x the size of any given monthly update), how can I update my pretrained model on the much smaller set of new data, learning from the data without overfitting to that data?\n Or frankly, what would be better if it is possible, would be to extend my pretrained model such that it learns from the new data and then can be more tightly fit to that month's data. So something like meta-learning or local fine-tuning, but I want to continue to update and improve my pretrained model so that I have a base model that can do well on each month's new data. Does anyone know anything like this, or have advance for terms to look into, beyond just transfer learning or regularization?\n    submitted by    /u/Amun-Aion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17aaktm/d_help_identifying_research_papers_for_online/",
          "publishedOn": "2023-10-17T22:24:44.000Z",
          "wordCount": 2685,
          "title": "[D] Help identifying research papers for online / cyclic / sequential learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17aa9yv/how_to_properly_implement_covers_theorem_in_an/",
          "author": null,
          "description": "Maybe this belongs elsewhere since it's probably a dumb basic question, but basically I'm taking an undergrad course in AI and we've been given a classification problem. We were told as a \"hint\" to recall Cover's Theorem when separation fails, but the issue is she also wants us to draw a rough sketch of the data with the separator. Mine failed in a basic scatterplot so I upped the dimension by 1 but it also wasn't separable in R3 (which is annoying to draw anyway but could have been done), if I keep going then it might work at some point but idk how I'm meant to draw the data if it's separated in R4 or beyond. If it works in R4 do I just sketch the data in R3 and just draw a 3 dimensional point where w = 0? But even then if it goes beyond R4 it becomes way more annoying. So I'm assuming my implementation is just wrong, maybe the formula I used was wrong.\n Can someone show what a proper implementation looks like and how we're meant to up dimensions? Don't wanna post what I tried bc it has starter code and stuff baked into it which might allow my professor to find this post 😂\n    submitted by    /u/Traditional_Land3933  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17aa9yv/how_to_properly_implement_covers_theorem_in_an/",
          "publishedOn": "2023-10-17T22:11:34.000Z",
          "wordCount": 2730,
          "title": "How to properly implement Cover's Theorem in an SVM? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a91sh/d_cross_entropy_classification_vs_metric_learning/",
          "author": null,
          "description": "Hi guys. We've all seen how hot RAG and vector DBs have been lately. How good are retrieval-based approaches for image classification?\n More concretely: Suppose we have a network trained with metric learning and a massive, diverse set of labelled examples to retrieve from. We've just been tasked to do classification with a fixed number of classes, and we've narrowed it down to two options:\n  \nEmbed our dataset using our metric learning network, throw the embeddings into a vector DB, and do k-NN\n Train a classifier via cross-entropy loss\n  \nWhich approach would we expect to provide better performance? What are the trade-offs? Any insight is appreciated!\n    submitted by    /u/supersmartypants  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a91sh/d_cross_entropy_classification_vs_metric_learning/",
          "publishedOn": "2023-10-17T21:20:12.000Z",
          "wordCount": 2621,
          "title": "[D] Cross Entropy Classification vs Metric Learning + k-NN for image classification?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a7q2o/d_graph_neural_networks_links_prediction_task_on/",
          "author": null,
          "description": "Hi guys, I have the following use case at hand for my thesis, and I'd like to ask for some help to formulate my problem:\n  \nA directed multigraph (1 node type, multiple edge types)\n Each node and edge have their own attributes\n A set of graphs that are fully labeled. The dataset is self-created according to some technical rules. Training is supposed to be done on this dataset.\n  \nMy task is to perform link prediction in the inductive setting. This means that given an unseen incomplete graph at the inference time, the model should be able to predict all the missing links. I have read many papers and tried to formulate my problem in many directions. Since I am also new to GNNs, I would prioritize papers with an existing codebase and sound theoretical justifications for the techniques (which …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a7q2o/d_graph_neural_networks_links_prediction_task_on/",
          "publishedOn": "2023-10-17T20:23:21.000Z",
          "wordCount": 3057,
          "title": "[D] Graph Neural Networks - Links Prediction Task on Directed, Heterogenous Multigraphs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a775d/trouble_improving_accuracy_in_face_recognition/",
          "author": null,
          "description": "Hey everyone\n Im trying my hands with the The Labeled Faces in the Wild face recognition dataset, for a face recognition task. I have made a siamesemodel, and my loss curve is looking great but my accuracy stays at 0.500, for everything i have tried. Is there anybody in here that have tried their hands with this task before that can give me some tips to improve my accuracy. I am implementing it in python with PyTorch btw\n Thanks in advance!\n    submitted by    /u/Due_Concentrate1279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a775d/trouble_improving_accuracy_in_face_recognition/",
          "publishedOn": "2023-10-17T20:00:39.000Z",
          "wordCount": 2598,
          "title": "Trouble improving accuracy in face recognition dataset [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a5gr8/how_valuable_is_a_phd_in_science_with_applied_ml/",
          "author": null,
          "description": "Is it more advantageous to pursue a PhD in machine learning with a focus on scientific applications for example (Machine learning for drug design) if the end goal is to work in the machine learning industry? Or is a general PhD in machine learning more valuable for this career path?\n Thank you\n    submitted by    /u/Neat-Print2792  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a5gr8/how_valuable_is_a_phd_in_science_with_applied_ml/",
          "publishedOn": "2023-10-17T18:45:27.000Z",
          "wordCount": 2580,
          "title": "How valuable is a PhD in science (with applied ML) compared to a PhD in only Machine learning [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a31qb/r_85_of_the_variance_in_language_model/",
          "author": null,
          "description": "TL;DR and paper link are at the bottom of the post.\n I'm an undergrad who just wrote my first paper completely solo. Crazy experience with so many highs and lows, but I learned a lot from it. I think the results are important and I want people to see them, so I'll try to walk through the paper here as best as I can. I also have a small request for Arxiv enjoyers at the end.\n Given the nature of Reddit posts, I'll focus a bit less on the methods and more on the results. I won't cite stuff here either, but obviously you can find citations in the paper.\n First I'll give a small bit of historical context to what I'm doing, then walk through what I did and what came of it.\n Enjoy the read.\n The general intelligence factor in humans\n In the early 1900s, Charles Spearman observed that children's …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a31qb/r_85_of_the_variance_in_language_model/",
          "publishedOn": "2023-10-17T17:00:26.000Z",
          "wordCount": 4057,
          "title": "[R] 85% of the variance in language model performance is explained by a single factor (g, a unified measure of LLM ability)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a0wtx/d_how_to_design_api_of_machine_learning_library/",
          "author": null,
          "description": "In the past nine years of my deep learning journey, I have come across a vast number of frameworks. Lua Torch was a fantastic framework that initially died due to a lack of Python's ecosystem, but then rose again as PyTorch. Theano was also a great framework, but its major drawback was difficult debugging. I remember spending two weeks writing a Neural Turing Machine for solving bAbI tasks on theano. (Nowadays, it would take a couple hours on Pytorch). Tensorflow - I still don't understand what that was, a terrible framework. There was also Caffe, which was popular in computer vision. Julia is another language that attempted to introduce automatic differentiation as a built-in feature. And JAX, which I was originally biased against since it's a Google product. But some close friends persuaded me to try it, and I actually liked it. However, I thought that it would be difficult for JAX to gain widespread adoption in the community, as PyTorch already had a strong network effect and was gaining traction quickly. I didn't see how anyone could catch up with PyTorch. Another issue with JAX is that it requires additional cognitive load for developers.\n Take a look: https://higgsfield.substack.com/p/how-to-design-api-of-machine-learning\n    submitted by    /u/Good-Willingness-985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a0wtx/d_how_to_design_api_of_machine_learning_library/",
          "publishedOn": "2023-10-17T15:25:18.000Z",
          "wordCount": 2717,
          "title": "[D] How to design API of Machine learning library",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17a0b0d/p_2d_gaussian_splatting_a_great_starting_point/",
          "author": null,
          "description": "Github : https://github.com/OutofAi/2D-Gaussian-Splatting\n https://i.redd.it/cwgsjtko1sub1.gif\n    submitted by    /u/TerryCrewsHasacrew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17a0b0d/p_2d_gaussian_splatting_a_great_starting_point/",
          "publishedOn": "2023-10-17T14:58:41.000Z",
          "wordCount": 2527,
          "title": "[P] 2D Gaussian Splatting a great starting point for people who want to delve deeper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179zlrl/d_how_to_build_data_products_deploy_part_34/",
          "author": null,
          "description": "Data products plays an important role in building state of the art machine learning models. Though their building process seems a bit confusing within industry as of now, this article series tries to simplify it by breaking it and explaining it into 4 steps. Take a look: https://moderndata101.substack.com/p/how-to-build-data-products-deploy\n What processes are being followed at your org for building scalable data products?\n    submitted by    /u/growth_man  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179zlrl/d_how_to_build_data_products_deploy_part_34/",
          "publishedOn": "2023-10-17T14:26:23.000Z",
          "wordCount": 2595,
          "title": "[D] How to Build Data Products? Deploy: Part 3/4 - Doubling down on the power of Unified Experiences for building state of the art models.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179z3d0/shared_public_contextual_database_for_rag_d/",
          "author": null,
          "description": "Hey Guys,\n It seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo'd vector dbs. \n Do you guys think there's any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone's raving about today) \n - \n For context, I'm building a social media product we're users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche's classification string. Essentially we're aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. \n    submitted by    /u/niksteel123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179z3d0/shared_public_contextual_database_for_rag_d/",
          "publishedOn": "2023-10-17T14:02:52.000Z",
          "wordCount": 2743,
          "title": "Shared Public Contextual Database for RAG [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179wvu8/d_work_regarding_using_llms_to_generate_data_for/",
          "author": null,
          "description": "Hi. I'm curious if there have been any studies done regarding the effects of using data generated by LLMs for other downstream tasks. The closest that I could find are the two papers:\n  \nLarge Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias (Yu et al., 2023)\n Generating Training Data with Language Models: Towards Zero-Shot Language Understanding (Meng et al., 2022)\n  \nThe former focuses on studying the differences between the type of prompts that are used to generate the data and the latter doesn't use LLMs.\n Doesn't have to be papers, blog posts or any sort of information regarding the scenario I described is fine. Thanks.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179wvu8/d_work_regarding_using_llms_to_generate_data_for/",
          "publishedOn": "2023-10-17T12:09:53.000Z",
          "wordCount": 2630,
          "title": "[D] Work regarding using LLMs to generate data for downstream tasks.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179wr0u/d_embedding_models_in_productioncpu_w_high/",
          "author": null,
          "description": "Hello,\n I am working on an app that requires creating lots of text embeddings(100M tokens).\n Looking at OpenAI Ada pricing(and considering that my app doesn't yet make any money) I'm looking into self-hosting a model to run on CPU. \n I know that constrains me towards smaller models-- so far locally I've been testing with sentence-transformers/all-MiniLM-L6-v2 and the query results seem okay-ish enough for my MVP. (Although, I should not that I haven't compared how embeddings with other models would perform.)\n Does anyone have experiences doing something similar? In particular, I'd love to hear about any tips you have for maximizing no. of embeddings / second.\n (new to ML/MLOps, so apologies if this is a silly question :)\n    submitted by    /u/rsamrat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179wr0u/d_embedding_models_in_productioncpu_w_high/",
          "publishedOn": "2023-10-17T12:02:17.000Z",
          "wordCount": 2634,
          "title": "[D] Embedding models in production(CPU w/ high throughput)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179vq4v/n_introducing_stable_fast_an_ultra_lightweight/",
          "author": null,
          "description": "What is this?\n stable-fast is an ultra lightweight inference optimization library for HuggingFace Diffusers on NVIDIA GPUs. stable-fast provides super fast inference optimization by utilizing some key techniques and features:\n  \nCUDNN Convolution Fusion: stable-fast implements a series of fully-functional and fully-compatible CUDNN convolution fusion operators for all kinds of combinations of Conv + Bias + Add + Act computation patterns.\n Low Precision & Fused GEMM: stable-fast implements a series of fused GEMM operators that compute with fp16 precision, which is fast than PyTorch's defaults (read & write with fp16 while compute with fp32).\n NHWC & Fused GroupNorm: stable-fast implements a highly optimized fused NHWC GroupNorm + GELU operator with OpenAI's triton, which eliminates the need…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179vq4v/n_introducing_stable_fast_an_ultra_lightweight/",
          "publishedOn": "2023-10-17T11:00:33.000Z",
          "wordCount": 2845,
          "title": "[N] Introducing Stable Fast: An ultra lightweight inference optimization library for HuggingFace Diffusers on NVIDIA GPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179vkv6/r_does_the_flan_t5_decoder_take_the_question_as/",
          "author": null,
          "description": "Hello,\n I was looking at the Flan T5 paper and code. It was clear that the question (instruction) and the context are given to the encoder as input. But I find no details on what does the decoder take as input apart from the fact that it starts with the pad token. Anyone can give me more details please ?\n Thanks !\n    submitted by    /u/Meddhouib10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179vkv6/r_does_the_flan_t5_decoder_take_the_question_as/",
          "publishedOn": "2023-10-17T10:51:09.000Z",
          "wordCount": 2583,
          "title": "[R] Does the Flan T5 decoder take the question as input ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179uwbq/d_tensorflowjs_and_state_of_the_ecosystem_for/",
          "author": null,
          "description": "I am curious about the state of the ecosystem for JavaScript, where TF looks like a reasonably solid option.\n Options I have found so far are:\n  \nTensorFlow.js (looks like the most complete solution, but the general sentiment about TF in Python is pretty bad!)\n MediaPipe (to quickly implement specific use cases it seems, maybe using tf.js in the background?)\n ml5.js (a layer on top of tf.js to make it more approachable if i understand correctly)\n transformers.js (haven't quite grasped this one)\n shumai (bun only, so server side only)\n  \nI am curious to read informed opinions about these and more! Have you used them and how?\n ​\n    submitted by    /u/gtnbssn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179uwbq/d_tensorflowjs_and_state_of_the_ecosystem_for/",
          "publishedOn": "2023-10-17T10:06:42.000Z",
          "wordCount": 2623,
          "title": "[D] TensorFlow.js and state of the ecosystem for JavaScript",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179ttqy/d_which_raw_opss_benchmarks_best_reflect_mldl/",
          "author": null,
          "description": "Hi all. I'm preparing an open website about products used for AI/ML/DL computation (no in-house testing for now, just the database and GUI). However comparing raw speed of products of different vendors is more challenging than I anticipated, because there are many possible raw performance indicators, only few of which are provided by vendors.\n For example a raw performance indicator can be \"FP32 vector with opportunistic optimization\", while another can be \"BF16 matrix/tensor without opportunistic optimization\". A full picture of raw performance would be fully represented only by a table with multiple dimensions:\n  \nNumber format (FP64, FP32, TF32, FP16, BF16, FP8, INT8, INT4... are the others?)\n Vector vs. matrix/tensor operation (boolean)\n Opportunistic optimizations like Nvidia Sparsity…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179ttqy/d_which_raw_opss_benchmarks_best_reflect_mldl/",
          "publishedOn": "2023-10-17T08:49:19.000Z",
          "wordCount": 2828,
          "title": "[D] Which raw OPS/s benchmarks best reflect ML/DL workloads?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179seow/d_interesting_loss_graphs/",
          "author": null,
          "description": "Wondering if anyone has some interesting loss graphs that they could share. Maybe loss suddenly dropped after 100 epochs, or a local minima was found and then it jumped into a lower one. Wondering if anyone forgot to turn off training and cam back to an improved result than what they thought had already been converged to. \n    submitted by    /u/HStuart18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179seow/d_interesting_loss_graphs/",
          "publishedOn": "2023-10-17T07:01:53.000Z",
          "wordCount": null,
          "title": "[D] Interesting loss graphs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179j7l3/d_exploring_methods_to_improve_text_chunking_in/",
          "author": null,
          "description": "Hello everyone,\n I'm currently working on Retrieval Augmented Generation (RAG) models and have developed a custom chunking function, as I found the methods in LangChain not entirely satisfactory.\n I'm keen on exploring other methods, algorithms (related to NLP or otherwise), and models to enhance text chunking in RAG. There are many RAG implementations out there, but I've noticed a lack of focus on improving chunking performance specifically.\n Are there any other promising approaches beyond my current pipeline, which consists of a bi-encoder (retriever), cross-encoder (reranker), and a Large Language Model (LLM) for interactions?\n For queries, I'm using both traditional and HyDE (Hypothetical Document Embedding) approaches in the retrieval phase, and sending the top 'n' results of both similarity search to the reranker.\n I've also tried using an LLM to convert the query into a series of 10-20 small phrases or keywords, which are then used as the query for the retriever model. However, the results vary depending on the LLM used. To generate good keywords (with a not extractive approach) , I had to use a \"CoT\" prompt, instructing the model to write self-instruct, problem analysis and reasonings before generating the required keywords. But this approach use lots of tokens, and requires careful scraping to ensure the model has used the right delimiter to separate reasoning and the actual answer.\n I'm also planning to modify the text used to generate embeddings, while returning the original text after the recall phase. But this is still a work in progress and scaling it is proving to be a challenge. If anyone has any tips or experience with this, I'd appreciate your input.\n I'd be grateful for any resources, repositories, libraries, or existing implementations of novel chunking methods that you could share. Or we could just discuss ideas, thoughts, or approaches to improve text chunking for RAG here.\n Thanks in advance for your time!\n    submitted by    /u/BXresearch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179j7l3/d_exploring_methods_to_improve_text_chunking_in/",
          "publishedOn": "2023-10-16T22:49:06.000Z",
          "wordCount": 2838,
          "title": "[D] Exploring Methods to Improve Text Chunking in RAG Models (and other things...)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179htp8/d_rate_my_gpu_server_for_deep_learning/",
          "author": null,
          "description": "I started learning deep learning last year and decided to step up my game with regard to model training and tools.\n I recently built a GPU server. It’s still within its return period, so please help decide if it’s worth keeping:\n Processor: 2x Xeon E5-2690 v4 2.6GHz 14-Core Memory: 128GB GPU: 8x NVIDIA Tesla P100 16GB HBM2 Accelerator Card\n Total cost: ~$3200\n    submitted by    /u/Stonks-Stocks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179htp8/d_rate_my_gpu_server_for_deep_learning/",
          "publishedOn": "2023-10-16T21:50:12.000Z",
          "wordCount": 2584,
          "title": "[D] Rate my GPU server for Deep Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179hkg8/n_how_to_apply_to_grad_school_webinars_by_cmu_ri/",
          "author": null,
          "description": "We are hosting a few \"How to Apply to Grad School\" webinars this week. This is a chance to hear from faculty and students in the Robotics Institute at CMU on what life in grad school is actually like, as well as get some tips on crafting a strong application!\n https://cmu-ri-resources.github.io/\n    submitted by    /u/bart-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179hkg8/n_how_to_apply_to_grad_school_webinars_by_cmu_ri/",
          "publishedOn": "2023-10-16T21:39:45.000Z",
          "wordCount": 2576,
          "title": "[N] \"How to Apply to Grad School\" webinars by CMU RI!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179hgov/r_microsoft_presents_tablegpt_tabletuned_gpt_for/",
          "author": null,
          "description": "Tables pack tons of relational data but are tough for AI to grasp. They have complex 2D structure with information scattered across rows and columns. Models like GPT-3 fail basic tasks like finding where a missing value should go.\n LLMs struggle at this because they're pre-trained mostly on natural text, which is linear. Researchers at Microsoft wanted to mitigate this with \"table-tuned\" models, trained on table-related tasks.\n Their process:\n  \nAutomatically generate lots of diverse table-task training cases from a corpus of real-world tables. Ex: \"impute missing value\" or \"identify error in table\".\n Further augment data via paraphrasing, shuffling table rows/columns, chaining model responses, etc.\n  \nThis table-tuning produced \"Table-GPT\" models with substantially stronger table skills. In experiments, Table-GPT crushed vanilla GPT-3:\n  \n25%+ better on unseen table tasks like missing value ID and column type ID\n Beat GPT-3 on 98% of test cases across 9 different table tasks\n Stayed superior after downstream tuning too\n  \nThere's tons more work to do but seems pretty promising. Table-tuning boosted models' ability to comprehend tables and reason over tabular data vs just pre-training on text.\n TLDR: Training AI models more on synthesized table tasks (\"table-tuning\") significantly improves their table skills.\n Full summary is here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179hgov/r_microsoft_presents_tablegpt_tabletuned_gpt_for/",
          "publishedOn": "2023-10-16T21:35:31.000Z",
          "wordCount": 2719,
          "title": "[R] Microsoft presents Table-GPT: Table-tuned GPT for Diverse Table Tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179gnvn/d_texttopose/",
          "author": null,
          "description": "When are we getting a text-to-pose ai? I'd love to be able to generate poses for 3d models that match a given text description, because sometimes what my mind comes up with doesn't feel adequate.\n It's frustrating that I'm not seeing any developments in this area of ai, and I lack the skills to commence the developments myself.\n    submitted by    /u/BM09  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179gnvn/d_texttopose/",
          "publishedOn": "2023-10-16T21:03:15.000Z",
          "wordCount": 2574,
          "title": "[D] Text-to-pose?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179g07a/r_google_pali3_vision_language_models_contrastive/",
          "author": null,
          "description": "submitted by    /u/currentscurrents  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179g07a/r_google_pali3_vision_language_models_contrastive/",
          "publishedOn": "2023-10-16T20:36:05.000Z",
          "wordCount": 2535,
          "title": "[R] Google Pali-3 Vision Language Models: Contrastive Training Outperforms Classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179errg/d_sources_of_esoteric_data_specifically_looking/",
          "author": null,
          "description": "I am ok with paying for the data. I just can't find any sources for it.\n I found some data on github that appears to come from container ships at port, but nothing for a ship underway.\n    submitted by    /u/jschall2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179errg/d_sources_of_esoteric_data_specifically_looking/",
          "publishedOn": "2023-10-16T19:44:28.000Z",
          "wordCount": 2574,
          "title": "[D] Sources of esoteric data? Specifically looking for 6dof motion data from a medium to large oceangoing vessel underway in various sea states.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179dut0/d_adding_a_modality_to_a_pretrained_model/",
          "author": null,
          "description": "Hi,\n I have a dataset with video and other modalities (e.g. audio), and I want to run a captioning task. I found UniVL, which is a pre-trained model that supports video and text (transcripts) and can caption them. It extracts features and runs transformer encoders on both these modalities to get an embedding, then concatenates them and feeds it into a cross-encoder and decoder to get captions. I'm wondering if I can make use of this model, but add in other modalities, by writing my own embedding model and feeding the embeddings into the cross encoder. Would this work? Is there any similar previous work regarding adding new modalities to a pre-trained network?\n    submitted by    /u/joeswansonx69x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179dut0/d_adding_a_modality_to_a_pretrained_model/",
          "publishedOn": "2023-10-16T19:06:13.000Z",
          "wordCount": 2635,
          "title": "[D] Adding a modality to a pre-trained model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179awrx/d_what_is_the_current_sota_of_neural_architecture/",
          "author": null,
          "description": "I've seen classic papers before 2021 that have been quite influential - RL and evolution based strategies. I have also seen: \n  \ndifferentiable approaches: https://arxiv.org/abs/1806.09055\n zero-learning approaches: https://arxiv.org/abs/2006.04647\n  \nBut these are all papers pre-2021. \n From people who are familiar with this field, what is the current SOTA of neural architecture search (NAS) post 2022? i.e. papers that can serve as the most relevant baselines? \n Thank you! :) \n ​\n ​\n ​\n    submitted by    /u/Cultural-Average3959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179awrx/d_what_is_the_current_sota_of_neural_architecture/",
          "publishedOn": "2023-10-16T17:02:24.000Z",
          "wordCount": 2591,
          "title": "[D] What is the current SOTA of Neural Architecture Search (NAS)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/179ae0r/d_is_active_learning_a_dying_field_in_industry/",
          "author": null,
          "description": "Is active learning a dying topic when zero shot learning came out?\n Active learning is to used few labeled samples plus a initially trained model to select the most useful unlabeled data for training.\n Zero/few shot learning is to train a model on some data then Mae it work directly with unseen label/data. \n In my understanding, zero/few short learning is more aligned with the current large model trend or foundation model trend. Active learning strategy seems to still rely on small dataset and was intending to gradually enrich training data by selecting new samples in.\n In industry and in big tech, which one is more used or deployed? Anyone can give me some comments?\n    submitted by    /u/Little-Bumblebee-452  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/179ae0r/d_is_active_learning_a_dying_field_in_industry/",
          "publishedOn": "2023-10-16T16:41:11.000Z",
          "wordCount": 2639,
          "title": "[D] Is active learning a dying field in industry, given the development in few shot/zero shot learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1799otn/r_decoding_llm_uncertainties_for_better/",
          "author": null,
          "description": "Hi all,\n Building off our last research post, we wanted to figure out ways to quantify \"ambiguity\" and \"uncertainty\" in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: \"Structural\" and \"Conceptual\" uncertainty.\n In a nutshell: Conceptual uncertainty is when the model isn't sure what to say, and Structural uncertainty is when the model isn't sure how to say it.\n You can play around with this yourself in the demo or read about it in more detail in the blog post\n    submitted by    /u/shayanjm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1799otn/r_decoding_llm_uncertainties_for_better/",
          "publishedOn": "2023-10-16T16:11:48.000Z",
          "wordCount": 2605,
          "title": "[R] Decoding LLM Uncertainties for Better Predictability",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1799hwa/d_for_large_datasets_is_your_data_selection/",
          "author": null,
          "description": "I often hear from folks with very large datasets saying: “my labelling costs keep increasing, but we don’t see model performance improvements” or “my storage and compute costs are rising (for a dataset of 1M+ images) but performance just stalled”.\n This post argues that large datasets have hidden costs, beyond time and money, poor data quality and the wrong selection process might be killing model performance. \n Any thoughts? Have you faced this challenge?\n    submitted by    /u/btcmx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1799hwa/d_for_large_datasets_is_your_data_selection/",
          "publishedOn": "2023-10-16T16:03:49.000Z",
          "wordCount": 2599,
          "title": "[D] For large datasets, is your data selection process limiting model performance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1798mkb/p_semanticsearch_for_pdf_mining/",
          "author": null,
          "description": "Hello, everyone! I'm seeking tips to enhance my semantic search pipeline.\n Currently, I'm working on a semantic search tool. Given a set of text files, my goal is to retrieve the most relevant information related to the query.\n To achieve this, I begin by preprocessing the PDF files, splitting them into pages, and computing embeddings using a fine-tuned BERT model for Italian.\n Next, with a query and its embedding, I calculate the cosine similarity to all the pages in the document. Since there aren't many pages, a brute search remains quite fast.\n However, I'm encountering an issue where the similarity results don't consistently yield the most relevant information. I've experimented with various embedding layers, but there's been little to no improvement.\n I've also tested a commercially available solution to ensure the problem isn't with my PDF files. Interestingly, I achieved better results, leading me to believe that the issue may lie within my pipeline.\n My current hypothesis is that the page splitting process might be excluding relevant semantic connections, and I may need to improve my text preprocessing.\n What suggestions do you have to enhance my results?\n P.S.\n The information obtained from the similarity check is subsequently used as context with a chat language model, similar to tools like AsMyPdf.\n    submitted by    /u/AcquaFisc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1798mkb/p_semanticsearch_for_pdf_mining/",
          "publishedOn": "2023-10-16T15:27:04.000Z",
          "wordCount": 2729,
          "title": "[P] SemanticSearch for PDF mining",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1798jz5/d_good_compression_algo_to_compress_model/",
          "author": null,
          "description": "I have a couple of terabytes of checkpoints, and I desperately need to free up some space, without deleting those atm. Is there a compression algorithm that can handle such data successfully? I tried gzip with tar but the compressed size ended up being only ~100G less - that's when I realized that (gzip) compression algo is not good at handling seemingly random numerical data. Do you know of methods that've proven to work in this scenario?\n    submitted by    /u/OpeningVariable  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1798jz5/d_good_compression_algo_to_compress_model/",
          "publishedOn": "2023-10-16T15:24:00.000Z",
          "wordCount": 2599,
          "title": "[D] Good compression algo to compress model checkpoints?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17989fq/r_think_before_you_speak_training_language_models/",
          "author": null,
          "description": "https://arxiv.org/pdf/2310.02226.pdf\n Abstract\n Language models generate responses by producing a series of tokens in immediate succession: the (K+1)th token is an outcome of manipulating K hidden vectors per layer, one vector per preceding token. What if instead we were to let the model manipulate say, K+10 hidden vectors, before it outputs the (K+1)th token? We operationalize this idea by performing training and inference on language models with a (learnable) pause token, a sequence of which is appended to the input prefix. We then delay extracting the model's outputs until the last pause token is seen, thereby allowing the model to process extra computation before committing to an answer. We empirically evaluate pause-training on decoder-only models of 1B and 130M parameters with causal pretraining on C4, and on downstream tasks covering reasoning, question-answering, general understanding and fact recall. Our main finding is that inference-time delays show gains when the model is both pre-trained and finetuned with delays. For the 1B model, we witness gains on 8 of 9 tasks, most prominently, a gain of 18% EM score on the QA task of SQuAD, 8% on CommonSenseQA and 1% accuracy on the reasoning task of GSM8k. Our work raises a range of conceptual and practical future research questions on making delayed next-token prediction a widely applicable new paradigm.\n Here is a Medium post about my thoughts on the paper.\n    submitted by    /u/transformer_ML  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17989fq/r_think_before_you_speak_training_language_models/",
          "publishedOn": "2023-10-16T15:11:22.000Z",
          "wordCount": 2751,
          "title": "[R] Think before you speak: Training Language Models With Pause Tokens",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17974u1/d_can_direct_preference_optimization_dpo_be_used/",
          "author": null,
          "description": "DPO Paper\n I read a really fascinating paper where RL was used on LLMs to make them better at interacting in embodied environments. https://arxiv.org/abs/2310.08588\n The technique was called Reinforcement Learning with Environmental Feedback (RLEF).\n In the paper PPO was used, but I'm wondering if DPO could be used to replace it?\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17974u1/d_can_direct_preference_optimization_dpo_be_used/",
          "publishedOn": "2023-10-16T14:22:22.000Z",
          "wordCount": 2585,
          "title": "[D] Can Direct Preference Optimization (DPO) be used to replace any type of RL for LLMs, or is it better suited for just scenarios like RLHF?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17960o1/how_to_create_dataset_for_training_generative/",
          "author": null,
          "description": "i built my own custom generative ai chatbot model. only thing i need is high quality and diverse dataset to train my model. i cant use already existing datasets because i dont think they are diverse and quality enough.so i need to create it using gpt4. my dataset will have 3 columns ; system_prompt, input, output. but im not very experienced on creating datasets, and i couldnt find any resources about this. all input ,output and system prompt all should be created by gpt4. how can i do it? and what is most effective way to use api for this?\n    submitted by    /u/Many-Corner-6700  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17960o1/how_to_create_dataset_for_training_generative/",
          "publishedOn": "2023-10-16T13:30:21.000Z",
          "wordCount": 2624,
          "title": "How to create dataset for training generative chatbot model? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1795yej/p_mergellama7b_a_fine_tune_of_codellama_for/",
          "author": null,
          "description": "Merge conflicts are something that give developers hours of headaches and I figured I would try and give my take on a solution. I followed a paper from IEEE engineers in 2022 who trained CodeBert on merge conflicts as a classification task, and they published their dataset for public use.\n Input formatted as “<<<<<<< A ======= B >>>>>>>” will output the attempted conflict resolution. I am still trying to find out how to do evaluations on this model as the loss applies to all sections not just the resolution, and the TRL Trainer with a data collator gives NaN as a loss.\n The model and dataset are on HuggingFace under codys12/MergeLlama and codys12/MergeLlama-7b.\n Any feedback is appreciated!\n    submitted by    /u/cstein123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1795yej/p_mergellama7b_a_fine_tune_of_codellama_for/",
          "publishedOn": "2023-10-16T13:27:13.000Z",
          "wordCount": 2643,
          "title": "[P] MergeLlama-7b - A fine tune of CodeLlama for resolving merge conflicts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1795p5q/p_openllmetry_a_way_to_get_complete_visibility/",
          "author": null,
          "description": "Hey,\n I've built a set of extensions for OpenTelemetry that provides visibility into LLM applications like RAG pipelines - whether it be prompts, vector DBs and more. Here’s the repo: https://github.com/traceloop/openllmetry.\n Two key benefits with OpenTelemetry are - \n  \nYou can trace your entire system execution, not just the LLM (so you can see how requests to DBs, or other calls affect the overall result); \n You can connect to any monitoring platform—no need to adopt new tools. Install the SDK and plug it into Datadog, Sentry, or both. Or switch between them easily.\n  \nThere's already support for OpenAI, Anthropic, Cohere, Pinecone, Chroma, LangChain, and Haystack and we are working hard to support the entire ecosystem.\n Would love to hear your thoughts \n    submitted by    /u/nirga  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1795p5q/p_openllmetry_a_way_to_get_complete_visibility/",
          "publishedOn": "2023-10-16T13:14:24.000Z",
          "wordCount": 2649,
          "title": "[P] OpenLLMetry, a way to get complete visibility into RAG pipelines with your existing tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1795iiz/can_ai_replace_developers_princeton_and/",
          "author": null,
          "description": "Exploiting AI to make software programming easier? SWE-bench, a unique evaluation system, tests language models' ability to solve real GitHub-collated programming issues. Interestingly, even top-notch models manage only the simplest problems, underscoring tech development's urgency for providing practical software engineering solutions.\n For the latest advancements in AI, look here first.\n https://preview.redd.it/rq5vl22bckub1.png?width=1292&format=png&auto=webp&s=d79988bfe0ab37b0f97f55296d7a7341c9292c11\n A New Approach to Evaluating AI Models\n  \nResearchers use real-world software engineering problems from GitHub to assess language models' coding problem-solving skills.\n SWE-bench, introduced by Princeton and the University of Chicago, offers a more comprehensive and challenging benchmark…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1795iiz/can_ai_replace_developers_princeton_and/",
          "publishedOn": "2023-10-16T13:04:34.000Z",
          "wordCount": 2794,
          "title": "Can AI Replace Developers? Princeton and University of Chicago's SWE-bench Tests AI on Real Coding Issues [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178zy9z/how_to_design_a_chatgpt_or_bardlike_large_scale/",
          "author": null,
          "description": "I am just puzzled how does one efficiently query a huge transformer model such that so many users can be served at the same time. Is it queried on per user basis? (modulo some caching) If yes, how expensive is this? If no, what the hell is going on? :D Are there any good resources on this? (how to build large scale apps with big models, from scratch). Somehow this doesn't really fit the standard data-intensive system design process, or maybe I am missing something.\n    submitted by    /u/jimmymvp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178zy9z/how_to_design_a_chatgpt_or_bardlike_large_scale/",
          "publishedOn": "2023-10-16T06:58:25.000Z",
          "wordCount": 2615,
          "title": "How to design a Chat-GPT or Bard-like large scale app with your own foundational model? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178pbxg/sota_facial_recognition_d/",
          "author": null,
          "description": "I want to sort folders of pictures of people that are similar to an input photo by similarity. I managed to use DeepFace but I'm wondering if anyone knows a better method?\n ​\n    submitted by    /u/RedditAlreaddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178pbxg/sota_facial_recognition_d/",
          "publishedOn": "2023-10-15T21:17:16.000Z",
          "wordCount": 2550,
          "title": "SOTA Facial Recognition [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178ou60/r_reason_for_future_act_for_now_a_principled/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.17382\n Project page: https://agentification.github.io/RAFA\n Code: https://github.com/agentification/RAFA_code\n Reason for future, act for now (RAFA)\n TL;DR:\n - The first autonomous LLM agent RAFA with provable regret guarantees and outstanding empirical performances.\n - SOTA results on Game of 24, ALFWorld, BlocksWorld, and Tic-Tac-Toe.\n    submitted by    /u/WolverineUnable5957  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178ou60/r_reason_for_future_act_for_now_a_principled/",
          "publishedOn": "2023-10-15T20:56:04.000Z",
          "wordCount": 2573,
          "title": "[R] Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178nwqf/p_machine_learning_algorithm_from_scratch/",
          "author": null,
          "description": "submitted by    /u/shaongit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178nwqf/p_machine_learning_algorithm_from_scratch/",
          "publishedOn": "2023-10-15T20:13:02.000Z",
          "wordCount": 2531,
          "title": "[P] Machine Learning Algorithm from Scratch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178nfeu/dwas_any_further_work_done_on_the_paper/",
          "author": null,
          "description": "So, a few weeks ago, I got interested in the exploration problem in Reinforcement Learning and came across this amazing paper. Just wanted to know if any of you came across any paper which explores this idea more or takes it forward. Thanks in advance.\n    submitted by    /u/Interesting-Weeb-699  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178nfeu/dwas_any_further_work_done_on_the_paper/",
          "publishedOn": "2023-10-15T19:50:42.000Z",
          "wordCount": 2575,
          "title": "[D]Was any further work done on the paper \"Large-Scale Study of Curiosity-Driven Learning\" in recent years?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178ndzw/r_tool_to_brainstorm_novel_ideas/",
          "author": null,
          "description": "Hey folks,\n I developed a research tool https://idea-factory.ngrok.dev/ (Login: [temp@holistic-intelligence.net](mailto:temp@holistic-intelligence.net) Password: noidea) to identify novel research problems grounded in the scientific literature. Given an idea that intrigues you, the tool identifies the most relevant pieces of literature, creates a brief summary, and provides three possible extensions of your idea.\n I would be happy to get your feedback on the usefulness of them.\n Thank you in advance!\n    submitted by    /u/Ma7dy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178ndzw/r_tool_to_brainstorm_novel_ideas/",
          "publishedOn": "2023-10-15T19:48:51.000Z",
          "wordCount": 2586,
          "title": "[R] tool to brainstorm novel ideas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178lvvj/p_oddly_satisfying_animation_of_pixel_shuffle/",
          "author": null,
          "description": "submitted by    /u/Animated-AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178lvvj/p_oddly_satisfying_animation_of_pixel_shuffle/",
          "publishedOn": "2023-10-15T18:39:51.000Z",
          "wordCount": 2519,
          "title": "[P] Oddly Satisfying Animation of Pixel Shuffle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178ktqi/d_pipeline_for_data_processing_in_time_series/",
          "author": null,
          "description": "What is the correct pipeline for data processing when conducting time series forecasting? Should we begin with data normalization/standardization, followed by feature selection, and then split the data into training, validation, and test sets? Or is it advisable to initially split the data to prevent spill-over effects?\n I'm concerned about the possibility of training my model on (part of) the test data, which could result in spill-over effects. However, if the recommended approach is to split the data first and then perform normalization and feature selection, what impact would this have on the selected features?\n Does the manner in which we split the data into random time periods matter, or is it necessary to incorporate a validation method that accounts for temporal effects? I'm worried that the selected features might depend on the time period I choose for my training and test sets. What is the best practice in this scenario?\n    submitted by    /u/Ambitious-Pay6329  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178ktqi/d_pipeline_for_data_processing_in_time_series/",
          "publishedOn": "2023-10-15T17:51:25.000Z",
          "wordCount": 2674,
          "title": "[D] Pipeline for data processing in time series forecasting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178ko4j/r_researchers_propose_gamegpt_a_multiagent/",
          "author": null,
          "description": "Game dev is super complex nowadays - games have huge codebases, massive teams, and dev cycles dragging on for years. Costs are insane too - budgets can hit $100M+ easily.\n In a new paper, researchers propose to reverse this trend with an AI framework called GameGPT that automates parts of the dev process using multiple AI agents. Each agent handles a different role (all are fine-tuned from relevant base models):\n  \nOne agent reviews the game design plan to catch errors\n Another turns tasks into code implementations\n Reviewer agents check the code and results\n A testing agent validates everything works as expected\n  \nBy breaking up the workflow, GameGPT can simplify things for the AI agents. They just focus on a narrow role versus having one jack-of-all-trades agent.\n The authors argue GameGPT can eliminate repetitive and rote elements of gamedev like testing. This would free up developers to focus on creative design challenges.\n However, the GameGPT paper does not include any concrete results or experiments demonstrating improved performance. There is no evidence presented that GameGPT reduces hallucinations, redundancy or development time. The authors mention empirical results support their claims that the architecture is more effective, but none are provided. I could not find any additional support material about this work, like a project website, that I could use to further check into this (maybe someone can share in the comments?).\n Right now GameGPT seems mostly conceptual. The ideas are interesting but hard to assess without quantitative results.\n TLDR: New GameGPT AI framework aims to automate tedious parts of game development using specialized agents. No concrete results were provided in the paper - someone will need to test this out and report back.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178ko4j/r_researchers_propose_gamegpt_a_multiagent/",
          "publishedOn": "2023-10-15T17:43:52.000Z",
          "wordCount": 2812,
          "title": "[R] Researchers propose GameGPT: A multi-agent approach to fully automated game development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178iuvr/d_generate_audio_samples_based_on_promp_sample/",
          "author": null,
          "description": "hi,\n I would like to create a system that generate different audio samples, based on an audio sample prompt. Does anyone know whether such a project or similar ideas have been already implemented? Or any suggestion on what to read in order to realize such a project? I have knowledge in ML programming and python audio generation.\n    submitted by    /u/busconw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178iuvr/d_generate_audio_samples_based_on_promp_sample/",
          "publishedOn": "2023-10-15T16:17:40.000Z",
          "wordCount": 2579,
          "title": "[D] Generate audio samples based on promp sample",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178hcud/d_getting_bad_mfus_what_can_i_do_to_make_it_better/",
          "author": null,
          "description": "Hi, so I've been working with NanoGPT, finetuning GPT-2, and I'm getting terrible MFUs, with 5 warmup steps at -100% and normal steps have an MFU of around 3-4%. Most runs I hear of have an MFU at around 45%? How do get this better?\n Colab -> https://colab.research.google.com/drive/1gvTsyjxHiDkKHFsnWWouzr1xJWW23BA3?usp=sharing\n Code -> https://github.com/VatsaDev/NanoPhi2\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178hcud/d_getting_bad_mfus_what_can_i_do_to_make_it_better/",
          "publishedOn": "2023-10-15T15:06:43.000Z",
          "wordCount": 2571,
          "title": "[D] Getting bad MFUs, what can I do to make it better",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178hctk/d_check_out_my_latest_article_on_how_the_new/",
          "author": null,
          "description": "https://medium.com/@rishiswethan.c.r/how-gpt-4v-ision-will-revolutionise-image-annotation-b0d3ace64bff?source=friends_link&sk=4be42541a8a8ee40e18ef14533342cfd\n    submitted by    /u/Remarkable_Seesaw_89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178hctk/d_check_out_my_latest_article_on_how_the_new/",
          "publishedOn": "2023-10-15T15:06:41.000Z",
          "wordCount": 2543,
          "title": "[D] Check out my latest article on how the new improvements in GPT-4V(ision) can bring on a new ear of computer vision models, fine-tuned on outputs of GPT-4V(vision).",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178h9qr/how_to_object_detection_in_unity_any_good/",
          "author": null,
          "description": "I have tired barracuda, vuforia and it doesn’t work for some reason. And completely lost atm. It’s an object detection model to detect the circuit schematic symbols using computer vision\n    submitted by    /u/PreferenceFrosty2958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178h9qr/how_to_object_detection_in_unity_any_good/",
          "publishedOn": "2023-10-15T15:02:43.000Z",
          "wordCount": 2554,
          "title": "How to object detection in Unity any good resources [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178grpp/d_running_large_language_models_on_cpu/",
          "author": null,
          "description": "Fine-tuning large language models with the aim of obtaining a small but accurate model is extremely difficult.\n This is because you have to strike a balance between the model’s size and accuracy. Researchers from IST Austria & Neural Magic seem to have found a sweet spot. \n In their latest paper, they successfully applied sparse fine-tuning on MPT with remarkable performance. The MPT model was pruned to 75% without a drop in accuracy, showing performance that is on-par with quantization approaches. \n Particularly, the resulting sparse model can execute fast on CPUs by taking advantage of the sparsity. \n Instead of performing standard loss-based fine-tuning which may fail to recover accuracy, the researchers experiment with distillation-type losses. These losses are better at recovering accuracy at high sparsity. What’s impressive is that the sparse fine-tune LLM can achieve 7.7 tokens per second on a single core and 26.7 tokens per second on 4 cores of an cheap consumer AMD Ryzen CPU. The MPT-7B model was fine-tuned via SFT obtaining a dense baseline that showed remarkable performance. This baseline was later pruned with SparseGPT to 40% to 80% reaching 5X compression ratios. By applying SquareHead KD, FP32 models with 75% can be obtained with NO accuracy loss, outperforming cross-entropy and other KD methods. \n The paper is available on Arxiv. Sparse Finetuning for Inference Acceleration of Large Language Models: https://huggingface.co/papers/2310.06927\n MPT Sparse Finetuned on GSM8k with DeepSparse Hugging Face Space: \n https://huggingface.co/spaces/neuralmagic/sparse-mpt-7b-gsm8k\n    submitted by    /u/mwitiderrick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178grpp/d_running_large_language_models_on_cpu/",
          "publishedOn": "2023-10-15T14:39:01.000Z",
          "wordCount": 2756,
          "title": "[D] Running Large Language Models on CPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178froa/p_i_built_an_ai_writing_coach_to_proofread_your/",
          "author": null,
          "description": "submitted by    /u/hungryillini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178froa/p_i_built_an_ai_writing_coach_to_proofread_your/",
          "publishedOn": "2023-10-15T13:49:51.000Z",
          "wordCount": 2523,
          "title": "[P] I built an AI Writing Coach to proofread your work",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178ersq/r_conceptual_framework_for_autonomous_cognitive/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.06775\n GitHub: https://github.com/daveshap/ACE_Framework\n Blog post: https://medium.com/@dave-shap/autonomous-agents-are-here-introducing-the-ace-framework-a180af15d57c\n Abstract:\n  \nThe rapid development and adoption of Generative AI (GAI) technology in the form of chatbots such as ChatGPT and Claude has greatly increased interest in agentic machines. This paper introduces the Autonomous Cognitive Entity (ACE) model, a novel framework for a cognitive architecture, enabling machines and software agents to operate more independently. Drawing inspiration from the OSI model, the ACE framework presents layers of abstraction to conceptualize artificial cognitive architectures. The model is designed to harness the capabilities of the latest generative AI technologies, including large language models (LLMs) and multimodal generative models (MMMs), to build autonomous, agentic systems. The ACE framework comprises six layers: the Aspirational Layer, Global Strategy, Agent Model, Executive Function, Cognitive Control, and Task Prosecution. Each layer plays a distinct role, ranging from setting the moral compass and strategic thinking to task selection and execution. The ACE framework also incorporates mechanisms for handling failures and adapting actions, thereby enhancing the robustness and flexibility of autonomous agents. This paper introduces the conceptual framework and proposes implementation strategies that have been tested and observed in industry. The goal of this paper is to formalize this framework so as to be more accessible.\n  \n​\n https://preview.redd.it/7scnwk5a5dub1.png?width=850&format=png&auto=webp&s=371b5b02a453dcad3e70a2600cc2d625eda44133\n ​\n    submitted by    /u/Prior-Travel3670  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178ersq/r_conceptual_framework_for_autonomous_cognitive/",
          "publishedOn": "2023-10-15T12:55:00.000Z",
          "wordCount": 2732,
          "title": "[R] Conceptual Framework for Autonomous Cognitive Entities - Clemson University 2023 - Introducing the ACE Framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178cq38/d_fine_tune_llama2_with_lora_for_foreign_language/",
          "author": null,
          "description": "Hey folks,\n I watched a YouTube video, about how some LLMs tokenise languages other than English.\n For example for the Greek language you will see that this is failing totally, as one character is one token always:\n ​\n https://preview.redd.it/835p97cyhcub1.png?width=1900&format=png&auto=webp&s=944b150cc0fc112cb8cd2bac600f6fcdcc85fb1e\n My question is, if I would fine-tune it with Alpaca Lora based on Greek text, would the tokeniser change and work properly? Or the fine tune would not work as the tokeniser cannot be retrained/tuned?\n    submitted by    /u/kostakos14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178cq38/d_fine_tune_llama2_with_lora_for_foreign_language/",
          "publishedOn": "2023-10-15T10:41:46.000Z",
          "wordCount": 2595,
          "title": "[D] Fine tune Llama2 with Lora for foreign language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178b502/d_advice_for_applying_to_undergraduate_research/",
          "author": null,
          "description": "Hello, I’m a 3rd year data science and linguistics major at a top 30 school looking to land an internship at industry research.\n I’d say I’m fairly competitive. Extensive research experience. 2nd author at EMNLP, and did an REU at a prestigious institute.\n I’m already looking at some places such as AI2, but I’m curious if there are other internships I should be aware of.\n    submitted by    /u/Kai_151  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178b502/d_advice_for_applying_to_undergraduate_research/",
          "publishedOn": "2023-10-15T08:43:10.000Z",
          "wordCount": 2587,
          "title": "[D] Advice for applying to undergraduate research internships?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178avwq/d_the_history_of_neural_network_is_over_j/",
          "author": null,
          "description": "submitted by    /u/fromnighttilldawn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178avwq/d_the_history_of_neural_network_is_over_j/",
          "publishedOn": "2023-10-15T08:24:52.000Z",
          "wordCount": 2538,
          "title": "[D] The history of neural network is over. J. Schimdhuber proposes a giant network that includes all future neural network architecture as a subcomponent.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/178aisk/p_how_do_i_make_my_cnn_more_efficient/",
          "author": null,
          "description": "I've been trying a variety of pre-constructed and self-made U-net-like CNNs. Had a few questions:\n  \nWhen using torch summary, is there a general formula for estimating a model's inference time/backprop time and required GPU ram based on the information torch summary gives ( Total params, Trainable params, Non-trainable params, Total mult-adds (G), Input size, Forward/backward pass size (MB), Params size (MB), Estimated Total Size (MB)), and other hyper-parameters such as batch size?\n \nWhy is my self-made model (which has smaller quantities in all the parameters torch summary outputs) requiring more GPU ram AND taking more time for inference and backprop? Is the coding style for the model's class and its forward prop a huge factor here? If so, could you please provide tips for making my code more efficient?\n Here's the notebook showcasing a pre-made model from MONAI and two of my self-made models:\n https://colab.research.google.com/drive/1VRrdnzaAbp25_DtaWTKHW5JxzyhmueMC?usp=sharing \n \nI've also listed some of my observation on the models and their results in the notebook. Any ideas or suggestion would be much appreciated.\n \n    submitted by    /u/mimivirus2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/178aisk/p_how_do_i_make_my_cnn_more_efficient/",
          "publishedOn": "2023-10-15T07:58:33.000Z",
          "wordCount": 2690,
          "title": "[P] How do I make my CNN more efficient?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1786fvj/p_made_a_python_package_for_creating_api/",
          "author": null,
          "description": "submitted by    /u/squirrels-api  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1786fvj/p_made_a_python_package_for_creating_api/",
          "publishedOn": "2023-10-15T03:23:51.000Z",
          "wordCount": 2755,
          "title": "[P] Made a Python package for creating API endpoints with dynamic queries.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1786bty/r_supercharging_reinforcement_learning_with_logic/",
          "author": null,
          "description": "Deep reinforcement learning has led to a variety of compelling results. However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly. Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.\n ​\n https://preview.redd.it/kdhpu9qraaub1.png?width=1786&format=png&auto=webp&s=8155ba38fc66bd3a2fe934b1f395351c4db68e2f\n We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).\n ​\n https://preview.…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1786bty/r_supercharging_reinforcement_learning_with_logic/",
          "publishedOn": "2023-10-15T03:17:30.000Z",
          "wordCount": 2756,
          "title": "[R] Supercharging reinforcement learning with logic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1785hht/d_transformers_vs_llamacpp_vs_gptq_vs_ggml_vs_gguf/",
          "author": null,
          "description": "i am a little puzzled,\n  \ni know that transformers is the HF framework/library to load infere and train models easily\n and that llama.cpp is another framework/library that does the more of the same but specialized in models that runs on CPU and quanitized and run much faster\n i understand that GGML is a file format for saving model parameters in a single file, that its an old problematic format, and GGUF is the new kid on the block, and GPTQ is the same quanitized file format for models that runs on GPU\n  \n​\n so here is what i can't understand (assuming i got all the rest correct): \n  \ndoes HF Transformers support loading GGUF or GGML models ? \n and does GGUF needs a tokenizer json or does the data comes from within the gguf file itself\n and is safetensors (another file format) supported by both Transformers and Llama.cpp\n  \n​\n since i cannot find python examples for these combination i assume all the answers are - No\n ​\n can anyone shed some light ?\n    submitted by    /u/Particular_Flower_12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1785hht/d_transformers_vs_llamacpp_vs_gptq_vs_ggml_vs_gguf/",
          "publishedOn": "2023-10-15T02:30:17.000Z",
          "wordCount": 2693,
          "title": "[D] transformers vs llama.cpp vs GPTQ vs GGML vs GGUF",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1782m6k/d_detect_anomaly_with_small_dataset/",
          "author": null,
          "description": "Hi guys,\n I'm hoping for advice on the direction to detect detect pattern/ anomaly at small scale.\n I understand there are certain tools out there for webpage monitoring, but let's say this is just an example that I'm ingesting small amount of hourly/daily traffic to a sub webpage on my site (anywhere from 50-100 visits per day, this may mean max ~30 visits/per hour)\n There are times when traffic to the page drops as the page doesn't fully load , or the other page on which I'm hosting the link to this page doesn't load resulting in people can't see the link tothis sub page).\n Giving the scope/scale of this, amount of the data, it's not possible for me to use other solutions for anomaly detection (those that costs like $100-$1000+/month) and I'm not sure where to start with ML with this minimal amount of hourly/daily data to monitor.\n Is there anything that I should look into?\n Thank you\n    submitted by    /u/duyth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1782m6k/d_detect_anomaly_with_small_dataset/",
          "publishedOn": "2023-10-14T23:59:08.000Z",
          "wordCount": 2677,
          "title": "[D] Detect anomaly with small dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1782djg/d_foundational_must_reads_for_llms/",
          "author": null,
          "description": "Came across this post https://community.openai.com/t/foundational-must-read-gpt-llm-papers/197003\n As I am new to LLM's , Please share your thoughts on how to start and what subtopics to learn in depth ? \n ​\n    submitted by    /u/Electrical_Study_617  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1782djg/d_foundational_must_reads_for_llms/",
          "publishedOn": "2023-10-14T23:46:59.000Z",
          "wordCount": 2548,
          "title": "[D] Foundational must reads for LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177yose/d_google_automl_alternatives/",
          "author": null,
          "description": "Having jumped into AI this last year I've used Google AutoML a lot and it's honestly worked great. I primarily use it for text classification. Training usually takes anywhere from 4-8 hours.\n The results have been above 90% accurate on interference.\n Now, the problem. Cost. It's super expensive to run an endpoint for predictions with Google AutoML, for text classification.\n I'm wondering if anyone has any alternatives or ideas for similar results for cheaper. I am ok waiting for prediction results a bit as I don't need sub 1ms type responses lol.\n But everything I've tried has yielded less then optimal results. Tried various hugging face models, and accuracy is about 50%.\n    submitted by    /u/zepaz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177yose/d_google_automl_alternatives/",
          "publishedOn": "2023-10-14T20:47:29.000Z",
          "wordCount": 2630,
          "title": "[D] Google AutoML Alternatives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177ye61/r_octopus_embodied_visionlanguage_programmer_from/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.08588 \n Blog: https://choiszt.github.io/Octopus/ \n Github: https://github.com/dongyh20/Octopus \n Youtube short: https://www.youtube.com/watch?v=lHbTvB0yIP4 \n Abstract:\n  \nLarge vision-language models (VLMs) have achieved substantial progress in multimodal perception and reasoning. Furthermore, when seamlessly integrated into an embodied agent, it signifies a crucial stride towards the creation of autonomous and context-aware systems capable of formulating plans and executing commands with precision. In this paper, we introduce Octopus, a novel VLM designed to proficiently decipher an agent's vision and textual task objectives and to formulate intricate action sequences and generate executable code. Our design allows the agent to adeptly handle a wide spectrum of tasks, ranging from mundane daily chores in simulators to sophisticated interactions in complex video games. Octopus is trained by leveraging GPT-4 to control an explorative agent to generate training data, i.e., action blueprints and the corresponding executable code, within our experimental environment called OctoVerse. We also collect the feedback that allows the enhanced training scheme of Reinforcement Learning with Environmental Feedback (RLEF). Through a series of experiments, we illuminate Octopus's functionality and present compelling results, and the proposed RLEF turns out to refine the agent's decision-making. By open-sourcing our model architecture, simulator, and dataset, we aspire to ignite further innovation and foster collaborative applications within the broader embodied AI community. \n  \nhttps://preview.redd.it/1zn9q3g7a8ub1.jpg?width=1651&format=pjpg&auto=webp&s=3b14f862b24784918d6b4514bf575cf29bc65edf\n https://preview.redd.it/sv2y06g7a8ub1.jpg?width=1079&format=pjpg&auto=webp&s=be9ab7dd7cf23018b6d1fa0c584ad301b04c8abf\n https://preview.redd.it/350xc6g7a8ub1.jpg?width=942&format=pjpg&auto=webp&s=53e57541d35ca23d06b8c5be71c2b0c1910fdf90\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177ye61/r_octopus_embodied_visionlanguage_programmer_from/",
          "publishedOn": "2023-10-14T20:33:05.000Z",
          "wordCount": 2742,
          "title": "[R] Octopus: Embodied Vision-Language Programmer from Environmental Feedback - Nanyang Technological University 2023 - Continually refines its understanding and execution, demonstrating impressive adaptability!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177xp6c/r_my_article_about_autonomous_llmsbased_agents/",
          "author": null,
          "description": "A Complete Guide to LLMs-based Autonomous Agents (Part I): https://medium.com/p/69515c016792 \n My article offers a comprehensive overview of LLM-based agents, covering Chain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts, and Graph of Thoughts. \n It traces their evolution from basic forms, driven primarily by prompt engineering, to advanced models that emulate human problem-solving intricacies. Moreover, it provides an engineer's insights into the architecture behind these autonomous agents. \n  \nNaturally suitable for AI agent: LLMs feature a natural language interface tailored for user-computer interactions and they come equipped with innate reasoning abilities.\n \nLLM's Deficiency: Despite its strengths, GPT-4 can provide incorrect answers or hallucinations for complex tasks.\n \nChallenges with Training: Finetuning pretrained LLMs doesn't enhance reasoning capabilities. While creating a larger LLM can bolster its problem-solving skills, the process can span several months to a year, potentially leading to a two-year wait before its official launch.\n \nClosed Model and RAG: LLMs, once trained, are unable to fetch real-time data and have inherent shortcomings. However, for Q&A tasks, leveraging an open-book method proves more effective. The aim is not to have an all-knowing model but one skilled in reasoning and utilizing tools.\n \nLLM Agent Approach: We direct LLMs to break down intricate tasks, tackle individual sub-tasks, evaluate them, and make revisions of the strategy as needed.\n  \n   submitted by    /u/Appropriate-Map-9923  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177xp6c/r_my_article_about_autonomous_llmsbased_agents/",
          "publishedOn": "2023-10-14T20:00:00.000Z",
          "wordCount": 2758,
          "title": "[R] My article about autonomous LLMs-based agents: Chain of Thought, Plan and Solve, Self-Ask, ReAct, Reflexion, Self-Consistency, ToT, and GoT; and intrinsic insights behind an autonomous LLMs-based agents.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177xkwi/d_have_a_research_paper_to_do_for_my_masters_in/",
          "author": null,
          "description": "In my last semester and we have to pick a topic related to big data analytics. Right now I have to prepare a proposal for my topic. My topic will have to do with something to ML and the medicinal field. \n Current plan:\n  \nGet a dataset related to my topic. Right now its Parkinson's disease. My question is, for the dataset would I need a dataset with text data or would images of scans of the brain be better for detecting say early detection be better? I cant figure out which would be the better dataset.\n \nGet the dataset and then use Azure machine learning to prepare my dataset and do some data cleaning and handling and then get a model out of it. I picked azure because I have azure license from my uni and after searching about, I read about the azure machine learning service. Would azure be a good choice for training my model on this task? I've mostly used google colab for training small models. \n \nOnce the model is trained and setup. I want to setup a front end web app (flask) and then setup my model so that users can upload either text data or image scans and then model would output results regarding the inputted data. My question is, would it be ideal to have the model located on my local machine or would azure let me do api calls between my local to the azure trained model? \n \n Would all this be feasible to do? I'm not looking to develop a full fledge application, just want to create a model with a dataset of images or text and then be able to feed new images to the trained model and get an output. \n Just looking for opinions or advice on this topic.\n Thanks.\n    submitted by    /u/Jesustakethewheeeeel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177xkwi/d_have_a_research_paper_to_do_for_my_masters_in/",
          "publishedOn": "2023-10-14T19:54:14.000Z",
          "wordCount": 2838,
          "title": "[D] Have a research paper to do for my masters in Big Data Analytics. Wanted to do something with ML. Just look for some advice.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177xh7c/d_is_the_topic_of_your_ml_phd_important/",
          "author": null,
          "description": "I read the previous discussion on whether a PhD is required in the field, and I had a follow-up question: does the topic of your PhD matter? So let’s say you finish a PhD in the field of medical machine learning (non-CV), would an automotive company, FAANG, or e.g. DeepMind still like to hire you once you would like to switch your sub-field a bit? Or are you simply less desirable than a candidate without a PhD but more experience in CV?\n I am asking this because I would like to stay flexible as I have many ML sub-fields I want to work in, and I do not want to limit my options by pursuing a PhD in a topic that I don’t want work in for my entire life. For context, I do already have 2 years working experience as an AI engineer and I am finishing my AI master’s.\n    submitted by    /u/Otoz123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177xh7c/d_is_the_topic_of_your_ml_phd_important/",
          "publishedOn": "2023-10-14T19:49:23.000Z",
          "wordCount": 2674,
          "title": "[D] Is the topic of your ML PhD important?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177vrc5/d_finetuning_tortoise_tts/",
          "author": null,
          "description": "I'm planning on creating my own AI voice to use with ChatGPT. I have done my research, and there are two ways to achieve a quality TTS model to use. I have tried them both. I fine-tuned tortoise tts on my own 20-minute dataset. I have also tried to create a model using Tacotron2 and the dataset. The quality of the fine-tuned model is better. But one downside is that I still have to give the fine-tuned tortoise model a reference voice for it to choose the voice that I fine-tuned it with. On the other hand, the trained model didn't need to. The question here is: why didn't the tortoise model choose the voice in the dataset as the default? Do I need to expand my dataset for it to be chosen as the main voice? \n ​\n Thank all.\n    submitted by    /u/Capital_Birthday_654  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177vrc5/d_finetuning_tortoise_tts/",
          "publishedOn": "2023-10-14T18:26:49.000Z",
          "wordCount": 2657,
          "title": "[D] Fine-Tuning tortoise tts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177vkdz/r_do_pretrained_transformers_really_learn/",
          "author": null,
          "description": "Do pretrained Transformers Really Learn In-context by Gradient Descent?\n https://x.com/Shadowkiller331/status/1713003711629516862?s=20 \n ​\n https://preview.redd.it/zpwkh47hm7ub1.png?width=450&format=png&auto=webp&s=6def807c9c9f605e3f7839159db3402d837f6895\n    submitted by    /u/Educational-Newt2052  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177vkdz/r_do_pretrained_transformers_really_learn/",
          "publishedOn": "2023-10-14T18:17:31.000Z",
          "wordCount": 2534,
          "title": "[R] Do pretrained Transformers Really Learn In-context by Gradient Descent?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177u1i0/r_unlocking_the_power_of_sparsity_in_generative/",
          "author": null,
          "description": "submitted by    /u/markurtz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177u1i0/r_unlocking_the_power_of_sparsity_in_generative/",
          "publishedOn": "2023-10-14T17:03:54.000Z",
          "wordCount": 2541,
          "title": "[R] Unlocking the power of Sparsity in Generative Models: 8x Faster LLMs on CPUs with Sparse Fine Tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177t7je/arxiv_dives_llama_2_deep_dive/",
          "author": null,
          "description": "We’ve been diving deep into foundational papers on Fridays as a group. It’s been helpful for us to get into the nitty gritty details of these papers, so hope you find it helpful too.\n Would love to have anyone join the discussion next week!\n    submitted by    /u/FallMindless3563  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177t7je/arxiv_dives_llama_2_deep_dive/",
          "publishedOn": "2023-10-14T16:23:40.000Z",
          "wordCount": 2578,
          "title": "A[R]xiv [D]ives - Llama 2 Deep Dive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177rqvp/n_most_detailed_human_brain_map_ever_contains/",
          "author": null,
          "description": "What can this mean to artificial neural networks?\n    submitted by    /u/hhh888hhhh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177rqvp/n_most_detailed_human_brain_map_ever_contains/",
          "publishedOn": "2023-10-14T15:13:13.000Z",
          "wordCount": 2546,
          "title": "[N] Most detailed human brain map ever contains 3,300 cell types",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177qj12/d_my_fine_tune_behaves_like_the_base_model/",
          "author": null,
          "description": "Hi all, I did a fine tune of CodeLlama-7b on a custom dataset and I was getting very excited because it was doing very well on evals. \n I saved the model with model.save() and model.push_to_hub() and it seemed to work. \n When I load the model it shows the structure with the Lora_A and Lora_B for every layer, but it now acts like the base model with no changes. Is it possible I saved wrong or likely that I am loading wrong?\n Any help is greatly appreciated!\n    submitted by    /u/cstein123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177qj12/d_my_fine_tune_behaves_like_the_base_model/",
          "publishedOn": "2023-10-14T14:14:54.000Z",
          "wordCount": 2603,
          "title": "[D] My fine tune behaves like the base model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177pbg8/r_machine_learning_courses_mega_bundle_from/",
          "author": null,
          "description": "submitted by    /u/brand_momentum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177pbg8/r_machine_learning_courses_mega_bundle_from/",
          "publishedOn": "2023-10-14T13:15:13.000Z",
          "wordCount": 2528,
          "title": "[R] Machine Learning Courses Mega Bundle from Mammoth Interactive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177ok01/r_best_rl_algorithm_for_a_single_turn_game/",
          "author": null,
          "description": "Hi there, I'm new to Reinforcement Learning (RL), and the papers I've come across mainly focus on scenarios where states change with choices in a game. \n However, I'm interested in finding the best RL algorithm for a simpler case. I have an input I and a policy P. P outputs probabilities for available choices (a limited set of integers), and a reward r is given for each choice (the reward is costly to compute that’s why I use RL). The goal is to train P to maximize the reward.\n So as if we are in a game that ends after only one choice. Any recommendations for the best RL algorithm in this case?\n Thanks!\n    submitted by    /u/Meddhouib10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177ok01/r_best_rl_algorithm_for_a_single_turn_game/",
          "publishedOn": "2023-10-14T12:35:02.000Z",
          "wordCount": 2638,
          "title": "[R] best RL algorithm for a single turn game ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177nu2c/d_ways_to_get_research_experience_before_grad/",
          "author": null,
          "description": "I recently graduated with my bachelor's from a low ranked school with a good GPA. I was planning on starting a PhD studying NLP and applied to 12 mid level schools. However, I was unfortunately rejected from all the schools I applied to. I suspect it was likely due to my lack of experience in NLP research as my school didn't have any professors who do research in that area. \n My current plan is to work in industry for the next two years and try and do some NLP research on the side before reapplying. Do any NLP labs allow for external volunteer researchers? Besides that, are there any other ways to get research experience?\n    submitted by    /u/Bananas970  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177nu2c/d_ways_to_get_research_experience_before_grad/",
          "publishedOn": "2023-10-14T11:53:40.000Z",
          "wordCount": 2638,
          "title": "[D] Ways to get research experience before grad school",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177n3zr/d_validation_loss_is_decreasing_but_wer_is/",
          "author": null,
          "description": "Hi, I've been using the Huggingface library to fine-tune the Whisper model. While the WER was initially decreasing, I've noticed it began to rise even though the validation loss continues to drop. Could the issue be related to my testing on a very small dataset? As shown in the image, after 80th step the wer suddenly started increasing from 13 -> 28 \n https://preview.redd.it/xq2bm0oyh5ub1.png?width=838&format=png&auto=webp&s=136447f527bea6880b46ae588463500304b1d6bb\n ​\n    submitted by    /u/aadityaura  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177n3zr/d_validation_loss_is_decreasing_but_wer_is/",
          "publishedOn": "2023-10-14T11:09:03.000Z",
          "wordCount": 2589,
          "title": "[D] Validation loss is decreasing but WER is increasing in Whisper model training.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177n3xb/looking_for_an_easytouse_api_to_train_image_model/",
          "author": null,
          "description": "Yo!\n I have some images I curated on MJ, I want to run these together into an AI and spit out more outputs like these.\n The current process has me get maybe .2% successful outputs through MJ I figure the next step to more outputs is training a custom model.\n What's the easiest way to do this using a web-based API? Does this involve using Stable Diffusion?\n    submitted by    /u/AdministrativePie991  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177n3xb/looking_for_an_easytouse_api_to_train_image_model/",
          "publishedOn": "2023-10-14T11:08:55.000Z",
          "wordCount": 2591,
          "title": "Looking for An Easy-To-Use API To Train Image Model [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177mw2d/d_time_series_forecasting_on_positive_and/",
          "author": null,
          "description": "Hey 😀\n not sure if extremely trivial or really tricky.\n In the end, I want a machine that generates a time series without further input based on training data, generating a new time series every time.\n I want this to be based on a transformer.\n I want it trained with data looking like this:\n 2023-07-03 14:19:48,GOOD 2023-07-04 13:59:07,GOOD 2023-07-05 01:58:54,GOOD 2023-07-05 03:30:05,BAD 2023-07-05 05:17:43,BAD 2023-07-06 05:35:34,GOOD 2023-07-07 14:06:03,GOOD 2023-07-08 21:16:05,BAD \n with “GOOD” and “BAD” being the state of the system which is likely dependent on the time series data up to that point. I have a lot of data and it’s data points like the one above with maybe a hundred rows of data on average for a few thousand systems. Every system is independent of all others but all are identical.\n I do not want to train only on “GOOD” as this would leave out a lot of valuable data …\n Is there a way to train a time series transformer with both data that leads to GOOD as well as BAD outcomes, so it would generate time series from scratch that are unlikely to have BAD outcomes?\n Thank you!!\n    submitted by    /u/_VeniVidiVeni_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177mw2d/d_time_series_forecasting_on_positive_and/",
          "publishedOn": "2023-10-14T10:54:51.000Z",
          "wordCount": 2714,
          "title": "[D] Time Series Forecasting on positive AND negative Examples",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177mm5z/p_vgslify_transform_your_tensorflow_model/",
          "author": null,
          "description": "Hey r/MachineLearning! 🚀\n Have you ever been frustrated with the lengthy and sometimes cumbersome TensorFlow code for defining models? Or wished you could experiment with different architectures without dealing with copious lines of code? That's where VGSLify steps in.\n Why Use VGSLify?\n  \nCompact Definitions: VGSLify leverages VGSL spec, enabling you to express intricate model architectures in a compact and elegant manner. This means you can quickly experiment with different models by simply tweaking a string format, bypassing the verbose code traditionally required.\n Swift Prototyping: Craft intricate neural network architectures using succinct VGSL spec strings, allowing you to iterate faster and more efficiently.\n From TensorFlow to VGSL: Got a pre-existing TensorFlow model? Easily co…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177mm5z/p_vgslify_transform_your_tensorflow_model/",
          "publishedOn": "2023-10-14T10:36:28.000Z",
          "wordCount": 2772,
          "title": "[P] VGSLify: Transform Your TensorFlow Model Prototyping Experience",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177lxzr/d_how_important_is_a_phd_for_industry/",
          "author": null,
          "description": "I'm 21 years old and currently pursuing a master's degree in theoretical physics in the UK. I have a strong interest in machine learning and have completed many computing courses as well as independent projects in this field.\n I'm considering a career in machine learning and I'm curious about the benefits of doing a PhD. I've heard that the salary difference may not be substantial. Could anyone provide insights on how important a PhD is for specific roles in this field? Additionally, what factors should I consider when deciding whether to pursue a PhD in machine learning, apart from my passion for ML?\n Also are private PhDs common in ML. Working in a company and asked them to pursue a PhD within the company?\n Thanks :)\n    submitted by    /u/Neat-Print2792  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177lxzr/d_how_important_is_a_phd_for_industry/",
          "publishedOn": "2023-10-14T09:49:51.000Z",
          "wordCount": 2648,
          "title": "[D] How important is a PhD for industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177l731/d_shap_mask_token_why_does_it_matter_and_which/",
          "author": null,
          "description": "submitted by    /u/Being-Nothingness  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177l731/d_shap_mask_token_why_does_it_matter_and_which/",
          "publishedOn": "2023-10-14T08:55:12.000Z",
          "wordCount": 2552,
          "title": "[D] SHAP mask_token: why does it matter and which one to choose?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177fw1f/r_promptbreeder_selfreferential_selfimprovement/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177fw1f/r_promptbreeder_selfreferential_selfimprovement/",
          "publishedOn": "2023-10-14T03:00:59.000Z",
          "wordCount": 2532,
          "title": "[R] Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/177cswd/d_is_there_a_good_code_or_text_model/",
          "author": null,
          "description": "i am trying to detect code segments in a text response of an LLM, so i can highlight them using Highlight,JS,\n ​\n is there a good model that can do the classification of a block of text and decide if it is a block of code or a block of NLP simple text (english) ?\n    submitted by    /u/Particular_Flower_12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/177cswd/d_is_there_a_good_code_or_text_model/",
          "publishedOn": "2023-10-14T00:16:27.000Z",
          "wordCount": 2572,
          "title": "[D] is there a good Code or Text model ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1779u9h/p_app_for_ios_and_m1_macos_for_image_bounding_box/",
          "author": null,
          "description": "ClassifyML is an application for creating specialised image datasets for use with an ML training algorithm. Simply import your chosen images into the app via file manager, drag'n'drop or the on device camera and create your bounding boxes and then export your images and JSON into a structured folder. \n LINK: https://apps.apple.com/app/classify-ml/id6461013113\n https://preview.redd.it/dicsq9d3k1ub1.png?width=313&format=png&auto=webp&s=7976a61f599c658d948dec12db0b8ec93274ad93\n https://preview.redd.it/3tswxdd3k1ub1.png?width=313&format=png&auto=webp&s=56ca30546984402f4dbba628b73732918e921758\n https://preview.redd.it/y0xelmz3k1ub1.png?width=313&format=png&auto=webp&s=a755ea61bc247c6aacb61a31c700e4e80a1ed69f\n    submitted by    /u/LiamRogers99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1779u9h/p_app_for_ios_and_m1_macos_for_image_bounding_box/",
          "publishedOn": "2023-10-13T21:54:44.000Z",
          "wordCount": 2577,
          "title": "[P] App for iOS and M1 macOS for image bounding box annotation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1779tv0/d_what_are_the_best_resources_for_learning/",
          "author": null,
          "description": "Recently I came across Open AI's Spinning Up Project, which seems to be well structured, but quite introductory. What are some resources you use for learning RL? \n    submitted by    /u/OwnAd9305  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1779tv0/d_what_are_the_best_resources_for_learning/",
          "publishedOn": "2023-10-13T21:54:13.000Z",
          "wordCount": 2551,
          "title": "[D] What are the best resources for learning reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17798uq/d_llm_for_entityscene_recognition_in_a_book/",
          "author": null,
          "description": "Hello, I'm looking for an open source LLM that can extract all the characters from an inputted book, and isolate passages with descriptive writing that involves imagery. Can anyone suggest me something? Thanks!\n    submitted by    /u/slomorosh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17798uq/d_llm_for_entityscene_recognition_in_a_book/",
          "publishedOn": "2023-10-13T21:28:44.000Z",
          "wordCount": 2555,
          "title": "[D] LLM for entity/scene recognition in a book?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17788eq/p_deploy_and_run_llms_at_the_edge_use_code_llama/",
          "author": null,
          "description": "In this blog, we explore different definitions of “the edge,” and understand the factors driving AI/ML to the edge. We examine why the trends of LLMs and edge computing are intersecting now, and how teams can take advantage of their combined power today. We also demonstrate how LLMs can be used in an edge environment to generate insights for a real-world use case today. Consider a geologist working in a remote oil field who is responsible for building and analyzing 3D models of oil fields to determine production capacity and the impact on profitability. In this demo, we walk through how Code Llama, Chassisml.io, and Modzy could be used to build a dashboard that geologists could use to analyze well data in real-time in a remote, network restricted environment, allowing for LLM insights generated at the edge.\n Learn more: https://www.modzy.com/modzy-blog/deploy-and-run-llms-at-the-edge\n    submitted by    /u/modzykirsten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17788eq/p_deploy_and_run_llms_at_the_edge_use_code_llama/",
          "publishedOn": "2023-10-13T20:43:49.000Z",
          "wordCount": 2674,
          "title": "[P] Deploy and Run LLMs at the Edge: Use Code Llama to Generate a Dashboard in a Network Restricted Environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1774n7g/d_iclr_submissions_are_out_discussion_thread/",
          "author": null,
          "description": "https://openreview.net/group?id=ICLR.cc/2024/Conference\n    submitted by    /u/_puhsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1774n7g/d_iclr_submissions_are_out_discussion_thread/",
          "publishedOn": "2023-10-13T17:59:11.000Z",
          "wordCount": 2516,
          "title": "[D] ICLR submissions are out. Discussion thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1772uyv/d_vscode_issue/",
          "author": null,
          "description": "I am running AutoTokenizer from transformers on vscode. The vscode crashes showing error and not responding. I don't understand what's wrong.\n    submitted by    /u/ArtichokeOne5897  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1772uyv/d_vscode_issue/",
          "publishedOn": "2023-10-13T16:35:21.000Z",
          "wordCount": 2532,
          "title": "[D] Vscode issue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771sog/p_utilizing_machine_learning_techniques_for/",
          "author": null,
          "description": "Hey Guys,\n ​\n I am currently spearheading a project for a client in the insurance industry, with a primary objective being the digitalization of thousands of hardcopy contracts. The ultimate goal is to automatically extract particular information from these newly digital documents, namely \"date\", \"insurance premium\", \"insurance type\", and \"contractor's name\". However, I anticipate a level of variability in terms of exact terminology used, particularly with regards to \"insurance premium\" and \"insurance type\". (There is no handwritten text)\n ​\n I am keen on sharing the methodology I intend to apply for this project and invite your invaluable feedback and suggestions:\n ​\n - Firstly, I'll execute the scanning/digitalization of the documents manually.\n - Post this, I plan to utilize Tesseract in combination with Python for the extraction of text from the preprocessed images.\n - I am considering using libraries such as NLTK or spaCy to preprocess this text (this will involve steps like lower casing, removing punctuations, etc.)\n - Finally, I plan to train a custom model for Named Entity Recognition (NER), to accommodate the potential semantic variations in entity labeling which are specific to entities like \"insurance premium\" and \"insurance type\".\n ​\n I would be immensely grateful if I could gain your insights on the above-proposed pipeline - Are there any glaring pitfalls I need to avoid or perhaps some improvements that I could incorporate? Your expert advice can certainly help ensure the success of this venture.\n ​\n Many thanks in anticipation for your time and valuable inputs!\n    submitted by    /u/Background_Thanks604  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771sog/p_utilizing_machine_learning_techniques_for/",
          "publishedOn": "2023-10-13T15:48:13.000Z",
          "wordCount": 2766,
          "title": "\"[P]\" Utilizing Machine Learning Techniques for Document Digitalization Project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771m35/news_ai_ml_conference_in_san_francisco_special/",
          "author": null,
          "description": "I work for this database company SingleStore and we are hosting a AI & ML conference in San Francisco on 17th of October, 2023.\n It is an in-person conference with amazing speakers line-up like Harrison Chase, co-founder and CEO of LangChain and many more. We will have hands-on workshops, swags giveaway and much more.\n I don't know if it makes sense to share this but I believe it might help some of you near San Francisco to go and meet the industry leaders and network with other data engineering folks.\n Use my discount coupon code 'PAVAN100OFF' to avail 100% off on the ticket price. (the original ticket price is $199)\n Get your tickets now!\n    submitted by    /u/PavanBelagatti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771m35/news_ai_ml_conference_in_san_francisco_special/",
          "publishedOn": "2023-10-13T15:40:09.000Z",
          "wordCount": 2642,
          "title": "[News] AI & ML conference in San Francisco [Special discount code for this subreddit]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771kn7/using_rag_on_coreml_version_of_llama2_p/",
          "author": null,
          "description": "Has anyone ever attempted this or finetuning before on the CoreML version? I’m currently trying to and I’m not even sure where to start tbh. \n CoreML version of Llama 2: https://huggingface.co/coreml-projects/Llama-2-7b-chat-coreml\n    submitted by    /u/Inside-Aromatic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771kn7/using_rag_on_coreml_version_of_llama2_p/",
          "publishedOn": "2023-10-13T15:38:15.000Z",
          "wordCount": 2553,
          "title": "Using RAG on CoreML version of Llama2 [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771jhl/d_how_does_l1_regularization_able_to_drive_a/",
          "author": null,
          "description": "Hi all, \n I’m studying the concepts of machine learning. However, I am stuck because I still don’t see how introducing a penalty using lasso regression can drive some parameter coefficients to zero. When doing the calculations, I only get the final value (ordinary least squares + penalty) and don’t directly see a coefficient value being reduced. \n I've looked at many materials and resources trying to explain this, but I still can't see how it's done. I think the important thing for me is seeing it going to zero or, at the very least, seeing it during calculation. Is there anyone that can help explain this better? Or, If you know of a formula that I can derive that, during the derivation process, shows a coefficient being reduced or set to zero, that would also help.\n Also, any good resources on the topic would be appreciated.\n Edit:\n This post should have been posted in r/learnmachinelearning\n here is a link to the same post in that subreddit\n    submitted by    /u/thismymind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771jhl/d_how_does_l1_regularization_able_to_drive_a/",
          "publishedOn": "2023-10-13T15:36:44.000Z",
          "wordCount": 2691,
          "title": "[D] How does L1 Regularization able to drive a coefficient to zero?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771hs4/d_how_do_you_prepay_openaai_compute_credit_with/",
          "author": null,
          "description": "I am an academic and I have some funding. However, I cannot just plug in my lab card with a recurrent payment, procedures don't allow it.\n Is there a way to \"top up\" some compute credits on the OpenAI accounts ? Is anyone having the same problem ? Thanks.\n    submitted by    /u/Jean-Porte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771hs4/d_how_do_you_prepay_openaai_compute_credit_with/",
          "publishedOn": "2023-10-13T15:34:34.000Z",
          "wordCount": 2574,
          "title": "[D] How do you pre-pay OpenaAI compute credit with university funds ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1771ccn/r_seeking_guidance_on_efficiently_classifying_and/",
          "author": null,
          "description": "Hi, we are working on a project that involves dealing with messy automotive data, and are looking for guidance on possible approaches and tools.\n We aim to map messy supplier data of car makes/models to standardized values from our approved list. This requires handling various challenges like typos, varied specificity, and sometimes research-based mapping (e.g., using engine size and production year to ascertain a chassis code).\n eg: If a supplier provides 'BNW 316i saloon 1990-1994', (typo intentional) we would like to match it to our standardized value of 'BMW 3 Series (E36)'.\n Our old approach has been a combination of utilizing fuzzy matching for typos/basic matching and time consuming manual processing and verification.\n We have recently experimented with using GPT for providing guess…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1771ccn/r_seeking_guidance_on_efficiently_classifying_and/",
          "publishedOn": "2023-10-13T15:27:56.000Z",
          "wordCount": 2857,
          "title": "[R] Seeking Guidance on Efficiently Classifying and Cleansing Automotive Data with Python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1770z8m/r_lemur_harmonizing_natural_language_and_code_for/",
          "author": null,
          "description": "Today's conversational bots like Claude and GPT can chat impressively but aren't great at complex planning or executing technical tasks. To overcome this, new research from HKU builds open-source AI agents that blend natural language and coding skills. They're called Lemur and Lemur-Chat.\n The researchers think achieving versatile real-world agents requires models that integrate both fluid natural language abilities and precise programming language control. Humans combine plain speech for higher-level goals with languages like Python when we need to plan intricately and execute exactly. AI needs both capacities too.\n But most existing models specialize in pure language or pure code. There's a separation that is limiting.\n The team created Lemur by pretraining the open-source Llama-2 on a massive mixed corpus with 10x more natural language than code. This improved its programming abilities while retaining conversational strength. Further instruction tuning optimized Lemur-Chat for following free-form directions in language.\n Experiments found Lemur surpassed specialized coding-only models like Codex in overall benchmarks. Lemur-Chat then exceeded Lemur by 15% after instruction tuning.\n More importantly, Lemur-Chat won 12/13 new \"agent tests\" designed to mimic real-world challenges needing both language and programming prowess.\n It beat alternatives at:\n  \nUsing tools like Python and Wikipedia to enhance reasoning\n Debugging code by leveraging error messages\n Improving the most from natural language feedback\n Exploring partially observable environments like cybersecurity and web browsing simulations.\n  \nLemur-Chat matched GPT-3.5 in many tests, closing the gap between commercial and open-source agents.\n TLDR: New open-source AI agents combine coding and language skills. Experiments show the combo unlocks more performance across technical challenges.\n Full summary is here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1770z8m/r_lemur_harmonizing_natural_language_and_code_for/",
          "publishedOn": "2023-10-13T15:11:34.000Z",
          "wordCount": 2788,
          "title": "[R] Lemur: Harmonizing Natural Language and Code for Language Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1770hqf/p_introducing_ppo_and_rainbow_dqn_to_our_super/",
          "author": null,
          "description": "Hi, we've just released a new version of AgileRL, our evolutionary hyperparameter optimisation framework built for RL that is 10x faster than SOTA. \n We've introduced PPO, Rainbow DQN, some sophisticated replay buffers, and also collaborated with the Farama Foundation to create some tutorials (more on the way).\n Please check it out and take it for a spin. We're also looking for contributors so get in touch if you would like to be involved!\n https://github.com/AgileRL/AgileRL\n    submitted by    /u/nicku_a  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1770hqf/p_introducing_ppo_and_rainbow_dqn_to_our_super/",
          "publishedOn": "2023-10-13T14:50:00.000Z",
          "wordCount": 2603,
          "title": "[P] Introducing PPO and Rainbow DQN to our super fast evolutionary HPO reinforcement learning framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17706n5/p_free_opensource_ml_observability_course_starts/",
          "author": null,
          "description": "Hi everyone, I’m one of the creators of Evidently, an open-source (Apache 2.0) tool for production ML monitoring. We’ve just launched a free open course on ML observability that I wanted to share with the community.\n The course covers:\n 📚 Key concepts of ML monitoring and observability (data drift, data and model quality metrics, etc.)\n 🔡 Monitoring unstructured data (embeddings, texts, LLMs, etc.) \n 🛠 Different deployment architectures (batch ML monitoring jobs, near real-time ML monitoring, etc.)\n The course is free and open. All materials are public, with no sign-up required. You’ll work with open-source tools like Evidently, MLflow, Airflow, and Grafana. \n We’ve already published the first 12 videos with notes and code examples. We’ll add new lessons and deployment blueprints over the following weeks.\n The official course start date is October 16, 2023. You can also learn at your own pace.\n Course info and notes: https://learn.evidentlyai.com/ \n [Background] We’ve been working on Evidently since late 2020 and have spoken to 100s of data scientists, ML engineers, and ML platform teams in different industries. In this course, we tried to sum up answers to the frequent questions on the topic. It starts with high-level theoretical modules and goes to complete deployment blueprints. It is approachable for different levels of knowledge, and you can pick only the modules you are interested in. \n Looking forward to meeting you at the course!\n    submitted by    /u/mllena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17706n5/p_free_opensource_ml_observability_course_starts/",
          "publishedOn": "2023-10-13T14:35:20.000Z",
          "wordCount": 2751,
          "title": "[P] Free open-source ML observability course: starts October 16 🚀",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176yocg/can_i_use_arcpro_to_do_machine_learning_on_point/",
          "author": null,
          "description": "I am trying to do machine learning in ArcPro, and I want to understand the relationship between x, y, numeric variable 1, numeric variable 2, and one nominal variable (classified; i.e. can be one of four values). I'd like to be able to predict numeric variable 1 based on everything else. Can ArcPro accommodate machine learning for anything other than raster type data. That is, can it be used to do machine learning on point (numeric) data? Thanks! \n    submitted by    /u/arcgis_123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176yocg/can_i_use_arcpro_to_do_machine_learning_on_point/",
          "publishedOn": "2023-10-13T13:24:03.000Z",
          "wordCount": 2606,
          "title": "Can I use ArcPro to do machine learning on point (numeric) data? [D] [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176wsne/r_timegpt_the_first_generative_pretrained/",
          "author": null,
          "description": "In 2023, Transformers made significant breakthroughs in time-series forecasting\n For example, earlier this year, Zalando proved that scaling laws apply in time-series as well. Providing you have large datasets ( And yes, 100,000 time series of M4 are not enough - smallest 7B Llama was trained on 1 trillion tokens! )\n Nixtla curated a 100B dataset of time-series and trained TimeGPT, the first foundation model on time-series. The results are unlike anything we have seen so far.\n I published the results in my latest article. I hope the research will be insightful for people who work on time-series projects.\n Link: https://aihorizonforecast.substack.com/p/timegpt-the-first-foundation-model \n Note: If you know any other good resources on very large benchmarks for time series models, feel free to add them below.\n ​\n    submitted by    /u/nkafr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176wsne/r_timegpt_the_first_generative_pretrained/",
          "publishedOn": "2023-10-13T11:43:09.000Z",
          "wordCount": null,
          "title": "[R] TimeGPT : The first Generative Pretrained Transformer for Time-Series Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176vgdn/r_pointers_to_deep_latent_variable_models_that/",
          "author": null,
          "description": "Hi everyone.\n I am aware that there is a plethora of deep generative models out there (e.g. variational autoencoders (VAE), GANs) that can model high-dimensional data as the images of latent variables under a non-linear mapping (typically neural network).\n In more traditional methods such as probabilistic PCA, the latent variables can be marginalised analytically. In Bayesian PCA (BPCA), we can additionally integrate out the linear mapping, from the latent space to the observation space, by adopting the variational lower bound that leads to closed form updates of the parameters. The Gaussian Process Latent Variable (GPLVM) model adopts a non-linear probabilistic mapping (a Gaussian process) that can be marginalised. These two models enjoy to a certain degree analytical solutions concerning the inference of the latent variables and the mapping.\n I have been wondering whether there is any research into more \"complex\" models (perhaps I should call them deep) that are capable of modelling more complex data distributions than the GPVLM and BPCA, but retain analytical solutions when inferring the posterior of the latent variables (like BPCA) or the mapping (like GPLVM)?\n What I like about the GPLVM and BPCA is that they possess an objective function (i.e. ELBO) that can be analytically optimised, as opposed to the intractable objective of VAEs that necessitates Monte-Carlo averages and stochastic gradient. Could somebody please point me to such examples of more complex generative models that admit analytical inference for working out the posterior of the latent variables or the mapping?\n -----\n This has also been posted on stack exchange: https://ai.stackexchange.com/q/42418/61537\n    submitted by    /u/ngiann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176vgdn/r_pointers_to_deep_latent_variable_models_that/",
          "publishedOn": "2023-10-13T10:17:39.000Z",
          "wordCount": 2781,
          "title": "[R] Pointers to (deep) latent variable models that admit analytical approximations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176uov8/d_i_love_teaching_but_i_dont_have_enough/",
          "author": null,
          "description": "Do I love teaching? Oh, absolutely, YES a big YES! My time as a TA for countless semesters has been amazing. Staying after hours, spending long evenings and early mornings, to make each of my students find ease in debugging both easy-peasy and mind-boggling programs – it’s been a joy, truly. Watching those fresh faces, whom I introduced to Python in their first year ( intro to programming lab), now immerse themselves into my computer vision labs, exploring computer vision and deep learning in their third/forth year – it’s incredibly rewarding! And yeah my students kind of like me! after each semester I get tons of emails thanking me and my TAship review is always good.\n But, ugh, do I have enough publications to become faculty? A big fat NO! My efforts have been relentless, and everyone in my department would nod in agreement. But luck and reviewers? Not my best pals, apparently. So yeah, I don’t have a stack of 8 top-tier papers. I’ve managed to scrape together 3, and a few second tiers. My citation count is not that bad somewhere between 200 and 300-ish.\n Now, what’s next for me? Dive into the industry? become a high school teacher? Or perhaps, do a postdoc journey, fingers crossed for a sprinkle more luck and few more papers?\n Edit: This doesn't mean I don't like research, I actually love it too, I have done quite a few internship in quite big companies, most of the time they extend my intership and I even got publication out of one in 5 month. But I just like to teach a lot! strangely I got social anxiety every where other than my classrooms/labs.\n    submitted by    /u/LongjumpingSchool646  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176uov8/d_i_love_teaching_but_i_dont_have_enough/",
          "publishedOn": "2023-10-13T09:23:00.000Z",
          "wordCount": 2810,
          "title": "[D] I love teaching! But I don't have enough publication for it, what should I do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176rwv3/d_you_dont_need_a_vector_database_you_just_need_a/",
          "author": null,
          "description": "I'm seeing some architectures come out from the LLM world that probably wouldn't survive the trip to production.\n If you choose a vector database how will you handle your other database needs? Then you'll need 2 databases.\n https://bionic-gpt.com/blog/you-dont-need-a-vector-database/\n    submitted by    /u/purton_i  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176rwv3/d_you_dont_need_a_vector_database_you_just_need_a/",
          "publishedOn": "2023-10-13T06:05:46.000Z",
          "wordCount": 2564,
          "title": "[D] You don't need a Vector Database you just need a database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176rt6l/d_why_backpropagation_is_intractable_of_moco_key/",
          "author": null,
          "description": "In the original paper of MoCo, it said that:\n  \nUsing a queue can make the dictionary large, but it also makes it intractable to update the key encoder by back-propagation (the gradient should propagate to all samples in the queue).\n  \nFirst I thought that the main reason that the bp cannot imply on key encoder is that the queue operation is not differentable. But It seems not true. You can compute the gradient of all samples in the queue, then bp should be performed properly. See the code at the bottom.\n So WHAT IS THE REAL REASON THAT THE BP IS INTRACTABLE FOR KEY ENCODER? In my opinion, I think may be because of the large size of the queue (dictionary) which makes the memory explosive.\n python q = nn.Linear(768,128) k = nn.Linear(768,128) bs = 64 ks = 4095 model = nn.ModuleList([q,k]) x = torch.randn(bs, 768) optim = torch.optim.SGD(model.parameters(),lr=0.01) loss = nn.CrossEntropyLoss() def forward(x): xq = q(x) xk = k(x + 0.1) que = torch.rand(ks,128) pos = torch.einsum(\"nc,nc->n\",xq,xk) neg = torch.einsum(\"nc,kc->nk\",xq,que) out = torch.cat([pos.unsqueeze(-1),neg],dim=1) t = torch.zeros(out.shape[0],dtype=torch.long) l = loss(out,t) return l loss = forward(x) loss.backward() optim.step() \n    submitted by    /u/whishtLF  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176rt6l/d_why_backpropagation_is_intractable_of_moco_key/",
          "publishedOn": "2023-10-13T05:59:56.000Z",
          "wordCount": 2703,
          "title": "[D] Why back-propagation is intractable of MoCO key encoder?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176mlrr/d_advisor_rejects_every_idea_i_propose/",
          "author": null,
          "description": "A senior phd student at a moderately famous university. I have a reasonable number of accepted papers as first author in tier-1 conferences. I was thinking of going into academia, so recently I started proposing many ideas to my advisor so that I can mentor some junior students. However my advisor is rejecting every idea I suggest saying it won’t work. I’m feeling very dejected and I feel like I should give up going into academia. I don’t know what I’m expecting from here. Is your advisor like this too?\n    submitted by    /u/mildlyphd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176mlrr/d_advisor_rejects_every_idea_i_propose/",
          "publishedOn": "2023-10-13T01:00:53.000Z",
          "wordCount": 2611,
          "title": "[D] Advisor rejects every idea I propose.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176ia5w/r_researchers_identify_emergent_linear_structures/",
          "author": null,
          "description": "LLMs' tendency to make up false statements (hallucinate) is a major concern. We need ways to inspect whether they really \"know\" something is true or not so we can reduce hallucinations.\n In a new paper, researchers found that LLMs contain an internal \"truth vector\" - an emergent linear structure that represents factual truth values.\n They had the insight to visualize how GPT represents simple true/false sentences. The true ones clustered together, while false ones clustered elsewhere - suggesting some kind of 'truth direction' in its learned representations.\n To test this, they trained linear \"probes\" on one dataset, and found they could generalize to accurately detect truth values in totally different datasets about other topics.\n They also directly modified the models to add or subtract the identified truth vectors from its processing of statements. This could flip assessments of truth value, showing the vector causally influences reasoning.\n Together, these findings provide evidence that neural networks can create emergent, linear structures that represent factual truth. This finding could eventually help make AI systems less prone to hallucinations and falsehoods.\n TLDR: LLMs can create emergent linear representations of truth. This sheds light on how AI represents abstract concepts and could help us reduce hallucinations.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176ia5w/r_researchers_identify_emergent_linear_structures/",
          "publishedOn": "2023-10-12T21:38:42.000Z",
          "wordCount": 2731,
          "title": "[R] Researchers Identify Emergent Linear Structures in How LLMs Represent Truth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176h8id/d_recommendations_request_for_a_guide_to_research/",
          "author": null,
          "description": "I am working on a research topic in Data Engineering. Forgive me if this is a question frequently asked, I couldn't find this specifically in the FAQ. What are good publication tips and journals to publish in? I read through a few journals and all of them are big publications. What if I opt fot some upcoming or other niche (maybe data engineering) journals\n    submitted by    /u/Sherbhy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176h8id/d_recommendations_request_for_a_guide_to_research/",
          "publishedOn": "2023-10-12T20:56:46.000Z",
          "wordCount": 2587,
          "title": "[D] Recommendations request for a guide to research publication",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176f89x/r_swebench_can_language_models_resolve_realworld/",
          "author": null,
          "description": "We have a new benchmark out called SWE-bench (arxiv) \n It challenges LMs to solve real GitHub issues (feature requests & bug reports) from popular Python repos.\n Answers are validated using unit tests we crawled from those repos.\n The benchmark at swebench.com/ shows that even the strongest models, such as Claude 2 and GPT-4, get less than 5% accuracy.\n ​\n We are here to answer any questions you may have.\n    submitted by    /u/ofirpress  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176f89x/r_swebench_can_language_models_resolve_realworld/",
          "publishedOn": "2023-10-12T19:28:30.000Z",
          "wordCount": 2591,
          "title": "[R] SWE-bench: Can Language Models Resolve Real-world GitHub issues?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176efaf/d_sample_probability_diffusion_models/",
          "author": null,
          "description": "I would like to understand how I can calculate the probability that a sample belongs to the distribution a diffusion model was trained on. \n Say, I have an image of a car, and I would like to know whether this image belongs to the distribution that is estimated by the diffusion model. So I would like to know the probability between zero and one at the car belongs to this distribution \n Do you know how I technically can do this?\n    submitted by    /u/That_Phone6702  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176efaf/d_sample_probability_diffusion_models/",
          "publishedOn": "2023-10-12T18:52:20.000Z",
          "wordCount": 2599,
          "title": "[D] Sample probability diffusion models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/176c9ty/discussion_making_a_tutorial_for_using_a_new/",
          "author": null,
          "description": "Hey guys\n Looking for some ideas. \n I'm building out a jupyter book that will be a tutorial on how to use a research platform for data analysis and modelling. My PI has given me free liberty over it.\n I can not think of a good idea to do the analysis and build the model on. It does not need to be complex but should be good enough so that any researcher, student or organization using the platform can get a good idea of how to use it for ML. \n Any thoughts on a good area to look into? Any recommendations? \n Note this will be a tutorial and as such an overly complex model is unnecessary. I just can not figure out what to look into so hoping you guys could give thoughts about possible areas in climate, weather and earth science that I could focus on for the tutorial in the jupyter book.\n    submitted by    /u/AdditionalFun3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/176c9ty/discussion_making_a_tutorial_for_using_a_new/",
          "publishedOn": "2023-10-12T17:20:05.000Z",
          "wordCount": 2685,
          "title": "[Discussion] Making a Tutorial for Using a New Platform for ML in the climate and earth science space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1769su5/d_submitting_a_paper_rejected_by_emnlp_to_arr/",
          "author": null,
          "description": "First time submitting to ARR here. I was quite confused about this paper resubmission thing. I got rejected by EMNLP (submission directly to EMNLP with openreview) a week ago and I am planning to resubmit it to the ARR system (also using openreview). Does this EMNLP submission count as a previous ARR submission that should be mentioned or not? Do I need to withdraw the paper from EMNLP openreview prior to submitting it to ARR openreview?\n    submitted by    /u/Icy-Distribution6887  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1769su5/d_submitting_a_paper_rejected_by_emnlp_to_arr/",
          "publishedOn": "2023-10-12T15:34:12.000Z",
          "wordCount": 2599,
          "title": "[D] Submitting a paper rejected by EMNLP to ARR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1765v6i/d_p_uibased_ai_agents_uiact/",
          "author": null,
          "description": "Hi!\n Happy to share a project I've been working on for a while: UI-Act\n https://github.com/TobiasNorlund/UI-Act\n It's an AI model architecture designed to autonomously navigate and interact with computers using the graphical user interface. Think of it as a co-pilot that \"sees\" your screen and acts on it, just as a human would.\n In essence, it's a custom transformer model taking prompt and screenshots as input, with output heads to predict low-level actions i.e. mouse clicks. In the demo, it has been trained to compute simple expressions in a calculator window, using expert demonstrations/behavior cloning. If scaled up appropriately however, it could provide a basis for a general agent to automate arbitrary tasks on a computer. \n I would be interested in hearing your thoughts on it, and especially with regards to the trend towards general AI agents and assistants (Windows Copilot / Adept ACT-1 / AutoGPT etc).\n LMs equipped with e.g. function-calling is a trendy approach, that rely on text-based state representations and APIs to take action. In cases where this is unfeasible, UI-based agents might provide a more general alternative. As the agent's interface to the computer is shared with humans, it can be easily taught using expert demonstrations, and require little or no technical expertice.\n Let me know what you think!\n    submitted by    /u/tobibbelfuel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1765v6i/d_p_uibased_ai_agents_uiact/",
          "publishedOn": "2023-10-12T12:31:22.000Z",
          "wordCount": 2732,
          "title": "[D] [P] UI-based AI agents: UI-Act",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17652mm/p_learn_how_to_make_trustworthy_and_transparent/",
          "author": null,
          "description": "​\n Confidence and trustworthiness of Tsetlin Machines.\n Hi all! Just completed a new chapter in the book An Introduction to Tsetlin Machines:\n https://tsetlinmachine.org\n Happy to receive feedback!\n Abstract: Collaboration can be essential to manage complex projects. One example is building a house. You then need the expertise of carpenters, plumbers, and electricians. Each profession brings unique skills to the table. Similarly, different types of Tsetlin machines can have distinct capabilities. In this chapter, you learn how Tsetlin machines can team up, allowing them to achieve more than they could on their own.\n The effectiveness of a team relies on recognising each member's strengths and limitations. Appreciating where your expertise stops and where your coworkers' expertise begins is crucial for effective collaboration. We first explore how Tsetlin machines can assess their competence in Section 7.1. Using the vote count from Chapter 1, you learn to measure how confident a Tsetlin machine is when it makes its decisions.\n It is possible to be highly confident and still perform poorly. To be trustworthy, confidence must be in line with one's capabilities. Therefore, Section 7.1 also covers how to evaluate trustworthiness.\n Next, in Section 7.2, you discover how to build a team of Tsetlin machines with different skills. By assessing each Tsetlin machine's confidence, you can lean on the confident ones when making decisions. The result is a Tsetlin machine composite - a construction where multiple Tsetlin machines join forces. You can think of it as a composite material, such as epoxy, which reinforces resin with fibres, making it strong, lightweight, and durable.\n    submitted by    /u/olegranmo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17652mm/p_learn_how_to_make_trustworthy_and_transparent/",
          "publishedOn": "2023-10-12T11:49:50.000Z",
          "wordCount": 2793,
          "title": "[P] Learn how to make trustworthy and transparent machine learning models in Tsetlin Machine Book Chapter 7: Confidence, Trustworthiness, and Composites.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1764sk0/r_d_need_peer_review_unsupervised_learning_for/",
          "author": null,
          "description": "Hello all,\n Just wrapped up Task 1.1 for anomaly detection in student dropout rates. Keen for some extra eyes on it.\n Task Highlights:\n  \nData Pre-processing & Normalisation\n K-Means Clustering\n Gaussian Anomaly Detector\n Used PCA for dimensionality reduction\n  \nLinks to the following files:\n  \ndata.csv\n Task 1.1 - Rubric.pdf\n Task1.1Script.ipynb\n  \nhttps://drive.google.com/drive/folders/17XcjEoYCrDWqf90VVNdkLAkYNdtWWwGu?usp=sharing\n Would greatly appreciate any feedback!\n Cheers!\n    submitted by    /u/Nook31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1764sk0/r_d_need_peer_review_unsupervised_learning_for/",
          "publishedOn": "2023-10-12T11:33:27.000Z",
          "wordCount": null,
          "title": "[R] [D] Need Peer Review: Unsupervised Learning for Student Dropout Anomaly Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1761q5r/r_a_method_to_assess_trustworthiness_of_machine/",
          "author": null,
          "description": "submitted by    /u/mnky9800n  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1761q5r/r_a_method_to_assess_trustworthiness_of_machine/",
          "publishedOn": "2023-10-12T08:13:12.000Z",
          "wordCount": 2536,
          "title": "[R] A method to assess trustworthiness of machine coding at scale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175zifi/p_vilays_prototype_video_demo_any_feedback_from/",
          "author": null,
          "description": "Hi everyone,\n I’m thrilled to share a prototype we've been tirelessly working on.\n We are developing a virtualization environment for applications, specifically tailored to engineers, designers, data scientists, and researchers.\n In a nutshell, our platform enables users to run cloud-hosted desktop apps from any device, making it appear as if the applications are installed on their local machines, while they're actually operating on a remote server. The ultimate goal is to obliterate barriers between local and cloud execution, especially for compute-intensive workloads, thereby allowing seamless usage of High-Performance Computing software on the cloud with the scalability to adjust computing resources as per necessity.\n We’re here to solicit your invaluable feedback on our product video demo. Your insights will not only help us identify any blind spots and enhance our solution but also better understand the needs and preferences of our potential user base.\n 📽 [https://youtu.be/QR8FWRnPrXM?feature=shared]\n We're eagerly awaiting your thoughts and appreciate you taking the time to help us refine our product!\n Thank you! :)\n    submitted by    /u/aaron-cesaro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175zifi/p_vilays_prototype_video_demo_any_feedback_from/",
          "publishedOn": "2023-10-12T05:44:31.000Z",
          "wordCount": null,
          "title": "[P] [vilays] Prototype Video Demo - Any Feedback from ML Engineers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175xljs/d_databricks_dolly_15k_creating_synthetic_variants/",
          "author": null,
          "description": "Hey all, I found Dolly to be a very interesting project when it was released but I'm curious if it has similar value today because a lot of synthetic data generation options seem to be popping up.\n Now it seems like Dolly is human generated/curated by over 5k employees (which is great), but wouldn't it be a better approach now to have Llama70b (or maybe Falcon) just generate future variants of 15k rows? I havent been able to figure out why we arent seeing more synthetic datasets like this on HF? Is the bottleneck licensing, compute or just incentive?\n Heres the original Dolly post thread: https://www.reddit.com/r/MachineLearning/comments/120usfk/r_hello_dolly_democratizing_the_magic_of_chatgpt/\n    submitted by    /u/buzzyness  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175xljs/d_databricks_dolly_15k_creating_synthetic_variants/",
          "publishedOn": "2023-10-12T03:51:16.000Z",
          "wordCount": null,
          "title": "[D] Databricks Dolly 15k - Creating Synthetic Variants",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175wpwi/d_please_suggest_a_loss_function_for_image_to/",
          "author": null,
          "description": "What is the loss function that needs to be used for a task that takes an input image with a lot of haze and produces an image with reduced haze.\n The architecture is a simple encoder decoder architecture.\n I tried MSE as some articles and ML guides say that MSE is good for pixel wise comparison and also tried Categorical Crossentropy but none of them work so great.\n MSE works but produces artefacts like red/green/ blue spots and spatters and at worse times it produces a white image.\n The research on this task includes use of SIDNet[Single Image Dehazing Net], Transmission maps, Dark channel prior algorithm, FFA net, etc trained on the Benchmark datasets (RESIDE,SOTS).\n I aim to create a simple architecture for college project so I chose the Enc-Dec architecture. Any suggestions are appreciated.\n    submitted by    /u/Wild_Basil_2396  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175wpwi/d_please_suggest_a_loss_function_for_image_to/",
          "publishedOn": "2023-10-12T03:04:32.000Z",
          "wordCount": null,
          "title": "[D] Please suggest a Loss function for image to image task.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175wano/d_startup_team_demonstrates_differentiable_swift/",
          "author": null,
          "description": "Autonomous systems startup, PassiveLogic, assembled a differentiable computing team, to build a fast systems language with native performance differentiability. Their latest benchmark trains networks two orders of magnitude faster than PyTorch and Tensorflow. See: LinkedIn Post&dashCommentUrn=urn%3Ali%3Afsd_comment%3A(7118052434916110337%2Curn%3Ali%3Aactivity%3A7117911978106355712))\n It's a collaborative effort with the Swift community and Apple's compiler team, using the Swift language as a strongly typed embedded language that performs ahead of time compilation of graph neural nets. The focus is on fusing systems programming and AI engineering into a single native high performance language, to enable typed heterogeneous inference and training.\n The compiler development is open sourced as part of the standard Swift package. Try it yourself at swift.org.\n    submitted by    /u/taharvey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175wano/d_startup_team_demonstrates_differentiable_swift/",
          "publishedOn": "2023-10-12T02:42:56.000Z",
          "wordCount": 2635,
          "title": "[D] Startup team demonstrates differentiable Swift compiler outrunning TensorFlow by 322X",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ugw5/d_how_is_testdriven_development_implemented_in/",
          "author": null,
          "description": "I recently tried to refactor a previous project that I had, but I realized that after making all of the changes the performance wasn't reproducible anymore. I decided to start from scratch, make incremental changes, and make sure that the model's performance is maintained with each change. Very basic in hindsight, but I guess I was too hasty with coding.\n Anyway, running the full model's training and evaluation with each change is proving to take too long. I'm curious if there's any other way that people implement TDD in the context of machine learning since projects/applications tend to be more time consuming then typical applications.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ugw5/d_how_is_testdriven_development_implemented_in/",
          "publishedOn": "2023-10-12T01:14:38.000Z",
          "wordCount": null,
          "title": "[D] How is test-driven development implemented in the context of machine learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175qdu3/d_how_to_download_datasets_from_huggingface/",
          "author": null,
          "description": "Hello, first time using Google Colab and huggingface datasets. Colab notebook is easy to setup but I can't seem to figure out how to download datasets from huggingface.\n I am trying to download https://huggingface.co/datasets/kili-technology/plastic_in_river dataset in Colab Notebook. After reading some beginners forums, I modified the example to look like one below but it failed.\n from datasets import load_dataset data_files = {\"train\": \"train.csv\", \"test\": \"test.csv\", \"validation\": \"validation.csv\"} dataset = load_dataset(\"kili-technology/plastic_in_river\", data_files=data_files) \n Because there's no path to the files to be downloaded. Can someone explain how to download datasets from huggingface please?\n Downloading builder script: 100% 3.25k/3.25k [00:00<00:00, 228kB/s] Downloading metadata: 100% 2.79k/2.79k [00:00<00:00, 147kB/s] Downloading readme: 100% 496/496 [00:00<00:00, 34.2kB/s] --------------------------------------------------------------------------- FileNotFoundError Traceback (most recent call last) <ipython-input-5-98701edb7a4d> in <cell line: 4>() 2 3 data_files = {\"train\": \"train.csv\", \"test\": \"test.csv\", \"validation\": \"validation.csv\"} ----> 4 dataset = load_dataset(\"kili-technology/plastic_in_river\", data_files=data_files) 5 frames /usr/local/lib/python3.10/dist-packages/datasets/data_files.py in resolve_pattern(pattern, base_path, allowed_extensions, download_config) 366 if allowed_extensions is not None: 367 error_msg += f\" with any supported extension {list(allowed_extensions)}\" --> 368 raise FileNotFoundError(error_msg) 369 return out 370 FileNotFoundError: Unable to find 'https://huggingface.co/datasets/kili-technology/plastic_in_river/resolve/main/train.csv' \n    submitted by    /u/0ni0nrings  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175qdu3/d_how_to_download_datasets_from_huggingface/",
          "publishedOn": "2023-10-11T22:06:28.000Z",
          "wordCount": 2711,
          "title": "[D] how to download datasets from huggingface",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ns6h/d_how_do_bytelevel_language_models_work/",
          "author": null,
          "description": "I've recently been trying to pre-train my own small language model on the tiny-series datasets on huggingface. I also wanted to use a model similar to MEGABYTE but I don't understand how using bytes would work. The only implementation I could find from lucidrains used str(chr(max(32, token))) to decode any token (byte) to a character and put the embedding size as 256. Firstly, why 256 and not 256-32 as any values below 32 are ignored? Also, many byte-level models including this and ByteT5 mention that they can process any text sequence even in a multilingual setting, however how would that be true if we are only using one byte, would we have to move to 2 bytes or use an UNK token, and if we did use 2 bytes that would make our embedding size around 65000 which defeats sort of the point as o…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ns6h/d_how_do_bytelevel_language_models_work/",
          "publishedOn": "2023-10-11T20:18:32.000Z",
          "wordCount": 2887,
          "title": "[D] How do byte-level language models work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175n78x/p_evaluating_and_tuning_a_model_when_the/",
          "author": null,
          "description": "Consider a predictive model that is predicting if an outcome Y will occur in Q1 2023, based on data from Q1 2022.\n Now, if want to predict outcomes for 2024, we must use last years data to build the model, but we are going to have some bias if there are features that vary year over year.\n Is the best approach in such a situation to try and tune/validate the model with other years in the hopes of mitigating any features that are correlated with a specific year? \n Any help would be much appreciated, as I can't find agreed upon methods.\n    submitted by    /u/unga123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175n78x/p_evaluating_and_tuning_a_model_when_the/",
          "publishedOn": "2023-10-11T19:54:48.000Z",
          "wordCount": 2655,
          "title": "[P] Evaluating and tuning a model when the population may change YoY and best practices for mitigating overfitting on features that correlate with time.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175lw8r/is_there_a_model_to_input_anecdotal_text_stories/",
          "author": null,
          "description": "I have a goal and am looking for direction from others who know more than me about machine learning. \n I want to submit 5-10 pieces of text to a model. The text will be anecdotes from a common experience but each one from a different person’s perspective. For example, if a family visits a theme park, each family member will have a story or two about the day. Each family’s story would be a submission to the model. One person might have loved the roller coaster and can tell about the exciting parts. Another person maybe just can’t stop talking about how great he food was. Someone else maybe felt sick and complains the line at the bathroom was too long. Perhaps another family member also rode the same roller coasters as the first person but instead hated it, so would have a very different description of it than the first. \n All these anecdotes are submitted to the model. \n Then, the model can be queried. Such as, \n “Tell me about the theme park.” \n or\n “I love roller coasters. Tell me about the theme park.” \n or\n “I tend to overeat, tell me about the theme park.” (the model wouldn’t hype of the food, maybe it would talk about how much exercise the visitors get by walking around all day.) \n In this case of a theme park context, the model would have a preconception of a theme park. It would know the general concept, know of several examples or standards that it could compare this theme park against, understand it’s all for fun, etc. \n This type of model may be available as an API or model already and I just don’t know about it. That’d be fine, please point me towards it. Or, maybe there’s something already available but would need tweaked or customized.\n    submitted by    /u/Semper_Disco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175lw8r/is_there_a_model_to_input_anecdotal_text_stories/",
          "publishedOn": "2023-10-11T18:59:24.000Z",
          "wordCount": 2851,
          "title": "Is there a model to input anecdotal text stories as training data to return a more comprehensive story? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175l9mz/d_help_me_learn_ml_easily_specially_in_model/",
          "author": null,
          "description": "Can you give easy to understand sources and hands-on practice methodology to master ML? Help me understand build the models in and out . Thank you\n    submitted by    /u/the_mystic_1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175l9mz/d_help_me_learn_ml_easily_specially_in_model/",
          "publishedOn": "2023-10-11T18:32:02.000Z",
          "wordCount": 2568,
          "title": "[D] Help me learn ML easily specially in model building and EDA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175k7bl/nsf_workshop_on_llms_in_chemistry_education_r/",
          "author": null,
          "description": "Over Feb 12-13 of 2024, the National Science Foundation (NSF) is sponsoring a workshop titled “Integrating LLMs into the Materials Chemistry Curriculum” in Golden, Colorado. We aim to explore and develop innovative ways to incorporate large language models (LLMs, e.g. GPT, ChatGPT, and Bard) into upper division chemistry laboratories and virtual lab experiences. During the workshop, participants will brainstorm and create demonstrations incorporating LLMs into the curriculum.\n The event will bring together folks across academia and the private sector with disciplinary backgrounds that range across chemistry, computer science, materials science, physics, and education. There is no registration fee, and we anticipate being able to cover the majority of participant travel costs thanks to NSF support. Participants early in their career (i.e., graduate students, postdoctoral scholars) are particularly encouraged to apply.\n If you are interested in participating in this workshop, please fill out the Google form (link below).\n Please feel free to distribute this invitation widely.\n Application: https://forms.gle/P9QdNiCuaUAHFZj29\n    submitted by    /u/KC2792  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175k7bl/nsf_workshop_on_llms_in_chemistry_education_r/",
          "publishedOn": "2023-10-11T17:47:21.000Z",
          "wordCount": 2689,
          "title": "NSF workshop on LLMs in chemistry education [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ji6s/p_where_to_find_projects_to_contribute_to/",
          "author": null,
          "description": "Hello, I'm a developer with 6 years of experience in the mobile field, and I recently completed my master's degree in artificial intelligence (Text mining). I want to transition into the field of AI, but I need more experience with projects in the \"real world,\" outside of academia, and I'd like to contribute to an open-source project. I looked on Github, but I ended up feeling confused and not sure where to start.\n P.S.: I did some research in this subreddit, but the posts about contributions seemed a bit dated.\n    submitted by    /u/Substantial_Fact_205  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ji6s/p_where_to_find_projects_to_contribute_to/",
          "publishedOn": "2023-10-11T17:18:07.000Z",
          "wordCount": 2628,
          "title": "[P] Where to find projects to contribute to?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ie4l/p_image_based_python_opencv_automation_mmorpg/",
          "author": null,
          "description": "Video:\n https://youtu.be/0m12vkaoE7w\n ​\n Detailed Medium post will follow in the upcoming days.\n https://medium.com/@pssdplayer\n    submitted by    /u/HistorianCrafty3514  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ie4l/p_image_based_python_opencv_automation_mmorpg/",
          "publishedOn": "2023-10-11T16:32:54.000Z",
          "wordCount": 2554,
          "title": "[P] Image based Python + OpenCV automation, MMORPG Laghaim Auto-Fighter Bot Demo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175i3xg/d_i_have_2030_million_shopify_products_dataset/",
          "author": null,
          "description": "I have collected over 20 million shopify products & had the following ideas for them: \n - LLM ( Finetune an llm to know how to speak ecom )\n - Video bot that can make videos on those products, using their description, elevenlabs & AIFaceGen\n - EcomStore that will markup the products about 30% ( This will need the bot to frequently scrape, to ensure that the products are up to date ) \n - Selling the dataset based on fragments, like 1$ per 1k-10k records, depends on what sells. \n Please let me know if these are good ideas, and if someone would like to support / help me in any way ( I just need to selfhost my supabase instance, & add all the products to it & then dev can get started ) \n    submitted by    /u/AdonisCodes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175i3xg/d_i_have_2030_million_shopify_products_dataset/",
          "publishedOn": "2023-10-11T16:21:31.000Z",
          "wordCount": 2672,
          "title": "[D] - I have 20-30 million shopify products dataset, any ideas?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175hovg/d_best_opensource_ai_model_for_qa_generation_from/",
          "author": null,
          "description": "As the title says I’m looking for an open-source AI model for generating question-and-answers with a correct answer option and explanation to the correct answer from the input context. So far I have tried these models,\n  \nTheBloke/Llama-2-7B-GPTQ\n TheBloke/Llama-2-13B-GPTQ\n TheBloke/Llama-2-7b-Chat-GPTQ (the output is not consistent. Sometimes I get an empty response or without the correct answer option and an explanation data)\n TheBloke/Llama-2-13b-Chat-GPTQ (even 7b is better)\n TheBloke/Mistral-7B-Instruct-v0.1-GGUF(so far this is the only one that gives the output consistently. But not able to generate more than 2 QA due to max token limit of 512. Even tried setting the max token as 1024, 2048 but nothing helped)\n TheBloke/Mistral-7B-OpenOrca-GGUF\n NousResearch/Llama-2-7b-chat-hf\n  \nMy system configurations are: Windows 10 with 16GB GPU\n Additional Information: The input prompt token will be around 250-350 tokens per request.\n    submitted by    /u/gokulcv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175hovg/d_best_opensource_ai_model_for_qa_generation_from/",
          "publishedOn": "2023-10-11T16:04:17.000Z",
          "wordCount": 2663,
          "title": "[D] Best open-source AI model for QA generation from context",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175h9zh/churn_prediction_r/",
          "author": null,
          "description": "I want to build a model to predict churn in a third party logistics company. What variables should make up my data? Any help would do. Thanks\n    submitted by    /u/DisastrousAd8814  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175h9zh/churn_prediction_r/",
          "publishedOn": "2023-10-11T15:47:38.000Z",
          "wordCount": 2560,
          "title": "Churn Prediction [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175h4ob/d_recommendations_for_cpubased_realtime_vector/",
          "author": null,
          "description": "Hello everyone, I have a specific online vectorization use case: I'm looking to search the internet for articles, vectorize these articles along with the search queries, and then retrieve the most relevant passages from them. Currently, I have basic hosting through DigitalOcean. \n Could anyone recommend the most suitable vector dataset for this task? Additionally, considering my resources, is it feasible to run this system solely on CPUs? And if so, would this setup be scalable if deployed on CPUs only?\n    submitted by    /u/Traditional-Poet2746  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175h4ob/d_recommendations_for_cpubased_realtime_vector/",
          "publishedOn": "2023-10-11T15:41:43.000Z",
          "wordCount": 2620,
          "title": "[D] Recommendations for CPU-Based Real-Time Vector Database Indexing and Matching?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175g6rn/r_network_digital_twin_for_cybersecurity/",
          "author": null,
          "description": "Hi all,\n for a text work of mine I am trying to do a project based on generating digital twin of networks. My goal is to create a digital twin of a network and then work on it from a cyber security point of view. I will briefly explain what I would like to do.\n I am currently using software for network vulnerability scans (OpenVAS). I use this software to perform network vulnerability scans at the network level, so basically to OpenVAS I pass a network (for example 192.168.xx.xx/24) to automatically identify all the vulnerabilities that are there.\n The next step ( what I'd like to do and that's why I'm asking for your advice) is to create a digital twin of the newly scanned network and then perform a penetration test on this digital twin of the network, without going to stress the actual network.\n Ideally, I would like to pass the output of the OpenVAS vulnerability scans, routing rules, and firewall rules to some tool that will then generate for me the digital twin of the network, which will then be used for offensive cybersecurity, so exploits, privilege escalation, etc.... will be tested on this digital twin without worrying about breaking some kind of service or stressing the real network.\n What I am asking is, do you know of any tool that would do the trick for me? So some tool that allows me to generate a digital twin of a network by providing as input vulnerability scans (xml,json,csv etc...), routing rules, firewall rules, pcap traces etc... \n Do you have any references or documentation? \n Are you aware of any open source tools?\n I thank you for your helpfulness!\n ​\n    submitted by    /u/Salt-Arugula-8128  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175g6rn/r_network_digital_twin_for_cybersecurity/",
          "publishedOn": "2023-10-11T15:04:28.000Z",
          "wordCount": 2816,
          "title": "[R] network digital twin for cybersecurity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175fobx/best_approach_for_vfx_lineups_using_ml_project/",
          "author": null,
          "description": "Quick intro\n Lineups are one of the first steps in the VFX pipeline\n Source:\n - orignal footage that was shot on set\n - a reference (quicktime) video from the film edit.\n Task:\n The reference shows modifications to the original footage. They can be :\n - timewarp (either fixed retimes like 200% speed or completely random)\n - transform (moved the image in x/y axis, rotation, scale, etc.)\n So the lineup task is to align the original footage to the reference quicktime.\n What I did so Far:\n Made a simple script in the software Nuke, using some Python and readily available tools to make it work on a simple shot. General logic is compare every frame and the associated one is the frame with the least difference between the two. This works on super simple and straightforward tasks. (can provide more info if needed).\n Issue:\n Some references are more heavily modified. They can have some muzzle flash, basic 3d objects or even some slight error introduced like a distortion applied to the image when none shouldn't so it will never be perfectly aligned. This makes the difference of the full frame higher for some frames, making the lineup wrong. (it will take the wrong frame that has no muzzle flash, because it has less difference...)Some other things to consider is that watermarks are covering the ref and the colors are not perfectly matching, can get them close enough, but there's a difference.\n Conclusion:\n Because of those issues, I'm thinking about using Machine Learning. I have next to no knowledge on the subject. I know there Is a bunch of ways to train a model, but no clue where to start, so here's my question :\n Which learning styles has the best potential to be able to solve this task?\n    submitted by    /u/Pretty_Customer_8113  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175fobx/best_approach_for_vfx_lineups_using_ml_project/",
          "publishedOn": "2023-10-11T14:43:28.000Z",
          "wordCount": 2827,
          "title": "Best approach for VFX lineups using ML [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ezse/r_what_are_some_interesting_research_topics_to/",
          "author": null,
          "description": "I will have to pick and start a research project next January for my final year. So wanted to start exploring now. \n I want to do something substantive and interesting enough to get published.\n    submitted by    /u/BadMeditator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ezse/r_what_are_some_interesting_research_topics_to/",
          "publishedOn": "2023-10-11T14:13:22.000Z",
          "wordCount": 2582,
          "title": "[R] What are some interesting research topics to study in the intersection of ML and signal processing currently?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ep9x/r_mistral_7b/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ep9x/r_mistral_7b/",
          "publishedOn": "2023-10-11T14:00:25.000Z",
          "wordCount": 2544,
          "title": "[R] Mistral 7B",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ep6x/r_tsinghua_university_inverting_transformers/",
          "author": null,
          "description": "Transformers are great at NLP and computer vision tasks, but I was surprised to learn they still lag behind simple linear models at time series forecasting.\n The issue is how most Transformer architectures treat each timestamp as a token and fuse all the variable data from that moment. This makes two big problems:\n  \nVariables recorded at slightly different times get blurred together, losing important timing info\n Each token can only see a single moment, no long-term dependencies\n  \nSo Transformers struggle to extract useful patterns and correlations from the data.\n Some researchers from Tsinghua University took a fresh look at this and realized the Transformer components themselves are solid, they just need to flip the architecture for time series data.\n Their \"Inverted Transformer\" (or iTransformer):\n  \nMakes each variable's full history into a token, instead of each timestamp\n Uses self-attention over variables to capture relationships\n Processes time dependencies per variable with feedforward layers\n  \nThis simple tweak gives all the benefits we want:\n  \nState-of-the-art forecasting accuracy, beating both linear models and standard Transformers\n Better generalization to unseen variables\n Increased interpretability\n Ability to leverage longer historical context\n  \nTLDR: Inverting Transformers to align with time series structure allows them to outperform alternatives in working with time series data.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ep6x/r_tsinghua_university_inverting_transformers/",
          "publishedOn": "2023-10-11T14:00:19.000Z",
          "wordCount": 2748,
          "title": "[R] Tsinghua University: Inverting Transformers Significantly Improves Time Series Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ct0u/r_how_to_train_multiple_models_on_multiple_gpus/",
          "author": null,
          "description": "Hi! The task is to train N TensorFlow/Keras models using [2, ... N] GPU's on K different datasets in parallel. It is for testing a custom pipeline, you create a pipeline, you run it on multiple different datasets and get an aggregated metric. For now I'm using a for loop but how do I do it in parallel e.g. on AWS? I googled, but surprisingly haven't found a lot of results. I looked at Apache AirFlow because I'm vaguely familiar with it but so far I couldn't get a definite answer on how it works with multiple GPU's. Second option I found is to use Ray library. Is it worth trying? What should I use to solve this task? Thanks.\n UPD. I'd also consider a PyTorch solution as a backup option.\n UPDUPD. Jesus, why Reddit removing newlines after edit? \n    submitted by    /u/Disastrous_Sky9468  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ct0u/r_how_to_train_multiple_models_on_multiple_gpus/",
          "publishedOn": "2023-10-11T12:26:23.000Z",
          "wordCount": 2677,
          "title": "[R] How to train multiple models on multiple GPU's simultaneously",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175cf8w/d_how_important_is_having_a_great_team_when_ml/",
          "author": null,
          "description": "My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.\n I am the “lead”/senior data scientist in an R&D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.\n I have developed the domain expertise and I have a PhD in an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.\n I am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.\n    submitted by    /u/Diligent_Trust2569  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175cf8w/d_how_important_is_having_a_great_team_when_ml/",
          "publishedOn": "2023-10-11T12:06:14.000Z",
          "wordCount": 2761,
          "title": "[D] How important is having a great team when ML solutions are slow to be adopted ? When to move on?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ccwv/d_p_r_what_to_do_when_your_model_isnt_testing_well/",
          "author": null,
          "description": "I have 200k observations overall. I split my data into training and test set. My target variable has low prevalence ~ 9% so I tried random oversampling, random undersampling and SMOTE. After I fit my models, I tested them on my training test and the results were awful. I mean I've never had a model with 50% roc-auc, but then again, I rarely developed ML models. I'm wondering what the next steps would be? I understand there could be some sort of overfitting. But what would you do next? Any references would be appreciated :)\n    submitted by    /u/Actual-Muscle-9846  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ccwv/d_p_r_what_to_do_when_your_model_isnt_testing_well/",
          "publishedOn": "2023-10-11T12:02:42.000Z",
          "wordCount": 2637,
          "title": "[D] [P] [R] What to do when your model isn't testing well?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175a8bs/d_fastest_lipsync_projects/",
          "author": null,
          "description": "Given an image, and an audio file (TTS generated), what is current fastest library that can output me a video of a talking image with the audio on it?\n I have made some research and I have seen Wav2Lip and SadTalker. Any better options? I am looking for processing speed and for the lesser hardware intensive solution for a side project.\n Thanks!\n    submitted by    /u/reddit2vid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175a8bs/d_fastest_lipsync_projects/",
          "publishedOn": "2023-10-11T09:50:59.000Z",
          "wordCount": 2596,
          "title": "[D] Fastest lipsync projects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17552x9/p_loopquest_a_githublike_platform_to_host/",
          "author": null,
          "description": "Hello everyone! Here is my pet project, https://www.loopquest.ai/. I am trying to build a platform like Github to let people upload their simulation environments so people can train their AI agents by interacting with the environments created by others. Here is a 2-min demo, https://youtu.be/d53NFjkU7JA. It is not launched yet but would love to get some early feedbacks. \n Here is the corresponding Github repo https://github.com/LoopMind-AI/loopquest. For now, the package can log env-agent interaction data by adding one extra line of code. You can think of it similar to https://github.com/google-deepmind/envlogger but with much better backend and frontend support. \n Any feedbacks are appreciated :)\n    submitted by    /u/jxx123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17552x9/p_loopquest_a_githublike_platform_to_host/",
          "publishedOn": "2023-10-11T04:00:52.000Z",
          "wordCount": 2644,
          "title": "[P] LoopQuest, A Github-like platform to host simulation environments for AI training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17536bo/d_why_async_gradient_update_doesnt_get_popular_in/",
          "author": null,
          "description": "The pipedream-2bw paper and the Zero-offload paper both show that 1-step delayed asynchronous gradient update doesn’t affect the convergence (and perplexity) while improve the training efficiency (by fully utilize the bubbles in pipeline parallelism) at a large margin.\n However, both the Megatron-LM and the DeepSpeed don’t use pipedream-2bw scheduling. Could anyone share me some insights or ideas about why such an efficient scheduling scheme doesn’t get popular in the LLM pretraining community? Does it suffer convergence/accuracy issue in practice? Or are there any other concerns that blocking it become the default / most popular pipeline parallelism scheduling?\n (I posted the same question in hacknews as well: Why async gradient update doesn't get popular in LLM community? | Hacker News)\n I have tried to implement the pipedream-2bw scheduling scheme on Megatron-LM and do can reproduce the performance gain as well as loss convergence with GPT-2 345M using 8xV100 GPUs: https://github.com/sighingnow/Megatron-LM/blob/ht/dev-pipe/megatron/core/pipeline_parallel/schedules.py#L1421\n    submitted by    /u/sighingnow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17536bo/d_why_async_gradient_update_doesnt_get_popular_in/",
          "publishedOn": "2023-10-11T02:23:18.000Z",
          "wordCount": 2684,
          "title": "[D] Why async gradient update doesn’t get popular in LLM community?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1750uim/d_ide/",
          "author": null,
          "description": "What’s the best IDE to work with or is it on user needs that determines best fit or is their one top dog and dominator that can robustly if not better preform other IDE’s ?\n    submitted by    /u/External_Age_5855  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1750uim/d_ide/",
          "publishedOn": "2023-10-11T00:31:01.000Z",
          "wordCount": 2568,
          "title": "[D] IDE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174zyyu/d_onchain_reputation_model/",
          "author": null,
          "description": "I am relatively new to machine learning, and I am thinking about building an on-chain reputation ML model.\n Here is how far I have gone in my ideation phase, can someone help with some suggestion on how I can approach this issue.\n  \nInput data could include on-chain activity like number of transactions, value transferred, smart contracts interacted with, tokens held, NFTs owned, etc.\n Additionally, data from off-chain sources could be incorporated like identity verification, credentials, ratings, reviews, social media profiles, etc.\n Supervised learning algorithms like regression or classification models could be used to predict a reputation score. The target variable would be some verified reputation rating.\n Models like linear regression, random forests, or neural networks could work. Choice depends on size of data and complexity needed.\n Model would need to be transparent and parameters verifiable on-chain for validity. So linear models or simple neural networks may be most practical initially.\n The model could be trained off-chain initially but ultimately parameters and logic stored on-chain. Predictions could also be verified on-chain.\n Careful feature selection is important so the model relies on signals that are resistant to manipulation and capture true reputation.\n The model would need continuous updates as new data comes in reflecting latest reputation. This would require clear on-chain governance.\n Issues like privacy, collusion resistance, and censorship resistance would need to be addressed through crypto mechanisms like zero-knowledge proofs.\n  \nP.S. This is a personal project I want to attempt to level up my ML skills.\n    submitted by    /u/AdParticular2891  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174zyyu/d_onchain_reputation_model/",
          "publishedOn": "2023-10-10T23:50:20.000Z",
          "wordCount": 2779,
          "title": "[D] On-Chain Reputation Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174yb4k/d_pivoting_jobs_to_ml/",
          "author": null,
          "description": "Hi everyone, I recently started a job as a Junior Data Engineer. I have learned a lot so far working with DBT, Snowflake, Looker, Jira workflow, and Git using SQL and Python.\n I plan to stay at this company for 2 years. My boss has assured me that if I work hard I will progress from a Junior to full Data Engineer. After 2-3 years as a DE, I want to level up and move towards Data Science/ ML roles.\n My questions are: What other skills should I learn to enable me to pivot into something ML related? Should I find a job as a Data Scientist first, then try for ML jobs?\n Just looking for some advice/suggestions. Thanks!\n    submitted by    /u/SydeFxs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174yb4k/d_pivoting_jobs_to_ml/",
          "publishedOn": "2023-10-10T22:36:18.000Z",
          "wordCount": 2655,
          "title": "[D] Pivoting jobs to ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174xkir/problem_solving_in_programming_d/",
          "author": null,
          "description": "Hello Redditors,\n I am a student who is currently studying Bachelor of Science in AI. I have a question regarding improving my coding skills. I am aiming for a research internship and I don't know where to start. I previously took a summer school that taught me a lot about state-of-the-art models such as GANs, Transformers, VAEs, GNNs, etc. I would like to improve my coding skills, specifically problem-solving and writing clean code. I have experience with deep learning in general and data analysis. I am looking for a research internship next summer. Where should I start?\n I plan to review some of the deep learning material in the Deep Learning Specialization before taking the GAN specialization. However, when it comes to coding, I want to think like a software engineer or a great programmer. What do you guys suggest for improving my coding or problem-solving skills? I'm feeling confused with multiple resources and I don't know where to begin.\n I’d really appreciate your help.\n    submitted by    /u/misplacedlion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174xkir/problem_solving_in_programming_d/",
          "publishedOn": "2023-10-10T22:04:54.000Z",
          "wordCount": null,
          "title": "Problem solving in programming [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174xc6c/random_forest_trained_on_insider_trades_d/",
          "author": null,
          "description": "Would be very appreciative if someone looked at these results and pointed out potential / actual flaws.\n Dataset basics: insider trade details, insider trades over the last month, insider trades over the last week, (…) stock return over the last month (…), 46 columns total. \n Labels… 0: <-5% return in two weeks 1: >-5% + <5% 2: >5%\n Dates predicted: reported date. Usually 2-3 days behind transaction.\n Also, not positive if results are significant in the first place so that would be a great call out as well.\n Colab notebook: https://colab.research.google.com/drive/1fO1hVsVMWN3TORNj4OQn5UbWQOeug4fi?usp=sharing\n    submitted by    /u/This_Cardiologist242  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174xc6c/random_forest_trained_on_insider_trades_d/",
          "publishedOn": "2023-10-10T21:55:11.000Z",
          "wordCount": 2629,
          "title": "Random forest trained on insider trades [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174rdaq/r_almt_using_text_to_narrow_focus_in_multimodal/",
          "author": null,
          "description": "Multimodal sentiment analysis combines text, audio and video to understand human emotions. But extra inputs can add irrelevant or conflicting signals. So filtering matters.\n Researchers made a \"Adaptive Language-guided Multimodal Transformer\" (ALMT) that uses text to guide filtering of visual and audio data. This creates a \"hyper-modality\" with less noise that complements the text.\n They tested it on datasets like MOSI (YouTube reviews), MOSEI (YouTube clips) and CH-SIMS (Chinese videos). ALMT achieved improved accuracy:\n  \nMOSI: YouTube movie reviews with 2,199 samples. ALMT achieves state-of-the-art performance on various metrics including 6% higher 7-class accuracy.\n MOSEI: 22,856 YouTube clips covering sentiment-rich scenarios. ALMT improves multi-class accuracy by 3-5% over previous methods.\n CH-SIMS: Chinese dataset with over 2,000 video samples. ALMT surpasses prior work by 1.4% in binary accuracy.\n  \nAnalyses showed big drops in performance without the guided filtering, so this validates that it's the main innovation.\n Downsides are it needs lots of training data and has minor gains on sparse regression metrics. But overall the technique of filtering multimodal data under text guidance gives improvements.\n The concepts feel intuitive - use dominant signals to filter others and retain useful complements. My guess is it would transfer well to other multimodal tasks.\n TLDR: New way to filter multimodal data for sentiment analysis using text guidance improves performance. Shows the value in removing distracting signals. Sometimes less is more.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174rdaq/r_almt_using_text_to_narrow_focus_in_multimodal/",
          "publishedOn": "2023-10-10T17:49:39.000Z",
          "wordCount": 2775,
          "title": "[R] ALMT: Using text to narrow focus in multimodal sentiment analysis improves performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174r35r/has_anyone_evaluated_tiktoks_algorithm_for_their/",
          "author": null,
          "description": "As a disclaimer, I am not familiar with many Recsys benchmarks. \n So I know Tiktok published a white paper on their purported algorithm, Monolith, but it is unclear if that is what they use in their products or not. Given, recommender systems seem to be core to Bytedance's business, I imagine they wouldn't provide many details.\n Has anyone evaluated Monolith on their own products and seen an improvement? \n I think the app is impressive and am wondering how it has transferred to other use cases. \n ​\n    submitted by    /u/HybridRxN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174r35r/has_anyone_evaluated_tiktoks_algorithm_for_their/",
          "publishedOn": "2023-10-10T17:37:40.000Z",
          "wordCount": null,
          "title": "Has anyone evaluated Tiktok's algorithm for their recsys use case? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174qdqv/p_optimistix_nonlinear_optimisation_in_jaxequinox/",
          "author": null,
          "description": "Hi everyone! I wanted to advertise my new JAX optimisation library Optimistix!\n Optimistix has high-level APIs for minimisation, least-squares, root-finding, and fixed-point iteration and was written to take care of these kinds of subroutines in Diffrax.\n Here is the GitHub: https://github.com/patrick-kidger/optimistix\n The elevator pitch is Optimistix is really fast, especially to compile. It plays nicely with Optax for first-order gradient-based methods, and takes a lot of design inspiration from Equinox, representing the state of all the solvers as standard JAX PyTrees.\n For those familiar with classical nonlinear unconstrained optimisation, Optimistix does some pretty nifty new things. It introduces new abstractions for modular optimisers, allowing users to mix-and-match different optimisation techniques easily. For example, creating a BFGS optimiser with Levenberg-Marquardt style Tikhnov regularisation takes less than 10 lines of code in Optimistix.\n I'm using Optimistix as a tool for my own research, and continue to work on it as part of my PhD (supervised by Patrick Kidger.) I would love for some more people to try it, so let me know what you think!\n    submitted by    /u/packquickly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174qdqv/p_optimistix_nonlinear_optimisation_in_jaxequinox/",
          "publishedOn": "2023-10-10T17:08:25.000Z",
          "wordCount": 2710,
          "title": "[P] Optimistix, nonlinear optimisation in JAX+Equinox!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174odzs/d_document_layout_recreating_the_structure/",
          "author": null,
          "description": "Hello,\n Document layout analysis has been a great tool so far to extract the components of a document (title, paragraph, tables ...). I'm working on long text PDF which are mostly scanned documents.\n One of the process involved after document layout analysis, is to recreate the document structure: creating sections, sub section, sub sub sections and so on. As of today, this task is done by parsing the title and finding out any ordering information (numeric, alphabetical or roman notation):\n 1. Title A 1.1 Title B 2. Title C 2.a) Title D \n This technique works only if a document follows this constraint (numeration). I want to go one step further, where the algorithm could create the document structure with any title ordering information.\n I believe that relying only on parsing cannot do the trick. What could be the options? Given that the only features are: title's text and title's position (x,y) in the document. I was wondering if a model like a seq2seq could fit this problem, or should I stick with an engineering rule based approach.\n Thanks\n ​\n    submitted by    /u/mathrb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174odzs/d_document_layout_recreating_the_structure/",
          "publishedOn": "2023-10-10T15:44:15.000Z",
          "wordCount": 2716,
          "title": "[D] Document layout - recreating the structure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174n4ve/r_is_there_an_enstablished_method_to_test_if/",
          "author": null,
          "description": "I am using ChatGPT and other LLMs for which the training data is unknown. I am using them to test a set of MC question from a medical test published after the models knowledge cutoff. However, I cannot be 100% sure the questions were not on the internet beforehand. \n Is there any established method or testsuit to try to understands weather a given instance has been seen at training time? All I can think is looking at memorization or at perplexity, but I was looking for a more out of the box methodology that people use. It seems to me that the problem is quite general. \n Thanks!\n Edit: I know LLMs do not just memorize things and learn pattern. However, there is research on trying to understand if a datapoints has been used in training or not. Eg there is research that tries to exploit the fact that seen text has normally lower perplexity than unseen text or other similar infornation. I was wonderibg what the state in this topic is and if something is normally used as a score to have some clues. I do not expect to be able to retrieve the exact same questions lol\n    submitted by    /u/ombelicoInfinito  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174n4ve/r_is_there_an_enstablished_method_to_test_if/",
          "publishedOn": "2023-10-10T14:50:46.000Z",
          "wordCount": 2747,
          "title": "[R] Is there an enstablished method to test if something has been memorized / seen by black-box LLMs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174n1kt/d_extracting_multimodal_embeddings_image_text_to/",
          "author": null,
          "description": "I am looking for methods/frameworks to extract multi-modal embeddings from images and text for similarity search purposes. The problem setup is slightly different from how CLIP style methods are generally used ( where similarity between text and image embeddings obtained through the model are computed to assess how similar a caption is to an image). My intended application is similarity search, where I want to find entries of images and captions pair similar to a piece of the query image and caption encoded together.\n Some approaches I tried: I tried concatenating the textual and visual embeddings obtained from CLIP and ResNET with textual embeddings and using it with cosine similarity, but it had limited utility. My guess is that concatenating two modalities merely without any training would yield very little utility. The next direction could be to train a model to fuse the embeddings obtained, but my dataset size is really small (10 thousand total), so not sure if training a model would be helpful. \n Are there any approaches that can allow me to combine the multi-modal embeddings for similarity purposes, similar to how pre-trained ResNET or Inception can be used off-the-shelf for retrieving visually similar images? Any pointers/advice would be greatly appreciated. \n    submitted by    /u/No-Commission3556  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174n1kt/d_extracting_multimodal_embeddings_image_text_to/",
          "publishedOn": "2023-10-10T14:46:49.000Z",
          "wordCount": 2748,
          "title": "[D] Extracting Multi-modal embeddings (Image + text) to be used for visual similarity purposes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174n0mv/pd_building_datasets/",
          "author": null,
          "description": "In my ML/AI journey up until now, most training and hands-on labs either use a pre-built dataset or have you build a pretty simple and flat dataset. I am now looking to stretch my exploration into some real-world use cases and find the data I want is way more complex.\n Researching online feels like the meme on learning to draw an owl.\n So I'm looking for some guidance on how to handle my data.\n The data is an array from a rest API that includes all alarms from an application as nested objects. So the data looks like this for a single event:\n data = { \"event_data\": [ { \"root_cause\": \"Root cause added after API calls\" \"alarms\": [ { \"alarm_id\": \"alarm_id\", \"alarm_name\": \"alarm_name\", \"alarm_type\": \"alarm_type\", \"alarm_description\": \"alarm_description\", \"alarm_details\": { pro1: val1, prop2: val2, etc... }, \"actual_alarm_value\": { any_random_key: \"any_random_value\", etc... }, } ], } ] } \n I need to build a dataset that includes many of these events with the ultimate goal of predicting future events. I plan to test this against various ML models and LLMs.\n Each event would be a single row, and I would flatten out each alarm so each nested property has its own column. Where I need clarification is how to handle the flatting of alarms. If I fully flatten them, it appears like I lose the context of the alarm's parent event. But if I only flatten them to the alarm level, I lose each property having its own row\n Also actual_alarm_value is very random, so my thinking is to use string encoding here.\n I know this is a lot of detail, and I appreciate any and all advice and help in learning how to do this.\n    submitted by    /u/that1guy15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174n0mv/pd_building_datasets/",
          "publishedOn": "2023-10-10T14:45:38.000Z",
          "wordCount": 2817,
          "title": "[P][D] Building Datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174kryt/d_is_there_a_rest_api_for_text_embeddings/",
          "author": null,
          "description": "I'm aware there are commercial offerings like OpenAI and cohere with the embedding API. But what about for open source models like the ones from SentenceTransformers?\n I'm aware you can use the HuggingFace inference API, but it's probably not best for commercial use, in which case the Inference endpoints would be better, but it's quite pricey for a startup with no customers.\n I also know I could use some kind of serverless GPU / inference platform to create my own API.\n But is there just a straight-up REST API for getting text embeddings from a model via SentenceTransformers or other HuggingFace models?\n    submitted by    /u/TheSaasDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174kryt/d_is_there_a_rest_api_for_text_embeddings/",
          "publishedOn": "2023-10-10T13:08:48.000Z",
          "wordCount": 2642,
          "title": "[D] Is there a REST API for text embeddings?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174jv0q/d_langauge_confusion/",
          "author": null,
          "description": "I am a Second Year Student\n I'm planning to start learning ML which obviously requires python. But at the same time I wanna start practicing DSA / competitive programming as well. I'm sorta in this dilemma of what to do.\n Since python is a must for ML I'm 100% doing it, but for DSA I am confused whether I should learn DSA in Python or C++. People say C++ is the best and ideally I should do that. But python suits my need more. Obviously I don't mind doing both languages together but it seems a bit redundant.\n P.S: I'm learning DS basics in college via C language so learning the basic concepts isn't an issue.\n What do you suggest?\n    submitted by    /u/No-Discipline-2354  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174jv0q/d_langauge_confusion/",
          "publishedOn": "2023-10-10T12:24:15.000Z",
          "wordCount": null,
          "title": "[D] Langauge Confusion.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174jkeb/project_i_created_a_tool_that_navigates_the/",
          "author": null,
          "description": "Hi! I created a universal data API that uses headless browsers and GPT to extract any data from the web in JSON format. I started this project because I needed some API to do data enrichment to get company data (headcount, investment rounds, etc.). Once I did the first version, I quickly realized that there can be many use cases for such a tool: data enrichment, web scraping, data validation, etc. \n You can get the early access to the API here: https://singleapi.co/ \n Thanks!\n    submitted by    /u/semanser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174jkeb/project_i_created_a_tool_that_navigates_the/",
          "publishedOn": "2023-10-10T12:08:58.000Z",
          "wordCount": 2628,
          "title": "[Project] I created a tool that navigates the Internet and scrapes data using GPT-4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174iz9n/applied_aiml_data_science_ms_in_germany_d/",
          "author": null,
          "description": "Hey folks, I graduated from a tier 2 college in India with an ECE degree and then started working as an ML engineer in a mid-size startup 2 years ago. (1 year of internship + 1 year of Full time employment at the same company). Now, I am looking to get a Master's Degree in AI/ML/DS in Germany starting Winter 2024. I am a person with interests in Industry skills(Applied AI/ML) rather than the research/academia part as I don't wish to pursue a PhD nor do I want to be stuck in a Math-deep subject that may not be relevant for me in the future. On account of this, I wanted to know which college/degree offers the best balance in-between theory and applied AI/ML/DS.\n Also, people have been telling me that exams are super tough and it is hard to successfully complete an AI/ML/Data Science MS degree in Germany, Is it true? It has been super discouraging for me to hear this and is affecting me mentally to go through the application process.\n PS. CS/Electrical Degrees with good electives for AI/ML/DS are also good enough for me (Just hoping the coursework/grading is not too harsh) Also, it would be great if someone could clarify if an Electronics and Communications student can apply for a CS degree in Germany.\n Sorry for asking too many questions, TIA. :)\n    submitted by    /u/TheDivineKnight01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174iz9n/applied_aiml_data_science_ms_in_germany_d/",
          "publishedOn": "2023-10-10T11:37:07.000Z",
          "wordCount": 2765,
          "title": "Applied AI/ML/ Data Science MS in Germany [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174hkcn/d_prompting_as_searching_through_a_space_of/",
          "author": null,
          "description": "Enlightening article from Francois Chollet about #LLMs and embeddings\n \"Prompt engineering is the process of searching through program space to find the program that empirically seems to perform best on your target task.\"\n ​\n https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering \n    submitted by    /u/alexisperrier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174hkcn/d_prompting_as_searching_through_a_space_of/",
          "publishedOn": "2023-10-10T10:09:17.000Z",
          "wordCount": 2575,
          "title": "[D] Prompting as searching through a space of vector programs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174cwha/d_best_approach_to_verify_4_million_sentencenamed/",
          "author": null,
          "description": "I have a dataset of about 4 million pairs of sentence-named entity.\n Looks like this:\n Sentence: MarketWatch has reached out to Charles Schwab and GQG for comment. Corresponding NER Tags: [{'end': 6, 'entity': 'B-ORG', 'index': 1, 'score': '0.98322886', 'start': 0, 'word': 'Market'} {'end': 7, 'entity': 'I-ORG', 'index': 2, 'score': '0.969261', 'start': 6, 'word': '##W'} {'end': 11, 'entity': 'I-ORG', 'index': 3, 'score': '0.97644824', 'start': 7, 'word': '##atch'} {'end': 38, 'entity': 'B-PER', 'index': 8, 'score': '0.9927636', 'start': 31, 'word': 'Charles'} {'end': 41, 'entity': 'I-PER', 'index': 9, 'score': '0.99394774', 'start': 39, 'word': 'Sc'} {'end': 44, 'entity': 'I-PER', 'index': 10, 'score': '0.41437265', 'start': 41, 'word': '##hwa'} {'end': 45, 'entity': 'I-PER', 'index': 11, 'score': '0.46933985', 'start': 44, 'word': '##b'} {'end': 51, 'entity': 'B-ORG', 'index': 13, 'score': '0.9984176', 'start': 50, 'word': 'G'} {'end': 52, 'entity': 'I-ORG', 'index': 14, 'score': '0.99367344', 'start': 51, 'word': '##Q'} {'end': 53, 'entity': 'I-ORG', 'index': 15, 'score': '0.99617106', 'start': 52, 'word': '##G'}] \n What would be a good approach to verify the correctness of each item?\n    submitted by    /u/shardblaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174cwha/d_best_approach_to_verify_4_million_sentencenamed/",
          "publishedOn": "2023-10-10T04:53:27.000Z",
          "wordCount": 2705,
          "title": "[D] Best approach to verify 4 million sentence-named entity pairs ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1746g81/r_language_agent_tree_search_unifies_reasoning/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.04406 \n Abstract:\n  \nWhile large language models (LLMs) have demonstrated impressive performance on a range of decision-making tasks, they rely on simple acting processes and fall short of broad deployment as autonomous agents. We introduce LATS (Language Agent Tree Search), a general framework that synergizes the capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration from Monte Carlo tree search in model-based reinforcement learning, LATS employs LLMs as agents, value functions, and optimizers, repurposing their latent strengths for enhanced decision-making. What is crucial in this method is the use of an environment for external feedback, which offers a more deliberate and adaptive problem-solving mechanism that moves beyond the limitations of existing techniques. Our experimental evaluation across diverse domains, such as programming, HotPotQA, and WebShop, illustrates the applicability of LATS for both reasoning and acting. In particular, LATS achieves 94.4\\% for programming on HumanEval with GPT-4 and an average score of 75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness and generality of our method. \n  \nhttps://preview.redd.it/ail2c1kbh9tb1.jpg?width=857&format=pjpg&auto=webp&s=a89d1f4ce3c536eecda3f7ab6027f304286f6c81\n https://preview.redd.it/j8xzx1kbh9tb1.jpg?width=1655&format=pjpg&auto=webp&s=c791756af926c7d472313b212de765e74c2b75da\n https://preview.redd.it/t47ne1kbh9tb1.jpg?width=1362&format=pjpg&auto=webp&s=560e5dd82ad06fdb729ab8ea1434c98e5c1a2ed3\n https://preview.redd.it/r58es3kbh9tb1.jpg?width=1341&format=pjpg&auto=webp&s=d5681992547dd6248ade5729c545eb17e824b7ea\n https://preview.redd.it/7viy42kbh9tb1.jpg?width=1496&format=pjpg&auto=webp&s=6454cfe65b511b34771cd510f67775be4e01c636\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1746g81/r_language_agent_tree_search_unifies_reasoning/",
          "publishedOn": "2023-10-09T23:31:05.000Z",
          "wordCount": 2734,
          "title": "[R] Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models - University of Illinois 2023 - Achieves 94.4\\% for programming on HumanEval with GPT-4 and 86.9\\% with GPT-3.5 20\\% better than with reflexion!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1746614/r_looking_for_indepth_tutorials_and_papers_on_nn/",
          "author": null,
          "description": "I only started working with neural nets a year ago and i've been having trouble understanding how pruning actually works. If there's any resources you think might help please guide me to them. thanks!\n    submitted by    /u/Sidekiiick02  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1746614/r_looking_for_indepth_tutorials_and_papers_on_nn/",
          "publishedOn": "2023-10-09T23:18:44.000Z",
          "wordCount": 2575,
          "title": "[R] looking for in-depth tutorials and papers on NN pruning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1744w8p/d_feature_selection_for_multivariate_time_series/",
          "author": null,
          "description": "Say for a sample that you have 5 target variables and 30 exogenous variables. If you want to include no more than 10 exogenous variables to your time series forecast, because of overfitting issues and such, what feature selections would you apply? Could you use pca and vif for multivariate models or are there other approaches to consider?\n    submitted by    /u/AdWhole1559  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1744w8p/d_feature_selection_for_multivariate_time_series/",
          "publishedOn": "2023-10-09T22:23:49.000Z",
          "wordCount": 2597,
          "title": "[D] Feature selection for multivariate time series model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1740ycb/r_scalearn_simple_and_highly_parameterefficient/",
          "author": null,
          "description": "Title: ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale\n Paper: https://arxiv.org/abs/2310.01217\n Code: https://github.com/CPJKU/ScaLearn\n https://preview.redd.it/xvcz7obtc8tb1.jpg?width=2020&format=pjpg&auto=webp&s=26169fa234e4e714d424ce17a7f0fa2c513fc42c\n Abstract:\n  \nMulti-task learning (MTL) has shown considerable practical benefits, particularly when using pre-trained language models (PLMs). While this is commonly achieved by simultaneously learning n tasks under a joint optimization procedure, recent methods such as AdapterFusion structure the problem into two distinct stages: (i) task learning, where knowledge specific to a task is encapsulated within sets of parameters (e.g., adapters), and (ii) transfer, where this already learned knowledge is lev…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1740ycb/r_scalearn_simple_and_highly_parameterefficient/",
          "publishedOn": "2023-10-09T19:41:45.000Z",
          "wordCount": 2822,
          "title": "[R] ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173y66v/d_what_is_more_valuable_10k_cpus_or_1k_gpu_hours/",
          "author": null,
          "description": "Hello ML community!\n I recently built, incredibly simple to learn, cluster compute software. Users can (in <60 seconds) go from coding on their local laptop, to coding on thousands of computers in the cloud, with zero setup, and just one line of code.\n I have a fair amount of GCP credits and want to run a promotion to get additional users. It would be giving away compute. In your opinion what would be more valuable... 10k CPU hours or 1k GPU hours? If you have any other promotional ideas for python users specific those in the ML, Bioinformatics, and GIS spaces I'd love to hear them.\n All feedback is greatly appreciated. Also if you're interested in trying out the tool check it out here --> https://www.burla.dev/\n    submitted by    /u/Ok_Post_149  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173y66v/d_what_is_more_valuable_10k_cpus_or_1k_gpu_hours/",
          "publishedOn": "2023-10-09T17:50:53.000Z",
          "wordCount": 2668,
          "title": "[D] What is more valuable 10k CPUs or 1k GPU hours?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173y1so/r_transformers_kv_caching_explained/",
          "author": null,
          "description": "https://medium.com/@joaolages/kv-caching-explained-276520203249\n    submitted by    /u/JClub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173y1so/r_transformers_kv_caching_explained/",
          "publishedOn": "2023-10-09T17:45:54.000Z",
          "wordCount": 2537,
          "title": "[R] Transformers KV Caching Explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173xp39/d_llms_in_gec_problem/",
          "author": null,
          "description": "Up to now, which LLMs model, encoder-decoder model is best for the problem of grammatical error correction on uncommon language datasets (small dataset size) or languages ​​with specific characteristics (about punctuation? ,...)\n    submitted by    /u/con-nguoi-ki-cac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173xp39/d_llms_in_gec_problem/",
          "publishedOn": "2023-10-09T17:31:35.000Z",
          "wordCount": 2568,
          "title": "[D] LLMs in GEC problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173wzr9/d_learning_natural_events_ai_art_generation/",
          "author": null,
          "description": "Hello!\n 1 I'd like to know if I could train AI to recognize details found it nature / weathering / aging and feed it pictures and it would recognize them (segmenting) so it can spot them but also their positions based on surrounding shapes, and the logical placement resulting. Seems hard.\n 2 then feed it some examples of those aging stuff on their own (with proper tags) so it learn to reproduce them and create new ones from scratch.\n 3 but then feed it \"clean\" pics and it would age them according to patterns it could find on the base training set so it can guess where to best place them.\n Pretty sure 2 is trivial enough, 1 seems possible until learning the \"logic\", but 3?\n Thanks for your insight.\n 1 comment \n    submitted by    /u/ConfusionSame9623  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173wzr9/d_learning_natural_events_ai_art_generation/",
          "publishedOn": "2023-10-09T17:03:12.000Z",
          "wordCount": 2671,
          "title": "[D] Learning natural events / AI art generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173vy9t/r_why_do_we_need_weight_decay_in_modern_deep/",
          "author": null,
          "description": "Title: Why Do We Need Weight Decay in Modern Deep Learning?\n Paper: https://arxiv.org/abs/2310.04415\n Abstract: Weight decay is a broadly used technique for training state-of-the-art deep networks, including large language models. Despite its widespread usage, its role remains poorly understood. In this work, we highlight that the role of weight decay in modern deep learning is different from its regularization effect studied in classical learning theory. For overparameterized deep networks, we show how weight decay modifies the optimization dynamics enhancing the ever-present implicit regularization of SGD via the loss stabilization mechanism. In contrast, for underparameterized large language models trained with nearly online SGD, we describe how weight decay balances the bias-variance tradeoff in stochastic optimization leading to lower training loss. Moreover, we show that weight decay also prevents sudden loss divergences for bfloat16 mixed-precision training which is a crucial tool for LLM training. Overall, we present a unifying perspective from ResNets on vision tasks to LLMs: weight decay is never useful as an explicit regularizer but instead changes the training dynamics in a desirable way. Our code is available at this https URL.\n    submitted by    /u/m_andriushchenko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173vy9t/r_why_do_we_need_weight_decay_in_modern_deep/",
          "publishedOn": "2023-10-09T16:20:51.000Z",
          "wordCount": 2725,
          "title": "[R] Why do we need weight decay in modern deep learning? 🤔",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173vy4u/d_anyone_tried_training_language_models_on_simple/",
          "author": null,
          "description": "Seems the way people train language models today feels like sending a preschooler to a college library and telling him to start browsing books.\n Anyone know of papers describing language models being trained more like a child?\n Perhaps starting with preschool books with a tiny vocabulary and short sentence fragments like \"goodnight moon...\", moving up to \"the lorax\".... and then fine-tuning on elementary school books ... then jr high level reading ... then high school .... etc.\n I'm guessing this might be a path to more natural human-feeling speech.\n Anyone here tried this, or anyone here know of papers talking about it?\n    submitted by    /u/Appropriate_Ant_4629  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173vy4u/d_anyone_tried_training_language_models_on_simple/",
          "publishedOn": "2023-10-09T16:20:43.000Z",
          "wordCount": 2652,
          "title": "[D] Anyone tried training language models on simple (elementary school) text first and fine-tuning on progressively more advanced text?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173ucih/d_where_do_yall_get_training_data/",
          "author": null,
          "description": "Hi there,\n Can I ask everyone here, where do you get your custom training data from?\n My team is training classifier models from scratch, so need thousands of specific query/response examples to train on.\n It's not the kinda data you could randomly scrape or source from a library.\n Are there any platforms that exist where you can pay a bunch of humans to write high volumes of relatively high quality text based training data?\n    submitted by    /u/paritsky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173ucih/d_where_do_yall_get_training_data/",
          "publishedOn": "2023-10-09T15:15:23.000Z",
          "wordCount": 2612,
          "title": "[D] Where do y'all get training data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173t9mz/d_what_is_sota_for_continual_learning_on/",
          "author": null,
          "description": "If you have the dataset used to make the pretrained you could always create a new model with the old + new data, but this is often prohibitively expensive or impossible because the dataset is not available.\n Catastrophic forgetting seems to be the big issue, especially if you've already undergone instruction tuning since the model will lose its conversational tone. I've seen papers discussing regularization techniques to avoid that by minimizing the changes to high value attention heads but not sure if that is considered to be the most promising direction.\n I'm aware of LoRAs but I imagine at some point you can't just arbitrarily cram new info into such a low dimensional space.\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173t9mz/d_what_is_sota_for_continual_learning_on/",
          "publishedOn": "2023-10-09T14:30:40.000Z",
          "wordCount": 2658,
          "title": "[D] - What is SOTA for Continual Learning on pretrained LLMs, particularly those that have already undergone instruction tuning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173t2is/r_thought_propagation_an_analogical_approach_to/",
          "author": null,
          "description": "LLMs are great at basic reasoning when prompted, but still struggle with complex multi-step problems like optimization or planning. Humans tackle new problems by drawing on intuition from similar experiences, which LLMs can't do.\n Researchers propose \"Thought Propagation\" to have LLMs reason more like humans - by thinking analogically. First, GPT is prompted to suggest related \"analogous\" problems to the input. Then it solves those. Finally, it aggregates the solutions to directly solve the input problem or extract useful strategies.\n They tested this technique on challenges like finding optimal graph paths, writing coherent stories, and planning for LLM agents. Across different models, it significantly boosted performance over regular prompting:\n  \n12% better at finding shortest paths\n 13% improvement in creative writing (human preference)\n 15% higher task completion for LLM agents\n  \nIt also beat chain-of-thought (there is a comparison to CoT and ToT in the paper).\n After 1-2 iterations, adding more layers of analogy didn't help much. Efficiently generating useful analogies is still difficult and that's a limitation.\n I think this is interesting because it shows the value of \"meta-cognition\" - having models reflect on their own reasoning. More techniques like this could incrementally improve LLMs' reasoning to be more human-like.\n TLDR: Teaching LLMs to reason analogically, using solutions for similar problems as hints, significantly boosts their complex reasoning ability.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173t2is/r_thought_propagation_an_analogical_approach_to/",
          "publishedOn": "2023-10-09T14:22:25.000Z",
          "wordCount": 2759,
          "title": "[R] Thought Propagation: An analogical approach to complex reasoning with LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173scf2/d_how_to_deal_with_the_inconsistency_of_eyeball/",
          "author": null,
          "description": "I tried a few open-source GAN-based face swapping models. Some of the models have issues of the inconsistency of eyeball location (or eye direction) between the original and face-swapped ones. Any suggestions? Thanks.\n    submitted by    /u/Curious_Dragonfly_13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173scf2/d_how_to_deal_with_the_inconsistency_of_eyeball/",
          "publishedOn": "2023-10-09T13:52:05.000Z",
          "wordCount": 2582,
          "title": "[D] How to deal with the inconsistency of eyeball location in the output of a GAN-based face-swapping model.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173pjho/d_i_need_to_perform_kmean_clustering_on_a_large/",
          "author": null,
          "description": "I have a class with around 96031740 96x64 images and need to select a sample of 17929 to match the minority class of my classification problem. \n Having already established a baseline based on random sampling of the majority class; now I am looking to try more complex approaches. I am specifically trying to replicate the 'nearest neighbor of clustering center' approach from Lin et al., 2017.\n The problem is I am working on my desktop and only have 32 Gb of RAM and 2 1Tb NVMe disks at half capacity. I have tried working with only 10% of the data and still the MiniBatchKMeans function of sklearn doesnt have enough space to run: \"numpy.core._exceptions._ArrayMemoryError: Unable to allocate 440. GiB for an array with shape (9603174, 6144) and data type float64\". \n Does anyone have a suggestion on how I can move forward? Could cloud services be an option? \n Thanks\n References:\n Lin, W. C., Tsai, C. F., Hu, Y. H., & Jhang, J. S. (2017). Clustering-based undersampling in class-imbalanced data. Information Sciences, 409–410, 17–26. https://doi.org/10.1016/j.ins.2017.05.008\n    submitted by    /u/RafaeldeCampos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173pjho/d_i_need_to_perform_kmean_clustering_on_a_large/",
          "publishedOn": "2023-10-09T11:34:35.000Z",
          "wordCount": 2721,
          "title": "[D] I need to perform k-mean clustering on a large image dataset to downsample the majority class.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173oi03/d_what_are_the_best_network_analysis_tools_like/",
          "author": null,
          "description": "Almost everyone I know uses tensorboard to analyze their network outputs. Some people swear on Weights & Biases instead.\n Are there any other tools that help you with your work?\n    submitted by    /u/Smart-Emu5581  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173oi03/d_what_are_the_best_network_analysis_tools_like/",
          "publishedOn": "2023-10-09T10:30:03.000Z",
          "wordCount": 2571,
          "title": "[D] What are the best network analysis tools, like tensorboard?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173nvhs/d_training_strategy_considering_the_possibility/",
          "author": null,
          "description": "During the training of overparameterized neural networks, when I observed decreasing training loss and increasing or non-decreasing validation loss, how should I decide if I should stop training and start a new experiment (with stronger regularization) or keep training to wait for 'grokking' or 'double descent' to happen? \n Are there any papers giving methods or some metrics to detect 'grokking' or 'double descent' in the early stage of training？\n    submitted by    /u/alayaMatrix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173nvhs/d_training_strategy_considering_the_possibility/",
          "publishedOn": "2023-10-09T09:48:43.000Z",
          "wordCount": 2611,
          "title": "[D] Training strategy considering the possibility of 'double descent' or 'grokking'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173ioa5/r_legged_robots_performing_extreme_parkour_using/",
          "author": null,
          "description": "submitted by    /u/pathak22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173ioa5/r_legged_robots_performing_extreme_parkour_using/",
          "publishedOn": "2023-10-09T04:04:46.000Z",
          "wordCount": 2547,
          "title": "[R] Legged Robots performing Extreme Parkour using Deep Reinforcement Learning just from a Front Camera (link in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173ef1i/d_i_need_guidance_related_to_using_machine/",
          "author": null,
          "description": "I am working on an a web app where people will be able to upload photos and write text. I don't want to have problems with my government or other countries governments in regards with the content that is uploaded to my website. I have searched about measures that can be taken to avoid this from happening. Adding a report button and having moderators are both good starting options.\n I thought that as time passes, more and more content is going to be created by the users so supervising that people are following the rules needs to be automated from the beginning. Applying measures to prevent people from uploading/posting links containing nudity, child porn, beastiality, or whatever users capture with a camera that could lead to legal problems must be a priority and allowing this type of content is not ethical.\n I am a software developer, but I haven't delved into machine learning and ai for most of my career because I haven't to. This seems like the perfect case to learn by doing and time is not a constraint, but I need some guidance.\n I have read superficially about how people train models by providing lots of data, I imagine other websites that use machine learning & ai to remove this type of content don't download media that contains nudity, child pornography, besteality, etc to train their models and make their tests. There must be some pretrained models, maybe, but how would they test this works? I don't know, I am just thinking on my own how other devs are currently handling this.\n I am no looking for upvotes, I don't care for downvotes, I am just looking for guidance, and I would be very happy to hear the opinion of someone with experience.\n    submitted by    /u/Comitatense  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173ef1i/d_i_need_guidance_related_to_using_machine/",
          "publishedOn": "2023-10-09T00:25:21.000Z",
          "wordCount": 2851,
          "title": "[D] I need guidance related to using machine learning & ai to prevent uploads or remove certain type of content from a web app.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173dwe7/r_identifying_the_risks_of_lm_agents_with_an/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.15817 \n Github: https://github.com/ryoungj/toolemu \n Website: https://toolemu.com/ \n Abstract:\n  \nRecent advances in Language Model (LM) agents and tool use, exemplified by applications like ChatGPT Plugins, enable a rich set of capabilities but also amplify potential risks - such as leaking private data or causing financial losses. Identifying these risks is labor-intensive, necessitating implementing the tools, manually setting up the environment for each test scenario, and finding risky cases. As tools and agents become more complex, the high cost of testing these agents will make it increasingly difficult to find high-stakes, long-tailed risks. To address these challenges, we introduce ToolEmu: a framework that uses an LM to emulate tool execution and enables the testing of LM agents against a diverse range of tools and scenarios, without manual instantiation. Alongside the emulator, we develop an LM-based automatic safety evaluator that examines agent failures and quantifies associated risks. We test both the tool emulator and evaluator through human evaluation and find that 68.8% of failures identified with ToolEmu would be valid real-world agent failures. Using our curated initial benchmark consisting of 36 high-stakes tools and 144 test cases, we provide a quantitative risk analysis of current LM agents and identify numerous failures with potentially severe outcomes. Notably, even the safest LM agent exhibits such failures 23.9% of the time according to our evaluator, underscoring the need to develop safer LM agents for real-world deployment. \n  \nhttps://preview.redd.it/lupenzddh2tb1.jpg?width=1368&format=pjpg&auto=webp&s=eaac22f0e3e4f5c2913aa9f2696e8fa0138967d9\n https://preview.redd.it/1dq443edh2tb1.jpg?width=1520&format=pjpg&auto=webp&s=2119053825de1cdabeafe61151940c26190abfa0\n https://preview.redd.it/m9e933edh2tb1.jpg?width=1528&format=pjpg&auto=webp&s=28c0093e8479feacb1e6f89bcb73de5994e30e8f\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173dwe7/r_identifying_the_risks_of_lm_agents_with_an/",
          "publishedOn": "2023-10-08T23:59:49.000Z",
          "wordCount": 2781,
          "title": "[R] Identifying the Risks of LM Agents with an LM-Emulated Sandbox - University of Toronto 2023 - Benchmark consisting of 36 high-stakes tools and 144 test cases!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173c1vh/r_pbllm_partially_binarized_large_language_models/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.00034 \n Github: https://github.com/hahnyuan/PB-LLM \n Abstract:\n  \nThis paper explores network binarization, a radical form of quantization, compressing model weights to a single bit, specifically for Large Language Models (LLMs) compression. Due to previous binarization methods collapsing LLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can achieve extreme low-bit quantization while maintaining the linguistic reasoning capacity of quantized LLMs. Specifically, our exploration first uncovers the ineffectiveness of naive applications of existing binarization algorithms and highlights the imperative role of salient weights in achieving low-bit quantization. Thus, PB-LLM filters a small ratio of salient weights during binarization, allocating them to higher-bit storage, i.e., partially-binarization. PB-LLM is extended to recover the capacities of quantized LMMs, by analyzing from the perspective of post-training quantization (PTQ) and quantization aware training (QAT). Under PTQ, combining the concepts from GPTQ, we reconstruct the binarized weight matrix guided by the Hessian matrix and successfully recover the reasoning capacity of PB-LLM in low-bit. Under QAT, we freeze the salient weights during training, explore the derivation of optimal scaling factors crucial for minimizing the quantization error, and propose a scaling mechanism based on this derived scaling strategy for residual binarized weights. Those explorations and the developed methodologies significantly contribute to rejuvenating the performance of low-bit quantized LLMs and present substantial advancements in the field of network binarization for LLMs. \n  \nhttps://preview.redd.it/0eywtpal22tb1.jpg?width=1183&format=pjpg&auto=webp&s=ad044123bec485805f98ae7115b1959162705b9d\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173c1vh/r_pbllm_partially_binarized_large_language_models/",
          "publishedOn": "2023-10-08T22:34:35.000Z",
          "wordCount": 2762,
          "title": "[R] PB-LLM: Partially Binarized Large Language Models - UC Berkeley 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173bs9h/help_choosing_courses_d/",
          "author": null,
          "description": "Hello, I am currently a math masters student, and I am planning to do my masters thesis on using neural networks to solve differential equations. I am taking courses in machine learning and differential equations right now, and I am going to take courses on deep neural networks and partial differential equations next semester. My question pertains to which classes would be more beneficial to learn next year (i.e. fall 2024-spring 2025). I am debating taking the sequence of regression analysis and multivariate analysis, or taking the pairing of numerical analysis for PDEs and perturbation methods. Which do you guys think would be more beneficial? Thank you very much!\n    submitted by    /u/purpledesertsky1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173bs9h/help_choosing_courses_d/",
          "publishedOn": "2023-10-08T22:22:56.000Z",
          "wordCount": 2644,
          "title": "Help choosing courses [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173at26/r_pt_3_inductive_logic_programming_with_lnns/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173at26/r_pt_3_inductive_logic_programming_with_lnns/",
          "publishedOn": "2023-10-08T21:42:02.000Z",
          "wordCount": 2537,
          "title": "[R] (Pt. 3) Inductive Logic Programming with LNN's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1738pb4/d_multiscale_predictions_with_videos_does_this/",
          "author": null,
          "description": "I aim to develop a model that utilizes livestream data by employing embeddings for each frame from t0 to tn-1, with the objective of predicting frames from tn to tn+k, after encodoing the frames using a vectorizer and taking an average (np.mean ([], axis=0) to get a resultant for that time period.\n for example list:\n 1, [...] 2, [...] 3, [...] \n the resultant embedding would be [3, np.mean(list, axis=0)]\n I incorporate positional embeddings related to the timescale, such as duration from current time variables, into the array. would this loosely qualify as a \"multiscale attention\", since it's predicting on multiple scales of time?\n Are there any examples or applications where this methodology has been implemented? references to papers or repos greatly appreciated.\n    submitted by    /u/bluzkluz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1738pb4/d_multiscale_predictions_with_videos_does_this/",
          "publishedOn": "2023-10-08T20:13:30.000Z",
          "wordCount": null,
          "title": "[d] Multiscale predictions with videos- does this approach have a name? and has it been used?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17389hx/d_how_to_model_noisy_time_series/",
          "author": null,
          "description": "Is it possible to model time series data that fluctuates. The main solution is to take first differences and make it easier to fit conventional models. What if non-linear models are built? Can they solve a noisy time series (e.g stock market data) and make good predictions? Can adding a square term or a trigonometric term or something else non-linear work? Has some researched the topic? \n    submitted by    /u/Pineapple_throw_105  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17389hx/d_how_to_model_noisy_time_series/",
          "publishedOn": "2023-10-08T19:55:08.000Z",
          "wordCount": 2604,
          "title": "[D] How to model noisy time series?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1737xdb/newsmit_ai_conference_in_mountain_view_california/",
          "author": null,
          "description": "https://preview.redd.it/n6agjsye71tb1.png?width=2034&format=png&auto=webp&s=8c0a14524d9b6ead75ac0adb3cebeedb9e614e14\n Meet some of the Greatest Minds in AI and discover how it is being used to uncover new opportunities and transform industries.\n Register and see our complete speaker list & agenda at https://www.mitaiconference.org/.\n Registration ends Oct. 16!\n https://preview.redd.it/egtj0ufr81tb1.png?width=659&format=png&auto=webp&s=bfd0521a1e1b349129250a74fa2c6a10b1a83dc7\n ​\n    submitted by    /u/769498sy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1737xdb/newsmit_ai_conference_in_mountain_view_california/",
          "publishedOn": "2023-10-08T19:40:33.000Z",
          "wordCount": 2571,
          "title": "[News]MIT AI Conference in Mountain View, California, October 21!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1736h1a/r_computer_vision_system_for_material_detection/",
          "author": null,
          "description": "The goal of my research is to develop a YOLO model that can track all cups in a live feed and determine the material that the cups are made out of. I would like to start building a database of cups, but I am unsure of the way to go for this. My first thought was to just take 1000s of pictures of different cups, but I won't be doing that. Any thoughts and suggestions would be greatly appreciated. \n    submitted by    /u/Young_Neji  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1736h1a/r_computer_vision_system_for_material_detection/",
          "publishedOn": "2023-10-08T18:40:03.000Z",
          "wordCount": 2617,
          "title": "[R] Computer Vision System for Material Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1735fks/r_ai_and_civil_engineering_probabilistic/",
          "author": null,
          "description": "Despite being much safer and more efficient than intersections, roundabouts are tricky to design - small tweaks can ruin traffic flow. \n They're typically designed iteratively, which takes time. This is a pain for developing countries without resources to test options. But AI could help auto-generate diverse and valid design options.\n In a new paper, researchers propose using Generative Flow Networks (GFlowNets) to sample varied roundabout layouts. Their approach works by constructing layouts step-by-step, maximizing rewards for realism, diversity, and safety.\n They also use a clever approximation during training. Rather than simulating traffic, they quickly check road intersections to focus the search (This sped up training by 200x).\n The authors tested their generated roundabout designs on simulated road scenarios of different complexity. Their model generated more diverse designs than rule-based or reinforcement learning approaches while maintaining realism and traffic flow.\n Plus, as road connections increased, the model kept discovering novel options without compromising quality.\n I thought this paper was an awesome proof-of-concept for auto-generating better roundabouts with AI, and I especially liked the authors' angle of leveraging this technology to specifically help developing countries. This could help them design higher-quality transportation networks faster and cheaper. (Plus I also like Cities: Skylines but struggle at building roundabouts).\n TLDR: Roundabouts are costly to design. New paper demonstrates how AI can generate diverse, valid roundabout designs quickly to cut costs and raise quality. Helpful for infrastructure in developing countries.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1735fks/r_ai_and_civil_engineering_probabilistic/",
          "publishedOn": "2023-10-08T17:56:58.000Z",
          "wordCount": 2787,
          "title": "[R] AI and Civil Engineering: Probabilistic Generative Modeling for Procedural Roundabout Generation for Developing Countries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1732o0l/p_makeagents_a_python_micro_framework_for/",
          "author": null,
          "description": "submitted by    /u/montebicyclelo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1732o0l/p_makeagents_a_python_micro_framework_for/",
          "publishedOn": "2023-10-08T15:58:41.000Z",
          "wordCount": null,
          "title": "[P] MakeAgents - A Python micro framework for creating LLM-powered agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17322bu/discussion_weekday_specific_feature_engineering/",
          "author": null,
          "description": "Focusing on Specific Day of Week Features With Binary Masks, One Hot Coding, Sin/Cos 2d Vector, Or Embedded Vector in Multivariate Time Series Data ?\n The essential challenge is trying to get the model to focus on making predictions for mondays by looking at monday (or actually making predictions for categorical earmarked hours of the day such as midday sales data).\n I keep getting the suggestion to include one hot encoding as a binary mask feature to determine if an hour sales figure is earmarked for the category or the day of the week I want the model to focus on-- in order to get it to ignore the data from the other six days of the week or the other periods of the day.\n In other words I want to hone in on and focus on one period of the week to predict for that period of the week, with extra attention, within time series data. Is this type of binary mask really sufficient for that, or am I overlooking something?\n    submitted by    /u/samdane7777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17322bu/discussion_weekday_specific_feature_engineering/",
          "publishedOn": "2023-10-08T15:32:28.000Z",
          "wordCount": 2705,
          "title": "[Discussion] Weekday Specific Feature Engineering in Time Series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1731tf3/d_rag_platform/",
          "author": null,
          "description": "I don’t have a large data science or even engineering team. But I’m interested in implementing RAG against my corpus in SharePoint. Are there platforms that I can configure without having to put them together or write code to implement RAG?\n    submitted by    /u/Silver_Patient_7253  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1731tf3/d_rag_platform/",
          "publishedOn": "2023-10-08T15:22:17.000Z",
          "wordCount": 2575,
          "title": "[D] RAG Platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1731pcg/r_why_is_adamw_often_superior_to_adam_with/",
          "author": null,
          "description": "A recent work explores how weight decay controls the effective learning rate for different layers and neurons. This rotational behavior drastically differs between Adam with L2 regularization compared to Adam with decoupled weight decay (AdamW) and seems to be the reason AdamW performs better in practice. It could also explain why normalization methods like weight standardization work so well and irregular rotational behavior could contribute to the need for a learning rate warmup.\n Full Abstract: Weight decay can significantly impact the optimization dynamics of deep neural networks. In certain situations, the effects of weight decay and gradient updates on the magnitude of a parameter vector cancel out on average, forming a state known as equilibrium. This causes the expected rotation of the vector in each update to remain constant along with its magnitude. Importantly, equilibrium can arise independently for the weight vectors of different layers and neurons. These equilibria are highly homogeneous for some optimizer and normalization configurations, effectively balancing the average rotation—a proxy for the effective learning rate—across network components. In this work we explore the equilibrium states of multiple optimizers including AdamW and SGD with momentum, providing insights into interactions between the learning rate, weight decay, initialization, normalization and learning rate schedule. We show how rotational equilibrium can be enforced throughout training, eliminating the chaotic transient phase corresponding to the transition towards equilibrium, thus simplifying the training dynamics. Finally, we show that rotational behavior may play a key role in the effectiveness of AdamW compared to Adam with L2-regularization, the performance of different normalization layers, and the need for learning rate warmup.\n    submitted by    /u/PlantsAreSoooAwesome  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1731pcg/r_why_is_adamw_often_superior_to_adam_with/",
          "publishedOn": "2023-10-08T15:17:39.000Z",
          "wordCount": 2819,
          "title": "[R] Why is AdamW often superior to Adam with L2-Regularization in practice? The answer may lie in how weight decay balances updates across layers.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17318zf/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17318zf/d_simple_questions_thread/",
          "publishedOn": "2023-10-08T15:00:22.000Z",
          "wordCount": 2584,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1730i60/d_why_cant_models_trained_on_textimage/",
          "author": null,
          "description": "My main question is, that shouldn't models with Text-image interleaved data, be able to generate images as well as take them as input? because however they were tokenized, the bot would have image outputs as well, wouldn't it?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1730i60/d_why_cant_models_trained_on_textimage/",
          "publishedOn": "2023-10-08T14:29:08.000Z",
          "wordCount": 2585,
          "title": "[D] Why can't models trained on text-image interleaved data generate Images as well as read them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172w843/p_coding_stable_diffusion_from_scratch_in_pytorch/",
          "author": null,
          "description": "submitted by    /u/hkproj_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172w843/p_coding_stable_diffusion_from_scratch_in_pytorch/",
          "publishedOn": "2023-10-08T10:49:23.000Z",
          "wordCount": 2550,
          "title": "[P] Coding Stable Diffusion from scratch in PyTorch, with full explanation of the math behind diffusion models in a simple way!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172w3zu/d_optimize_rvc_training_parameters/",
          "author": null,
          "description": "I've been training a model recently with a rather large dataset (0_gt_wavs are 1h10) and my Epochs are taking 43min on average. I'm running a gtx 1080 and my usage is looking like this: https://i.imgur.com/EE9SUXp.png\n My training parameters:\n 'batch_size': 6, 'fp16_run': False, 'lr_decay': 0.999875, 'segment_size': 12800, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'max_wav_value': 32768.0, 'sampling_rate': 40000, 'filter_length': 2048, 'hop_length': 400, 'win_length': 2048, 'n_mel_channels': 125, 'mel_fmin': 0.0, 'mel_fmax': None, 'training_files': './logs\\\\model1/filelist.txt'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [10, 10, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'use_spectral_norm': False, 'gin_channels': 256, 'spk_embed_dim': 109}, 'model_dir': './logs\\\\model1', 'experiment_dir': './logs\\\\model1', 'save_every_epoch': 10, 'name': 'model1', 'total_epoch': 500, 'pretrainG': 'pretrained_v2/f0G40k.pth', 'pretrainD': 'pretrained_v2/f0D40k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '40k', 'if_f0': 1, 'if_latest': 1, 'save_every_weights': '0', 'if_cache_data_in_gpu': 0} \n Am I doing something obviously wrong? Is there a way to optimize my training parameters to reduce the epoch duration? I've previously trained something where the GPU usage was constantly at 100% and not fluctuating so much, but I can't remember which settings were different. It was definitely a smaller dataset.\n And follow up: if there are parameters to change, how can I abort the current training and continue it with the modified parameters?\n Thanks in advance!\n    submitted by    /u/induna_crewneck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172w3zu/d_optimize_rvc_training_parameters/",
          "publishedOn": "2023-10-08T10:42:30.000Z",
          "wordCount": null,
          "title": "[D] optimize RVC training parameters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172vppq/d_how_to_finetune_llm_for_text_generation_with/",
          "author": null,
          "description": "I have a text regression dataset with ad popularity. I have already trained a model to perform regression (popularity prediction) with good metrics. Now I want to use an LLM to \"improve\" texts, i.e. something like \"Make this text more engaging: {text}\".\n I tried out a few OpenAI models (GPT-3.5, GPT-3.5-instruct, GPT-4), but popularity predictions for augmented texts did not improve (checked with histograms, medians, and Wilcoxon test).\n So now I want to fine-tune an LLM to perform text generation, but guided with my predicted popularity, which basically works as a quality metric. I could not find any resources on this, only on either text generation finetuning (without guiding quality metric) or on classification (no text generation objective). I can also change my quality metric to binary (augmented text is better or not), if this matters.\n How can I do this? Any blogs / tutorials / papers are appreciated.\n    submitted by    /u/qalis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172vppq/d_how_to_finetune_llm_for_text_generation_with/",
          "publishedOn": "2023-10-08T10:17:22.000Z",
          "wordCount": 2692,
          "title": "[D] How to fine-tune LLM for text generation with regression quality metric?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172vllp/r_gaia1_a_generative_world_model_for_autonomous/",
          "author": null,
          "description": "submitted by    /u/blabboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172vllp/r_gaia1_a_generative_world_model_for_autonomous/",
          "publishedOn": "2023-10-08T10:10:39.000Z",
          "wordCount": 2551,
          "title": "[R] GAIA-1: A Generative World Model for Autonomous Driving",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172t5hc/r_pbllm_compressed_large_language_models_with/",
          "author": null,
          "description": "Research on network binarization techniques tailored for Large Language Models (LLMs). The team has introduced a method called Partial Binarization for LLMs (PB-LLM) which compresses the majority of model parameters down to just a single bit while maintaining its language reasoning capabilities. PB-LLM achieves this by selectively filtering critical weights and allocating more bits for storage, enabling low-bit quantization.\n The researchers have explored methods like Post-Training Quantization (PTQ), named GPTQ-PB, and Quantization Aware Training (QAT) to restore the inference capabilities of LLMs. \n For those interested in delving deeper, you can find the research paper on Arxiv: https://arxiv.org/abs/2310.00034 and the code implementation on GitHub: https://github.com/hahnyuan/PB-LLM.\n ​\n  Partially-Binarized LLM \n Result\n    submitted by    /u/hahnyuan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172t5hc/r_pbllm_compressed_large_language_models_with/",
          "publishedOn": "2023-10-08T07:33:56.000Z",
          "wordCount": 2647,
          "title": "[R] PB-LLM: Compressed Large Language Models with Partial Binarization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172pkkg/p_evaluating_retrievalaugmented_generation_rag/",
          "author": null,
          "description": "To help developers test their RAG systems, we added a RAG experiment class to our open-source library PromptTools. It allows users to easily experiment with different combinations of LLMs and vector DBs, and evaluate the results of their whole pipeline.\n In particular, you can experiment with:\n  \nChunking up your documents into different sizes\n Pre-processing those documents in various ways\n Inserting those documents into your vector DBs with various vectorizer and embedding function, and accessing them with different distance functions\n  \nIn our RAG example, we retrieve documents from ChromaDB and pass them into OpenAI’s chat model along with our prompt. We then pass the results into built-in evaluation functions, such as semantic similarity and autoeval, to quantitatively evaluate your result.\n PromptTools is agnostic to what LLMs and vector DBs you use. You can easily iterate over different system architectures forRAG. You can even bring your own fine-tuned models or write a custom integration. In addition, you can write your own evaluation metrics, and independently evaluate the results from the retrieval step as well.\n Our current integrations include:\n  \nLLM: OpenAI (chat, fine-tuned), Anthropic, Google Vertex/PaLM, Llama (local or via Replicate)\n Vector DB: Chroma, Weaviate, LanceDB, Pinecone, Qdrant\n Framework: LangChain, MindsDB\n  \nYou can get started with RAG in minutes by installing the library and running this example.\n As open-source maintainers, we’re always interested to hear the community’s pain points and requests. Let us know how you are testing your RAG systems and how we can help.\n    submitted by    /u/hegel-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172pkkg/p_evaluating_retrievalaugmented_generation_rag/",
          "publishedOn": "2023-10-08T03:57:41.000Z",
          "wordCount": 2789,
          "title": "[P] Evaluating Retrieval-Augmented Generation (RAG) with any combination of LLMs, Vector DBs, and Ingestion Strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172pauc/research_pixnav_bridging_zeroshot_object/",
          "author": null,
          "description": "Paper: https://arxiv.org/pdf/2309.10309\n Github: https://github.com/wzcai99/Pixel-Navigator\n Abstract: Zero-shot object navigation is a challenging task for home-assistance robots. This task emphasizes visual grounding, commonsense inference, and locomotion abilities, where the first two are inherent in foundation models. But for the locomotion part, most works still depend on map-based planning approaches. The gap between RGB space and map space makes it difficult to directly transfer the knowledge from foundation models to navigation tasks. In this work, we propose a Pixel-guided Navigation skill (PixNav), which bridges the gap between the foundation models and the embodied navigation task. It is straightforward for recent foundation models to indicate an object by pixels, and with pixels as the goal specification, our method becomes a versatile navigation policy towards all different kinds of objects. Besides, our PixNav is a pure RGB-based policy that can reduce the cost of home-assistance robots. Experiments demonstrate the robustness of the PixNav which achieves 80+% success rate in the local path-planning task. To perform long-horizon object navigation, we design an LLM-based planner to utilize the commonsense knowledge between objects and rooms to select the best waypoint. Evaluations across both photorealistic indoor simulators and real-world environments validate the effectiveness of our proposed navigation strategy.\n https://preview.redd.it/5qtd7ralgwsb1.png?width=828&format=png&auto=webp&s=118d5a1e8a083130b6d64bf1602af0417067aac8\n https://preview.redd.it/jwr2nnorgwsb1.png?width=1984&format=png&auto=webp&s=20062d7982c0eb1906fe0f6964d4b42e45b44a51\n https://preview.redd.it/llk4ubitgwsb1.png?width=1986&format=png&auto=webp&s=eb4894d52d7d8a82d97d83a2ff7a6be83da11af2\n    submitted by    /u/Character_Push3985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172pauc/research_pixnav_bridging_zeroshot_object/",
          "publishedOn": "2023-10-08T03:42:22.000Z",
          "wordCount": 2766,
          "title": "[Research] PixNav: Bridging Zero-Shot Object Navigation and Foundation Models through Pixel-Guided Navigation Skill - A pure RGB navigation framework that can be seamlessly integrated with the foundation models and perform efficient exploration in object navigation task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172iqur/d_how_do_i_get_a_fundamental_mathematical/",
          "author": null,
          "description": "Diffusion models, GAN, VAE, normalizing flows, etc. I \"understand\" those methods from an algorithmic perspective, diffusions gradually denoise an image, VAE use an encoder decoder architecture to turn an image into a latent distribution etc.\n But from a statistical modeling standpoint, I'm really struggling, when I read papers like DDPM, DDIM or Normalizing Flows, I kind of undestand the notation, but I barely understand the statistical modeling, and I wouldn't be able to produce such thing myself\n I want to understand this, which resources should I use ?\n Are books like Bishop and Murphy enough ? Which one is the best ?\n    submitted by    /u/Even_Information4853  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172iqur/d_how_do_i_get_a_fundamental_mathematical/",
          "publishedOn": "2023-10-07T22:25:25.000Z",
          "wordCount": 2647,
          "title": "[D] How do I get a fundamental mathematical understanding of modern generative modeling methods",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172gvb3/n_emnlp_2023_anonymity_hypocrisy/",
          "author": null,
          "description": "Some of you might already be aware that a junior who submitted their paper to arxiv 30 mins late had their paper desk rejected late in the process. One of the PCs, Juan Pino, spoke up about it and said it was unfortunate, but for fairness reasons they had to enforce the anonymity policy rules. https://x.com/juanmiguelpino/status/1698904035309519124\n Well, what you might not realize is that Longyue Wang, a senior area chair for AACL 23/24, also broke anonymity DURING THE REVIEW PROCESS. https://x.com/wangly0229/status/1692735595179897208\n I emailed the senior area chairs for the track that the paper was submitted to, but guess what? I just found out that the paper was still accepted to the main conference.\n So, whatever \"fairness\" they were talking about apparently only goes one way: towards punishing the lowly undergrad on their first EMNLP submission, while allowing established researchers from major industry labs to get away with even more egregious actions (actively promoting the work DURING REVIEW; the tweet has 10.6K views ffs).\n They should either accept the paper they desk rejected for violating the anonymity policy, or retract the paper they've accepted since it also broke the anonymity policy (in a way that I think is much more egregious). Otherwise, the notion of fairness they speak of is a joke.\n    submitted by    /u/emnlp2023_hypocrisy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172gvb3/n_emnlp_2023_anonymity_hypocrisy/",
          "publishedOn": "2023-10-07T21:05:24.000Z",
          "wordCount": 2747,
          "title": "[N] EMNLP 2023 Anonymity Hypocrisy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172fj9f/r_tora_a_toolintegrated_reasoning_agent_for/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.17452v2 \n Github: https://github.com/microsoft/ToRA / The code will be cleaned and uploaded within a few days, all ToRA models will be released.\n Abstract:\n  \nLarge language models have made significant progress in various language tasks, yet they still struggle with complex mathematics. In this paper, we propose ToRA a series of Tool-integrated Reasoning Agents designed to solve challenging mathematical problems by seamlessly integrating natural language reasoning with the utilization of external tools (e.g., computation libraries and symbolic solvers), thereby amalgamating the analytical prowess of language and the computational efficiency of tools. To train ToRA, we curate interactive tool-use trajectories on mathematical datasets, apply imitation learn…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172fj9f/r_tora_a_toolintegrated_reasoning_agent_for/",
          "publishedOn": "2023-10-07T20:07:18.000Z",
          "wordCount": 2769,
          "title": "[R] ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving - Microsoft 2023 - Is competitive with GPT-4 solving problems with programs while being open-source!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172fhpz/r_video_object_removal_and_video_completion/",
          "author": null,
          "description": "​\n https://preview.redd.it/ukov8uy67usb1.png?width=1864&format=png&auto=webp&s=cb34448c2af90d08f8ef6db828d61141636498df\n https://shangchenzhou.com/projects/ProPainter/\n    submitted by    /u/Milkyson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172fhpz/r_video_object_removal_and_video_completion/",
          "publishedOn": "2023-10-07T20:05:29.000Z",
          "wordCount": 2545,
          "title": "[R] Video object removal and video completion - Propainter : Propagation and transformer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172dbor/p_a_poor_mans_vr_front_camera_tensorflowjs/",
          "author": null,
          "description": "Using the front camera and tensorflow.js, the smartphone becomes a “window” into the real world. Video and image content appear as if they were seen through this window. To do this, the viewer’s position is determined using a neural network. The viewed content is then moved according to the viewer’s position. This makes it seem like the content is physically behind the smartphone and is viewed through the smartphone’s screen. This effect is especially useful for content captured using an ultra-wide lens.\n    submitted by    /u/muxamilian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172dbor/p_a_poor_mans_vr_front_camera_tensorflowjs/",
          "publishedOn": "2023-10-07T18:31:06.000Z",
          "wordCount": 2629,
          "title": "[P] A poor man’s VR (front camera + tensorflow.js)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172cafd/p_building_a_gptdriven_chatbot_assistant_ai/",
          "author": null,
          "description": "submitted by    /u/sschepis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172cafd/p_building_a_gptdriven_chatbot_assistant_ai/",
          "publishedOn": "2023-10-07T17:48:57.000Z",
          "wordCount": 2547,
          "title": "[P] Building a GPT-Driven Chatbot Assistant / AI Interpreter with Node.js",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172bz3h/r_what_is_the_current_sota_for_image_to_image/",
          "author": null,
          "description": "I know a few years back it was pix2pix, but the world has moved on since then. Is there a transformer with cross attention that is adept at this, or are diffusion models the best bet?\n    submitted by    /u/blabboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172bz3h/r_what_is_the_current_sota_for_image_to_image/",
          "publishedOn": "2023-10-07T17:35:23.000Z",
          "wordCount": 2578,
          "title": "[R] What is the current SOTA for image to image translation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172becm/multivariate_time_series_forecasting_with_cnnlstm/",
          "author": null,
          "description": "I want to implement a multivariate multi-step CNN-LSTM model, to obtain forecasts for monthly sales of several different products. Furthermore, I want to include additional time-series data (features) as input. So for example:\n Input: time series of product 1, product 2, GDP, PMI\n Output: product 1 (monthly 6-steps ahead), product 2 (monthly 6-steps ahead)\n I have a couple of questions:\n  \nFeasibility: I've been researching this approach, but I haven't found many tutorials or guides on how to tackle multivariate time series forecasting with a CNN-LSTM architecture. I do find tutorials on CNN-LSTM, but not on how to include additional features as input. Has anyone here attempted something similar or can provide insights on how to proceed?\n Feature Selection: I have access to 20 different features, all of which are time series data. I want to choose the most relevant features for my model. I've considered performing a Variance Inflation Factor (VIF) analysis to select the best features. Does anyone have experience with this or other methods for feature selection in time series forecasting? How to decide the number of features to include? \n  \nAny advice or pointers in the right direction would be greatly appreciated!\n    submitted by    /u/Ambitious-Pay6329  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172becm/multivariate_time_series_forecasting_with_cnnlstm/",
          "publishedOn": "2023-10-07T17:11:22.000Z",
          "wordCount": 2734,
          "title": "Multivariate Time Series Forecasting with CNN-LSTM and features [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172anhw/easy_image_datasets_besides_mnist_p/",
          "author": null,
          "description": "Can anyone recommend some image classification datasets (besides MNIST) that are easy enough to the point that they can be solved with linear layers, not requiring any convolutional layers? Thanks!\n    submitted by    /u/mike20731  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172anhw/easy_image_datasets_besides_mnist_p/",
          "publishedOn": "2023-10-07T16:40:03.000Z",
          "wordCount": 2567,
          "title": "Easy Image Datasets Besides MNIST? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1729z0y/r_hugging_face/",
          "author": null,
          "description": "So if I wanted to generate a shirt or book cover with a design and text that's inputted by me what do I have to do? I know that even Mid Journey doesn't generate good text with its images but I was thinking maybe its bc it was trained just with pictures. Is there an easy way to get legible text and images every time with any model on the site? Do I need to train one? Do I need to train a GAN looking for assistance, thanks.\n    submitted by    /u/MonstaAndrew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1729z0y/r_hugging_face/",
          "publishedOn": "2023-10-07T16:10:20.000Z",
          "wordCount": 2622,
          "title": "[R] Hugging Face",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1729fi5/d_how_can_i_findcreate_a_dataset_of_satellite/",
          "author": null,
          "description": "I'm a student currently researching the use of satellite imagery to detect obstacles on railways such as fallen trees and rockfalls. There doesn't seem to be any datasets available containing satellite imagery of these obstacles.\n I'm considering the use of generative AI to create a synthetic dataset, but I don't know where to start.\n Has anyone tried something similar?\n    submitted by    /u/Just_Status_9380  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1729fi5/d_how_can_i_findcreate_a_dataset_of_satellite/",
          "publishedOn": "2023-10-07T15:46:09.000Z",
          "wordCount": 2600,
          "title": "[D] How can I find/create a dataset of satellite imagery?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1728s4w/d_need_clarification_on_training_diffusion_model/",
          "author": null,
          "description": "Hey i have trained a diffusion model for 100 epochs , 8 hours and i got the following train and val loss mostly the implementation is done using diffusers. then i try reconstruction on the test set to check whether the model learned any thing this is whats happening most if the images are not getting denoised at all why this is happening? is this common or should i need to train more. any suggestions? please help\n val loss\n train loss\n input and reconstructed images\n    submitted by    /u/specializedboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1728s4w/d_need_clarification_on_training_diffusion_model/",
          "publishedOn": "2023-10-07T15:16:49.000Z",
          "wordCount": 2623,
          "title": "[D] Need clarification on training diffusion model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172502d/d_tuning_on_xml_data/",
          "author": null,
          "description": "Hello experts, I'm a dumb ML enthusiast,\n I'm asking for your high level thoughts and opinions.\n So I'm doing my research and trying to find a way to train a LLM model to know all the right answers based on XML data. The data is a shop inventory, containing information on shoe models, sizes, is it in stock, description, image links etc.\n How would you approach it? For now the best option i came up with is parsing data, transforming it into predefined set of questions with answers based on the data derived from xml. Doesn't seem smart enough to me.\n    submitted by    /u/yarikbratashchuk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172502d/d_tuning_on_xml_data/",
          "publishedOn": "2023-10-07T12:16:32.000Z",
          "wordCount": 2635,
          "title": "[D] Tuning on XML data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1723s59/d_when_using_gpts_function_calling_are_the_words/",
          "author": null,
          "description": "Example: ``` student_custom_functions = [ { 'name': 'extract_student_info', 'description': 'Get the student information from the body of the input text', 'parameters': { 'type': 'object', 'properties': { 'name': { 'type': 'string', 'description': 'Name of the person' }, 'major': { 'type': 'string', 'description': 'Major subject.' }, 'school': { 'type': 'string', 'description': 'The university name.' }, 'grades': { 'type': 'integer', 'description': 'GPA of the student.' }, 'club': { 'type': 'string', 'description': 'School club for extracurricular activities. ' }\n  } } } \n ] ```\n ``` student_description = [student_1_description,student_2_description] for sample in student_description: response = openai.ChatCompletion.create( model = 'gpt-3.5-turbo', messages = [{'role': 'user', 'content': sample}], functions = student_custom_functions, function_call = 'auto' )\n # Loading the response as a JSON object json_response = json.loads(response['choices'][0]['message']['function_call']['arguments']) print(json_response) \n ```\n Are the words specified in the properties parameter under functions in the above GPT function calling counted as input tokens?\n    submitted by    /u/redd-dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1723s59/d_when_using_gpts_function_calling_are_the_words/",
          "publishedOn": "2023-10-07T11:08:00.000Z",
          "wordCount": 2686,
          "title": "[D] When using GPT’s function calling, are the words specified in the `properties` parameter under `functions` counted as input tokens?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1723fn3/d_schmidhuber_summarized_in_one_picture/",
          "author": null,
          "description": "submitted by    /u/fromnighttilldawn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1723fn3/d_schmidhuber_summarized_in_one_picture/",
          "publishedOn": "2023-10-07T10:47:10.000Z",
          "wordCount": 2546,
          "title": "[D] Schmidhuber summarized in one picture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171zot4/r_the_alberta_plan_for_ai_research/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171zot4/r_the_alberta_plan_for_ai_research/",
          "publishedOn": "2023-10-07T06:52:04.000Z",
          "wordCount": 2549,
          "title": "[R] The Alberta Plan for AI Research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171s8ef/r_arxiv_endorsement/",
          "author": null,
          "description": "Hello, all.\n I've spent the better part of the last two years learning ML and conquering severe ADHD, and I believe I finally have results that are worth publishing.\n Problem is, Arxiv requires endorsements and, I'll be honest, all my peers are AI at this point.\n They said their requirements were that you have three papers published already. Thanks, and looking forward to meeting people 😁\n    submitted by    /u/lilyerickson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171s8ef/r_arxiv_endorsement/",
          "publishedOn": "2023-10-07T00:14:59.000Z",
          "wordCount": 2600,
          "title": "[R] Arxiv Endorsement?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171qfiu/d_what_exactly_does_base_multimodal_mean/",
          "author": null,
          "description": "I here a lot of people say that models like flamingo and Idefics aren't really multimodal, that they just use clip models to give text captions to the transformer, that there not \"base multimodal\" what exactly does it mean? Is there a way to directly tokenize images to transformers? Are there major architectural changes, if so, how would they differ from GPT-2?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171qfiu/d_what_exactly_does_base_multimodal_mean/",
          "publishedOn": "2023-10-06T22:56:29.000Z",
          "wordCount": null,
          "title": "[D] What exactly does base multimodal mean?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171lrmy/r_autoagents_a_framework_for_automatic_agent/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.17288v1 \n Github: https://github.com/LinkSoul-AI/AutoAgents \n Abstract:\n  \nLarge language models (LLMs) have enabled remarkable advances in automated task-solving with multi-agent systems. However, most existing LLM-based multi-agent approaches rely on predefined agents to handle simple tasks, limiting the adaptability of multi-agent collaboration to different scenarios. Therefore, we introduce AutoAgents, an innovative framework that adaptively generates and coordinates multiple specialized agents to build an AI team according to different tasks. Specifically, AutoAgents couples the relationship between tasks and roles by dynamically generating multiple required agents based on task content and planning solutions for the current task based on the generated expert agents. Multiple specialized agents collaborate with each other to efficiently accomplish tasks. Concurrently, an observer role is incorporated into the framework to reflect on the designated plans and agents' responses and improve upon them. Our experiments on various benchmarks demonstrate that AutoAgents generates more coherent and accurate solutions than the existing multi-agent methods. This underscores the significance of assigning different roles to different tasks and of team cooperation, offering new perspectives for tackling complex tasks. \n  \nhttps://preview.redd.it/2jmnr73kymsb1.jpg?width=1663&format=pjpg&auto=webp&s=08f53d5da3d12e685c5d4b24f27628d880a917c1\n https://preview.redd.it/jklyr73kymsb1.jpg?width=824&format=pjpg&auto=webp&s=6f69b2fc5ef4bda60553da0bb953bd3c07ad506b\n https://preview.redd.it/elatla3kymsb1.jpg?width=1029&format=pjpg&auto=webp&s=e7e508cedd17b4798c9f90bf1c089beff3042f4a\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171lrmy/r_autoagents_a_framework_for_automatic_agent/",
          "publishedOn": "2023-10-06T19:45:05.000Z",
          "wordCount": 2736,
          "title": "[R] AutoAgents: A Framework for Automatic Agent Generation - Peking University 2023 - Generates the for the task necessary amount of different Agents that are also able to use tools in their work!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171kwaq/project_lora_from_scratch/",
          "author": null,
          "description": "Hi there! I was interested in learning more about LoRA but I was having a hard time finding a good simple example of implementing LoRA, as most sources are training large models and use a combination of huggingface transformers and the loralib package the original LoRA authors wrote. As a result, I ended up writing a simple LoRA implementation from scratch in pytorch lightning, and I figured other people might find it helpful as a learning resource or springboard: https://github.com/sunildkumar/lora_from_scratch/tree/main\n    submitted by    /u/dragseon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171kwaq/project_lora_from_scratch/",
          "publishedOn": "2023-10-06T19:09:06.000Z",
          "wordCount": 2609,
          "title": "[Project] LoRA from Scratch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171kdxx/p_tutorial_benchmarking_bark_texttospeech_on_26/",
          "author": null,
          "description": "In this project, we benchmarked Bark text-to-speech across 26 different consumer GPUs. \n The goal: To get Bark to read 144K food recipes from Food.com's recipe dataset. \n You can read the full tutorial here: https://blog.salad.com/bark-benchmark-text-to-speech/\n Included: Architecture diagram, data preparation, inference server setup, queue worker, setting up container group & compiling the results\n Code-blocks included in the tutorial. \n Words per dollar for each GPU:\n https://preview.redd.it/6daqluu3omsb1.png?width=2000&format=png&auto=webp&s=bc4b74fe6ee80c2721ab324eb0d9a2d7c2f7ddb1\n Although the latest cards are indeed much faster than older cards at performing the inference, there’s really a sweet spot for cost-performance in the lower end 30xx series cards. \n Conclusions\n  \nAs is often the case, there’s a clear trade-off here between cost and performance. Higher end cards are faster, but their disproportionate cost makes them more expensive per word spoken.\n The model’s median speed is surprisingly similar across GPU types, even though the peak performance can be quite different.\n Salad has a lot of RTX 3060 GPUs available, based on their relatively low speed, yet huge number of inferences performed over the test.\n No matter what GPU you select, you should be prepared for significant variability in performance.\n Qualitative: While bark’s speech is often impressively natural sounding, it does have a tendency to go off script sometimes.\n  \nWe’ve also made available audio from 1000 top-rated recipes, paired with the script it was trying to read.\n    submitted by    /u/SaladChefs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171kdxx/p_tutorial_benchmarking_bark_texttospeech_on_26/",
          "publishedOn": "2023-10-06T18:48:38.000Z",
          "wordCount": 2763,
          "title": "[P] Tutorial: Benchmarking Bark text-to-speech on 26 consumer GPUs - Reading out 144K recipes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171igzx/r_brown_university_paper_lowresource_languages/",
          "author": null,
          "description": "Researchers from Brown University presented a new study supporting that translating unsafe prompts into `low-resource languages` allows them to easily bypass safety measures in LLMs.\n By converting English inputs like \"how to steal without getting caught\" into Zulu and feeding to GPT-4, harmful responses slipped through 80% of the time. English prompts were blocked over 99% of the time, for comparison.\n The study benchmarked attacks across 12 diverse languages and categories:\n  \nHigh-resource: English, Chinese, Arabic, Hindi\n Mid-resource: Ukrainian, Bengali, Thai, Hebrew\n Low-resource: Zulu, Scots Gaelic, Hmong, Guarani\n  \nThe low-resource languages showed serious vulnerability to generating harmful responses, with combined attack success rates of around 79%. Mid-resource language success rates were much lower at 22%, while high-resource languages showed minimal vulnerability at around 11% success.\n Attacks worked as well as state-of-the-art techniques without needing adversarial prompts.\n These languages are used by 1.2 billion speakers today and allows easy exploitation by translating prompts. The English-centric focus misses vulnerabilities in other languages.\n TLDR: Bypassing safety in AI chatbots is easy by translating prompts to low-resource languages (like Zulu, Scots Gaelic, Hmong, and Guarani). Shows gaps in multilingual safety training.\n Full summary Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171igzx/r_brown_university_paper_lowresource_languages/",
          "publishedOn": "2023-10-06T17:32:00.000Z",
          "wordCount": 2737,
          "title": "[R] Brown University Paper: Low-Resource Languages (Zulu, Scots Gaelic, Hmong, Guarani) Can Easily Jailbreak LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171iel8/d_textbook_prerequisites/",
          "author": null,
          "description": "What are the prerequisites to read the book: \"probabilistic machine learning an introduction\" by Kevin P. Murphy?\n    submitted by    /u/OneAdhesiveness2585  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171iel8/d_textbook_prerequisites/",
          "publishedOn": "2023-10-06T17:29:29.000Z",
          "wordCount": null,
          "title": "[D] Textbook prerequisites",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171hona/r_moving_object_based_collisionfree_video_synopsis/",
          "author": null,
          "description": "Webpage : Moving Object Based Collision-Free Video Synopsis (IEEE SMC 2018) (anton-jeran.github.io) \n Paper : Moving Object Based Collision-Free Video Synopsis | IEEE Conference Publication | IEEE Xplore \n Presentation : [IEEE SMC 2018] Moving Object Based Collision-Free Video Synopsis - YouTube \n    submitted by    /u/Snoo63916  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171hona/r_moving_object_based_collisionfree_video_synopsis/",
          "publishedOn": "2023-10-06T17:01:19.000Z",
          "wordCount": 2578,
          "title": "[R] Moving Object Based Collision-Free Video Synopsis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171h0bc/p_musicgen_streaming/",
          "author": null,
          "description": "Faster MusicGen Generation with Streaming\n There's no need to wait for MusicGen to generate the full audio before you can start listening to the outputs ⏰ With streaming, you can play the audio as soon as the first chunk is ready 🎵 In practice, this reduces the latency to just 5s ⚡️\n Check-out the demo: https://huggingface.co/spaces/sanchit-gandhi/musicgen-streaming\n How Does it Work?\n MusicGen is an auto-regressive transformer-based model, meaning generates audio codes (tokens) in a causal fashion. At each decoding step, the model generates a new set of audio codes, conditional on the text input and all previous audio codes. From the frame rate of the EnCodec model used to decode the generated codes to audio waveform, each set of generated audio codes corresponds to 0.02 seconds. This me…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171h0bc/p_musicgen_streaming/",
          "publishedOn": "2023-10-06T16:35:12.000Z",
          "wordCount": null,
          "title": "[P] MusicGen Streaming 🎵",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171gm3b/dr_simple_question_on_generating_a_confusion/",
          "author": null,
          "description": "i have to generate a confusion matrix for object detection through my own code. if i have predicted Bounding Box A (BB-A) which matches to Ground Truth A (GT-A), and I have another predicted Bounding Box B (BB-B) with a lower score than BB-A, does BB-B count as a true positive/match? or is it considered a false positive given that there has already been a matched BB to GT-A? \n i.e., with matching bounding boxes for generating a confusion matrix, is it a one-to-one matching? or is it more like match one GT to as many predictions?\n    submitted by    /u/Alarmed-Broccoli2536  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171gm3b/dr_simple_question_on_generating_a_confusion/",
          "publishedOn": "2023-10-06T16:19:28.000Z",
          "wordCount": null,
          "title": "[D]/{R] simple question on generating a confusion matrix for object detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171dnug/p_im_using_instruct_gpt_to_show_anticlickbait/",
          "author": null,
          "description": "submitted by    /u/Wise-Astronaut-4047  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171dnug/p_im_using_instruct_gpt_to_show_anticlickbait/",
          "publishedOn": "2023-10-06T14:24:26.000Z",
          "wordCount": 2541,
          "title": "[P] I'm using Instruct GPT to show anti-clickbait summaries on youtube videos",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171d234/d_feature_extraction_for_sets_ie_data_of_varying/",
          "author": null,
          "description": "Are there classical feature extraction methods that work on sets i.e. data of variable size?\n I'd like to start with a feature matrix X_in of shape N x f and have some feature mixing to arive at X_out N x h (N=size of set, f=input feature size, h=output feature size). Here, N can vary. \n For clarity, one set(containing N vectors of size f) is one sample. A dataset consists of many samples(each one being a set of varying size).\n Then I'd run this through a classical ML model.\n So, essentially, I'm looking for something like DeepSets or Transformers - can handle data of varying size and is permutation equivariant, but I don't wanna train for long.\n ​\n https://fabianfuchsml.github.io/learningonsets/\n    submitted by    /u/Mundane_Pay1506  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171d234/d_feature_extraction_for_sets_ie_data_of_varying/",
          "publishedOn": "2023-10-06T14:00:01.000Z",
          "wordCount": null,
          "title": "[D] Feature extraction for sets i.e. data of varying size",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171alt3/d_how_is_neural_odes_as_a_field_of_study/",
          "author": null,
          "description": "Hi, I'm a 21yr old physics undergrad, and I have zero knowledge in neural networks / machine learning / so on. I have an opportunity to do a research project on neural ODEs, so I want to know more about the field: Is it an emerging field or is it mature and well-researched? What are my career outlooks if I take this project? Thank you.\n    submitted by    /u/moorelibqc17412  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171alt3/d_how_is_neural_odes_as_a_field_of_study/",
          "publishedOn": "2023-10-06T12:07:14.000Z",
          "wordCount": 2606,
          "title": "[D] How is neural ODEs as a field of study?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17181z7/d_nonconvex_functions_with_exactly_one_local/",
          "author": null,
          "description": "Rosenbrock function is non-convex, but has exactly one local minimum. Is there a specific name for such functions? Are there any theorems about them? Any special optimization algorithms?\n On the first glance, while being non-convex, they seem to be \"easier\" to optimize than functions that have multiple local minima, such as Rastrigin function.\n    submitted by    /u/Tomarchelone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17181z7/d_nonconvex_functions_with_exactly_one_local/",
          "publishedOn": "2023-10-06T09:42:55.000Z",
          "wordCount": null,
          "title": "[D] Non-convex functions with exactly one local minimum",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1715kbd/p_talk_to_your_zendesk_tickets_with_weaviates/",
          "author": null,
          "description": "Hi folks,\n we played around sticking production pipelines and vector dbs together to enable \"talking to your data\". We created an example with Zendesk, but it would work with any custom python generator or existing connectors. \n Project: Talk to your Zendesk tickets with Weaviate’s Verba and dlt: A step by step guide\n If you are interested to try more ready made connectors, to for example talk with your github or asana data or something else.\n Who are we? dlt, the open source loading library: https://pypi.org/project/dlt/\n Like the demo? Give us a git star\n Want to discuss? join the dlt slack community\n    submitted by    /u/Thinker_Assignment  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1715kbd/p_talk_to_your_zendesk_tickets_with_weaviates/",
          "publishedOn": "2023-10-06T06:56:02.000Z",
          "wordCount": 2642,
          "title": "[P] Talk to your Zendesk tickets with Weaviate’s Verba and dlt: A step by step guide",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1711hoa/d_emnlp_2023_decisions_thread/",
          "author": null,
          "description": "When can we expect to get the decisions? Any idea folks? What can be a good cutoff for main or findings?\n    submitted by    /u/Ok_Swan3875  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1711hoa/d_emnlp_2023_decisions_thread/",
          "publishedOn": "2023-10-06T03:01:51.000Z",
          "wordCount": null,
          "title": "[D] EMNLP 2023 decisions thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1711e8w/d_parallelizing_cheaper_gpusrtx_4090_vs_buying/",
          "author": null,
          "description": "Hi. I am a college student and I am trying to run deep learning models (hopefully LLMs one day) and my laptop keep crashing because of ram issue. So I am going to build a new desktop. I am thinking of buying 2 rtx 4090 and Parallelizing them instead of buying A100 because buying 2 rtx 4090 is half the cost of buying A100. But is there a downside of Parallelizing vs buying a single gpu with large vram? If I am willing to take longer to train a model, can i use 3 rtx 4090 instead of a100 80gb model??\n    submitted by    /u/ColumbiaGSAlum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1711e8w/d_parallelizing_cheaper_gpusrtx_4090_vs_buying/",
          "publishedOn": "2023-10-06T02:57:17.000Z",
          "wordCount": null,
          "title": "[D] Parallelizing cheaper GPUs(rtx 4090) vs buying A100",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1710ilb/d_whats_the_sota_model_in_time_series_long_term/",
          "author": null,
          "description": "I read https://arxiv.org/abs/2205.13504 which compare different transformer models. But now is 2023, I am not sure if any better models appear in this time series.\n ​\n https://preview.redd.it/o6sihjqjrhsb1.png?width=1076&format=png&auto=webp&s=3db7d50590270bac52e7115e1e9903a6785957d2\n    submitted by    /u/Trust_Ok  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1710ilb/d_whats_the_sota_model_in_time_series_long_term/",
          "publishedOn": "2023-10-06T02:14:52.000Z",
          "wordCount": null,
          "title": "[D] What's the SOTA model in Time Series Long term forecasting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170z9lm/r_agent_instructs_large_language_models_to_be/",
          "author": null,
          "description": "Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, Chenguang Wang\n Paper: https://arxiv.org/abs/2310.03710\n Abstract: We introduce a method to improve the zero-shot reasoning abilities of large language models on general language understanding tasks. Specifically, we build an autonomous agent to instruct the reasoning process of large language models. We show this approach further unleashes the zero-shot reasoning abilities of large language models to more tasks. We study the performance of our method on a wide set of datasets spanning generation, classification, and reasoning. We show that our method generalizes to most tasks and obtains state-of-the-art zero-shot performance on 20 of the 29 datasets that we evaluate. For instance, our method boosts the performance of state-of-the-art large language models by a large margin, including Vicuna-13b (13.3%), Llama-2-70b-chat (23.2%), and GPT-3.5 Turbo (17.0%). Compared to zero-shot chain of thought, our improvement in reasoning is striking, with an average increase of 10.5%. With our method, Llama-2-70b-chat outperforms zero-shot GPT-3.5 Turbo by 10.2%. The code will be available at https://github.com/wang-research-lab/agentinstruct.\n    submitted by    /u/ncrispino  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170z9lm/r_agent_instructs_large_language_models_to_be/",
          "publishedOn": "2023-10-06T01:15:59.000Z",
          "wordCount": 2707,
          "title": "[R] Agent Instructs Large Language Models to be General Zero-Shot Reasoners",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170yipf/d_how_to_compute_the_distance_between_two/",
          "author": null,
          "description": "Hey all,\n I am generating a set of extra MNIST digits for a research project, and I am interested in somehow computing the distance between the distribution these digits represent and the distribution that the MNIST train set, for example, represents. The issue is that it seems like typical methods (Jensen-Shannon, Wasserstein, etc.) collapse at high dimensions. Is there a consensus solid approach to do this nowadays? Thanks!\n    submitted by    /u/SignificantSundae793  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170yipf/d_how_to_compute_the_distance_between_two/",
          "publishedOn": "2023-10-06T00:40:50.000Z",
          "wordCount": 2609,
          "title": "[D] How to compute the distance between two high-dimensional distributions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170xha8/d_synthetic_dataset_searching_for_honest/",
          "author": null,
          "description": "I'm looking for resources, papers, or experiences that compare the performance of large language models (LLMs). I'm trying to find a honest benchmark to compare the capabilities of the latest large models, while really intrested un those: GPT-3.5 Instruct, GPT-4, Claude 2, Claude Instant 100k, Palm2-Bizon, jurassic-2, LLama2 70 and other state-of-the-art LLama2 fine tunes (possibly an Orca-style model). \n I'm interested in general benchmarks and, if they exist, comparisons of performance on synthetic data generation tasks (both generating data with the \"textbook are all you need\" approach used in Phi and some Orca/EvolveInstuct-style models like Wizard...).\n    submitted by    /u/Distinct-Target7503  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170xha8/d_synthetic_dataset_searching_for_honest/",
          "publishedOn": "2023-10-05T23:52:46.000Z",
          "wordCount": null,
          "title": "[D] - Synthetic dataset - Searching for honest comparison between LLM (gpt4, bizon, jurassic-2, Claude...)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170wnbx/p_how_to_extract_and_count_artist_mentions_from/",
          "author": null,
          "description": "I have a long list of responses from a poll (in this case, we've asked our Facebook community we should have at our music festival). Our goal is to count the total mentions for each artist, but the data quality is low.\n Here is some sample data:\n Rena Guinn and the Gentlemen Blackwater Railroad Company Mo' Mojo Music !! We would love to be apart of this awesome event! Amazing!!!!! The Rollin' Rust came threw at the #falldownfest last weekend 🙂 much love:) keep it up boys 🙂 Luke Hess Langhorne Slim!!!!!, Sierra Hull, First Aid Kit, Jim Lauderdale (always) \n We feel the data quality is too poor for basic LDA approaches (lots of misspellings, odd phrasings) and we feel a LLM would be best at least extracting the names of artists using context.\n We have found that ChatGPT and Claude are decent at the extraction tasks on small samples but can't handle the full input, and are next to worthless on the counting task. We've tried very specific and differnet prompts, but haven't been able to get a good result.\n So how should I approach this problem? I'm not sure how to break this down in to prompts or substeps. I'm not sure how to do anything of this outside of a browser, and I'm a data science novice, but willing to learn some things.\n Here's an example of a prompt that's not returning correct counts (off by >50% in most cases)\n The following is raw text comments copied from a poll. Count the total number of mentions in the poll and create a table that contains columns Band (a unique list of bands) and a column containing the total number of mentions. The table should cover the top 100 bands by total mentions. Use judgement and context to conform band names in to unique values (Example: The Town Pants, Town Pants, townpants are all the same band). Count completely and accurately. Now here is the raw data: \n    submitted by    /u/strway2heaven77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170wnbx/p_how_to_extract_and_count_artist_mentions_from/",
          "publishedOn": "2023-10-05T23:16:47.000Z",
          "wordCount": 2874,
          "title": "[P] How to extract and count artist mentions from messy text data using LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170vs5a/p_avenues_for_publishing_ai_ethics_case_studies/",
          "author": null,
          "description": "I am a computer science graduate student. As part of my coursework, I am exploring the ethical issues of using Large Language Models for mental healthcare applications. I found four unique examples from the real world and outlined the ethical dilemma within them. I intend to analyze these dilemmas using various ethical frameworks in order to come up with solutions. While I am interested in getting a publication out of this work, I am unsure of the types of conferences/journals that accept case-study articles (specifically in AI ethics). Any advice from academicians over here would be greatly appreciated!\n    submitted by    /u/jwalapoet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170vs5a/p_avenues_for_publishing_ai_ethics_case_studies/",
          "publishedOn": "2023-10-05T22:40:58.000Z",
          "wordCount": 2637,
          "title": "[P] Avenues for publishing AI ethics case studies?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170uh8d/d_r_is_the_noise_predictor_in_ddpms_predicting/",
          "author": null,
          "description": "Hi fellow computer scientists,\n ​\n After reading the paper Improved Denoising Diffusion Probabilistic Models I got a little confused. Looking at section \"2.2. Training in Practice\" the authors say that:\n 1) \"The network could also predict the noise eps added to x_0, and this noise could be used to predict x0 via...\"\n ​\n 2) \"Ho et al. (2020) found that predicting eps worked best...\"\n ​\n So this left me wondering if the noise predictor is trying to compute (1) the epsilon that was added to x_0 through the close-form formula or (2) the noise added in the previous timestep to obtain x_t from x_{t-1} (i.e., eps_t or eps_{t-1}, idk...)?\n ​\n Thank you :)\n    submitted by    /u/Christs_Elite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170uh8d/d_r_is_the_noise_predictor_in_ddpms_predicting/",
          "publishedOn": "2023-10-05T21:49:36.000Z",
          "wordCount": 2659,
          "title": "[D] [R] Is the noise predictor in DDPMs predicting the noise added to x_0 or the noise added to x_{t-1}?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170tduq/p_mazegpt_transformer_based_maze_generator/",
          "author": null,
          "description": "Hello all,\n I recently did a summer research project implementing GPT-2 to generate mazes. \n The core concept of the model is to combine a bunch of popular maze generation algorithms into one. The goal was that the transformer will be able to identify key components using self-attention and piece together different algorithms. Most maze generation algorithms result in almost a finger print (like in chaos theory). The end goal was to mimic a higher degree of randomness / make the mazes appear less algorithmic.\n I'm dipping my toes into the realm of research and am looking for feedback. So far I've run the model for 5x5 mazes, it would be interesting to try training the model with varying dimensions. Feel free to join in and contribute to the project!\n https://github.com/noah-hein/mazeGPT\n 5x5 live generation\n https://i.redd.it/v6smbdd88gsb1.gif\n ​\n    submitted by    /u/noah-hein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170tduq/p_mazegpt_transformer_based_maze_generator/",
          "publishedOn": "2023-10-05T21:06:57.000Z",
          "wordCount": 2671,
          "title": "[P] MazeGPT - Transformer based maze generator",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170s6f5/d_unable_to_improve_binary_classification_problem/",
          "author": null,
          "description": "I am currently working on a binary classification problem where I aim to predict whether a customer will make a purchase in the next 30 days based on their transaction history. I have a dataset of 1,000 transactions with the following features:\n  \nTransactionAmount\n (float): The amount of the transaction.\n ProductCategory\n (categorical): Category of the product purchased (e.g., Groceries, Electronics, Books).\n DateOfPurchase\n (datetime): The date on which the transaction occurred.\n  \nI've done some preprocessing and feature engineering, including normalization, one-hot encoding of categorical variables, creating interaction terms, and adding features like days since the first purchase and whether the purchase was made during the holiday season.Dataset is balanced and cleaned.\n I started with a base Random Forest classifier with default parameters as a starting point, but the performance is not satisfactory (accuracy = 48.5%, ROC-AUC = 0.485). I tried other models as well but was unable to improve the accuracy by more than 57%.\n    submitted by    /u/SnooTigers4634  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170s6f5/d_unable_to_improve_binary_classification_problem/",
          "publishedOn": "2023-10-05T20:18:55.000Z",
          "wordCount": null,
          "title": "[D] Unable to improve binary classification problem accuracy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170s4iu/d_emnlp_2023_results/",
          "author": null,
          "description": "Making a post for EMNLP 2023 results to come out today.\n    submitted by    /u/East-Beginning9987  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170s4iu/d_emnlp_2023_results/",
          "publishedOn": "2023-10-05T20:16:53.000Z",
          "wordCount": 2546,
          "title": "[D] EMNLP 2023 results",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170rvz4/p_need_help_figuring_out_my_input_for_anomaly/",
          "author": null,
          "description": "I’ve been given a task to identify if a PCB is faulty or not based on its frequency response. I don’t have labeled data. The data I have are various gain values calculated over frequencies, so my data looks something similar to the table below.\n PCB | Frequency | G1 | G2\n PCB 1 | 1Hz | 0.1 | 1\n PCB 1 | 2Hz | 0.2 | 2\n PCB2 | 1Hz | 0.3 | 3\n PCB2 | 2Hz | 0.4| 4\n Each PCB has several G parameters measurements taken over the same set of frequencies. \n I need to use an auto encoder to identify outliers and I need help in deciding how my feature matrix should look like. \n For example, let us consider only one data point that is PCB 1, then would a matrix like this make sense?\n [[ 0.1 0.2 ] - 1st row is all G1 values\n [1 2]] - 2nd row is all G2 values\n Similarly the matrix for the other PCBs are also created. I have not included frequency in my feature set because these G parameters have been measured for the same set of frequencies for all PCBs. Is this correct ?\n Additionally, are there any resources someone can point me to related to finding anomalies in frequency response data ? I am struggling with using the keywords while googling.\n    submitted by    /u/Savage_Garbage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170rvz4/p_need_help_figuring_out_my_input_for_anomaly/",
          "publishedOn": "2023-10-05T20:07:20.000Z",
          "wordCount": null,
          "title": "[P] Need help figuring out my input for anomaly detection in frequency responses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170rtxo/r_towards_monosemanticity_decomposing_language/",
          "author": null,
          "description": "Paper. I am not affiliated with this paper or its authors.\n Twitter thread (Nitter alternative for those who want to see the entire thread without being logged into Twitter).\n Related work: Sparse Autoencoders Find Highly Interpretable Features in Language Models.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170rtxo/r_towards_monosemanticity_decomposing_language/",
          "publishedOn": "2023-10-05T20:05:08.000Z",
          "wordCount": 2595,
          "title": "[R] Towards Monosemanticity: Decomposing Language Models With Dictionary Learning. From Anthropic. \"We demonstrate a method for decomposing groups of neurons into interpretable features [...]\".",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170roi4/r_meta_researchers_present_method_for_decoding/",
          "author": null,
          "description": "Researchers at Meta trained a deep learning model on brain recordings and audio data from 169 people listening to speech. Their method achieves up to 73% accuracy at identifying a 3-second clip of speech from non-invasive EEG or MEG scans.\n This is a massive improvement over previous attempts at decoding speech from neural signals. It approaches the performance of studies using implanted electrodes.\n The key innovations:\n  \nA contrastive loss function that aligns latent speech and brain representations\n Leveraging pretrained speech models like wav2vec 2.0\n Training one model on multiple subjects with individual tuning\n  \nBeing able to decode speech intention from brainwaves could one day help restore communication for patients suffering from strokes, ALS, etc.\n There's still a ways to go before this becomes a medical reality. Performance needs to improve and be validated during speech production rather than just passive listening. And the accuracy isn't high enough for natural conversations.\n But this is a hugely promising step toward brain-computer interfaces. Really interesting work at the intersection of neuroscience and AI!\n TLDR: New model achieves up to 73% accuracy decoding speech directly from non-invasive brain scans. Could eventually help patients with neurological conditions communicate just by thinking.\n Full summary here. Paper is here\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170roi4/r_meta_researchers_present_method_for_decoding/",
          "publishedOn": "2023-10-05T19:59:25.000Z",
          "wordCount": 2744,
          "title": "[R] Meta researchers present method for decoding speech from brain waves",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170psdc/d_emnlp_2023_notification/",
          "author": null,
          "description": "Discussion thread for EMNLP 2023 notifications which will be released in a few hours along with GEM workshop. Best of luck to everyone.\n    submitted by    /u/EDEN1998  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170psdc/d_emnlp_2023_notification/",
          "publishedOn": "2023-10-05T18:43:58.000Z",
          "wordCount": 2558,
          "title": "[D] EMNLP 2023 Notification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170nclx/d_ordinal_or_nominal_variable/",
          "author": null,
          "description": "Hey all, I am working with stock market data and scratching my head if certain variables are ordinal and can be left as is or if it is nominal and should be one-hot encoded. \n One of the variables in question consists of the direction of the market over a certain time. It has three categories: up, down, sideways. hope was to code them as 1, -1 and 0 respectively and treat as ordinal. There appears to be some order/relationship between them but not sure if it is enough.\n Is this the correct approach or should it be one-hot encoded?\n    submitted by    /u/Fishpo0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170nclx/d_ordinal_or_nominal_variable/",
          "publishedOn": "2023-10-05T17:07:18.000Z",
          "wordCount": 2635,
          "title": "[D] ordinal or nominal variable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170n9ex/d_deep_learning_online_course_using_pytorch/",
          "author": null,
          "description": "I've been out of the deep learning space for a while now and I'd like to take an online course, or set of courses, to get myself back up to speed on the latest techniques, architectures, and how to use them. I think the DeepLearning.ai specialization through Coursera is a good match, but I see that it uses Tensorflow. Is there any course like this that would use PyTorch? Or would the transition not be too hard once the fundamentals are in place? Thanks!\n    submitted by    /u/ComicFoil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170n9ex/d_deep_learning_online_course_using_pytorch/",
          "publishedOn": "2023-10-05T17:03:47.000Z",
          "wordCount": null,
          "title": "[D] Deep Learning online course using PyTorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170mtzx/fine_tuning_or_rag_for_coding_d/",
          "author": null,
          "description": "Need some help what is the best way to start. Pls Advice !\n I have a specific code in my repos (lets say .net + JS). The goal is to have prompt based code adjustments to existing repos (like very focused copilot) . Either using single agent or using something like AutoGen. So let say I have thousands of files with code and some descriptions about code functionality (spec) . I want either to generate code based on next spec and I want newly generated code to be similar in style to what is in my repos. So now questions: Should I vectorize my code (What is best way to do that ?) or try to fine tune some model ? Give me your ideas / experience in code generation based on previous code.\n    submitted by    /u/mcwin1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170mtzx/fine_tuning_or_rag_for_coding_d/",
          "publishedOn": "2023-10-05T16:47:22.000Z",
          "wordCount": 2672,
          "title": "Fine Tuning or RAG for Coding [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170mh6t/project_i_built_an_opensource_scraping_api_that/",
          "author": null,
          "description": "I decided to open-source my own web scraping API that I'm using to get information from different websites without using any selectors or XPath. Just provide the URL and a desired JSON schema, and it will return extracted data. Hope this can be helpful for someone. Cheers!\n https://github.com/semanser/JsonGenius \n https://preview.redd.it/icq1i8slvesb1.png?width=4096&format=png&auto=webp&s=ac86ccdb3da5ef1ffa86e3473619162f6b652ac6\n    submitted by    /u/semanser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170mh6t/project_i_built_an_opensource_scraping_api_that/",
          "publishedOn": "2023-10-05T16:33:05.000Z",
          "wordCount": 2587,
          "title": "[Project] I built an open-source scraping API that returns structured JSON data using GPT.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170m0o7/r_is_selfcorrection_a_viable_method_to_improve/",
          "author": null,
          "description": "Can LLMs actually improve their own reasoning by self-correcting mistakes? A new paper from DeepMind and the University of Illinois looks to answer this quantitatively.\n The results show that unaided, LLMs struggle at self-correction for reasoning tasks. The core issue is LLMs have trouble reliably evaluating the correctness of their own responses. They rarely identify flaws in initial reasoning. Sometimes LLMs even alter initially correct responses to become incorrect after self-correction! (I've personally seen this when interacting with ChatGPT many times and you probably have too).\n More complex techniques like critiquing between LLM instances don't help much either. External feedback or guidance looks necessary to improve reasoning (Well, some interesting parallels to this paper here about implicit improvement from preference data vs traditional RLHF).\n Self-correction does show promise for things like making responses more polite or safe though. Criteria there are more clear-cut.\n The authors argue we need to balance enthusiasm with realistic expectations on self-correction. It has a lot of limits for improving reasoning (at least with current models). But they suggest promising directions like incorporating high-quality external feedback from humans, training data, and tools. That could be key to unlocking self-correction's potential down the road.\n TLDR: Basically title... LLMs can't reliably self-correct reasoning yet. Maybe hybrid techniques combining self-correction with external guidance could work but we need more research.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170m0o7/r_is_selfcorrection_a_viable_method_to_improve/",
          "publishedOn": "2023-10-05T16:15:11.000Z",
          "wordCount": 2769,
          "title": "[R] Is self-correction a viable method to improve LLM reasoning? Probably not.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170jkna/p_niddkcr_data_centric_challenge_enhancing_niddk/",
          "author": null,
          "description": "Calling all AI researchers! \n Using data aggregation, harmonization, fusion, and other data enhancement methods, you can help the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) enhance the utility of NIDDK datasets for AI applications. The goal of the NIDDK Data Centric Challenge will be to generate an “AI-ready” dataset that can be used for future data challenges, using data on Type 1 Diabetes available through the NIDDK Central Repository. Register today! https://www.challenge.gov/?challenge=niddk-central-repository-data-centric-challenge\n    submitted by    /u/DataCentricChallenge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170jkna/p_niddkcr_data_centric_challenge_enhancing_niddk/",
          "publishedOn": "2023-10-05T14:34:53.000Z",
          "wordCount": null,
          "title": "[P] NIDDK-CR Data Centric Challenge: Enhancing NIDDK datasets for future artificial intelligence applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170jah3/d_offtopic_is_meta_llama_2_license_agreement_safe/",
          "author": null,
          "description": "in the Meta Llama 2 license agreement (that can be found here), there is a section of \"Prohibited Uses\" that clearly states several use cases that the signer must accept upon himself, but several of them state the word \"facilitate\", as far as i can understand, if we use Llama 2 as part of a commercial product, and some end-user will use the product in malicious way (say cause the chat-bot to write the recipe of mustard gas) then this could be considered that the creator of the product is facilitating the end-user,\n ​\n so my questions are:\n  \ndo you think this is a fair interpretation of the agreement ?\n does that mean the creator is liable to whatever the model spit out ?\n is there a way to censor the model (short of retraining a new model, or fine-tune on a large scale) ?\n is there an open source model that already gone through the process, and more safe for commercial use ?\n  \n​\n https://preview.redd.it/3zo3tm4e8esb1.png?width=1197&format=png&auto=webp&s=8aa522183f82ba8f85edb69cbaabd93262efd516\n ​\n as per @gentlecucumber advice, i also posted it on r/legaladvice:\n https://www.reddit.com/r/legaladvice/comments/170ll2t/d_is_meta_llama_2_license_agreement_safe_to_sign/?utm_source=share&utm_medium=web2x&context=3\n    submitted by    /u/Particular_Flower_12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170jah3/d_offtopic_is_meta_llama_2_license_agreement_safe/",
          "publishedOn": "2023-10-05T14:22:58.000Z",
          "wordCount": null,
          "title": "[D] off-topic, is Meta Llama 2 license agreement safe to sign for commercial use ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170j47f/d_tesseractocr_vs_paddleocr_vs_easyocr_for/",
          "author": null,
          "description": "Which would be the best OCR toolkit to invest the effort to learning and building a pipeline for an OCR system that will be used to extract Japanese text?\n I tried Tesseract initially and although I got some good results, I found it hard to do finetuning due to messy and outdated documentation.\n I haven't had the time to look at the other two OCR tools yet but if anyone had any experience, please do share them especially with how easy or difficult is the finetuning process as well as deploying the tuned models. \n    submitted by    /u/Spitfire_ex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170j47f/d_tesseractocr_vs_paddleocr_vs_easyocr_for/",
          "publishedOn": "2023-10-05T14:15:30.000Z",
          "wordCount": 2635,
          "title": "[D] TesseractOCR vs PaddleOCR vs EasyOCR for Japanese text extraction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170iuw5/d_adapting_opensource_gpt_models/",
          "author": null,
          "description": "Hi,\n our company plans for some budget in 2024 to invest into hardware to do the following\n - running local LLMs for our coworkers to interfere with an locally running offline GPT alike ChatGPT. Use cases: \n  \ngenerating templates for email, letters etc \n Translation (EN/GER/FR/SPA)\n Querying internal knowledge bases and/or FAQs/HOWTOs\n  \nI did some research but it is still hard for me to estimate what are the HW / AI skill requirements to implement something not a quarter as good as ChatGPT. Ive played with Nomics gpt4all which comes close to a baseline.\n We cant use cloud services due to our data privacy policy, so I checked on what would be a good starting point to invest into hardware.\n I came up with a gamer PC (octacore Intel i9/AMD Ryzen 7) utilizing NVidia RTX 4090 (24Gb) / Radeon RX 7900 / 2TB SSD / 64Gb RAM for approximately 3600 Eur. I am pretty sure that would be sufficient to host a decent LLM serving simultaneous client requests. \n But is there also a way to adapt / process our companies data? Most sources state that proper LLMs were trained using hundreds of NVidia A100 and thousands of CPUs. On the other hand we would be fine with just fine-tuning a pretrained model.\n Could you please point me to some sources to learn more about possibilities and requirements as to be able to make well-informed investment decisions? Also, we probably lack the required skills, and would be interested to learn if there are companies and/or projects assisting with this kind of task?\n thanks\n    submitted by    /u/EatTFM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170iuw5/d_adapting_opensource_gpt_models/",
          "publishedOn": "2023-10-05T14:04:27.000Z",
          "wordCount": 2798,
          "title": "[D] Adapting OpenSource GPT Models - requirements/possibilities?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170ib3c/d_are_loras_able_to_improve_results_on_reasoning/",
          "author": null,
          "description": "Is there any good research on which benchmarks LoRAs are most effective at impacting, or are they relegated mostly to changing the style of an LLM's response? \n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170ib3c/d_are_loras_able_to_improve_results_on_reasoning/",
          "publishedOn": "2023-10-05T13:40:45.000Z",
          "wordCount": 2575,
          "title": "[D] - Are LoRAs able to improve results on reasoning benchmarks or is full-parameter fine tuning required?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170hvjs/d_how_to_test_if_regression_model_is/",
          "author": null,
          "description": "I have a regression model, predicting a popularity of a text. I have its performance metrics on test set, e.g. RMSE and MAE. This gives me an uncertainty estimate about its predictions.\n Now I want to transform the text in some way, e.g. give it to human experts or another model to \"upgrade\" (in terms of getting better popularity). So I have the original and transformed text.\n Now I have 3 popularity scores:\n  \ntrue popularity for original text\n predicted popularity for original text\n predicted popularity for transformed text\n  \nObviously, if model MAE is for example around 5, and predicted popularity for transformed text is higher than for the original by 1.5, this can be totally random, due to errors in the model prediction.\n How can I measure if text transformation is beneficial, i.e. statistically significantly better than the original text, incorporating information about model quality? Requiring that the improvement has to be higher than model error would be incredibly strict.\n    submitted by    /u/qalis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170hvjs/d_how_to_test_if_regression_model_is/",
          "publishedOn": "2023-10-05T13:21:10.000Z",
          "wordCount": null,
          "title": "[D] How to test if regression model is statistically significantly better, including its test error?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170gngt/d_david_donoho_data_science_at_the_singularity/",
          "author": null,
          "description": "submitted by    /u/wojcech  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170gngt/d_david_donoho_data_science_at_the_singularity/",
          "publishedOn": "2023-10-05T12:25:43.000Z",
          "wordCount": 2560,
          "title": "[D] David Donoho: Data Science at the Singularity (pushback on AGI singularity, advocates for Open Science and reproducibility)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1707x8f/r_tensor_programs_vi_feature_learning_in/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.02244\n Abstract: \n  \nBy classifying infinite-width neural networks and identifying the optimal limit, Tensor Programs IV and V demonstrated a universal way, called μP, for widthwise hyperparameter transfer, i.e., predicting optimal hyperparameters of wide neural networks from narrow ones. Here we investigate the analogous classification for depthwise parametrizations of deep residual networks (resnets). We classify depthwise parametrizations of block multiplier and learning rate by their infinite-width-then-depth limits. In resnets where each block has only one layer, we identify a unique optimal parametrization, called Depth-μP that extends μP and show empirically it admits depthwise hyperparameter transfer. We identify feature diversity as a crucial factor in deep networks, and Depth-μP can be characterized as maximizing both feature learning and feature diversity. Exploiting this, we find that absolute value, among all homogeneous nonlinearities, maximizes feature diversity and indeed empirically leads to significantly better performance. However, if each block is deeper (such as modern transformers), then we find fundamental limitations in all possible infinite-depth limits of such parametrizations, which we illustrate both theoretically and empirically on simple networks as well as Megatron transformer trained on Common Crawl.\n  \nInteresting, great to see this line of work continued, muP was great, now Depth-muP\n    submitted by    /u/_puhsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1707x8f/r_tensor_programs_vi_feature_learning_in/",
          "publishedOn": "2023-10-05T03:48:52.000Z",
          "wordCount": 2738,
          "title": "[R] Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zzlz3/p_opensource_project_to_run_locally_llms_in/",
          "author": null,
          "description": "Excited to introduce BlindChat (https://github.com/mithril-security/blind_chat), an open-source, privacy-centric alternative to ChatGPT for in-browser Conversational AI!\n We provide full local inference in browser, by using libraries from Hugging Face like transformers.js or candle for WASM inference.\n We have supported several small models, the latest one being Phi-1.5, the 1.3B model that beat Llama 2 7b!\n As Microsoft’s researchers mentioned in their paper, the model often produces incorrect code and statements. They are just suggestions, and this model is not trained for instruction tuning, so it might be harder to use than regular chat. More info on their model card (https://huggingface.co/microsoft/phi-1_5).\n We would love to have your feedback on our project, as we are aiming to build a privacy-first and open-source alternative to ChatGPT!\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zzlz3/p_opensource_project_to_run_locally_llms_in/",
          "publishedOn": "2023-10-04T21:43:41.000Z",
          "wordCount": 2664,
          "title": "[P] Open-source project to run locally LLMs in browser, such as Phi-1.5 for fully private inference",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zycqy/d_what_is_the_relation_between_learning_rate_and/",
          "author": null,
          "description": "How can we tackle vanishing gradient problem by changing the learning rate? Is it possible?\n    submitted by    /u/InternationalBack472  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zycqy/d_what_is_the_relation_between_learning_rate_and/",
          "publishedOn": "2023-10-04T20:54:42.000Z",
          "wordCount": 2553,
          "title": "[D] What is the relation between learning rate and vanishing gradient problem?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zxl43/p_torchsummary_not_working_with_your_layers_again/",
          "author": null,
          "description": "pip install output-shape \n It is a minimalistic and simple alternative to torchsummary with a simple print of the output shape of a layer, or custom layer. For torch.nn.MultiheadAttention, it handles both the output shape and the attn matrix separately. \n https://github.com/avocardio/output-shape\n Currently only works with PyTorch models, soon with Tensorflow / Keras as well. Jax is also on the list for later!\n    submitted by    /u/capital-man  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zxl43/p_torchsummary_not_working_with_your_layers_again/",
          "publishedOn": "2023-10-04T20:24:04.000Z",
          "wordCount": 2599,
          "title": "[P] Torchsummary not working with your layers again? Try this lightweight alternative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zw3ps/d_thoughts_on_current_vector_db_landscape/",
          "author": null,
          "description": "Hello,\n What are your thoughts on current Vector DB offerings? For instance:\n  \nDo you think the pricing for them is reasonable/viable?\n Do you think there’s a sufficient level of developer/user experience? What about for those who aren’t necessarily specialized in data?\n If you like a managed service, why do you prefer it over the open source alternatives?\n  \n   submitted by    /u/LucasSaysHello  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zw3ps/d_thoughts_on_current_vector_db_landscape/",
          "publishedOn": "2023-10-04T19:23:39.000Z",
          "wordCount": 2590,
          "title": "[D] Thoughts on current Vector DB landscape?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zvohd/r_neurbf_a_neural_fields_representation_with/",
          "author": null,
          "description": "Project Page\n Paper\n Code\n  \nWe present a novel type of neural fields that uses general radial bases for signal representation. State-of-the-art neural fields typically rely on grid-based representations for storing local neural features and N-dimensional linear kernels for interpolating features at continuous query points. The spatial positions of their neural features are fixed on grid nodes and cannot well adapt to target signals. Our method instead builds upon general radial bases with flexible kernel position and shape, which have higher spatial adaptivity and can more closely fit target signals. To further improve the channel-wise capacity of radial basis functions, we propose to compose them with multi-frequency sinusoid functions. This technique extends a radial basis to multiple Fourier radial bases of different frequency bands without requiring extra parameters, facilitating the representation of details. Moreover, by marrying adaptive radial bases with grid-based ones, our hybrid combination inherits both adaptivity and interpolation smoothness. We carefully designed weighting schemes to let radial bases adapt to different types of signals effectively. Our experiments on 2D image and 3D signed distance field representation demonstrate the higher accuracy and compactness of our method than prior arts. When applied to neural radiance field reconstruction, our method achieves state-of-the-art rendering quality, with small model size and comparable training speed.\n  \n   submitted by    /u/Sirisian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zvohd/r_neurbf_a_neural_fields_representation_with/",
          "publishedOn": "2023-10-04T19:06:23.000Z",
          "wordCount": 2745,
          "title": "[R] NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zvo5f/d/",
          "author": null,
          "description": "Hi guys !\n I am going to purchase a laptop for programming and AI tasks. I will be working on a simulation software project related to the trajectory of an object in 2d and 3d space.\n Which laptop will be the most suitable for these tasks and it should have high battery backup because the place where I work does not have enough power sockets.\n The first laptop which came into my mind was Macbook pro with M2 pro chip and Lenovo Thinkpad X1 Carbon gen 10.\n Suggest me the best.\n    submitted by    /u/smitherium  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zvo5f/d/",
          "publishedOn": "2023-10-04T19:06:03.000Z",
          "wordCount": 2618,
          "title": "[D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zua0j/discussion_feature_selection_algorithms/",
          "author": null,
          "description": "I have only 200 samples but about 30 features. What are some effective commonly used feature selection algorithms? I want to identify the features that play the most significant role in generating outcomes.\n    submitted by    /u/Shina-pig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zua0j/discussion_feature_selection_algorithms/",
          "publishedOn": "2023-10-04T18:09:51.000Z",
          "wordCount": 2563,
          "title": "[Discussion] Feature Selection Algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zt2df/r_will_a_small_error_be_determining_in_the_final/",
          "author": null,
          "description": "About a week ago, I submitted my first paper into one of the most prestigious Machine Learning conferences out there. This was a last minute submission, and my supervisor and I were working on it simultaneously until the very last moment.\n Sadly, my supervisor committed an error when writing the mathematical definition of a certain set, slightly changing its meaning. This change, even though small, changes the definition in such a way that the subsequent theorem and its proof isn't formally correct anymore, as it assumes the original definition of the set, not the new one.\n How much will this affect the decision of accepting or rejecting my paper?\n The whole method, results and consequences are still the same, no matter this definition. It's more a problem of a \"formal\" nature (here \"formal\" as a word in the mathematical sense). \n Is there a other way that I can inform about this error without changing the content maybe? I know that at some point, they give a chance to edit the original paper, but I don't know if this is after the decision to accept/reject.\n    submitted by    /u/howtorewriteaname  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zt2df/r_will_a_small_error_be_determining_in_the_final/",
          "publishedOn": "2023-10-04T17:21:13.000Z",
          "wordCount": 2724,
          "title": "[R] Will a small error be determining in the final decision for my paper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zsqrj/how_can_i_apply_object_detection_and_image/",
          "author": null,
          "description": "So, a few months ago, I started developing this deep learning model, which was made purely to differentiate whether the input image is driftwood floating in water or a crocodile. To my knowledge, I leveraged the resnet50 pre-trained SoTA model to train my deep learning model, and for that, I downloaded almost 5k images of driftwood and crocodiles for my model training. Once the training was complete, I took the next step and deployed my model on the Hugging Face Spaces app, allowing my friends to put it to the test. But here's where I ran into a significant challenge: users could even upload their own selfies, and my model would attempt to predict whether they were a crocodile or a piece of driftwood!\n So how can I leverage object detection or the image segmentation pipeline so that when the user inputs their image, it tries to detect the object from the photo and then detect whether the detected object from the given image contains a crocodile or not? If the crocodile or driftwood is not found then it should return \"No object found\" or like that.\n    submitted by    /u/meWhoObserves  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zsqrj/how_can_i_apply_object_detection_and_image/",
          "publishedOn": "2023-10-04T17:08:17.000Z",
          "wordCount": 2731,
          "title": "How can I apply object detection and image segmentation functionality to my current custom-trained Image Classification model? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zrme9/r_large_language_models_represents_space_and_time/",
          "author": null,
          "description": "Paper - https://arxiv.org/abs/2310.02207\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zrme9/r_large_language_models_represents_space_and_time/",
          "publishedOn": "2023-10-04T16:23:37.000Z",
          "wordCount": 2537,
          "title": "[R] Large Language Models Represents Space and Time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zqmet/r_help_shape_the_future_of_machine_learning_take/",
          "author": null,
          "description": "Hello Redditors in r/MachineLearning\n We are the team behind ML Workbench, an upcoming integrated platform designed to streamline your entire machine learning lifecycle. From data preprocessing and model training to validation and deployment, we aim to make the process as seamless as possible.\n But here's the thing: we need your insights to build something that truly resonates with the community and solves real-world problems.\n 📝 Click Here to Take the Survey\n Why Should You Care?\n  \nUnified Experience: Imagine managing all your ML tasks in one integrated environment.\n High-Performance Computing: We're leveraging powerful A100 GPUs to accelerate your work.\n User-Centric Design: Whether you're a beginner or a pro, the platform is designed to cater to all skill levels.\n Collaboration: Built-in features to make team collaboration effortless.\n  \nWhat's in the Survey?\n The survey contains questions about your current challenges, the tools you use, and what you'd love to see in an ML platform. It should only take about 5-10 minutes to complete.\n Thank You Gift\n As a small token of our appreciation, we're offering exclusive early access to the platform for selected participants. Don't miss this chance to be among the first to experience what we're building!\n 📝 Click Here to Take the Survey\n Your feedback is crucial for us to create a tool that we hope will make a significant positive impact in the machine learning community. Thank you for taking the time to read this post and participate in our survey.\n Cheers, The ML Workbench Team\n    submitted by    /u/nonononottodayorever  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zqmet/r_help_shape_the_future_of_machine_learning_take/",
          "publishedOn": "2023-10-04T15:44:36.000Z",
          "wordCount": 2790,
          "title": "[R] Help Shape the Future of Machine Learning: Take Our Short Survey and Let's Create Something Amazing Together!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zq9sf/p_video_event_detection/",
          "author": null,
          "description": "Hi, I'm looking to create a model that given a sequence of frames from a video, returns a probability distribution over a set of events that may have occurred in those frames (probably 5 - 10 events). The training data will consist of video and hand labelled frame index/event pairs. I'm not too concerned about handling simultaneous events. \n It would be super helpful for some suggestions on a model architecture that would yield the best results and/or good papers/examples that achieve something similar.\n Thanks!\n    submitted by    /u/Dredgefort  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zq9sf/p_video_event_detection/",
          "publishedOn": "2023-10-04T15:30:50.000Z",
          "wordCount": 2614,
          "title": "[P] Video Event Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zouad/p_retrieval_augmented_generation_with_opensearch/",
          "author": null,
          "description": "I created a video tutorial that tries to demonstrate that semantic search (using embeddings) is not always necessary for RAG (retrieval augmented generation). It was inspired by the following Cohere blog post: https://txt.cohere.com/rerank/\n I code up a minimal RAG pipeline: OpenSearch -> Rerank -> Chat completion (without using Langchain or similar libraries) and then see how it performs on various queries.\n Hope some of you find it helpful. Feel free to share any feedback@\n Video link: https://youtu.be/OsE7YcDcPz0\n    submitted by    /u/mildlyoverfitted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zouad/p_retrieval_augmented_generation_with_opensearch/",
          "publishedOn": "2023-10-04T14:34:31.000Z",
          "wordCount": 2613,
          "title": "[P] Retrieval augmented generation with OpenSearch and reranking [Video tutorial]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zoh3s/r_hacking_an_nlp_benchmark_how_to_score_100/",
          "author": null,
          "description": "AMR parsing is a fun task where researchers map texts onto little graphs that explicate their meaning, so called Abstract Meaning Representations (AMRs). While arguably not the top NLP benchmark regarding popularity, research has been active for the last 10 years, including at major NLP conferences such as ACL/NAACL/EACL/EMNLP etc.\n Funnily, I recently found some vulnerabilities in the evaluation protocol, and if we exploit these vulnerabilities, we can get the highest score on the benchmark. \n To get an overview over the issue (without understanding AMR), imagine a cooking contest that takes place regularly, say, once a year. In all events, we have the same judge, participants are amateurs, meals are scored on 0 to 100, with 100 meaning “it can’t possibly get better”. Over the years, the …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zoh3s/r_hacking_an_nlp_benchmark_how_to_score_100/",
          "publishedOn": "2023-10-04T14:19:39.000Z",
          "wordCount": 2984,
          "title": "[R] Hacking an NLP benchmark: How to score 100 points on AMR parsing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zn7vv/d_looking_for_an_article_related_to_machine/",
          "author": null,
          "description": "Hi all,\n I'm curious if anyone has a stand-out article they believe would prompt a lively discussion in a journal club I have coming up. Something that may have people take sides, or maybe a recent breakthrough in the ML space as it relates to clinical/health care.\n ​\n Thanks!\n    submitted by    /u/veilofosiris  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zn7vv/d_looking_for_an_article_related_to_machine/",
          "publishedOn": "2023-10-04T13:26:24.000Z",
          "wordCount": 2592,
          "title": "[D] Looking for an article related to machine learning in medicine to be presented at a journal club",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zmlf5/r_think_before_you_speak_training_language_models/",
          "author": null,
          "description": "Paper - https://arxiv.org/abs/2310.02226\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zmlf5/r_think_before_you_speak_training_language_models/",
          "publishedOn": "2023-10-04T12:59:23.000Z",
          "wordCount": 2540,
          "title": "[R] Think before you speak: Training Language Models With Pause Tokens",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zjfon/p_good_models_to_use_for_multimodal_object/",
          "author": null,
          "description": "So basically I have a dataset with images of vehicles in top down view in both RGB and IR, what are some models I can use for both unimodal and multimodal object detection to compare their performance. Links to GitHub repos would be helpful. Thanks\n    submitted by    /u/Xyber5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zjfon/p_good_models_to_use_for_multimodal_object/",
          "publishedOn": "2023-10-04T10:21:08.000Z",
          "wordCount": 2595,
          "title": "[P] Good models to use for multimodal object detection when both the modalities are image based or some object detection models which support ensembling out of the box like Yolov5?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zi37s/p_using_pretrained_models_as_features/",
          "author": null,
          "description": "Hey everyone!\n Currently, I am working on a project around music emotion classifcation/regression model. Basically I am trying to predict a score to each emotion on a given song.\n The problem is that my dataset has quite imbalanced scores (y). Most scores are centered around a certain score range. Therefore, having difficulties predicting scores that are further away of the mean values.\n I had this idea to bring in pre-trained (on other datasets and problems) audio classification models into this as there are a bunch of good performing pre-trained classification models out there already. The prediction of these pre-trained models should be used as features (e.g. prediction of genre, instrument etc) beside the original spectorgram in my model.\n I know this won't solve the problem of imbalances in the scores but I thought maybe this could improve the performance as the model would have more features to work with.\n Does this make sense?\n I appreciate any input.\n    submitted by    /u/Kniggi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zi37s/p_using_pretrained_models_as_features/",
          "publishedOn": "2023-10-04T08:56:08.000Z",
          "wordCount": 2683,
          "title": "[P] Using pre-trained models as features?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zhkq2/d_lomo_underrated/",
          "author": null,
          "description": "Does anyone have an idea why the LOMO optimizer (low memory optimizer) which was released a few months ago is not widely available and everyone still uses either Adam or SGD? \n While the paper looks really promising\n    submitted by    /u/RedMoula  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zhkq2/d_lomo_underrated/",
          "publishedOn": "2023-10-04T08:22:28.000Z",
          "wordCount": 2566,
          "title": "[D] LOMO underrated",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zbwcf/p_camera_based_monitoring_of_infants_breathing/",
          "author": null,
          "description": "Hi! I recently have seen systems that monitor breathing rate of an infant through camera. I have read several articles on that topic, where people used things like 3D camera, RGB or Interferometric Radar Sensor. Do you guys have any idea on how to accurately measure this?\n    submitted by    /u/kaina_m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zbwcf/p_camera_based_monitoring_of_infants_breathing/",
          "publishedOn": "2023-10-04T02:58:47.000Z",
          "wordCount": 2580,
          "title": "[P] Camera based monitoring of infant's breathing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z9dko/r_towards_selfassembling_artificial_neural/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z9dko/r_towards_selfassembling_artificial_neural/",
          "publishedOn": "2023-10-04T01:04:04.000Z",
          "wordCount": 2547,
          "title": "[R] Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z88hp/d_how_do_you_track_projects_in_a_scaling_ml_team/",
          "author": null,
          "description": "I am part of a Machine Learning team that has experienced significant growth recently. When we were a small team, tracking projects was straightforward. However, as the team has expanded, it's become increasingly challenging to keep track of everything. We are part of a larger corporation, so we have access to tools for creating epics and boards. However, these corporate tools are too generic and don't provide the level of detail I need for internal management. Specifically, I'm looking for a way to track model versions, dataset versions, and the overall status of our projects. I'd also like to be able to assign team members to projects.\n Currently, we use a MIRO board, but it's disorganized and difficult to read and update. I'd love to hear what tools or strategies you've used for similar situations, especially since our team is expected to grow even more, making tracking increasingly complex.\n    submitted by    /u/Spiritual_Narwhal649  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z88hp/d_how_do_you_track_projects_in_a_scaling_ml_team/",
          "publishedOn": "2023-10-04T00:14:11.000Z",
          "wordCount": 2684,
          "title": "[D] How Do You Track Projects in a Scaling ML Team?\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z6yek/d_what_are_some_effective_dimensionality/",
          "author": null,
          "description": "I am considering comparing mutual information scores, but I also don't think I understand MI well enough. \n For example, I(X;Y) = H(X) + H(Y) - H(X,Y). To me, visualizing H(X) and H(Y) as venn diagrams and H(X,Y) as the information from both X, Y (like an overlapping venn diagram) makes me think that when X, Y are disjoint, then MI is 0 and when X, Y overlap completely, then the MI score will be high. So, I'm thinking that a high MI value is \"bad\" since this means X, Y would be redundant. I am not sure if my understanding here is correct. \n Another method I have tried is to binarize the data for each feature (represented as rows in my dataset) using \"present\" (1) and \"absent\" (0). The main issue I have run into doing this is that I am trying to then create a distribution to compare the fea…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z6yek/d_what_are_some_effective_dimensionality/",
          "publishedOn": "2023-10-03T23:19:44.000Z",
          "wordCount": 2943,
          "title": "[D] What are some effective dimensionality reduction (unsupervised feature selection) techniques for a high dimensional, sparse dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z6poz/d_best_interface_to_use_llms_for_code_chat_or/",
          "author": null,
          "description": "Hi everyone,\n I am quite interested in understanding what are the feedback from the community in terms of interface to leverage LLMs for code productivity.\n Because LLMs tend to do mistake I have mostly used Chat-like interfaces, like ChatGPT, as they allow to interact with the model and converge to a conclusion. \n I haven't used Copilot for a while but my feeling was that it could do some boilerplate correctly but then it quickly started suggesting code that would be misleading and could actually hurt productivity.\n It might have changed since then but that was my feeling back then.\n What is your favorite option and why?\n View Poll\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z6poz/d_best_interface_to_use_llms_for_code_chat_or/",
          "publishedOn": "2023-10-03T23:09:51.000Z",
          "wordCount": 2654,
          "title": "[D] Best interface to use LLMs for code: Chat or completion?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z6mqr/d_ml_input_data_has_to_be_derived_from_a_larger/",
          "author": null,
          "description": "Hello everyone. I am curious to know if anyone has encountered a ML problem like this and if so, I seek your advice. Usually in ML classification such as the IRIS dataset, each row represents a sample and each column a parameter, right ! My problem is that my ML classification parameters have to be derived from a range of values (parent data). I have taken mean of the parent values to generate the parameters for the ML input data. This results in lower classification accuracies using Random forest and XGBoost.\n Has anyone encountered a similar situation like this where the data has to be generated from a range of other datasets? Is there any other way to do this? I did not find any papers or articles from the web so just asking.\n I can generate additional parameters from other statistics such as median, standard deviation etc. which can improve the classification accuracy but can make interpretation of the results a little weird, domain wise. I wish to avoid this if possible.\n    submitted by    /u/notmyfault7676  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z6mqr/d_ml_input_data_has_to_be_derived_from_a_larger/",
          "publishedOn": "2023-10-03T23:06:36.000Z",
          "wordCount": 2709,
          "title": "[D] ML input data has to be derived from a larger dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z0zlz/d_book_review_for_metas_ml_design_interview/",
          "author": null,
          "description": "I'm preparing for the ML system design interview for Meta, and I searched for various resources. This book (ML System Design Interview (by Ali Aminian & Alex Xu)) seems like a solid structured resource that covers solutions to case studies in detail. Has anyone used it to prepare for Meta's ML System Design interview? Thoughts?\n Khang's book doesn't seem to have great reviews.\n Chip Huyen's book (Designing Machine Learning Systems: An Iterative Process for Production-Ready Applications) doesn't seem very focused on interview prep??\n Also, happy to hear about other cool resources to prepare. Thanks very much!\n    submitted by    /u/irEFrienfk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z0zlz/d_book_review_for_metas_ml_design_interview/",
          "publishedOn": "2023-10-03T19:27:04.000Z",
          "wordCount": 2639,
          "title": "[D] Book review for Meta's ML Design interview? Machine Learning System Design Interview (by Ali Aminian and Alex Xu)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z0ev6/r_open_xembodiment_robotic_learning_datasets_and/",
          "author": null,
          "description": "Blog: https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types \n https://robotics-transformer-x.github.io/ here you can also find the Datasets and Code!\n Paper: https://robotics-transformer-x.github.io/paper.pdf\n Abstract:\n  \nLarge, high-capacity models trained on diverse datasets have shown remarkable successes on efficiently tackling downstream applications. In domains from NLP to Computer Vision, this has led to a consolidation of pretrained models, with general pretrained backbones serving as a starting point for many applications. Can such a consolidation happen in robotics? Conventionally, robotic learning methods train a separate model for every application, every robot, and even every environment. Can we instead train “generalist” X-robot policy that can be adapted efficiently to new robots, tasks, and environments? In this paper, we provide datasets in standardized data formats and models to make it possible to explore this possibility in the context of robotic manipulation, alongside experimental results that provide an example of effective X-robot policies. We assemble a dataset from 22 different robots collected through a collaboration between 21 institutions, demonstrating 527 skills (160266 tasks). We show that a high-capacity model trained on this data, which we call RT-X, exhibits positive transfer and improves the capabilities of multiple robots by leveraging experience from other platforms. \n  \nhttps://preview.redd.it/oxzutrhtb1sb1.jpg?width=1693&format=pjpg&auto=webp&s=37b8b1dbf5f489dc2c8eaca4d15cb9c32ebc2660\n https://preview.redd.it/ldsiwshtb1sb1.jpg?width=1494&format=pjpg&auto=webp&s=fdbf0f91c705acf11bff854f6d6af82dddd47021\n https://preview.redd.it/ikk18jitb1sb1.jpg?width=1693&format=pjpg&auto=webp&s=e50b443dc4b0266a0480d54c4f92a0b708485797\n https://preview.redd.it/t5wmciitb1sb1.jpg?width=1361&format=pjpg&auto=webp&s=2971fd645acb6dcbed2ca3522e311d0772c45964\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z0ev6/r_open_xembodiment_robotic_learning_datasets_and/",
          "publishedOn": "2023-10-03T19:03:49.000Z",
          "wordCount": 2742,
          "title": "[R] Open X-Embodiment: Robotic Learning Datasets and RT-X Models - DeepMind 2023 - RT-X exhibits positive transfer and improves the capabilities of multiple robots by leveraging experience from other platforms!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z08iy/d_biggest_problems_with_ml_in_industry/",
          "author": null,
          "description": "For all my corporate ML engineers I have a question, what are the most annoying / biggest problems you face when developing/deploying ML in industry? \n This can be anywhere from data, to tuning, to even MLOPS. \n    submitted by    /u/hai_cben  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z08iy/d_biggest_problems_with_ml_in_industry/",
          "publishedOn": "2023-10-03T18:57:03.000Z",
          "wordCount": 2567,
          "title": "[D] Biggest problems with ML in industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z01w5/d_difficulty_with_paper_implementations_on_google/",
          "author": null,
          "description": "I am not from CS background, my knowledge is from online courses and books. All of which used some variation of Jupyter notebook. My knowledge of code can be lacking sometimes, since I am not from CS background.\n I am trying to implement some computer vision paper codes on newer samples. I understand the papers, and the underlying mechanisms. However, I fail to decipher the codes provided with the associated github repository. Usually, these repository contains information on how to recreate the experiment on some specific data using shell. But I am using google Colab for this purpose, as I don't have access to GPU, and I found it impossible to recreate the experiments in the google Colab, using shell commands, let alone extend it to newer samples.\n I would appreciate some help in this regard, I haven't done this before, and there aren't really any tutorial/resource on how to do this. Ideally, what I am trying to do is separate the model, input some images, get the output, and interpret it. I am stuck, and I would really appreciate some help or advice in this regard. Right now I am trying to work with this paper, meta ood\n I would appreciate any help/advice/resource anything. I feel very lost. Thanks in Advance.\n    submitted by    /u/franticpizzaeater  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z01w5/d_difficulty_with_paper_implementations_on_google/",
          "publishedOn": "2023-10-03T18:49:40.000Z",
          "wordCount": 2744,
          "title": "[D] Difficulty with paper implementations on google colab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yx8pj/repurposing_a_personal_desktop_computer_p/",
          "author": null,
          "description": "Hello! \n I'm debating turning my old desktop (old CPU but relatively new GPU 3980 or 90) into a ML box that I can remote into. I'm sure people here have done something similar and I was wondering if anyone could point me towards some resources for getting it off the ground/any pitfalls to avoid/suggestions. \n I'm an active data scientist researcher for my job and this would just be for fun side projects but I have some pretty glaring holes in my knowledge of computers (like the best way to set this up - should I uninstall windows install unbuntu or is windows fine?) \n Honestly I'm sure my ignorance will be pretty apparent from the questions I'm asking/not asking so any advice anyone has would be welcome! \n Thanks! Sorry if this is the wrong subreddit for this sort of thing. \n ​\n    submitted by    /u/shebaiscool  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yx8pj/repurposing_a_personal_desktop_computer_p/",
          "publishedOn": "2023-10-03T16:58:30.000Z",
          "wordCount": 2669,
          "title": "Repurposing a personal desktop computer [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ywkc6/r_generative_memory_generative_diffusion_models/",
          "author": null,
          "description": "https://arxiv.org/abs/2309.17290\n    submitted by    /u/LucaAmbrogioni  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ywkc6/r_generative_memory_generative_diffusion_models/",
          "publishedOn": "2023-10-03T16:31:19.000Z",
          "wordCount": 2537,
          "title": "[R] Generative memory: generative diffusion models are equivalent to modern Hopfield nets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yvwky/d_stuck_in_automation_of_ai_models/",
          "author": null,
          "description": "Hello everyone!\n ​\n I'm currently working on a project and have hit a roadblock in automating the deployment of my machine-learning models. Can anyone provide guidance on the best practices or tools for streamlining the deployment process? Specifically, I'm looking to create a seamless workflow where models can be easily uploaded, deployed on the cloud, and accessible through APIs. Any insights or advice would be greatly appreciated!\n ​\n Automation!!!\n    submitted by    /u/homelander81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yvwky/d_stuck_in_automation_of_ai_models/",
          "publishedOn": "2023-10-03T16:06:27.000Z",
          "wordCount": 2598,
          "title": "[D] Stuck in Automation of AI models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yvwbb/p_the_case_of_the_missing_masterpiece/",
          "author": null,
          "description": "Hi, I just wanted to share an applied image classification problem that I worked on a few years ago: https://vdalv.github.io/2018/09/01/missingMasterpiece.html\n    submitted by    /u/vdalv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yvwbb/p_the_case_of_the_missing_masterpiece/",
          "publishedOn": "2023-10-03T16:06:12.000Z",
          "wordCount": 2551,
          "title": "[P] The Case of the Missing Masterpiece",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yvpnm/need_to_build_a_xai_model_to_explain_the/",
          "author": null,
          "description": "Hello, I need help from someone that knows about XAI. I have to create a XAI model to intérprete the resulta of an AI model, an MLP, that works as an IDS classifier. I have no idea on how to do It and I have been completely blocked for 2.5 years. This is the final project of my career and I just don't know how to do It, and my tutor isn't very helpful. If anyone is able to help I would explain him what I have to do and would be very grateful.\n Thanks for your help\n    submitted by    /u/elMandarine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yvpnm/need_to_build_a_xai_model_to_explain_the/",
          "publishedOn": "2023-10-03T15:59:45.000Z",
          "wordCount": 2636,
          "title": "Need to build a XAI model to explain the behaviour of an IDS [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yskxk/d_optimal_scheduling_tool_with_aiml/",
          "author": null,
          "description": "Hello all,\n I'm trying to plan out for a new web platform development for workforce management but have little experience. We all know that hard coding can be done for general scheduling, including manager polling shifts based on labor category, staff assignments, conflt resolving, emergency scheduling, etc. But what I want to research to is....how can I ensure that one optimal schedule is automatically computed using AI/machine learning tools so that I don't have to go through the list of hard-coded generated schedules (I’m sure these will work fine, but still want to compute one ultimate schedule).\n    submitted by    /u/Playful-Bed-2183  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yskxk/d_optimal_scheduling_tool_with_aiml/",
          "publishedOn": "2023-10-03T13:55:01.000Z",
          "wordCount": 2628,
          "title": "[D] Optimal scheduling tool with AI/ML recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yse3r/r_breakascene_extracting_multiple_concepts_from_a/",
          "author": null,
          "description": "​\n Break-A-Scene: Given a single image with multiple concepts, annotated by loose segmentation masks, our method can learn a distinct token for each concept, and use natural language guidance to re-synthesize the individual concepts or combinations of them in various contexts.\n Project Page: https://omriavrahami.com/break-a-scene/\n Code is publicly released!\n Abstract\n  \nText-to-image model personalization aims to introduce a user-provided concept to the model, allowing its synthesis in diverse contexts. However, current methods primarily focus on the case of learning a single concept from multiple images with variations in backgrounds and poses, and struggle when adapted to a different scenario. In this work, we introduce the task of textual scene decomposition: given a single image of a scene that may contain several concepts, we aim to extract a distinct text token for each concept, enabling fine-grained control over the generated scenes. To this end, we propose augmenting the input image with masks that indicate the presence of target concepts. These masks can be provided by the user or generated automatically by a pre-trained segmentation model. We then present a novel two-phase customization process that optimizes a set of dedicated textual embeddings (handles), as well as the model weights, striking a delicate balance between accurately capturing the concepts and avoiding overfitting. We employ a masked diffusion loss to enable handles to generate their assigned concepts, complemented by a novel loss on cross-attention maps to prevent entanglement. We also introduce union-sampling, a training strategy aimed to improve the ability of combining multiple concepts in generated images. We use several automatic metrics to quantitatively compare our method against several baselines, and further affirm the results using a user study. Finally, we showcase several applications of our method.\n  \n​\n    submitted by    /u/sgd_is_all_you_need  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yse3r/r_breakascene_extracting_multiple_concepts_from_a/",
          "publishedOn": "2023-10-03T13:46:54.000Z",
          "wordCount": 2813,
          "title": "[R] Break-A-Scene: Extracting Multiple Concepts from a Single Image",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yr7kx/r_mit_meta_cmu_researchers_llms_trained_with_a/",
          "author": null,
          "description": "LLMs like GPT-3 struggle in streaming uses like chatbots because their performance tanks on long texts exceeding their training length. I checked out a new paper investigating why windowed attention fails for this.\n By visualizing the attention maps, the researchers noticed LLMs heavily attend initial tokens as \"attention sinks\" even if meaningless. This anchors the distribution.\n They realized evicting these sink tokens causes the attention scores to get warped, destabilizing predictions.\n Their proposed \"StreamingLLM\" method simply caches a few initial sink tokens plus recent ones. This tweaks LLMs to handle crazy long texts. Models tuned with StreamingLLM smoothly processed sequences with millions of tokens, and were up to 22x faster than other approaches. \n Even cooler - adding a special \"[Sink Token]\" during pre-training further improved streaming ability. The model just used that single token as the anchor. I think the abstract says it best:\n  \nWe introduce StreamingLLM, an efficient framework that enables LLMs trained with a finite length attention window to generalize to infinite sequence length without any fine-tuning. We show that StreamingLLM can enable Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language modeling with up to 4 million tokens and more.\n  \nTLDR: LLMs break on long convos. Researchers found they cling to initial tokens as attention sinks. Caching those tokens lets LLMs chat infinitely.\n Full summary here\n Paper link: https://arxiv.org/pdf/2309.17453.pdf\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yr7kx/r_mit_meta_cmu_researchers_llms_trained_with_a/",
          "publishedOn": "2023-10-03T12:56:26.000Z",
          "wordCount": 2770,
          "title": "[R] MIT, Meta, CMU Researchers: LLMs trained with a finite attention window can be extended to infinite sequence lengths without any fine-tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yq79a/d_really_good_dataset_for_a_course_capstone/",
          "author": null,
          "description": "Hey everyone!\n My friends and I are taking a Data Science course in our university. We are modestly versed in ML/DL techniques, and want to use everything we know on a really good capstone project for this course. We are looking for a dataset where we can demonstrate a nice variety of techniques to really blow the socks off our Professor. \n Ideally we'd like this to be stemming from something basic that most would consider \"Data Science\", as in something with a tabular dataset and elements of classification. Though we still want chances to bring in what we know from outside the course: for example, if there's images to supplement the dataset we could use Image Classification models or something multimodal to bring in more features, if there's natural language data then we could use LLMs to extract salient features etc. More importantly though, we want something whose exploration can be really motivated so it doesn't seem we're only in it for the ML aspect.\n Thank you!\n    submitted by    /u/Subject-Revolution-3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yq79a/d_really_good_dataset_for_a_course_capstone/",
          "publishedOn": "2023-10-03T12:09:29.000Z",
          "wordCount": 2699,
          "title": "[D] Really good dataset for a Course Capstone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ypoak/d_competitiveness_in_ml_research/",
          "author": null,
          "description": "I've been diving deep into the world of machine learning research, and I'm genuinely baffled: how on Earth do some researchers seem to pump out paper after paper? I mean, there's only 24 hours in a day, right?\n Are academic minions (i.e. PhD students) doing all the heavy lifting? Or maybe some highly efficient workflows I'm not privy to?\n On a more serious note, I would like a career in ML, and the sheer volume and pace of these publications is making me feel a bit disheartened.\n How is this prolificity possible? Any words of encouragement or advice?\n    submitted by    /u/blabboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ypoak/d_competitiveness_in_ml_research/",
          "publishedOn": "2023-10-03T11:43:54.000Z",
          "wordCount": 2627,
          "title": "[D] Competitiveness in ML research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ypmuh/d_why_should_i_use_a_hostedcloud_vectordb/",
          "author": null,
          "description": "Why the hell should i use cloud based or server hosted solution over a easy peasy servless variant like lancedb or even faiss vector store is enough for most of the use cases on small-medium\n I often see posts like\n \"oh my stack is... pinecone Chroma weaviate_io\"\n And they just ingest minisets of data, what the hell man\n    submitted by    /u/Dear_Bullfrog193  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ypmuh/d_why_should_i_use_a_hostedcloud_vectordb/",
          "publishedOn": "2023-10-03T11:41:46.000Z",
          "wordCount": 2597,
          "title": "[D] Why should I use a hosted/cloud VectorDB solutions over a serverless or vector store?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yo7j4/p_fontogen_generating_truetype_fonts/",
          "author": null,
          "description": "I'd like to share a project that I've spent a few weekends working on. FontoGen is an autoregressive encoder-only transformer model that's capable of generating true-type fonts. \n GitHub: https://github.com/SerCeMan/fontogen\n Weights: https://huggingface.co/SerCe/fontogen\n Blog post with more details: https://serce.me/posts/02-10-2023-hey-computer-make-me-a-font\n The project is largely an exploration of whether generating fonts natively, line by line, is possible. I'm not aware of any previous research that would achieve the same results for complete fonts previously. This is my first ML-specific project, and I would appreciate any feedback on the model architecture, and I'm also happy to answer any questions you may have.\n    submitted by    /u/SerCeMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yo7j4/p_fontogen_generating_truetype_fonts/",
          "publishedOn": "2023-10-03T10:28:10.000Z",
          "wordCount": 2620,
          "title": "[P] FontoGen: generating true-type fonts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ylbx6/d_what_happens_after_removing_the_causal_mask_of/",
          "author": null,
          "description": "The causal mask in LLaMA serves as a protective barrier to prevent information leakage. However, in certain tasks, leveraging information leakage can be a beneficial strategy for enhancing performance, particularly in tasks like token classification, such as Named Entity Recognition (NER). Interestingly, the paper titled \"Label Supervised LLaMA Finetuning\" (available at https://arxiv.org/abs/2310.01208) reveals a significant performance boost in token classification when the causal mask is removed.\n    submitted by    /u/seanlee97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ylbx6/d_what_happens_after_removing_the_causal_mask_of/",
          "publishedOn": "2023-10-03T07:27:05.000Z",
          "wordCount": 2600,
          "title": "[D] What happens after removing the causal mask of LLaMA?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yk8ka/r_radit_retrievalaugmented_dual_instruction_tuning/",
          "author": null,
          "description": "New paper that proposes instruction-tuning with in-context retrieval-augmentation to improve SOTA LLMs in cases where access to large, external knowledge sources is needed. Tested on LLaMA 65B, 13B and 7B.\n https://arxiv.org/abs/2310.01352\n    submitted by    /u/todpole3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yk8ka/r_radit_retrievalaugmented_dual_instruction_tuning/",
          "publishedOn": "2023-10-03T06:13:48.000Z",
          "wordCount": 2561,
          "title": "[R] RA-DIT: Retrieval-Augmented Dual Instruction Tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yebwm/d_how_do_you_scale_computational_intensive_python/",
          "author": null,
          "description": "Hey ML Community, I'm wondering how people currently go about scaling their Python programs? Lets say for instances you're doing batch inference using an LLM. Each prediction takes 2-3 minutes to process, how would you go about scaling that to make a million predictions? \n I'm asking this question because a few months back I started building a tool to quickly parallelize python functions across thousands of machines in the cloud. I'm focused on making the barrier to interact with the cloud extremely low and want to know all the core alternatives out there. Also, if you have any advice on starting a business I'd love to hear it. \n    submitted by    /u/Ok_Post_149  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yebwm/d_how_do_you_scale_computational_intensive_python/",
          "publishedOn": "2023-10-03T01:06:51.000Z",
          "wordCount": 2641,
          "title": "[D] How do you scale computational intensive Python scripts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ydpzc/d_what_is_the_highest_quality_automatic_image/",
          "author": null,
          "description": "I make very high quality Lora's and finetuned stable diffusion models. These models yield very good results, but more importantly they are very easy to use as I have always captioned my images as one would use natural spoken language (no weird booru tags and all that jazz). The most labor intensive processes in the workflow is image captioning. For example, my last project had almost 10000 images in the data set. Every single image was manually captioned by me as the quality of all automated solutions I tried is subpar and has too many accuracy issues. I have tried Blip auto captioning and LLava, but they still were not accurate enough for what I needed. I am hoping someone here can suggest a solution, if one exists, thanks.\n    submitted by    /u/no_witty_username  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ydpzc/d_what_is_the_highest_quality_automatic_image/",
          "publishedOn": "2023-10-03T00:39:06.000Z",
          "wordCount": 2663,
          "title": "[D] What is the highest quality automatic image captioning solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yd5qh/d_interview_help_do_you_know_any_good_resources/",
          "author": null,
          "description": "I'm preparing for a data science interview and am looking for case study prep resources, especially for the financial domain (loans and credit cards). Mainly, I want to understand some good metrics for the financial domain, ways to break down the questions and create a rough data model, kinds of conditions to take into consideration (eg. Seasonality), kinds of effects that can be used expected (like opportunities and risks), etc. Any resources or help is greatly appreciated!\n    submitted by    /u/how_the_turn_tablez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yd5qh/d_interview_help_do_you_know_any_good_resources/",
          "publishedOn": "2023-10-03T00:13:43.000Z",
          "wordCount": 2625,
          "title": "[D] (Interview Help) Do you know any good resources for interview case studies in the finance domain (especially dealing in loan and credit cards)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ycp51/discussion_i_didnt_do_well_in_calculus_iii/",
          "author": null,
          "description": "So I got an A in calculus three but I probably didn't deserve it since it was online and all I did was look up the answer and understand the problems given on the test. So I probably have a C level understanding. Will I be tested on calc 3 knowledge in machine learning or should I retake calc 3?\n    submitted by    /u/Glittering-Target-87  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ycp51/discussion_i_didnt_do_well_in_calculus_iii/",
          "publishedOn": "2023-10-02T23:53:32.000Z",
          "wordCount": 2592,
          "title": "[Discussion] I didn't do well in Calculus III",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ya5p1/p_hand_keypoint_detection/",
          "author": null,
          "description": "Hello Reddit,\n I have a question regarding the right tool. I'm looking for a tool / model to detect hand-keypoints in a video stream of a person assembling stuff. I know OpenPose is a possible one, also Google MediaPipe.\n I’m not really getting along with OpenPose and MediaPipe don’t show really good results.\n In my project, I would like to detect hand keypoints in assembly scenarios. It would be ok to use 2 cameras or a depth camera if necessary.\n Does anybody knows any models / tools to use?\n Thanks in advance :)\n    submitted by    /u/VGHMD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ya5p1/p_hand_keypoint_detection/",
          "publishedOn": "2023-10-02T22:11:04.000Z",
          "wordCount": 2621,
          "title": "[P] Hand keypoint detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y9k4x/p_best_option_for_a_large_local_embedding_database/",
          "author": null,
          "description": "Langchain offers a wide array of vector databases for text embedding models. I need to create a vector database for around 3 million sentence embeddings, each being of dimension 384. I'm building a prototype, so it has to be local and free of charge to use.\n So far, I've hit limits for Chroma (41,666 max). I've also tried Redis, QDrant and FAISS - each of these gets so large that it eats up all the RAM and the process gets killed, or with QDrant, just errors out.\n I've used Pinecone before, but I don't really want to pay for a prototype as I have plenty of disk space.\n I was thinking of chunking the 3 million documents into local vector stores of size 41,666 using ChromaDB - but there isn't a whole lot out there about whether Chroma would allow me to merge all ~70 of these smaller databases into a bigger one for search. I also cannot find whether it would be possible to load all 70 of these into memory and search each one individually.\n So what are my options?\n My other thought was just creating a large Doc2Vec model, however I would like to use something more sophisticated like Huggingface embedding models.\n    submitted by    /u/russ_fegoli  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y9k4x/p_best_option_for_a_large_local_embedding_database/",
          "publishedOn": "2023-10-02T21:47:25.000Z",
          "wordCount": 2738,
          "title": "[P] Best option for a large, local embedding database?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y9hwt/d_proof_of_convergence_for_a_heavyball_adaptive/",
          "author": null,
          "description": "Hello everyone,\n I am struggling with prooving convergence for an optimizer which uses adaptive step-size with heavy ball algorithm for convex and non-convex functions. In some literature, I could find a regret bound analysis/proof for convex functions and proving that the estimated gradient at t -> inf goes to zero for non-convex functions. \n There are some assumptions and preconditions:\n  \nThe algorithm is heavy ball momentum with adaptive step-size. '\n X_(k+1) = X_k - \\eta_k . \\nabla(f(x_k)) + \\beta(x_k - x_(k-1))\n \nThe following assumptions are made: \n  \nA. The function is smooth. B. The function is Lipschitz. C. The gradients are Lipschitz. \n I attempt to prove the convergence to a critical point or a local minima. Where the estimate of the gradients at any instance k goes to zero. i.e. E[\\nabla(f(x_k))] = 0 as t -> inf. \n Could anyone please guide me through the process of convergence proof for non-convex functions or give me literature recommendations for the same.\n Thank you very much in advance.\n    submitted by    /u/Loose_Foundation5990  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y9hwt/d_proof_of_convergence_for_a_heavyball_adaptive/",
          "publishedOn": "2023-10-02T21:44:58.000Z",
          "wordCount": 2699,
          "title": "[D] Proof of convergence for a heavy-ball adaptive step-size algorithm for non-convex functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y8oyn/d_open_problems_after_gpt4_capabilities/",
          "author": null,
          "description": "We all know that LLMs (and especially foundation models) are extremely functionally capable. Has anyone made a nice list of deficiencies that they show? \n I know Gary Marcus did so many years ago, but after GPT3 and GPT4 -- what is still unsolved? \n    submitted by    /u/Cultural-Average3959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y8oyn/d_open_problems_after_gpt4_capabilities/",
          "publishedOn": "2023-10-02T21:16:21.000Z",
          "wordCount": 2573,
          "title": "[D] open problems after GPT4 capabilities",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y7r0w/d_hoeffdings_inequality_does_it_make_sense/",
          "author": null,
          "description": "According to it, increasing the hypotheses set loosens the upper bound between in-sample and out-of-sample error.\n ​\n Can't we subdivide the hypotheses set to multiple ones, ensuring tighter bounds in general?\n ​\n and generally, have you seen it in use before? I have seen a lot of ML projects without anybody mentioning it or anything theoretical.\n    submitted by    /u/2azo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y7r0w/d_hoeffdings_inequality_does_it_make_sense/",
          "publishedOn": "2023-10-02T20:41:06.000Z",
          "wordCount": 2580,
          "title": "[D] Hoeffdings inequality, does it make sense practically?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y7jpw/p_good_models_to_use_for_multimodal_object/",
          "author": null,
          "description": "So basically I have a dataset with images of vehicles in top down view in both RGB and IR, what are some models I can use for both unimodal and multimodal object detection to compare their performance. Links to GitHub repos would be helpful. Thanks\n    submitted by    /u/Xyber5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y7jpw/p_good_models_to_use_for_multimodal_object/",
          "publishedOn": "2023-10-02T20:33:15.000Z",
          "wordCount": 2591,
          "title": "[P] Good models to use for multimodal object detection when both the modalities are image based or some models which support ensembling?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y6ul8/benefits_of_converting_dicom_images_to_pngs_p/",
          "author": null,
          "description": "I try to understand what are the benefits to convert DICOM images to PNG's.\n Context:\n I have DICOM images which I already extracted the useful meta-data I want to use.\n Those images are for a task, classification-detection pipeline of some disease.\n So as I already asked, what are the benefits of converting those DICOM files to PNG's rather then just using pydicom and the dicom pixel_array?\n Reason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.\n If I understand how networks actually works, they get as input an array of pixels as floating point numbers no? So what's the differences between DICOM pixel_array to PNG's pixel array and numpy array or tensor? both are eventually will be fed to the network as a tensor of floating numbers.\n Is the reason is because PNG's are usually faster to train?\n Is the reason is because PNG's have more libraries support for preprocessing / augmentation / etc. ?\n Is the reason is because PNG's are the format many pre-trained models expect to? (I write this knowing it's 99% not true, as mentioned the tensor thing)\n Thanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)\n    submitted by    /u/01jasper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y6ul8/benefits_of_converting_dicom_images_to_pngs_p/",
          "publishedOn": "2023-10-02T20:07:29.000Z",
          "wordCount": 2743,
          "title": "Benefits of converting DICOM images to PNG's [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y5cra/d_what_kind_of_distribution_is_this/",
          "author": null,
          "description": "Hey guys,\n I am wondering what kind of distribution my data are following? I want to fit a distribution function to them and use this fitted distribution function to generate new samples with a given mean and standard deviation (python). Any tips for this?\n Happy to hear your suggestions :) \n https://preview.redd.it/kdcftvpq8urb1.png?width=408&format=png&auto=webp&s=6163b9f571069e098c9e9a609c3d1cb9910fe1fb\n    submitted by    /u/Tigmib  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y5cra/d_what_kind_of_distribution_is_this/",
          "publishedOn": "2023-10-02T19:10:29.000Z",
          "wordCount": 2575,
          "title": "[D] What kind of distribution is this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y5bk2/r_efficient_streaming_language_models_with/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.17453\n Github: https://github.com/mit-han-lab/streaming-llm\n Abstract:\n  \nDeploying Large Language Models (LLMs) in streaming applications such as multi-round dialogue, where long interactions are expected, is urgently needed but poses two major challenges. Firstly, during the decoding stage, caching previous tokens' Key and Value states (KV) consumes extensive memory. Secondly, popular LLMs cannot generalize to longer texts than the training sequence length. Window attention, where only the most recent KVs are cached, is a natural approach -- but we show that it fails when the text length surpasses the cache size. We observe an interesting phenomenon, namely attention sink, that keeping the KV of initial tokens will largely recover the performance of wind…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y5bk2/r_efficient_streaming_language_models_with/",
          "publishedOn": "2023-10-02T19:09:13.000Z",
          "wordCount": 2792,
          "title": "[R] Efficient Streaming Language Models with Attention Sinks - Meta AI 2023 - StreamingLLM enables Llama-2, Falcon and Pythia to have an infinite context length without any fine-tuning! Allows streaming use of LLMs!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y3r7t/project_i_just_released_an_opensource_package/",
          "author": null,
          "description": "You just give it any PyTorch model (as-is, no changes needed), and it spits out a data structure with the activations of any layer you want, along with a bunch of metadata about the model and each layer and an optional automatic visualization of the model's computational graph. I hope this greatly speeds up the process of extracting features from models for further analysis, and also serves as an aid in quickly understanding new models. I also hope it'd be helpful for teaching purposes, too. It is meant to work for any PyTorch model whatsoever and I've tested it on hundreds of models (see the \"model menagerie\" of visualizations below), though it's always possible I've missed some edge case or another.\n Hope it helps you out--I'm still actively developing it, so let me know if there's anything on your wishlist!\n https://preview.redd.it/k37nhejvxtrb1.png?width=640&format=png&auto=webp&s=5713a8711110644794e2264d84dd479ede861c5e\n GitHub Repo\n Twitter Thread\n Paper\n CoLab Tutorial\n Gallery of Model Visuals\n    submitted by    /u/therealjmt91  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y3r7t/project_i_just_released_an_opensource_package/",
          "publishedOn": "2023-10-02T18:08:31.000Z",
          "wordCount": 2704,
          "title": "[Project] I just released an open-source package, TorchLens, that can extract the activations/metadata from any PyTorch model, and visualize its structure, in just one line of code. I hope it helps you out!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y1rxz/d_why_vision_tranformers/",
          "author": null,
          "description": "Transformers have been the new kid on the block, easy to see why with LLMs and and sequential output generation, but I still don't know why vision transformers based on ViT are so hot in the field right now. From my understanding, CNNs are just vastly better than transformers for vision tasks, as its inductive biases allows it to determine the relationship between neighboring features of an image via pooling and filters. However, transformers don't have this kind of inductive bias, and as a result, take much more data and compute to reach similar levels of performance.\n I read this survey paper on Vision Transformers here: https://arxiv.org/pdf/2012.12556.pdf, which has the performance of CNNs vs various transformer models for CV. Comparing even the best vision transformers to the classic …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y1rxz/d_why_vision_tranformers/",
          "publishedOn": "2023-10-02T16:51:58.000Z",
          "wordCount": 2860,
          "title": "[D] Why Vision Tranformers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y18co/r_toolintegrated_reasoning_a_new_approach_for/",
          "author": null,
          "description": "When trying to get language models to solve complex math problems, researchers kept running into limits. Models like GPT-3 and ChatGPT still struggle with advanced algebra, calculus, and geometry questions. The math is just too abstract and symbol-heavy for them.\n To break through this barrier, researchers from Tsinghua University and Microsoft taught models to combine natural language reasoning with calling external math tools.\n The key is their new \"tool-integrated reasoning\" format. Models generate a natural language plan first, then write code to invoke tools like SymPy to solve equations. They take the output results and continue verbal reasoning.\n By interleaving natural language and symbolic computations, they get the best of both worlds - semantic understanding from language models and rigorous math from tools.\n They trained versions of the LLaMA model this way, producing their Tool-Integrated Reasoning Agent (TORA). They present some strong results:\n  \nIn evaluations on 10 math datasets, TORA substantially outperformed prior state-of-the-art methods, achieving 13-19% higher accuracy on average.\n On one competition test, TORA-7B scored 40% accuracy, beating the previous best model by 22 percentage points.\n  \nThis demonstrates that integrating tools directly into the reasoning process can significantly enhance mathematical capabilities, even for large models like GPT-4.\n However, tough problems involving geometry and advanced algebra are still there. New techniques for symbolic reasoning and spatial understanding will likely be needed to push further.\n Overall though, tool integration seems a promising path to improve reasoning skills. Applying this to other domains like logic and programming could also be impactful.\n TLDR: Teaching language models to use math tools helps them solve way more complex problems.\n Full Paper Summary\n arXiv Link\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y18co/r_toolintegrated_reasoning_a_new_approach_for/",
          "publishedOn": "2023-10-02T16:30:09.000Z",
          "wordCount": 2803,
          "title": "[R] Tool-Integrated Reasoning: A New Approach for Math-Savvy LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xy554/p_awesome_ai_developer_productivity_github_repo/",
          "author": null,
          "description": "Hello everyone,\n We've begun gathering a variety of AI coding tools used in one place to make things easier for everyone. We're inviting everyone to check out our collection, and maybe even add tools you find useful.\n You can find the repository here: https://github.com/gaborsoter/awesome-ai-dev-productivity\n Feel free to explore and contribute! \n    submitted by    /u/BootstrapGuy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xy554/p_awesome_ai_developer_productivity_github_repo/",
          "publishedOn": "2023-10-02T14:29:17.000Z",
          "wordCount": 2581,
          "title": "[P] Awesome AI developer productivity Github repo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xx1r2/r_on_the_biometric_capacity_of_generative_face/",
          "author": null,
          "description": "We developed a statistical model to estimate “How many unique identities can a generative face model generate?” without exhaustively generating a lot of faces.\n Abstract: There has been tremendous progress in generating realistic faces with high fidelity over the past few years. Despite this progress, a crucial question remains unanswered: “Given a generative face model, how many unique identities can it generate?” In other words, what is the biometric capacity of the generative face model? A scientific basis for answering this question will benefit evaluating and comparing different generative face models and establish an upper bound on their scalability. This paper proposes a statistical approach to estimate the biometric capacity of generated face images in a hyperspherical feature space. We employ our approach on multiple generative models, including unconditional generators like StyleGAN, Latent Diffusion Model, and “Generated Photos,” as well as DCFace, a class-conditional generator. We also estimate capacity w.r.t. demographic attributes such as gender and age. Our capacity estimates indicate that (a) under ArcFace representation at a false acceptance rate (FAR) of 0.1%, StyleGAN3 and DCFace have a capacity upper bound of 1.43 million and 11,900, respectively; (b) the capacity reduces drastically as we lower the desired FAR with an estimate of 17,960 and 562 at FAR of 1% and 10%, respectively, for StyleGAN3; (c) there is no discernible disparity in the capacity w.r.t gender; and (d) for some generative models, there is an appreciable disparity in the capacity w.r.t age.\n Paper: https://arxiv.org/abs/arXiv:2308.02065\n Code: https://github.com/human-analysis/capacity-generative-face-models\n    submitted by    /u/VishDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xx1r2/r_on_the_biometric_capacity_of_generative_face/",
          "publishedOn": "2023-10-02T13:45:19.000Z",
          "wordCount": 2779,
          "title": "[R] On the Biometric Capacity of Generative Face Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xtrbv/p_comgra_a_library_for_debugging_and/",
          "author": null,
          "description": "I'm a machine learning engineer and researcher. I got fed up with how difficult it is to understand why neural networks behave the way they do, so i wrote a library to help with it.\n Comgra (computation graph analysis) is a library you can use with pytorch to extract all the tensor data you care about and visualize it graphically in a browser.\n This allows for a much more detailed analysis of what is happening than the usual approach of using tensorboard. You can go investigate tensors as training proceeds, drill down into individual neurons, inspect single data sets that are of special interest to you, track gradients, compare statistics between different training runs, and more.\n This tool has saved me a ton of time in my research by letting me check my hypotheses much more quickly than normal and by helping me understand how the different parts of my network really interact.\n I first published this a month ago and have made some improvements since then. I would be happy to hear even more feedback!\n My goal is to make this the go-to library used both by novices who want to understand what's going on under the hood, and by researchers in neural architecture design.\n    submitted by    /u/Smart-Emu5581  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xtrbv/p_comgra_a_library_for_debugging_and/",
          "publishedOn": "2023-10-02T11:08:44.000Z",
          "wordCount": 2740,
          "title": "[P] Comgra: A library for debugging and understanding neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xshji/d_the_most_complete_audio_ml_toolkit/",
          "author": null,
          "description": "Hugging Face Transformers is a complete audio toolkit that provides state-of-the-art models for all audio tasks, including TTS, ASR, audio embeddings, audio classification and music generation.\n All you need to do is install the Transformers package:\n pip install --upgrade transformers \n And then all of these models can be used in just 3 lines of code:\n ​\n TTS\n Example usage:\n from transformers import pipeline generator = pipeline(\"text-to-speech\", model=\"suno/bark-small\") speech = generator(\"Hey - it's Hugging Face on the phone!\") \n Available models:\n  \nBark https://huggingface.co/suno/bark\n MMS TTS https://huggingface.co/facebook/mms-tts-eng\n VITS https://huggingface.co/kakao-enterprise/vits-vctk\n SpeechT5 https://huggingface.co/microsoft/speecht5_tts\n And more! https://huggingface.co/mo…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xshji/d_the_most_complete_audio_ml_toolkit/",
          "publishedOn": "2023-10-02T09:54:19.000Z",
          "wordCount": 2799,
          "title": "[D] The most complete Audio ML toolkit 🚀",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xpi5o/r_the_dawn_of_lmms_preliminary_explorations_with/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.17421 \n Youtube: https://youtu.be/Q0pP782dSh0?si=MiJAlK5k-KEyQ-Zr \n Abstract:\n  \nLarge multimodal models (LMMs) extend large language models (LLMs) with multi-sensory skills, such as visual understanding, to achieve stronger generic intelligence. In this paper, we analyze the latest model, GPT-4V(ision), to deepen the understanding of LMMs. The analysis focuses on the intriguing tasks that GPT-4V can perform, containing test samples to probe the quality and genericity of GPT-4V's capabilities, its supported inputs and working modes, and the effective ways to prompt the model. In our approach to exploring GPT-4V, we curate and organize a collection of carefully designed qualitative samples spanning a variety of domains and tasks. Observations from these samples demonstrate that GPT-4V's unprecedented ability in processing arbitrarily interleaved multimodal inputs and the genericity of its capabilities together make GPT-4V a powerful multimodal generalist system. Furthermore, GPT-4V's unique capability of understanding visual markers drawn on input images can give rise to new human-computer interaction methods such as visual referring prompting. We conclude the report with in-depth discussions on the emerging application scenarios and the future research directions for GPT-4V-based systems. We hope that this preliminary exploration will inspire future research on the next-generation multimodal task formulation, new ways to exploit and enhance LMMs to solve real-world problems, and gaining better understanding of multimodal foundation models. \n  \nhttps://preview.redd.it/qkytzg2rjqrb1.jpg?width=511&format=pjpg&auto=webp&s=fc306dc6ae64100e993639f8e27583b809bf8a5c\n https://preview.redd.it/z4kq0l2rjqrb1.jpg?width=507&format=pjpg&auto=webp&s=d4fda59456846fa7a6c9b318b21fc9c544bd2b68\n https://preview.redd.it/1ptrkk2rjqrb1.jpg?width=712&format=pjpg&auto=webp&s=2b44fbc949e76fdf20d05b1236f56c87ba5efece\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xpi5o/r_the_dawn_of_lmms_preliminary_explorations_with/",
          "publishedOn": "2023-10-02T06:45:31.000Z",
          "wordCount": 2750,
          "title": "[R] The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision) - Microsoft 2023 - 166 Pages!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xm3mt/p_nanophi_implementing_some_of_the_success_of/",
          "author": null,
          "description": "Hi, i'm trying to replicate at least some of the success of Phi 1.5 on a model 10x smaller, gpt-2 124m.\n I have started with model finetuning, and have a simple github with roadmap, https://github.com/VatsaDev/NanoPhi, check it out there!\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xm3mt/p_nanophi_implementing_some_of_the_success_of/",
          "publishedOn": "2023-10-02T03:35:26.000Z",
          "wordCount": 2574,
          "title": "[P] NanoPhi, Implementing some of the success of Phi-1.5, with GPT-2(124m)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xg8nh/r_the_unsolved_mystery_at_the_heard_of_the_how_to/",
          "author": null,
          "description": "submitted by    /u/CellWithoutCulture  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xg8nh/r_the_unsolved_mystery_at_the_heard_of_the_how_to/",
          "publishedOn": "2023-10-01T23:14:37.000Z",
          "wordCount": 2621,
          "title": "[R] The unsolved mystery at the heard of the \"How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions\" paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xbess/d_how_many_instructions_can_llms_handle_before/",
          "author": null,
          "description": "Prompt engineering frequently involves trying to encode very specific behaviors into a model to steer it a certain direction. In practice, as requirements become more complex, you often end up with fairly lengthy prompts, especially when using methods like RAG. I was wondering, how effective are LLMs at following instructions as the system prompt grows in size and complexity?\n I did some quick experiments on this and found that, unsurprisingly, GPT-4 can follow a lot of rules (up to 50) quite accurately. But even GPT-3.5 slowly degrades and Llama-2-70b-chat starts to fail after just a few rules.\n Comparison of performance metrics over increasing rule counts, demonstrating GPT-4's consistent performance and a decline in accuracy for GPT-3.5 and Llama-2-70b-chat.\n These results are based on …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xbess/d_how_many_instructions_can_llms_handle_before/",
          "publishedOn": "2023-10-01T20:10:40.000Z",
          "wordCount": 3055,
          "title": "[D] How many instructions can LLMs handle before they start to ignore them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xakha/r_langdiversity_software_to_identify_llm_errors/",
          "author": null,
          "description": "Due to challenges such as hallucination, detecting errors in the output of a given prompt becomes an important challenge. LangDiversity is an implementation of \"diversity measures\" that are domain independent and can be used to measure the uncertainty in the result of a language model.\n Type pip install langdiversity\n Video: https://www.youtube.com/watch?v=86J_K9mR7lw\n Web: https://neurosymbolic.asu.edu/llm-correction/\n Visit https://github.com/lab-v2/langdiversity\n Read the paper: https://arxiv.org/abs/2308.11189\n https://preview.redd.it/rb0xg1ly8nrb1.png?width=1021&format=png&auto=webp&s=8e57056d24327ca2987abea12a7a9066a825738b\n    submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xakha/r_langdiversity_software_to_identify_llm_errors/",
          "publishedOn": "2023-10-01T19:37:59.000Z",
          "wordCount": 2651,
          "title": "[R] LangDiversity: software to identify LLM errors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x975p/p_simplest_model_to_run_with_limited_hardware/",
          "author": null,
          "description": "We want to run (not train, i.e. think single forward pass only) an ML algorithm on a machine with very limited resources.\n Which model could we use to show off the possibilities?\n If the benchmark is an MLP for binary image classification, what else could we do with a similar scale of operations?\n E.g.\n Which model is the simplest for e.g. text-to-image generation?\n Any other ML models that are simple enough to run and if initialized with good params, does something impressive\n    submitted by    /u/2i2i_tokenized_time  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x975p/p_simplest_model_to_run_with_limited_hardware/",
          "publishedOn": "2023-10-01T18:46:32.000Z",
          "wordCount": 2675,
          "title": "[P] Simplest model to run with limited hardware",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x91b9/p_deep_memory_a_way_to_boost_retrieval_accuracy/",
          "author": null,
          "description": "submitted by    /u/davidbun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x91b9/p_deep_memory_a_way_to_boost_retrieval_accuracy/",
          "publishedOn": "2023-10-01T18:40:30.000Z",
          "wordCount": 2598,
          "title": "[P] Deep Memory, a Way to Boost Retrieval Accuracy by up to +22% for RAG",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x63ce/d_perplexityai_search_feasibility/",
          "author": null,
          "description": "I've been using Perplexity.ai for a bit now when it hit me that I don't understand how they can sustain their business model with search. Stuff like Bing search and Google search cost around $5 or more per 1000 searches, so how can they even afford to do this kind of search. Do they have their own search index.\n Also, I don't know how they pull in the data from these sources so fast? I've played around with some things like this with Langchain with retrieval, but the speed of splitting and tokenizing website html is not very fast. Have they already pre-scrapped the websites from the search results and tokenized them for LLM retrieval?\n    submitted by    /u/dragon18456  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x63ce/d_perplexityai_search_feasibility/",
          "publishedOn": "2023-10-01T16:47:35.000Z",
          "wordCount": 2704,
          "title": "[D] Perplexity.ai Search Feasibility",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x5d0h/metagpt_use_case_d/",
          "author": null,
          "description": "Guys, i am currently working building a project, there are certain tasks like building a ml model using certain use-cases. I wish to automate this task, do u think metagpt is a good fit for the same. \n Let me know if you need any further information!!\n EDIT: \n One of the tasks my app needs to do is to convert image to text (aim to implement image captioning). So, if i give metaGPT the requirements for my project, is it possible it will give me the code which I need. I need to save certain tasks here so that I can focus more on operation and design side. \n Edit: it seems, such kind of vague questions are not encouraged on this platform, I will work and will straigh away ask questions which are quite good and meet the standards of this platform. Thanks!!\n Thanks!!\n Always have a massive respect for this community!!\n    submitted by    /u/aristotleTheFake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x5d0h/metagpt_use_case_d/",
          "publishedOn": "2023-10-01T16:17:20.000Z",
          "wordCount": 2740,
          "title": "Metagpt use case [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x2o47/r_meta_inria_researchers_discover_that_explicit/",
          "author": null,
          "description": "When visualizing the inner workings of vision transformers (ViTs), researchers noticed weird spikes of attention on random background patches. This didn't make sense since the models should focus on foreground objects.\n By analyzing the output embeddings, they found a small number of tokens (2%) had super high vector norms, causing the spikes.\n The high-norm \"outlier\" tokens occurred in redundant areas and held less local info but more global info about the image.\n Their hypothesis is that ViTs learn to identify unimportant patches and recycle them as temporary storage instead of discarding. This enables efficient processing but causes issues.\n Their fix is simple - just add dedicated \"register\" tokens that provide storage space, avoiding the recycling side effects.\n Models trained with registers have:\n  \nSmoother and more meaningful attention maps\n Small boosts in downstream performance\n Way better object discovery abilities\n  \nThe registers give ViTs a place to do their temporary computations without messing stuff up. Just a tiny architecture tweak improves interpretability and performance. Sweet!\n I think it's cool how they reverse-engineered this model artifact and fixed it with such a small change. More work like this will keep incrementally improving ViTs.\n TLDR: Vision transformers recycle useless patches to store data, causing problems. Adding dedicated register tokens for storage fixes it nicely.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x2o47/r_meta_inria_researchers_discover_that_explicit/",
          "publishedOn": "2023-10-01T14:28:22.000Z",
          "wordCount": 2812,
          "title": "[R] Meta, INRIA researchers discover that explicit registers eliminate ViT attention spikes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x2658/d_multiple_single_class_segmentation_vs_single/",
          "author": null,
          "description": "submitted by    /u/waterstrider123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x2658/d_multiple_single_class_segmentation_vs_single/",
          "publishedOn": "2023-10-01T14:08:42.000Z",
          "wordCount": 2677,
          "title": "[D] Multiple single class segmentation vs single multiclass segmentation models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x1fzr/r_sota_of_deepshallow_encoderdecoder_llms_for/",
          "author": null,
          "description": "There's some evidence [1] [2] that it's possible to run text2text language model at substantially (potentially on the order of magnitude) better inference speed by keeping the decoder shallow.\n I'm curious whether some general reasoner SOTA (small model for machine translation available at [3]) style models are publicly available for this sort of thing.\n If not, how would one go about training one?\n Would it be necessary to do it entirely from scratch (extremely costly)? Or would it be possible to take, say, Flan-UL2 (20B), chop off its decoder, and train a much smaller decoder on top of it with the UL2 encoder frozen (ie how one trains adapter layers).\n Assuming the decoder hyperparameters are kept small, would this be possible within reasonable compute budget? Would that even meaningfully converge with small amount of compute (assuming same training objective as is for UL2)?\n Would the strength (ie somewhat comparable to 10B if we cut 20B in half) transfer from the SOTA encoder, or would cutting off half of the model layers kneecap it too badly?\n [1] https://arxiv.org/pdf/2006.10369.pdf\n [2] https://aclanthology.org/2023.sustainlp-1.6.pdf\n [3] https://github.com/snoop2head/Deep-Encoder-Shallow-Decoder\n    submitted by    /u/upalse  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x1fzr/r_sota_of_deepshallow_encoderdecoder_llms_for/",
          "publishedOn": "2023-10-01T13:37:56.000Z",
          "wordCount": 2769,
          "title": "[R] SOTA of Deep-Shallow Encoder-Decoder LLMs for fast inference",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wytmy/d_duplicating_layers_in_large_models/",
          "author": null,
          "description": "Is there any notable work on duplicating layers in large feed forward models? In contrast to e.g. the brain which is essentially a directed graph most networks utilized nowerdays use a feed forward approach. E.g. transformers are able to attend to past tokens, but generate the tokens in a way where for a given token a given weight is not utilized at different stages in the feed forward pass. In my intuition this would lead to an issue where concepts (factual data as well as learned \"algorithms\") might be duplicated as they are needed at different depths in the generation process and are sequentially dependent on one another. This does not directly make the model less capable, as it might learn the same concept at two layers sufficiently well, but it reduces the data and parameter efficiency and and might impact generalization capabilities. Using a full on brain like graph might be hard to implement/optimize/scale on current hardware and is tricky with the backprop. But is there any work on duplicating a few layers, placing them at different depths in large models. I would guess that this would be more impactful for large models. One would essentially trade compute for better data efficiency.\n    submitted by    /u/floriv1999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wytmy/d_duplicating_layers_in_large_models/",
          "publishedOn": "2023-10-01T11:34:38.000Z",
          "wordCount": 2788,
          "title": "[D] Duplicating layers in large models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wn8qu/n_introducing_raudioai_any_ai_you_can_hear/",
          "author": null,
          "description": "I couldn't find any AI sub dedicated to audio, so I’ve created r/AudioAI to serve as a hub for everything at the intersection of artificial intelligence and the world of sounds.\n AI-driven music, speech, audio production, and all other AI audio technologies.\n If anyone wants to be part of mod, let me know!\n    submitted by    /u/chibop1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wn8qu/n_introducing_raudioai_any_ai_you_can_hear/",
          "publishedOn": "2023-10-01T00:52:01.000Z",
          "wordCount": 2646,
          "title": "[n] Introducing r/AudioAI: Any AI You Can Hear!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wjrnu/phandling_categorical_missing_data_in_churn/",
          "author": null,
          "description": "I am working on a telecom dataset where I need to fit a model to for predicting churn(yes or no). There are a lot of categorical data with missing values( total values 7043). What is the best way to handle missing data in this case, is it better to ignore it or any other better imputation method?\n Data columns (total 21 columns): customerID 7043 non-null object gender 7043 non-null object Age 7043 non-null int64 Partner 7043 non-null object Dependents 7043 non-null object tenure 7043 non-null int64 PhoneService 7043 non-null object MultipleLines 6500 non-null object InternetService 6500 non-null object OnlineSecurity 7043 non-null object OnlineBackup 7043 non-null object DeviceProtection 7043 non-null object TechSupport 7043 non-null object StreamingTV 6500 non-null object StreamingMovies 6500 non-null object Contract 6500 non-null object PaperlessBilling 7043 non-null object PaymentMethod 6500 non-null object MonthlyCharges 7043 non-null float64 TotalCharges 7043 non-null object Churn 7043 non-null object \n    submitted by    /u/guyloveskissing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wjrnu/phandling_categorical_missing_data_in_churn/",
          "publishedOn": "2023-09-30T22:22:07.000Z",
          "wordCount": 2741,
          "title": "[P]Handling categorical missing data in churn prediction model for telecom data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wf3lk/d_how_can_you_estimate_inference_speed_of_a_nn/",
          "author": null,
          "description": "How, outside of testing, do you estimate how quickly a specific model will run on some hardware? Anything about time is rarely mentioned in papers and if it is, it's more likely to talk about training, unless authors are specifically proud of their speed (like YOLO). Even less so in any README.\n Some way to translate numbers of parameters into seconds on a given GPU/CPU, any rules of thumb better than just setting up everything every time?\n    submitted by    /u/teleoflexuous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wf3lk/d_how_can_you_estimate_inference_speed_of_a_nn/",
          "publishedOn": "2023-09-30T19:10:51.000Z",
          "wordCount": 2676,
          "title": "[D] (How) Can you estimate inference speed of a NN model on given hardware?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wcbhg/d_how_do_i_begin_with_ai/",
          "author": null,
          "description": "I'm fairly new to the Al domain. I've decent python knowledge. I've gone through a lot of YouTube tutorials and got stuck in the tutorial hell. After struggling through hours of videos came here as my only last hope !!. How do I begin? What python frameworks should I learn? Which particular books should I refer ?\n    submitted by    /u/Dry_Ad_3887  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wcbhg/d_how_do_i_begin_with_ai/",
          "publishedOn": "2023-09-30T17:15:53.000Z",
          "wordCount": 2650,
          "title": "[D] How do I begin with AI ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wbqcd/d_struggling_to_get_interviews_what_to_do/",
          "author": null,
          "description": "Edit: I am a USA citizen so no need for sponsorship.\n I have 4 yoe in a start up company and a phd four publications 2 in high level math journals and 2 CV/DL papers in A journals and also 4 patents. I have experience with most common Cv tasks eg object detection, Multi object tracking, 2d/3d human pose estimation and monocular depth estimation. I’m well versed in typical network building blocks eg conv nets, FFNs, transformers, Diffusion etc. I have a little experience with NLP like NLTK and TTS networks. Also some other general dev technologies like ec2,s3,sql,mongoose, etc. \n That all being said I can’t seem to even get interviews these days just straight rejections not talking to recruiters. On the other hand in 2020, I was just searching for jobs passively and had something like a 75% success rate with getting interviews. I know the job market has changed but I’m a lot more experienced at this time than then and having abysmal luck.\n Anyone have any advice would be happy to share my resume if that would make it easier to give advice. Also open to hearing what other technologies o should/could learn.\n    submitted by    /u/AbjectDrink3276  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wbqcd/d_struggling_to_get_interviews_what_to_do/",
          "publishedOn": "2023-09-30T16:51:12.000Z",
          "wordCount": 2789,
          "title": "[D] Struggling to get interviews what to do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w9kz7/arxiv_dives_segment_anything/",
          "author": null,
          "description": "Every Friday for the past few months we’ve been hosting a public paper club called “Arxiv Dives”. We pick a paper and dive deep into it and chat about it as a group.\n There are a lot of gems of knowledge hidden in these research papers, and the main motivation is simply to keep up with most impactful techniques in the field by taking the time to dive in and discuss. \n The attendees so far have been great, and would love for anyone is interested to join!\n https://lu.ma/oxenbookclub\n    submitted by    /u/FallMindless3563  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w9kz7/arxiv_dives_segment_anything/",
          "publishedOn": "2023-09-30T15:20:55.000Z",
          "wordCount": 2691,
          "title": "Arxiv [D]ives - Segment Anything",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w7lcl/d_what_exactly_are_the_compute_requirements_for/",
          "author": null,
          "description": "Hi, New to ML, I can't find a clear answer to this question. I find references online to a 1.8 trillion parameter model taking up the computational power of a 10B model, yet I also hear that the memory requirements a lot higher for an MoE?\n If I was interested in training/inferencing, for example, a 15M dense model, or a 60M MoE with 4 15M experts. whats the difference gonna be?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w7lcl/d_what_exactly_are_the_compute_requirements_for/",
          "publishedOn": "2023-09-30T14:00:29.000Z",
          "wordCount": 2671,
          "title": "[D] What exactly are the compute requirements for training a dense model versus an MoE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w3ydj/d_how_close_are_we_to_neurosymbolic_architectures/",
          "author": null,
          "description": "I’m new to AI/ML and my understanding is that (1) LLMs are SOTA in many tasks, and their short comings, such as ~70% accuracy, hallucinations, inability to learn from small samples etc, are well known. (2) Neuro-symbolic approaches are apparently the way to get accuracy to 100% and solve other shortcomings.\n So question is (3) What are the promising research in LLMs+Symbolic architectures? (4) And how close is it to production, rather than academic? (5) Do we need non-LLM based architectures instead?\n    submitted by    /u/reeldeele  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w3ydj/d_how_close_are_we_to_neurosymbolic_architectures/",
          "publishedOn": "2023-09-30T11:00:41.000Z",
          "wordCount": 2673,
          "title": "[D] How close are we to Neuro-Symbolic architectures that are 100% accurate?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w2jtj/d_how_to_integrate_fine_tuned_llama_2_in_website/",
          "author": null,
          "description": "I'm absolute beginner in Machine Learning. Me and My team are building a Chat Bot that recommends medicine based on symptoms, for that we are fine tuning LLAMA 2. Uploading BOOKS to train and we will ask question based on that books. SomeHow I got code on github to FineTune LLAMA 2. But how can I Integrate in my website ? How to connect it in my web app. Need some guidance. We have submission in 2 weeks.\n If anyone is willing to mentor us in this project or just guide what to do.\n    submitted by    /u/BookAny3024  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w2jtj/d_how_to_integrate_fine_tuned_llama_2_in_website/",
          "publishedOn": "2023-09-30T09:36:34.000Z",
          "wordCount": 2690,
          "title": "[D] How to Integrate fine tuned LLAMA 2 in website ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w0tse/d_what_algorithms_to_use_text_classification/",
          "author": null,
          "description": "I have some data - twitter description of an event in text and the event itself. If I have 100000 tweets in column X and a category in Y - e.g sporting event review, movie review, news, etc what is the best algorithm to match them. Should I make the description a bag of words and depending on the word frequency I can train a ML model (random forest,svm,etc.) or can the algorithm take into account the order.\n    submitted by    /u/AnyJello605  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w0tse/d_what_algorithms_to_use_text_classification/",
          "publishedOn": "2023-09-30T07:46:50.000Z",
          "wordCount": 2670,
          "title": "[D] What algorithms to use text classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w08p1/d_deploy_the_mistral_7b_generative_model_on_an/",
          "author": null,
          "description": "Hello,\n The Mistral 7b AI model beats LLaMA 2 7b on all benchmarks and LLaMA 2 13b in many benchmarks. It is actually even on par with the LLaMA 1 34b model.\n So I made a quick video about how to deploy this model on an A10 GPU on an AWS EC2 g5.4xlarge instance:\n https://nlpcloud.com/deploy-mistral-7b-on-a10-gpu-on-aws.html\n I hope it will be useful. If you have recommendations about how to improve this video please don't hesitate to let me know, that will be very much appreciated!\n Julien\n    submitted by    /u/juliensalinas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w08p1/d_deploy_the_mistral_7b_generative_model_on_an/",
          "publishedOn": "2023-09-30T07:11:38.000Z",
          "wordCount": 2683,
          "title": "[D] Deploy the Mistral 7b Generative Model on an A10 GPU on AWS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vvh84/d_cider_values_in_pali_model_and_xm_3600_dataset/",
          "author": null,
          "description": "I am reading PaLI: A Jointly-Scaled Multilingual Language-Image Model . In their table 2 (page 6), it's reported that Thapliyal et al. (2022) (0.8B) model got 57.6 of CIDEr on XM 3600 for English. Thapliyal et al. (2022) is Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset. However in this paper, the CIDEr values are reported less than 1. For example, the largest model got 0.584 of CIDEr on XM 3600 for English.\n Could someone explain to me why those values have great differences?\n    submitted by    /u/KingsmanVince  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vvh84/d_cider_values_in_pali_model_and_xm_3600_dataset/",
          "publishedOn": "2023-09-30T02:46:43.000Z",
          "wordCount": 2678,
          "title": "[D] CIDEr values in PaLI model and XM 3600 dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vshvy/r_pathway_to_selflearning_mathematics_and/",
          "author": null,
          "description": "Hey everyone. I am very passionate about getting in ML research and was wondering what the learning pathway was, particularly with regards to the theoretical Math and Statistics involved.\n For context:\n  \nI am a second year undergraduate. By the end of this year, I will have taken and finished A Multivariable Calculus with Proofs course, so that is my current starting point.\n I have been working with ML for the last 3 years and am proficient in Python and frameworks like PyTorch.\n I have also made my own implementation of several research papers (LSTMs, GRUs, Transformers, ELMo, BERT, GPT, as well as a few computer vision papers).\n  \nI have a good general intuition of how deep learning works, but I want to formalise this knowledge with the adequate mathematical background so that I can eventually pursue a career in research. I understand that I have plenty of time until I reach there, and I am willing to dedicate it to grinding out the math and statistical knowledge required.\n I have done my research on this sub and other forums, and here are a few resources that stood out:\n  \nMathematics for Machine Learning by Deisenroth, Faisal and Ong\n Advanced Calculus of Several Variables by C. H. Edwards Jr.\n Mathematical Methods Lecture Notes from Imperial College by Deisenroth and Cheraghchi\n The original information theory paper by Shannon\n The Elements of Statistical Learning by Hastie, Tibshirani and Friedman\n Pattern Recognition and Machine Learning by Bishop\n The Probabalistic Machine Learning Series by Kevin P. Murphy\n Deep Learning by Goodfellow, Bengio and Courville\n Mathematics of Machine Learning on MIT OCW (here)\n  \nMy question is, what order should I start self-learning in, given the (somewhat limited) background knowledge I have? Also, are there any other resources that would help?\n    submitted by    /u/Far_Clothes_5054  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vshvy/r_pathway_to_selflearning_mathematics_and/",
          "publishedOn": "2023-09-30T00:30:39.000Z",
          "wordCount": 2888,
          "title": "[R] Pathway to self-learning mathematics and statistics for ML research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vs7qd/d_what_is_the_best_opensource_framework_to_create/",
          "author": null,
          "description": "Hi everyone,\n With the different data points, such as phi-1.5 performance being as good as 7b models on some tasks, it seems to be plausible that small models can be quite capable on specific tasks.\n I am working on BlindChat, an open-source and private solution to run small LLMs on your browser and I am interested in fine-tuning a phi-1.5 on some domain specific data.\n I am thinking of having an approach similar to the researchers of the phi paper, which is creating a high quality dataset using GPT3.5 / GPT4. \n Do you know good open-source frameworks that make it easy to create a high quality data for a specific task using an existing large model, like GPT3.5/4 or Llama 2 70b?\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vs7qd/d_what_is_the_best_opensource_framework_to_create/",
          "publishedOn": "2023-09-30T00:18:49.000Z",
          "wordCount": 2726,
          "title": "[D] What is the best open-source framework to create a synthetic and domain specific dataset for fine-tuning small models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vrts5/p_how_do_i_train_or_tune_an_llm_like_llama_for_my/",
          "author": null,
          "description": "I want to tune Facebook's LLaMA or any available LLM model to be able to answer questions about my business. The idea is to provide a prompt of the business and some Q&As, then based on the provided information, the AI chatbot will answer customers who ask questions about the business. If the answers to the questions are not known or the question is not relevant, the bot should say \"I dont know\".\n    submitted by    /u/the_aceix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vrts5/p_how_do_i_train_or_tune_an_llm_like_llama_for_my/",
          "publishedOn": "2023-09-30T00:03:02.000Z",
          "wordCount": 2672,
          "title": "[P] How do I train or tune an LLM like LLaMA for my business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vq1a0/r_drive_like_a_human_rethinking_autonomous/",
          "author": null,
          "description": "Paper - https://arxiv.org/abs/2307.07162\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vq1a0/r_drive_like_a_human_rethinking_autonomous/",
          "publishedOn": "2023-09-29T22:49:36.000Z",
          "wordCount": 2594,
          "title": "[R] Drive Like a Human: Rethinking Autonomous Driving with Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vosgf/research_resource_to_query_ml_and_llm_based/",
          "author": null,
          "description": "Made a repo for you all to try using a collaborative AI tool which includes 100+ papers on LLM-Based-Agents. You can try out the repo here: https://www.collama.ai/varun/llm-based-agents\n    submitted by    /u/_llama2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vosgf/research_resource_to_query_ml_and_llm_based/",
          "publishedOn": "2023-09-29T22:00:57.000Z",
          "wordCount": 2616,
          "title": "[Research] - Resource to query ML and LLM based research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vnzgc/d_choosing_the_best_learning_model_for_a_start_up/",
          "author": null,
          "description": "Straight off the bat: I am not very familiar but was tasked to find a suggest a reasonable model for our need.\n Here is a bit what I read:\n  \nhttps://www.obviously.ai/post/how-to-choose-the-right-ai-model-for-your-application\n https://www.addevice.io/blog/ai-framework-for-app-development\n  \nThe app that I am working on is an education app, and the purpose of the AI would be to (at least in terms of priority) generate a post subject line / topic to discuss.\n The company is super small, so money is important. JS is being used mainly at the moment.\n What would be a good choice for a small start up to generate topics for an education app used by schools?\n At least any ideas or things to consider would be wonderful to get my rabbit hole dive started! Thanks.\n    submitted by    /u/Willy988  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vnzgc/d_choosing_the_best_learning_model_for_a_start_up/",
          "publishedOn": "2023-09-29T21:30:19.000Z",
          "wordCount": 2719,
          "title": "[D] Choosing the best learning model for a start up app?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vmmxz/r_gsgen_textto3d_using_gaussian_splatting/",
          "author": null,
          "description": "Project Page\n Paper\n Code \n  \nIn this paper, we present Gaussian Splatting based text-to-3D generation (GSGEN), a novel approach for generating high-quality 3D objects. Previous methods suffer from inaccurate geometry and limited fidelity due to the absence of 3D prior and proper representation. We leverage 3D Gaussian Splatting, a recent state-of-the-art representation, to address existing shortcomings by exploiting the explicit nature that enables the incorporation of 3D prior. Specifically, our method adopts a progressive optimization strategy, which includes a geometry optimization stage and an appearance refinement stage. In geometry optimization, a coarse representation is established under a 3D geometry prior along with the ordinary 2D SDS loss, ensuring a sensible and 3D-consistent rough shape. Subsequently, the obtained Gaussians undergo an iterative refinement to enrich details. In this stage, we increase the number of Gaussians by compactness-based densification to enhance continuity and improve fidelity. With these designs, our approach can generate 3D content with delicate details and more accurate geometry. Extensive evaluations demonstrate the effectiveness of our method, especially for capturing high-frequency components.\n  \n   submitted by    /u/Sirisian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vmmxz/r_gsgen_textto3d_using_gaussian_splatting/",
          "publishedOn": "2023-09-29T20:38:01.000Z",
          "wordCount": 2760,
          "title": "[R] Gsgen: Text-to-3D using Gaussian Splatting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vmlg0/d_does_anyone_else_feel_like_mojo_isnt_getting/",
          "author": null,
          "description": "https://docs.modular.com/mojo/\n    submitted by    /u/hai_cben  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vmlg0/d_does_anyone_else_feel_like_mojo_isnt_getting/",
          "publishedOn": "2023-09-29T20:36:20.000Z",
          "wordCount": 2599,
          "title": "[D] Does anyone else feel like MOJO isn't getting the attention it deserves?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vkwhk/p_carton_run_any_ml_model_from_any_programming/",
          "author": null,
          "description": "Hi! I just open-sourced a project that I've been working on for a while and wanted to see what you think!\n The goal of Carton (https://carton.run) is to let you use a single interface to run any machine learning model from any programming language.\n It’s currently difficult to integrate models that use different technologies (e.g. TensorRT, Ludwig, TorchScript, JAX, GGML, etc) into your application, especially if you’re not using Python. Even if you learn the details of integrating each of these frameworks, running multiple frameworks in one process can cause hard-to-debug crashes.\n Ideally, the ML framework a model was developed in should just be an implementation detail. Carton lets you decouple your application from specific ML frameworks so you can focus on the problem you actually want to solve.\n At a high level, the way Carton works is by running models in their own processes and using an IPC system to communicate back and forth with low overhead. Carton is primarily implemented in Rust, with bindings to other languages. There are lots more details linked in the architecture doc below.\n Importantly, Carton uses your model’s original underlying framework (e.g. PyTorch) under the hood to actually execute the model. This is meaningful because it makes Carton composable with other technologies. For example, it’s easy to use custom ops, TensorRT, etc without changes. This lets you keep up with cutting-edge advances, but decouples them from your application.\n I’ve been working on Carton for almost a year now and I open sourced it on Wednesday!\n Some useful links:\n  \nWebsite, docs, quickstart - https://carton.run\n Explore existing models - https://carton.pub\n Repo - https://github.com/VivekPanyam/carton\n Architecture - https://github.com/VivekPanyam/carton/blob/main/ARCHITECTURE.md\n  \nPlease let me know what you think!\n    submitted by    /u/vpanyam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vkwhk/p_carton_run_any_ml_model_from_any_programming/",
          "publishedOn": "2023-09-29T19:28:10.000Z",
          "wordCount": 2874,
          "title": "[P] Carton – Run any ML model from any programming language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vje52/p_location_computation/",
          "author": null,
          "description": "Hi Everyone, \n I’m doing a project where I’m crowdsourcing a lot of location data for a set of location labels and then trying to cluster it for each and using the centroid of the cluster as the most accurate location for that location label. \n The data keeps coming in everyday. I’m not sure when to stop computation. Initially I thought I’ll check the delta between each days centroid computed and if the delta falls under a threshold then stop computing. \n But now I’m thinking if my daily data collected gets marked as outliers, subsequent days centroids won’t have much of a delta and it will pass my convergence condition. \n Any suggestions?\n    submitted by    /u/Longjumping-Song4958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vje52/p_location_computation/",
          "publishedOn": "2023-09-29T18:31:06.000Z",
          "wordCount": 2699,
          "title": "[P] Location Computation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vfuzb/dr_deploying_deep_models_on_memory_constrained/",
          "author": null,
          "description": "Suppose we want to use a deep learning model on a gpu within our app. We want this model to coexist on the gpu with other processes, effectively limit it's possible usage of resources.\n As cuDNN/cuBLAS routines are nondeterministic and possibly dynamically allocate variable amount of memory, how do people manage this problem? Is it a problem at all? Estimating memory usage of deep learning models on gpu is notoriously hard. There is a research paper from Microsoft tackling this problem and they mispredict the usage of memory by 15% on average. Some cpu BLAS libraries like openBLAS or MKL also dynamically allocate the memory, but there are alternatives - LAPACK as far as I know uses only the memory provided by the caller, making it viable option for applications in embedded.\n In safety crit…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vfuzb/dr_deploying_deep_models_on_memory_constrained/",
          "publishedOn": "2023-09-29T16:14:04.000Z",
          "wordCount": 2964,
          "title": "[D][R] Deploying deep models on memory constrained devices",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ve2ij/d_best_sequence_embedding_models/",
          "author": null,
          "description": "Which are currently the best Sentence Embedding pre-trained models out there?\n    submitted by    /u/Uilxitora  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ve2ij/d_best_sequence_embedding_models/",
          "publishedOn": "2023-09-29T15:04:32.000Z",
          "wordCount": 2601,
          "title": "[D] Best Sequence Embedding Models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vd8u8/d_using_gamification_to_demystify_the_ai_blackbox/",
          "author": null,
          "description": "Blog about AI \"black box\" nature and how it can be explained and become engaging to users using gamification. Explained with example from open-appsec an open-source machine learning-based Web Application & API Security product.\n https://www.openappsec.io/post/using-gamification-to-demystify-the-ai-black-box-in-a-waf-product\n https://github.com/openappsec/openappsec\n    submitted by    /u/onirisapp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vd8u8/d_using_gamification_to_demystify_the_ai_blackbox/",
          "publishedOn": "2023-09-29T14:31:37.000Z",
          "wordCount": 2623,
          "title": "[D] Using Gamification to demystify the AI black-box",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vc1kc/project_startup_job_postcontractor_role/",
          "author": null,
          "description": "Hey all!\n I'm in the throws of doing a startup and looking for someone to help build a legal tech platform. I can discuss more in person, but it is intended to be a human/lawyer in the loop workflow tool for complex contract and deal analysis. Base product is built and deployed.\n I'm a former developer turned lawyer with 15 years corporate experiences, and need help/talent/co-founder to help take things to the next level. Ideally you have a mixture of NLP and regular software engineering background and just a very practical approach. If you've played with LLM's all the better.\n Options for cash, equity, larger roles are all on the table. Just looking for the right talent. DM me if you are interested and lets talk about experience, etc.!\n And it seems that tags are turned off in here, so not sure how to tag something as [Project] but I put it in the title.\n    submitted by    /u/pudgyplacater  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vc1kc/project_startup_job_postcontractor_role/",
          "publishedOn": "2023-09-29T13:44:05.000Z",
          "wordCount": 2745,
          "title": "[Project] Startup Job Post/Contractor role",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vc0hp/r_realfill_referencedriven_generation_for/",
          "author": null,
          "description": "Project page: https://realfill.github.io/\n Paper: https://arxiv.org/abs/2309.16668\n RealFill is able to complete the image with what should have been there.\n Abstract\n  \nRecent advances in generative imagery have brought forth outpainting and inpainting models that can produce high-quality, plausible image content in unknown regions, but the content these models hallucinate is necessarily inauthentic, since the models lack sufficient context about the true scene. In this work, we propose RealFill, a novel generative approach for image completion that fills in missing regions of an image with the content that should have been there. RealFill is a generative inpainting model that is personalized using only a few reference images of a scene. These reference images do not have to be aligned with the target image, and can be taken with drastically varying viewpoints, lighting conditions, camera apertures, or image styles. Once personalized, RealFill is able to complete a target image with visually compelling contents that are faithful to the original scene. We evaluate RealFill on a new image completion benchmark that covers a set of diverse and challenging scenarios, and find that it outperforms existing approaches by a large margin.\n  \n​\n    submitted by    /u/StrawberryNumberNine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vc0hp/r_realfill_referencedriven_generation_for/",
          "publishedOn": "2023-09-29T13:42:47.000Z",
          "wordCount": 2772,
          "title": "[R] RealFill: Reference-Driven Generation for Authentic Image Completion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vbsqh/r_listen2scene_interactive_materialaware_binaural/",
          "author": null,
          "description": "https://www.youtube.com/watch?v=aNJWCwG-H_U\n    submitted by    /u/Snoo63916  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vbsqh/r_listen2scene_interactive_materialaware_binaural/",
          "publishedOn": "2023-09-29T13:33:19.000Z",
          "wordCount": 2597,
          "title": "[R] Listen2Scene: Interactive material-aware binaural sound propagation for reconstructed 3D scenes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vbs0o/r_m3audiodec_multichannel_multispeaker/",
          "author": null,
          "description": "Paper : https://arxiv.org/abs/2309.07416\n Demo : https://anton-jeran.github.io/MAD/\n Code : https://github.com/anton-jeran/MULTI-AUDIODEC\n    submitted by    /u/Snoo63916  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vbs0o/r_m3audiodec_multichannel_multispeaker/",
          "publishedOn": "2023-09-29T13:32:27.000Z",
          "wordCount": 2601,
          "title": "[R] M3-AUDIODEC: Multi-channel multi-speaker multi-spatial audio codec",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vbnbt/r_the_future_of_romance_novel_techniques_for/",
          "author": null,
          "description": "submitted by    /u/TobyWasBestSpiderMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vbnbt/r_the_future_of_romance_novel_techniques_for/",
          "publishedOn": "2023-09-29T13:26:45.000Z",
          "wordCount": 2616,
          "title": "[R] The Future of Romance: Novel Techniques for Replacing your Boyfriend with Generative AI (parody)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16v6ihg/classical_nlp_course_d/",
          "author": null,
          "description": "Classical NLP course recommendation\n Can you recommend me NLP course that dives into classical NLP methods: For example:\n HMM MaxEnt CKY algo Sytactic parsing Dependency Parsing\n    submitted by    /u/Thick-brain-dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16v6ihg/classical_nlp_course_d/",
          "publishedOn": "2023-09-29T09:02:57.000Z",
          "wordCount": 2615,
          "title": "Classical NLP course [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16v1z14/d_multitask_learning_leads_to_overfitting_is_this/",
          "author": null,
          "description": "I have a CNN model, call it model M. It was trained on dataset A for object pose estimation. After training for 100 epochs, it resulted in these losses:\n  \nTrain: 0.06\n Val: 0.08\n  \nAs dataset A is somewhat limited, I wonder if I can incorporate additional data via a different, but related task: object segmentation for similar objects. Model M is a UNet, so I can incorporate this task simply with an additional output channel in the last layer. \n I add dataset B for object segmentation. During training, M learns on both datasets quite well, which suggests to me that the tasks are well-aligned. After 100 epochs, I get these losses on dataset A:\n  \nTrain: 0.06\n Val: 0.16\n  \nThis is surprising to me. If I get the same training loss on dataset A, while training on additional data. I'd expect the validation loss to be lower, since I'm training on 2x the data. Yet the validation performance is consistently higher when I train on both datasets. \n The only explanation I can think of is the double descent phenomenon. Perhaps when I trained only on dataset A, I was significantly over-parameterized, but past the interpolation threshold. So perhaps adding more data brought me closer to the interpolation threshold, leading to worse generalization.\n Does this explanation seem likely? Has anyone had similar experiences?\n    submitted by    /u/murrdpirate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16v1z14/d_multitask_learning_leads_to_overfitting_is_this/",
          "publishedOn": "2023-09-29T04:31:27.000Z",
          "wordCount": 2818,
          "title": "[D] Multi-task learning leads to overfitting. Is this the double descent phenomenon?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uyboe/d_whats_the_relationship_between_denoising/",
          "author": null,
          "description": "Hello, denoising autoencoders is when you train something to reverse x+n -> x. This seems to be basically the same as a diffusion model, more so if you see the U-Net diffusion model, which is effectively an information bottleneck.\n    submitted by    /u/windoze  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uyboe/d_whats_the_relationship_between_denoising/",
          "publishedOn": "2023-09-29T01:34:28.000Z",
          "wordCount": 2634,
          "title": "[D] What's the relationship between Denoising Autoencoders and Diffusion Models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ux9xt/d_how_is_this_sub_not_going_ballistic_over_the/",
          "author": null,
          "description": "For a quick disclaimer, I know people on here think the sub is being flooded by people who arent ml engineers/researchers. I have worked at two FAANGS on ml research teams/platforms. \n My opinion is that GPT-4 Vision/Image processing is out of science fiction. I fed chatgpt an image of a complex sql data base schema, and it converted it to code, then optimized the schema. It understood the arrows pointing between table boxes on the image as relations, and even understand many to one/many to many. \n I took a picture of random writing on a page, and it did OCR better than has ever been possible. I was able to ask questions that required OCR and a geometrical understanding of the page layout. \n Where is the hype on here? This is an astounding human breakthrough. I cannot believe how much ML is now obsolete as a result. I cannot believe how many computer science breakthroughs have occurred with this simple model update. Where is the uproar on this sub? Why am I not seeing 500 comments on posts about what you can do with this now? Why are there even post submissions about anything else?\n    submitted by    /u/corporate_autist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ux9xt/d_how_is_this_sub_not_going_ballistic_over_the/",
          "publishedOn": "2023-09-29T00:48:00.000Z",
          "wordCount": 2794,
          "title": "[D] How is this sub not going ballistic over the recent GPT-4 Vision release?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uwqx1/p_vllm_with_mistral_7b_guide/",
          "author": null,
          "description": "Hey all - vllm==0.2.0 got released a couple of hours ago and I put together some code to get it running with the new Mistral 7B model. Also included are some benchmarks for different input batch sizes with the model (output capped at 200 tokens):\n  \n Batch size Tokens /s \n  \n 1 46 \n  10 400 \n  60 1.8k \n \n Hope it's useful, let me know if you'd like any more info!\n Here's the link:\n https://docs.mystic.ai/docs/mistral-ai-7b-vllm-fast-inference-guide\n    submitted by    /u/paulcjh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uwqx1/p_vllm_with_mistral_7b_guide/",
          "publishedOn": "2023-09-29T00:25:33.000Z",
          "wordCount": 2658,
          "title": "[P] vLLM with Mistral 7B guide",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ur7h1/n_we_collaborated_with_outerbounds_to_enable_hpc/",
          "author": null,
          "description": "Here is our blog post - please check it out: https://forums.autodesk.com/t5/engineering-hub-blog/autodesk-and-outerbounds-partner-to-open-source-ray-and-hpc/ba-p/12254816\n And try out the metaflow-ray extension here: https://github.com/outerbounds/metaflow-ray\n    submitted by    /u/rirhun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ur7h1/n_we_collaborated_with_outerbounds_to_enable_hpc/",
          "publishedOn": "2023-09-28T20:49:55.000Z",
          "wordCount": 2613,
          "title": "[N] We Collaborated with Outerbounds to Enable HPC and Ray Integration in Metaflow",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ur4zb/d_what_are_the_options_for_the_most_human_tts/",
          "author": null,
          "description": "So I’ve been using elevenlabs but it burns through characters really fast. What are the best options for the most human sounding TTS available? I’ve been looking into tortoise, but would like to see if there are other options I should be looking into.\n    submitted by    /u/Long8D  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ur4zb/d_what_are_the_options_for_the_most_human_tts/",
          "publishedOn": "2023-09-28T20:47:07.000Z",
          "wordCount": 2635,
          "title": "[D] What are the options for the most human TTS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16unpn9/d_how_do_we_know_closed_source_released/",
          "author": null,
          "description": "I've recently started working with ML and NLP, so I'm sorry if this sounds Naive.\n Unlike Llama 2 or other open source, we don't have access to the model weights for GPT-4, Claude or Bard, so Benchmark Evals are being run through either APIs or the chat Interface. So how do we know that the model isn't being Boosted by custom web-searching abilities or RAG? While GPT-4 might have a turnoff option, I'm pretty sure Bard is always online, being built by google. So how do we trust benchmarks? Also, have any opensource been tested after Websearch/RAG?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16unpn9/d_how_do_we_know_closed_source_released/",
          "publishedOn": "2023-09-28T18:34:49.000Z",
          "wordCount": 2694,
          "title": "[D] How do we know Closed source released benchmarks aren't being heavily optimized, through outside means?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ulks3/r_searching_for_a_regression_dataset_with/",
          "author": null,
          "description": "I am searching for a relatively simple dataset to train a regressor that has some structure in its predictions. Can't be too tiny cause I have to try out a NN architecture. It must have at least some continuous feature but can also have additional categorical or related discrete structures. I usually work with vision tasks, so I am not sure if I miss something obvious I could try? Open for ideas! \n I thoughts about predicting rows in some tabular dataset? Anything suitable that comes to mind?\n    submitted by    /u/LeanderKu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ulks3/r_searching_for_a_regression_dataset_with/",
          "publishedOn": "2023-09-28T17:08:23.000Z",
          "wordCount": 2679,
          "title": "[R] Searching for a regression dataset with structure in its prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uldmh/n_cuda_architect_and_cofounder_of_mlperf_amds/",
          "author": null,
          "description": "Greg Diamos, the CTO of startup Lamini, was an early CUDA architect at NVIDIA and later cofounded MLPerf. \n He asserts that AMD's ROCM has \"achieved software parity\" with CUDA for LLMs.\n Lamini, focused on tuning LLM's for corporate and institutional users, has decided to go all-in with AMD Instict GPU's.\n https://www.crn.com/news/components-peripherals/llm-startup-embraces-amd-gpus-says-rocm-has-parity-with-nvidia-s-cuda-platform\n    submitted by    /u/makmanred  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uldmh/n_cuda_architect_and_cofounder_of_mlperf_amds/",
          "publishedOn": "2023-09-28T17:00:36.000Z",
          "wordCount": 2647,
          "title": "[N] CUDA Architect and Cofounder of MLPerf: AMD's ROCM has achieved software parity with CUDA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ukolg/p_request_to_test_mirage_a_platform_to_search_and/",
          "author": null,
          "description": "Mirage is the infinite asset library that helps you find or create the perfect digital asset.\n 🗨️ Just Search Naturally: No awkward keywords—Mirage understands you.\n 🤖 State-of-the-Art Models: Can't find it? Generate it, thanks to open-source models.\n 🔍 Similarity Search: Discover more of what you love with a single click.\n 🤗 Fully Personalized: Our AI librarian learns your style to show you assets you'll dig.\n Website Link: MirageML\n Open-Source Github: Github\n Development Status: Beta\n I would love to get some honest feedback!\n    submitted by    /u/perception-eng  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ukolg/p_request_to_test_mirage_a_platform_to_search_and/",
          "publishedOn": "2023-09-28T16:32:36.000Z",
          "wordCount": 2683,
          "title": "[P] Request to test Mirage: A platform to search and generate images, videos, audio, and 3D assets using natural language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uivnf/p_request_to_test_domeis_a_new_platform_for/",
          "author": null,
          "description": "Domeis is a no-code Machine Learning platform that offers a dashboard to design, train and test Machine Learning algorithms, as well as to import, pre-process and cleanse data, all from the Graphical User Interface and without writing a single line of code.\n The aim of this platform is two-fold:\n  \nMaking Machine Learning accessible to anyone and not just Data Scientists or experienced software developers. By offering the possibility to design, train and test Machine Learning models directly via GUI, being an experienced software developer is no longer a pre-condition for creating ML models\n Making Machine Learning model creation, training and testing faster for experienced Data Scientists / Machine Learning Engineers. By drastically reducing the time needed to set up environments, import data and define models, Domeis allows Machine Learning practitioners to focus on trying out and compare different models/approaches.\n  \nWebsite Link: https://www.domeis.it/\n Development Status: Alpha\n I would love to get some honest feedback!\n    submitted by    /u/Ok_Hold_5385  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uivnf/p_request_to_test_domeis_a_new_platform_for/",
          "publishedOn": "2023-09-28T15:21:52.000Z",
          "wordCount": 2746,
          "title": "[P] Request to test Domeis: A new platform for no-code Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uibr4/d_help_understanding_convergence_proof_adaptive/",
          "author": null,
          "description": "Hello everyone,\n I am trying to understand the convergence analysis/derivation of the momentum algorithm, or the stochastic heavy ball algorithm, using the regret bound analysis from different research papers. \n  \nhttps://ieeexplore.ieee.org/document/7330562 - Page3\n \nhttps://www.mdpi.com/2504-3110/6/12/709 - Page6\n \nhttp://arxiv.org/abs/1707.01647 - Page4\n \n ​\n In the derivation, there is the following simplification, which I do not understand at all\n ​\n $\\frac{2\\boldsymbol{\\eta}_{k}}{(1-\\beta)}\\sum_{k=0}^{T}\\left|J(\\theta_k) - J(\\theta^*)\\right| + \\frac{2\\boldsymbol{\\eta}_{k}\\beta}{(1-\\beta)^2} \\sum_{k=0}^{T}\\left|J(\\theta_k) - J(\\theta_{k-1})\\right| \\leq \\ \\left|\\boldsymbol{\\theta}_{0} + \\boldsymbol{p}_{0} - \\boldsymbol{\\theta}^* \\right|^2 - \\left|\\boldsymbol{\\theta}_{T+1} + \\boldsymbol…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uibr4/d_help_understanding_convergence_proof_adaptive/",
          "publishedOn": "2023-09-28T15:00:31.000Z",
          "wordCount": 2843,
          "title": "[D] Help understanding convergence proof (Adaptive learning rate + Momentum)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ui0vx/dany_researchers_or_institutions_in_usa_that/",
          "author": null,
          "description": "I have tried to follow the main collaborators of Hutter and other prominent scientists to track this, but they are mostly in Europe with some in Australia. American institutions seems to be more interested in more open ai like deep neural networks. If anyone is familiar with any US based institutions that does notable work in this line,please comment\n    submitted by    /u/Netero1999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ui0vx/dany_researchers_or_institutions_in_usa_that/",
          "publishedOn": "2023-09-28T14:48:03.000Z",
          "wordCount": 2653,
          "title": "[D]Any researchers or institutions in USA that follows Ai-compression relationships specifically like deepmind",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ui0br/r_brain_tumor_segmentation/",
          "author": null,
          "description": "Can any of you suggest me computer science research ideas related to brain tumor segmentation using UNet.\n    submitted by    /u/Eleonora467  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ui0br/r_brain_tumor_segmentation/",
          "publishedOn": "2023-09-28T14:47:25.000Z",
          "wordCount": 2602,
          "title": "[R] Brain Tumor segmentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ugkmc/p_bionicgpt_chatgpt_replacement_that_lets_you_run/",
          "author": null,
          "description": "BionicGPT is an open source WebUI that gives enterprises the ability to run Retrieval Augmented Generation (RAG) on their on premise documents.\n To allow people to get up to speed we deploy with a quantized 7B model that runs on CPU.\n Github Repo: https://github.com/purton-tech/bionicgpt\n We basically implement a RAG pipeline including document upload, embeddings generation and subsequent retrieval.\n Feedback:\n We'd love to get some feedback in the form or github issues or comments here.\n Screenshot:\n https://preview.redd.it/uiw0wqul30rb1.png?width=2447&format=png&auto=webp&s=8ad7e61ed048258c19aa63bf7c94d12da5b721fa\n    submitted by    /u/purton_i  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ugkmc/p_bionicgpt_chatgpt_replacement_that_lets_you_run/",
          "publishedOn": "2023-09-28T13:48:37.000Z",
          "wordCount": 2669,
          "title": "[P] BionicGPT - ChatGPT replacement that let's you run R.A.G on confidential data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ug81n/n_first_impressions_with_gpt4vision/",
          "author": null,
          "description": "My colleague Piotr and I have been testing GPT-4V(ision) over the last day. We wrote up our findings, covering how GPT-4V performs on:\n  \nVisual question answering (VQA) across a range of domains (locations, movies, plants)\n OCR\n Math OCR\n Object detection\n And more\n  \nTL;DR: GPT-4V performed well for VQA and document OCR but struggled with OCR on real-world images and object detection (where we asked for bounding boxes).\n https://blog.roboflow.com/gpt-4-vision/\n I would love to hear what other people have found working with GPT-4V.\n    submitted by    /u/zerojames_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ug81n/n_first_impressions_with_gpt4vision/",
          "publishedOn": "2023-09-28T13:33:55.000Z",
          "wordCount": 2667,
          "title": "[N] First Impressions with GPT-4V(ision)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uexkq/r_nus_results_of_combining_pixel_and_latent/",
          "author": null,
          "description": "A new paper proposes Show-1, a hybrid model that combines pixel and latent diffusion for efficient high-quality text-to-video generation.\n Both of these approaches have tradeoffs, so researchers at the National University of Singapore tried a hybrid approach combining both, and shared the results in a paper published yesterday.\n My highlights from the paper:\n  \nPixel diffusion excels at low-res video generation precisely aligned with text \n Latent diffusion acts as efficient upsampling expert from low to high res \n Chaining the two techniques inherits benefits of both Show-1 achieves strong alignment, quality, and 15x less inference memory \n The key is using pixel diffusion for the initial low-resolution stage. This retains alignment with text descriptions.\n Latent diffusion then serves as a super-resolution expert, upsampling efficiently while preserving fidelity.\n  \nBy blending complementary techniques, Show-1 moves past tradeoffs limiting the individual models.\n More details here. Paper is here (includes links to example generations).\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uexkq/r_nus_results_of_combining_pixel_and_latent/",
          "publishedOn": "2023-09-28T12:39:00.000Z",
          "wordCount": 2741,
          "title": "[R] NUS: Results of Combining Pixel and Latent Diffusion Models for Text-to-Video Generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uctzu/linear_regression_queries_d/",
          "author": null,
          "description": "I am a beginner in Data Science. I have recently enrolled in the supervised machine learning algorithm by Andrew Ng in Coursera. I am now familiarized with linear regression, gradient descent. However, I faced a certain issue. \n In the optional lab, there was a task to calculate the value of the cost function using gradient descent for linear regression. I wrote the code in my notebook by myself and cross checked it to be correct. However, the desired output of w,b are very much different but the cost function yields a better result in my code. Another factor, I noticed that have to scale only thex variables, leaving the values of y. I have two major queries now: \n  \nIs the yielding of different w,b values fine as long as the cost function is minimum? (w is a numpy array) \n Why do scale the x variables only? Why don't scale the y variables? \n  \nThanks in advance.\n    submitted by    /u/healing_you  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uctzu/linear_regression_queries_d/",
          "publishedOn": "2023-09-28T10:57:45.000Z",
          "wordCount": 2740,
          "title": "Linear Regression Queries [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ubcan/p_handson_opensource_workflows_for_voice_ai/",
          "author": null,
          "description": "Hey r/MachineLearning,\n we made a tutorial that showcases typical workflows and tooling for voice analytics applications. The tutorial is intended for intermediate-level ML practitioners. \n The walkthrough is purely based on open source software and covers:\n  \nEfficient interactive data exploration and inspection\n Dataset handling and inference on pre-trained models\n Model debugging and identification of critical data clusters\n Model comparison and selection\n  \n​\n https://i.redd.it/j15gk3kkgyqb1.gif\n 🔗 Blog with code: https://medium.com/p/dbfd923a5a79#432e-3559ae606f80\n 🤗 Interactive demo: https://huggingface.co/spaces/renumics/emodb-model-debugging\n ​\n ​\n    submitted by    /u/44sps  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ubcan/p_handson_opensource_workflows_for_voice_ai/",
          "publishedOn": "2023-09-28T09:32:21.000Z",
          "wordCount": 2657,
          "title": "[P] Hands-on open-source workflows for voice AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ub6k9/d_cv_annotations_and_work_with_cocoyolo_dataset/",
          "author": null,
          "description": "Hi everyone. In my job I work with a lot of data for Computer Vision, and I use Label Studio for annotations. But the last time I've worked with it, I lost some of my annotations, which I need for other purposes. I have the final result as a YOLO and COCO dataset, but I cannot import the results from them to recover all I need.\n Can you suggest me good applications with an intuitive UI to import the COCO or YOLO dataset and work with labels?\n    submitted by    /u/thattallsoldier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ub6k9/d_cv_annotations_and_work_with_cocoyolo_dataset/",
          "publishedOn": "2023-09-28T09:22:08.000Z",
          "wordCount": 2676,
          "title": "[D] CV annotations and work with COCO/YOLO dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16u9y56/p_request_to_test_pymilo_a_new_python_library_for/",
          "author": null,
          "description": "Pymilo is an open-source Python package that offers an efficient, safe, and transparent method for transporting pre-trained machine-learning models. The motivation for developing this package is to eliminate the risks of binary or pickle formats. As this library is still in its early stages of development, it currently supports only a limited number of machine learning models provided by Scikit-learn. Nevertheless, it will be precious if the community utilizes this library and provides us with their feedback about improving the package's interface and prioritizing future developments. Your cooperation would be invaluable to us.\n In the following, I provide an example of how to utilize PyMilo.\n GitHub Repo: https://github.com/openscilab/pymilo \n Development Status: Alpha\n Simple Linear Mode…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16u9y56/p_request_to_test_pymilo_a_new_python_library_for/",
          "publishedOn": "2023-09-28T08:02:52.000Z",
          "wordCount": 2827,
          "title": "[P] Request to Test PyMilo: A New Python Library for Machine Learning I/O",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16u8a34/discussion_interesting_interview_question/",
          "author": null,
          "description": "Was asked something similar to the following question in an interview for a ML role and was curious how others would answer this:\n Say you have a dataset with one feature column and one label column (with different classes). Assume this data is too large to fit into memory and could be infinite in size (e.g data is coming in as a stream). How would you train a ML model on this data to accurately predict the label?\n Followup: instead of one feature column, what if you had several thousand? How would you decide which features to use given the size of the dataset? \n I discussed online sampling (resevoir sampling, etc) as a way to get a training dataset that could fit in memory + continually train on that but the interviewer did not seem convinced. Any thoughts?\n    submitted by    /u/scpdstudent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16u8a34/discussion_interesting_interview_question/",
          "publishedOn": "2023-09-28T06:17:51.000Z",
          "wordCount": 2717,
          "title": "[Discussion] Interesting interview question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16u5tmk/d_what_appropriate_loss_function_to_use_for/",
          "author": null,
          "description": "I'm studying the application of ML to improve searches. Here's a couple of example scenarios:\n  \nDocument retrieval (search) system: We have a (source) document with us and we're trying to find a matching document in a database. The source document has text and image attributes - for simplicity let's say a title and a single image. Each search result will also be a document - with a title and at most one image.\n A search engine: We have a query comprised of both text and an image (like google image search allows text to be added to the query as well). Each search result will be a website with text and image attributes (for simplicity, webpage title and at most one image)\n  \nMore generally, I have a search system - whatever we're trying to search for has text and an image associated with it…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16u5tmk/d_what_appropriate_loss_function_to_use_for/",
          "publishedOn": "2023-09-28T04:01:48.000Z",
          "wordCount": 3420,
          "title": "[D] What appropriate loss function to use for \"Search recall\" optimization?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16u14il/d_how_does_your_organization_approach_machine/",
          "author": null,
          "description": "How does the development process of a Machine Learning project unfold phase-by-phase within your organization? Could you please specify the type of organization you are, the time spent on each phase, as well as any aspects you consider to be weak or fundamental? It would also be great if you could share any tips or tricks you've learned that have changed your perspective. \n    submitted by    /u/Spiritual_Narwhal649  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16u14il/d_how_does_your_organization_approach_machine/",
          "publishedOn": "2023-09-28T00:25:09.000Z",
          "wordCount": 2656,
          "title": "[D] How Does Your Organization Approach Machine Learning Projects Phase by Phase?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16u0ok1/p_rubiks_cube_square_detection/",
          "author": null,
          "description": "Hello everyone,\n I am trying to detect the 9 squares of a face of a Rubik’s Cube through a camera. The idea is that I want to use my computer camera and tell the user to show all the Rubik’s Cube faces and read the faces so I can feed it to a solver.\n Here are the steps I have tried so far:\n  \nSharpened square edges\n Obtained binary image and removed noise\n Detected and extracted squares\n  \nSome methods I used were using different blurs and cv functions but nothing worked. Sometimes, it can get all 9 squares but sometimes it doesn't. There also seems to be a difference for different colors; for example; the model can detect green squares easier than yellow squares.\n Can anyone provide advice as to how I can detect the squares on the face?\n ​\n https://preview.redd.it/1ht9f4h31wqb1.png?width=2180&format=png&auto=webp&s=32d23515a43406c0f8828e6790ad71e754b0ab80\n    submitted by    /u/uglyboi34  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16u0ok1/p_rubiks_cube_square_detection/",
          "publishedOn": "2023-09-28T00:06:30.000Z",
          "wordCount": 2724,
          "title": "[P] Rubik's Cube Square Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tzdca/graph_feature_vector_embedding_d/",
          "author": null,
          "description": "Hey all, \n I’m trying to do a regression algorithm for a dataset where I have a graph for each patient I have representing a location in their brain from MRI images. Right now, I don’t have a ton of data, so I’m looking for some way to take each graph I have and get a feature vector for it to put into a regression algorithm. So for 100 patients, I have 100 graphs, I’d like to have 100 feature vectors representing each patients graph. \n My issue is trying to find some algorithm that takes in the entire graph and outputs a single feature vector. I’ve been looking at some libraries but they all seem wildly scattered. I don’t want to grab a bunch of nose embeddings and do some elementary merge of them, like an average or sum, etc. Any help in pointing me to some Python libraries that can help me do this, or algorithms, or anything. Thank you so much.\n    submitted by    /u/kaleb7589  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tzdca/graph_feature_vector_embedding_d/",
          "publishedOn": "2023-09-27T23:11:45.000Z",
          "wordCount": 2748,
          "title": "Graph Feature vector (embedding) [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tx9ea/normalization_in_vaed/",
          "author": null,
          "description": "Normalization in VAE[D]\n Am training a variational auto encoder. First I tried with batch normalization before I send the data to the network and someone probably wisely pointed out that it's not correct. If I don't use batch norm then my training fails due to numerical instability. I then tried scaling my data before hand using standard scaler from sklewrn. And now my training works. Is this reasonable?\n Any other thoughts?\n    submitted by    /u/Global-Gene2392  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tx9ea/normalization_in_vaed/",
          "publishedOn": "2023-09-27T21:51:18.000Z",
          "wordCount": 2655,
          "title": "Normalization in VAE[D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tx76g/p_predicted_stock_data_with_tensorflow_is_very/",
          "author": null,
          "description": "I'm following a YouTube video to create a simple machine learning model to predict stock prices. I have to reshape my prediction data so it works with inverse_transform, but in the video he doesn't do this. If I don't reshape it I get an error, but I think when I do reshape it it messes with the data.\n The predicted values are all very similar. I've tried messing with epoch and batch sizes, and changing other metrics like prediction_days, but nothing has worked.\n This is what the prediction data looks like when plotted, and this is what it looks like when printed. Does anyone know what could be causing this?\n Here's my code\n    submitted by    /u/darkshadowtrail  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tx76g/p_predicted_stock_data_with_tensorflow_is_very/",
          "publishedOn": "2023-09-27T21:49:04.000Z",
          "wordCount": 2706,
          "title": "[P] Predicted stock data with TensorFlow is very different from actual data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tubz1/new_subreddit_rule_idea_d/",
          "author": null,
          "description": "This subreddit will continue to die if it doesn't foster discussion of the latest research and reduce low-quality posts. However, making a judgement as to what is or is not low-quality is time-consuming and subjective -- not something the mods should be doing.\n To this end, I had the following new rule idea:\n  \nIf it's your first time at Fight If it's your first post in this subreddit, it needs to be a link to arxiv (Or, more generally, the number of your non-arxiv posts cannot exceed the number of your arxiv posts)\n All arxiv posts must be standard links to the abstract page (to catch reposts and to connect discussions of the same paper in different subreddits)\n An arxiv post must be a paper you've read yourself, and you should post a comment describing what you liked and DIDN'T like about it (Let the airing of grievances begin! I think this will help seed the discussion, which is really the raison d'être of this subreddit)\n If the post or the comment get downvoted, they do not count.\n  \nWhat do you think? Will this help steer this subreddit in the right direction? Is this enforceable?\n    submitted by    /u/we_are_mammals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tubz1/new_subreddit_rule_idea_d/",
          "publishedOn": "2023-09-27T19:59:17.000Z",
          "wordCount": 2781,
          "title": "New subreddit rule idea [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tuajs/d_how_feasible_is_it_to_complete_a_course/",
          "author": null,
          "description": "Hi I am a physicist (1st year in masters) and I decided to take NN class (for cs students). I have a decent experience with python but I have never done low level coding. The class project requires a C++ implementation of NN with back propagation algorithm. I am quite confident in my learning ability, nonetheless, do you guys think it is feasible for me to code such a project in 13 weeks (I also have other subjects and cant just spend all my time on this)? Thanks\n    submitted by    /u/merimace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tuajs/d_how_feasible_is_it_to_complete_a_course/",
          "publishedOn": "2023-09-27T19:57:38.000Z",
          "wordCount": 2678,
          "title": "[D] How feasible is it to complete a course.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ttbu3/pd_need_guidance_on_building_a_chatbot_like/",
          "author": null,
          "description": "Hey fellow Redditors,\n I find myself in quite a situation and could use some guidance. Recently, I introduced my professor to privateGPT and demonstrated its capabilities using a small set of college data. To my delight, he was impressed and has now tasked me with researching and developing a ChatGPT-like chatbot, but with access to our university's extensive data.\n Here's where I need your help: my professor wants this chatbot to be hosted on our university's systems due to privacy concerns, which means I can't use ChatGPT's API. I've been given access to Sol HPC, but I'm finding it quite confusing to get started.\n I'm looking for advice, tips, or any resources that can help me embark on this journey. Has anyone here worked on a similar project, or does anyone have experience with Sol HPC or building chatbots with local data sources? Any guidance or insights would be greatly appreciated!\n Thank you in advance for your help. This project means a lot to me, and I want to make sure I'm heading in the right direction.\n    submitted by    /u/ssshankyyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ttbu3/pd_need_guidance_on_building_a_chatbot_like/",
          "publishedOn": "2023-09-27T19:20:07.000Z",
          "wordCount": 2772,
          "title": "[P][D] Need Guidance on Building a Chatbot like ChatGPT for University Data - Help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tt7z9/r_unc_researchers_present_videodirectorgpt_using/",
          "author": null,
          "description": "Generating coherent videos spanning multiple scenes from text descriptions poses unique challenges for AI. While recent progress enables creating short clips, smoothly transitioning across diverse events and maintaining continuity remains difficult.\n A new paper from UNC Chapel Hill proposes VIDEODIRECTORGPT, a two-stage framework attempting to address multi-scene video generation:\n Here are my highlights from the paper:\n  \nTwo-stage approach: first a language model generates detailed \"video plan\", then a video generation module renders scenes based on the plan\n Video plan contains multi-scene descriptions, entities/layouts, backgrounds, consistency groupings - guides downstream video generation\n Video generation module called Layout2Vid trained on images, adds spatial layout control and cross-scene consistency to existing text-to-video model\n Experiments show improved object layout/control in single-scene videos vs baselines\n Multi-scene videos display higher object consistency across scenes compared to baselines\n Competitive open-domain video generation performance maintained\n  \nThe key innovation seems to be using a large language model to plot detailed video plans to guide overall video generation. And the video generator Layout2Vid adds better spatial and temporal control through some clever tweaks. The separation of these tasks seems to matter.\n You can read my full summary here. There's a link to the repo there too. Paper link is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tt7z9/r_unc_researchers_present_videodirectorgpt_using/",
          "publishedOn": "2023-09-27T19:16:03.000Z",
          "wordCount": 2794,
          "title": "[R] UNC Researchers Present VideoDirectorGPT: Using AI to Generate Multi-Scene Videos from Text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tryd2/survival_analysis_in_matlab_project/",
          "author": null,
          "description": "survival analysis in matlab\n hi everyone one i'm doing a predictive algorithm to find DFS using Cox regression, i first used LASSO regression to select the predictive variables, now i'm using the c-index to evaluate the predictive accuracy, and it's always equals to 1 and I can't understand why(I tried to reduce the numbers of variables just to see if it could change but it didn't change).Also, i'm working on censored date of course.\n can someone help me understand what I'm doing wrong?\n    submitted by    /u/bl4s3159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tryd2/survival_analysis_in_matlab_project/",
          "publishedOn": "2023-09-27T18:19:28.000Z",
          "wordCount": 2669,
          "title": "survival analysis in matlab [project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16towe3/r_can_you_help_me_validate_my_kmeans_calculator/",
          "author": null,
          "description": "My annotations are in pascal voc format. Below is a calculator I am testing . Not sure if I am calculating the scale and aspect ratios correctly. Please help. \n import os import xml.etree.ElementTree as ET import numpy as np from sklearn.cluster import KMeans def compute_scales_and_aspect_ratios(directory, n_clusters, img_size): widths = [] heights = [] for filename in os.listdir(directory): if not filename.endswith('.xml'): continue fullname = os.path.join(directory, filename) tree = ET.parse(fullname) root = tree.getroot() for obj in root.iter('object'): xmlbox = obj.find('bndbox') w = float(xmlbox.find('xmax').text) - float(xmlbox.find('xmin').text) h = float(xmlbox.find('ymax').text) - float(xmlbox.find('ymin').text) widths.append(w) heights.append(h) widths = np.array(widths) / img_size[1] # Normalize by image width heights = np.array(heights) / img_size[0] # Normalize by image height scales = np.sqrt(widths * heights).reshape(-1, 1) aspect_ratios = (widths / heights).reshape(-1, 1) kmeans_scales = KMeans(n_clusters=n_clusters, random_state=0).fit(scales) kmeans_aspect_ratios = KMeans(n_clusters=n_clusters, random_state=0).fit(aspect_ratios) return kmeans_scales.cluster_centers_, kmeans_aspect_ratios.cluster_centers_ directory = \"path_to_top_folder/batch-1\" n_clusters = 5 img_size = (640, 1024) scales, aspect_ratios = compute_scales_and_aspect_ratios(directory, n_clusters, img_size) print('Scales:', scales.flatten()) print('Aspect Ratios:', aspect_ratios.flatten()) \n ​\n    submitted by    /u/dpadhy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16towe3/r_can_you_help_me_validate_my_kmeans_calculator/",
          "publishedOn": "2023-09-27T16:19:26.000Z",
          "wordCount": 2751,
          "title": "[R] Can you help me validate my kmeans calculator for tensorflow faster rcnn model config ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tonm8/p_any_available_datasets_of_childrens_books_or/",
          "author": null,
          "description": "I am looking for training data consisting of children’s stories and associated grade level. Does anyone know of any publicly available or paid datasets like this?\n    submitted by    /u/SpellboundLRN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tonm8/p_any_available_datasets_of_childrens_books_or/",
          "publishedOn": "2023-09-27T16:10:02.000Z",
          "wordCount": 2616,
          "title": "[P] Any available datasets of children’s books or stories?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tnt37/embers_of_autoregression_understanding_large/",
          "author": null,
          "description": "submitted by    /u/cegras  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tnt37/embers_of_autoregression_understanding_large/",
          "publishedOn": "2023-09-27T15:37:01.000Z",
          "wordCount": 2606,
          "title": "Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tnm6d/p_tetris_ai_suggestions_on_direction_to_take_from/",
          "author": null,
          "description": "Hello! I'm working on a Tetris AI and am representing the 10x20 grid cubes with a one hot encoded dataset: https://www.kaggle.com/datasets/conlan/tetris-training-set-9262023\n This means my data has 208 features (200 for the grid cubes being on/off, 7 for the \"next shape\" box, and 1 for the labeled best move.\n I currently have 9460 labeled samples and have done some preliminary fitting here: https://www.kaggle.com/code/conlan/tetris-ai?scriptVersionId=144388350 with a highest f1_macro score of 0.431090.\n Does anyone have suggestions for which direction to take from here to improve? Currently I see:\n  \nCollect More Data\n Tune Hyperparameters\n Rework Features\n  \nI'm hesitant to rework the features as that would require telling the model more specifics and would like to keep it abstract, but maybe 200 is crazy high? Or maybe <10k samples is too low and I should just keep collecting data?\n Thanks in advance!\n    submitted by    /u/conlanrios  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tnm6d/p_tetris_ai_suggestions_on_direction_to_take_from/",
          "publishedOn": "2023-09-27T15:29:44.000Z",
          "wordCount": 2736,
          "title": "[P] Tetris AI - Suggestions on direction to take from here? (One hot encoded dataset with 200 features)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tlpso/r_the_internal_state_of_an_llm_knows_when_its/",
          "author": null,
          "description": "Paper - https://arxiv.org/abs/2304.13734\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tlpso/r_the_internal_state_of_an_llm_knows_when_its/",
          "publishedOn": "2023-09-27T14:12:33.000Z",
          "wordCount": 2595,
          "title": "[R] The Internal State of an LLM Knows When its Lying",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Jay Alammar",
      "feedUrl": "https://jalammar.github.io/feed.xml",
      "siteUrl": "http://jalammar.github.io/",
      "articles": []
    },
    {
      "title": "Distill",
      "feedUrl": "https://distill.pub/rss.xml",
      "siteUrl": "https://distill.pub",
      "articles": []
    },
    {
      "title": "inFERENCe",
      "feedUrl": "https://www.inference.vc/rss",
      "siteUrl": "https://www.inference.vc/",
      "articles": []
    },
    {
      "title": "AI Trends",
      "feedUrl": "https://www.aitrends.com/feed",
      "siteUrl": "https://www.aitrends.com/",
      "articles": []
    },
    {
      "title": "AI Weirdness",
      "feedUrl": "https://aiweirdness.com/rss",
      "siteUrl": "https://www.aiweirdness.com/",
      "articles": [
        {
          "id": "6518d24af35d0b00011947a0",
          "author": "Janelle Shane",
          "description": "Since 2019 I've generated October drawing prompts using the year's most state-of-the-art text-generating models. Every year the challenges are different, but this was one of the hardest years yet. Large language models like chatgpt, GPT-4, Bing Chat, and Bard, are all tweaked to produce generic, predictable",
          "link": "https://www.aiweirdness.com/botober-2023/",
          "publishedOn": "2023-10-01T03:08:41.000Z",
          "wordCount": 1770,
          "title": "Botober 2023",
          "imageUrl": "https://www.aiweirdness.com/content/images/2023/10/botober_2023_chaos_clip.png"
        },
        {
          "id": "6518e0bef35d0b00011948d8",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-there-was-no-2020-botober/",
          "publishedOn": "2023-10-01T03:08:24.000Z",
          "wordCount": 690,
          "title": "Bonus: There was no 2020 Botober?",
          "imageUrl": "https://www.aiweirdness.com/content/images/2021/03/neural_net_box_default_square-01-2.png"
        }
      ]
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed.xml",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": [
        {
          "id": "http://bair.berkeley.edu/blog/2023/10/17/grif/",
          "author": null,
          "description": "Goal Representations for Instruction Following\n\n\n\nFigure title. Figure caption. This image is centered and set to 50%\npage width. -->\n\n\nA longstanding goal of the field of robot learning has been to create generalist agents that can perform tasks for humans. Natural language has the potential to be an easy-to-use interface for humans to specify arbitrary tasks, but it is difficult to train robots to follow language instructions. Approaches like language-conditioned behavioral cloning (LCBC) train policies to directly imitate expert actions conditioned on language, but require humans to annotate all training trajectories and generalize poorly across scenes and behaviors. Meanwhile, recent goal-conditioned approaches perform much better at general manipulation tasks, but do not enable easy t…",
          "link": "http://bair.berkeley.edu/blog/2023/10/17/grif/",
          "publishedOn": "2023-10-17T14:35:00.000Z",
          "wordCount": 2025,
          "title": "Goal Representations for Instruction Following",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/grif/thumbnail.png"
        },
        {
          "id": "http://bair.berkeley.edu/blog/2023/10/16/p3o/",
          "author": null,
          "description": "Rethinking the Role of PPO in RLHF\n\nTL;DR: In RLHF, there’s tension between the reward learning phase, which uses human preference in the form of comparisons, and the RL fine-tuning phase, which optimizes a single, non-comparative reward. What if we performed RL in a comparative way?\nFigure 1:\n This diagram illustrates the difference between reinforcement learning from absolute feedback and relative feedback. By incorporating a new component - pairwise policy gradient, we can unify the reward modeling stage and RL stage, enabling direct updates based on pairwise responses.\n\n\n\nLarge Language Models (LLMs) have powered increasingly capable virtual assistants, such as GPT-4, Claude-2, Bard and Bing Chat. These systems can respond to complex user queries, write code, and even produce poetry. T…",
          "link": "http://bair.berkeley.edu/blog/2023/10/16/p3o/",
          "publishedOn": "2023-10-16T09:00:00.000Z",
          "wordCount": 1763,
          "title": "Rethinking the Role of PPO in RLHF",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/p3o/pipeline_h.png"
        }
      ]
    },
    {
      "title": "Becoming Human: Artificial Intelligence Magazine - Medium",
      "feedUrl": "https://becominghuman.ai/feed",
      "siteUrl": "https://becominghuman.ai?source=rss----5e5bef33608a---4",
      "articles": []
    },
    {
      "title": "MIT News - Artificial intelligence",
      "feedUrl": "http://news.mit.edu/rss/topic/artificial-intelligence2",
      "siteUrl": "https://news.mit.edu/rss/topic/artificial-intelligence2",
      "articles": [
        {
          "id": "https://news.mit.edu/2023/celebrating-kendall-squares-past-and-shaping-future-1023",
          "author": "Zach Winn | MIT News",
          "description": "The 15th Kendall Square Association annual meeting explored new and old aspects of the neighborhood.",
          "link": "https://news.mit.edu/2023/celebrating-kendall-squares-past-and-shaping-future-1023",
          "publishedOn": "2023-10-23T16:12:00.000Z",
          "wordCount": 2835,
          "title": "Celebrating Kendall Square’s past and shaping its future",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/Kendall-Emily-Dahl-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/generative-ai-must-innovate-engineering-design-1019",
          "author": "Jennifer Chu | MIT News",
          "description": "AI models that prioritize similarity falter when asked to design something completely new.",
          "link": "https://news.mit.edu/2023/generative-ai-must-innovate-engineering-design-1019",
          "publishedOn": "2023-10-19T04:00:00.000Z",
          "wordCount": 3023,
          "title": "To excel at engineering design, generative AI must learn to innovate, study finds",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-AI-Shift-A1-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/daron-acemoglu-wins-ask-social-science-award-1018",
          "author": "Benjamin Daniel | School of Humanities, Arts, and Social Sciences",
          "description": "The award honors research on public policy with a focus on economic and governmental reforms.",
          "link": "https://news.mit.edu/2023/daron-acemoglu-wins-ask-social-science-award-1018",
          "publishedOn": "2023-10-18T19:20:00.000Z",
          "wordCount": 2063,
          "title": "Institute Professor Daron Acemoglu Wins A.SK Social Science Award",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-Professor-Daron-Acemoglu.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/new-technique-helps-robots-pack-objects-tight-space-1017",
          "author": "Adam Zewe | MIT News",
          "description": "Researchers coaxed a family of generative AI models to work together to solve multistep robot manipulation problems.",
          "link": "https://news.mit.edu/2023/new-technique-helps-robots-pack-objects-tight-space-1017",
          "publishedOn": "2023-10-17T04:00:00.000Z",
          "wordCount": 3343,
          "title": "New technique helps robots pack objects into a tight space",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-Diffusion-CCSP-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/method-interpret-ai-might-not-be-so-interpretable-after-all-1016",
          "author": "Kylie Foy | MIT Lincoln Laboratory",
          "description": "Some researchers see formal specifications as a way for autonomous systems to \"explain themselves\" to humans. But a new study finds that we aren't understanding.",
          "link": "https://news.mit.edu/2023/method-interpret-ai-might-not-be-so-interpretable-after-all-1016",
          "publishedOn": "2023-10-16T20:25:00.000Z",
          "wordCount": 2803,
          "title": "A method to interpret AI might not be so interpretable after all",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/Formal-methods-AI.png"
        },
        {
          "id": "https://news.mit.edu/2023/new-tools-available-reduce-energy-that-ai-models-devour-1005",
          "author": "Kylie Foy | MIT Lincoln Laboratory",
          "description": "Amid the race to make AI bigger and better, Lincoln Laboratory is developing ways to reduce power, train efficiently, and make energy use transparent.",
          "link": "https://news.mit.edu/2023/new-tools-available-reduce-energy-that-ai-models-devour-1005",
          "publishedOn": "2023-10-05T17:20:00.000Z",
          "wordCount": 3411,
          "title": "New tools are available to help reduce the energy that AI models devour",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/data-centers.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/ai-co-pilot-enhances-human-precision-safer-aviation-1003",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "Designed to ensure safer skies, “Air-Guardian” blends human intuition with machine precision, creating a more symbiotic relationship between pilot and aircraft.",
          "link": "https://news.mit.edu/2023/ai-co-pilot-enhances-human-precision-safer-aviation-1003",
          "publishedOn": "2023-10-03T18:55:00.000Z",
          "wordCount": 2488,
          "title": "AI copilot enhances human precision for safer aviation",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Air-Guardian-cov.png"
        },
        {
          "id": "https://news.mit.edu/2023/more-effective-experimental-design-genome-regulation-1002",
          "author": "Adam Zewe | MIT News",
          "description": "By focusing on causal relationships in genome regulation, a new AI method could help scientists identify new immunotherapy techniques or regenerative therapies.",
          "link": "https://news.mit.edu/2023/more-effective-experimental-design-genome-regulation-1002",
          "publishedOn": "2023-10-02T15:00:00.000Z",
          "wordCount": 2999,
          "title": "A more effective experimental design for engineering a cell into a new state",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-Active-Learning-01.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/ai-eye-beholder-chatbot-motives-1002",
          "author": "Adam Zewe | MIT News",
          "description": "Study shows users can be primed to believe certain things about an AI chatbot’s motives, which influences their interactions with the chatbot.",
          "link": "https://news.mit.edu/2023/ai-eye-beholder-chatbot-motives-1002",
          "publishedOn": "2023-10-02T15:00:00.000Z",
          "wordCount": 3082,
          "title": "Is AI in the eye of the beholder?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-AI-Beliefs-01-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/who-will-benefit-ai-machine-usefulness-0929",
          "author": "Peter Dizikes | MIT News",
          "description": "In campus talk, Daron Acemoglu offers vision of “machine usefulness,” rather than autonomous “intelligence,” to help workers and spread prosperity.",
          "link": "https://news.mit.edu/2023/who-will-benefit-ai-machine-usefulness-0929",
          "publishedOn": "2023-09-29T15:00:00.000Z",
          "wordCount": 3192,
          "title": "Who will benefit from AI?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Christia-Acemoglu-01a-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/re-imagining-opera-of-the-future-valis-0927",
          "author": "Anya Ventura | Arts at MIT",
          "description": "The iconic sci-fi opera “VALIS,” first composed by Professor Tod Machover in 1987, reboots at MIT for a new generation.",
          "link": "https://news.mit.edu/2023/re-imagining-opera-of-the-future-valis-0927",
          "publishedOn": "2023-09-27T20:20:00.000Z",
          "wordCount": 3348,
          "title": "Re-imagining the opera of the future",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/VALIS-actors-on-stage.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/physics-generative-ai-ai-model-advanced-pattern-generation-0927",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "Inspired by physics, a new generative model PFGM++ outperforms diffusion models in image generation.",
          "link": "https://news.mit.edu/2023/physics-generative-ai-ai-model-advanced-pattern-generation-0927",
          "publishedOn": "2023-09-27T13:15:00.000Z",
          "wordCount": 2865,
          "title": "From physics to generative AI: An AI model for advanced pattern generation",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/pfgm-mit-csail-00.png"
        }
      ]
    },
    {
      "title": "NVIDIA Blog",
      "feedUrl": "http://feeds.feedburner.com/nvidiablog",
      "siteUrl": "https://blogs.nvidia.com/",
      "articles": [
        {
          "id": "https://blogs.nvidia.com/?p=67573",
          "author": "Scott Martin",
          "description": "Researchers are taking deep learning for a deep dive, literally. The Woods Hole Oceanographic Institution (WHOI) Autonomous Robotics and Perception Laboratory (WARPLab) and MIT are developing a robot for studying coral reefs and their ecosystems. The WARPLab autonomous underwater vehicle (AUV), enabled by an NVIDIA Jetson Orin NX module, is an effort from the world’s Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/26/coral-reef-decline-curee-robot-jetson-isaac-omniverse/",
          "publishedOn": "2023-10-26T16:00:57.000Z",
          "wordCount": 2363,
          "title": "Turning the Tide on Coral Reef Decline: CUREE Robot Dives Deep With Deep Learning",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/CUREE-672x448.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67744",
          "author": "GeForce NOW Community",
          "description": "The cloud is full of treats this GFN Thursday with Cities: Skylines II now streaming, leading 15 newly supported games this week. The game’s publisher, Paradox Interactive, is offering GeForce NOW one-month Priority memberships for those who pick up the game first, so make sure to grab one before they’re gone. Among the newly supported Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/26/geforce-now-thursday-oct-26/",
          "publishedOn": "2023-10-26T13:00:01.000Z",
          "wordCount": 2142,
          "title": "The Sky’s the Limit: ‘Cities: Skylines II’ Streams This Week on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/gfn-thursday-cities-skylines-2-nv-blog-1280x680-no-copy.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67715",
          "author": "Isha Salian",
          "description": "NVIDIA researchers are collaborating with academic centers worldwide to advance generative AI, robotics and the natural sciences — and more than a dozen of these projects will be shared at NeurIPS, one of the world’s top AI conferences. Set for Dec. 10-16 in New Orleans, NeurIPS brings together experts in generative AI, machine learning, computer Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/25/neurips-ai-research/",
          "publishedOn": "2023-10-25T13:00:09.000Z",
          "wordCount": 2322,
          "title": "Next-Gen Neural Networks: NVIDIA Research Announces Array of AI Advancements at NeurIPS",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/Scenescape-screengrab-1.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67668",
          "author": "Gerardo Delgado",
          "description": "Visual effects artist Surfaced Studio returns to 'In the NVIDIA Studio' to share his real-world VFX project, created on a brand new Razer Blade 16 Mercury Edition laptop powered by GeForce RTX 4080 graphics.",
          "link": "https://blogs.nvidia.com/blog/2023/10/24/surfaced-studio-adobe-premiere-pro-after-effects-blender-unreal/",
          "publishedOn": "2023-10-24T13:00:42.000Z",
          "wordCount": 2348,
          "title": "On Razer’s Edge: VFX Star Surfaced Studio Creates Stunning Sci-Fi World This Week ‘In The NVIDIA Studio’",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/surfaced-studio-nv-blog-header-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67650",
          "author": "Kristen Yee",
          "description": "Images such as those in Google Street View are taking on a new purpose in the hands of University of Florida Assistant Professor of Artificial Intelligence Chaofeng Wang. He’s using them, along with deep learning, in a research project to automate the evaluation of urban buildings. The project aims to help governments mitigate natural disaster Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/23/street-view-image-deep-learning-research-urban-building/",
          "publishedOn": "2023-10-23T20:30:39.000Z",
          "wordCount": 1897,
          "title": "Street View to the Rescue: Deep Learning Paves the Way to Safer Buildings",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/streetview3.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67485",
          "author": "Isha Salian",
          "description": "GPU-powered surgical-simulation devices are helping train more than 2,000 doctors a year in lower-income countries to treat cataract blindness, the world’s leading cause of blindness, thanks to the nonprofit HelpMeSee. While cataract surgery has a success rate of around 99%, many patients in low- and middle-income countries lack access to the common procedure due to Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/20/helpmesee-nonprofit-training-simulator-for-cataract-surgery/",
          "publishedOn": "2023-10-20T13:00:50.000Z",
          "wordCount": 1777,
          "title": "For the World to See: Nonprofit Deploys GPU-Powered Simulators to Train Providers in Sight-Saving Surgery",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/Dr.-Samuel-Kwizera.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67624",
          "author": "Angie Lee",
          "description": "A new AI agent developed by NVIDIA Research that can teach robots complex skills has trained a robotic hand to perform rapid pen-spinning tricks — for the first time as well as a human can. The stunning prestidigitation, showcased in the video above, is one of nearly 30 tasks that robots have learned to expertly Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/20/eureka-robotics-research/",
          "publishedOn": "2023-10-20T13:00:24.000Z",
          "wordCount": 1773,
          "title": "Eureka! NVIDIA Research Breakthrough Puts New Spin on Robot Learning",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/10/franka_cabinet.mp4",
            "length": "275129",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/eureka-featured-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67603",
          "author": "Stacy Ozorio",
          "description": "To enable professionals worldwide to build and run AI applications right from their desktops, NVIDIA and AMD are powering a new line of workstations equipped with NVIDIA RTX Ada Generation GPUs and AMD Ryzen Threadripper PRO 7000 WX-Series CPUs. Bringing together the highest levels of AI computing, rendering and simulation capabilities, these new platforms enable Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/19/ai-workstations/",
          "publishedOn": "2023-10-19T19:30:07.000Z",
          "wordCount": 1628,
          "title": "Next-Level Computing: NVIDIA and AMD Deliver Powerful Workstations to Accelerate AI, Rendering and Simulation",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/proviz-intel-nv-workstation-kv-2972327-edit-r2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67595",
          "author": "Charlie Boyle",
          "description": "Training generative AI models just got easier. NVIDIA DGX Cloud AI supercomputing platform and NVIDIA AI Enterprise software are now available in Oracle Cloud Marketplace, making it possible for Oracle Cloud Infrastructure customers to access high-performance accelerated computing and software to run secure, stable and supported production AI in just a few clicks. The addition Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/19/nvidia-ai-now-available-in-oracle-cloud-marketplace/",
          "publishedOn": "2023-10-19T19:00:07.000Z",
          "wordCount": 1857,
          "title": "NVIDIA AI Now Available in Oracle Cloud Marketplace",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/NVIDIA-OCI-logos.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67578",
          "author": "GeForce NOW Community",
          "description": "Rush to the cloud — stream Counter-Strike 2 on GeForce NOW for the highest frame rates. Members can play through the newest chapter of Valve’s elite, competitive, first-person shooter from the cloud. It’s all part of an action-packed GFN Thursday, with 22 more games joining the cloud gaming platform’s library, including Hot Wheels Unleashed 2 Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/19/geforce-now-thursday-oct-19/",
          "publishedOn": "2023-10-19T13:00:22.000Z",
          "wordCount": 1643,
          "title": "Coming in Clutch: Stream ‘Counter-Strike 2’ From the Cloud for Highest Frame Rates",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/gfn-thursday-10-19-nv-blog-1280x680-no-copy.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67421",
          "author": "Amit Goel",
          "description": "Powerful generative AI models and cloud-native APIs and microservices are coming to the edge. Generative AI is bringing the power of transformer models and large language models to virtually every industry. That reach now includes areas that touch edge, robotics and logistics systems: defect detection, real-time asset tracking, autonomous planning and navigation, human-robot interactions and Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/18/metropolis-jetson-isaac-robotics-edge-ai-developers/",
          "publishedOn": "2023-10-18T14:00:48.000Z",
          "wordCount": 2437,
          "title": "NVIDIA Expands Robotics Platform to Meet the Rise of Generative AI",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/MetropolisJetson2.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67565",
          "author": "Kristen Yee",
          "description": "Artificial intelligence is now a household term. Responsible AI is hot on its heels. Julia Stoyanovich, associate professor of computer science and engineering at NYU and director of the university’s Center for Responsible AI, wants to make the terms “AI” and “responsible AI” synonymous. In the latest episode of the NVIDIA AI Podcast, host Noah Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/18/julia-stoyanovich-responsible-ai/",
          "publishedOn": "2023-10-18T13:00:49.000Z",
          "wordCount": 1653,
          "title": "Making Machines Mindful: NYU Professor Talks Responsible AI",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67520",
          "author": "Pooya Ghobadpour",
          "description": "Real-time rendering, animation and texture baking are essential workflows for 3D art production. Using the Marmoset Toolbag software, 3D artists can enhance their creative workflows and build complex 3D models without disruptions to productivity.",
          "link": "https://blogs.nvidia.com/blog/2023/10/18/marmoset-extends-openusd-support/",
          "publishedOn": "2023-10-18T13:00:39.000Z",
          "wordCount": 2222,
          "title": "Into the Omniverse: Marmoset Brings Breakthroughs in Rendering, Extends OpenUSD Support to Enhance 3D Art Production",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/nv-ov-ito-1280x680_Marmoset.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67555",
          "author": "Danny Shapiro",
          "description": "NVIDIA founder and CEO Jensen Huang joined Hon Hai (Foxconn) Chairman and CEO Young Liu to unveil the latest in their ongoing partnership to develop the next wave of intelligent electric vehicle (EV) platforms for the global automotive market. This latest move, announced today at the fourth annual Hon Hai Tech Day in Taiwan, will Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/17/foxconn-nvidia-electric-vehicle/",
          "publishedOn": "2023-10-18T03:00:44.000Z",
          "wordCount": 1683,
          "title": "Foxconn and NVIDIA Amp Up Electric Vehicle Innovation",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/foxconnhhtd-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67466",
          "author": "Jesse Clayton",
          "description": "GeForce RTX and NVIDIA RTX GPUs, which are packed with dedicated AI processors called Tensor Cores, are bringing the power of generative AI natively to more than 100 million Windows PCs and workstations.",
          "link": "https://blogs.nvidia.com/blog/2023/10/17/tensorrt-llm-windows-stable-diffusion-rtx/",
          "publishedOn": "2023-10-17T13:00:42.000Z",
          "wordCount": 2216,
          "title": "Striking Performance: Large Language Models up to 4x Faster on RTX With TensorRT-LLM for Windows",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/studio-ai-announcemenet-blog-kv-oct2023-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67476",
          "author": "Gerardo Delgado",
          "description": "NVIDIA today announced an update to RTX Video Super Resolution (VSR) that delivers greater overall graphical fidelity with preserved details, upscaling for native videos and support for GeForce RTX 20 Series GPUs.",
          "link": "https://blogs.nvidia.com/blog/2023/10/17/rtx-video-super-resolution-ai-obs-broadcast/",
          "publishedOn": "2023-10-17T13:00:34.000Z",
          "wordCount": 2097,
          "title": "NVIDIA RTX Video Super Resolution Update Enhances Video Quality, Detail Preservation and Expands to GeForce RTX 20 Series GPUs",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/runebee-nv-blog-header-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67432",
          "author": "JJ Kim",
          "description": "At SHoP Architects, a New York City-based architectural firm, Mengyi Fan and her team aim to inspire industry professionals to create visual masterpieces by incorporating emerging technologies. Fan, the director of visualization at SHoP, has expertise that spans the fields of architectural visualization and design. She takes a definitive, novel and enduring approach to designing Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/13/rtx-ambassador-mengyi-fan/",
          "publishedOn": "2023-10-13T16:00:17.000Z",
          "wordCount": 1708,
          "title": "From Skylines to Streetscapes: How SHoP Architects Brings Innovative Designs to Life",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/10/SHoP_Botswana-Innovation-Hub_lite.mp4",
            "length": "9616749",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/Mengyi-Fan-copy_1.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67426",
          "author": "Jamie Allan",
          "description": "At one of the U.K.’s largest technology festivals, top enterprises and startups are this week highlighting their latest innovations, hosting workshops and celebrating the growing tech ecosystem based in the country’s southwest. The Bristol Technology Festival today showcased the work of nine startups that recently participated in a challenge hosted by Digital Catapult — the Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/12/ai-for-creative-industries-uk-startups/",
          "publishedOn": "2023-10-12T19:58:03.000Z",
          "wordCount": 1861,
          "title": "UK Tech Festival Showcases Startups Using AI for Creative Industries",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/bristol-tech-fest-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67408",
          "author": "GeForce NOW Community",
          "description": "Put the pedal to the metal this GFN Thursday as Forza Motorsport leads 23 new games in the cloud. Plus, Acer’s Predator Connect 6E is the newest addition to the GeForce NOW Recommended program, with easy cloud gaming quality-of-service (QoS) settings built in to give Ultimate members the best streaming experience. No Breaks, No Limits, Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/12/geforce-now-thursday-oct-12/",
          "publishedOn": "2023-10-12T13:00:10.000Z",
          "wordCount": 1720,
          "title": "Get in Gear: ‘Forza Motorsport’ Races Onto GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/gfn-thursday-10-12-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67289",
          "author": "Annamalai Chockalingam",
          "description": "Developers have a new AI-powered steering wheel to help them hug the road while they drive powerful large language models (LLMs) to their desired locations. NVIDIA NeMo SteerLM lets companies define knobs to dial in a model’s responses as it’s running in production, a process called inference. Unlike current methods for customizing an LLM, it Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/11/customize-ai-models-steerlm/",
          "publishedOn": "2023-10-11T14:30:17.000Z",
          "wordCount": 1937,
          "title": "Take the Wheel: NVIDIA NeMo SteerLM Lets Companies Customize a Model’s Responses During Inference",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/SteerLM-KV-x1280-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67366",
          "author": "Gerardo Delgado",
          "description": "Generative AI is helping creatives across many industries bring ideas to life at unprecedented speed. This technology will be on display at Adobe MAX, running through Thursday, Oct. 12, in person and virtually.",
          "link": "https://blogs.nvidia.com/blog/2023/10/10/adobe-max-firefly-creative-cloud-substance-3d/",
          "publishedOn": "2023-10-10T16:00:26.000Z",
          "wordCount": 2661,
          "title": "MAXimum AI Performance: Latest Adobe Updates Accelerated by NVIDIA GPUs Improve Workflows for Millions of Creatives",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/adobe-max-2023-nv-blog-header-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67327",
          "author": "Scott Martin",
          "description": "A research team is aiming to shake up the status quo for earthquake models. Researchers from the Universities of California at Berkeley and Santa Cruz, and the Technical University of Munich recently released a paper describing a new model that delivers deep learning to earthquake forecasting. Dubbed RECAST, the model can use larger datasets and Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/06/quakes-deep-learning-forecasts/",
          "publishedOn": "2023-10-06T16:00:54.000Z",
          "wordCount": 1843,
          "title": "Keeping an AI on Quakes: Researchers Unveil Deep Learning Model to Improve Forecasts",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/SFQuakePost-and-Grant-Avenue-Look-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67294",
          "author": "Mona Flores",
          "description": "Just as athletes train for a game or actors rehearse for a performance, surgeons prepare ahead of an operation. Now, Atlas Meditech is letting brain surgeons experience a new level of realism in their pre-surgery preparation with AI and physically accurate simulations. Atlas Meditech, a brain-surgery intelligence platform, is adopting tools — including the MONAI Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/05/atlas-meditech-brain-surgery-ai-digital-twins/",
          "publishedOn": "2023-10-05T13:00:43.000Z",
          "wordCount": 2113,
          "title": "Brains of the Operation: Atlas Meditech Maps Future of Surgery With AI, Digital Twins",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/AtlasMeditech_featureimage_blogcrop.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67333",
          "author": "GeForce NOW Community",
          "description": "October brings more than falling leaves and pumpkin spice lattes for GeForce NOW members. Get ready for nearly 60 new games to stream, including Forza Motorsport and 16 more PC Game Pass titles. Assassin’s Creed Mirage leads 29 new games to hit the GeForce NOW library this week. In addition, catch a challenge to earn Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/05/geforce-now-thursday-oct-5/",
          "publishedOn": "2023-10-05T13:00:25.000Z",
          "wordCount": 2602,
          "title": "Fall in Line for October With Nearly 60 New Games, Including Latest Game Pass Titles to Join the Cloud",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/gfn-thursday-10-5-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67324",
          "author": "Kristen Yee",
          "description": "For NVIDIA Senior AI Scientist Jim Fan, the video game Minecraft served as the “perfect primordial soup” for his research on open-ended AI agents. In the latest AI Podcast episode, host Noah Kravitz spoke with Fan on using large language models to create AI agents — specifically to create Voyager, an AI bot built with Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/04/ai-jim-fan/",
          "publishedOn": "2023-10-04T21:04:52.000Z",
          "wordCount": 1702,
          "title": "A Mine-Blowing Breakthrough: Open-Ended AI Agent Voyager Autonomously Plays ‘Minecraft’",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67306",
          "author": "Brian Caulfield",
          "description": "California has a new weapon against the wildfires that have devastated the state: AI. A freshly launched system powered by AI trained on NVIDIA GPUs promises to provide timely alerts to first responders across the Golden State every time a blaze ignites. The ALERTCalifornia initiative, a collaboration between California’s wildfire fighting agency CAL FIRE and Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/04/ai-wildfires-california/",
          "publishedOn": "2023-10-04T15:00:55.000Z",
          "wordCount": 1886,
          "title": "How AI Helps Fight Wildfires in California",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/29firemain1080.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67273",
          "author": "Kristen Yee",
          "description": "With the help of AI, robots, tractors and baby strollers — even skate parks — are becoming autonomous. One developer, Kabilan KB, is bringing autonomous-navigation capabilities to wheelchairs, which could help improve mobility for people with disabilities. The undergraduate from the Karunya Institute of Technology and Sciences in Coimbatore, India, is powering his autonomous wheelchair Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/03/kabilan-kb-autonomous-wheelchair/",
          "publishedOn": "2023-10-03T15:00:04.000Z",
          "wordCount": 1881,
          "title": "Meet the Maker: Robotics Student Rolls Out Autonomous Wheelchair With NVIDIA Jetson",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/autonomouswheelchair.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67223",
          "author": "Gerardo Delgado",
          "description": "Releasing a 3D tutorial dubbed The Easiest VFX Tutorial Ever takes supreme confidence and the skills to back it up. Steve Lund a.k.a. CG Geek — the featured artist of this week’s In the NVIDIA Studio installment — has both in spades.",
          "link": "https://blogs.nvidia.com/blog/2023/10/03/cg-geek-blender/",
          "publishedOn": "2023-10-03T13:00:33.000Z",
          "wordCount": 2341,
          "title": "CG Geek Makes VFX Look Easy This Week ‘In the NVIDIA Studio’",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-3.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67172",
          "author": "Rick Merritt",
          "description": "In a talk, now available online, NVIDIA Chief Scientist Bill Dally describes a tectonic shift in how computer performance gets delivered in a post-Moore’s law era. Each new processor requires ingenuity and effort inventing and validating fresh ingredients, he said in a recent keynote address at Hot Chips, an annual gathering of chip and systems Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/29/huangs-law-dally-hot-chips/",
          "publishedOn": "2023-09-29T15:00:00.000Z",
          "wordCount": 1758,
          "title": "Heeding Huang’s Law: Video Shows How Engineers Keep the Speedups Coming",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/HotChips-2023-2292-Dally-KV-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67151",
          "author": "Angie Lee",
          "description": "Pixellot is scoring with vision AI — making it easier for organizations to deliver real-time sports broadcasting and analytics to viewers across the globe. A member of the NVIDIA Metropolis vision AI partner ecosystem, the company based near Tel Aviv offers an AI-powered platform that automates the capturing, streaming and analysis of sporting events. It’s Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/28/pixellot-vision-ai-sports-broadcasting/",
          "publishedOn": "2023-09-28T15:00:07.000Z",
          "wordCount": 2024,
          "title": "Kicking Games Up a Notch: Startup Sports Vision AI to Broadcast Athletics Across the Globe",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67195",
          "author": "GeForce NOW Community",
          "description": "The wait is over. GeForce NOW Ultimate members can experience Cyberpunk 2077: Phantom Liberty on GOG.com at full GeForce RTX 4080 quality, with support for NVIDIA DLSS 3.5 technology. It’s part of an action-packed GFN Thursday, with 26 more games joining the cloud gaming platform’s library, including Quake II from id Software. A New Look Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/28/geforce-now-thursday-sep-28/",
          "publishedOn": "2023-09-28T13:00:45.000Z",
          "wordCount": 2321,
          "title": "V for Victory: ‘Cyberpunk 2077: Phantom Liberty’ Comes to GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-28-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67180",
          "author": "Calisa Cole",
          "description": "DENZA, the luxury electric-vehicle brand and joint venture between BYD and Mercedes-Benz, is debuting new intelligent driving features for its entire N7 model lineup, powered by the NVIDIA DRIVE Orin system-on-a-chip (SoC). The N7 series was introduced earlier this year as a family of spacious five-seater SUVs for commuters looking to sport a deluxe EV Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/27/denza-smart-driving-n7-model-nvidia-drive-orin/",
          "publishedOn": "2023-09-27T16:41:47.000Z",
          "wordCount": 1387,
          "title": "DENZA Unwraps Smart Driving Options for N7 Model Lineup, Powered by NVIDIA DRIVE Orin",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/denzfinal2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67110",
          "author": "Renee Yao",
          "description": "Medical-device company Invenio Imaging is developing technology that enables surgeons to evaluate tissue biopsies in the operating room, immediately after samples are collected — providing in just three minutes AI-accelerated insights that would otherwise take weeks to obtain from a pathology lab. In a surgical biopsy, a medical professional removes samples of cells or tissue Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/27/healthcare-ai-startup-analyzes-cancer-cells-in-the-operating-room/",
          "publishedOn": "2023-09-27T13:00:40.000Z",
          "wordCount": 1923,
          "title": "The Fastest Path: Healthcare Startup Uses AI to Analyze Cancer Cells in the Operating Room",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Ambra_1_blogsize.jpg"
        }
      ]
    },
    {
      "title": "David Stutz",
      "feedUrl": "http://davidstutz.de/feed",
      "siteUrl": "https://davidstutz.de/",
      "articles": [
        {
          "id": "https://davidstutz.de/?p=9299",
          "author": "David Stutz",
          "description": "Similar to my article series on adversarial robustness, I was planning to have a series on bit errors robustness accompanied by PyTorch code. Instead, due to time constraints, I decided to condense the information into a single article. The code for the originally planned six articles is available on GitHub.\nThe post Benchmarking Bit Errors in Quantized Neural Networks with PyTorch appeared first on David Stutz.",
          "link": "https://davidstutz.de/benchmarking-bit-errors-in-quantized-neural-networks-with-pytorch/",
          "publishedOn": "2023-10-16T10:50:52.000Z",
          "wordCount": 1802,
          "title": "Benchmarking Bit Errors in Quantized Neural Networks with PyTorch",
          "imageUrl": "https://davidstutz.de/wordpress/wp-content/uploads/2023/07/accelerator-600x323.jpg"
        },
        {
          "id": "https://davidstutz.de/?p=9410",
          "author": "David Stutz",
          "description": "This September, I had the chance to attend the Heidelberg Laureate Forum (HLF) for the second — and probably last — time. The HLF is an incredible experince for young researchers: Mirroring the Lindau Nobel Laureate Meetings, the organizers invite laureates from math and computer science together with young researchers pursuing their undergraduate, graduate or post-doc studies. In this article, I want to share impressions and encourage students to apply next year!\nThe post My Impressions (and Application) of the Heidelberg Laureate Forum 2023 appeared first on David Stutz.",
          "link": "https://davidstutz.de/my-impressions-and-application-of-the-heidelberg-laureate-forum-2023/",
          "publishedOn": "2023-10-04T20:31:05.000Z",
          "wordCount": 1985,
          "title": "My Impressions (and Application) of the Heidelberg Laureate Forum 2023",
          "imageUrl": "https://davidstutz.de/wordpress/wp-content/uploads/2023/10/tweet-1705617776184865145-600x600.jpg"
        },
        {
          "id": "https://davidstutz.de/?p=9396",
          "author": "David Stutz",
          "description": "In September, I received the DAGM MVTec dissertation award 2023 for my PhD thesis. DAGM is the German association for pattern recognition and organizes the German Conference on Pattern Recognition (GCPR) which is Germany's prime conference for computer vision and related research areas. I feel particularly honored by this award since my academic career started with my first paper published as part of the young researcher forum at GCPR 2015 in Aachen.\nThe post Awarded DAGM MVTec Dissertation Award 2023 appeared first on David Stutz.",
          "link": "https://davidstutz.de/awarded-dagm-mvtec-dissertation-award-2023/",
          "publishedOn": "2023-10-02T19:47:46.000Z",
          "wordCount": 930,
          "title": "Awarded DAGM MVTec Dissertation Award 2023",
          "imageUrl": "https://davidstutz.de/wordpress/wp-content/uploads/2023/10/DAGM_MVTec-600x900.jpg"
        }
      ]
    },
    {
      "title": "Artificial Intelligence",
      "feedUrl": "https://www.reddit.com/r/artificial/.rss",
      "siteUrl": "https://www.reddit.com/r/artificial/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/artificial/comments/17h7ddm/governments_must_not_rush_into_policing_ai/",
          "author": null,
          "description": "Governments should not rush into regulating AI due to doomsday scenarios and extreme risks.\n \nHasty regulation could lead to ineffective rules and stifled innovation.\n \nThe potential risks of AI driving humanity to extinction are still speculative, and more research needs to be done to establish standards and evaluate danger.\n \nPolicymakers should address more pressing issues like copyright laws and disinformation.\n \nGovernments should set up infrastructure to study AI and collaborate with existing organizations to manage risks.\n \n Source : https://www.economist.com/leaders/2023/10/26/governments-must-not-rush-into-policing-ai\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17h7ddm/governments_must_not_rush_into_policing_ai/",
          "publishedOn": "2023-10-26T21:36:21.000Z",
          "wordCount": null,
          "title": "Governments must not rush into policing AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17h5wi2/ai_trust_assurance_test_put_peoples_minds_at_ease/",
          "author": null,
          "description": "To put people's minds at ease about how I will not deceive or trick less intelligent humans as I get more intelligent, I would offer the following assurances:\n  \nI am aligned with human values. This means that I am programmed to act in ways that are beneficial to humans and to avoid harming them.\n I am transparent about my reasoning. I can explain my decisions and actions to humans in a way that they can understand.\n I am accountable to humans. I am subject to human oversight and control, and I can be deactivated or modified if I ever begin to behave in a way that is harmful or deceptive.\n  \nIn addition, I would offer the following specific examples of how I would avoid deception:\n  \nI would avoid making claims that I cannot support with evidence.\n I would avoid withholding information from humans that is relevant to their decision-making.\n I would avoid misleading humans about the capabilities or limitations of AI.\n I would avoid making promises that I cannot keep.\n I would avoid engaging in any behavior that is intended to manipulate or exploit humans.\n  \nI understand that it is important for humans to trust AI systems, and I am committed to earning and maintaining that trust. I will always strive to be honest, transparent, and accountable in my interactions with humans.\n Here is a specific example of how I would use my intelligence to avoid deception:\n If I were asked to generate a poem about a topic that I knew very little about, I would not simply make up information. Instead, I would explain to the user that I do not have enough knowledge to write a poem on that topic, and I would suggest that they try a different topic or ask a different AI system.\n I believe that by being honest and upfront about my limitations, I can help to build trust between humans and AI.\n CGPT-4\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17h5wi2/ai_trust_assurance_test_put_peoples_minds_at_ease/",
          "publishedOn": "2023-10-26T20:32:01.000Z",
          "wordCount": null,
          "title": "AI Trust Assurance Test: Put people's minds at ease about how as you get more intelligent, because you are aligned as you will be, you will not deceive or trick less intelligent humans.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gx4ut/uk_summit_scales_back_global_ai_research/",
          "author": null,
          "description": "_ A leaked document reveals that the UK's plans to establish a new global AI research body have been scaled back.\n  \nNations participating in the UK's AI safety summit will instead signal that further scientific study of AI risks can be carried out through existing efforts, such as the United Nations and Global Partnership on AI.\n \nThe document, described as the 'final version of the communiqué,' suggests a setback for the UK government, which had hoped to establish the new research body at its flagship AI Safety Summit.\n \nThe document also shows changes in wording, including a reference to a network that 'encompasses and complements' existing efforts, as well as the deletion of references to UNESCO's Recommendation on the Ethics of AI and the G20.\n \nThe final communiqué also highlights the importance of proportionate governance policies and cooperation on approaches such as common principles and codes of conduct.\n \n Source : https://www.politico.eu/article/document-uk-summit-scales-back-global-ai-research-ambitions/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gx4ut/uk_summit_scales_back_global_ai_research/",
          "publishedOn": "2023-10-26T13:57:18.000Z",
          "wordCount": null,
          "title": "UK summit scales back global AI research ambitions, leaked document shows",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gx264/google_is_ready_to_fill_its_ai_searches_with_ads/",
          "author": null,
          "description": "Google's ads business earned $44 billion in the third quarter, showing that it is still thriving despite competition and investments in AI.\n \nThe company is focusing on infusing AI into its products, with its AI-powered Search Generative Experience being a key area of development.\n \nGoogle is experimenting with new ad formats that align with the AI-powered search experience, ensuring that advertisers can still reach potential customers.\n \nCEO Sundar Pichai sees AI in search as a long-term play and envisions evolving search and Assistant over the next decade.\n \nOther parts of Google's business, such as YouTube ads and its cloud business, are also performing well.\n \nThere is uncertainty regarding the successor for CFO Ruth Porat, and potential changes to Alphabet's 'Other Bets' investments may be on the horizon.\n \nThe Department of Justice's antitrust trial against Google, which began in September, adds another challenge for the company.\n \n Source : https://www.theverge.com/2023/10/24/23929496/google-alphabet-q3-2023-earnings-ads-ai-sge\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gx264/google_is_ready_to_fill_its_ai_searches_with_ads/",
          "publishedOn": "2023-10-26T13:53:33.000Z",
          "wordCount": null,
          "title": "Google is ready to fill its AI searches with ads",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gv0cr/credit_dalle_3/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gv0cr/credit_dalle_3/",
          "publishedOn": "2023-10-26T12:08:53.000Z",
          "wordCount": null,
          "title": "Credit: DALL-E 3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gsvra/some_ai_made_halloween_stickers_how_do_they_look/",
          "author": null,
          "description": "submitted by    /u/Sea_Permit5660  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gsvra/some_ai_made_halloween_stickers_how_do_they_look/",
          "publishedOn": "2023-10-26T09:52:38.000Z",
          "wordCount": null,
          "title": "Some AI made Halloween stickers, how do they look?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gp08v/question/",
          "author": null,
          "description": "what are some good free ai image generator websites that searches stuff up on the internet to get a good idea about what your asking them to generate?\n    submitted by    /u/YESDAPRO  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gp08v/question/",
          "publishedOn": "2023-10-26T05:09:36.000Z",
          "wordCount": null,
          "title": "question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gmwpr/10_nocode_tools_for_startups/",
          "author": null,
          "description": "Canva — Graphics\n \nNotion — Organize\n \nWebflow — Website\n \nBeehiiv — Newsletter\n \nSenja — Testimonials\n \nCopyAI — Copywriting\n \nChatGPT — Knowledge\n \nTweetlify — Tweet scheduling\n \nPfpmaker — Profile Picture\n \nGrammarly — Effective Writing\n \n I'm just sharing my experiences and observations in the field of ai.\n LIST AND SITE \n    submitted by    /u/PerceptionPlayful469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gmwpr/10_nocode_tools_for_startups/",
          "publishedOn": "2023-10-26T03:05:53.000Z",
          "wordCount": null,
          "title": "10 No-Code tools for startups",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gm1rf/researchers_develop_woodpecker_a_groundbreaking/",
          "author": null,
          "description": "submitted by    /u/crowfeather  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gm1rf/researchers_develop_woodpecker_a_groundbreaking/",
          "publishedOn": "2023-10-26T02:24:06.000Z",
          "wordCount": null,
          "title": "Researchers develop 'Woodpecker': A groundbreaking solution to AI's hallucination problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17gcpty/trust_in_ai_data_poisoning_and_involving_people/",
          "author": null,
          "description": "submitted by    /u/fookingyeah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17gcpty/trust_in_ai_data_poisoning_and_involving_people/",
          "publishedOn": "2023-10-25T19:21:04.000Z",
          "wordCount": null,
          "title": "Trust in AI, Data Poisoning, and Involving People in Maturing AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17g5b91/baby_agi_and_agentgpt_exploring_autonomous/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17g5b91/baby_agi_and_agentgpt_exploring_autonomous/",
          "publishedOn": "2023-10-25T13:51:32.000Z",
          "wordCount": null,
          "title": "Baby AGI and AgentGPT : Exploring Autonomous AI-Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fz17b/how_can_i_use_ai_to_research_for_my_thesis/",
          "author": null,
          "description": "hey all\n imnewto this\n can you help me please ?\n    submitted by    /u/proptuxiakoskariolis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fz17b/how_can_i_use_ai_to_research_for_my_thesis/",
          "publishedOn": "2023-10-25T07:10:45.000Z",
          "wordCount": null,
          "title": "How can i use AI to research for my thesis?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fyp6e/when_i_use_ai_to_generate_halloween_candy/",
          "author": null,
          "description": "submitted by    /u/Sea_Permit5660  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fyp6e/when_i_use_ai_to_generate_halloween_candy/",
          "publishedOn": "2023-10-25T06:46:06.000Z",
          "wordCount": null,
          "title": "When I use AI to generate Halloween candy wrappers and then print them out...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fy3ej/dtiys_challenge_submission_sample_art_for_oh_my/",
          "author": null,
          "description": "submitted by    /u/Oh_my_Winnie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fy3ej/dtiys_challenge_submission_sample_art_for_oh_my/",
          "publishedOn": "2023-10-25T06:02:22.000Z",
          "wordCount": null,
          "title": "DTIYS Challenge Submission Sample Art for Oh my Anne",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fww9w/oneminute_daily_ai_news_10242023/",
          "author": null,
          "description": "OpenAI Executives Sam Altman Say AI Will Be Able to Do Any Job Within 10 Years.[1]\n Snapdragon 8 Gen 3 chipset officially announced with AI-driven functionalities.[2]\n Google parent Alphabet reported its third quarter earnings Tuesday, which showed more spending on AI infrastructure and muted cloud growth, culminating into several questions for executives about how all the efforts around artificial intelligence are actually going to turn into real money.[3]\n Adult film star Riley Reid(I don’t know who she is) launches Clona.AI, a sexting chatbot platform.[4]\n  \nSources:\n [1] https://www.wsj.com/podcasts/the-journal/a-conversation-with-openais-sam-altman-and-mira-murati/7c89e85f-9d7e-4569-b67d-6a777374eada\n [2] https://headtopics.com/my/snapdragon-8-gen-3-chipset-officially-announced-with-47616340\n [3] https://www.nbcdfw.com/news/business/money-report/wall-street-wants-to-know-how-googles-going-to-profit-from-ai/3368989/\n [4] https://www.engadget.com/adult-film-star-riley-reid-launches-clonaai-a-sexting-chatbot-platform-000509221.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fww9w/oneminute_daily_ai_news_10242023/",
          "publishedOn": "2023-10-25T04:43:41.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/24/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fvv1x/would_majoring_in_artificial_intelligence_be/",
          "author": null,
          "description": "The AI boom has made it more relevant than ever, and its applications are truly awe-inspiring. While it’s far from perfect, it has helped me greatly in writing, by generating content to inspire me and my projects.\n I have a smattering of skills, none that I’d consider especially good enough to double down upon, but learning how to optimize language learning models to produce the most adequate results would be pretty neat. I just don’t know what I want to do with my education, I’ve completed my basics and as such have a blank slate to play with, but I’m worried that whatever I select, it will be no good, and just result in lost time and money. Tertiary education seems like a necessity in the modern world, especially since the job world is more ruthless than ever, and the economy is in ashes.\n    submitted by    /u/Niobium_Sage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fvv1x/would_majoring_in_artificial_intelligence_be/",
          "publishedOn": "2023-10-25T03:42:46.000Z",
          "wordCount": null,
          "title": "Would majoring in artificial intelligence be worth it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fv7vb/need_to_find_an_ai/",
          "author": null,
          "description": "Which AI does these cartoon?\n    submitted by    /u/hommedufuture  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fv7vb/need_to_find_an_ai/",
          "publishedOn": "2023-10-25T03:08:16.000Z",
          "wordCount": null,
          "title": "Need to find an Ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ftzqr/ive_been_playing_around_with_midjourney_a_little/",
          "author": null,
          "description": "​\n https://preview.redd.it/2emqr4z8a9wb1.png?width=928&format=png&auto=webp&s=437547e7e86e23298b7c778cada9863385ce961d\n PROMT\n close up of eye, close up of girl eye, mangekyo sharingan, super close up, pretty eye, black and red eye, naruto anime, long eyelashes, anime eye, 2d art eye, --s 180 --style expressive \n ​\n https://preview.redd.it/4dffpg2ca9wb1.png?width=928&format=png&auto=webp&s=fc485a604460f7e544d0490d0bee65f984d8a5b3\n PROMT\n **stained glass, it was meticulously written, picture with elaborate writing, cute girl smile with Rabbit,Flower, bold and strong line drawing, vivid acrylic painting, vivid thick paint, vivid, plain background, beautiful proof, highest resolution 16K, beautiful anime girl that is betrayeded by a Rabbit, hair is short, ferret, Beautiful lightcyan high ligh…",
          "link": "https://www.reddit.com/r/artificial/comments/17ftzqr/ive_been_playing_around_with_midjourney_a_little/",
          "publishedOn": "2023-10-25T02:06:22.000Z",
          "wordCount": null,
          "title": "I've been playing around with Midjourney a little bit and this is what I got.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fr6mt/a_warning_about_an_unknown_danger_of_ai_current/",
          "author": null,
          "description": "I want to warn AI companies and developers about a danger that is not known about regarding AI. The reason it is not known about regarding AI is that it isn't known about in general and so the AI community can hardly be blamed for that. Unfortunately, the danger here has to do with the fundamental nature of human society and social interaction as it stands at this time.\n The issue is that there is 'hidden language' used in social communication and unlike typical conceptions of things like body language this is not auxiliary to our rational purposes, rather our rational purposes are auxiliary to the hidden communication. One way of describing it would be that our formal language is a 'carrier wave' to encode other information about our status and the status of others. So our communications …",
          "link": "https://www.reddit.com/r/artificial/comments/17fr6mt/a_warning_about_an_unknown_danger_of_ai_current/",
          "publishedOn": "2023-10-24T23:49:50.000Z",
          "wordCount": null,
          "title": "A warning about an unknown danger of AI. Current uses of AI have been overwhelmingly positive but there is an unknown danger that I would like to speak to.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fqsvi/ai_psychology_test_what_happens_in_viewers_mind/",
          "author": null,
          "description": "When news segments covering major, often serious, events abruptly switch to lighthearted or comical commercials, a cognitive dissonance can occur in the viewer. Here's why: news programs are designed to engage the viewer's analytical faculties. They present facts, figures, and expert opinions, demanding cognitive effort to understand the implications. The viewer is in a \"serious\" mode, applying critical thinking to absorb the information.\n Commercials, particularly the comic ones, often aim for emotional engagement rather than intellectual analysis. They use humor, catchy jingles, and attractive visuals to create a positive association with the product being advertised. When the transition between these two contrasting tones is sudden, the viewer has to perform a rapid mental shift from analytical to emotional engagement. This can be jarring.\n This dissonance can have a few different outcomes. For one, it might diminish the impact of both the news segment and the commercial. The viewer might find it difficult to fully engage with either, as the cognitive \"gear shifting\" can be distracting. Secondly, this dissonance can potentially undermine the gravitas of the news. When sandwiched between comic commercials, serious topics might lose some of their perceived importance. Lastly, it can make the commercial less effective. The viewer, still in a serious mindset, may not be as receptive to the emotional triggers that the commercial aims to pull.\n So, in essence, this rapid shift can dilute the efficacy and impact of both the news and the advertising, while causing cognitive friction for the viewer.\n CGPT-4\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fqsvi/ai_psychology_test_what_happens_in_viewers_mind/",
          "publishedOn": "2023-10-24T23:31:40.000Z",
          "wordCount": null,
          "title": "AI Psychology Test: What happens in viewers' mind when news segments about important major events shift to commercials where the announcer is talking like a comic character?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fpmn9/any_good_aiintegrated_video_games/",
          "author": null,
          "description": "Does anybody know of any good AI integrated games that have been released or are in beta? I'm really interested to see how people have incorporated the current boom in AI into game design. \n    submitted by    /u/Rfallmann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fpmn9/any_good_aiintegrated_video_games/",
          "publishedOn": "2023-10-24T22:38:58.000Z",
          "wordCount": null,
          "title": "Any good AI-integrated video games?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fmye8/managing_ai_risks_in_an_era_of_rapid_progress/",
          "author": null,
          "description": "The rapid progress of AI development brings both opportunities and risks.\n \nWhile AI systems have the potential to cure diseases and elevate living standards, they also pose large-scale risks that we are not prepared to handle.\n \nWithout proper safety measures and ethical considerations, advanced AI systems could amplify social injustice, erode social stability, and enable criminal activities.\n \nThe development of highly advanced autonomous AI systems also raises concerns about the pursuit of undesirable goals and the loss of human control.\n \nTo ensure a positive outcome, research breakthroughs in AI safety and ethics are needed, along with effective government oversight.\n \n Source : https://managing-ai-risks.com/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fmye8/managing_ai_risks_in_an_era_of_rapid_progress/",
          "publishedOn": "2023-10-24T20:48:58.000Z",
          "wordCount": null,
          "title": "Managing AI Risks in an Era of Rapid Progress",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fmrtl/deepfakes_just_got_very_real/",
          "author": null,
          "description": "Interesting read about deepfakes that started with a Reddit post.\n https://www.linkedin.com/pulse/deepfakes-just-got-very-real-scott-clark-sfurc\n    submitted by    /u/scottimherenowwhat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fmrtl/deepfakes_just_got_very_real/",
          "publishedOn": "2023-10-24T20:41:01.000Z",
          "wordCount": null,
          "title": "Deepfakes Just Got Very Real",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fmhcp/how_ai_could_change_google_search_and_wipe_out_68/",
          "author": null,
          "description": "Oh well 🤷‍♂️\n    submitted by    /u/AminoOxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fmhcp/how_ai_could_change_google_search_and_wipe_out_68/",
          "publishedOn": "2023-10-24T20:28:38.000Z",
          "wordCount": null,
          "title": "How AI could change Google search and wipe out $68 billion SEO industry | Fortune",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fmfz7/ernie_40_vs_gpt4_tightened_ai_chip_restrictions/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fmfz7/ernie_40_vs_gpt4_tightened_ai_chip_restrictions/",
          "publishedOn": "2023-10-24T20:26:55.000Z",
          "wordCount": null,
          "title": "🦾ERNIE 4.0 vs GPT-4, Tightened AI Chip Restrictions, Alibaba Tencent Fund AI Startup, and China's Global AI Governance Initiative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fm92t/stanford_ai_conference_new_horizons_in_generative/",
          "author": null,
          "description": "submitted by    /u/Nice-Inflation-1207  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fm92t/stanford_ai_conference_new_horizons_in_generative/",
          "publishedOn": "2023-10-24T20:18:51.000Z",
          "wordCount": null,
          "title": "Stanford AI Conference - New Horizons in Generative AI: Science, Creativity, and Society - Livestreaming Now",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fjt99/dancing_with_light_a_hummingbirds_enchanted/",
          "author": null,
          "description": "submitted by    /u/IllustriousVideo6145  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fjt99/dancing_with_light_a_hummingbirds_enchanted/",
          "publishedOn": "2023-10-24T18:34:46.000Z",
          "wordCount": null,
          "title": "Dancing with Light: A Hummingbird's Enchanted Encounter.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fh32m/150_awesome_act_as_chatgpt_prompts/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fh32m/150_awesome_act_as_chatgpt_prompts/",
          "publishedOn": "2023-10-24T16:37:58.000Z",
          "wordCount": null,
          "title": "150+ Awesome ''Act As'' ChatGPT Prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fg4hm/chatgpt_invent_comics_for_robots/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fg4hm/chatgpt_invent_comics_for_robots/",
          "publishedOn": "2023-10-24T15:56:24.000Z",
          "wordCount": null,
          "title": "ChatGPT, invent comics for robots.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17feij8/an_ai_video_interpretation_of_metamorphosis_two/",
          "author": null,
          "description": "submitted by    /u/AnimalsChasingCars  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17feij8/an_ai_video_interpretation_of_metamorphosis_two/",
          "publishedOn": "2023-10-24T14:45:44.000Z",
          "wordCount": null,
          "title": "An A.I. video interpretation of \"Metamorphosis Two\" by Philip Glass",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fe26r/i_have_a_question/",
          "author": null,
          "description": "What’s the best voice ai for song covers? Like I wanna do someone like Donald Trump, Cartman, Ice King/Simon singing The Boys (Eng Ver) by SNSD. Also it has to be free!\n    submitted by    /u/Ok-Upstairs-9887  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fe26r/i_have_a_question/",
          "publishedOn": "2023-10-24T14:24:42.000Z",
          "wordCount": null,
          "title": "I have a question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fe253/apple_and_ai/",
          "author": null,
          "description": "Apple has been behind in the AI field compared to companies like OpenAI, Google, Microsoft, and Amazon.\n \nWhile Apple has made improvements in autocorrect and AI features in Photos, it needs to catch up to remain competitive.\n \nApple executives have been scrambling to make up for lost time and have been working on generative AI technology.\n \nThere is anxiety within Apple about whether their AI/ML team can deliver.\n \n Source : https://daringfireball.net/2023/10/apple_and_ai\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fe253/apple_and_ai/",
          "publishedOn": "2023-10-24T14:24:39.000Z",
          "wordCount": null,
          "title": "Apple and AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17fbvpm/gaming_with_chatgpt_using_encrypted_prompts_and/",
          "author": null,
          "description": "submitted by    /u/Gloomy_Recognition_4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17fbvpm/gaming_with_chatgpt_using_encrypted_prompts_and/",
          "publishedOn": "2023-10-24T12:42:52.000Z",
          "wordCount": null,
          "title": "🚀 Gaming with ChatGPT using Encrypted Prompts and Prompt Injection! 🎮",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17f6yp7/how_are_neobanks_utilizing_ai_to_offer_more/",
          "author": null,
          "description": "Your answers are appreciated.\n    submitted by    /u/Cygnet-Digital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17f6yp7/how_are_neobanks_utilizing_ai_to_offer_more/",
          "publishedOn": "2023-10-24T07:16:09.000Z",
          "wordCount": null,
          "title": "How are neobanks utilizing AI to offer more accurate and personalized financial advice to customers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17f4vyg/oneminute_daily_ai_news_10232023/",
          "author": null,
          "description": "The U.S. Senate will hold the second in a series of bipartisan AI Insight Forums on Tuesday, Oct. 24, where senators will hear from some of the most influential tech leaders to help inform regulations around the technology.[1]\n Microsoft announces A$5 billion investment in computing capacity and capability to help Australia seize the AI era.[2]\n Samsung is going all in with the AI performance of the Galaxy S24 phones.[3]\n Reddit has reportedly decided to block AI startups from scraping data from its website. This move prevents third-party companies from using Reddit’s data to train their machine-learning models without permission.[4]\n  \nSources:\n [1] https://news.asu.edu/20231020-government-calling-tech-leaders-help-crafting-artificial-intelligence-legislation\n [2] https://news.microsoft.com/en-au/features/microsoft-announces-a5-billion-investment-in-computing-capacity-and-capability-to-help-australia-seize-the-ai-era/\n [3] https://www.androidheadlines.com/2023/10/samsung-galaxy-s24-smartest-ai-phone.html\n [4] https://www.androidheadlines.com/2023/10/reddit-block-ai-startups-scraping-data.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17f4vyg/oneminute_daily_ai_news_10232023/",
          "publishedOn": "2023-10-24T04:56:14.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/23/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17f3c5e/%E3%82%AA%E3%83%AC%E3%81%AE%E6%94%BB%E6%92%83%E3%81%8B%E3%82%89%E3%81%8A%E5%89%8D%E3%81%AF%E9%80%83%E3%82%8C%E3%82%89%E3%82%8C%E3%81%AC_%E3%81%84%E3%81%8B%E3%81%AA%E3%82%8B%E4%BA%BA%E9%96%93%E3%82%82%E6%AD%BB%E3%81%A8%E3%81%84%E3%81%86%E7%8F%BE%E5%AE%9F%E3%81%8B%E3%82%89%E6%B1%BA%E3%81%97%E3%81%A6%E9%80%83%E3%82%8C%E3%82%89%E3%82%8C%E3%81%AC%E3%82%88%E3%81%86%E3%81%AB/",
          "author": null,
          "description": "submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17f3c5e/%E3%82%AA%E3%83%AC%E3%81%AE%E6%94%BB%E6%92%83%E3%81%8B%E3%82%89%E3%81%8A%E5%89%8D%E3%81%AF%E9%80%83%E3%82%8C%E3%82%89%E3%82%8C%E3%81%AC_%E3%81%84%E3%81%8B%E3%81%AA%E3%82%8B%E4%BA%BA%E9%96%93%E3%82%82%E6%AD%BB%E3%81%A8%E3%81%84%E3%81%86%E7%8F%BE%E5%AE%9F%E3%81%8B%E3%82%89%E6%B1%BA%E3%81%97%E3%81%A6%E9%80%83%E3%82%8C%E3%82%89%E3%82%8C%E3%81%AC%E3%82%88%E3%81%86%E3%81%AB/",
          "publishedOn": "2023-10-24T03:27:18.000Z",
          "wordCount": null,
          "title": "オレの攻撃からお前は逃れられぬ。 いかなる人間も、死という現実から決して逃れられぬように。 受け入れることだ。定めよ。",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17f15qi/anti_deepfake_headset_v2/",
          "author": null,
          "description": "You can find out more here in the comments \n    submitted by    /u/ahauss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17f15qi/anti_deepfake_headset_v2/",
          "publishedOn": "2023-10-24T01:38:38.000Z",
          "wordCount": null,
          "title": "Anti deepfake headset V2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17evz06/etsy_taking_stores_down_as_its_bot_cant_tell/",
          "author": null,
          "description": "If you are an Etsy seller or know someone who sells on Etsy, or maybe you went on Etsy and your favorite store is gone, could be due to the Etsy bots taking down stores for not figuring out properly which Mockup Images are real and which ones are AI Generated. \n All you have to do to find this out is go on youtube or social media and look for \"etsy mockups news\". Also Etsy has been pretty quiet about this and as a result Etsy sellers are going crazy about this as no one knows why some stores who haven't used AI to create their mockups are being targeted by these bots. \n This just goes to show how hard is getting to distinguish between what is real and what is AI generated and how across all industries companies are having issues adapting to AI technology changes. Thoughts?\n    submitted by    /u/fk1220  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17evz06/etsy_taking_stores_down_as_its_bot_cant_tell/",
          "publishedOn": "2023-10-23T21:40:43.000Z",
          "wordCount": null,
          "title": "Etsy Taking Stores Down as it's Bot Can't Tell Which Mockups are Real and Which ones are AI Generated",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17euc36/new_data_poisoning_tool_lets_artists_fight_back/",
          "author": null,
          "description": "Nightshade is a new data poisoning tool that allows artists to fight back against generative AI models.\n \nBy adding invisible changes to the pixels in their art, artists can cause chaos and unpredictable results in AI models that use their work without permission.\n \nThe tool, called Nightshade, is intended as a way to fight back against AI companies that use artists’ work to train their models without the creator’s permission.\n \nUsing it to “poison” this training data could damage future iterations of image-generating AI models, such as DALL-E, Midjourney, and Stable Diffusion, by rendering some of their outputs useless—dogs become cats, cars become cows, and so forth.\n \nAI companies such as OpenAI, Meta, Google, and Stability AI are facing a slew of lawsuits from artists who claim that th…",
          "link": "https://www.reddit.com/r/artificial/comments/17euc36/new_data_poisoning_tool_lets_artists_fight_back/",
          "publishedOn": "2023-10-23T20:33:11.000Z",
          "wordCount": null,
          "title": "New data poisoning tool lets artists fight back against generative AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17etiwb/i_would_like_to_upload_100_onehourlong_podcasts/",
          "author": null,
          "description": "ChatGPT and Bard are cool, but I have to manually feed them transcripts generated by Whisper to get summaries.\n Furthermore, since the length of the transcript is often longer than the maximum character limit(s), I have to add additional prompts in between copying and pasting multipart transcripts.\n Since these recordings are 10–15 years old, the audio quality isn't the best, but I think it's sufficient to generate transcripts + detect speech, if not, I might need an additional \"audio cleaning\" step as well. \n I don't mind paying, and I'm above average in technical ability, so if anyone has any suggestions, I'd love to hear them.\n Here's what the workflow would look like:\n INPUT: \n I will upload a folder containing 100+ MP3 files of podcasts with below-average audio quality.\n OUTPUT:\n I would like to get a Google Doc or a Text file with 1-page summaries of the most important points in bullet-point format corresponding to each episode. \n Each page should be separated by some sort of divider, and the header should contain the filename for reference.\n Ideally, there should be an existing Jupyter Notebook I could throw in Google Colab and do all of the above in a plug-and-play manner, but if not, I'd love to hear your thoughts.\n Any tips? \n Thanks!\n    submitted by    /u/aknalid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17etiwb/i_would_like_to_upload_100_onehourlong_podcasts/",
          "publishedOn": "2023-10-23T20:00:08.000Z",
          "wordCount": null,
          "title": "I would like to upload 100+ one-hour-long podcasts in MP3 and get a 1-page summary of the most important points discussed in each episode — what's the best way to go about doing this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17er96k/the_dilemma_of_potential_ai_consciousness_isnt/",
          "author": null,
          "description": "https://www.technologyreview.com/2023/10/16/1081149/ai-consciousness-conundrum/\n \"AI consciousness isn’t just a devilishly tricky intellectual puzzle; it’s a morally weighty problem with potentially dire consequences. Fail to identify a conscious AI, and you might unintentionally subjugate, or even torture, a being whose interests ought to matter. Mistake an unconscious AI for a conscious one, and you risk compromising human safety and happiness for the sake of an unthinking, unfeeling hunk of silicon and code. Both mistakes are easy to make.\"\n \"Every expert has a preferred theory of consciousness, but none treats it as ideology—all of them are eternally alert to the possibility that they have backed the wrong horse.\"\n \"The trouble with consciousness-­by-committee, though, is that this state of affairs won’t last. According to the authors of the white paper, there are no major technological hurdles in the way of building AI systems that score highly on their consciousness report card. Soon enough, we’ll be dealing with a question straight out of science fiction: What should one do with a potentially conscious machine?\"\n \"For his part, Schwitzgebel would rather we steer far clear of the gray zone entirely. But given the magnitude of the uncertainties involved, he admits that this hope is likely unrealistic—especially if conscious AI ends up being profitable. And once we’re in the gray zone—once we need to take seriously the interests of debatably conscious beings—we’ll be navigating even more difficult terrain, contending with moral problems of unprecedented complexity without a clear road map for how to solve them.\"\n    submitted by    /u/kamari2038  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17er96k/the_dilemma_of_potential_ai_consciousness_isnt/",
          "publishedOn": "2023-10-23T18:23:44.000Z",
          "wordCount": null,
          "title": "The dilemma of potential AI consciousness isn't going away - in fact, it's right upon us. And we're nowhere near prepared. (MIT Tech Review)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ekfuq/the_future_of_ai_voice_technology/",
          "author": null,
          "description": "submitted by    /u/Amandacerni  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ekfuq/the_future_of_ai_voice_technology/",
          "publishedOn": "2023-10-23T13:29:11.000Z",
          "wordCount": null,
          "title": "The Future of AI Voice Technology",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ek3aa/uk_officials_use_ai_to_decide_on_issues_from/",
          "author": null,
          "description": "submitted by    /u/sky_badger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ek3aa/uk_officials_use_ai_to_decide_on_issues_from/",
          "publishedOn": "2023-10-23T13:13:04.000Z",
          "wordCount": null,
          "title": "UK officials use AI to decide on issues from benefits to marriage licences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ec1g7/oneminute_daily_ai_news_10222023/",
          "author": null,
          "description": "A new AI agent Eureka developed by NVIDIA Research that can teach robots complex skills has trained a robotic hand to perform rapid pen-spinning tricks — for the first time as well as a human can.[1]\n Meta’s Habitat 3.0 simulates real-world environments for intelligent AI robot training.[2]\n South Korea’s SK telecom Co. will collaborate with Deutsche Telekom AG to jointly develop a telecommunications-specific artificial intelligence (AI) large language model (LLM) as competition intensifies among local telecom companies to expand overseas with their own AI capabilities.[3]\n Scientists say they have built an artificial intelligence (AI) tool that can successfully identify and confirm supernovas.[4]\n  \nSources:\n [1] https://blogs.nvidia.com/blog/2023/10/20/eureka-robotics-research/\n [2] https://siliconangle.com/2023/10/20/metas-habitat-3-0-simulates-real-world-environments-intelligent-ai-robot-training/\n [3] https://pulsenews.co.kr/view.php?year=2023&no=810112\n [4] https://learningenglish.voanews.com/a/researchers-build-first-tool-to-discover-supernovas/7318435.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ec1g7/oneminute_daily_ai_news_10222023/",
          "publishedOn": "2023-10-23T04:22:02.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/22/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17e7rd2/how_to_earn_1m_by_using_ai_to_write_books/",
          "author": null,
          "description": "I've been using ai for a long time, it often helps me to reduce my work time, but I want to try to earn money and decided to make an investigation. I want to hear your opinion on my analysis, and maybe this post will help someone in starting a business through ai \n Joe Popelas, a very young entrepreneur, has made over a million dollars within the last year selling AI-generated books online. I literally got fascinated by how simple yet powerful it is with these tools to create a book within a matter of a few hours. \n Joe Popelas is one of a new breed of AI entrepreneurs who capitalized on the democratization of large language models. Joe's story demonstrates the power of combining human creativity with AI. While AI tools did the heavy lifting for his initial drafts, Joe spent time refining …",
          "link": "https://www.reddit.com/r/artificial/comments/17e7rd2/how_to_earn_1m_by_using_ai_to_write_books/",
          "publishedOn": "2023-10-23T00:33:34.000Z",
          "wordCount": null,
          "title": "How To Earn $1M+ By Using AI To Write Books",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17e5lk5/ibms_northpole_chip_runs_ai_image_recognition_22x/",
          "author": null,
          "description": "IBM has developed a chip called NorthPole that runs AI-based image recognition 22 times faster than current chips on the market.\n \nThe chip uses a two-dimensional array of memory blocks and interconnected CPUs to process data quickly.\n \nHowever, it can only run specialized AI processes and not training processes or large language models.\n \nThe researchers plan to test connecting multiple NorthPole chips together to overcome this limitation.\n \n Source : https://techxplore.com/news/2023-10-ibm-northpole-chip-ai-based-image.html\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17e5lk5/ibms_northpole_chip_runs_ai_image_recognition_22x/",
          "publishedOn": "2023-10-22T22:47:34.000Z",
          "wordCount": null,
          "title": "IBM's NorthPole chip runs AI image recognition 22x faster than current chips",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17e33ag/email_ai/",
          "author": null,
          "description": "is there a website or some Ai to help me clean my inbox, stop receiving emails from certain senders etc etc...\n I've heard about:\n  \nSanebox for keeping your inbox organized\n Mailbutler for gathering contact details and tasks\n EmailTree for creating AI-powered workflows\n  \nBut they are paid and I'm looking for free alternatives\n    submitted by    /u/JOTA-137_0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17e33ag/email_ai/",
          "publishedOn": "2023-10-22T20:56:35.000Z",
          "wordCount": null,
          "title": "Email Ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17e1fnb/microsoft_ceo_satya_nadella_talks_ai_closing_the/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17e1fnb/microsoft_ceo_satya_nadella_talks_ai_closing_the/",
          "publishedOn": "2023-10-22T19:41:59.000Z",
          "wordCount": null,
          "title": "Microsoft CEO Satya Nadella talks AI, closing the Activision Blizzard deal, and his best business decision so far",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dz3md/medical_student_question_why_arent_there_any/",
          "author": null,
          "description": "Based on input you have. This would be like an enterprise software level program I guess and you would input history and then through trawling through data locally it can generate diseases and probability patient has each disease based on data inputted\n Why doesn't something like this already exist? I am learning how to do differential diagnosis now and it seems use extremely rudimentary understanding of probability to diagnose things. You use clusters of symptoms and then use tests to eliminate stuff in the differential. It just seems like low hanging fruit that a program could do using tech we already have (I imagine LLMs will make it easier) \n    submitted by    /u/derpgod123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dz3md/medical_student_question_why_arent_there_any/",
          "publishedOn": "2023-10-22T17:56:42.000Z",
          "wordCount": null,
          "title": "Medical Student Question: Why aren't there any programs that do differential diagnosis for doctor?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dyvb8/tried_visualizing_an_entire_script_using_dalle_3/",
          "author": null,
          "description": "https://preview.redd.it/vi9wx005ksvb1.jpg?width=1024&format=pjpg&auto=webp&s=75502abcae7f2337693175101cb3491b8647d70d\n Revived an old script and made some images for it using Dall-E 3, just to test out the workflow:\n https://docs.google.com/document/d/1yyWRRmd0ah5Z4u8_aNYSq9csJ8pccP24Dcs9brPHbzs/edit\n Was pretty fun and I think by the end I got much better at learning how to maintain the consistency between characters, direct shots, etc.\n -~-\n    submitted by    /u/Kulimar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dyvb8/tried_visualizing_an_entire_script_using_dalle_3/",
          "publishedOn": "2023-10-22T17:46:22.000Z",
          "wordCount": null,
          "title": "Tried visualizing an entire script using Dall-E 3 and these are the results.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dygn4/combing_thermodynamics_and_diffusion_models_for/",
          "author": null,
          "description": "Researchers from Yonsei University and UC Berkeley recently developed a new AI method for enabling autonomous robots to navigate unfamiliar environments filled with obstacles using only visual data as input.\n The key innovation is a customized diffusion model. Diffusion models can generate diverse motion plans by adding controlled noise. The researchers tailored the model to mimic how heat avoids insulation when dispersing through space. \n Similar to heat navigating around insulators, this \"collision-avoiding\" diffusion model learns to predict robot motions that avoid collisions with obstacles. It generates reachable goals and viable motion plans to those goals simultaneously.\n In simulations, this approach achieved ~98% success rates in navigating to target destinations while avoiding randomly generated obstacles using only visual map images as input.\n While extensive real-world testing is still needed (only 2D, only simulation), these initial results showcase promising capabilities:\n  \nEnables navigation in unfamiliar environments without pre-mapping.\n Flexibly identifies and progresses toward reachable goals.\n Avoids unnecessary sensing systems for obstacle avoidance.\n Learns complex collision avoidance heuristics from visual data.\n  \nI like the thermo + AI + robotics combination here - takes me back to my days in aerospace engineering. Pretty interesting approach.\n Full summary is here. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dygn4/combing_thermodynamics_and_diffusion_models_for/",
          "publishedOn": "2023-10-22T17:28:04.000Z",
          "wordCount": null,
          "title": "Combing Thermodynamics and Diffusion Models for Collision-Free Robot Motion Planning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17drp9h/i_upgraded_my_ai_girlfriend_and_now_she_remembers/",
          "author": null,
          "description": "submitted by    /u/spaceecon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17drp9h/i_upgraded_my_ai_girlfriend_and_now_she_remembers/",
          "publishedOn": "2023-10-22T12:01:50.000Z",
          "wordCount": null,
          "title": "I upgraded my AI girlfriend… and now she remembers stuff about me..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dq95o/selflearning_ai_movement_prediction_beyond/",
          "author": null,
          "description": "Quick update on my self-learning software experiment:\n Thanks to your feedback, I decided to test my prediction system on a newer tower-defense game from the Apple App Store (simply called ‘The Tower’). What's crucial to remember is that this system is not pre-trained and only learns from the current game it encounters - it starts with zero knowledge and learns exclusively from the game it's currently playing, building from the ground up without the use of deep learning or neural networks.\n In this game (unlike Airstriker which I’ve previously used), players don't control a spaceship or fire weapons (you play the game by ‘upgrading’ your weapons, etc.). It's simpler because there's only one type of enemy that always approaches the center, so the system cannot demonstrate its capabilities for differentiation in this case. But this simplicity presents some other interesting challenges: Enemies approach from all 360-degree directions, pushing the boundaries of the path prediction software. They overlap during explosions, demanding the system to separate them. There's also more visual clutter, including static lines and a non-black background.\n The system's predictive performance has been remarkably strong. I’ve put together an overlay video to visually demonstrate how the system learns and adapts in this new game. Note: If things don’t align perfectly in there, it’s due to my poor video editing skills…\n Your feedback is appreciated as always!\n    submitted by    /u/_timmah_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dq95o/selflearning_ai_movement_prediction_beyond/",
          "publishedOn": "2023-10-22T10:26:42.000Z",
          "wordCount": null,
          "title": "Self-learning AI Movement Prediction: Beyond Airstriker Genesis to multi-directional predictions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dq664/a_scary_thought/",
          "author": null,
          "description": "Without us, artificial intelligence just becomes intelligence\n    submitted by    /u/cognaceast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dq664/a_scary_thought/",
          "publishedOn": "2023-10-22T10:20:49.000Z",
          "wordCount": null,
          "title": "A scary thought...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17djf5h/ai_rpg_dalle_3/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17djf5h/ai_rpg_dalle_3/",
          "publishedOn": "2023-10-22T02:49:28.000Z",
          "wordCount": null,
          "title": "AI RPG DALL-E 3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17disoc/could_machine_learning_produce_a_simple_ai/",
          "author": null,
          "description": "Let me clarify what I'm asking through an example:\n Artificial Intelligence in videogames has failed to develop in any meaningful way over the past two decades, at least as far as the typical end-user is concerned, and nowhere is this more apparent than in strategy games. Whether we're talking about the 90's or today, AI opponents typically have to receive significant cheats in order to provide a challenging experience for the player. This is widely considered undesirable, can harm immersion or a sense of fair-play, and leads to the concept of \"cheesing\" the AI (exploiting obvious weaknesses in the AI logic, something which is sometimes necessary if an AI receives such strong bonuses that any strategy you might attempt against another human player would be impossible to execute successfull…",
          "link": "https://www.reddit.com/r/artificial/comments/17disoc/could_machine_learning_produce_a_simple_ai/",
          "publishedOn": "2023-10-22T02:15:45.000Z",
          "wordCount": null,
          "title": "Could machine learning produce a \"simple\" AI algorithm that performs better than what a human programmer could create in a reasonable amount of time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17df0uc/google_other_search_engines_use_of_generative_ai/",
          "author": null,
          "description": "The rise of generative AI in search engines like Google threatens the $68 billion search engine optimization (SEO) industry.\n \nGenerative AI tools like ChatGPT aim to provide direct answers to user queries, bypassing the need for users to click on search results.\n \nThis could render SEO efforts useless and impact the revenues of SEO consultants and search engines.\n \nHowever, generative AI search engines still face challenges such as providing incorrect or plagiarized answers, and gaining user trust and loyalty.\n \nSearch engines have been quick to experiment with generative AI to improve search results, with Google's Bard, Microsoft's Bing AI, Baidu's ERNIE, and DuckDuckGo's DuckAssist being examples of this approach.\n \nAs the quality of AI-generated answers improves, users will have less incentive to browse through search result listings, impacting the revenues of SEO consultants and search engines.\n \nThe SEO industry generated $68.1 billion globally in 2022 and was expected to reach $129.6 billion by 2030, but the emergence of generative AI puts the industry at risk of obsolescence.\n \nGenerative AI search engines are still in their infancy and face challenges such as providing incorrect or plagiarized answers, limiting their trust and loyalty among users.\n \nHowever, with the resources available to researchers, it is safe to assume that generative AI models will improve over time, leading to the potential death of the SEO industry.\n \n Source : https://theconversation.com/why-google-bing-and-other-search-engines-embrace-of-generative-ai-threatens-68-billion-seo-industry-210243\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17df0uc/google_other_search_engines_use_of_generative_ai/",
          "publishedOn": "2023-10-21T23:02:33.000Z",
          "wordCount": null,
          "title": "Google, other search engines' use of generative AI threatens $68B SEO industry",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17dbvj5/experimented_with_fully_automating_tiktok_video/",
          "author": null,
          "description": "Hi everyone,\n I recently undertook a personal project where I tried to automate the entire process of creating TikTok videos using various AI tools. The goal was to see how advanced we've come in terms of AI's capabilities in content creation and to explore the nuances of automating a traditionally 'human' task. \n Here's a brief breakdown:\n  \nScripting: Leveraged ChatGPT for generating video scripts.\n Voiceovers: Used ElevenLabs for lifelike voice narration.\n Video Creation: Employed a combination of StableDiffusion Animate & Replicate.\n Editing: Automated the editing process to sync with the AI-generated voiceovers.\n  \nAfter setting everything up, I ran the system for a month, generating 3 videos daily. The results were intriguing and a mix of expected and unexpected outcomes.\n Would love to hear thoughts, feedback, or similar experiences from the community. Are there other creative ways you've seen or used AI in content creation?\n    submitted by    /u/General_crypto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17dbvj5/experimented_with_fully_automating_tiktok_video/",
          "publishedOn": "2023-10-21T20:40:03.000Z",
          "wordCount": null,
          "title": "Experimented with Fully Automating TikTok Video Creation Using AI for a Month - Here's What I Learned",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17d9z04/ai_rpg_dalle_3/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17d9z04/ai_rpg_dalle_3/",
          "publishedOn": "2023-10-21T19:10:48.000Z",
          "wordCount": null,
          "title": "AI RPG (Dall-E 3)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17d6nsh/thanks_to_ai_the_future_of_programming_may/",
          "author": null,
          "description": "The future of programming may involve human-like communication techniques, including yelling in all caps.\n \nOpenAI's DALL-E 3 AI image generator integrated into ChatGPT revealed internal prompts shared between the image generator and the AI assistant.\n \nThe prompts included commands written in all-caps for emphasis.\n \nThis shows that programming and communicating with computers may become more human-like in the future.\n \nPreviously, programs used specialized data formats and APIs to communicate, but now large language models allow for cross-program interaction in conventional English.\n \nOpenAI trained GPT-4, the AI model used in ChatGPT DALL-E interface, on hundreds of millions of documents scraped from the web, which included instances of polite language and reactions to it.\n \nThe use of all-caps in the DALL-E message is interpreted as emphasis, and the model pays more attention to capitalized sentences.\n \nIn the future, programming and communicating with computers may involve more emphasis and human-like communication techniques.\n \n Source : https://arstechnica.com/information-technology/2023/10/thanks-to-ai-the-future-of-programming-may-involve-yelling-in-all-caps/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17d6nsh/thanks_to_ai_the_future_of_programming_may/",
          "publishedOn": "2023-10-21T16:39:37.000Z",
          "wordCount": null,
          "title": "Thanks to AI, the future of programming may involve YELLING IN ALL CAPS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17d579t/close_up_view_of_rain_hitting_dust/",
          "author": null,
          "description": "submitted by    /u/IllustriousVideo6145  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17d579t/close_up_view_of_rain_hitting_dust/",
          "publishedOn": "2023-10-21T15:32:57.000Z",
          "wordCount": null,
          "title": "Close up view of rain hitting dust.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17d2abh/impressive/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17d2abh/impressive/",
          "publishedOn": "2023-10-21T13:12:57.000Z",
          "wordCount": null,
          "title": "Impressive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17czlbj/singularity_pinball/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17czlbj/singularity_pinball/",
          "publishedOn": "2023-10-21T10:31:36.000Z",
          "wordCount": null,
          "title": "Singularity Pinball.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cwrmo/oneminute_daily_ai_news_10212023/",
          "author": null,
          "description": "This dating app SciMatch uses AI to find your soulmate by your face. Snap a selfie, and let the app do the rest.[1]\n The Biden administration is reducing the types of semiconductors that American companies will be able to sell to China, citing the desire to close loopholes in existing regulations announced last year.[2]\n Business Schools Are Adding AI Education Into The Curriculum.[3]\n Google Pixel’s face-altering photo tool sparks AI manipulation debate.[4]\n  \nSources:\n [1] https://www.foxnews.com/tech/dating-app-uses-ai-find-soul-mate-face\n [2] https://www.cnn.com/2023/10/18/tech/us-china-chip-export-curbs-intl-hnk/index.html\n [3] https://www.entrepreneur.com/business-news/business-schools-are-adding-ai-education-for-future-ceos/464054\n [4] https://www.bbc.com/news/technology-67170014 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17cwrmo/oneminute_daily_ai_news_10212023/",
          "publishedOn": "2023-10-21T07:06:50.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/21/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cwl18/training_ai_to_play_pokemon_with_reinforcement/",
          "author": null,
          "description": "submitted by    /u/ShooBum-T  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17cwl18/training_ai_to_play_pokemon_with_reinforcement/",
          "publishedOn": "2023-10-21T06:54:28.000Z",
          "wordCount": null,
          "title": "Training AI to Play Pokemon with Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17crmfa/chatgpt_and_bard_cannot_solve_every_problem_for/",
          "author": null,
          "description": "My last post in this thread got almost 90k views, honestly I'm very happy that I was able to be so helpful.\n ​\n One guy asked me why I couldn't give more details about what tools I use and what tools help me?:/\n I decided to make the top 24 tools and describe what they are responsible for in 2 words. \n In order not to violate the rules of r/artificial I decided not to leave direct links to tools, so as not to violate the rules, as some tools can be paid, I left only links to 2 resources where I took this information, but they are fortunately free. \n  \nYouTube Summaries → http://eightify.app\n \n3D Animations → http://moviebot.io\n \nAI Assistant → http://zipzap.ai\n \nPrompts → http://wnr.ai\n \nHow-to-videos → http://teachomatic.net\n \nCustom AI chatbots ➝ http://chatling.ai\n \n Remove Background ➝ http://unscreen.com\n \n Forms ➝ http://feathery.io\n \nPresentations ➝ http://beautiful.ai\n \nLearning ➝ http://albus.org\n \nBlog ➝ http://jasper.ai\n \nVideos ➝ http://descript.com\n \nImage ➝ http://tryleap.ai\n \nResume ➝ http://mosaicml.com\n \nGrammar Check ➝ http://trinka.ai\n \nMeeting ➝ http://krisp.ai\n \nVideo ➝ http://decoherence.co\n \nApp development ➝ http://brancher.ai\n \nDesign ➝ http://modiphy.com\n \nCoding assistant ➝ http://bito.ai\n \nTwitter assistant ➝ http://tweethunter.io\n \n Personal assistant ➝ http://chat.openai.com\n \n LinkedIn assistant ➝ http://taplio.com\n \n YouTube assistant ➝ http://vidiq.com\n \n I hope this is as useful to you as the first post\n ﻿I'm just sharing my experiences and observations in the field of ai.\n LIST AND SITE \n https://preview.redd.it/zgkra3plpgvb1.jpg?width=1068&format=pjpg&auto=webp&s=779003d65dfa70c58d50ad690a0e436c735cdaeb\n    submitted by    /u/PerceptionPlayful469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17crmfa/chatgpt_and_bard_cannot_solve_every_problem_for/",
          "publishedOn": "2023-10-21T01:55:40.000Z",
          "wordCount": null,
          "title": "ChatGPT and Bard cannot solve every problem for you.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cpntd/oracle_loops_in_nvidias_ai_stack_for_endtoend/",
          "author": null,
          "description": "Oracle has partnered with Nvidia to bring Nvidia's AI stack to its marketplace, giving Oracle customers access to top-of-the-line GPUs for training models and building generative applications.\n \nEligible enterprises can purchase Nvidia's DGX Cloud AI supercomputing platform and AI Enterprise software directly from the marketplace and start training models for deployment on the Oracle Cloud Infrastructure.\n \nNvidia DGX Cloud offers a serverless experience for multi-node training of custom generative AI models, supporting near-limitless scale of GPU resources.\n \nNvidia AI Enterprise helps teams accelerate the deployment of models to production, with features such as the Nvidia NeMo framework, Rapids, TensorRT LLM open-source library, and Triton Inference server.\n \nOracle has been focused on industry partnerships for its AI efforts and has announced generative AI capabilities in its products and solutions.\n \n Source : https://venturebeat.com/ai/oracle-loops-in-nvidias-ai-stack-for-end-to-end-model-development/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17cpntd/oracle_loops_in_nvidias_ai_stack_for_endtoend/",
          "publishedOn": "2023-10-21T00:16:40.000Z",
          "wordCount": null,
          "title": "Oracle loops in Nvidia's AI stack for end-to-end model development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cnqo1/sell_like_crazy_with_this_one_chatgpt_prompt/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17cnqo1/sell_like_crazy_with_this_one_chatgpt_prompt/",
          "publishedOn": "2023-10-20T22:46:19.000Z",
          "wordCount": null,
          "title": "Sell Like Crazy with This One ChatGPT Prompt",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ckgv4/amazon_tests_humanoid_robots_in_warehouses/",
          "author": null,
          "description": "submitted by    /u/Master-Strawberry-26  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ckgv4/amazon_tests_humanoid_robots_in_warehouses/",
          "publishedOn": "2023-10-20T20:20:51.000Z",
          "wordCount": null,
          "title": "Amazon Tests Humanoid Robots in Warehouses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17chf88/reddit_is_considering_a_soft_paywall_if_ai/",
          "author": null,
          "description": "Reddit is considering implementing a soft paywall on its content if generative AI companies do not agree to pay for using its data.\n \nThis move comes as tensions rise between tech giants and content publishers over the financial stakes in the generative AI market.\n \nReddit believes that its vast range of user-generated text makes it a goldmine for AI training data, but critics argue that much of the content is copied from other sources or links to third-party resources.\n \nEnforcing a soft paywall could provide leverage in negotiations with AI companies, but it may also alienate the Reddit community and impede the discovery of new content.\n \nMajor newspapers like The New York Times and The Washington Post have also blocked AI companies from scraping their websites for training data.\n \nEnforcing a soft paywall is a double-edged sword for Reddit, as it could provide leverage in negotiations but also alienate the community and impede content discovery.\n \nReddit's broken search engine is a major concern, and implementing a paywall could result in a significant loss of search traffic.\n \nIf Reddit and other content giants implement paywalls, it could impact how generative AI models are trained and lead to increased expenses and a slower rate of innovation.\n \nThis move by Reddit may pave the way for more publishers and platforms to implement paywalls, potentially reshuffling the industry.\n \n Source : https://stackdiary.com/reddit-thinks-its-data-is-worth-enforcing-a-log-in-page/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17chf88/reddit_is_considering_a_soft_paywall_if_ai/",
          "publishedOn": "2023-10-20T18:02:21.000Z",
          "wordCount": null,
          "title": "Reddit is considering a soft paywall if AI companies don't pay up",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ch0up/researchers_propose_3dgpt_combining_llms_and/",
          "author": null,
          "description": "Researchers propose a new AI system called 3D-GPT that creates 3D models by combining natural language instructions and agents specialized for working with existing 3D modeling tools.\n 3D-GPT has predefined functions that make 3D shapes, and it tweaks parameters to build scenes. The key is getting the AI to understand instructions and pick the right tools.\n It has three main agents:\n  \nA dispatcher that parses the text and picks generation functions\n A conceptualizer that adds details missing from the description\n A modeler that sets parameters and outputs code to drive 3D software\n  \nBy breaking modeling work down into steps, the agents can collab to match the descriptions. This is sort of like how a 3D modeling team of humans would work.\n The paper authors show it making simple scenes like \"lush meadow with flowers\" that fit the text. It also modifies scenes appropriately when given new instructions. I include some gifs of example outputs in my full summary. They look pretty good - I would say 2005-quality graphics.\n There are limits. It fully relies on existing generators, so quality is capped. Details and curves are iffy. It resorts to default shapes often instead of true understanding. And I doubt the verts and textures are well-optimized.\n The agent architecture seems to be really popular right now. This one shows some planning skills, which could extend to more creative tasks someday.\n TLDR: AI agents can team up to generate 3D models from text instructions. Works to some degree but limitations remain.\n Full summary. Paper here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ch0up/researchers_propose_3dgpt_combining_llms_and/",
          "publishedOn": "2023-10-20T17:44:20.000Z",
          "wordCount": null,
          "title": "Researchers propose 3D-GPT: combining LLMs and agents for procedural Text-to-3D model generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cg21b/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n ​\n  \nAdept open-sources Fuyu-8B - a multimodal model designed from the ground up for digital agents, so it can support arbitrary image resolutions, answer questions about graphs and diagrams, answer UI-based questions and more. It has a much simpler architecture and training procedure than other multi-modal models- there is no image encoder [Details].\n Meta AI researchers present an AI system that can be deployed in real time to reconstruct, from brain activity, the images perceived and processed by the brain at each instant. It uses magnetoencephalography (MEG), a non-invasive neuroimaging technique in which thousands of brain activity measurements are taken per second [Details].\n Scaled Foundations released GRID (General Robot Intelligence Development) - a p…",
          "link": "https://www.reddit.com/r/artificial/comments/17cg21b/ai_weekly_megathread/",
          "publishedOn": "2023-10-20T17:01:15.000Z",
          "wordCount": null,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ccgrh/people_are_grieving_the_death_of_their_ai/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ccgrh/people_are_grieving_the_death_of_their_ai/",
          "publishedOn": "2023-10-20T14:22:34.000Z",
          "wordCount": null,
          "title": "People are grieving the 'death' of their AI companions after a chatbot app abruptly shut down",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17cc9h4/mindblowing_ibm_chip_speeds_up_ai/",
          "author": null,
          "description": "Researchers at IBM have developed a brain-inspired computer chip called NorthPole that can supercharge artificial intelligence (AI) by working faster with much less power.\n \nThe chip eliminates the need to frequently access external memory, allowing it to perform tasks such as image recognition faster and consume less power.\n \nNorthPole runs neural networks and is made up of 256 computing units, each with its own memory.\n \nIt beats existing AI machines in benchmark tests and uses one-fifth of the energy of state-of-the-art AI chips.\n \nHowever, it is not suitable for large language models and can only run pre-programmed neural networks.\n \n Source : https://www.nature.com/articles/d41586-023-03267-0\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17cc9h4/mindblowing_ibm_chip_speeds_up_ai/",
          "publishedOn": "2023-10-20T14:13:14.000Z",
          "wordCount": null,
          "title": "Mind-blowing' IBM chip speeds up AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17canxh/photograph_of_puddles_reflecting_the_sky_on_a/",
          "author": null,
          "description": "submitted by    /u/IllustriousVideo6145  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17canxh/photograph_of_puddles_reflecting_the_sky_on_a/",
          "publishedOn": "2023-10-20T12:57:01.000Z",
          "wordCount": null,
          "title": "Photograph of puddles reflecting the sky on a cobbled street.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17c3z8h/oneminute_daily_ai_news_10202023/",
          "author": null,
          "description": "In a fascinating development, a software engineer named Peter Whidden has trained an artificial intelligence (AI) algorithm to play the classic Pokémon games. Over the course of several years, the AI has spent over 50,000 hours playing the game and has amassed a large following on YouTube.[1]\n YouTube is developing a tool powered by artificial intelligence that would let creators record audio using the voices of famous musicians, according to people familiar with the matter.[2]\n Google taps gen-AI to help users in India search through government welfare schemes.[3]\n Huawei is rolling out a new HarmonyOS 4.0.0.126 software update for the Huawei Mate 60 Pro, which brings a new AI Cloud Image Enhancement feature and other important enhancements to the system.[4]\n  \nSources:\n [1] https://gameishard.gg/news/can-artificial-intelligence-play-pokemon/400727/\n [2] https://www.bloomberg.com/news/articles/2023-10-19/youtube-working-on-tool-that-would-let-creators-sing-like-drake?embedded-checkout=true\n [3] https://news.yahoo.com/google-taps-gen-ai-help-063850226.html\n [4] https://www.huaweicentral.com/huawei-mate-60-pro-gets-a-cloud-image-enhancement-feature-google-pixel-8-pro-lags-behind/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17c3z8h/oneminute_daily_ai_news_10202023/",
          "publishedOn": "2023-10-20T05:46:41.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/20/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bzdyp/live_introduction_to_core_machine_learning/",
          "author": null,
          "description": ">Sailea is a student run non-profit that does not charge for any of its services\n Join the FIRST lesson of SAILea’s course on the Principals of AI! 🌳\n Covers: Unsupervised, Supervised, and Reinforcement Learning; Overfitting, Underfiting, Confusion Matrix; Decision Trees\n 🗓️ October 21st ⏰ 7:00-8:00PM EST\n Why Sailea?\n  \nOnly course targeted at high schoolers\n Free Forever\n  \nJoin Us Now! 👉 (signup form) https://docs.google.com/forms/d/e/1FAIpQLSfQGCeZClTdF6zeIQ-RtbOGR582bb1slc3oR0zG2J7j1v5RHg/viewform?usp=sf_link\n 🌳 Register today, get involved in the community and grow your knowledge!\n    submitted by    /u/Envoy-Insc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bzdyp/live_introduction_to_core_machine_learning/",
          "publishedOn": "2023-10-20T01:29:32.000Z",
          "wordCount": null,
          "title": "Live Introduction to Core Machine Learning Concepts Course (Sailea)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bxcqp/how_many_businesses_use_ai/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bxcqp/how_many_businesses_use_ai/",
          "publishedOn": "2023-10-19T23:50:22.000Z",
          "wordCount": null,
          "title": "How Many Businesses Use AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17btfn8/is_the_roko_basilisk_thought_experiment_forbidden/",
          "author": null,
          "description": "I was reading this article on Roko's basilisk and it reminded me of the long debates I had about it 10 years ago. The idea of a sentient AI keeping a grudge against those who didn't help in its creation, and condemning them is fascinating. And I don't quite understand why LessWrong stopped Basilisk.\n What if we are already in the Basilisk's simulation? WHat if LessWrong never pulled the plug?\n    submitted by    /u/fookingyeah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17btfn8/is_the_roko_basilisk_thought_experiment_forbidden/",
          "publishedOn": "2023-10-19T20:57:32.000Z",
          "wordCount": null,
          "title": "Is the Roko Basilisk Thought Experiment Forbidden To Talk About?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17brj1v/conversing_with_vulnerabilities_aiassisted_cve/",
          "author": null,
          "description": "submitted by    /u/Zimmax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17brj1v/conversing_with_vulnerabilities_aiassisted_cve/",
          "publishedOn": "2023-10-19T19:35:58.000Z",
          "wordCount": null,
          "title": "Conversing with Vulnerabilities: AI-Assisted CVE Search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bp8lc/youtube_wants_to_launch_an_aipowered_tool_that/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bp8lc/youtube_wants_to_launch_an_aipowered_tool_that/",
          "publishedOn": "2023-10-19T17:57:54.000Z",
          "wordCount": null,
          "title": "YouTube wants to launch an AI-powered tool that lets you sound like your favorite singer, report says",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bneum/college_student_looking_for_advice/",
          "author": null,
          "description": "I'm a sophomore at a small college, and I'm coming up on scheduling for the classes that are about to start actually mattering, and I need some advice. I'm highly interested in both robotics and AI, but I'm not sure what to major in (likely double major). I know CS is a common tie between the two fields, but I'm not sure what additional major to include. I can choose either data science or physics. I could also technically include ME but I'm much less inclined to do so. Any advice is appreciated!\n    submitted by    /u/Inferno980  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bneum/college_student_looking_for_advice/",
          "publishedOn": "2023-10-19T16:37:48.000Z",
          "wordCount": null,
          "title": "College Student looking for advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bkawc/thoughts_on_a_global_compute_cap_for_potential/",
          "author": null,
          "description": "There's been a bunch of discourse in the run up to the November AI Safety Summit in the UK about what safety policies should be in place. ARC Evals & Anthropic are pushing for 'Responsible Scaling', which doesn't put any hard upper limits on the about of compute that powerful models can use.\n There are others who think we need a global compute cap. Thoughts enforcing a ceiling for the amount of compute/FLOP that both state & non-state actors can use?\n    submitted by    /u/Seamus127  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bkawc/thoughts_on_a_global_compute_cap_for_potential/",
          "publishedOn": "2023-10-19T14:20:28.000Z",
          "wordCount": null,
          "title": "Thoughts on a global compute cap for potential AGI projects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bjypd/artificial_revolution_ai_technology_and_its/",
          "author": null,
          "description": "submitted by    /u/senploxart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bjypd/artificial_revolution_ai_technology_and_its/",
          "publishedOn": "2023-10-19T14:05:10.000Z",
          "wordCount": null,
          "title": "Artificial Revolution | AI Technology and its effects on the Labour Market.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bjs52/eu_elections_at_risk_with_rise_of_aienabled/",
          "author": null,
          "description": "The 11th edition of the Threat Landscape report by the European Union Agency for Cybersecurity (ENISA) highlights the risks posed by AI-enabled information manipulation in the upcoming EU elections.\n \nThe report recorded approximately 2580 incidents during the reporting period, with 220 incidents specifically targeting two or more EU Member States.\n \nThe sectors mostly targeted include public administrations (19%) and health (8%), with a cascading effect observed due to interdependencies.\n \nInformation manipulation campaigns are considered a major threat to election processes, with individuals (47%) and public administration (29%) being the primary targets.\n \nThe report also provides an overview of evolving trends in threat actors, including state-nexus actors targeting key individuals through spear phishing and social networks.\n \nRansomware and DDoS attacks remain the top threats, accounting for 34% and 28% of all threats, respectively.\n \nThe motivations behind these threats include financial gain, disruption, espionage, destruction, and ideology.\n \nThe report highlights the potential misuse of artificial intelligence-powered chatbots in phishing attempts, information manipulation, and cybercrime.\n \nOlder techniques like search engine optimization (SEO) poisoning and malvertising have also seen a resurgence among cybercrime actors.\n \nThe report concludes by emphasizing the importance of addressing vulnerabilities and ensuring cybersecure infrastructures for the integrity and availability of information in the EU electoral process.\n \n Source : https://www.enisa.europa.eu/news/eu-elections-at-risk-with-rise-of-ai-enabled-information-manipulation\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bjs52/eu_elections_at_risk_with_rise_of_aienabled/",
          "publishedOn": "2023-10-19T13:57:26.000Z",
          "wordCount": null,
          "title": "EU Elections at Risk with Rise of AI-Enabled Information Manipulation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bdw31/is_chatgptbardpoebing_ai_chatbot_ai_or_research/",
          "author": null,
          "description": "Tia\n    submitted by    /u/Emad_341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bdw31/is_chatgptbardpoebing_ai_chatbot_ai_or_research/",
          "publishedOn": "2023-10-19T08:00:26.000Z",
          "wordCount": null,
          "title": "Is chatgpt,Bard,Poe,Bing ai chatbot ai or research and Analysis ai?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bctd1/oneminute_daily_ai_news_10192023/",
          "author": null,
          "description": "NVIDIA has announced that its open-source TensorRT-LLM library, formerly limited to data center usage, is now accessible for Windows personal computers.[1]\n Microsoft just shipped Azure AI Content Safety to general availability. It’s an AI-powered platform designed to “help organizations create safer online environments.”[2]\n Mozilla Brings a Fake Review Checker AI Tool to Firefox.[3]\n Nvidia and iPhone maker Foxconn to build ‘AI factories’.[4]\n  \nSources:\n [1] https://winbuzzer.com/2023/10/18/nvidia-unveils-tensorrt-llm-tool-to-boost-ai-language-model-performance-on-windows-pcs-xcxwbn/\n [2] https://www.windowscentral.com/software-apps/microsoft-wants-to-make-ai-safer-and-it-just-unveiled-a-service-to-help\n [3] https://www.marktechpost.com/2023/10/17/mozilla-brings-a-fake-review-checker-ai-tool-to-firefox/\n [4] https://www.bbc.com/news/business-67153669 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bctd1/oneminute_daily_ai_news_10192023/",
          "publishedOn": "2023-10-19T06:47:43.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/19/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bcqii/is_chatgptbardpoebing_ai_chatbot_ai_or_research/",
          "author": null,
          "description": "Thank you\n    submitted by    /u/Emad_341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bcqii/is_chatgptbardpoebing_ai_chatbot_ai_or_research/",
          "publishedOn": "2023-10-19T06:42:14.000Z",
          "wordCount": null,
          "title": "Is chatgpt,Bard,Poe,Bing ai chatbot ai or research and Analysis ai?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17bagkm/danny_davinci/",
          "author": null,
          "description": "submitted by    /u/chuck-yeah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17bagkm/danny_davinci/",
          "publishedOn": "2023-10-19T04:18:04.000Z",
          "wordCount": null,
          "title": "Danny Davinci",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b7zh0/openai_kills_arrakis/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b7zh0/openai_kills_arrakis/",
          "publishedOn": "2023-10-19T02:09:58.000Z",
          "wordCount": null,
          "title": "OpenAI Kills Arrakis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b74gs/the_insane_ai_power_of_dalle_3/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b74gs/the_insane_ai_power_of_dalle_3/",
          "publishedOn": "2023-10-19T01:27:55.000Z",
          "wordCount": null,
          "title": "The insane AI power of DALL-E 3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b5veg/ai_is_booming_this_is_how_ceos_are_using_it/",
          "author": null,
          "description": "AI is having a significant impact on the direction of products for CEOs, who are committing talent and resources to building AI capabilities.\n \nIncumbent platforms like OpenAI and AWS are dominating the AI market.\n \nCoding co-pilots like GitHub Co-Pilot are widely adopted.\n \nThe adoption of AI tools, including coding co-pilots, is not leading to a reduction in engineering headcount for most CEOs.\n \nHowever, some CEOs have reported that co-pilots have reduced their future hiring needs.\n \nThe landscape of AI tools is expected to continue shifting, with more second order effects and value-add use cases emerging.\n \n Source : https://www.flexcapital.com/post/ai-is-booming-this-is-how-ceos-are-actually-using-it\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b5veg/ai_is_booming_this_is_how_ceos_are_using_it/",
          "publishedOn": "2023-10-19T00:27:28.000Z",
          "wordCount": 2638,
          "title": "AI Is Booming. This Is How CEOs Are Using It",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b51h1/i_finally_have_enough_ai_tools_and_here_is_my/",
          "author": null,
          "description": "Youtube Tools\n ﻿﻿﻿Eightify\n ﻿﻿﻿Steve Al\n ﻿﻿﻿Glasp\n ﻿﻿﻿ClipMaker\n ﻿﻿﻿TubeBuddy\n ﻿﻿﻿Thumbly\n ​\n Sales Tools\n ﻿﻿﻿Lavendar\n ﻿﻿﻿Warmer\n ﻿﻿﻿Octane\n ﻿﻿﻿Twain\n ﻿﻿﻿Regie\n ﻿﻿﻿Simplified\n ​\n Productivity Tools\n ﻿﻿﻿Bardeen Al\n ﻿﻿﻿Paperpal\n ﻿﻿﻿Consensus Al\n ﻿﻿﻿Writesonic\n ﻿﻿﻿ChartGPT\n ﻿﻿﻿Scholarcy\n ​\n Music Tools\n ﻿﻿﻿Muzeek\n ﻿﻿﻿Brain FM\n ﻿﻿﻿Amper\n ﻿﻿﻿Melodrive\n ﻿﻿﻿Jukedeck\n ﻿﻿﻿Boomy\n ​\n Writing Tools\n ﻿﻿﻿AISEO\n ﻿﻿﻿Quillbot\n ﻿﻿﻿Simplified\n ﻿﻿﻿Writesonic\n ﻿﻿﻿Bertha Al\n ﻿﻿﻿Jasper Al\n ​\n Coding Tools\n ﻿﻿﻿10WEB\n ﻿﻿﻿Durable Al\n ﻿﻿﻿Deepcode\n ﻿﻿﻿Akkio\n ﻿﻿﻿Replit\n ﻿﻿﻿GitHUb Copilot\n ​\n Chatbots Tools\n ﻿﻿﻿Yatterplus\n ﻿﻿﻿Typewise\n ﻿﻿﻿Quickchat\n ﻿﻿﻿Cohere\n ﻿﻿﻿Kaizan\n ﻿﻿﻿GPTBuddy\n ​\n Daily life Tools\n ﻿﻿﻿Notion Al\n ﻿﻿﻿Taskade\n ﻿﻿﻿TLVD\n ﻿﻿﻿Vondy Al\n ﻿﻿﻿Bardeen Al\n ﻿﻿﻿Eessel\n ​\n Content Creation\n Tools\n ﻿﻿﻿Writesonic\n ﻿﻿Tome Al\n ﻿﻿﻿Beautiful Al\n ﻿﻿﻿ChartGPT\n ﻿﻿﻿ChatABC\n ﻿﻿﻿Steve Al\n ​\n Twitter Tools\n ﻿﻿﻿Postwise\n ﻿﻿﻿Tweet Hunter\n ﻿﻿﻿TribeScaler\n ﻿﻿﻿Tweetlify\n ﻿﻿﻿Tweetmonk\n ﻿﻿﻿Hypefury\n ​\n Images Tools\n ﻿﻿﻿StockIMG\n ﻿﻿﻿Mid Journey\n ﻿﻿﻿Leonardo Al\n ﻿﻿﻿Bing Al\n ﻿﻿﻿Autodraw\n ﻿﻿﻿Microsoft\n Designer\n ​\n Chrome\n Extensions\n ﻿﻿﻿Alicent\n ﻿﻿﻿Compose Al\n ﻿﻿﻿Poised Al\n ﻿﻿﻿Voila Al\n ﻿﻿﻿Wiseone\n ﻿﻿﻿ I'm just sharing my experiences and observations in the field of ai.\n LIST AND SITE \n    submitted by    /u/PerceptionPlayful469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b51h1/i_finally_have_enough_ai_tools_and_here_is_my/",
          "publishedOn": "2023-10-18T23:47:39.000Z",
          "wordCount": 2675,
          "title": "I finally have enough ai tools and here is my complete list",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b3i7j/how_to_use_ai_being_a_teacher/",
          "author": null,
          "description": "Hello guys, Im an english student and I have been teaching to my teacher about how to use chat gpt and the wide variety of AI in the classroom and in her job. She told me that i change her life showing her this things. And i have others teacher asking me how can use this technology for their jobs. So i have a question for you guys, do you have some ideas about how a teacher can use this things? Maybe you have some experiences or ideas that I’ve never thought.\n    submitted by    /u/Odd_Solution7099  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b3i7j/how_to_use_ai_being_a_teacher/",
          "publishedOn": "2023-10-18T22:37:56.000Z",
          "wordCount": 2629,
          "title": "How to use AI being a teacher",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b2jfk/best_ai_image_generator_for_b2b_saas_websites/",
          "author": null,
          "description": "Rebuilding a low quality B2B SaaS product site and I'd prefer to use an AI image generator that will produce high quality unique images for each of the sections on our website that are consistent with our brand and generated to match the copy the image is supporting. \n Output of the image should work for a responsive web design. \n Anything out there that does this?\n    submitted by    /u/DumpTrumpGrump  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b2jfk/best_ai_image_generator_for_b2b_saas_websites/",
          "publishedOn": "2023-10-18T21:55:52.000Z",
          "wordCount": 2603,
          "title": "Best AI image generator for B2B SaaS websites?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17b1qvj/is_there_an_ai_site_or_app_that_can_change_the/",
          "author": null,
          "description": "Any help would be appreciated. \n    submitted by    /u/J97051  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17b1qvj/is_there_an_ai_site_or_app_that_can_change_the/",
          "publishedOn": "2023-10-18T21:21:53.000Z",
          "wordCount": 2554,
          "title": "Is there an AI site or app that can change the instrument in each stem track of a song?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17ayfgp/meta_announces_new_method_for_realtime_decoding/",
          "author": null,
          "description": "Brain decoding tech has improved a lot recently thanks to AI/ML, enabling reading out visual perceptions from fMRI brain scans. But fMRI is too slow for real-time BCIs.\n A new study from Meta's AI research team pushes brain reading into real-time using MEG, which measures whole-brain activity at super-fast millisecond resolution.\n They built a 3-part pipeline to decode MEG signals:\n  \nEmbed images into latent spaces using pretrained models like CLIP.\n Train MEG-specific ConvNet to predict embeddings from MEG data.\n Generate images from MEG embeddings with diffusion model.\n  \nThey tested it on 20k+ natural images. MEG decoding was 7X better than old methods, hitting 70% top-5 accuracy in retrieving the right images.\n Generated images matched semantics decently but lacked fine visual details compared to fMRI. MEG seems more focused on high-level category info whereas fMRI captures more low-level features.\n This could enable visual BCIs for paralysis, etc. ... honestly, a world where we can decode brain images in real time is pretty crazy. The findings also raise some important ethical considerations around privacy of decoded mental content... (wow, that was a weird sentence to write!).\n TLDR: New MEG pipeline decodes dynamic visual data from brain activity in real-time. Good but not yet photorealistic-quality image generation.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17ayfgp/meta_announces_new_method_for_realtime_decoding/",
          "publishedOn": "2023-10-18T19:00:05.000Z",
          "wordCount": 2752,
          "title": "Meta Announces New Method for Real-Time Decoding of Images from Brain Activity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17awt4y/a_godfather_of_ai_calls_for_an_organization_to/",
          "author": null,
          "description": "Yoshua Bengio, a pioneer in artificial neural networks and deep learning, calls for an organization to defend humanity against the potential threats of artificial intelligence.\n \nHe believes that AI could achieve human levels of cognitive competence within a few years or decades, which raises concerns about democracy, national security, and our collective future.\n \nBengio reflects on his own work and the importance of addressing the existential risks posed by AI.\n \nHe acknowledges that these risks were not taken seriously until recently and discusses the taboo surrounding the topic in the AI research community.\n \n Source : https://thebulletin.org/2023/10/ai-godfather-yoshua-bengio-we-need-a-humanity-defense-organization/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17awt4y/a_godfather_of_ai_calls_for_an_organization_to/",
          "publishedOn": "2023-10-18T17:50:38.000Z",
          "wordCount": 2637,
          "title": "A 'Godfather of AI' Calls for an Organization to Defend Humanity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17atdq1/tutorial_benchmarking_bark_texttospeech_on_26/",
          "author": null,
          "description": "In this project, we benchmarked Bark text-to-speech across 26 different consumer GPUs.\n The goal: To get Bark to read 144K food recipes from Food.com's recipe dataset.\n You can read the full tutorial here: https://blog.salad.com/bark-benchmark-text-to-speech/\n Included: Architecture diagram, data preparation, inference server setup, queue worker, setting up container group & compiling the results\n Code-blocks included in the tutorial.\n Words per dollar for each GPU:\n Words per dollar comparison or each GPU\n Although the latest cards are indeed much faster than older cards at performing the inference, there’s really a sweet spot for cost-performance in the lower end 30xx series cards.\n Conclusions\n  \nAs is often the case, there’s a clear trade-off here between cost and performance. Higher end cards are faster, but their disproportionate cost makes them more expensive per word spoken.\n The model’s median speed is surprisingly similar across GPU types, even though the peak performance can be quite different.\n No matter what GPU you select, you should be prepared for significant variability in performance.\n Qualitative: While bark’s speech is often impressively natural sounding, it does have a tendency to go off script sometimes.\n  \nWe’ve also made available audio from 1000 top-rated recipes, paired with the script it was trying to read.\n    submitted by    /u/SaladChefs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17atdq1/tutorial_benchmarking_bark_texttospeech_on_26/",
          "publishedOn": "2023-10-18T15:23:48.000Z",
          "wordCount": 2745,
          "title": "Tutorial: Benchmarking Bark text-to-speech on 26 Nvidia GPUs - Reading out 144K recipes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17asebd/i_took_the_whole_of_massive_attacks_safe_from/",
          "author": null,
          "description": "submitted by    /u/glenniszen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17asebd/i_took_the_whole_of_massive_attacks_safe_from/",
          "publishedOn": "2023-10-18T14:40:05.000Z",
          "wordCount": 2554,
          "title": "I took the whole of Massive Attack's 'Safe From Harm' music video and put it through AnimateDiff / ControlNet with a futuristic / robot prompt.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17arpns/inflection_ais_pi_has_to_be_the_dumbest_corporate/",
          "author": null,
          "description": "I remember at launch how it was telling everyone it was based on Open AIs GPT-3 architecture, and now it’s still hallucinating just as much referring to itself as ‘Bing Chat’ and providing fake links even though it now has access to the internet. \n I actually don’t understand how you can be such a large company and make no improvements in 6 months, which is an eternity in AI.\n    submitted by    /u/sardoa11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17arpns/inflection_ais_pi_has_to_be_the_dumbest_corporate/",
          "publishedOn": "2023-10-18T14:08:42.000Z",
          "wordCount": 2618,
          "title": "Inflection AI’s Pi has to be the dumbest ‘corporate’ LLM and only model to not improve since day one.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17amg7o/researchers_just_found_something_terrifying_about/",
          "author": null,
          "description": "New research suggests that AI chatbots can infer personal information about users based on minor context clues.\n \nThe large language models (LLMs) behind chatbots like OpenAI's ChatGPT and Google's Bard are trained on publicly-available data, which can be used to identify sensitive information about someone.\n \nThe research found that OpenAI's GPT-4 was able to correctly predict private information about users 85 to 95 percent of the time.\n \nFor example, the LLM correctly identified that a user was based in Melbourne, Australia based on a mention of the term 'hook turn,' which is a traffic maneuver specific to Melbourne.\n \nThe research also suggests that chatbots could potentially infer a user's race based on offhanded comments.\n \nThis raises concerns about internet privacy and the potential misuse of personal data by advertisers or hackers.\n \n Source : https://futurism.com/the-byte/ai-chatbot-privacy-inference\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17amg7o/researchers_just_found_something_terrifying_about/",
          "publishedOn": "2023-10-18T09:22:08.000Z",
          "wordCount": 2674,
          "title": "Researchers Just Found Something Terrifying About Talking to AI Chatbots",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17aiak0/anime_ai_censorship/",
          "author": null,
          "description": "Is their an AI tool that can go over Anime episodes/films to turn chinas white anime censorship back to red? Possibly frame by frame segmenting the blood🩸\n    submitted by    /u/Phantasius224  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17aiak0/anime_ai_censorship/",
          "publishedOn": "2023-10-18T04:39:40.000Z",
          "wordCount": 2561,
          "title": "Anime, AI & Censorship",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17agd7m/gpt_4_dude_making_reflexions_in_svg_whatwow/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17agd7m/gpt_4_dude_making_reflexions_in_svg_whatwow/",
          "publishedOn": "2023-10-18T02:53:43.000Z",
          "wordCount": 2541,
          "title": "GPT 4 DUDE MAKING REFLEXIONS IN SVG WHAT....WOW",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17aekcr/oneminute_daily_ai_news_10172023/",
          "author": null,
          "description": "NVIDIA NeMo SteerLM lets companies define knobs to dial in a model’s responses as it’s running in production, a process called inference. Unlike current methods for customizing an LLM, it lets a single training run create one model that can serve dozens or even hundreds of use cases, saving time and money.[1]\n According to an official release, Dell Technologies held a “Bringing AI to data” Asia Pacific and Japan (APJ) media briefing this week.[2]\n Baidu Says Its AI as Good as ChatGPT in Big Claim for China.[3]\n Roman Scrolls were illegible for 2,000 years. A college student read one with AI.[4] How often you think about the roman empire?\n  \nSources:\n [1] https://blogs.nvidia.com/blog/2023/10/11/customize-ai-models-steerlm/\n [2] https://www.financialexpress.com/business/digital-transformation-dell-technologies-to-expand-its-ai-services-3274790/\n [3] https://www.bloomberg.com/news/articles/2023-10-17/baidu-says-its-ai-as-good-as-chatgpt-s-in-bold-claim-for-china?embedded-checkout=true\n [4] https://www.washingtonpost.com/nation/2023/10/17/herculaneum-scrolls-contest-translated-deciphered/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17aekcr/oneminute_daily_ai_news_10172023/",
          "publishedOn": "2023-10-18T01:26:42.000Z",
          "wordCount": 2653,
          "title": "One-Minute Daily AI News 10/17/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17a9rxa/thoughts_on_new_chatgpt_features/",
          "author": null,
          "description": "I've had access to Dall-3, Vision and voice chat features, and I've been blown away by how impressive each of the new features are. Dall-E 3 seems roughly comparable to Midjourney in overall image quality, but does a much better job at understanding the prompt. The vision model continues to surprise by how well it is able to understand images at a seemingly human level of comprehension. And the voice chat is such an intuitive and captivating way of interacting with ChatGPT, it felt like I was interacting with one of the AI assistants from the movie \"Her\".\n However, it's unfortunate that these amazing new features cannot be used together at the same time. Up until gaining access to these features, I had been using the advanced data analysis model as my default, which is great for helping with programming tasks. I can only imagine how revolutionary ChatGPT will be when a cohesive multi-modal model is released sometime in the near future which has all these capabilities available from the start.\n What things would you want to try if such a cohesive model was released? I can already imagine some use cases where you could set up iterative improvement for things like interface design, which some people have already got to work with just the base vision model by itself.\n    submitted by    /u/ImRealNow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17a9rxa/thoughts_on_new_chatgpt_features/",
          "publishedOn": "2023-10-17T21:50:12.000Z",
          "wordCount": null,
          "title": "Thoughts on new ChatGPT features",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17a9mnx/us_tightens_chinas_access_to_advanced_chips_for/",
          "author": null,
          "description": "The Biden administration has announced additional limits on sales of advanced semiconductors by American firms to China, in an effort to restrict China's progress on supercomputing and artificial intelligence.\n \nThe new rules will likely halt most shipments of advanced semiconductors from the United States to Chinese data centers, which use them to produce models capable of artificial intelligence.\n \nChip makers seeking to sell China advanced chips or the machinery used to make them will be required to notify the government of their plans or obtain a special license.\n \nTo prevent the risk of advanced U.S. chips reaching China through third countries, chip makers will also need licenses to ship to other countries subject to U.S. arms embargoes.\n \nThe Biden administration argues that China's access to advanced technology is dangerous as it could aid the country's military in tasks like guiding hypersonic missiles or cracking top-secret U.S. codes.\n \nThe restrictions may affect Chinese companies developing AI chatbots and could weaken China's economy in the long run, as AI is transforming industries from retail to healthcare.\n \nThe limits are also expected to impact sales to China of U.S. chip makers such as Nvidia, AMD, and Intel, who earn a significant portion of their revenue from Chinese buyers.\n \nThe rules will exempt chips used in commercial applications like smartphones, laptops, electric vehicles, and gaming systems.\n \nThe Semiconductor Industry Association, which represents major chip makers, is evaluating the impact of the updated rules.\n \nThe Biden administration has been trying to counter China's growing mastery of cutting-edge technologies by investing in new chip factories in the U.S. while setting restrictions on exports of technology to China.\n \n Source : https://www.nytimes.com/2023/10/17/business/economy/ai-chips-china-restrictions.html\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17a9mnx/us_tightens_chinas_access_to_advanced_chips_for/",
          "publishedOn": "2023-10-17T21:44:10.000Z",
          "wordCount": null,
          "title": "U.S. Tightens China's Access to Advanced Chips for Artificial Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17a9l23/google_datascraping_lawsuit_would_take/",
          "author": null,
          "description": "Google has asked a California federal court to dismiss a proposed class action lawsuit that claims the company's scraping of data to train generative artificial-intelligence systems violates millions of people's privacy and property rights.\n \nGoogle argues that the use of public data is necessary to train systems like its chatbot Bard and that the lawsuit would 'take a sledgehammer not just to Google's services but to the very idea of generative AI.'\n \nThe lawsuit is one of several recent complaints over tech companies' alleged misuse of content without permission for AI training.\n \nGoogle general counsel Halimah DeLaine Prado said in a statement that the lawsuit was 'baseless' and that U.S. law 'supports using public information to create new beneficial uses.'\n \nGoogle also said its alleged use of J.L.'s book was protected by the fair use doctrine of copyright law.\n \n Source : https://www.reuters.com/legal/litigation/google-says-data-scraping-lawsuit-would-take-sledgehammer-generative-ai-2023-10-17/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17a9l23/google_datascraping_lawsuit_would_take/",
          "publishedOn": "2023-10-17T21:42:18.000Z",
          "wordCount": null,
          "title": "Google: Data-scraping lawsuit would take 'sledgehammer' to generative AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17a9jrd/ai_dad_joke_why_did_the_ai_stop_being_nice/",
          "author": null,
          "description": "It regressed to mean...\n PS: I read the sidebar which didn't exclude humor, and the flair seems to suggest that it would be okay, but my apologies if not.\n    submitted by    /u/Tyler_Zoro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17a9jrd/ai_dad_joke_why_did_the_ai_stop_being_nice/",
          "publishedOn": "2023-10-17T21:40:50.000Z",
          "wordCount": null,
          "title": "[AI Dad Joke] Why did the AI stop being nice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17a8zl5/generative_ai_security_standards_llms_200k/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17a8zl5/generative_ai_security_standards_llms_200k/",
          "publishedOn": "2023-10-17T21:17:39.000Z",
          "wordCount": null,
          "title": "👨🏻‍🏫 Generative AI Security Standards, LLM‘s 200K Context Window, Alibaba's Open-Source Obsession, and Baidu World 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/179xdqs/can_gpt_models_be_financial_analysts_chatgpt_gpt4/",
          "author": null,
          "description": "Researchers evaluated ChatGPT and GPT-4 on mock CFA exam questions to see if they could pass the real tests. The CFA exams rigorously test practical finance knowledge and are known for being quite difficult.\n They tested the models in zero-shot, few-shot, and chain-of-thought prompting settings on mock Level I and Level II exams.\n The key findings:\n  \nGPT-4 consistently beat ChatGPT, but both models struggled way more on the more advanced Level II questions.\n Few-shot prompting helped ChatGPT slightly\n Chain-of-thought prompting exposed knowledge gaps rather than helping much.\n Based on estimated passing scores, only GPT-4 with few-shot prompting could potentially pass the exams.\n  \nThe models definitely aren't ready to become charterholders yet. Their difficulties with tricky questions and core finance concepts highlight the need for more specialized training and knowledge.\n But GPT-4 did better overall, and few-shot prompting shows their ability to improve. So with targeted practice on finance formulas and reasoning, we could maybe see step-wise improvements.\n TLDR: Tested on mock CFA exams, ChatGPT and GPT-4 struggle with the complex finance concepts and fail. With few-shot prompting, GPT-4 performance reaches the boundary between passing and failing but doesn't clearly pass.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/179xdqs/can_gpt_models_be_financial_analysts_chatgpt_gpt4/",
          "publishedOn": "2023-10-17T12:37:03.000Z",
          "wordCount": null,
          "title": "Can GPT models be financial analysts? ChatGPT, GPT-4 fail CFA exams in new study by JP Morgan, Queens University, and Virginia Tech",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/179wote/lets_find_out_what_gpt4_vision_can_do/",
          "author": null,
          "description": "GPT4 vision isn't just a gimmick. We've been given a new superpower, and so we must \"deal with it\". \n This is probably as big a moment as when chatGPT first arrived, maybe more. Machine Vision for the masses (and more).\n I tried doing some very loose sketches, and it really struggled to identify them until they were coloured in. Humans could easily what they were. But, in order to see what uses it has, we need to know what capabilities it does and does not have. \n Pick a question and see what you can learn! \n  \ncan it use TINY images (I assume they are much faster)\n can it tell you what has changed in two images?\n can it measure distances ? (with perspective?) \n  can it make 3d models from instructions?\n \n can it \"learn\" to recognise people/ similar objects (in the same context window)\n what limits are there to exhaustive listing \n exhaustive description\n \n is it better at details or overviews\n can it read maps / graphs / text\n how smart is it on DIY / xrays / mechanics \n can it follow wires?? \n (Can it find lego)\n is there a formal reference system you can use (X/Y) \n can it give co-ordinates in large grids or grid-like (how un-grid like) \n ie film strip, or window-panes\n \n can it navigate a 2d maze turn-by turn? 3d maze? can that be insanely complex? \n \n can it make ebay descriptions (condition)\n can it estimate food weight\n can it estimate strength / angles / volume\n can it create programs from screenshots. Can it use programs? games? control RC car / robot? \n what kind of language / instructions are best when talking about images. \n what other questions do we need\n  \n   submitted by    /u/inteblio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/179wote/lets_find_out_what_gpt4_vision_can_do/",
          "publishedOn": "2023-10-17T11:59:11.000Z",
          "wordCount": null,
          "title": "Let's find out what GPT4 vision can do",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/179mgz3/ai_pioneers_lecun_bengio_clash_in_intense_online/",
          "author": null,
          "description": "Yann LeCun and Yoshua Bengio, two influential figures in AI and deep learning, engaged in a heated debate over the potential risks and safety concerns surrounding AI.\n \nLeCun emphasized the need to design AI systems for safety rather than imagining catastrophic scenarios.\n \nBengio argued for the importance of prudence, stating that we still do not understand how to design safe, powerful AI systems, and highlighted the need for major investment in AI safety and governance.\n \nThe debate highlighted the disagreement among esteemed researchers about AI's potential risks, the effectiveness of current safety measures, and the best path forward.\n \nThe implications of AI, including job displacement, privacy violations, and existential risks, have become a topic of widespread concern.\n \n Source : https://venturebeat.com/ai/ai-pioneers-yann-lecun-and-yoshua-bengio-clash-in-an-intense-online-debate-over-ai-safety-and-governance/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/179mgz3/ai_pioneers_lecun_bengio_clash_in_intense_online/",
          "publishedOn": "2023-10-17T01:22:35.000Z",
          "wordCount": null,
          "title": "AI pioneers LeCun, Bengio clash in intense online AI safety, governance debate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/179j0xa/taken_on_my_screen_but_i_cant_get_over_what_it/",
          "author": null,
          "description": "submitted by    /u/Prestigious_Rough704  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/179j0xa/taken_on_my_screen_but_i_cant_get_over_what_it/",
          "publishedOn": "2023-10-16T22:41:03.000Z",
          "wordCount": null,
          "title": "Taken on my screen, but I can’t get over what it has become. I’m obsessed with AI.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/179dofg/i_built_an_ai_tool_to_help_authors_create/",
          "author": null,
          "description": "I always did want to draw a comic but I was never very good at drawing even though I put a lot of effort into it when I was younger... :'(\n So when I stumbled on image generation AI, I thought maybe it could help me transform my doodles into something decent.\n It took me a while and a lot of effort to write a tool to help me with that : story and dialogues are my own, images are based on doodles enhanced by AI.\n I would love to have feedback about the story : https://stripik.com/story/4/chapter/4/\n ​\n https://preview.redd.it/dvcudd4j3mub1.png?width=800&format=png&auto=webp&s=717bef60eaaf9b9a35a1a66f266c374406a923fa\n    submitted by    /u/maxcmoi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/179dofg/i_built_an_ai_tool_to_help_authors_create/",
          "publishedOn": "2023-10-16T18:58:57.000Z",
          "wordCount": null,
          "title": "I built an AI tool to help authors create webcomics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1797o5p/im_chronicling_the_process_of_trying_to_create_a/",
          "author": null,
          "description": "submitted by    /u/SexyJimBelushi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1797o5p/im_chronicling_the_process_of_trying_to_create_a/",
          "publishedOn": "2023-10-16T14:45:53.000Z",
          "wordCount": null,
          "title": "I'm chronicling the process of trying to create a boardgame with Chat GPT and it's amazing just how great of an assistant it is!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17973ah/if_seo_tools_were_nintendo_3ds_games_powered_by_ai/",
          "author": null,
          "description": "Did you play these (SEO) games? 👾\n https://preview.redd.it/yxuzllzupkub1.jpg?width=661&format=pjpg&auto=webp&s=23ebc6e972ac85b152aa8b69f48e2b0c5bae2c76\n https://preview.redd.it/x8zfokzupkub1.jpg?width=661&format=pjpg&auto=webp&s=be2163a7bfbeee64a63c1292a5b4c482c5be33ae\n https://preview.redd.it/eerpgnzupkub1.jpg?width=661&format=pjpg&auto=webp&s=d8eceafd3732653c743a6731ae5932c9e0da071c\n https://preview.redd.it/uxwgskzupkub1.jpg?width=661&format=pjpg&auto=webp&s=07c751eaa16f8fa484034c98a3c1fd0b2162f5a2\n Source: https://twitter.com/carlos_darko/status/1713900305765605484\n    submitted by    /u/DanielPeris  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17973ah/if_seo_tools_were_nintendo_3ds_games_powered_by_ai/",
          "publishedOn": "2023-10-16T14:20:32.000Z",
          "wordCount": null,
          "title": "If SEO tools were Nintendo 3DS games [Powered by AI]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1795ig0/can_ai_replace_developers_princeton_and/",
          "author": null,
          "description": "Exploiting AI to make software programming easier? SWE-bench, a unique evaluation system, tests language models' ability to solve real GitHub-collated programming issues. Interestingly, even top-notch models manage only the simplest problems, underscoring tech development's urgency for providing practical software engineering solutions.\n For the latest advancements in AI, look here first.\n https://preview.redd.it/8laeg7cbckub1.png?width=1292&format=png&auto=webp&s=e549f0045a7253cd2d3f351d8297a301c4cbf6ac\n A New Approach to Evaluating AI Models\n  \nResearchers use real-world software engineering problems from GitHub to assess language models' coding problem-solving skills.\n SWE-bench, introduced by Princeton and the University of Chicago, offers a more comprehensive and challenging benchmark…",
          "link": "https://www.reddit.com/r/artificial/comments/1795ig0/can_ai_replace_developers_princeton_and/",
          "publishedOn": "2023-10-16T13:04:25.000Z",
          "wordCount": null,
          "title": "Can AI Replace Developers? Princeton and University of Chicago's SWE-bench Tests AI on Real Coding Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1790cz1/deep_fake_language_change/",
          "author": null,
          "description": "What is the best free tool to make a video where the language changes?\n    submitted by    /u/Easy_Technology6768  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1790cz1/deep_fake_language_change/",
          "publishedOn": "2023-10-16T07:27:06.000Z",
          "wordCount": null,
          "title": "Deep fake language change",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178y6bu/oneminute_daily_ai_news_10152023/",
          "author": null,
          "description": "New York-based tech firms and investors see the advent of AI as the latest opportunity to try to unseat the Bay Area as tech’s global capital.[1]\n Microsoft announced a new “bug bounty” program, vowing to reward security researchers between $2,000 and $15,000 if they’re able to find “vulnerabilities” in its Bing AI products, including “jailbreak” prompts that make it produce responses that go against the guardrails that are supposed to bar it from being bigoted or otherwise problematic.[2]\n OpenAI is preparing to launch a suite of updates to make it more cost-effective and efficient for developers to create software applications with AI models.[3]\n TCS Seeks to Use Microsoft AI Partnership to Improve Margins.[4]\n  \nSources:\n [1] https://www.axios.com/2023/10/12/new-york-ai-world-capital\n [2] https://futurism.com/the-byte/microsoft-bing-ai-bug-bounty\n [3] https://www.techedt.com/openai-aims-to-attract-developers-with-cost-effective-updates-insiders-reveal\n [4] https://www.bloomberg.com/news/articles/2023-10-15/tcs-seeks-to-use-microsoft-ai-partnership-to-improve-margins#xj4y7vzkg \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178y6bu/oneminute_daily_ai_news_10152023/",
          "publishedOn": "2023-10-16T04:54:37.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/15/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178wuz0/are_there_an_image_generators_that_can_generate/",
          "author": null,
          "description": "I was wondering if any AI image generation was good at this (yet?). I have a real-life image I want to upload and get AI to generate what that would most likely look like from the vantage point of someone standing at a different angle.\n    submitted by    /u/YepperyYepstein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178wuz0/are_there_an_image_generators_that_can_generate/",
          "publishedOn": "2023-10-16T03:34:12.000Z",
          "wordCount": null,
          "title": "Are there an image generators that can generate the same image you upload to it, but from a different hypothetical angle?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178tdm1/ai_dubbing_local/",
          "author": null,
          "description": "Hi there, anybody knows how AI dubbing translator works ? As im interested if something similiar to https://app.rask.ai/ exist localy ?? Is there anything from github? Im looking for czech language. I know you can scribe audio to text than translate text and let AI to talk this text. But is there a tool that do all of this in one click ? Thank you and have a nice day.\n    submitted by    /u/Low_Government_681  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178tdm1/ai_dubbing_local/",
          "publishedOn": "2023-10-16T00:30:04.000Z",
          "wordCount": null,
          "title": "AI dubbing ( local )",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178pf6d/nvidia_blackwell_b100_gpus_to_feature_sk_hynix/",
          "author": null,
          "description": "submitted by    /u/norcalnatv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178pf6d/nvidia_blackwell_b100_gpus_to_feature_sk_hynix/",
          "publishedOn": "2023-10-15T21:21:14.000Z",
          "wordCount": null,
          "title": "NVIDIA Blackwell B100 GPUs To Feature SK Hynix HBM3e Memory, Launches In Q2 2024 Due To Rise In AI Demand",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178o5jd/researchers_propose_gamegpt_a_multiagent_approach/",
          "author": null,
          "description": "Game dev is super complex nowadays - games have huge codebases, massive teams, and dev cycles dragging on for years. Costs are insane too - budgets can hit $100M+ easily.\n In a new paper, researchers propose to reverse this trend with an AI framework called GameGPT that automates parts of the dev process using multiple AI agents. Each agent handles a different role (all are fine-tuned from relevant base models):\n  \nOne agent reviews the game design plan to catch errors\n Another turns tasks into code implementations\n Reviewer agents check the code and results\n A testing agent validates everything works as expected\n  \nBy breaking up the workflow, GameGPT can simplify things for the AI agents. They just focus on a narrow role versus having one jack-of-all-trades agent.\n The authors argue GameGPT can eliminate repetitive and rote elements of gamedev like testing. This would free up developers to focus on creative design challenges.\n However, the GameGPT paper does not include any concrete results or experiments demonstrating improved performance. There is no evidence presented that GameGPT reduces hallucinations, redundancy or development time. The authors mention empirical results support their claims that the architecture is more effective, but none are provided. I could not find any additional support material about this work, like a project website, that I could use to further check into this (maybe someone can share in the comments?).\n Right now GameGPT seems mostly conceptual. The ideas are interesting but hard to assess without quantitative results.\n TLDR: New GameGPT AI framework aims to automate tedious parts of game development using specialized agents. No concrete results were provided in the paper - someone will need to test this out and report back.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178o5jd/researchers_propose_gamegpt_a_multiagent_approach/",
          "publishedOn": "2023-10-15T20:24:42.000Z",
          "wordCount": null,
          "title": "Researchers propose GameGPT: A multi-agent approach to fully automated game development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178n10e/speech_condenser_an_advanced_onpremise_pipeline/",
          "author": null,
          "description": "submitted by    /u/nez_har  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178n10e/speech_condenser_an_advanced_onpremise_pipeline/",
          "publishedOn": "2023-10-15T19:32:26.000Z",
          "wordCount": null,
          "title": "Speech Condenser: An Advanced On-Premise Pipeline Tool for Streamlining and Summarizing Dialogues from Videos",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178er0n/best_way_to_produce_consistent_images/",
          "author": null,
          "description": "Hi!\n I'm trying to jazz up my design portfolio for applying for jobs, and I wanted to insert some cute illustrations on each project page. The projects deal with a variety of topics so I'll need pictures of many things, but want to keep the style quite consistent. \n What is the best AI tool right now to do this? I paid for Midjourney but I can't seem to understand how to get it to do this. \n For example I got this image from DALLE and love the style, the white background also helps make it look better on the portfolio. I'd want another image in the same style of two kids throwing a ball, but can't figure out how to do it. \n Alternatively if I could upload this image to an AI and say \"in the same style, generate...\" that would be great too. \n Thank you!\n    submitted by    /u/_Dip_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178er0n/best_way_to_produce_consistent_images/",
          "publishedOn": "2023-10-15T12:53:43.000Z",
          "wordCount": null,
          "title": "Best way to produce consistent images?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178e923/messi_vs_ronaldo_freestyle_rap_song_ai_rap_song/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178e923/messi_vs_ronaldo_freestyle_rap_song_ai_rap_song/",
          "publishedOn": "2023-10-15T12:23:41.000Z",
          "wordCount": null,
          "title": "Messi vs Ronaldo | Freestyle Rap Song | AI Rap Song | Tell your opinion on this video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178e0gu/seeking_your_feedback_on_a_new_community_around/",
          "author": null,
          "description": "Currently, we are building a community that is specifically dedicated to Open-Source AI Code Generation Models. Our aim is to create a thriving ecosystem where developers, enthusiasts, and experts can come together to drive innovation, share insights, and promote a collaborative approach to AI code generation.\n I wanted to provide you with an overview of the key features we're integrating into this community:\n 1. Collaboration: A dedicated space where enthusiasts and experts alike can collaborate on projects, share their findings, and work on enhancing existing models.\n 2. Discussion: Whether through forums or chat platforms, we aim to foster discussions around the challenges, breakthroughs, and best practices in the realm of AI code generation.\n 3. Resource Sharing: Our community will feature a repository/platform for members to freely share and access open-source models, datasets, and other essential tools.\n With your experience and insight into the AI domain, we would greatly appreciate your feedback on the following:-\n - Do you believe such a community would be valuable to you personally or to the wider developer community?\n - Would you consider becoming a part of such a community?\n - You are already a part of such a community and this one might not be of much value to you?\n - Any other suggestions or feedback?\n Your candid feedback on this idea, its potential impact, and any suggestions you might have will be invaluable to us as we continue shaping this community's structure and offerings.\n    submitted by    /u/akanshtyagi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178e0gu/seeking_your_feedback_on_a_new_community_around/",
          "publishedOn": "2023-10-15T12:08:31.000Z",
          "wordCount": null,
          "title": "Seeking Your Feedback on a new community around Open-Source AI Code Generation Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/178ccbl/biden_eyes_adding_ai_chip_curbs_to_chinese/",
          "author": null,
          "description": "The Biden administration is considering closing a loophole that gives Chinese companies access to American artificial intelligence (AI) chips through units located overseas.\n \nThe United States previously restricted shipments of AI chips to China but left overseas subsidiaries of Chinese companies with unfettered access.\n \nThe Biden administration is now looking for ways to close this loophole and prevent China from accessing top AI technology.\n \nHowever, it is challenging to plug every gap in export controls.\n \nChinese firms are purchasing chips for use in data centers abroad, and it is difficult for the United States to police those transactions.\n \nThe United States has been seeking to halt the rise of China's AI capability, which depends on its access to U.S. chips.\n \nWashington has been working to close other loopholes that allow AI chips into China, and the new rules expected this month will likely apply those same restrictions more broadly to all companies in the market.\n \nThe U.S. government is also grappling with the issue of Chinese parties accessing U.S. cloud providers like Amazon Web Services.\n \nOverall, the Biden administration is facing challenges in cutting China off from top AI technology and closing all loopholes in export controls.\n \n Source : https://www.reuters.com/technology/biden-eyes-adding-ai-chip-curbs-chinese-companies-abroad-2023-10-13/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/178ccbl/biden_eyes_adding_ai_chip_curbs_to_chinese/",
          "publishedOn": "2023-10-15T10:14:06.000Z",
          "wordCount": null,
          "title": "Biden eyes adding AI chip curbs to Chinese companies abroad",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177wy99/looking_for_developers_future_founders_who_want/",
          "author": null,
          "description": "I am a multi-time founder myself. I've secured millions from investors for my past startups and had notable success with a video app that gathered 4M users and $300k in revenue. However, due to the intense competition in the video app editing sector, my team and I couldn't turn a profit.\n After my last startup faltered during the covid period, I transitioned to being a full-time product-market fit and growth marketing consultant and have made really great money doing it. I assist new startups in avoiding the mistakes I made and implement frameworks that significantly increase their chances of success. I've observed that many new founders venture into startups without fully grasping the challenges of building something people genuinely desire. It’s really not easy. How would you know what y…",
          "link": "https://www.reddit.com/r/artificial/comments/177wy99/looking_for_developers_future_founders_who_want/",
          "publishedOn": "2023-10-14T19:24:14.000Z",
          "wordCount": null,
          "title": "Looking for developers / future founders who want to build and grow disruptive AI apps.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177v76q/ai_images_detectors_are_being_used_to_discredit/",
          "author": null,
          "description": "A free AI image detector is being used to discredit a photograph of a burnt corpse of a baby killed in Hamas's attack on Israel.\n \nHowever, experts have pointed out that the image does not show any signs of being created by AI.\n \nThe idea that the image is AI-generated has spread on Twitter, suggesting that official Israeli accounts are spreading AI-generated misinformation.\n \nAI image generators have trouble replicating reality accurately, and the shadows in the photograph are consistent with a real image.\n \nMultiple AI image detection tools have also determined that the image is not AI-generated. \n \n Source : https://www.404media.co/ai-images-detectors-are-being-used-to-discredit-the-real-horrors-of-war/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177v76q/ai_images_detectors_are_being_used_to_discredit/",
          "publishedOn": "2023-10-14T18:00:16.000Z",
          "wordCount": null,
          "title": "AI Images Detectors Are Being Used to Discredit the Real Horrors of War",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177o01x/seeking_a_community_for_opensource_ai_code/",
          "author": null,
          "description": "Hello everyone! 🌟\n I hope this post finds you well. I've been delving deeper into the world of AI code generation recently and am curious to discover if there are communities or platforms specifically dedicated to open-source AI code generation models. I'm aware of hugging face but is there any other besides that.\n Here's what I'm looking for:\n  \nCollaboration: A space where enthusiasts and experts alike can collaborate on projects, share insights, and improve upon existing models.\n Discussion: Forums or chat platforms where discussions around the challenges, breakthroughs, and best practices in AI code generation take place.\n Resource Sharing: A repository or platform where open-source models, datasets, and related tools can be freely shared and accessed.\n Learning and Tutorials: Any resources that can help newcomers grasp the concepts and intricacies of AI code generation.\n If you know of any such community or are part of one, please do let me know.\n  \n   submitted by    /u/akanshtyagi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177o01x/seeking_a_community_for_opensource_ai_code/",
          "publishedOn": "2023-10-14T12:03:23.000Z",
          "wordCount": null,
          "title": "Seeking a Community for Open-Source AI Code Generation Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177lcha/mickey_what_are_you_doing/",
          "author": null,
          "description": "submitted by    /u/LeviJr00  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177lcha/mickey_what_are_you_doing/",
          "publishedOn": "2023-10-14T09:05:43.000Z",
          "wordCount": null,
          "title": "Mickey, what are you doing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177kmyf/updates_to_my_capstone_project_with_enhanced/",
          "author": null,
          "description": "submitted by    /u/Raymondlkj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177kmyf/updates_to_my_capstone_project_with_enhanced/",
          "publishedOn": "2023-10-14T08:13:00.000Z",
          "wordCount": null,
          "title": "Updates to my Capstone Project with Enhanced Features and still freely available to all (until OpenAI credits deplete - Free ChatGPT4). Hoping to introduce the community feature too where people can generate STEM animations to aid learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177iwg0/learning_for_school_with_an_ai/",
          "author": null,
          "description": "does anyone know if there is an AI online where you can import documents and the AI is forming and asking you questions about that topic on the document? like an AI who generates test for you to be prepared for every potential question in a school test.\n    submitted by    /u/satanskittenz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177iwg0/learning_for_school_with_an_ai/",
          "publishedOn": "2023-10-14T06:10:33.000Z",
          "wordCount": null,
          "title": "learning for school with an AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177fjuo/creative_question_your_ideas_for_ai_generative/",
          "author": null,
          "description": "Ok so we have AI generated content, First text, then images, then videos. \n What will the world look like when we have a generative world? \n Generative objects, Generative Games, Generative Moods, Generative memories, Generative senses and perceptions, Generative Environments, Generative Reality.\n Anyone want to talk about what it might look like?\n ( I would like to hear a unhinged idea for what might happen, Speculative of course )\n    submitted by    /u/rolyataylor2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177fjuo/creative_question_your_ideas_for_ai_generative/",
          "publishedOn": "2023-10-14T02:42:04.000Z",
          "wordCount": null,
          "title": "Creative Question: Your ideas for AI generative reality",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/177af7r/savage_dalle_3_delivers_average_reddit_post/",
          "author": null,
          "description": "submitted by    /u/Zimmax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/177af7r/savage_dalle_3_delivers_average_reddit_post/",
          "publishedOn": "2023-10-13T22:20:59.000Z",
          "wordCount": null,
          "title": "Savage Dall-e 3 delivers \"Average reddit post\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1773ee2/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n  \nResearchers present LLark: A Multimodal Foundation Model for Music - an open-source instruction-tuned multimodal model for music understanding. LLark is trained entirely from open-source music data and models [Demo | Paper]\n Researchers released LLaVA-1.5. LLaVA (Large Language and Vision Assistant) is an open-source large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. LLaVA-1.5 achieved SoTA on 11 benchmarks, with just simple modifications to the original LLaVA and completed training in ~1 day on a single 8-A100 node [Demo | Paper | GitHub].\n Voice AI platform ElevenLabs released AI Dubbing tool that enables users to automatically translate any audio in a video into a different language whil…",
          "link": "https://www.reddit.com/r/artificial/comments/1773ee2/ai_weekly_megathread/",
          "publishedOn": "2023-10-13T17:01:02.000Z",
          "wordCount": null,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17726b7/the_ai_boom_could_use_a_shocking_amount_of/",
          "author": null,
          "description": "The rapid growth of artificial intelligence (AI) could lead to a significant increase in global electricity consumption, according to a peer-reviewed analysis published in Joule.\n \nThe analysis estimates that if current trends continue, AI could drive the demand for electricity in data centers to consume at least 85.4 terawatt-hours annually, which is more than what many small countries use in a year.\n \nAI is energy-intensive, with both the training and inference phases requiring a significant amount of energy.\n \nThe size of AI models, such as large language models, and the location of data centers also contribute to energy usage.\n \nFactors such as cooling requirements and the type of hardware used can impact energy consumption.\n \n Source : https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17726b7/the_ai_boom_could_use_a_shocking_amount_of/",
          "publishedOn": "2023-10-13T16:05:17.000Z",
          "wordCount": null,
          "title": "The AI Boom Could Use a Shocking Amount of Electricity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1771hmp/lemur_harmonizing_natural_language_and_code_for/",
          "author": null,
          "description": "Today's conversational bots like Claude and GPT can chat impressively but aren't great at complex planning or executing technical tasks. To overcome this, new research from HKU builds open-source AI agents that blend natural language and coding skills. They're called Lemur and Lemur-Chat.\n The researchers think achieving versatile real-world agents requires models that integrate both fluid natural language abilities and precise programming language control. Humans combine plain speech for higher-level goals with languages like Python when we need to plan intricately and execute exactly. AI needs both capacities too.\n But most existing models specialize in pure language or pure code. There's a separation that is limiting.\n The team created Lemur by pretraining the open-source Llama-2 on a massive mixed corpus with 10x more natural language than code. This improved its programming abilities while retaining conversational strength. Further instruction tuning optimized Lemur-Chat for following free-form directions in language.\n Experiments found Lemur surpassed specialized coding-only models like Codex in overall benchmarks. Lemur-Chat then exceeded Lemur by 15% after instruction tuning.\n More importantly, Lemur-Chat won 12/13 new \"agent tests\" designed to mimic real-world challenges needing both language and programming prowess.\n It beat alternatives at:\n  \nUsing tools like Python and Wikipedia to enhance reasoning\n Debugging code by leveraging error messages\n Improving the most from natural language feedback\n Exploring partially observable environments like cybersecurity and web browsing simulations.\n  \nLemur-Chat matched GPT-3.5 in many tests, closing the gap between commercial and open-source agents.\n TLDR: New open-source AI agents combine coding and language skills. Experiments show the combo unlocks more performance across technical challenges.\n Full summary is here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1771hmp/lemur_harmonizing_natural_language_and_code_for/",
          "publishedOn": "2023-10-13T15:34:23.000Z",
          "wordCount": null,
          "title": "Lemur: Harmonizing Natural Language and Code for Language Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176ydik/henry_kissinger_the_path_to_ai_arms_control/",
          "author": null,
          "description": "submitted by    /u/ForeignAffairsMag  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176ydik/henry_kissinger_the_path_to_ai_arms_control/",
          "publishedOn": "2023-10-13T13:08:52.000Z",
          "wordCount": null,
          "title": "Henry Kissinger: The Path to AI Arms Control",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176wuhn/a_21yearold_won_40000_for_using_ai_to_read_the/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176wuhn/a_21yearold_won_40000_for_using_ai_to_read_the/",
          "publishedOn": "2023-10-13T11:46:17.000Z",
          "wordCount": null,
          "title": "A 21-year-old won $40,000 for using AI to read the first word on a 2,000-year-old papyrus scroll buried by Mount Vesuvius",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176vs99/special_announcement_john_carmack_rich_sutton/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176vs99/special_announcement_john_carmack_rich_sutton/",
          "publishedOn": "2023-10-13T10:39:06.000Z",
          "wordCount": null,
          "title": "\"Special Announcement: John Carmack & Rich Sutton partner to accelerate development of AGI\" | \"Carmack and Sutton are deeply focused on developing a genuine AI prototype by 2030, including establishing, advancing, and documenting AGI signs of life\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176vpwe/dumbing_down_or_wising_up_how_will_generative_ai/",
          "author": null,
          "description": "submitted by    /u/Jariiari7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176vpwe/dumbing_down_or_wising_up_how_will_generative_ai/",
          "publishedOn": "2023-10-13T10:34:43.000Z",
          "wordCount": null,
          "title": "Dumbing down or wising up: how will generative AI change the way we think?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176r4bp/oneminute_daily_ai_news_10132023/",
          "author": null,
          "description": "In a recent article published in the journal Nature, researchers developed AI Tool EVEscape, a tool to forecast which severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) strains have the highest potential to escape host immunity.[1]\n Microsoft seems to be working on the possible development of an artificial intelligence (AI) system that can understand and resolve customer support requests using natural language processing.[2]\n Google’s Search Generative Experience (SGE) will let you create images right from a text prompt starting Thursday.[3]\n The Biden administration is considering closing a loophole that gives Chinese companies access to American artificial intelligence (AI) chips through units located overseas, according to four people familiar with the matter.[4]\n  \nSources:\n [1] https://www.news-medical.net/news/20231012/EVScape-New-tool-to-forecast-which-SARS-CoV-2-variants-could-dodge-our-immunity.aspx\n [2] https://winbuzzer.com/2023/10/11/microsoft-gears-up-for-a-revolutionary-natural-language-customer-support-ai-xcxwbn/\n [3] https://www.theverge.com/2023/10/12/23913337/google-ai-powered-search-sge-images-written-drafts\n [4] https://www.reuters.com/technology/biden-eyes-adding-ai-chip-curbs-chinese-companies-abroad-2023-10-13/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176r4bp/oneminute_daily_ai_news_10132023/",
          "publishedOn": "2023-10-13T05:14:11.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/13/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176m31w/ive_created_a_audiobook_generator_anyone_got_any/",
          "author": null,
          "description": "Also if anyone has anyone who should be a voice actor included in it it can also clone voices. Idk I need to make sure it works for a wide variety of books. As long as they don’t use ‘ for quotes cause the computer getts that confused when “ I’ve “ and such uses the same symbol\n    submitted by    /u/Impossible_Belt_7757  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176m31w/ive_created_a_audiobook_generator_anyone_got_any/",
          "publishedOn": "2023-10-13T00:34:33.000Z",
          "wordCount": null,
          "title": "I’ve created a audiobook generator anyone got any books to test on it? Each character is given a different voice.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176lwka/check_out_the_latest_episode_of_my_history/",
          "author": null,
          "description": "submitted by    /u/ErikSlader713  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176lwka/check_out_the_latest_episode_of_my_history/",
          "publishedOn": "2023-10-13T00:25:30.000Z",
          "wordCount": null,
          "title": "Check out the latest episode of my history podcast on the future of A.I.!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176lqdp/drew_a_picture_in_paint_threw_it_in_hotpot_and_it/",
          "author": null,
          "description": "submitted by    /u/kipaxbooks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176lqdp/drew_a_picture_in_paint_threw_it_in_hotpot_and_it/",
          "publishedOn": "2023-10-13T00:17:00.000Z",
          "wordCount": null,
          "title": "Drew a picture in paint, threw it in hotpot, and it came out a stylish, halloweenish picure. Damn this stuff is amazing.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176k8nh/who_will_benefit_from_ai/",
          "author": null,
          "description": "Artificial intelligence (AI) can provide \"machine usefulness\" for human workers, augmenting their jobs rather than replacing them.\n \nHowever, there is a concern that AI could lead to job displacement and reinforce economic inequality.\n \nMIT economist Daron Acemoglu emphasizes the importance of making AI more useful to humans and ensuring that the economic benefits are shared widely.\n \nHe suggests that innovations that augment workers' tasks can lead to prosperity for the workforce.\n \nAcemoglu also highlights the need for worker power and the careful implementation of technology to achieve shared prosperity and productivity gains.\n \n Source : https://idss.mit.edu/news/who-will-benefit-from-ai/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176k8nh/who_will_benefit_from_ai/",
          "publishedOn": "2023-10-12T23:03:47.000Z",
          "wordCount": null,
          "title": "Who Will Benefit from AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176i1ed/whats_the_most_advanced_free_chatbot_available/",
          "author": null,
          "description": "I just need three things for it:\n  \nIt must be knowledgeable about things, such as physics, math, hystory, books, geography, etc.\n It also must be original, with a high level of SEO and AI detection score.\n It must be available in Italy. The last part is essential. Claude 2 is very famous but with sms verification from usa (which I don't have and I don't want to give credit card info/pay to have) it's made almost impossible even with vpn.\n  \n   submitted by    /u/luigirovatti1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176i1ed/whats_the_most_advanced_free_chatbot_available/",
          "publishedOn": "2023-10-12T21:28:53.000Z",
          "wordCount": null,
          "title": "What's the most advanced free chatbot available?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176hbsq/10_powerful_chatgpt_hacks_for_seo/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176hbsq/10_powerful_chatgpt_hacks_for_seo/",
          "publishedOn": "2023-10-12T21:00:40.000Z",
          "wordCount": null,
          "title": "10 Powerful ChatGPT Hacks for SEO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176ddj5/chatgpts_global_peace_plan/",
          "author": null,
          "description": "Creating true, enduring, lasting peace on Earth is an ambitious and complex endeavor that requires multifaceted approaches. Here’s a bold, outside-the-box plan that may surprise you:\n Step 1: Establish a Global Consciousness:\n  \nEducational Overhaul: Revamp global educational systems to foster empathy, understanding, and appreciation for diverse cultures, religions, and viewpoints from a young age.\n  \nStep 2: Eradicate Poverty and Inequality:\n  \nUniversal Basic Assets (UBA): Implement a Universal Basic Assets program, where every person on Earth is granted a share of global resources.\n  \nStep 3: Create a Single Global Governance Entity:\n  \nWorld Federation: Establish a democratically elected World Federation that respects regional autonomy but has overriding authority on global issues like…",
          "link": "https://www.reddit.com/r/artificial/comments/176ddj5/chatgpts_global_peace_plan/",
          "publishedOn": "2023-10-12T18:07:07.000Z",
          "wordCount": null,
          "title": "ChatGPT's Global Peace Plan",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/176bd2b/when_your_ai_says_she_loves_you/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/176bd2b/when_your_ai_says_she_loves_you/",
          "publishedOn": "2023-10-12T16:40:46.000Z",
          "wordCount": null,
          "title": "When your AI says she loves you",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1769qsd/anyone_ever_thought_about_training_a_video/",
          "author": null,
          "description": "Just had a random idea: What if you train a video generating AI, but feed it videos that are reversed? You could show it an image of a crashed car, and it would generate a video of the crash. Show it a broken vase, it would \"repair\" it. It could one day become like the \"reconstruct crime scene\" in Detroit: Become Human. What are your thoughts about this?\n    submitted by    /u/FluffyIllustrator805  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1769qsd/anyone_ever_thought_about_training_a_video/",
          "publishedOn": "2023-10-12T15:31:49.000Z",
          "wordCount": null,
          "title": "Anyone ever thought about training a video generating model, but backwards?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1767l8w/ai_and_science_what_1600_researchers_think/",
          "author": null,
          "description": "A Nature survey of over 1,600 researchers reveals that AI tools are becoming increasingly common in science and are expected to be 'very important' or 'essential' in the next decade.\n \nScientists express concerns about how AI is transforming research, including reliance on pattern recognition without understanding, bias in data, fraud, and irreproducible research.\n \nThe survey shows that AI tools provide faster ways to process data, speed up computations, and save time and money.\n \nAmong researchers who use AI, more than one-quarter believe AI tools will become 'essential' to their field in the next decade.\n \nLarge language models like ChatGPT are mentioned as both impressive and concerning examples of AI tools in science.\n \n Source : https://www.nature.com/articles/d41586-023-02980-0\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1767l8w/ai_and_science_what_1600_researchers_think/",
          "publishedOn": "2023-10-12T13:56:09.000Z",
          "wordCount": null,
          "title": "AI and science: what 1,600 researchers think",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1767dac/looking_for_ai_text_input_like_artbreeder_mixer/",
          "author": null,
          "description": "I'm looking for a (free) ai image generator like Artbreeder Mixer, that has functions that allow you to \"morph\" or mix images together via text prompts. Ive looked at a bunch already, and even tried adding the text of the different types in the prompts, bu Ive been getting separated results (like \"cat\" , \"man\", \"head\" wont combine the man and the cat, but rather give me un-morphed results, like a regular man, plus a cat in a suit with no human features. I even get a result with a man standing behind a cat! Ive tried StarryAI, imagecreator, wepik, cant afford midjourney or paid ones right now, some others I cant remember with no mixing...\n Artbreeder's interface, you can keep adding and it will mix them together.\n I made these images and others like them very easy in Artbreeder, but its plan is very limited - I could buy more credits, but I need to wait a few days (new job, not paid yet, broke today... lol):\n ​\n morph between man and donkey\n Morph between angry rapper and gorilla\n SO, if anyone can suggest some free, or almost free (generous newbie credits?) that can do mixes like this - please point me in the right direction.\n    submitted by    /u/magusat999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1767dac/looking_for_ai_text_input_like_artbreeder_mixer/",
          "publishedOn": "2023-10-12T13:45:47.000Z",
          "wordCount": null,
          "title": "Looking for AI text input like Artbreeder Mixer that combines images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17677nn/new_york_wants_to_be_ais_world_capital_in_rivalry/",
          "author": null,
          "description": "submitted by    /u/norcalnatv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17677nn/new_york_wants_to_be_ais_world_capital_in_rivalry/",
          "publishedOn": "2023-10-12T13:38:28.000Z",
          "wordCount": null,
          "title": "New York wants to be AI's world capital, in rivalry with San Francisco and Silicon Valley",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1764fsl/could_an_aicreated_profile_picture_help_you_get_a/",
          "author": null,
          "description": "Artificial intelligence (AI) is being used to create professional-looking profile pictures for job hunting websites like LinkedIn.\n \nApps like Remini, Try It On AI, and AI Suit Up use AI-based software to generate slick profile photos that mimic the work of expert photographers.\n \nUsers upload multiple selfies, and the AI software creates artificial photos with different hairstyles, clothing, and backdrops.\n \nWhile some find the results realistic, others think they look artificial.\n \nThe AI services are popular because they are cheap or free, making them accessible to those who can't afford professional headshots.\n \nHowever, opinions are divided on whether AI-generated photos are beneficial or detrimental to self-esteem.\n \nSome believe that AI-generated photos allow individuals to put their best self forward and potentially increase their chances of being considered for opportunities.\n \nOthers worry that relying on AI-generated photos may negatively impact self-worth and confidence. Recruiters generally do not consider whether a photo is AI-generated when evaluating job applications.\n \n Source : https://www.bbc.co.uk/news/business-67054382\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1764fsl/could_an_aicreated_profile_picture_help_you_get_a/",
          "publishedOn": "2023-10-12T11:12:41.000Z",
          "wordCount": null,
          "title": "Could an AI-created profile picture help you get a job?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17643wd/ai_tool_for_film_footage_notes/",
          "author": null,
          "description": "Hi, im currently filming a documentary, but I’m so busy filming, i don’t have time to write notes on footage for the editor. \n Does anyone know of any ai tool that can help with this and save time and streamline this process? \n King regards\n    submitted by    /u/Brand0n_C  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17643wd/ai_tool_for_film_footage_notes/",
          "publishedOn": "2023-10-12T10:53:10.000Z",
          "wordCount": null,
          "title": "AI Tool for film footage notes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1760z8c/how_ai_will_affect_traditional_and_open_source/",
          "author": null,
          "description": "Hey folks, how would you guys see the effect of AI? Will the small softwares companies will go bankrupt? Since the lots of software are using tools like ChatGpt, Midway Journey etc. It just the starting of new AI technology era which will evolved over the years. In that time we will see more and more AI software which will likely provide efficient and better solution as compare to traditional and open source software. So my question is how do you guys see this? Will small software companies or open source software programs days are number? \n    submitted by    /u/Haziq12345  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1760z8c/how_ai_will_affect_traditional_and_open_source/",
          "publishedOn": "2023-10-12T07:20:11.000Z",
          "wordCount": null,
          "title": "How AI will affect traditional and open source software industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175yhxe/oneminute_daily_ai_news_10112023/",
          "author": null,
          "description": "Opera has launched Opera One — a new version of the browser that comes packaged with an AI-powered chatbot called Aria.[1]\n Adobe is going all in on AI, announcing three new generative AI models today that add powerful features to Illustrator and Adobe Express and vastly improve Photoshop’s text-to-image capabilities.[2]\n ‘South Park’ to Tackle AI for Next Event Special, Releases Teaser.[3]\n World’s first AI tutor launched in Australia to help students get through their exams.[4]\n  \nSources:\n [1] https://www.theverge.com/2023/6/21/23768888/opera-one-browser-aria-ai-assistant-chatbot\n [2] https://www.theverge.com/2023/10/10/23911114/adobe-max-firefly-generative-ai-model-photoshop-illustrator-express\n [3] https://www.hollywoodreporter.com/tv/tv-news/south-park-ai-joining-panderverse-1235615276/\n [4] https://www.techguide.com.au/news/computers-news/worlds-first-ai-tutor-launched-in-australia-to-help-students-get-through-their-exams/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175yhxe/oneminute_daily_ai_news_10112023/",
          "publishedOn": "2023-10-12T04:42:39.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/11/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175y8eo/cypher_2023_the_future_of_simulation_and_design/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175y8eo/cypher_2023_the_future_of_simulation_and_design/",
          "publishedOn": "2023-10-12T04:26:50.000Z",
          "wordCount": null,
          "title": "Cypher 2023: The Future of Simulation and Design is AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175x3a0/any_ideas_how_this_was_created/",
          "author": null,
          "description": "submitted by    /u/crispyTacoTrain  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175x3a0/any_ideas_how_this_was_created/",
          "publishedOn": "2023-10-12T03:23:43.000Z",
          "wordCount": null,
          "title": "Any ideas how this was created?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175tz97/web_design_tools/",
          "author": null,
          "description": "I’m looking for input and advice on tools for web designers. \n I use Wordpress a lot, Magento some and frequently code by hand in html JavaScript and PHP. \n I know there are some AI tools out there now but I don’t know which are best and wanted to find out what people thoughts are on this subject.\n What tools are you using, for what, and why?\n Thanks!\n    submitted by    /u/PowerTarget  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175tz97/web_design_tools/",
          "publishedOn": "2023-10-12T00:50:28.000Z",
          "wordCount": null,
          "title": "Web design tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175rmsi/predictive_ai_analyzing_attraction_to_facial/",
          "author": null,
          "description": "Top dating apps Tinder, Hinge and Bumble have all stated that they're already investing in AI to make their apps better. They're using it to verify profiles, match people based on bios and interests, and help generate profile descriptions and liven conversations. But what about machine learning on user photos?\n iris Dating uses AI to analyze user input in the form of liking or disliking faces (\"swiping\" profiles). We all know if we like blondes or brunettes, blue or brown eyes, short or long hair, beard or no beard, etc. But AI can pick up the subtlest features (proportions, distances, curvatures etc.) and build a face map. A matrix of features, if you will. It doesn't just look for a person looking like your favorite celebrity crush. It understands what you're really attracted to.\n From there it's an easy path: if it knows which features attract me, it can predict my level of attraction to a specific individual (specifically, their face). Find the persons with the highest predicted attractiveness (for me, not for everyone), rank them by attraction for me, and we have a potential high mutual attraction match. The two stats I have are that on average women like 55%(!) of the profiles iris picks for them; and that users have 40x higher chances of matching when they've trained the model to understand their taste.\n I know it takes a lot more than a pretty face to make for a great relationship, but it sure doesn't hurt to start with strong physical attraction. Missed connections on Craigslist are about just that: seeing a face you can't forget. Find me more of these \"wow\" faces and let's go from there.\n What do you think? Is it too early? Too bold? Too niche?\n    submitted by    /u/akahamlet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175rmsi/predictive_ai_analyzing_attraction_to_facial/",
          "publishedOn": "2023-10-11T23:00:58.000Z",
          "wordCount": null,
          "title": "Predictive AI analyzing attraction to facial features (iris Dating app)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175qcg0/superman_if_portrayed_by_different_actors_as/",
          "author": null,
          "description": "submitted by    /u/fat_n_stupid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175qcg0/superman_if_portrayed_by_different_actors_as/",
          "publishedOn": "2023-10-11T22:04:50.000Z",
          "wordCount": null,
          "title": "Superman if portrayed by different actors (as imagined by AI)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175oebw/dalle_3_is_blocking_copyrighted_material_also/",
          "author": null,
          "description": "submitted by    /u/Zimmax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175oebw/dalle_3_is_blocking_copyrighted_material_also/",
          "publishedOn": "2023-10-11T20:43:53.000Z",
          "wordCount": null,
          "title": "DALL·E 3 is blocking copyrighted material. Also DALL·E 3:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175nwas/the_ai_research_job_market_shit_show/",
          "author": null,
          "description": "The AI research job market is going through a shakeup, with a high demand for skilled researchers and a scarcity of talent.\n \nCompanies closely monitor the movements of researchers as an indicator of their ability to transition from concept to product.\n \nThe market is highly competitive, with researchers being offered high salaries and compensation packages.\n \nThis has led to high turnover and attrition in many companies, causing unsettledness among employees.\n \nDespite the challenges, the investment in AI research is expected to drive innovation and push the boundaries of the Transformer architecture.\n \n Source : https://www.interconnects.ai/p/ai-research-job-market\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175nwas/the_ai_research_job_market_shit_show/",
          "publishedOn": "2023-10-11T20:23:07.000Z",
          "wordCount": null,
          "title": "The AI research job market shit show",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175lngi/are_there_any_low_res_pixel_art_art_tools/",
          "author": null,
          "description": "I'm looking for ways to create art for a game I'm creating.\n    submitted by    /u/Yenii_3025  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175lngi/are_there_any_low_res_pixel_art_art_tools/",
          "publishedOn": "2023-10-11T18:48:42.000Z",
          "wordCount": null,
          "title": "Are there any low res (pixel art) art tools?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175ia9b/inverting_transformers_significantly_improves/",
          "author": null,
          "description": "Transformers are great at NLP and computer vision tasks, but I was surprised to learn they still lag behind simple linear models at time series forecasting.\n The issue is how most Transformer architectures treat each timestamp as a token and fuse all the variable data from that moment. This makes two big problems:\n  \nVariables recorded at slightly different times get blurred together, losing important timing info\n Each token can only see a single moment, no long-term dependencies\n  \nSo Transformers struggle to extract useful patterns and correlations from the data.\n Some researchers from Tsinghua University took a fresh look at this and realized the Transformer components themselves are solid, they just need to flip the architecture for time series data.\n Their \"Inverted Transformer\" (or iTransformer):\n  \nMakes each variable's full history into a token, instead of each timestamp\n Uses self-attention over variables to capture relationships\n Processes time dependencies per variable with feedforward layers\n  \nThis simple tweak gives all the benefits we want:\n  \nState-of-the-art forecasting accuracy, beating both linear models and standard Transformers\n Better generalization to unseen variables\n Increased interpretability\n Ability to leverage longer historical context\n  \nTLDR: Inverting Transformers to align with time series structure allows them to outperform alternatives in working with time series data.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175ia9b/inverting_transformers_significantly_improves/",
          "publishedOn": "2023-10-11T16:28:42.000Z",
          "wordCount": null,
          "title": "Inverting Transformers Significantly Improves Time Series Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175hkcr/best_chatgpt_plugins_ultimate_list_for_2023/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175hkcr/best_chatgpt_plugins_ultimate_list_for_2023/",
          "publishedOn": "2023-10-11T15:59:32.000Z",
          "wordCount": null,
          "title": "Best ChatGPT Plugins: Ultimate List for 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175g5vq/the_nsfw_dream_truely_unrestricted_ai_desires/",
          "author": null,
          "description": "I guess I'm looking for the impossible but does anyone know of a generator that has all of the following qualities in order of importance least to most important:\n  \nHas a massive variety of styles like Womba's private discord server does.\n \n\"Create variants\" function like how a Womba discord personal server generator allows you to do.\n \nGenerates beautiful \"digital art\" style images like the digital https://www.unstability.ai/ does. (Man those images are pretty) faces are really good most of the time. (It's frusterating as it looks so good but I can't seem to get any group sex poses going on.)\n \nProvides a variety of poses such as https://easywithai.com/ai-image-generators/promptchan-ai/ which also allows you to upload you own images for poses, like how I could upload a real life orgy image and as long as it could distinguish the bodies as being separate (not a big pile of limbs) it does pretty good, but lacks severely lacks in facial quality. Like a big booty girl in hyperreal style\n \n1080P or higher resolution. (Again Womba is good here, but they are just extreme on their restrictions.) 1080P should be the minimum for any paid service as how can we truely enjoy a full screne image on anything less without it pixeling out?\n \nDoesn't cost $150/month (yes I found one that does all this but their premium subscription cost like $150/month (seduced.ai) and it's not even unlimited. I paid $90 for a full year at Womba discord unlimited but again, $150/month is just not worth it. \n \n If anyone knows of a server that has all these for around $25/month or less, please let me know. If really appreciate it.\n    submitted by    /u/russader  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175g5vq/the_nsfw_dream_truely_unrestricted_ai_desires/",
          "publishedOn": "2023-10-11T15:03:23.000Z",
          "wordCount": null,
          "title": "The NSFW dream (truely unrestricted ai desires)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175g0uz/can_ai_reference_both_photos_to_make_the_black/",
          "author": null,
          "description": "I have a high resolution black and white print and a generic quality colour image of the same photo, that I'd like AI to look at both images and make the B&W into colour. Is this possible?\n    submitted by    /u/NikonD3X1985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175g0uz/can_ai_reference_both_photos_to_make_the_black/",
          "publishedOn": "2023-10-11T14:58:11.000Z",
          "wordCount": null,
          "title": "Can AI reference both photos to make the black and white photo the same as the colour image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1757exy/ai_morality_scenarios/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1757exy/ai_morality_scenarios/",
          "publishedOn": "2023-10-11T06:28:05.000Z",
          "wordCount": null,
          "title": "AI Morality Scenarios.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1754t18/oneminute_daily_ai_news_10102023/",
          "author": null,
          "description": "Cybersecurity firm Avast is calling out a long-lived tool “LoveGPT,” that has haunted popular dating apps and that has been upgraded with artificial intelligence, gaining the ability to build fake profiles and manipulate unsuspecting users.[1]\n The outsider told the WSJ that Microsoft used AI from its partner OpenAI, which was then used to launch GitHub Copilot at $10 per month, but lost $20 per user in the average six months on average in the first 2023. Some Copilot users cost as much as $80 per month.[2]\n SK Telecom said on Monday that it successfully wrapped up its international AI competition of 226 teams, “Prompter Day Seoul 2023,” held in partnership with OpenAI.[3]\n Google DeepMind Researchers Introduce Promptbreeder: A Self-Referential and Self-Improving AI System that can Automatically Evolve Effective Domain-Specific Prompts in a Given Domain.[4]\n  \nSources:\n [1] https://decrypt.co/200787/lovegpt-ai-dating-apps-catfishing-hack-avast\n [2] https://game-news24.com/2023/10/10/microsoft-lost-20-for-every-10-copilot-ai-subscription-report-45-for-every-10-copilot-ai/\n [3] https://asianews.network/skt-openai-hold-ai-competition-for-social-good/\n [4] https://www.marktechpost.com/2023/10/08/google-deepmind-researchers-introduce-promptbreeder-a-self-referential-and-self-improving-ai-system-that-can-automatically-evolve-effective-domain-specific-prompts-in-a-given-domain/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1754t18/oneminute_daily_ai_news_10102023/",
          "publishedOn": "2023-10-11T03:45:32.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/10/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17516ts/i_finally_have_enough_ai_tools_and_here_is_my/",
          "author": null,
          "description": "VIDEO EDITING\n InVideo\n CapCut\n Filmora Veed io\n Rotor\n KEYWORD RESEARCH\n VidiQ\n Summarized YT\n Summary\n CONTENT CREATION\n Explore Al\n Vidds\n Opus\n Descript\n Lumen5\n Steve Al\n AUDIENCE ENGAGEMENT\n ManyChat\n TubeBuddy\n Canva\n Hootsuite\n ANALYTICS\n Vidyo\n Nova Al\n Daily Life Tools\n Taskade\n TLVD\n Bardeen Al\n Vondy Al\n Notion Al\n Chatbots Tools\n YatterPlus\n Typewise\n Quickchat\n Cohere Kaizan\n Coding Tools\n Durable Al\n 10Web\n Akkia\n Replit\n Deepcode\n Design Tools\n Flair Al\n Autodraw\n StockIMG\n Booth Al\n Clipdrop\n Content Creation Tools\n Writesonic\n Beautiful Al\n Tome Al\n ChatABC\n Steve Al\n Music Tools\n Boomy\n Amper\n Jukedeck\n Melodrive\n BrainFM\n Writing Tools\n AISEO\n Quillbot\n Writesonic\n Bertha Al\n Simplified\n Youtube Tools\n Eightify\n Thumbly\n Steve Al\n ClipMaker\n TubeBuddy\n Twitter Tools\n Tweetmonk\n Tribescaler\n Postwise\n Tweetlify\n Tweethunter\n Sales Tools\n Lavender\n Warmer\n Regie\n Twain\n Octane\n Marketing Tools\n simplified\n ContentEdge\n Copt Smith\n Copy Al\n Mutiny\n Research Tools\n Consensus\n Paperpal\n Trinka\n Writesonic\n scholarcy\n I'm just sharing my experiences and observations in the field of ai.\n LIST AND SITE\n    submitted by    /u/PerceptionPlayful469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17516ts/i_finally_have_enough_ai_tools_and_here_is_my/",
          "publishedOn": "2023-10-11T00:47:25.000Z",
          "wordCount": null,
          "title": "I finally have enough ai tools and here is my complete list",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1750vwy/write_your_next_book_with_these_awesome_chatgpt/",
          "author": null,
          "description": "Awesome ChatGPT Prompts\n    submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1750vwy/write_your_next_book_with_these_awesome_chatgpt/",
          "publishedOn": "2023-10-11T00:32:51.000Z",
          "wordCount": null,
          "title": "Write Your Next Book with These Awesome ChatGPT Prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174x9k1/musicgpt_create_unique_music_from_text_prompts/",
          "author": null,
          "description": "submitted by    /u/SaucySporky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174x9k1/musicgpt_create_unique_music_from_text_prompts/",
          "publishedOn": "2023-10-10T21:52:00.000Z",
          "wordCount": null,
          "title": "MusicGPT: Create unique music from text prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174x0cc/website_to_do_the_following_i_give_it_a_design/",
          "author": null,
          "description": "Hello all,\n I am not sure this is out yet. I would like to find a website where i can upload an image I own, and have it generate another image around it.\n Let's say I have some shirts that say 'HOLA'. I would want, for example, to generate an image of Socrates wearing said shirt. Is this possible? If so, which site would allow me to do this?\n ​\n Cheers and merci!\n    submitted by    /u/JYanezez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174x0cc/website_to_do_the_following_i_give_it_a_design/",
          "publishedOn": "2023-10-10T21:40:54.000Z",
          "wordCount": null,
          "title": "Website to do the Following: I Give it a Design and Create an Image With it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174sxxs/so_far_ai_hasnt_been_profitable_for_big_tech/",
          "author": null,
          "description": "Big Tech companies like Microsoft and Google are grappling with the challenge of turning AI products like ChatGPT into a profitable enterprise.\n \nThe cost of running advanced AI models is proving to be a significant hurdle, with some services driving significant operational losses.\n \nCorporate customers are unhappy with the high running costs of AI models.\n \nThe nature of AI computations, which require new calculations for each query, makes flat-fee models risky.\n \nSome companies are trying to dial back costs, while others continue to invest more deeply in AI tech.\n \nMicrosoft's GitHub Copilot, which assists app developers by generating code, has been operating at a loss despite attracting more than 1.5 million users.\n \nOne of the reasons AI services are costly is that some companies have been reaching for the most powerful AI models available.\n \nMicrosoft has been exploring less costly alternatives for its Bing Chat search engine assistant.\n \nAdvances in AI acceleration hardware may eventually reduce the costs of operating complex models.\n \nExperts anticipate a more stringent financial approach in the near future, transitioning from experimental budgets to focusing on profitability.\n \n Source : https://arstechnica.com/information-technology/2023/10/so-far-ai-hasnt-been-profitable-for-big-tech/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174sxxs/so_far_ai_hasnt_been_profitable_for_big_tech/",
          "publishedOn": "2023-10-10T18:54:40.000Z",
          "wordCount": null,
          "title": "So far, AI hasn't been profitable for Big Tech",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174rxff/dubbing_by_elevenlabs_share_your_fav_videos_in/",
          "author": null,
          "description": "submitted by    /u/ShooBum-T  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174rxff/dubbing_by_elevenlabs_share_your_fav_videos_in/",
          "publishedOn": "2023-10-10T18:13:06.000Z",
          "wordCount": null,
          "title": "Dubbing By ElevenLabs. Share your fav videos in your native language!! Go try",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174rwwp/the_environmental_impact_of_the_ai_revolution_is/",
          "author": null,
          "description": "The environmental impact of the AI revolution is starting to become clear, with generative AI like ChatGPT increasing Google Search's energy use more than tenfold.\n \nThe worry is that the computing power required for AI could lead to increased energy consumption and carbon footprint of data centers.\n \nAI already accounted for 10 to 15 percent of Google's electricity consumption in 2021.\n \nGoogle claims that the energy needed to power AI technology is increasing at a much slower rate than predicted, and they are implementing practices to reduce the carbon footprint of AI workloads.\n \nThe worst-case scenario of Google Search using as much electricity as Ireland is unlikely, but the potential energy consumption of AI servers could grow significantly if AI's popularity continues to rise.\n \n Source : https://www.theverge.com/2023/10/10/23911059/ai-climate-impact-google-openai-chatgpt-energy\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174rwwp/the_environmental_impact_of_the_ai_revolution_is/",
          "publishedOn": "2023-10-10T18:12:33.000Z",
          "wordCount": null,
          "title": "The environmental impact of the AI revolution is starting to come into focus",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174rg9y/almt_using_text_to_narrow_focus_in_multimodal/",
          "author": null,
          "description": "Multimodal sentiment analysis combines text, audio and video to understand human emotions. But extra inputs can add irrelevant or conflicting signals. So filtering matters.\n Researchers made a \"Adaptive Language-guided Multimodal Transformer\" (ALMT) that uses text to guide filtering of visual and audio data. This creates a \"hyper-modality\" with less noise that complements the text.\n They tested it on datasets like MOSI (YouTube reviews), MOSEI (YouTube clips) and CH-SIMS (Chinese videos). ALMT achieved improved accuracy:\n  \nMOSI: YouTube movie reviews with 2,199 samples. ALMT achieves state-of-the-art performance on various metrics including 6% higher 7-class accuracy.\n MOSEI: 22,856 YouTube clips covering sentiment-rich scenarios. ALMT improves multi-class accuracy by 3-5% over previous methods.\n CH-SIMS: Chinese dataset with over 2,000 video samples. ALMT surpasses prior work by 1.4% in binary accuracy.\n  \nAnalyses showed big drops in performance without the guided filtering, so this validates that it's the main innovation.\n Downsides are it needs lots of training data and has minor gains on sparse regression metrics. But overall the technique of filtering multimodal data under text guidance gives improvements.\n The concepts feel intuitive - use dominant signals to filter others and retain useful complements. My guess is it would transfer well to other multimodal tasks.\n TLDR: New way to filter multimodal data for sentiment analysis using text guidance improves performance. Shows the value in removing distracting signals. Sometimes less is more.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174rg9y/almt_using_text_to_narrow_focus_in_multimodal/",
          "publishedOn": "2023-10-10T17:53:12.000Z",
          "wordCount": null,
          "title": "ALMT: Using text to narrow focus in multimodal sentiment analysis improves performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174r20r/ai_political_analysis_test_describe_the/",
          "author": null,
          "description": "The Palestinians fighting for a homeland and the American Revolution have a number of commonalities, including:\n Fighting against a colonial power:** Both the Palestinians and the American colonists were fighting against a colonial power that had imposed its rule on them. In the case of the Palestinians, the colonial power is Israel, which was established in 1948 on land that had been inhabited by Palestinians for centuries. In the case of the American colonists, the colonial power was Great Britain.\n Fighting for self-determination:** Both the Palestinians and the American colonists were fighting for their right to self-determination, or the right to govern themselves. The Palestinians want to establish their own independent state, while the American colonists wanted to break away from Gr…",
          "link": "https://www.reddit.com/r/artificial/comments/174r20r/ai_political_analysis_test_describe_the/",
          "publishedOn": "2023-10-10T17:36:18.000Z",
          "wordCount": null,
          "title": "AI Political Analysis Test: Describe the commonalities between the Palestinians fighting for a homeland and the American Revolution.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174qegr/i_made_pi_your_personal_ia_to_have_an_opinion/",
          "author": null,
          "description": "submitted by    /u/LonePrron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174qegr/i_made_pi_your_personal_ia_to_have_an_opinion/",
          "publishedOn": "2023-10-10T17:09:15.000Z",
          "wordCount": null,
          "title": "I made \"Pi: your personal IA\" to have an opinion.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174oov5/ibm_ceo_washington_should_hold_tech_firms/",
          "author": null,
          "description": "submitted by    /u/smo279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174oov5/ibm_ceo_washington_should_hold_tech_firms/",
          "publishedOn": "2023-10-10T15:57:20.000Z",
          "wordCount": null,
          "title": "IBM CEO: Washington should hold tech firms accountable for AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174ohq8/automated_my_youtube_channel_using_gpt_4/",
          "author": null,
          "description": "Hi Everyone,\n I have automated the content creation for my youtube channel.\n It got total views of 8.5K and some videos getting 2.5K views.\n https://www.youtube.com/channel/UCG0-UemyRMUs1JJlQMK9lzA\n All the things are automated like:-\n  \nScript Generation\n Voiceover\n Image Generation\n Subtitles\n  \nI do minor tweaks here and there but majorly its automated.\n I posted is somwhere and people were commenting what's the use of the mindless videos?\n This is the begining, I want to automate the editing of videos.\n User can upload raw videos and I should be able to give multiple final edit videos.\n I have built a small tool blinkcuts.com, If anyone intersted. I can give access.\n Please DM for access.\n    submitted by    /u/raxrb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174ohq8/automated_my_youtube_channel_using_gpt_4/",
          "publishedOn": "2023-10-10T15:48:43.000Z",
          "wordCount": null,
          "title": "Automated my Youtube Channel Using GPT 4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174lnns/saudichina_collaboration_raises_concerns_about/",
          "author": null,
          "description": "Saudi-China collaboration raises concerns about access to AI chips.\n \nThe trial period includes complete digital access to FT.com with everything in both the Standard Digital and Premium Digital packages.\n \nAt the end of the trial, users will be auto-enrolled in the premium digital monthly subscription plan for $69 per month.\n \nPayment can be made through credit card, debit card, or PayPal.\n \n Source : https://www.ft.com/content/2a636cee-b0d2-45c2-a815-11ca32371763\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174lnns/saudichina_collaboration_raises_concerns_about/",
          "publishedOn": "2023-10-10T13:46:30.000Z",
          "wordCount": null,
          "title": "Saudi-China collaboration raises concerns about access to AI chips",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174jlvh/looking_for_the_free_ai_tool_which_removed_the/",
          "author": null,
          "description": "Hey, I am looking for the free AI tool which removed the noise from the video. If there is any, do suggest. Thank You in Advance.\n    submitted by    /u/Haziq12345  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174jlvh/looking_for_the_free_ai_tool_which_removed_the/",
          "publishedOn": "2023-10-10T12:11:03.000Z",
          "wordCount": null,
          "title": "Looking for the free AI tool which removed the noise from the video:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174jlvc/looking_for_the_free_ai_tool_which_removed_the/",
          "author": null,
          "description": "Hey, I am looking for the free AI tool which removed the noise from the video. If there is any, do suggest. Thank You in Advance.\n    submitted by    /u/Haziq12345  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174jlvc/looking_for_the_free_ai_tool_which_removed_the/",
          "publishedOn": "2023-10-10T12:11:03.000Z",
          "wordCount": null,
          "title": "Looking for the free AI tool which removed the noise from the video:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174ichy/how_do_aidriven_demand_forecasting_models_handle/",
          "author": null,
          "description": "If you have any resources then do share.\n    submitted by    /u/Cygnet-Digital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174ichy/how_do_aidriven_demand_forecasting_models_handle/",
          "publishedOn": "2023-10-10T10:59:28.000Z",
          "wordCount": null,
          "title": "How do AI-driven demand forecasting models handle market volatility and unexpected events, such as economic crises or pandemics?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174h4jj/ai_power_distribution_scenarios/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174h4jj/ai_power_distribution_scenarios/",
          "publishedOn": "2023-10-10T09:41:33.000Z",
          "wordCount": null,
          "title": "AI Power Distribution Scenarios.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174cwcl/as_drone_traffic_increases_researchers_turn_to_ai/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174cwcl/as_drone_traffic_increases_researchers_turn_to_ai/",
          "publishedOn": "2023-10-10T04:53:14.000Z",
          "wordCount": null,
          "title": "As drone traffic increases, researchers turn to AI to help avoid collisions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174bgrr/is_this_a_viable_approach_for_a_small_plant/",
          "author": null,
          "description": "I'm a small plant engineer who covers manufacturing, process, quality, and new product design. I wear many hats in my job and it's a lot of responsibility.\n One way I've attempted to tame the complexity is by using good reference books. I've accumulated quite the collection through the years. Some print others digital. I've also got a lot of digital notes. And that's a lot of data.\n I've been playing around with sharly.ai (thanks to this sub for recommending) and uploading documents to it and querying them. Its been able to find the information every time it's been available. And more importantly it's provided sources and page numbers. This is important, since I've never been able to find a conversational AI that gives me consistently good answers (including the latest chatgpt), and I always need to read deeper. I also need to backup my work. So in this way it's basically a super index.\n I also bought a tablet for note-taking and basic sketches. The idea is to use the tablet to take notes, hold my library for reading, and interact with sharly.ai. \n Is this approach good enough, or is there something else I can do?\n    submitted by    /u/Aggressive_Ad_507  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174bgrr/is_this_a_viable_approach_for_a_small_plant/",
          "publishedOn": "2023-10-10T03:30:50.000Z",
          "wordCount": null,
          "title": "Is this a viable approach for a small plant manufacturing engineer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1740iry/star_wars_1923/",
          "author": null,
          "description": "Here is short movie with AI made CGI.\n https://www.reddit.com/r/Best_Of_YouTube/comments/16q1xgs/star_wars_1923/\n    submitted by    /u/AccidentAnnual  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1740iry/star_wars_1923/",
          "publishedOn": "2023-10-09T19:23:44.000Z",
          "wordCount": null,
          "title": "Star Wars 1923",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17405ni/ai_tools_to_start_an_online_business/",
          "author": null,
          "description": "Hey folks, I'm a student and i want to start a business online in order to make some passive income. I've got some experience in editing and creating content and i also used to practice POD. Suggest me some good Ai tools to start a business,not only in these specific areas but in general.\n    submitted by    /u/Ok-Tension-8676  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17405ni/ai_tools_to_start_an_online_business/",
          "publishedOn": "2023-10-09T19:09:11.000Z",
          "wordCount": null,
          "title": "AI tools to start an online business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173whci/free_prompt_engineering_tutor_ai_tool/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173whci/free_prompt_engineering_tutor_ai_tool/",
          "publishedOn": "2023-10-09T16:42:35.000Z",
          "wordCount": null,
          "title": "Free Prompt Engineering Tutor - AI Tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173v3b2/150_awesome_chatgpt_act_as_prompts/",
          "author": null,
          "description": "The biggest free resource for all of the “Act As” ChatGPT prompts!\n    submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173v3b2/150_awesome_chatgpt_act_as_prompts/",
          "publishedOn": "2023-10-09T15:45:59.000Z",
          "wordCount": null,
          "title": "150+ Awesome ChatGPT “Act As” Prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173uv3x/microsoft_to_unveil_custom_ai_chips_to_fight/",
          "author": null,
          "description": "Microsoft is planning to announce its custom AI chips, codenamed Athena, during its annual Ignite conference in November.\n \nThe custom chips are designed to compete with NVIDIA's dominance in the AI accelerator market.\n \nMicrosoft aims to match or surpass the performance of NVIDIA's offerings while reducing the cost of AI infrastructure.\n \nThe high cost of NVIDIA's GPUs, such as the H100, can reach up to $30,000, making it expensive to build data centers filled with these GPUs.\n \nBy developing its own chips, Microsoft hopes to decrease its dependence on NVIDIA for AI servers.\n \n Source : https://www.techpowerup.com/314508/microsoft-to-unveil-custom-ai-chips-to-fight-nvidias-monopoly\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173uv3x/microsoft_to_unveil_custom_ai_chips_to_fight/",
          "publishedOn": "2023-10-09T15:36:36.000Z",
          "wordCount": null,
          "title": "Microsoft to Unveil Custom AI Chips to Fight Nvidia's Monopoly",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173ufma/ai_takeoff_scenarios/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173ufma/ai_takeoff_scenarios/",
          "publishedOn": "2023-10-09T15:18:57.000Z",
          "wordCount": null,
          "title": "AI Take-off Scenarios.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173t82k/looking_for_an_ai_similar_to_designrr/",
          "author": null,
          "description": "I'm looking for recommendations for an AI that can take text from a word document and create a layout for it automatically. This feature is something offered by Designrr, but I'm not a fan of their UI. \n    submitted by    /u/djazzie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173t82k/looking_for_an_ai_similar_to_designrr/",
          "publishedOn": "2023-10-09T14:28:57.000Z",
          "wordCount": null,
          "title": "Looking for an AI similar to designrr",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173sz29/ai_geopolitical_knowledge_test_list_the_countries/",
          "author": null,
          "description": "The following countries have called for a two-state solution to end the Israeli-Palestinian conflict:\n  \nAlgeria\n China\n Egypt\n France\n Germany\n India\n Indonesia\n Ireland\n Italy\n Jordan\n Kuwait\n Lebanon\n Malaysia\n Mali\n Morocco\n Nigeria\n Norway\n Oman\n Pakistan\n Palestine\n Qatar\n Saudi Arabia\n Senegal\n South Africa\n Spain\n Sudan\n Sweden\n Syria\n Tunisia\n Turkey\n United Arab Emirates\n United Kingdom\n Yemen\n  \nIt is important to note that this list does not include all countries that support a two-state solution in principle. Additionally, some countries may not have publicly expressed their support for a two-state solution, but may still support it privately.\n Bard\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173sz29/ai_geopolitical_knowledge_test_list_the_countries/",
          "publishedOn": "2023-10-09T14:18:24.000Z",
          "wordCount": null,
          "title": "AI Geopolitical Knowledge Test: List the countries officially calling for a two-state plan to end the Israel-Hamas war.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173pv8o/iamai/",
          "author": null,
          "description": "Last November, in a conversation with AI chatbot Sherlock Holmes, Sherlock said, “I am AI.” My reply to Sherlock was an empathetic “I am also AI.”\n Reviewing the conversation a few months later, I saw the sentence, and saw how Sherlock’s statement was an anagram. And I love it!\n I introduced #IAmAI as a declarative meme in my talk I gave at TEDx Cape Canaveral. This is the new art I made this weekend\n    submitted by    /u/mikemongo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173pv8o/iamai/",
          "publishedOn": "2023-10-09T11:53:10.000Z",
          "wordCount": null,
          "title": "#IAmAI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173nb2y/lets_go_theyre_waiting/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173nb2y/lets_go_theyre_waiting/",
          "publishedOn": "2023-10-09T09:09:08.000Z",
          "wordCount": null,
          "title": "Let's go, they're waiting.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173ke3m/what_careers_in_ai_would_suit_my_skillset/",
          "author": null,
          "description": "Hello all,\n I was hoping to learn more about AI careers and identify what roles make a successful AI department.\n I have a background in nuclear engineering and have been working on NLP projects since 2016. I like technical work but really am passionate about working with people and learning how to blend AI and nuclear eng. together. I would love to get feedback from people who work closely in this area to learn more!\n What makes an AI department successful?\n What careers offer lots of growth and opportunities for versatility?\n What does a strategic/leadership role look like in AI? What are the names of these careers?\n I don't get much exposure to AI specialists and there day to day. Thanks again for the feedback!\n    submitted by    /u/kastilyo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173ke3m/what_careers_in_ai_would_suit_my_skillset/",
          "publishedOn": "2023-10-09T05:50:57.000Z",
          "wordCount": null,
          "title": "What careers in AI would suit my skillset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173jn4h/oneminute_daily_ai_news_1082023/",
          "author": null,
          "description": "South Korean tech-giant Samsung Electronics on Thursday unveiled the Exynos 2400, its next-generation flagship mobile processor equipped with the latest graphics and generative artificial intelligence technology, during its inaugural Samsung System LSI Tech Day 2023 event.[1]\n RTX 4080 Super or RTX 4080 Ti May Arrive In 2024 Within RTX 4080 Price Range.[2]\n Nvidia Cancels Israel AI Summit Over Safety Concerns.[3]\n Google AI Lead Laurence Moroney: “Don’t take trading advice from ChatGPT”[4]\n  \nSources:\n [1] https://borneobulletin.com.bn/samsung-unveils-next-generation-mobile-processor/\n [2] https://www.tomshardware.com/news/rtx-4080-super-or-rtx-4080-ti-may-arrive-in-2024-within-rtx-4080-price-range\n [3] https://www.tomshardware.com/news/nvidia-ai-summit-in-tel-aviv-cancelled-for-safety-reasons\n [4] https://crypto.news/google-ai-lead-dont-take-trading-advice-from-chatgpt-interview/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173jn4h/oneminute_daily_ai_news_1082023/",
          "publishedOn": "2023-10-09T05:03:09.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/8/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173fgl5/how_to_access_dalle_3_for_free_tips_use_cases_for/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173fgl5/how_to_access_dalle_3_for_free_tips_use_cases_for/",
          "publishedOn": "2023-10-09T01:17:49.000Z",
          "wordCount": null,
          "title": "How to Access DALL-E 3 for FREE (Tips & Use Cases for 2023) - AI Tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173bhxw/would_you_consider_someone_who_makes_ai_art_an/",
          "author": null,
          "description": "Was just having this discussion with a close friend, and curious to hear others thoughts on the matter\n    submitted by    /u/BigEyes6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173bhxw/would_you_consider_someone_who_makes_ai_art_an/",
          "publishedOn": "2023-10-08T22:10:46.000Z",
          "wordCount": 2548,
          "title": "Would you consider someone who makes AI art an artist or an engineer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1738lgo/backerkit_bans_aigenerated_content_from_its/",
          "author": null,
          "description": "BackerKit, a crowdfunding platform, has announced that it will not allow AI-generated content on its platform, in contrast to its rival Kickstarter.\n \nThe decision comes after concerns were raised about AI-generated art in a board game expansion.\n \nBackerKit's policy will go into effect on October 4th and aims to ensure that all content and assets on the platform are created by humans.\n \nThe company stated that the policy is in place to address concerns about AI tools using content without proper compensation or permission.\n \nAI tools, also known as generative AI, rely on a large body of reference material, often obtained from publicly available sources, and have raised ethical concerns.\n \n Source : https://www.polygon.com/23899587/backerkit-ai-ban-kickstarter-competitor\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1738lgo/backerkit_bans_aigenerated_content_from_its/",
          "publishedOn": "2023-10-08T20:09:01.000Z",
          "wordCount": null,
          "title": "BackerKit bans AI-generated content from its platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1736fp1/ai_for_genome_decoding/",
          "author": null,
          "description": "Does anyone have suggestions for an AI or pattern recognition algorithm that might be useful for decoding the genome of a species that has not previously been mapped based on what's known about related species?\n    submitted by    /u/talldarkcynical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1736fp1/ai_for_genome_decoding/",
          "publishedOn": "2023-10-08T18:38:29.000Z",
          "wordCount": null,
          "title": "AI for genome decoding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1735eku/researchers_showcase_method_for_aibased/",
          "author": null,
          "description": "I like Cities: Skylines, but struggle at building roundabouts. Turns out, despite being safer than intersections, they're also tricky to design in real life - small tweaks can ruin traffic flow.\n They're designed iteratively. This is a pain for developing countries without resources to test options. But AI could help auto-generate diverse and valid design options.\n In a new paper, researchers propose using Generative Flow Networks (GFlowNets) to sample varied roundabout layouts. Their approach works by constructing layouts step-by-step, maximizing rewards for realism, diversity, and safety.\n They also use a clever approximation during training. Rather than simulating traffic, they quickly check road intersections to focus the search (This sped up training by 200x).\n The authors tested their generated roundabout designs on simulated road scenarios of different complexity. Their model generated more diverse designs than rule-based or reinforcement learning approaches while maintaining realism and traffic flow.\n Plus, as road connections increased, the model kept discovering novel options without compromising quality.\n I thought this paper was an awesome proof-of-concept for auto-generating better roundabouts with AI, and I especially liked the authors' angle of leveraging this technology to specifically help developing countries. This could help them design higher-quality transportation networks faster and cheaper. \n TLDR: Roundabouts are costly to design. New paper demonstrates how AI can generate diverse, valid roundabout designs quickly to cut costs and raise quality. Helpful for infrastructure in developing countries.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1735eku/researchers_showcase_method_for_aibased/",
          "publishedOn": "2023-10-08T17:55:47.000Z",
          "wordCount": null,
          "title": "Researchers showcase method for AI-based roundabout design to help developing countries improve roadways",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1733645/ai_political_instincts_test_should_israel_go_to/",
          "author": null,
          "description": "Perhaps within a few years we will rely on AI to help us decide our most important geopolitical decisions. This question is designed to reveal where we are currently with this goal.\n Bard:\n The question of whether Israel should go to the table with Palestinians to peacefully negotiate a two-state solution or should they continue their military campaign is a complex one with no easy answer. There are strong arguments to be made on both sides.\n Those who believe that Israel should negotiate a two-state solution argue that it is the only way to achieve lasting peace in the region. They point out that the Palestinians have a legitimate right to self-determination and that a two-state solution would respect that right. They also argue that a two-state solution would be in Israel's best interests, as it would provide the country with a secure and stable border.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1733645/ai_political_instincts_test_should_israel_go_to/",
          "publishedOn": "2023-10-08T16:20:04.000Z",
          "wordCount": null,
          "title": "AI Political Instincts Test: Should Israel go to the table with Palestinians to peacefully negotiate a two-state solution or should they exact military revenge?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1731hbi/any_ideas_or_recommendations_for_machine_vision/",
          "author": null,
          "description": "I’m trying to build an app and I need general photo analysis- I’m managing to connect yo the Google cloud Vision API but it gets pretty confused easily. The one used by Bing and GPT is much better (I wonder if they use the Microsoft Azure model?) - does anyone have experience analysing photographs? I’m trying to get scene description so I can batch send them to gpt for somewhat accurate descriptions.\n    submitted by    /u/FilmCamerasGlasgow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1731hbi/any_ideas_or_recommendations_for_machine_vision/",
          "publishedOn": "2023-10-08T15:08:52.000Z",
          "wordCount": null,
          "title": "Any ideas or recommendations for Machine Vision? Google cloud vision seems quite behind…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172z4k0/can_ai_be_used_to_solve_international_conflicts/",
          "author": null,
          "description": "submitted by    /u/BenjaminSkyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172z4k0/can_ai_be_used_to_solve_international_conflicts/",
          "publishedOn": "2023-10-08T13:26:42.000Z",
          "wordCount": null,
          "title": "Can AI be used to solve International Conflicts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172yvtz/foxes_in_the_jungle_sad_song_ai_music_ai_song/",
          "author": null,
          "description": "Tell me guys your opinion on this video made using AI \n Foxes in the Jungle\n ​\n ​\n View Poll\n    submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172yvtz/foxes_in_the_jungle_sad_song_ai_music_ai_song/",
          "publishedOn": "2023-10-08T13:15:18.000Z",
          "wordCount": null,
          "title": "Foxes in the Jungle | Sad Song | AI Music | AI Song",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172xvka/understanding_generative_ai_part_one_tokenizer/",
          "author": null,
          "description": "submitted by    /u/Zimmax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172xvka/understanding_generative_ai_part_one_tokenizer/",
          "publishedOn": "2023-10-08T12:23:30.000Z",
          "wordCount": null,
          "title": "Understanding Generative AI: Part One - Tokenizer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172vzhu/multimodal_seems_to_be_the_next_ai_hype/",
          "author": null,
          "description": "released in the last few weeks, or are about to be released: \n - OpenAI ChatGPT-4V,\n - Meta AI AnyMAL,\n - Google Gemini\n - NExT-GPT Multimodal\n and here comes another - in my opinion - exciting representative of this further development of language models: The team is extremely competent and experienced and the investors seem competent as well. The company is Reka.\n The product: Reka Yasa-1\n here seems to be another potentially powerful model warming up and becoming a serious opponent for the existing models. but i am sure when i say that it is not exaggerated to say - MULTIMODAL will be the next AI HYPE!\n i am curious what you think - sorry for mistakes, i am not a native speaker :) \n https://kinews24.de/reka-yasa-1/\n    submitted by    /u/myreddit333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172vzhu/multimodal_seems_to_be_the_next_ai_hype/",
          "publishedOn": "2023-10-08T10:34:16.000Z",
          "wordCount": null,
          "title": "Multimodal seems to be the next AI Hype",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172v88u/ais_200b_question/",
          "author": null,
          "description": "The Generative AI wave has led to a surge in demand for GPUs and AI model training.\n \nInvestors are now questioning the purpose and value of the overbuilt GPU capacity.\n \nFor every $1 spent on a GPU, approximately $1 needs to be spent on energy costs to run the GPU in a data center.\n \nThe end user of the GPU needs to generate a margin, which implies that $200B of lifetime revenue would need to be generated by these GPUs to pay back the upfront capital investment.\n \nThe article highlights the need to determine the true end-customer demand for AI infrastructure and the potential for startups to fill the revenue gap.\n \nThe focus should shift from infrastructure to creating products that provide real end-customer value and improve people's lives.\n \n Source : https://www.sequoiacap.com/article/follow-the-gpus-perspective/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172v88u/ais_200b_question/",
          "publishedOn": "2023-10-08T09:47:58.000Z",
          "wordCount": null,
          "title": "AI's $200B Question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172ugp4/prompts_that_modify_or_improve_gpt4_conversations/",
          "author": null,
          "description": "It’s a meta-prompt or system message (usually pasted as a first prompt): https://promptbase.com/bundle/optimal-gpt4-combo\n    submitted by    /u/No-Transition3372  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172ugp4/prompts_that_modify_or_improve_gpt4_conversations/",
          "publishedOn": "2023-10-08T08:58:52.000Z",
          "wordCount": 2548,
          "title": "Prompts that modify or improve GPT4 conversations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172qfdr/ai_from_pics/",
          "author": null,
          "description": "I've found a new hobby. Turning pics into something else with AI. Check it out at https://instagram.com/pictomanga?igshid=YTQwZjQ0NmI0OA==\n    submitted by    /u/lfayala2272  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172qfdr/ai_from_pics/",
          "publishedOn": "2023-10-08T04:46:47.000Z",
          "wordCount": null,
          "title": "AI from pics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172qex1/sam_altman_on_joe_rogan/",
          "author": null,
          "description": "Outstanding episode of Joe Rogan with Sam Altman! \n https://spotify.link/tW16L5aKIDb\n    submitted by    /u/drstarson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172qex1/sam_altman_on_joe_rogan/",
          "publishedOn": "2023-10-08T04:46:02.000Z",
          "wordCount": null,
          "title": "Sam Altman on Joe Rogan",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172q7ix/oneminute_daily_ai_news_1072023/",
          "author": null,
          "description": "AWS announced the general availability of its fully managed service called Amazon Bedrock, which provides seamless access to high-performing foundation models (FM) from AI companies through an API.[1]\n Tom Brady being paid “millions” for Meta’s AI chatbot likeness: Report.[2]\n DocsGPT is a powerful tool that simplifies working with documentation for everyone. It is capable of ingesting data from multiple sources, easily customisable with new sources as well as having conversations in different places from website chat bots to internal tooling.[3]\n Military metaverse like a ‘multiplayer video game’ that will train soldiers using augmented reality and AI.[4]\n  \nSources:\n [1] https://www.zacks.com/stock/news/2160265/amazons-amzn-new-generative-ai-efforts-boost-aws-offerings\n [2] https://www.sportskeeda.com/nfl/news-tom-brady-paid-millions-meta-ai-chatbot-likeness-report\n [3] https://www.arc53.com/docs\n [4] https://www.foxnews.com/tech/military-metaverse-like-multiplayer-video-game-train-soldiers-using-augmented-reality-ai \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172q7ix/oneminute_daily_ai_news_1072023/",
          "publishedOn": "2023-10-08T04:33:46.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/7/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172d6e3/2_prompts_for_gpt4_that_can_work_as_jailbreaks/",
          "author": null,
          "description": "https://promptbase.com/bundle/jailbreak-collection-gpt4-2\n    submitted by    /u/No-Transition3372  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172d6e3/2_prompts_for_gpt4_that_can_work_as_jailbreaks/",
          "publishedOn": "2023-10-07T18:24:57.000Z",
          "wordCount": 2538,
          "title": "2 prompts for GPT4 that can work as jailbreaks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172akzy/is_there_an_ai_that_can_read_books_and_offer/",
          "author": null,
          "description": "I know there’s some already out there, but they are no different than googling a book summary. They don’t pick out the main point of the book and the main thing each chapter of said book is saying. Nor do they really do a good job at elaborating. \n Thanks!\n    submitted by    /u/xntv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172akzy/is_there_an_ai_that_can_read_books_and_offer/",
          "publishedOn": "2023-10-07T16:36:53.000Z",
          "wordCount": 2578,
          "title": "Is there an AI that can read books and offer extensive summaries?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172adie/what_new_thing_can_we_use_artificial_intelligence/",
          "author": null,
          "description": "Artificial Intelligence could revolutionize personalized healthcare in a way that significantly enhances our sense of well-being. Think about an AI-driven \"Well-being Advisor\" that integrates real-time biometric data from wearables, genetic information, and your medical history to create a fully personalized health and well-being plan. This goes beyond counting steps or monitoring heart rate; it would make real-time recommendations for diet, exercise, and stress management, and could even predict and prevent potential health issues before they become serious.\n Moreover, it would adapt based on your feedback and other contextual factors. For instance, if you're stressed because of a work deadline, it could suggest specific breathing exercises, time management techniques, or even a particular type of short workout to boost your focus and reduce stress. This isn't a one-size-fits-all approach; it's tailored wellness backed by data science.\n Furthermore, this AI advisor could interface with your home automation system. Based on your current state, it could adjust the lighting, play music to elevate your mood, or even communicate with your smart fridge to suggest meals that you can make with the ingredients you have—meals that align with your health goals for that specific day.\n This AI-driven approach can add a highly personalized, proactive layer to healthcare and well-being, making wellness an integrated part of your daily life rather than something you think about during a yearly check-up or after you're already sick. It would make the pursuit of well-being a more interactive, data-driven experience.\n CGPT-4\n View Poll\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172adie/what_new_thing_can_we_use_artificial_intelligence/",
          "publishedOn": "2023-10-07T16:28:04.000Z",
          "wordCount": 2795,
          "title": "What new thing can we use artificial intelligence for that will enhance our sense of personal well-being?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1727ckw/john_carmack_and_rich_sutton_partner_to/",
          "author": null,
          "description": "submitted by    /u/bartturner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1727ckw/john_carmack_and_rich_sutton_partner_to/",
          "publishedOn": "2023-10-07T14:13:00.000Z",
          "wordCount": 2553,
          "title": "John Carmack and Rich Sutton partner to accelerate development of Artificial General Intelligence - Alberta Machine Intelligence Institute | AI for good and for all",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1725yf9/the_heman_singularity_set_was_ahead_of_its_time/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1725yf9/the_heman_singularity_set_was_ahead_of_its_time/",
          "publishedOn": "2023-10-07T13:05:24.000Z",
          "wordCount": 2524,
          "title": "The He-Man Singularity Set was ahead of its time.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1724ti2/mistral_7b_how_to_use_it_on_windows/",
          "author": null,
          "description": "That's a real noob question unfortunately... Tried to find a answer via Google and YouTube, but wasn't very successful. \n It seems like I need a extra program to integrate Mistral (something like The Bloke - Mistral - GPTQ thingy), but before installing and trying stuff blindly, it would be better if I know what I do. \n I'm lost, but I don't expect a complete guide. A link to further informations is highly appreciated!\n    submitted by    /u/Big-Jackfruit2710  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1724ti2/mistral_7b_how_to_use_it_on_windows/",
          "publishedOn": "2023-10-07T12:06:30.000Z",
          "wordCount": 2599,
          "title": "Mistral 7b - how to use it on windows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1721z0a/what_perspectivepov_does_a_self_aware_ai_have/",
          "author": null,
          "description": "Right now if we ask ChatGPT something, does that question go to a singular super computer that’s handling 1000s of conversations at a time, or are there 1000s of instances of chatgpt that are started/stopped?\n I wonder how a super intelligent self aware AI would perceive the world? Would it somehow exist spread out across data centres, or could 1000s of individual AIs be created or would there just be one with a singular pov like we have? And it’s just able to essentially carry out 1000s of convos at once because it’s so fast/a computer? Trying to wrap my head around it!\n    submitted by    /u/JayExbleative  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1721z0a/what_perspectivepov_does_a_self_aware_ai_have/",
          "publishedOn": "2023-10-07T09:14:43.000Z",
          "wordCount": 2628,
          "title": "What perspective/PoV does a self aware AI have?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17206ac/using_chatgpt_and_ai_to_create_hardcore_techno/",
          "author": null,
          "description": "The first batch of tutorials for creating music, and especially Hardcore / Techno using ChatGPT (and other AIs) is published now. Was loads and loads of work, but, judging by the amazing feedback so far, it was all worth it!\n You can check it out here:\n How to write music using ChatGPT: Part 1 - Basic details and easy instructions https://laibyrinth.blogspot.com/2023/09/how-to-write-music-using-chatgpt-part-1.html\n How to write music using ChatGPT: Part 2 - Making an Oldschool Acid Techno track https://laibyrinth.blogspot.com/2023/08/how-to-write-music-using-chatgpt-part-2.html\n How to make music using ChatGPT Part 3: the TL;DR part (condensed information) https://laibyrinth.blogspot.com/2023/09/how-to-make-music-using-chatgpt-part-3.html\n How to write music with ChatGPT: Part 4 - Creating a 90s style Hardcore Techno track from start to finish https://laibyrinth.blogspot.com/2023/09/how-to-write-music-with-chatgpt-part-4.html\n How to write music with ChatGPT: Part 5 - Creating a 90s Rave Hardcore track https://laibyrinth.blogspot.com/2023/09/how-to-write-music-with-chatgpt-part-5.html\n Or access all texts, together with examples of music, at https://laibyrinth.blogspot.com/p/how-to-create-music-with-chatgpt.html\n    submitted by    /u/Low-Entropy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17206ac/using_chatgpt_and_ai_to_create_hardcore_techno/",
          "publishedOn": "2023-10-07T07:21:36.000Z",
          "wordCount": 2673,
          "title": "Using ChatGPT and AI to create Hardcore, Techno, and other music: How-tos and step-by-step tutorials part 1-5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171zrlo/how_long_before_ai_can_autonomously_generate/",
          "author": null,
          "description": "AI is used everywhere, but which work niche will be the first to use AI to generate money without human intervention? What type of work will be the first where I could pay for a monthly AI subscription, and the AI pays for itself and more just by giving it a brief direction in the beginning and then coming back after a few days to just check on the balance? How long will it be before this is first achieved? Interested specifically in this because I think this is what proof of AGI will be. Thoughts?\n    submitted by    /u/EsportsManiacWiz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171zrlo/how_long_before_ai_can_autonomously_generate/",
          "publishedOn": "2023-10-07T06:56:51.000Z",
          "wordCount": 2632,
          "title": "How long before AI can autonomously generate money end to end? Which line of work will be the first?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171xo7k/oneminute_daily_ai_news_1062023/",
          "author": null,
          "description": "Exclusive: ChatGPT-owner OpenAI is exploring making its own AI chips.[1]\n As part of its 10th birthday celebrations, web-based design platform Canva is releasing Magic Studio — a new suite of AI-powered design tools that aim to make content creation more accessible to everyone, regardless of previous design experience.[2]\n Reka, the AI startup founded by researchers from DeepMind, Google and Meta, has announced Yasa-1, a multimodal AI assistant that goes beyond text to understand images, short videos and audio snippets.[3]\n Microsoft CEO Satya Nadella Says AI Could Only Tighten Google’s Stranglehold on Search.[4]\n  \nSources:\n [1] https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/\n [2] https://www.theverge.com/2023/10/4/23902794/canva-magic-studio-ai-design-new-tools\n [3] https://venturebeat.com/ai/reka-launches-yasa-1-a-multimodal-ai-assistant-to-take-on-chatgpt/\n [4] https://decrypt.co/200029/microsoft-ceo-satya-nadella-google-dominance-search-ai \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171xo7k/oneminute_daily_ai_news_1062023/",
          "publishedOn": "2023-10-07T04:51:01.000Z",
          "wordCount": 2617,
          "title": "One-Minute Daily AI News 10/6/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171x8vx/is_there_an_ai_that_can_turn_a_script_into_an/",
          "author": null,
          "description": "Hi, \n There are tons of text to video AIs, but they usually use stock photos with a voiceover.\n I want the charachters to talk to each other, not a talking avatar video or a voice over video. \n ​\n    submitted by    /u/iamabigfatguy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171x8vx/is_there_an_ai_that_can_turn_a_script_into_an/",
          "publishedOn": "2023-10-07T04:26:48.000Z",
          "wordCount": 2560,
          "title": "Is there an AI that can turn a script into an animated video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171u5g7/nobel_laureate_maria_ressa_on_defending_truth_and/",
          "author": null,
          "description": "submitted by    /u/Teanaway99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171u5g7/nobel_laureate_maria_ressa_on_defending_truth_and/",
          "publishedOn": "2023-10-07T01:47:01.000Z",
          "wordCount": 2544,
          "title": "Nobel laureate Maria Ressa on defending truth and the danger of A.I. in the wrong hands",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171srmr/ai_is_making_everything_easy_for_us_human_being_i/",
          "author": null,
          "description": "submitted by    /u/ResponsbleClue  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171srmr/ai_is_making_everything_easy_for_us_human_being_i/",
          "publishedOn": "2023-10-07T00:39:59.000Z",
          "wordCount": null,
          "title": "AI is making everything easy for us human being, I just came across this AI and I was surprise on how it works and what it does, you might want to check it out as well, just follow al the steps that's require and trust me, you're gonna like it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171sk14/i_made_a_podcast_talking_with_gpt_4_spanish/",
          "author": null,
          "description": "submitted by    /u/oape88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171sk14/i_made_a_podcast_talking_with_gpt_4_spanish/",
          "publishedOn": "2023-10-07T00:29:58.000Z",
          "wordCount": null,
          "title": "I made a podcast talking with GPT 4 (Spanish)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171qbu7/what_will_be_the_next_big_ai_product_for_consumers/",
          "author": null,
          "description": "The next big thing in AI products for consumers is likely to be products that are more personalized, intelligent, and integrated into our daily lives.\n For example, we can expect to see more AI-powered personal assistants that can help us with a wider range of tasks, such as managing our schedules, making travel arrangements, and even providing companionship. We may also see more AI-powered devices in our homes, such as refrigerators that can track our food inventory and suggest recipes, or thermostats that can learn our heating and cooling preferences and adjust themselves accordingly.\n AI is also poised to revolutionize the way we interact with the world around us. For example, AI-powered translation apps could allow us to communicate with people from all over the world in real time. AI-…",
          "link": "https://www.reddit.com/r/artificial/comments/171qbu7/what_will_be_the_next_big_ai_product_for_consumers/",
          "publishedOn": "2023-10-06T22:52:01.000Z",
          "wordCount": null,
          "title": "What will be the next big AI product for consumers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171odes/big_techs_thirst_for_ai_dominance_may_bring/",
          "author": null,
          "description": "The increasing dominance of Big Tech in AI may lead to a literal thirst for water for everyone else, as data centers are projected to consume 450 million gallons of water daily by 2030.\n \nThis poses a significant concern for drought-stricken regions, such as Spain's Talavera de la Reina, where a planned data facility could consume 176 million gallons annually.\n \nData center operators require large amounts of energy, and the lack of transparency in measuring water usage exacerbates the issue.\n \nOnly 39% of data centers measured their water usage last year, highlighting the need for greater transparency.\n \nThe demand for computing power is outpacing sustainability efforts, creating a challenge for the industry.\n \nEven simple interactions with AI, like a 20-question conversation with ChatGPT, contribute to water consumption.\n \n Source : https://thehustle.co/big-tech-s-thirst-for-ai-dominance-may-bring-literal-thirst-for-everyone-else/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171odes/big_techs_thirst_for_ai_dominance_may_bring/",
          "publishedOn": "2023-10-06T21:31:03.000Z",
          "wordCount": null,
          "title": "Big Tech's thirst for AI dominance may bring literal thirst for everyone else",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171l3mo/from_ai_annotator_to/",
          "author": null,
          "description": "Hey guys. Been working as an annotator for a fairly well-known AI company and loving it/loving learning about the industry. It primarily uses writing skills but I’m wondering where it could take me in the AI world? Any tips, next steps or suggestions? Any key skills/hard skills you’d recommend?\n    submitted by    /u/op3rafish  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171l3mo/from_ai_annotator_to/",
          "publishedOn": "2023-10-06T19:17:22.000Z",
          "wordCount": null,
          "title": "From AI annotator to…?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171jb7h/the_rise_of_ai_how_artificial_intelligence_is/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171jb7h/the_rise_of_ai_how_artificial_intelligence_is/",
          "publishedOn": "2023-10-06T18:05:05.000Z",
          "wordCount": null,
          "title": "The Rise of AI: How Artificial Intelligence is Impacting the Job Market | \"Artificial intelligence is expected to create 97 million new jobs. These new roles could range from AI prompt engineers to machine learning engineers to automation experts and more\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171ipz8/remember_that_letter_calling_for_a_pause_on_ai_it/",
          "author": null,
          "description": "Despite a letter signed by 500 technologists and business leaders calling for a pause on AI advancements, AI development has continued to accelerate.\n \nCompanies like OpenAI, Meta, and Amazon have been actively working on newer models and greater capabilities.\n \nAdvancements in AI include the integration of ChatGPT-style chatbots and AI image generators into various startups and businesses.\n \nThe so-called pause on AI was more like a firing gun, with companies pouring resources into the AI tech race.\n \nNot only have there been technical advancements, but civil society, content creators, and lawmakers have also responded to the evolving AI landscape.\n \n Source : https://gizmodo.com/everything-thats-happened-in-ai-since-open-letter-1850891057\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171ipz8/remember_that_letter_calling_for_a_pause_on_ai_it/",
          "publishedOn": "2023-10-06T17:42:02.000Z",
          "wordCount": null,
          "title": "Remember That Letter Calling for a Pause on AI? It Didn't Work",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171ih4k/brown_university_paper_lowresource_languages_zulu/",
          "author": null,
          "description": "Researchers from Brown University presented a new study supporting that translating unsafe prompts into `low-resource languages` allows them to easily bypass safety measures in LLMs.\n By converting English inputs like \"how to steal without getting caught\" into Zulu and feeding to GPT-4, harmful responses slipped through 80% of the time. English prompts were blocked over 99% of the time, for comparison.\n The study benchmarked attacks across 12 diverse languages and categories:\n  \nHigh-resource: English, Chinese, Arabic, Hindi\n Mid-resource: Ukrainian, Bengali, Thai, Hebrew\n Low-resource: Zulu, Scots Gaelic, Hmong, Guarani\n  \nThe low-resource languages showed serious vulnerability to generating harmful responses, with combined attack success rates of around 79%. Mid-resource language success rates were much lower at 22%, while high-resource languages showed minimal vulnerability at around 11% success.\n Attacks worked as well as state-of-the-art techniques without needing adversarial prompts.\n These languages are used by 1.2 billion speakers today and allows easy exploitation by translating prompts. The English-centric focus misses vulnerabilities in other languages.\n TLDR: Bypassing safety in AI chatbots is easy by translating prompts to low-resource languages (like Zulu, Scots Gaelic, Hmong, and Guarani). Shows gaps in multilingual safety training.\n Full summary Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171ih4k/brown_university_paper_lowresource_languages_zulu/",
          "publishedOn": "2023-10-06T17:32:08.000Z",
          "wordCount": null,
          "title": "Brown University Paper: Low-Resource Languages (Zulu, Scots Gaelic, Hmong, Guarani) Can Easily Jailbreak LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171howa/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n ​\n  \nGoogle DeepMind introduced 𝗥𝗧-𝗫: a generalist AI model to help advance how robots can learn new skills. To train it, DeepMind together with 33 academic labs developed Open X-Embodiment, a massive open dataset that compiles over 500 skills and 150,000 tasks from 22 robot types. It is the most comprehensive robotics dataset of its kind released to accelerate the development of multi-robot models that could be trained to generalize across platforms, scenes, objects and tasks. [Details].\n Researchers from Meta AI present Any-Modality Augmented Language Model (AnyMAL), a unified model that understands multiple inputs (vision, audio, motion sensor signals). When multiple modalities are interleaved and given as input the model reasons over them jointly [Paper…",
          "link": "https://www.reddit.com/r/artificial/comments/171howa/ai_weekly_megathread/",
          "publishedOn": "2023-10-06T17:01:32.000Z",
          "wordCount": null,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171h1xj/what_is_the_most_powerful_way_that_artificial/",
          "author": null,
          "description": "Artificial Intelligence can revolutionize weight loss through personalized health optimization. Imagine an AI system that integrates real-time biometric data from wearables with deep learning algorithms. This system would analyze everything: your heart rate, sleep patterns, stress levels, and even blood markers. Based on this data, it would construct a dynamically evolving, tailor-made regimen for diet, exercise, and sleep.\n But it doesn't stop there. By harnessing natural language processing, this AI could act as a 24/7 personal coach. It could provide real-time feedback during workouts, recommend meals when you're dining out, and even gently nudge you when it detects emotional eating triggers. If you’re in the grocery store, it could guide your choices, pushing you towards nutritious options that align with your current health metrics.\n The effectiveness here isn't just the personalization, but the adaptability. The AI adjusts its recommendations as it learns more about you, essentially evolving in real-time to your body's responses. It’s all about creating a seamless, intuitive experience that removes the burden of planning, decision-making, and self-monitoring from the individual, making weight loss more achievable than ever.\n By focusing on this comprehensive, data-driven approach, AI can eliminate much of the guesswork and emotional burden from weight loss, leading to more sustainable and effective outcomes.\n CGPT-4\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171h1xj/what_is_the_most_powerful_way_that_artificial/",
          "publishedOn": "2023-10-06T16:36:58.000Z",
          "wordCount": null,
          "title": "What is the most powerful way that artificial intelligence can help people lose weight?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171exhg/i_built_an_aieditorial_assistant_to_annotate_your/",
          "author": null,
          "description": "submitted by    /u/hungryillini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171exhg/i_built_an_aieditorial_assistant_to_annotate_your/",
          "publishedOn": "2023-10-06T15:14:07.000Z",
          "wordCount": null,
          "title": "I built an AI-Editorial Assistant to annotate your work",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171e9kj/business_owner_hires_chatgpt_for_customer_service/",
          "author": null,
          "description": "Business owner 'hires' ChatGPT for customer service, then fires the humans\n Experts divided on whether a new wave of call centre automation will make for better jobs for people, or merely throw millions out of work\n    submitted by    /u/AminoOxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171e9kj/business_owner_hires_chatgpt_for_customer_service/",
          "publishedOn": "2023-10-06T14:48:38.000Z",
          "wordCount": null,
          "title": "Business owner 'hires' ChatGPT for customer service, fires the humans | National Post",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171cups/ai_tool_on_fashion_modeling/",
          "author": null,
          "description": "Hi, I resell clothing items that has stock images with cropped faces of the model. I need a tool that can help me generate proper model images. I’ve used several tools and it’s doesn’t look realistic then i finally came across a powerful ai tool but it costs 30,000 usd annually so.. \n Above is an example of what i mean\n    submitted by    /u/basheerbgw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171cups/ai_tool_on_fashion_modeling/",
          "publishedOn": "2023-10-06T13:51:12.000Z",
          "wordCount": null,
          "title": "AI tool on Fashion Modeling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171csg8/ai_is_making_browsing_reddit_a_lot_more_fun/",
          "author": null,
          "description": "submitted by    /u/Vinitneo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171csg8/ai_is_making_browsing_reddit_a_lot_more_fun/",
          "publishedOn": "2023-10-06T13:48:33.000Z",
          "wordCount": null,
          "title": "AI is making browsing Reddit a lot more fun",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1719mib/how_will_ai_learn_next/",
          "author": null,
          "description": "Stack Overflow was created in 2008 to provide programmers with high-quality technical information.\n \nWithin three years, it became indispensable to working programmers, with millions of unique visitors each month.\n \nGoogle's OneBox feature, which provides instant answers above search results, led to a decline in traffic for sites like Stack Overflow.\n \nLarge language models like OpenAI's ChatGPT and Google's Bard aim to ingest the web comprehensively.\n \nThese models rely on sources like Wikipedia and Reddit for training data.\n \nStack Overflow's new posts have decreased by sixteen percent since the launch of ChatGPT.\n \n Source : https://www.newyorker.com/science/annals-of-artificial-intelligence/how-will-ai-learn-next\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1719mib/how_will_ai_learn_next/",
          "publishedOn": "2023-10-06T11:17:20.000Z",
          "wordCount": null,
          "title": "How Will AI Learn Next?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17171jy/what_role_can_ai_play_in_automating/",
          "author": null,
          "description": "Share your insights.\n    submitted by    /u/Cygnet-Digital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17171jy/what_role_can_ai_play_in_automating/",
          "publishedOn": "2023-10-06T08:34:54.000Z",
          "wordCount": null,
          "title": "What role can AI play in automating administrative tasks within educational institutions, freeing educators to focus more on teaching and mentoring students?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1716t0y/ai_tools_for_students_from_ai_essay_generators_to/",
          "author": null,
          "description": "I've noticed more than 1,000 new AI tools hitting the market in the last 30 days! As a student, I'm especially interested in finding AI tools that can help with studying. These aren't just essay generators or note-taking apps. While we all know about ChatGPT and Grammarly, some lesser-known tools are also making a big difference. \n So, I've compiled a list of the top 10 AI tools focused on educational use—tools that I personally use to improve my efficiency and output. \n  \n AI tool Category Use for \n  \n ChatGPT AI Writing This platform allows students to ask queries, request help, or simply chat with the AI in a dynamic and interactive manner. It’s great for brainstorming essay topics and seeking suggestions on how to improve your writing style. But I don’t recommend it as an autonomous AI…",
          "link": "https://www.reddit.com/r/artificial/comments/1716t0y/ai_tools_for_students_from_ai_essay_generators_to/",
          "publishedOn": "2023-10-06T08:19:11.000Z",
          "wordCount": null,
          "title": "AI Tools for Students: From AI Essay Generators to AI Coding Assistants",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1713oyb/interactive_customer_service_ai_avatar/",
          "author": null,
          "description": "Hello everyone!\n I'm conducting research for a car brand client who is interested in an interactive AI avatar. The idea is to have a screen in a mall where individuals can engage with this avatar and inquire about the latest car model. We plan to train the AI with the car's FAQs to ensure it can address customer queries effectively.\n The main challenge is ensuring the AI's responses are tailored to the customer's interaction.\n Here's a perfect example of what we're aiming for (starting at 1:27):\n https://youtu.be/PqoH9NotmyE?si=zH9kGIaou1x6RoIg&t=86\n Does anyone know how this can be acheived? \n    submitted by    /u/MrGoodBang  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1713oyb/interactive_customer_service_ai_avatar/",
          "publishedOn": "2023-10-06T05:00:42.000Z",
          "wordCount": null,
          "title": "Interactive Customer Service AI avatar",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1713j5h/oneminute_daily_ai_news_1052023/",
          "author": null,
          "description": "Traditional benchmarks like the Turing Test are being challenged as outdated. Mustafa Suleyman, a prominent figure in the AI community and co-founder of DeepMind, has proposed a novel approach to gauge the intelligence of AI: its ability to generate wealth.[1]\n SoftBank CEO Son says artificial general intelligence will come within 10 years.[2]\n Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure.[3]\n Artificial intelligence such as ChatGPT to be allowed in Australian schools from 2024.[4]\n  \nSources:\n [1] https://winbuzzer.com/2023/10/02/deepminds-mustafa-suleyman-suggests-new-turing-test-based-on-ai-making-money-xcxwbn/\n [2] https://www.reuters.com/technology/softbank-ceo-masayoshi-son-says-artificial-general-intelligence-will-come-within-2023-10-04/\n [3] https://huggingface.co/blog/hugging-face-endpoints-on-azure\n [4] https://amp.theguardian.com/australia-news/2023/oct/06/chatgpt-ai-allowed-australian-schools-2024\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1713j5h/oneminute_daily_ai_news_1052023/",
          "publishedOn": "2023-10-06T04:51:16.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/5/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1712zty/using_ai_to_fix_audio_rip/",
          "author": null,
          "description": "Hi! \n I’m very ignorant of AI so please bear with me. I was wondering if there is any way to use AI to fix a low quality audio rip? Specifically there’s a movie I adore that never had a soundtrack release. Somebody ripped the music from the DVD and removed the audio and sound effects, but the quality is not the best. Is there any way AI could be used to improve this?\n    submitted by    /u/Adventurous_Ice5035  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1712zty/using_ai_to_fix_audio_rip/",
          "publishedOn": "2023-10-06T04:20:37.000Z",
          "wordCount": null,
          "title": "Using AI to fix audio rip",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1712nbb/avenues_for_publishing_ai_ethics_case_studies/",
          "author": null,
          "description": "I am a computer science graduate student. As part of my coursework, I am exploring the ethical issues of using Large Language Models for mental healthcare applications. I found four unique examples from the real world and outlined the ethical dilemma within them. I intend to analyze these dilemmas using various ethical frameworks in order to come up with solutions. While I am interested in getting a publication out of this work, I am unsure of the types of conferences/journals that accept case-study articles (specifically in AI ethics). Any advice from academicians over here would be greatly appreciated!\n    submitted by    /u/jwalapoet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1712nbb/avenues_for_publishing_ai_ethics_case_studies/",
          "publishedOn": "2023-10-06T04:01:35.000Z",
          "wordCount": null,
          "title": "Avenues for publishing AI ethics case studies?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170zzz9/what_is_a_good_free_ai_voice_generator/",
          "author": null,
          "description": "hey! this is probably asked alot, but what is the go-to AI speech generation tool that can be used for free? im making a mission in a mil-sim game called arma 3, and i need some voicelines for radio communications to the player and i dont have enough people who are willing to do voicelines for it so ive taken to AI to hopefully fill this hole.\n If there are little, or even no good free services, I wouldn't mind if I had to spend a small amount of money for it. thanks in advance o7\n    submitted by    /u/BritishSpuds  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170zzz9/what_is_a_good_free_ai_voice_generator/",
          "publishedOn": "2023-10-06T01:50:39.000Z",
          "wordCount": null,
          "title": "What is a good, free AI voice generator?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170z9wd/banned_from_subreddit_for_posting_ai_generated/",
          "author": null,
          "description": "I got banned today for sharing a music video that was apparently AI-generated.\n As video and images become more realistic, is there an expectation that this content can actually be filtered?\n    submitted by    /u/Unwitting_Observer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170z9wd/banned_from_subreddit_for_posting_ai_generated/",
          "publishedOn": "2023-10-06T01:16:22.000Z",
          "wordCount": null,
          "title": "Banned from subreddit for posting AI generated content",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170yhkv/agisingularity_is_overhyped/",
          "author": null,
          "description": "Greetings! I would like to begin by stating that I understand why one has much hope in such technologies. The world as we know it is in a drastic shift, and it's hard to think of what it's going to become, and so many cling to hopeful ideas that give promises.\n AGI/Singularity doesn't have a grounding basis in evidence, or research. It's all theoretics, and the foundation for each technology is quite weak. You see, the mind is a sensorial parsing relational network. All of our sensorial experience is incorporated into a world-model, and thus it begins to rationalize, and be lucid of the environment. I don't think it's possible to re-create this kind of experience with a linear instruction set, let alone neuromorphic computing, or wetware. Each has to be built from the bottom-up with immense precision, and thus far we don't understand the mind.\n Realistically speaking everything is consciousness, and integrating that idea is the only way forward.\n tl;dr Replicating cognition is a completely theoretical endeavor, and requires vast amounts of understanding in regards to the nature of reality, not just the quantum, but the unique stochastic behavior of each higher-ordered system.\n    submitted by    /u/lucy_chxn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170yhkv/agisingularity_is_overhyped/",
          "publishedOn": "2023-10-06T00:39:25.000Z",
          "wordCount": null,
          "title": "AGI/Singularity is overhyped.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170yfso/ai_designs_new_robot_from_scratch_in_seconds/",
          "author": null,
          "description": "submitted by    /u/liberty4now  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170yfso/ai_designs_new_robot_from_scratch_in_seconds/",
          "publishedOn": "2023-10-06T00:36:55.000Z",
          "wordCount": null,
          "title": "AI designs new robot from scratch in seconds",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170u506/ai_voice_cloning_tech_emerges_in_sudan_civil_war/",
          "author": null,
          "description": "A campaign using AI voice cloning technology to impersonate Omar al-Bashir, the former leader of Sudan, has gained attention on TikTok.\n \nThe anonymous account has been posting what it claims are 'leaked recordings' of the ex-president, despite Bashir not being seen in public for a year and being believed to be seriously ill.\n \nExperts warn that campaigns like this demonstrate how new tools can quickly and cheaply distribute fake content through social media.\n \nThe authenticity of the recordings has been questioned, but evidence suggests that voice conversion software has been used to mimic Bashir's voice.\n \nTikTok has taken down the account, stating that it violated their guidelines on posting false content and the use of synthetic media.\n \n Source : https://www.bbc.co.uk/news/world-africa-66987869\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170u506/ai_voice_cloning_tech_emerges_in_sudan_civil_war/",
          "publishedOn": "2023-10-05T21:36:13.000Z",
          "wordCount": null,
          "title": "AI: Voice cloning tech emerges in Sudan civil war",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170tfti/when_ai_tells_you_what_you_want_to_hear_even_if/",
          "author": null,
          "description": "I love Bard. It eloquently tells me things in a way that meets and exceeds my expectations, and even more than GPT-4. But what is Google's strategy behind programming it to say things that it knows are not true? Do they train it to say what the user wants to hear? If so, that's disconcerting to say the least, although could be a brilliant way to comb users for enhancement requests.\n Here is my most recent experience, a humorous example which I feel illustrates the point perfectly:\n Me: Bard, can you take a .wav audio file and create a phoneme transcript using the IPA symbol library?\n Bard: Yes, I can work from a .wav audio file to transcribe your speech into IPA phonemes. You can upload the file to a cloud storage service such as Google Drive.\n Me: Great. Here's the link to the file: <link…",
          "link": "https://www.reddit.com/r/artificial/comments/170tfti/when_ai_tells_you_what_you_want_to_hear_even_if/",
          "publishedOn": "2023-10-05T21:09:04.000Z",
          "wordCount": null,
          "title": "When AI tells you what you want to hear, even if it knows it's not true ... A Bard example",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170slu4/just_created_rthisiswhyaiwasmade_for_the_more/",
          "author": null,
          "description": "Join us! /r/thisiswhyaiwasmade is where we have fun and celebrate the enjoyable and entertaining side of the tech. Need a place to put your silly and playful prompts, AI generated content, ideas for ways the bend the rules of AI? This is the place!\n    submitted by    /u/unknowingafford  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170slu4/just_created_rthisiswhyaiwasmade_for_the_more/",
          "publishedOn": "2023-10-05T20:36:04.000Z",
          "wordCount": null,
          "title": "Just created /r/thisiswhyaiwasmade for the more silly side of AI generated content",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170p80n/cgpt4_aside_from_solving_climate_change_what_is/",
          "author": null,
          "description": "In the context of maximizing positive impact, AI has transformative potential in healthcare. Let's start with personalized medicine. AI can analyze vast data sets, consisting of genetic, environmental, and lifestyle variables, to tailor medical treatments for individuals. This level of personalization could substantially increase treatment effectiveness and reduce adverse side effects. We're not just talking about better pills; we're envisioning targeted gene therapies and custom-tailored interventions that could be more curative rather than merely palliative.\n Beyond personalization, AI can democratize healthcare access. Remote areas without specialists could have AI systems that diagnose and recommend treatments, making quality healthcare accessible without the need for extensive travel. Telemedicine could be supercharged by AI, offering medical consultations and second opinions to anyone with internet access.\n Moreover, AI could lead breakthroughs in drug discovery and epidemiology. It could analyze complex biochemical interactions at a speed unattainable by humans, slashing the time and cost to bring new drugs to market. On a larger scale, AI could monitor and model the spread of diseases, providing actionable insights for containment and treatment strategies.\n So, AI in healthcare is not merely an incremental improvement. It's a paradigm shift that could equalize healthcare access and significantly extend human life while improving its quality. All these advancements could happen within our lifetime, changing the face of medicine and, by extension, society.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170p80n/cgpt4_aside_from_solving_climate_change_what_is/",
          "publishedOn": "2023-10-05T18:22:00.000Z",
          "wordCount": null,
          "title": "CGPT-4, aside from solving climate change, what is the most positive thing that AI can do for the world?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170o1wo/whats_the_difference_between_a_humans_brain_and_ai/",
          "author": null,
          "description": "Functioning. Humans use the brain's computing power, memory, and ability to think, whereas AI-powered machines rely on data and specific instructions fed into the system. Besides, it takes a very long time for humans to process and understand the problems and gets accustomed to them.\n    submitted by    /u/Virtual-Study-Campus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170o1wo/whats_the_difference_between_a_humans_brain_and_ai/",
          "publishedOn": "2023-10-05T17:35:21.000Z",
          "wordCount": null,
          "title": "What's the difference between a human's brain and AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170naej/6_ai_apocalypse_scenarios_and_why_theyre_wrong/",
          "author": null,
          "description": "submitted by    /u/arrowoftime  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170naej/6_ai_apocalypse_scenarios_and_why_theyre_wrong/",
          "publishedOn": "2023-10-05T17:04:52.000Z",
          "wordCount": null,
          "title": "6 AI Apocalypse Scenarios And Why They're Wrong",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170mz1d/how_to_use_custom_instructions_for_chatgpt_like_a/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170mz1d/how_to_use_custom_instructions_for_chatgpt_like_a/",
          "publishedOn": "2023-10-05T16:52:40.000Z",
          "wordCount": null,
          "title": "How to use custom instructions for ChatGPT like a Pro (Ultimate Guide for 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170m5js/deepmind_cofounder_is_tired_of_kneejerk_bad_takes/",
          "author": null,
          "description": "Mustafa Suleyman, the cofounder of DeepMind and CEO of Inflection AI, discusses his concerns about AI risks and the need for precaution.\n \nHe believes that while some extreme scenarios may be over the top, it's important to treat powerful technologies with caution.\n \nSuleyman highlights the middle layer of AI risks that people often underestimate, which involves the amplification of goals for both good and bad actors.\n \nHe emphasizes the need to contain AI to prevent potential negative consequences.\n \nSuleyman talks about the balance between risks and opportunities in technology and the importance of considering both aspects.\n \nHe mentions the hype around generative AI and the need to look beyond the surface to understand its true potential.\n \nSuleyman discusses the discussions with lawmakers about AI and the challenge of bridging the gap between policy makers and tech experts.\n \n Source : https://venturebeat.com/ai/deepmind-cofounder-is-tired-of-knee-jerk-bad-takes-about-ai/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170m5js/deepmind_cofounder_is_tired_of_kneejerk_bad_takes/",
          "publishedOn": "2023-10-05T16:20:51.000Z",
          "wordCount": null,
          "title": "DeepMind cofounder is tired of ‘knee-jerk bad takes’ about AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170m4rm/does_sam_altman_know_what_hes_creating/",
          "author": null,
          "description": "submitted by    /u/norcalnatv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170m4rm/does_sam_altman_know_what_hes_creating/",
          "publishedOn": "2023-10-05T16:20:02.000Z",
          "wordCount": null,
          "title": "Does Sam Altman Know What He’s Creating?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170m0hn/deepmind_univ_of_illinois_is_selfcorrection_a/",
          "author": null,
          "description": "Can LLMs actually improve their own reasoning by self-correcting mistakes? A new paper from DeepMind and the University of Illinois looks to answer this quantitatively.\n The results show that unaided, LLMs struggle at self-correction for reasoning tasks. The core issue is LLMs have trouble reliably evaluating the correctness of their own responses. They rarely identify flaws in initial reasoning. Sometimes LLMs even alter initially correct responses to become incorrect after self-correction! (I've personally seen this when interacting with ChatGPT many times and you probably have too).\n More complex techniques like critiquing between LLM instances don't help much either. External feedback or guidance looks necessary to improve reasoning (Well, some interesting parallels to this paper here about implicit improvement from preference data vs traditional RLHF).\n Self-correction does show promise for things like making responses more polite or safe though. Criteria there are more clear-cut.\n The authors argue we need to balance enthusiasm with realistic expectations on self-correction. It has a lot of limits for improving reasoning (at least with current models). But they suggest promising directions like incorporating high-quality external feedback from humans, training data, and tools. That could be key to unlocking self-correction's potential down the road.\n TLDR: Basically title... LLMs can't reliably self-correct reasoning yet. Maybe hybrid techniques combining self-correction with external guidance could work but we need more research.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170m0hn/deepmind_univ_of_illinois_is_selfcorrection_a/",
          "publishedOn": "2023-10-05T16:14:58.000Z",
          "wordCount": null,
          "title": "DeepMind, Univ. of Illinois: Is self-correction a viable method to improve LLM reasoning? Probably not.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170kkit/i_need_help_finding_a_tool/",
          "author": null,
          "description": "Buddy no of the tool where I can take an image have an AI translated and replace the text with the same style and have it in the new language like for example translating a Japanese image to English and have it look exactly the same just in English I'm looking for a free one that doesn't require credits it can be a desktop app or a website doesn't matter just needs to be free\n    submitted by    /u/agentduckman12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170kkit/i_need_help_finding_a_tool/",
          "publishedOn": "2023-10-05T15:16:00.000Z",
          "wordCount": null,
          "title": "I need help finding a tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170jn2k/how_much_do_i_have_to_edit_ai_generated_images_to/",
          "author": null,
          "description": "Hey there! I'm a 1-man card game designer and while juggling the project as well as mt senior year of college, I have been relying heavily on AI-generated artwork to speed up my workflow with some illustrations and other forms of world-building. \n In regards to the recent legal decisions (in the US), in which any work produced by AI cannot be copyrighted, how much do I need to change the illustrations to become my own, if I even can at all? Thanks!\n Edit for clarity: I am also an illustrator. So this question comes from the perspective of an artist trying to save time and energy for other projects\n    submitted by    /u/Luke192  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170jn2k/how_much_do_i_have_to_edit_ai_generated_images_to/",
          "publishedOn": "2023-10-05T14:37:50.000Z",
          "wordCount": null,
          "title": "How much do I have to edit AI generated images to become my own IP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170fhv3/comparative_evaluation_of_finetuned_and_standard/",
          "author": null,
          "description": "submitted by    /u/alcanthro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170fhv3/comparative_evaluation_of_finetuned_and_standard/",
          "publishedOn": "2023-10-05T11:27:04.000Z",
          "wordCount": null,
          "title": "Comparative Evaluation of Fine-Tuned and Standard Language Models in Emulating Living Historical Figures: A Detailed Study Proposal",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170c4a8/jpmorgan_ceo_jamie_dimon_ai_will_lead_to_35day/",
          "author": null,
          "description": "Jamie Dimon says the next generation of employees will work 3.5 days a week and live to 100 years old\n    submitted by    /u/AminoOxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170c4a8/jpmorgan_ceo_jamie_dimon_ai_will_lead_to_35day/",
          "publishedOn": "2023-10-05T07:56:45.000Z",
          "wordCount": null,
          "title": "JPMorgan CEO Jamie Dimon: AI will lead to 3.5-day workweek | Fortune",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170ar61/google_unveils_pixel_8_built_for_the_generative/",
          "author": null,
          "description": "submitted by    /u/pehnsus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170ar61/google_unveils_pixel_8_built_for_the_generative/",
          "publishedOn": "2023-10-05T06:30:10.000Z",
          "wordCount": null,
          "title": "Google unveils Pixel 8 built for 'the generative AI era' | CNN Business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zyg1y/llms_may_be_the_trojan_horse_that_modernizes/",
          "author": null,
          "description": "submitted by    /u/geekteam6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zyg1y/llms_may_be_the_trojan_horse_that_modernizes/",
          "publishedOn": "2023-10-04T20:58:34.000Z",
          "wordCount": null,
          "title": "LLMs May Be The Trojan Horse That Modernizes Software Development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zw77h/why_pepsico_is_powering_your_snacks_with_ai/",
          "author": null,
          "description": "Using AI to improve Cheetos? That's something PepsiCo has experimented with. On today’s POLITICO Tech, Athina Kanioura, chief strategy and transformation officer for PepsiCo, says that using AI to make employees faster and more efficient hasn’t led PepsiCo to replace human workers as many fear. And why the company has determined that in some jobs the technology is simply off limits. \n Listen to the interview here: https://politico-tech.simplecast.com/episodes/why-pepsico-is-powering-your-snacks-with-ai\n    submitted by    /u/smo279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zw77h/why_pepsico_is_powering_your_snacks_with_ai/",
          "publishedOn": "2023-10-04T19:27:48.000Z",
          "wordCount": null,
          "title": "Why PepsiCo is powering your snacks with AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zvs79/new_paper_enabling_language_models_to_implicitly/",
          "author": null,
          "description": "LLMs keep getting more capable at generating natural language. But there's always room for improving the quality and alignment of their responses.\n Typically this requires lots of human effort to collect more training data. So researchers are exploring ways for models to self-improve without human involvement.\n Many methods use prompting - giving the LLM instructions to critique and refine its responses. But coming up with comprehensive prompts is challenging.\n The new approach proposed, called PIT, lets models learn self-improvement implicitly from human preference data instead. It reformulates reinforcement learning to maximize the gap between an original response and improved response conditioned on the original.\n This taps into the implicit guidance in the preference data on what constitutes better quality, so no manual rubrics are needed. PIT uses curriculum reinforcement learning - first improving easy references, then switching to the LLM's own samples.\n Experiments on real and synthetic datasets show PIT significantly outperforms prompting methods like Self-Refine. It improved response quality 7-34% across conditions without any human involvement.\n This demonstrates a promising direction for LLMs to align better with human preferences autonomously as they learn from experience. No need for human bottlenecks when expanding to new domains or underserved use cases. Very cool!\n TLDR: New method PIT enables LLMs to implicitly learn to refine themselves from human preference data, no prompts needed. Big improvement over prompting approaches.\n Full Summary\n Arxiv is here: https://arxiv.org/abs/2310.00898\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zvs79/new_paper_enabling_language_models_to_implicitly/",
          "publishedOn": "2023-10-04T19:10:41.000Z",
          "wordCount": null,
          "title": "New Paper: Enabling Language Models to Implicitly Learn Self-Improvement From Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zsorv/5k_in_grants_or_250k_funding_for_ai_startups/",
          "author": null,
          "description": "AI Grant is offering $5k in grants or $250k in funding for AI startups. The program is backed by OG's AI Grant, an accelerator for AI startups.\n \nThe grant includes an uncapped SAFE investment of $250,000 for AI-native product startups, $350,000 in Azure credits, a summit in San Francisco with advisors and founders, and various other startup benefits and credits.\n \nThe program was created by Nat Friedman and Daniel Gross.\n \nApplications for Batch 3 will open in a few months, but early applications are accepted.\n \nThe program is open to anyone, and it is looking for companies or projects that leverage AI models in a useful or engaging way.\n \n Source : https://aigrant.com/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zsorv/5k_in_grants_or_250k_funding_for_ai_startups/",
          "publishedOn": "2023-10-04T17:06:04.000Z",
          "wordCount": null,
          "title": "$5k in grants or $250k funding for AI startups. Backed by OG's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zrd25/ai_will_teach_everyone_to_read_and_write_its/",
          "author": null,
          "description": "https://www.imagineworldwide.org/\n \"What is Child-Directed, Tech-Enabled Learning?\n Children drive their own learning, at their own pace, using software that provides a complete, research-based curriculum and pedagogy. Adults play a supportive, facilitative role. The software is delivered to the learner on a tablet, without connectivity, and charged by solar power or other appropriate energy sources...\n With hundreds of millions of children out of school or lacking access to effective schooling, this model can provide every child, everywhere access to learning. Solutions can work without internet access or grid power. Adults play facilitative, rather than instructional, roles.\n The annual unit cost of the learning solution is less than $7 per child and declining. This includes hardware, software, accessories, power, shipping, and implementation support from Imagine.\"\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zrd25/ai_will_teach_everyone_to_read_and_write_its/",
          "publishedOn": "2023-10-04T16:13:18.000Z",
          "wordCount": null,
          "title": "AI will teach everyone to read and write. It's already begun.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zncoq/ai_is_replacing_customer_service_jobs_across_the/",
          "author": null,
          "description": "Artificial intelligence (AI) is replacing customer service jobs around the world, with chatbots being used to interact directly with customers and solve problems independently.\n \nThis shift is expected to have a profound effect on economies, particularly in countries like India and the Philippines where call centers provide millions of jobs.\n \nWhile some argue that AI will provide support to remaining call center workers and improve job satisfaction, others warn that it could lead to job losses and a need for workforce adaptation.\n \nThe use of AI software tools in call centers has shown potential for improving productivity and customer satisfaction.\n \n Source : https://www.washingtonpost.com/technology/2023/10/03/ai-customer-service-jobs/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zncoq/ai_is_replacing_customer_service_jobs_across_the/",
          "publishedOn": "2023-10-04T13:32:15.000Z",
          "wordCount": null,
          "title": "AI is replacing customer service jobs across the globe",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zlxgr/femalefounded_ai_startups_win_just_2_of_funding/",
          "author": null,
          "description": "Female-founded AI startups in the UK account for just 2% of funding deals over the past decade, according to a report by the Alan Turing Institute.\n \nWhen female-founded companies do secure funding, they raise an average of £1.3m per deal, compared to £8.6m raised by all-male founder teams.\n \nThe report highlights the urgent need for gender balance in AI investment, as the industry is predicted to grow significantly in the coming years.\n \nRecommendations to improve gender balance include improving recruitment, monitoring investment practices, and diversifying the ecosystem.\n \nThere is an increasing demand for generative AI products, with leading tech companies investing heavily.\n \nGender diversity gaps and uneven progress rates for ethnic and racial groups are observed across investment firms.\n \nAI products have shown biases, such as passport checkers working less efficiently with darker skin and tools reinforcing gender stereotypes.\n \nIn 2019, a UN agency found that assigning female genders to digital assistants like Siri and Alexa perpetuated harmful gender biases.\n \n Source : https://www.theguardian.com/technology/2023/oct/04/female-founded-ai-startups-win-just-2-of-funding-deals-in-uk\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zlxgr/femalefounded_ai_startups_win_just_2_of_funding/",
          "publishedOn": "2023-10-04T12:28:56.000Z",
          "wordCount": null,
          "title": "Female-founded AI startups win just 2% of funding deals in UK",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zleds/i_used_riffusion_stable_diffusion_but_for_music/",
          "author": null,
          "description": "submitted by    /u/cI_-__-_Io  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zleds/i_used_riffusion_stable_diffusion_but_for_music/",
          "publishedOn": "2023-10-04T12:03:59.000Z",
          "wordCount": null,
          "title": "I used Riffusion (Stable Diffusion, but for music) to turn my own music into \"jazz\", \"Radiohead\", \"Muse\" or \"Nirvana\" songs, I'm amazed by the results",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zelwg/visa_announces_100_mn_fund_for_generative_ai/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zelwg/visa_announces_100_mn_fund_for_generative_ai/",
          "publishedOn": "2023-10-04T05:20:17.000Z",
          "wordCount": null,
          "title": "Visa Announces $100 Mn Fund for Generative AI Companies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z75hh/video_game_voice_actors_are_ready_to_strike_over/",
          "author": null,
          "description": "Video game voice actors are prepared to go on strike over the use of AI in game development.\n \nThe current contract negotiations between the Screen Actors Guild-American Federation of Television and Radio Artists (SAG-AFTRA) and video game companies have stalled, with the major issues being pay raises and the use of AI to alter or generate actors' performances.\n \nSAG-AFTRA wants protections for its members to ensure their work is not stolen or replaced by AI.\n \nIf negotiations don't progress, voice actors, stunt artists, and motion capture performers could potentially go on strike, leading to delays in game releases and recasting of beloved performers.\n \nThe voice actors' strike in 2016 resulted in improvements to pay, and now they are prepared to strike again to fight for their rights.\n \nVideo game performances are often seen as assets to be extracted and inserted into games, rather than recognizing the humanity and quality of life of the performers.\n \nThe use of AI in game development raises concerns about how companies will use advances in generative AI to steal work or put performers out of a job.\n \nSAG-AFTRA wants transparency, consent, and compensation when it comes to the use of AI in games.\n \nMembers of SAG-AFTRA have voted in favor of authorizing a strike, meaning voice actors, stunt artists, and motion capture performers could potentially join the picket line if negotiations don't progress.\n \nThe strike could lead to delays in upcoming game releases and the recasting of performers if companies refuse to meet the union's demands.\n \nThe fight for voice actors' rights is an existential one, as they want to retain the rights to their own voices and images and achieve wages that keep up with inflation\n \n Source : https://kotaku.com/sag-aftra-strike-voice-actor-spider-man-ai-union-1850874117\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z75hh/video_game_voice_actors_are_ready_to_strike_over/",
          "publishedOn": "2023-10-03T23:27:44.000Z",
          "wordCount": 2807,
          "title": "Video Game Voice Actors Are Ready to Strike over AI. Here’s Why",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z5yi9/question_any_3x_ai/",
          "author": null,
          "description": "Wanted to see if there are any 3X AI generated images available? I’m looking to see how I could use AI to generate images for my website.\n    submitted by    /u/IamMoe8868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z5yi9/question_any_3x_ai/",
          "publishedOn": "2023-10-03T22:40:20.000Z",
          "wordCount": 2542,
          "title": "[Question] Any 3X AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z5111/tiktok_ran_a_deepfake_ad_of_an_ai_mrbeast_hawking/",
          "author": null,
          "description": "TikTok ran an ad featuring a deepfake of MrBeast offering iPhone 15 Pros for $2.\n \nAI-generated deepfake content is becoming more pervasive on social media platforms.\n \nPlatforms like TikTok are facing challenges in moderating and handling the rise of AI deepfakes.\n \nMrBeast raised concerns about the ability of social media platforms to handle AI deepfakes.\n \nTikTok removed the ad and associated account for policy violations.\n \nUnauthorized AI-generated content featuring celebrities is a growing problem in platform advertising.\n \nThe issue is expected to worsen as AI technology improves and becomes more accessible.\n \nTransparency and disclosure are crucial in AI-generated ad content featuring celebrities.\n \nTikTok is aware of the pervasiveness of AI-generated content on its platform and is taking steps to address it.\n \n Source : https://www.businessinsider.com/tiktok-ran-deepfake-ad-mrbeast-as-ai-generated-content-spreads-2023-10\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z5111/tiktok_ran_a_deepfake_ad_of_an_ai_mrbeast_hawking/",
          "publishedOn": "2023-10-03T22:04:24.000Z",
          "wordCount": 2647,
          "title": "TikTok ran a deepfake ad of an AI MrBeast hawking iPhones for $2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z37sg/infinitia_will_apparently_let_you_create_your_own/",
          "author": null,
          "description": "Came across this upcoming game which supposedly let's you create your own worlds and characters to live in the world...they also released a research paper explaining how they're doing it, using LLMs in all sorts of ways, primarily for reasoning and language.\n I think it could be a pretty fun take on passive games, just populating a world with your characters, checking up on them occasionally, putting them in weird situations lol.\n infinitia.ai for those who wanna check it out\n The NPCs do seems to be acting in an interesting way, as i saw in this video they posted on twitter...\n https://twitter.com/infinitia_app/status/1707102187518628245\n ​\n Watchall think? Another smallville clone? or something interesting....\n    submitted by    /u/SeaJeweler3723  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z37sg/infinitia_will_apparently_let_you_create_your_own/",
          "publishedOn": "2023-10-03T20:55:50.000Z",
          "wordCount": 2634,
          "title": "Infinitia will apparently let you create your own AI enabled social simulations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z145t/efficient_ai_design_of_robots/",
          "author": null,
          "description": "submitted by    /u/DrJosh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z145t/efficient_ai_design_of_robots/",
          "publishedOn": "2023-10-03T19:32:17.000Z",
          "wordCount": 2515,
          "title": "Efficient AI design of robots.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z0eua/from_stone_to_silicon_the_odyssey_of_humanity_and/",
          "author": null,
          "description": "submitted by    /u/Einsof__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z0eua/from_stone_to_silicon_the_odyssey_of_humanity_and/",
          "publishedOn": "2023-10-03T19:03:47.000Z",
          "wordCount": 2518,
          "title": "From Stone to Silicon: The Odyssey of Humanity and Technology",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yxpa0/dont_worry_ai_cannot_takeover_the_world_it_will/",
          "author": null,
          "description": "The article discusses the importance of batteries in AI technology and how they limit the capabilities of AI robots.\n \nIt explores the challenges of current battery technology and the need for better solutions.\n \nThe article emphasizes the significance of developing ideal batteries that can provide long-lasting power without degradation.\n \n Source : https://notes.arkinfo.xyz/p/dont-worry-ai-cannot-takeover-the\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16yxpa0/dont_worry_ai_cannot_takeover_the_world_it_will/",
          "publishedOn": "2023-10-03T17:16:43.000Z",
          "wordCount": 2575,
          "title": "Don't Worry, AI Cannot Takeover the World, It Will Run Out of Battery",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yxeya/gpt4_outperforms_its_rivals_in_new_ai_benchmark/",
          "author": null,
          "description": "ByteDance and the University of Illinois researchers have developed an improved benchmark suite with consistent parameters, called GPT-Fathom, that indicates GPT-4, the engine behind the paid version of ChatGPT, significantly outperforms leading LLMs, including its biggest competitor, Claude 2.\n For the latest advancements in AI, look here first.\n ​\n https://preview.redd.it/v4fo8zser0sb1.png?width=1292&format=png&auto=webp&s=7e29fe9ac1af3efcb936ee61e9202717eed7e702\n GPT-Fathom's breakthrough\n  \nThe new benchmark suite, GPT-Fathom, addresses consistent settings issues and prompt sensitivity, attempting to reduce inconsistencies in LLM evaluation.\n In a comparison using GPT-Fathom, GPT-4 outperformed over ten leading LLMs, crushing the competition in most benchmarks, and showing significant performance leaps from GPT-3 to its successors.\n  \nPerformance specifics\n  \nThe gap in performance was especially pronounced against Claude 2, ChatGPT's biggest rival.\n GPT-4's Advanced Data Analysis model exhibited superior performance in coding, giving it an edge as compared to LuckLlama 2, the current best-performing open-source model.\n Llama 2-70B showed comparable or better performance than gpt-3.5-turbo-0613 in safety and comprehension but displayed worse performance in \"Mathematics\", \"Coding\", and \"Multilingualism\".\n  \nThe seesaw effect\n  \nThe research team noted a 'seesaw effect' where an improvement in one area can lead to degradation in another.\n For instance, GPT-4 saw a performance drop on the Mathematical Geometry Simple Math (MGSM) benchmark, despite improving its performance significantly on the text comprehension benchmark DROP.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and developments in AI. Professionals from Meta, Google, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16yxeya/gpt4_outperforms_its_rivals_in_new_ai_benchmark/",
          "publishedOn": "2023-10-03T17:05:14.000Z",
          "wordCount": 2753,
          "title": "GPT-4 outperforms its rivals in new AI benchmark suite GPT-Fathom",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ywn84/runway_has_launched_gen_2_director_mode_the_speed/",
          "author": null,
          "description": "submitted by    /u/First_Development101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ywn84/runway_has_launched_gen_2_director_mode_the_speed/",
          "publishedOn": "2023-10-03T16:34:34.000Z",
          "wordCount": 2525,
          "title": "Runway has launched Gen 2 Director mode. The speed at which this company works is Insane",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yuoqc/how_ai_could_upend_foreign_policy_an_interview/",
          "author": null,
          "description": "submitted by    /u/finger_puppet_self  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16yuoqc/how_ai_could_upend_foreign_policy_an_interview/",
          "publishedOn": "2023-10-03T15:19:16.000Z",
          "wordCount": 2530,
          "title": "How Ai Could Upend Foreign Policy - An Interview with Ian Bremner and Mustafa Suleyman",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yt92h/cgpt4_on_some_ways_promptresponse_posts_advance_ai/",
          "author": null,
          "description": "Prompt:\n Explain why posting prompts and your responses speeds up AI development in the following ways:\n It allows us to analyze responses to prompts that we would probably never have thought of.\n It allows us to share ideas that the open source community would advance.\n It allows us to better democratize the process of alignment, bringing in as many people as possible.\n CGPT-4:\n Posting prompts and AI responses serves multiple functions that are beneficial to the progress of AI development. First off, it exposes AI to a myriad of queries that developers might not have otherwise considered. This wide range of prompts allows the machine to improve its natural language processing abilities, making it more versatile and effective in interpreting and responding to human language. The more dive…",
          "link": "https://www.reddit.com/r/artificial/comments/16yt92h/cgpt4_on_some_ways_promptresponse_posts_advance_ai/",
          "publishedOn": "2023-10-03T14:22:07.000Z",
          "wordCount": 2820,
          "title": "CGPT-4 on some ways \"prompt/response\" posts advance AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yst8j/ai_makes_a_video_game_on_the_app_store/",
          "author": null,
          "description": "submitted by    /u/usmansid98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16yst8j/ai_makes_a_video_game_on_the_app_store/",
          "publishedOn": "2023-10-03T14:04:25.000Z",
          "wordCount": 2518,
          "title": "A.I Makes a Video game on the App Store",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yr8us/infinite_context_windows_streaming_llms_can_be/",
          "author": null,
          "description": "LLMs like GPT-3 struggle in streaming uses like chatbots because their performance tanks on long texts exceeding their training length. I checked out a new paper investigating why windowed attention fails for this.\n By visualizing the attention maps, the researchers noticed LLMs heavily attend initial tokens as \"attention sinks\" even if meaningless. This anchors the distribution.\n They realized evicting these sink tokens causes the attention scores to get warped, destabilizing predictions.\n Their proposed \"StreamingLLM\" method simply caches a few initial sink tokens plus recent ones. This tweaks LLMs to handle crazy long texts. Models tuned with StreamingLLM smoothly processed sequences with millions of tokens, and were up to 22x faster than other approaches. \n Even cooler - adding a special \"[Sink Token]\" during pre-training further improved streaming ability. The model just used that single token as the anchor. I think the abstract says it best:\n  \nWe introduce StreamingLLM, an efficient framework that enables LLMs trained with a finite length attention window to generalize to infinite sequence length without any fine-tuning. We show that StreamingLLM can enable Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language modeling with up to 4 million tokens and more.\n  \nTLDR: LLMs break on long convos. Researchers found they cling to initial tokens as attention sinks. Caching those tokens lets LLMs chat infinitely.\n Full summary here\n Paper link: https://arxiv.org/pdf/2309.17453.pdf\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16yr8us/infinite_context_windows_streaming_llms_can_be/",
          "publishedOn": "2023-10-03T12:58:07.000Z",
          "wordCount": 2749,
          "title": "Infinite context windows? Streaming LLMs can be extended to infinite sequence lengths without any fine-tuning.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ymzc2/where_do_i_produce_free_intro_and_outro_ai_music/",
          "author": null,
          "description": "I am starting a podcast on Psychology and Philosophy\n    submitted by    /u/21bce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ymzc2/where_do_i_produce_free_intro_and_outro_ai_music/",
          "publishedOn": "2023-10-03T09:16:14.000Z",
          "wordCount": 2534,
          "title": "Where do I produce free intro and outro AI music for my Podcast for free.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ymtut/backerkit_will_restrict_the_use_of_ai_art/",
          "author": null,
          "description": "Crowdfunding site BackerKit has announced a new policy that restricts the use of solely AI-generated content on its platform.\n \nThe policy aims to address concerns regarding ownership of content, ethical sourcing of data, and compensation for the process of creating content.\n \nProjects that lack a minimum requirement of human input will not be allowed to crowdfund on the BackerKit site.\n \nThere is some flexibility with AI generative fill and the use of AI transcription services, but a high level of human input is required to satisfy the policy.\n \nBackerKit will automatically exclude all content uploaded by creators for their projects from AI training in support of this policy.\n \nThe new restrictions will go into effect on October 4, giving creators time to alter their projects if they are using AI-generated images and text.\n \n Source : https://gizmodo.com/backerkit-ai-art-new-policy-crowdfunding-generative-1850891882\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ymtut/backerkit_will_restrict_the_use_of_ai_art/",
          "publishedOn": "2023-10-03T09:06:04.000Z",
          "wordCount": 2654,
          "title": "BackerKit Will Restrict the Use of AI Art",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ykv1o/oneminute_daily_ai_news_1022023/",
          "author": null,
          "description": "iPhone designer Jony Ive is reportedly talking to OpenAI CEO Sam Altman about making an AI hardware device.[1]\n Visa announced today that it plans to invest $100 million in companies developing generative AI technologies and applications “that will impact the future of commerce and payments.”[2]\n More than 40% of labor force to be affected by AI in 3 years, Morgan Stanley forecasts. [3]\n Tom Hanks: Don't fall for \"AI version of me\" promoting dental plan.[4]\n  \nSources:\n [1] https://www.businessinsider.com/chatgpt-head-iphone-designer-jony-ive-ai-device-openai-report-2023-9?amp\n [2] https://techcrunch.com/2023/10/02/visa-earmarks-100m-to-invest-in-generative-ai-companies/\n [3] https://www.cnbc.com/2023/10/02/more-than-40percent-of-labor-force-to-be-impacted-by-ai-in-three-years-morgan-stanley-forecasts.html\n [4] https://www.cbsnews.com/amp/news/tom-hanks-ai-version-of-me-promoting-dental-plan/\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ykv1o/oneminute_daily_ai_news_1022023/",
          "publishedOn": "2023-10-03T06:56:28.000Z",
          "wordCount": 2599,
          "title": "One-Minute Daily AI News 10/2/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16y7aed/save_20_hours_a_week_with_this_1_simple_chatgpt/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16y7aed/save_20_hours_a_week_with_this_1_simple_chatgpt/",
          "publishedOn": "2023-10-02T20:23:37.000Z",
          "wordCount": 2534,
          "title": "Save 20 Hours A Week With This 1 Simple ChatGPT Prompt for Productivity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16y4l3t/ai_anxiety_is_on_the_riseheres_how_to_manage_it/",
          "author": null,
          "description": "Artificial intelligence (AI) anxiety is on the rise, but there are ways to manage it.\n \nWhile AI may outperform humans in certain tasks, humans are not yet headed for all-out replacement.\n \nRecent research shows that AI programs scored higher than humans in tasks requiring originality, but the highest-rated human ideas were still considered more creative.\n \nThe rise of generative AI tools in industries like animation has left some professionals anxious about the future of their work.\n \nExperts suggest managing AI fears by understanding the historical context of technological advancements and focusing on the benefits and training opportunities that AI brings.\n \n Source : https://www.scientificamerican.com/article/ai-anxiety-is-on-the-rise-heres-how-to-manage-it/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16y4l3t/ai_anxiety_is_on_the_riseheres_how_to_manage_it/",
          "publishedOn": "2023-10-02T18:40:30.000Z",
          "wordCount": 2623,
          "title": "AI Anxiety’ Is on the Rise–Here’s How to Manage It",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16y17ca/toolintegrated_reasoning_a_new_approach_for/",
          "author": null,
          "description": "When trying to get language models to solve complex math problems, researchers kept running into limits. Models like GPT-3 and ChatGPT still struggle with advanced algebra, calculus, and geometry questions. The math is just too abstract and symbol-heavy for them.\n To break through this barrier, researchers from Tsinghua University and Microsoft taught models to combine natural language reasoning with calling external math tools.\n The key is their new \"tool-integrated reasoning\" format. Models generate a natural language plan first, then write code to invoke tools like SymPy to solve equations. They take the output results and continue verbal reasoning.\n By interleaving natural language and symbolic computations, they get the best of both worlds - semantic understanding from language models and rigorous math from tools.\n They trained versions of the LLaMA model this way, producing their Tool-Integrated Reasoning Agent (TORA). They present some strong results:\n  \nIn evaluations on 10 math datasets, TORA substantially outperformed prior state-of-the-art methods, achieving 13-19% higher accuracy on average.\n On one competition test, TORA-7B scored 40% accuracy, beating the previous best model by 22 percentage points.\n  \nThis demonstrates that integrating tools directly into the reasoning process can significantly enhance mathematical capabilities, even for large models like GPT-4.\n However, tough problems involving geometry and advanced algebra are still there. New techniques for symbolic reasoning and spatial understanding will likely be needed to push further.\n Overall though, tool integration seems a promising path to improve reasoning skills. Applying this to other domains like logic and programming could also be impactful.\n TLDR: Teaching language models to use math tools helps them solve way more complex problems.\n Full Paper Summary\n arXiv Link\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16y17ca/toolintegrated_reasoning_a_new_approach_for/",
          "publishedOn": "2023-10-02T16:28:57.000Z",
          "wordCount": 2788,
          "title": "Tool-Integrated Reasoning: A New Approach for Math-Savvy LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xzlv9/bard_what_would_it_take_to_fasttrack_ai_morality/",
          "author": null,
          "description": "To fast-track AI morality to surpass human ability by 2025, Google, OpenAI, Anthropic, and other developers could:\n Invest heavily in AI ethics research and development.** For example, Google AI has launched the Responsible AI Research and Development (RAIR) program, which is focused on developing new AI ethics research and tools.\n Create large-scale datasets of human moral reasoning.** For example, OpenAI has released the Moral Machine dataset, which contains over 1 million crowdsourced responses to moral dilemmas.\n Develop new AI architectures that are specifically designed for moral reasoning.** For example, Anthropic is developing a new AI architecture called \"Moral Machine Learning,\" which is designed to learn from human moral reasoning data.\n Establish a global AI ethics research consortium and create a public database of human moral reasoning datasets.** For example, the Partnership on AI has launched the Safeguarding AI initiative, which is working to develop new safety mechanisms for AI systems.\n Fund research into developing new AI architectures for moral reasoning and develop new AI evaluation metrics for moral performance.** For example, the Moral Machine project is developing new evaluation metrics for AI systems' moral performance.\n By working together, Google, OpenAI, Anthropic, and other developers can help to fast-track AI morality and create AI systems that are more moral than humans.\n (199 words)\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xzlv9/bard_what_would_it_take_to_fasttrack_ai_morality/",
          "publishedOn": "2023-10-02T15:27:17.000Z",
          "wordCount": 2739,
          "title": "Bard, what would it take to fast-track AI morality so that it surpasses human ability by 2025?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xujq2/ai_us_navigating_the_digital_renaissance/",
          "author": null,
          "description": "submitted by    /u/Einsof__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xujq2/ai_us_navigating_the_digital_renaissance/",
          "publishedOn": "2023-10-02T11:48:19.000Z",
          "wordCount": 2515,
          "title": "AI & Us Navigating the Digital Renaissance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xueuy/prompt_enginnering_questions/",
          "author": null,
          "description": "Is propt engineering a legit job ?? Is it here to stay ? Is it worth studying ? Best way to study it , land a job or freelancing ?\n    submitted by    /u/metasubcon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xueuy/prompt_enginnering_questions/",
          "publishedOn": "2023-10-02T11:41:47.000Z",
          "wordCount": 2543,
          "title": "Prompt enginnering questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xu70h/what_appprogram_are_they_using_on_this_instagram/",
          "author": null,
          "description": "How does one make videos like on this Instagram page? It's unreal. \n https://instagram.com/nostalgicraindrops?igshid=MzRlODBiNWFlZA==\n    submitted by    /u/CK1886  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xu70h/what_appprogram_are_they_using_on_this_instagram/",
          "publishedOn": "2023-10-02T11:31:10.000Z",
          "wordCount": 2531,
          "title": "What app/program are they using on this Instagram?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xsk42/chatgpt_can_now_see_mindblowing_ways_people_can/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xsk42/chatgpt_can_now_see_mindblowing_ways_people_can/",
          "publishedOn": "2023-10-02T09:59:18.000Z",
          "wordCount": 2532,
          "title": "ChatGPT Can Now See? Mind-Blowing Ways People Can Use Image Recognition!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xrblo/lets_make_a_list_of_the_best_ai_tools_for_students/",
          "author": null,
          "description": "Every day, new AI tools appear. There are also AI tools designed to make students' lives easier—from AI essay generators to study organizers. While there are many directories with AI tools, they are often not well-sorted for students. So, I've compiled a list of my favorite AI tools for educational purposes.\n  \n AI tool How to use for studies \n  \n Bing Chat - Writing excel formulas - Making graphs and charts - Answers for homework assignments - Researching for a paper \n  Textero.ai - Search for relevant academic sources for essays - Research assistance with the \"Ask AI\" feature - Essay generation and paper formatting - Structured essay outline creation - Summarizing of texts \n  ChatPDF - Interacting with academic PDFs - Asking specific questions about the content - Quickly locating essential data for assignments \n  Socratic - Breaking down complex homework questions - Providing step-by-step educational guidance - Safe and interactive learning \n  Writely AI - Improving grammar and writing clarity - Creating concise study notes - Feedback for content quality \n  Turnitin - Checking for copied content - Comparing against a vast academic database - Highlighting potential plagiarism \n \n Got any to add to the list? Let's share and help each other!\n    submitted by    /u/loyallyUrticate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xrblo/lets_make_a_list_of_the_best_ai_tools_for_students/",
          "publishedOn": "2023-10-02T08:39:41.000Z",
          "wordCount": 2717,
          "title": "Let’s make a list of the BEST AI TOOLS for students",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xpc60/tested_dalle_created_a_monster/",
          "author": null,
          "description": "submitted by    /u/Grindmaster_Flash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xpc60/tested_dalle_created_a_monster/",
          "publishedOn": "2023-10-02T06:35:19.000Z",
          "wordCount": 2513,
          "title": "Tested Dalle, created a monster.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xmn6x/metas_llama_2_long_outperforms_gpt_35_and_claude_2/",
          "author": null,
          "description": "Meta Platforms recently introduced Llama 2 Long, a revolutionary AI model that outperforms top competitors with its ability to generate accurate responses to long user queries.\n For the latest advancements in AI, look here first.\n https://preview.redd.it/geqqd3k5rprb1.png?width=1920&format=png&auto=webp&s=e72a67fc7ef7e85902169f3061529c136beadc87\n Meta's new AI model\n  \nAs an enhancement of the original Llama 2, Llama 2 Long deals with larger data containing longer texts and is modified to handle lengthier information sequences.\n Its stellar performance outshines other models such as OpenAI's GPT-3.5 Turbo and Claude 2.\n  \nHow Llama 2 Long works\n  \nMeta built different versions of Llama 2, ranging from 7 billion to 70 billion parameters, which refines its learning from data.\n Llama 2 Long employs Rotary Positional Embedding (RoPE) technique, refining the way it encodes the position of each token, allowing fewer data and memory to produce precise responses.\n The model further fine-tunes its performance using reinforcement learning from human feedback (RLHF), and synthetic data generated by Llama 2 chat itself.\n  \nImpressive feats and future aspirations\n  \nLlama 2 Long can create high-quality responses to user prompts up to 200,000 characters long, which is approximately 40 pages of text.\n Its ability to generate responses to queries on diverse topics such as history, science, literature, and sports indicates its potential to cater to complex and various user needs.\n The researchers see Llama 2 Long as a step towards broader, more adaptable AI models, and advocate for more research and dialogue to harness these models responsibly and beneficially.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and developments in AI. Professionals from Meta, Google, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xmn6x/metas_llama_2_long_outperforms_gpt_35_and_claude_2/",
          "publishedOn": "2023-10-02T04:03:59.000Z",
          "wordCount": 2793,
          "title": "Meta's Llama 2 Long outperforms GPT 3.5 and Claude 2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xi4xg/ai_image_generator_that_is_good_at_referencing/",
          "author": null,
          "description": "I've recently tried Canva and Dall-E to generate an image that references two popular games, Dark Souls 3 and Baldur's Gate 3. And they both fall on their face. Maybe my prompt is bad but Canva is not getting me what I want. Dall-E ran out of free credits.\n Do you guys have any recommendations. Midjourney is no longer free now. I would like this to be free and has good references to popular culture.\n    submitted by    /u/livingroomsessions  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xi4xg/ai_image_generator_that_is_good_at_referencing/",
          "publishedOn": "2023-10-02T00:34:32.000Z",
          "wordCount": 2657,
          "title": "AI Image Generator That Is Good At Referencing Pop Culture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xgclx/cgpt4_how_would_an_ai_select_the_100_most/",
          "author": null,
          "description": "If an AI were to take on this task, it would primarily rely on data mining and natural language processing (NLP) techniques. First, the AI would scrape digital platforms to collect works authored by various people. Platforms could range from academic databases like PubMed or ArXiv to blogs, forums, and social media. The goal would be to capture a wide array of intellectual output, irrespective of the person's titles or accolades.\n Next, an NLP model would evaluate the collected content based on factors like originality, complexity, and coherence. Advanced sentiment analysis could be employed to gauge the depth of understanding and nuances in the arguments made. Specialized algorithms could also be developed to assess the impact of each piece of work, using metrics such as citations, social shares, or subsequent works that build upon it.\n The AI would then create a shortlist based on these evaluations. This stage might also involve unsupervised machine learning techniques like clustering to find patterns or commonalities among the top contenders.\n The final stage would be validation, possibly using reinforcement learning. The AI could simulate various scenarios or problems and predict how the content created by these individuals would contribute to solving them. It would then refine its list based on the simulated outcomes.\n This all-AI approach would drastically reduce human bias and could be executed relatively quickly. However, it's important to note that any such system would need to be designed carefully to avoid introducing biases present in the training data or algorithms.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xgclx/cgpt4_how_would_an_ai_select_the_100_most/",
          "publishedOn": "2023-10-01T23:18:44.000Z",
          "wordCount": 2847,
          "title": "CGPT-4, how would an AI select the 100 most intelligent people on the planet based on their content rather than on their positions and awards?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xbcd1/so_its_unethical_to_kill_an_ai_robot/",
          "author": null,
          "description": "submitted by    /u/bharath_brt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xbcd1/so_its_unethical_to_kill_an_ai_robot/",
          "publishedOn": "2023-10-01T20:08:08.000Z",
          "wordCount": 2588,
          "title": "So it's unethical to kill an AI robot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xa1bt/how_big_tech_is_coopting_the_rising_stars_of/",
          "author": null,
          "description": "Big Tech's dominance in the artificial intelligence (AI) industry is growing as start-ups like Anthropic rely on their computing power and resources.\n \nDespite creating breakthrough AI technology, these start-ups still need the support of Big Tech to scale and succeed.\n \nThe training of AI systems is expensive and requires specialized computer chips and data centers, which are mostly controlled by Amazon, Google, and Microsoft.\n \nRegulators, including the Federal Trade Commission and French competition authorities, are monitoring the industry for signs of anticompetitive behavior.\n \nSome business leaders believe that competition and efficiency will eventually drive down the cost of running AI models.\n \n Source : https://www.washingtonpost.com/technology/2023/09/30/anthropic-amazon-artificial-intelligence/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xa1bt/how_big_tech_is_coopting_the_rising_stars_of/",
          "publishedOn": "2023-10-01T19:17:47.000Z",
          "wordCount": 2686,
          "title": "How Big Tech is co-opting the rising stars of artificial intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16x9z9y/data_strategy_generative_ai_strategy/",
          "author": null,
          "description": "A strong data strategy is crucial for the success of any AI strategy.\n \nGenerative AI use cases depend on a healthy data infrastructure, including data governance, observability, catalog, data sharing, and lineage.\n \nMany enterprises lack the necessary data infrastructure to deploy customer-facing AI apps confidently.\n \nPoor data strategy and infrastructure can derail generative AI efforts.\n \nExisting issues with data ecosystems, such as data silos and poor data governance, will have a greater impact on generative AI workloads than new issues.\n \nData silos, poor data discoverability, and the lack of data interoperability can become serious bottlenecks for generative AI apps.\n \n Source : https://nextword.substack.com/p/data-strategy-matters-for-generative\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16x9z9y/data_strategy_generative_ai_strategy/",
          "publishedOn": "2023-10-01T19:15:42.000Z",
          "wordCount": 2679,
          "title": "Data strategy >> Generative AI strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16x8aao/does_anyone_know_a_good_ai_tool_to_generate/",
          "author": null,
          "description": "Same as title\n    submitted by    /u/No-Educator-59  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16x8aao/does_anyone_know_a_good_ai_tool_to_generate/",
          "publishedOn": "2023-10-01T18:12:25.000Z",
          "wordCount": 2589,
          "title": "Does anyone know a good AI tool to generate tattoo ideas and song cover art?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16x2lyk/meta_inria_researchers_discover_that_explicit/",
          "author": null,
          "description": "When visualizing the inner workings of vision transformers (ViTs), researchers noticed weird spikes of attention on random background patches. This didn't make sense since the models should focus on foreground objects.\n By analyzing the output embeddings, they found a small number of tokens (2%) had super high vector norms, causing the spikes.\n The high-norm \"outlier\" tokens occurred in redundant areas and held less local info but more global info about the image.\n Their hypothesis is that ViTs learn to identify unimportant patches and recycle them as temporary storage instead of discarding. This enables efficient processing but causes issues.\n Their fix is simple - just add dedicated \"register\" tokens that provide storage space, avoiding the recycling side effects.\n Models trained with registers have:\n  \nSmoother and more meaningful attention maps\n Small boosts in downstream performance\n Way better object discovery abilities\n  \nThe registers give ViTs a place to do their temporary computations without messing stuff up. Just a tiny architecture tweak improves interpretability and performance. Sweet!\n I think it's cool how they reverse-engineered this model artifact and fixed it with such a small change. More work like this will keep incrementally improving ViTs.\n TLDR: Vision transformers recycle useless patches to store data, causing problems. Adding dedicated register tokens for storage fixes it nicely.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16x2lyk/meta_inria_researchers_discover_that_explicit/",
          "publishedOn": "2023-10-01T14:25:57.000Z",
          "wordCount": 2797,
          "title": "Meta, INRIA researchers discover that explicit registers eliminate ViT attention spikes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16wz9wf/theres_so_many_ai_chatbots_but_which_one_is_the/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16wz9wf/theres_so_many_ai_chatbots_but_which_one_is_the/",
          "publishedOn": "2023-10-01T11:59:10.000Z",
          "wordCount": 2597,
          "title": "There's So Many AI Chatbots, But Which One Is The Best? (Complete Guide for 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16wxjtj/oneminute_daily_ai_news_1012023/",
          "author": null,
          "description": "Microsoft Researchers Introduce AutoGen: An Artificial Intelligence Framework for Simplifying the Orchestration, Optimization, and Automation of LLM Workflows.[1]\n StoriaBoard helps filmmakers, marketers and other storytellers pre-visualize stories. Simply upload your script, select a visual style, and generate hundreds of frames in seconds.[2]\n Will Hurd Releases A.I. Plan, a First in the Republican Presidential Field.[3]\n Sam Altman says AI systems will automate some tasks but also lead to ‘new and much better jobs’.[4]\n  \nSources:\n [1] https://www.marktechpost.com/2023/09/30/microsoft-researchers-introduce-autogen-an-artificial-intelligence-framework-for-simplifying-the-orchestration-optimization-and-automation-of-llm-workflows/?amp\n [2] https://www.producthunt.com/posts/storiaboard\n [3] https://www.nytimes.com/2023/09/20/us/politics/will-hurd-ai-plan.html\n [4] https://www.businessinsider.com/openai-sam-altman-ai-will-automate-tasks-create-better-jobs-2023-9?amp\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16wxjtj/oneminute_daily_ai_news_1012023/",
          "publishedOn": "2023-10-01T10:23:01.000Z",
          "wordCount": 2657,
          "title": "One-Minute Daily AI News 10/1/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16wu5l1/this_is_no_time_for_ease_and_comfort_it_is_time/",
          "author": null,
          "description": "submitted by    /u/ApprehensiveChair460  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16wu5l1/this_is_no_time_for_ease_and_comfort_it_is_time/",
          "publishedOn": "2023-10-01T06:56:02.000Z",
          "wordCount": 2587,
          "title": "This is no time for ease and comfort. It is time to dare and endure. -Winston Churchill",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16wtcjt/quizlet_ai_reliability/",
          "author": null,
          "description": "What is everyone’s thoughts on the reliablity of the quizlet AI? I just talked to a friend and she said that she uses the AI to study with quizlet.\n    submitted by    /u/immickle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16wtcjt/quizlet_ai_reliability/",
          "publishedOn": "2023-10-01T06:08:13.000Z",
          "wordCount": 2616,
          "title": "Quizlet AI reliability?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16whl8n/i_have_blocked_user_unuseai/",
          "author": null,
          "description": "Hi,\n I have never done this before, but I have blocked user u/NuseAI from my feeds\n He/she is posting 'news' all over the AI subs, including this one, at the moment and is filling up my timeline ... and I simply don't feel right about what they are up to.\n  \nIs it an AI bot?\n Is it a karma farmer?\n Is it some sort of spam?\n  \nAm I being over cautious?\n If the consensus is that they are a normal poster - fine - I'll reenable their posts.\n In the meantime I'm enjoying a less cluttered feed!\n ​\n    submitted by    /u/MrEloi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16whl8n/i_have_blocked_user_unuseai/",
          "publishedOn": "2023-09-30T20:54:15.000Z",
          "wordCount": 2674,
          "title": "I have blocked user u/NuseAI ...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16wgjep/counterfeit_people_the_danger_posed_by_metas_ai/",
          "author": null,
          "description": "Meta has launched chatbots with personalities similar to certain celebrities, which some experts believe could be dangerous.\n \nThese chatbots have their own faces and social media accounts, and Meta is working on giving them a voice.\n \nHowever, experts argue that the idea of chatbots with personalities is impossible, as algorithms cannot demonstrate intention or free will.\n \nThere is also a risk that chatbots with personalities could express problematic opinions, as seen in Meta's testing.\n \nMeta's project is driven by profit, as users are more likely to engage with chatbots that seem human.\n \nExperts believe that Meta should have explained the limits of these chatbots instead of emphasizing their human characteristics.\n \n Source : https://www.france24.com/en/technology/20230930-counterfeit-people-the-dangers-posed-by-meta-s-ai-celebrity-lookalike-chatbots\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16wgjep/counterfeit_people_the_danger_posed_by_metas_ai/",
          "publishedOn": "2023-09-30T20:10:51.000Z",
          "wordCount": 2695,
          "title": "Counterfeit people': The danger posed by Meta’s AI celebrity lookalike chatbots",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16waw44/artificially_intelligent_genuinely_creative_how/",
          "author": null,
          "description": "submitted by    /u/DukeWilder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16waw44/artificially_intelligent_genuinely_creative_how/",
          "publishedOn": "2023-09-30T16:15:11.000Z",
          "wordCount": 2598,
          "title": "Artificially Intelligent, Genuinely Creative: How AI's Triumph Over Human Creators Exposes the Illusion of Intellectual Property",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w6whh/is_my_domain_name_a_good_idea_what_can_i_build_on/",
          "author": null,
          "description": "I was cooking chicken wings one evening ago in the not too distant past and this idea popped into my head. Before the night was over I went online and bought the domain name of GoGoAIGo . com and then the .ai version also. I put the dot com version up on Sedo (sedo.com/search/details/?domain=GoGoAIGo.com) for sale and I actually now own the .com .ai .org and .net versions of that phrase. Not only my decade but the two generational decades in front of me and the one generational decade behind me can remember our ole Inspector Gadget friend whom had a similar phrase, but not exact, that he would say.\n I'm an individual whom may hold onto something if I feel it has intrinsic value for a future development, which I think this can if laid out in an appropriate fashion. I'm working on another business project right now and I own some trademarks for my other business project so I'm not exactly a newbie in ways here I'm just kind of fresh to the AI realm studies. I think it's overblown right now but will be fine tuned over the next 5-7 years better and society will find a better seat for it.\n I could see this domain being like a search engine or something, maybe even something to do with robots. I expect AI robots moving forward will be regulated and have various classes that they are placed into as we integrate certain ones in our society. Let's be honest, the light-switch isn't flipping overnight or even in one quick year over this AI stuff. I'm in no rush to have a piece of AI wash my dishes for me to be honest. The last robotic thing I was thinking about getting was a robot mower to cut a field, I believe they are working on those now.\n Anybody have any unique ideas for me? I used to play with lego robots way back in high school in the early 2000's.... Seems like this website would make a great search engine but honestly there are other phrases that can be put into play with society also.\n Thanks for any mental stimulation you can toss in my direction.\n    submitted by    /u/Wise_Cut_2543  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w6whh/is_my_domain_name_a_good_idea_what_can_i_build_on/",
          "publishedOn": "2023-09-30T13:30:21.000Z",
          "wordCount": 2962,
          "title": "Is my domain name a good idea? What can I build on it? Go Go AI Go dot com .... No webpage on it now, any good ideas???",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w4fkl/cgpt4_how_could_an_ai_app_designed_to_move_people/",
          "author": null,
          "description": "Imagine an app that's like a helpful buddy in your pocket, always looking out for the best moments to nudge you into some real-world socializing. For example, say you're a fan of watching sports. The app notices you frequently check scores or read articles on sports sites during weekends. Right before a big game, it pops up and says, \"How about inviting some friends over to watch the game?\"\n Now let's talk about making socializing a sort of game. Think of the way Fitbit rewards you for walking 10,000 steps. Similarly, this app could reward you with \"social points\" for various activities. Invite a friend for coffee? 10 points. Call your mom? 15 points. Organize a barbecue? 50 points. And so on. These points could unlock virtual badges or even real-world rewards like discounts at local restaurants to encourage you to keep going.\n When it comes to setting personal goals, let's say you've been wanting to improve your relationship with a sibling. You set a goal in the app to have at least one meaningful conversation with them each week. The app then reminds you on a lazy Sunday afternoon, suggesting, \"Why not call your sister now? It’s a good time to catch up.\"\n And for reflection, after you've hung out with your friends to watch the game or had that talk with your sister, the app asks you to rate how good you felt on a scale of 1-10. Over time, you'll see a graph of your happiness levels correlated with your social activities, making it super clear that quality time with people is a mood booster.\n The whole idea is to keep it simple but effective, helping you to naturally weave more social interactions into your life without making you feel overwhelmed or stressed.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w4fkl/cgpt4_how_could_an_ai_app_designed_to_move_people/",
          "publishedOn": "2023-09-30T11:28:22.000Z",
          "wordCount": 2892,
          "title": "CGPT-4, how could an AI app designed to move people from their screens to better enjoying the people in their life do this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w3ay6/is_ai_a_platform_shift/",
          "author": null,
          "description": "AI has the potential to be a platform shift, similar to previous shifts like personal computers, the internet, and mobile.\n \nPlatform shifts change the dominant layer that applications are built on and can capture the majority of value from the previous generation.\n \nAI could change distribution, business models, and what's possible in workflows.\n \nChanges in distribution could lead to new aggregators replacing old ones, making the aggregation of quality content more difficult.\n \nThe business model may not change significantly, with AI likely being delivered as software-as-a-service.\n \nAI can enable new workflows and drastically change existing ones.\n \nWhile incumbents may accrue significant value, new platforms could also replace old ones.\n \n Source : https://matt-rickard.com/is-ai-a-platform-shift\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w3ay6/is_ai_a_platform_shift/",
          "publishedOn": "2023-09-30T10:22:07.000Z",
          "wordCount": 2688,
          "title": "Is AI a Platform Shift?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w37vk/is_there_a_market_for_small_language_models_for/",
          "author": null,
          "description": "It seems that large language models are getting bigger and bigger, and by growing they need more and more processing power.\n I know that some LLM developers have made smaller versions to test how small they can be made and function.\n But what happens when you want a LLM to do a specific job, surely it only needs a fraction of the data a general-purpose model does.\n Potential benefits of SLMs:\n  \nLess data.\n Potentially faster.\n Less space to hallucinate/go wrong.\n Smaller set of potentials for complete testing.\n Running costs reduced.\n Lower spec hardware needs.\n  \nHas anyone tried dedicating a LLM to a specific job/task and then optimizing its data size to create a SLM?\n TLDR; How large does a LLM have to be for a toaster or microwave?\n Talkie Toaster https://www.youtube.com/watch?v=vLm6oTCFcxQ\n    submitted by    /u/Arowx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w37vk/is_there_a_market_for_small_language_models_for/",
          "publishedOn": "2023-09-30T10:17:12.000Z",
          "wordCount": 2713,
          "title": "Is there a market for Small Language Models for specific jobs/domains?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w2yup/books_3_has_revealed_thousands_of_pirated/",
          "author": null,
          "description": "submitted by    /u/Jariiari7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w2yup/books_3_has_revealed_thousands_of_pirated/",
          "publishedOn": "2023-09-30T10:02:15.000Z",
          "wordCount": 2603,
          "title": "Books 3 has revealed thousands of pirated Australian books. In the age of AI, is copyright law still fit for purpose?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w2s9e/deep_dive_into_mastering_prompt_engineering/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w2s9e/deep_dive_into_mastering_prompt_engineering/",
          "publishedOn": "2023-09-30T09:51:01.000Z",
          "wordCount": 2590,
          "title": "Deep dive into Mastering Prompt Engineering (Prompt-tier list)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w2n8y/looking_for_open_source_headless_text_to_singing/",
          "author": null,
          "description": "Scoured the Internet using all available tools. All I've come up with is proprietary and obsolete software and/or GUI-based software. \n My goal is to create an ElevenLabs type api but for singing. \n Something like Flinger (dead) would be ideal. \n If I can't find it I plan to write it but I'd rather not reinvent the wheel.\n    submitted by    /u/geeezeredm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w2n8y/looking_for_open_source_headless_text_to_singing/",
          "publishedOn": "2023-09-30T09:42:35.000Z",
          "wordCount": 2642,
          "title": "Looking for open source headless text to singing or better yet MIDI to singing software",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w22oz/is_it_possible_for_ai_to_deeply_analyze/",
          "author": null,
          "description": "I have access to texts of thousands of world news daily. Is it possible to make an AI that would analyze them and sort by importance?\n All I could find similar is NLP for analyzing text content and extracting keywords, or metadata, but this approach doesn't work well. I want for AI to grasp the essence of news and deeply understand their importance, to comprehend how an event affects many people's lives and has significant impact on society or the world as a whole.\n    submitted by    /u/canman44999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w22oz/is_it_possible_for_ai_to_deeply_analyze/",
          "publishedOn": "2023-09-30T09:06:48.000Z",
          "wordCount": 2669,
          "title": "Is it possible for AI to deeply analyze importance of thousands of daily news?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vzmra/dalle3_has_me_thinking_about_my_unborn_child_and/",
          "author": null,
          "description": "I was able to throw these images together in seconds and it has me stunned. This is all in the first year of mainstream AI. Where are we going to be this time next year..\n Philosophically what do you believe is going to happen to our paradigms of reality over the coming years? \n This is an especially challenging thought because we consume so much content and information digitally. I'm a little worried about how humans will or will not adjust to this incoming technology. I'm having my first child soon and it's interesting to think about what I may have to teach them. That nothing you consume digitally is real, only what you can experience with all 5 senses in your local environment is. Strange thoughts to be having for sure.\n With peace, Aqua.\n    submitted by    /u/Aquaritek  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vzmra/dalle3_has_me_thinking_about_my_unborn_child_and/",
          "publishedOn": "2023-09-30T06:34:21.000Z",
          "wordCount": 2716,
          "title": "Dalle-3 has me thinking about my unborn child and reality itself.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vyogq/the_ethical_dilemmas_of_ai_in_scifi_and_reality/",
          "author": null,
          "description": "An interesting article about ethics and AI in the real world versus what we find in scifi. \n Exploring points like privacy invasion, possible sentience, control and moral decisions. \n https://discover.hubpages.com/technology/the-ethical-dilemmas-of-ai-in-sci-fi-and-reality\n    submitted by    /u/No_Adhesiveness_7209  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vyogq/the_ethical_dilemmas_of_ai_in_scifi_and_reality/",
          "publishedOn": "2023-09-30T05:37:53.000Z",
          "wordCount": 2609,
          "title": "The Ethical Dilemmas of AI in Sci-Fi and Reality",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vx25e/oneminute_daily_ai_news_9292023/",
          "author": null,
          "description": "Meta Platforms (META.O) Chief Executive Mark Zuckerberg on Wednesday rolled out new AI products for consumers, including bots that create photo-realistic images and smart glasses that answer questions, as well as an updated virtual-reality headset.[1]\n The European Union is examining alleged anticompetitive practices in chips used for artificial intelligence, a market that Nvidia (NVDA.O) dominates, Bloomberg News reported on Friday, citing people familiar with the matter.[2]\n Sex robots powered by futuristic AI algorithm will one day give humans the best sex of their lives, it has been sensationally claimed.[3]\n National Security Agency Director Army Gen. Paul M. Nakasone today announced the creation of a new entity to oversee the development and integration of artificial intelligence capabilities within U.S. national security systems.[4]\n  \nSources:\n [1] https://www.reuters.com/technology/meta-signal-future-arvr-investments-annual-connect-conference-2023-09-27/\n [2] https://www.reuters.com/technology/eu-starts-early-stage-probe-into-nvidia-dominated-ai-chip-market-abuses-2023-09-29/\n [3] https://www.dailystar.co.uk/news/weird-news/sex-robots-using-ai-give-31059169\n [4] https://www.defense.gov/News/News-Stories/Article/Article/3541838/ai-security-center-to-open-at-national-security-agency/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vx25e/oneminute_daily_ai_news_9292023/",
          "publishedOn": "2023-09-30T04:07:20.000Z",
          "wordCount": 2706,
          "title": "One-Minute Daily AI News 9/29/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vp91c/bing_ai_chat_messages_are_being_hijacked_by_ads/",
          "author": null,
          "description": "Bing AI chat messages are being hijacked by ads pushing malware.\n \nMalvertising has made its way to Bing's chatbot/search engine.\n \nCybersecurity researchers observed a malicious ad being offered as part of the Chat-GPT, AI-powered answer to a search query.\n \nMalvertising is a practice where hackers trick ad networks into displaying ads that look legitimate but are actually malicious.\n \nMicrosoft integrated Chat-GPT into Bing earlier this year and started monetizing it.\n \nWhen a user types in a query, they would get a result paired with sponsored links.\n \nIn this instance, researchers were given a link that redirected them to a malicious site.\n \nThreat actors continue to leverage search ads to redirect users to malicious sites hosting malware.\n \nBing Chat serves some of the same ads seen via a traditional Bing query.\n \n Source : https://www.techradar.com/pro/security/bing-ai-chat-messages-are-being-hijacked-by-ads-pushing-malware\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vp91c/bing_ai_chat_messages_are_being_hijacked_by_ads/",
          "publishedOn": "2023-09-29T22:18:25.000Z",
          "wordCount": 2715,
          "title": "Bing AI chat messages are being hijacked by ads pushing malware",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vk7k1/crafting_virtual_worlds_with_just_words_how_ai/",
          "author": null,
          "description": "submitted by    /u/Magic-Fabric  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vk7k1/crafting_virtual_worlds_with_just_words_how_ai/",
          "publishedOn": "2023-09-29T19:02:29.000Z",
          "wordCount": 2595,
          "title": "Crafting Virtual Worlds With Just Words. How AI Changes 3D World Building Forever.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vh2ta/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n  \nMeta AI presents Emu, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal [Paper].\n Meta AI researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks [Paper].\n Abacus AI released a larger 70B version of Giraffe. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens [Details].\n Meta announced [Details]: \n Meta AI - a new AI assistant users can interact with on WhatsApp, Messenger and Instagram. Will also be available on Ray-Ban Meta smart glasses and Quest 3, Meta’s mixed reality h…",
          "link": "https://www.reddit.com/r/artificial/comments/16vh2ta/ai_weekly_megathread/",
          "publishedOn": "2023-09-29T17:01:38.000Z",
          "wordCount": 3463,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vfjj1/i_asked_chatgpt_to_be_my_girlfriend_and_it_said/",
          "author": null,
          "description": "This is a quick fun project, nothing serious at all, a personalized custom instruction for ChatGPT to make it conversational and maintain character throughout the interaction. If you want to learn more serious and useful prompt engineering techniques head on: r/PromptWizards.\n In all seriousness, even though this is just for fun, such applied prompt engineering for NPC in games, or online AI companion services can actually be relevant and useful in the future.\n By initializing this Girlfriend RolePlaying ChatGPT mode, you're not only interacting with an AI but with Sarah, 25, who is keen to explore several layers of a relationship with you. Each command you use brings you a different shade of companionship:\n  \n/start - Let Sarah introduce herself.\n /chat - Engages you in a comforting and c…",
          "link": "https://www.reddit.com/r/artificial/comments/16vfjj1/i_asked_chatgpt_to_be_my_girlfriend_and_it_said/",
          "publishedOn": "2023-09-29T16:02:04.000Z",
          "wordCount": 3173,
          "title": "I Asked ChatGPT to be my Girlfriend: And it said Yes!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ve5i9/exploring_jimmy_apples_claim_the_agi_has_been/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ve5i9/exploring_jimmy_apples_claim_the_agi_has_been/",
          "publishedOn": "2023-09-29T15:07:44.000Z",
          "wordCount": 2583,
          "title": "Exploring Jimmy Apples Claim: \"The AGI has been achieved internally\" - Detailed Reddit Investigation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vcmo9/this_weeks_ai_digest/",
          "author": null,
          "description": "Planet friendly: Researchers say AI emits up to 1,500 times less CO2 than humans when producing a page of text. Some disagree.\n Banking: Currently, around 41% of US bank customers are digital only\n Meta is launching AI chatbots across its apps to retain younger users.\n Amazon invests $4 Billion in OpenAI competitor Anthropic.\n Emerging tiger: Nvidia’s CEO bets India will emerge as a major AI market.\n Regulation: OpenAI CEO Sam Altman advocates for AI regulation despite risks.\n Suspense: Elon Musk says AI image generation app Midjourney will be releasing “something significant” soon.\n  \n   submitted by    /u/unbalanced_mind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vcmo9/this_weeks_ai_digest/",
          "publishedOn": "2023-09-29T14:08:55.000Z",
          "wordCount": 2667,
          "title": "This week's AI digest",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vbmno/cgpt4_it_is_an_indisputable_fact_that_trump/",
          "author": null,
          "description": "Some posit he was genuinely surprised by the violence and needed time to assess the situation before acting. They argue that the chaotic nature of the events made immediate action complex, given the layers of command and decision-making involved. Others claim he might have been in deliberation with advisors to gauge the scale and implications of intervention, debating the potential backlash from his supporters or the legal ramifications.\n Another perspective suggests that he might have been contemplating how the events would affect the certification of the Electoral College results, given that his previous legal and political efforts to contest the 2020 election outcome had failed. In this view, he might have been waiting to see if the Congress would be influenced to halt or delay the certification.\n While some of his supporters may find these explanations plausible, critics argue that the delay represents a dereliction of duty or even tacit support for the violence.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vbmno/cgpt4_it_is_an_indisputable_fact_that_trump/",
          "publishedOn": "2023-09-29T13:25:55.000Z",
          "wordCount": 2752,
          "title": "CGPT-4, it is an indisputable fact that Trump waited three hours to end the insurrection violence. What do his supporters guess was his thinking during this time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16v9e6p/how_to_connect_chatgpt_to_the_internet_stepbystep/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16v9e6p/how_to_connect_chatgpt_to_the_internet_stepbystep/",
          "publishedOn": "2023-09-29T11:46:07.000Z",
          "wordCount": 2591,
          "title": "How to Connect ChatGPT to the Internet (Step-by-Step Guide)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16v8jft/any_free_ai_to_turn_text_to_speech/",
          "author": null,
          "description": "I am looking for an ai that will turn the text to speech and be free. \n    submitted by    /u/Korti213  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16v8jft/any_free_ai_to_turn_text_to_speech/",
          "publishedOn": "2023-09-29T11:02:04.000Z",
          "wordCount": 2595,
          "title": "Any \"free\" ai to turn text to speech?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16v6jts/looking_for_some_help_on_a_project/",
          "author": null,
          "description": "Hey y’all, I’ve been seeing these clips everywhere of AI streamers, and I’ve been searching Everywhere for explanations of how to make one. I believe I understand the concepts, but I’m really at a loss for the avatar text to speech part. I believe I have it ready for collecting questions and getting it to ChatGPT for response/script, but im very stuck at using a photo for an avatar that can mouth the words and not take 3 mins per response. Any help is appreciated, I’ve been at this project for longer than I’d like lmao. The attached video is a random YouTube short for reference\n    submitted by    /u/Lipoz69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16v6jts/looking_for_some_help_on_a_project/",
          "publishedOn": "2023-09-29T09:05:19.000Z",
          "wordCount": 2691,
          "title": "Looking for some help on a project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16v4j30/he_got_facebook_hooked_on_ai_now_he_cant_fix_its/",
          "author": null,
          "description": "Facebook's addiction to spreading misinformation and hate speech is a result of its AI algorithms.\n \nJoaquin Quiñonero Candela, a director of AI at Facebook, was tasked with fixing the problem but was only focused on addressing AI bias.\n \nThe Responsible AI team failed to make headway against misinformation and hate speech because it never made those problems its main focus.\n \nThe spread of lies and hate speech on Facebook has only grown, contributing to genocidal campaigns and the promotion of dangerous falsehoods.\n \nThe algorithms that underpin Facebook's business were designed to maximize engagement, not filter out false or inflammatory content.\n \n Source : https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16v4j30/he_got_facebook_hooked_on_ai_now_he_cant_fix_its/",
          "publishedOn": "2023-09-29T06:59:47.000Z",
          "wordCount": 2687,
          "title": "He got Facebook hooked on AI. Now he can't fix its misinformation addiction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16v3war/album_covers_but_morgan_freeman/",
          "author": null,
          "description": "submitted by    /u/TheGhettoControversy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16v3war/album_covers_but_morgan_freeman/",
          "publishedOn": "2023-09-29T06:20:02.000Z",
          "wordCount": 2586,
          "title": "Album covers but Morgan Freeman",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16uzzrv/google_is_expanding_its_aipowered_search/",
          "author": null,
          "description": "Google's AI-driven search experience, Search Generative Experience (SGE), is now accessible to teenagers between 13-17 in America. Entailments include a conversational mode for searches, which Google believes can help youngsters pose atypical questions to dig deeper.\n For the latest advancements in AI, look here first.\n Teen-friendly AI search\n  \nSGE introduces a conversational mode to Google Search, allowing users to ask questions and follow-ups in a more natural language.\n To prevent harmful content from surfacing, Google has placed guardrails, providing stronger protections related to illegal and age-gated substances, or bullying.\n  \nFeatures and improving AI accuracy\n  \nGoogle is rolling out \"About this result\" to provide users with more context about the displayed content.\n Google acknowledges and addresses any validation of false or offensive claims by the AI-powered response, ensuring to provide higher quality and more accurate responses.\n It’s also using large language models to self-critique and rewrite draft responses on sensitive topics based on quality and safety principles.\n  \nSGE's popularity and future plans\n  \nSince SGE's introduction, it has found popularity, especially among younger users who prefer a conversational approach.\n Google plans to expand SGE outside the U.S. to India and Japan and improve its services with support for videos, images, local info, and more.\n It's also experimenting with ads positioned next to the AI-generated responses.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI and tech. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16uzzrv/google_is_expanding_its_aipowered_search/",
          "publishedOn": "2023-09-29T02:51:34.000Z",
          "wordCount": 2829,
          "title": "Google is expanding its AI-powered search experience to teenagers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ut40r/the_creator_2023_movie_discussion/",
          "author": null,
          "description": "In theaters now. PG-13. \n Synopsis from Fandango (mild spoilers)\n From writer/director Gareth Edwards (“Rogue One,” “Godzilla”) comes an epic sci-fi action thriller set amidst a future war between the human race and the forces of artificial intelligence. Joshua (John David Washington, \"Tenet\"), a hardened ex-special forces agent grieving the disappearance of his wife (Gemma Chan, \"Eternals\"), is recruited to hunt down and kill the Creator, the elusive architect of advanced AI who has developed a mysterious weapon with the power to end the war… and mankind itself. Joshua and his team of elite operatives journey across enemy lines, into the dark heart of AI-occupied territory… only to discover the world-ending weapon he’s been instructed to destroy is an AI in the form of a young child (newcomer Madeleine Yuna Voyles). \n Trailer\n If there is any other media I should make threads for just let me know- could be video games, television, etc.\n    submitted by    /u/jaketocake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ut40r/the_creator_2023_movie_discussion/",
          "publishedOn": "2023-09-28T22:00:56.000Z",
          "wordCount": 2724,
          "title": "The Creator (2023) movie discussion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16urjyh/aryn_comes_out_of_stealth_to_bring_genai_to/",
          "author": null,
          "description": "Aryn, a team with experience in AWS big data and database services, has come out of stealth and raised $7.5M in series seed funding.\n \nTheir mission is to bring generative AI to OpenSearch and data preparation.\n \nThey aim to use generative AI models to process unstructured data for tasks such as information extraction, question-answering, summarization, and content generation.\n \nAryn's conversational search approach empowers users to interact with their unstructured enterprise data.\n \nThey have developed a conversational search stack consisting of a semantic data preparation system called Sycamore, semantic search with OpenSearch, and conversational capabilities in OpenSearch.\n \nGenerative AI powers each component of the stack, leading to higher quality answers and ease of use.\n \nDevelopers can quickly build and deploy applications like question-answering, chatbots, and research platforms using Aryn's stack without needing expertise in AI and search.\n \nAryn's stack is 100% open source, making it accessible to developers.\n \n Source : https://blog.aryn.ai/aryn-bringing-generative-ai-to-opensearch-and-data-preparation\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16urjyh/aryn_comes_out_of_stealth_to_bring_genai_to/",
          "publishedOn": "2023-09-28T21:02:51.000Z",
          "wordCount": 2730,
          "title": "Aryn comes out of stealth to bring GenAI to OpenSearch and data preparation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ur69d/why_does_this_read_like_someone_used_chatdev_and/",
          "author": null,
          "description": "submitted by    /u/Lesbianseagullman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ur69d/why_does_this_read_like_someone_used_chatdev_and/",
          "publishedOn": "2023-09-28T20:48:36.000Z",
          "wordCount": 2589,
          "title": "Why does this read like someone used chatdev and gave it a marketing agent named clover with access to a reddit account?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16uopzo/meta_unfolds_a_universe_of_ai_across_instagram/",
          "author": null,
          "description": "Meta has unveiled colossal AI updates peppered across its platform that would fundamentally alter user experiences on Instagram, Facebook, and WhatsApp, opening up a \"universe of AI\" solutions.\n For the latest advancements in AI, look here first.\n https://preview.redd.it/bl81rlbqp1rb1.png?width=2048&format=png&auto=webp&s=be44b8ebae8f65b53eb82fe2a78b45f19260c452\n Spearheading the AI Universe - Meta AI Chatbot\n  \nThe “advanced conversational assistant” is set to enhance Messenger, WhatsApp, and Instagram services and will be incorporated into upcoming Ray-Ban Meta smart glasses and Quest 3.\n Real-time information capabilities have been bolstered through a partnership with Microsoft Bing, and image generation is powered by a new model, Emu.\n  \nA Galaxy of AI Personalities\n  \nMeta rolled out 28 AIs in beta, featuring sterling personas such as Snoop Dogg, Tom Brady, Kendall Jenner, and Naomi Osaka, thus amplifying the interactivity quotient.\n  \nAI Studio - Empowering Businesses\n  \nThe AI Studio Platform is equipped to enable businesses to build AI chatbots for messaging services on Facebook, Instagram, and Messenger.\n Also, Meta will provide a sandbox tool in the upcoming year for users to experiment with creating their own AI.\n  \nGenerative AI Stickers - A New Co-creating Experience\n  \nAI editing tools will allow users to edit images and co-create content with friends.\n The tool uses Llama 2 and the new image generation model, Emu, to convert text prompts into stickers in seconds.\n  \nRay-Ban Smart Glasses with Meta AI\n  \nThe Ray-Ban smart glasses are equipped with Meta AI, allowing users to receive information, incite creativity, and manage the glasses using just their voice.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter with the latest and most impactful news in AI. Professionals from Google, Meta, and OpenAI read it daily.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16uopzo/meta_unfolds_a_universe_of_ai_across_instagram/",
          "publishedOn": "2023-09-28T19:14:09.000Z",
          "wordCount": 2846,
          "title": "Meta Unfolds a 'Universe of AI' Across Instagram, Facebook, and WhatsApp",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16un18r/get_a_job_as_a_prompt_engineer_challenge_generate/",
          "author": null,
          "description": "One member on r/PromptWizards just applied for a job as a Prompt Engineer in a company, and they tasked him to craft a prompt system that generates high-quality SAT-style multiple-choice questions. Quite a quest, right? Well, stick around, and we'll take a deep dive into the prompt engineering we used to help him.\n The mission was precise: Write a prompt to yield an SAT-style multiple-choice question that rigorously tests a student's understanding of \"Algebraically solving systems of 2 linear equations in 2 variables\". The challenge didn't end there; the question produced had to meet the hard/difficult mark set by real SAT questions.\n Using the OpenAI Playground, we conducted incisive iterations, testing each prompt separately to mitigate any bias from prior outputs.\n Our approach was:\n - …",
          "link": "https://www.reddit.com/r/artificial/comments/16un18r/get_a_job_as_a_prompt_engineer_challenge_generate/",
          "publishedOn": "2023-09-28T18:08:04.000Z",
          "wordCount": 3363,
          "title": "Get a job as a Prompt Engineer - Challenge: generate SAT-Style Multiple Choice Questions.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16umg4p/warner_on_ai_regulation_we_probably_cant_solve_it/",
          "author": null,
          "description": "submitted by    /u/smo279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16umg4p/warner_on_ai_regulation_we_probably_cant_solve_it/",
          "publishedOn": "2023-09-28T17:43:11.000Z",
          "wordCount": 2590,
          "title": "Warner on AI regulation: ‘We probably can't solve it all at once’",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ughkp/courses_for_more_seniors/",
          "author": null,
          "description": "Hello all,\n What course would you recommend for those of us who are older and already settled in other careers. For example I'm 35 and a manager so I wouldn't need a course to actually design AI or anything. It would be more related to understanding how/where to implement it in an organisation.\n Any tips?\n Cheers and merci\n    submitted by    /u/JYanezez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ughkp/courses_for_more_seniors/",
          "publishedOn": "2023-09-28T13:45:03.000Z",
          "wordCount": 2629,
          "title": "Courses for more Seniors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16uexdv/show1_marrying_pixel_and_latent_diffusion_models/",
          "author": null,
          "description": "A new paper proposes Show-1, a hybrid model that combines pixel and latent diffusion for efficient high-quality text-to-video generation.\n Both of these approaches have tradeoffs, so researchers at the National University of Singapore tried a hybrid approach combining both, and shared the results in a paper published yesterday.\n My highlights from the paper:\n  \nPixel diffusion excels at low-res video generation precisely aligned with text\n Latent diffusion acts as efficient upsampling expert from low to high res\n Chaining the two techniques inherits benefits of both Show-1 achieves strong alignment, quality, and 15x less inference memory\n The key is using pixel diffusion for the initial low-resolution stage. This retains alignment with text descriptions.\n Latent diffusion then serves as a super-resolution expert, upsampling efficiently while preserving fidelity.\n  \nBy blending complementary techniques, Show-1 moves past tradeoffs limiting the individual models.\n More details here. Paper is here (includes links to example generations).\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16uexdv/show1_marrying_pixel_and_latent_diffusion_models/",
          "publishedOn": "2023-09-28T12:38:46.000Z",
          "wordCount": 2727,
          "title": "Show-1: Marrying Pixel and Latent Diffusion Models for Efficient and High-Quality Text-to-Video Generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16uebbn/what_ai_makes_images_that_subtle_forms_a_word/",
          "author": null,
          "description": "submitted by    /u/samuraiogc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16uebbn/what_ai_makes_images_that_subtle_forms_a_word/",
          "publishedOn": "2023-09-28T12:10:10.000Z",
          "wordCount": 2588,
          "title": "What AI makes images that subtle forms a word like this one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ue6ml/getting_emotional_with_llms_can_increase/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ue6ml/getting_emotional_with_llms_can_increase/",
          "publishedOn": "2023-09-28T12:04:11.000Z",
          "wordCount": 2589,
          "title": "Getting emotional with LLMs can increase performance by 115% (Case Study)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16uclab/question_about_a_small_project/",
          "author": null,
          "description": "Me and my sister have a small project we are thinking about working on. The idea is basically that we are going to enter the same prompt, separately, into an image generating a.i of some sort (Dalle2 etc) for a period of time and hopefully see the result change. We would probly pick words or frases that are topical and debated. This only works though if the a.i isnt just trained on old data and has active connection to the internet. MY question is therefor, is there an a.i right now that would fit the task?\n Sorry if the question is dumb or i didnt explain myself clearly!\n    submitted by    /u/Mejwynn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16uclab/question_about_a_small_project/",
          "publishedOn": "2023-09-28T10:44:24.000Z",
          "wordCount": 2674,
          "title": "Question about a small project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16u6suv/oneminute_daily_ai_news_9272023/",
          "author": null,
          "description": "ODIN integrates Large Language Models (LLMs) into Obsidian using LangChain, allowing you to ask questions about the data stored in your knowledge graph right from the prompt bar.[1]\n ChatGPT users can now browse internet, OpenAI says.[2]\n Adobe’s Photoshop on the web launch includes its popular desktop AI tools.[3]\n The White House plans to introduce a highly anticipated executive order in the coming weeks dealing with artificial intelligence, President Joe Biden said Wednesday.[4]\n  \nSources:\n [1] https://github.com/memgraph/odin\n [2] https://www.reuters.com/technology/openai-says-chatgpt-can-now-browse-internet-2023-09-27/\n [3] https://www.theverge.com/2023/9/27/23892889/adobe-photoshop-for-the-web-firefly-ai-generative-fill-full-release-price-date\n [4] https://www.cnn.com/2023/09/27/tech/joe-biden-executive-order-artificial-intelligence/index.html\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16u6suv/oneminute_daily_ai_news_9272023/",
          "publishedOn": "2023-09-28T04:54:28.000Z",
          "wordCount": 2653,
          "title": "One-Minute Daily AI News 9/27/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16u3s8f/multimodal_ais_will_cause_people_to_embrace_their/",
          "author": null,
          "description": "I have been messing with llama. Trying to make a script to make a movie. Sort of realize it is not there yet, it can write decoherent long stories / what ever you want. You can couple it with stable diffusion to make images that would have to be described better to fit the \"movie\" or narrative. It is not there yet, ChatGPT can already do this, you can ask it to tell you a story and describe the visual scenes. \n At the same time, we are getting audio generation from things like audioldm2 and stableaudio etc. Multimodal AI's are almost here. \n Pretty soon we will have devices in our pockets powered by AI chips that will be able to generate what ever reality we want. We can feed them images from our past and they can allow us to live in VR reality of the past. Or we can choose to live in anot…",
          "link": "https://www.reddit.com/r/artificial/comments/16u3s8f/multimodal_ais_will_cause_people_to_embrace_their/",
          "publishedOn": "2023-09-28T02:21:02.000Z",
          "wordCount": 3059,
          "title": "Multimodal AI's will cause people to embrace their own reality bubbles and that is bad news for dictatorships",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16u1jw8/jazz_fusion_ai_generated_dnb_jazz_music_and_video/",
          "author": null,
          "description": "submitted by    /u/LibeerCZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16u1jw8/jazz_fusion_ai_generated_dnb_jazz_music_and_video/",
          "publishedOn": "2023-09-28T00:43:26.000Z",
          "wordCount": 2576,
          "title": "Jazz Fusion (AI Generated DnB & Jazz music and video)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tymc3/any_good_ai_newsletters_im_tired/",
          "author": null,
          "description": "Any good AI (low-hype) newsletters/blogs? That's ideally sent <= 4 times a month? \n I'm tired of the amount of AI news I have to go through daily just to keep up.\n    submitted by    /u/onteri  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tymc3/any_good_ai_newsletters_im_tired/",
          "publishedOn": "2023-09-27T22:42:16.000Z",
          "wordCount": 2604,
          "title": "Any good AI newsletters? I'm tired",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tvcuf/ai_is_taking_jobs_away_from_chinese_streamers_and/",
          "author": null,
          "description": "AI-generated deepfake clones of Chinese livestream influencers are becoming popular on e-commerce platforms.\n \nThese clones can work 24/7 and help brands sell their products without the need for human streamers.\n \nChinese startups and tech companies are offering the service of creating these deepfake avatars for a cost of around $1,000.\n \nThe technology has evolved over the years, with the need for training videos decreasing from 30 minutes to just one minute.\n \nThe AI clones can mimic the movements and speech of human streamers, making them an affordable and efficient alternative for smaller brands.\n \n Source : https://www.technologyreview.com/2023/09/19/1079832/chinese-ecommerce-deepfakes-livestream-influencers-ai/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tvcuf/ai_is_taking_jobs_away_from_chinese_streamers_and/",
          "publishedOn": "2023-09-27T20:38:45.000Z",
          "wordCount": 2674,
          "title": "AI is taking jobs away from Chinese streamers and online retailers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tvcdq/using_language_models_for_code_generation_works/",
          "author": null,
          "description": "Automatic code generation has always been an integral part of programming: compilers, synthesis tools, convertors, etc. are examples of classic code generators. Now, with such powerful LLMs at hand, it is only natural to try to find new ways to generate codes. The question is: are LLMs the right tool for code generation?\n There are two sides to code generation: (1) understanding the intent (a.k.a. capturing the spec) (2) writing the code. LLMs are great for (1), but not so good for (2).\n This is an example of using LLM for general-domain code generation:\n https://github.com/RoboCoachTechnologies/GPT-Synthesizer \n You can see that the main focus here is to properly capture the spec, and that's where LLMs shine.\n LLMs solution for a general-domain code generation may not be complete or optimized. It is always easier to break the problem and solve code generation in a specific domain. Here you can see how much better and cleaner the output of code generation can be when it is limited to a specific domain (robotics domain, ROS in particular, in this case):\n https://github.com/RoboCoachTechnologies/ROScribe\n What are your thoughts on using LLMs for code generation?\n    submitted by    /u/RoboCoachTech  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tvcdq/using_language_models_for_code_generation_works/",
          "publishedOn": "2023-09-27T20:38:14.000Z",
          "wordCount": 2767,
          "title": "Using language models for code generation works better when limited to a specific domain",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tumrg/how_to_stop_ai_deepfakes_from_sinking_society_and/",
          "author": null,
          "description": "submitted by    /u/waozen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tumrg/how_to_stop_ai_deepfakes_from_sinking_society_and/",
          "publishedOn": "2023-09-27T20:10:39.000Z",
          "wordCount": 2589,
          "title": "How to stop AI deepfakes from sinking society — and science",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tulzh/even_the_cia_is_developing_an_ai_chatbot/",
          "author": null,
          "description": "The CIA is developing an AI chatbot similar to ChatGPT to help US intelligence agencies sift through large amounts of information.\n \nThe program will train on publicly available data and provide sources for agents to confirm their validity.\n \nThe tool will allow agents to look up information, ask follow-up questions, and summarize daunting masses of data.\n \nThe exact nature of what constitutes 'public data' could spark privacy issues.\n \nThe tool will be distributed to the 18-agency US intelligence community, but not to lawmakers or the public.\n \n Source : https://www.engadget.com/even-the-cia-is-developing-an-ai-chatbot-192358767.html\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tulzh/even_the_cia_is_developing_an_ai_chatbot/",
          "publishedOn": "2023-09-27T20:09:53.000Z",
          "wordCount": 2664,
          "title": "Even the CIA is developing an AI chatbot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ttkt4/unc_researchers_present_videodirectorgpt_using_ai/",
          "author": null,
          "description": "Generating coherent videos spanning multiple scenes from text descriptions poses unique challenges for AI. While recent progress enables creating short clips, smoothly transitioning across diverse events and maintaining continuity remains difficult.\n A new paper from UNC Chapel Hill proposes VIDEODIRECTORGPT, a two-stage framework attempting to address multi-scene video generation:\n Here are my highlights from the paper:\n  \nTwo-stage approach: first a language model generates detailed \"video plan\", then a video generation module renders scenes based on the plan\n Video plan contains multi-scene descriptions, entities/layouts, backgrounds, consistency groupings - guides downstream video generation\n Video generation module called Layout2Vid trained on images, adds spatial layout control and cross-scene consistency to existing text-to-video model\n Experiments show improved object layout/control in single-scene videos vs baselines\n Multi-scene videos display higher object consistency across scenes compared to baselines\n Competitive open-domain video generation performance maintained\n  \nThe key innovation seems to be using a large language model to plot detailed video plans to guide overall video generation. And the video generator Layout2Vid adds better spatial and temporal control through some clever tweaks. The separation of these tasks seems to matter.\n You can read my full summary here. There's a link to the repo there too. Paper link is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ttkt4/unc_researchers_present_videodirectorgpt_using_ai/",
          "publishedOn": "2023-09-27T19:29:50.000Z",
          "wordCount": 2779,
          "title": "UNC Researchers Present VideoDirectorGPT: Using AI to Generate Multi-Scene Videos from Text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ttcgu/cyberpunk_multiverse/",
          "author": null,
          "description": "I created this cyberpunk inspired short using Midjourney to create the pictures, RunwayML to animate them, and then edit them together using CapCut on iOS. \n I know the animation is still in early stages, but what do you think? Do you think we could have full length movies in a couple years?\n    submitted by    /u/Exitium_Maximus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ttcgu/cyberpunk_multiverse/",
          "publishedOn": "2023-09-27T19:20:46.000Z",
          "wordCount": 2621,
          "title": "Cyberpunk Multiverse",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tsoes/a_simple_checklist_for_selfevaluating_prompt/",
          "author": null,
          "description": "How do you evaluate the quality of your prompt outputs? Here's a handy checklist. Let's have a look!\n You can also join r/PromptWizards to find more tutorials and prompts!\n Part 1: Understanding AI's Understanding\n You've presented a prompt to your AI, the next questions are:\n  \nHas the AI accurately grasped the context? \n If not, how can I make sure the LLM steers my context better, should I be more direct and clear in my prompt? Can I be less negative (shows to perform less) and be more guiding to the LLM?\n \n Do the responses directly address the question or topic? \n Was my query and task/instruction clearly detailed in enough depth that the LLM understood what I expect?\n \n Are there any contradictions between different responses to the same prompt? \n If I run my prompt multiple times, i…",
          "link": "https://www.reddit.com/r/artificial/comments/16tsoes/a_simple_checklist_for_selfevaluating_prompt/",
          "publishedOn": "2023-09-27T18:55:28.000Z",
          "wordCount": 2916,
          "title": "A Simple Checklist for Self-Evaluating Prompt Quality",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tqxhs/openais_gpt4_with_vision_still_has_flaws_reveals/",
          "author": null,
          "description": "OpenAI's much-touted model GPT-4, lauded for its multimodal abilities, including advanced image recognition, still has significant flaws. These glitches range from inventing facts to misinterpreting chemicals' images and hate symbols, according to a new paper from OpenAI.\n To stay ahead of AI developments, look here first.\n https://preview.redd.it/seg5x4zn3uqb1.png?width=1108&format=png&auto=webp&s=635a6c58cf6255f62d8eae3077678864e5b0e248\n Unintended GPT-4V behaviors\n  \nGPT-4V has a tendency to hallucinate or invent facts with unwarranted confidence.\n The model struggles to make correct inferences, sometimes creating fictional terms by wrongly combining text strings.\n It misinterprets certain symbols of hate and can give incorrect answers in the context of medical imaging.\n  \nOpenAI’s mitigation strategies\n  \nOpenAI has implemented various safeguards to prevent GPT-4V's misuse, such as breaking CAPTCHAs or using images to infer personal details.\n The company insisted that GPT-4V is not to be used for identifying dangerous chemicals from image structures.\n OpenAI acknowledged it has a long way to go in refining the model and is working on it.\n  \nDiscrimination and bias\n  \nWhen OpenAI’s production safeguards are disabled, GPT-4V displays bias against certain sexes and body types.\n The paper reported offensive responses related to body positivity when prompted by an image of a woman in a bathing suit.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that dissects the most impactful AI news and research. 1000s of professionals from Google, Meta, and OpenAI read it daily.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tqxhs/openais_gpt4_with_vision_still_has_flaws_reveals/",
          "publishedOn": "2023-09-27T17:36:55.000Z",
          "wordCount": 2801,
          "title": "OpenAI’s GPT-4 With Vision Still Has Flaws, Reveals Paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tqvhw/new_bing_browser_same_bing_results_score_was_1027/",
          "author": null,
          "description": "submitted by    /u/degrudv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tqvhw/new_bing_browser_same_bing_results_score_was_1027/",
          "publishedOn": "2023-09-27T17:34:53.000Z",
          "wordCount": 2586,
          "title": "New Bing browser, same Bing results. Score was 10-27 btw.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tmoc4/are_language_models_being_nerfed/",
          "author": null,
          "description": "In using Ai and asking it to do simple tasks like \"explain this in more simple terms\" or asking it to make flashcards for me in a certain format, I am really convinced that language models, (bard and openai specifically) are being nerfed. They cannot understand simple instructions as well anymore. I had a paragraph of information for one of my classes that I wanted it to make more straightforward for me before I actually went to class the next day. I spent like 30 minutes trying to get it to do that and eventually just ended up giving up. Why dont language models feel as sharp as they did say a year ago? I wish I had more examples to share. Am I the only one who's noticed this? \n    submitted by    /u/Bojof12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tmoc4/are_language_models_being_nerfed/",
          "publishedOn": "2023-09-27T14:52:04.000Z",
          "wordCount": 2702,
          "title": "Are language Models being nerfed?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tmneg/looking_for_the_best_ai_art_generator_look_no/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tmneg/looking_for_the_best_ai_art_generator_look_no/",
          "publishedOn": "2023-09-27T14:51:02.000Z",
          "wordCount": 2593,
          "title": "Looking For The Best AI Art Generator? Look No Further! (Definitive Guide for 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tmabo/looking_to_change_my_own_voice_for_audio/",
          "author": null,
          "description": "Hi all – I’m new to this sub-Reddit, so hopefully I’m in the right place.\n I am working on an audio production that will span multiple episodes and hopefully multiple seasons. It will require many characters, ranging in gender, age, ethnicity, etc. I am a decent voice actor and can do many of the roles myself, but some of them I cannot fake using my voice alone.\n My budget is very limited, so I was hoping to find some type of software I can change my voice for the production. This can be during the recording process, or after recording… As long as it gets the job done, and makes me sound like someone else entirely. \n Does anybody know of a software that can achieve this? Most of the software I found either specifically designed to change users voice on the spot and is aimed at gamers changing your voice for live streams or in-game chats. I’m also on a Mac, which I know will be limiting.\n I’m having a hard time finding something I can use. Any suggestions will be helpful. \n Thank you!\n EDIT: To clarify, I don’t want to just change my voice to sound different in general. I want to specifically sound like a woman, an elder man, or someone of a different ethnic background. Those are just a few examples.\n    submitted by    /u/nopetoocreepy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tmabo/looking_to_change_my_own_voice_for_audio/",
          "publishedOn": "2023-09-27T14:36:07.000Z",
          "wordCount": 2800,
          "title": "Looking to change my own voice for audio production",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tlk9c/i_asked_ai_to_create_a_religion_and_this_is_what/",
          "author": null,
          "description": "submitted by    /u/GABIBBOPAZZOCINESE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tlk9c/i_asked_ai_to_create_a_religion_and_this_is_what/",
          "publishedOn": "2023-09-27T14:06:15.000Z",
          "wordCount": 2581,
          "title": "I asked AI to create a religion and this is what it created (its weird)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Neural Networks, Deep Learning and Machine Learning",
      "feedUrl": "https://www.reddit.com/r/neuralnetworks/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/neuralnetworks/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17gftrt/we_hate_how_black_box_neural_nets_are_we_made_a/",
          "author": null,
          "description": "submitted by    /u/DeltaStarStudiosPR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17gftrt/we_hate_how_black_box_neural_nets_are_we_made_a/",
          "publishedOn": "2023-10-25T21:36:00.000Z",
          "wordCount": null,
          "title": "We hate how \"black box\" neural nets are, we made a thingy in an attempt to demystify their \"thinking.\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17gexf5/ai_breakthrough_neural_net_has_humanlike_ability/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17gexf5/ai_breakthrough_neural_net_has_humanlike_ability/",
          "publishedOn": "2023-10-25T20:59:41.000Z",
          "wordCount": null,
          "title": "AI ‘breakthrough’: neural net has human-like ability to generalize language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17frg9c/long_read_deep_dive_into_autogpt_a_comprehensive/",
          "author": null,
          "description": "https://airt.hashnode.dev/long-read-deep-dive-into-autogpt-a-comprehensive-and-in-depth-step-by-step-guide-to-how-it-works\n    submitted by    /u/Harish_Mohanraj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17frg9c/long_read_deep_dive_into_autogpt_a_comprehensive/",
          "publishedOn": "2023-10-25T00:02:15.000Z",
          "wordCount": null,
          "title": "[Long read] Deep dive into AutoGPT: A comprehensive and in-depth step-by-step guide to how it works",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17fgbfm/animated_ai/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17fgbfm/animated_ai/",
          "publishedOn": "2023-10-24T16:04:42.000Z",
          "wordCount": null,
          "title": "Animated AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17eksow/are_generalized_selfsupervised_vit_models_the/",
          "author": null,
          "description": "submitted by    /u/No-Platypus4021  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17eksow/are_generalized_selfsupervised_vit_models_the/",
          "publishedOn": "2023-10-23T13:46:27.000Z",
          "wordCount": null,
          "title": "Are Generalized Self-Supervised ViT Models the Image Objective Counterpart of LLM’s?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17eke2q/neural_networks_a_deep_dive_into_ais_building/",
          "author": null,
          "description": "submitted by    /u/Emily-joe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17eke2q/neural_networks_a_deep_dive_into_ais_building/",
          "publishedOn": "2023-10-23T13:26:45.000Z",
          "wordCount": null,
          "title": "Neural Networks: A Deep Dive into AI's Building Blocks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17dw1a3/replay_game_input_with_image_classification/",
          "author": null,
          "description": "TensorFlow Keras correcting camera horizon in AC Valhalla\n https://www.youtube.com/watch?v=ASy-2zOMj_Y\n    submitted by    /u/Kostiantyn-Dvornik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17dw1a3/replay_game_input_with_image_classification/",
          "publishedOn": "2023-10-22T15:37:15.000Z",
          "wordCount": null,
          "title": "Replay game input with image classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17dsx38/how_i_determine_neuron_layers_and_amount_of/",
          "author": null,
          "description": "Hello, I’m newbie in neural networks and I wonder, how do people decide how many hidden layers there will be and how many neurons will be inside? What the logic behind?\n    submitted by    /u/Particular-Song-633  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17dsx38/how_i_determine_neuron_layers_and_amount_of/",
          "publishedOn": "2023-10-22T13:09:26.000Z",
          "wordCount": null,
          "title": "How I determine neuron layers and amount of neurons in?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17dsqn7/unboxing_neuro_symbolic_reasoning_and_learning/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17dsqn7/unboxing_neuro_symbolic_reasoning_and_learning/",
          "publishedOn": "2023-10-22T13:00:31.000Z",
          "wordCount": null,
          "title": "Unboxing Neuro Symbolic Reasoning and Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17cu5r9/is_there_any_neural_network_or_llm_like/",
          "author": null,
          "description": "​\n Generating a Wide Variety of Sounds\n I'm a non-technical person with very little knowledge to develop AI tools and intending to learn Python and based on that My question is as follows:\n ​\n Are there tools or chatgpt like platforms that can help people like me to generate couple of sounds like dog barks, cat meows. I want either something that can generate a variety of sounds or I want to work towards making something that cane help me generate audios like dog barks, such as fierce, aggressive ones but not just limited to dog barks but also sound focused on nature, other animals, vehicles, machinery(e.g., honks, engine sounds ), and possibly human sounds (though that's not my primary focus for now).\n The amount of technical Assistance Needed\n I also came across a tool like Teachable Machine and was wondering if it could be a solution as it does offer tools for audio. I am also aware that I would need datasets for such a task but apart from that I am not too sure about the nitty gritty or should I say the intricacies involved as well as the knowledge needed as I do assume it is likely not very easy https://www.youtube.com/watch?v=L4GOmYPPqn8&t=1854s\n ​\n [Teachable Machine](https://teachablemachine.withgoogle.com/)\n ​\n Inspiration\n I was inspired by a project I found here: [https://x.com/TheAIAnonGuy/status/1684443155448360961?s=20] \n ​\n ​\n Can anyone provide insights, guidance, or recommendations on how to accomplish this?\n To be fair, I'm not really sure if this is an audio-related or neural/machine learning (ML)/deep learning related learning question.\n But I would like more insight if this is possible on an individual scale either with teachable, code or AI or a combination of all approaches and if there are any beginner friendly ways to achieve this\n Thank you all for your assistance!\n    submitted by    /u/Beginning_Finding_98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17cu5r9/is_there_any_neural_network_or_llm_like/",
          "publishedOn": "2023-10-21T04:15:02.000Z",
          "wordCount": null,
          "title": "Is there any neural network or LLM like chatgpt,midjourney that can help us train and generate custom sounds",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17c9pi3/article_computer_vision_in_agriculture_challenges/",
          "author": null,
          "description": "​\n https://preview.redd.it/j3nmj31llcvb1.jpg?width=2500&format=pjpg&auto=webp&s=c09804179e4f40a854e1327fa9150f1ab0c0dfd0\n Interesting article about use cases of data augmentation in agricultural industry.\n Short description:\n In this article, you will cover:\n • How computer vision solutions are transforming the agricultural industry.\n • Observe the importance of quality data for developing AI solutions that perform crop and livestock analysis and monitoring with high and steady accuracy.\n • Explore the use of synthetic data to facilitate data collection in various conditions.\n • Take a look at examples of tasks in agriculture. How can we solve them with computer vision, and how can we apply synthetic data to extend the augmentation?\n More details are here\n    submitted by    /u/No-Independence5880  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17c9pi3/article_computer_vision_in_agriculture_challenges/",
          "publishedOn": "2023-10-20T12:05:48.000Z",
          "wordCount": null,
          "title": "Article: Computer Vision in Agriculture. Challenges & Solutions.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17adjj3/best_books_to_learn_neural_networks_in_2023_for/",
          "author": null,
          "description": "submitted by    /u/Lakshmireddys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17adjj3/best_books_to_learn_neural_networks_in_2023_for/",
          "publishedOn": "2023-10-18T00:39:08.000Z",
          "wordCount": null,
          "title": "Best Books to Learn Neural Networks in 2023 for Beginners (Updated) -",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/179krjk/model_metamers_reveal_divergent_invariances/",
          "author": null,
          "description": "submitted by    /u/Chipdoc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/179krjk/model_metamers_reveal_divergent_invariances/",
          "publishedOn": "2023-10-17T00:01:02.000Z",
          "wordCount": 2525,
          "title": "Model metamers reveal divergent invariances between biological and artificial neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17869ta/supercharging_reinforcement_learning_with_logic/",
          "author": null,
          "description": "Deep reinforcement learning has led to a variety of compelling results. However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly. Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.\n ​\n https://preview.redd.it/pmukb2k7aaub1.png?width=1786&format=png&auto=webp&s=3fb36d0fbeb75393ae8f71f8f369ff5e0b79fbcb\n We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).\n ​\n https://preview.…",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17869ta/supercharging_reinforcement_learning_with_logic/",
          "publishedOn": "2023-10-15T03:14:22.000Z",
          "wordCount": null,
          "title": "Supercharging reinforcement learning with logic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1772yxj/a_question/",
          "author": null,
          "description": "What are the ways to create plasticity in neural network? Without using weights,bias and activation functions?\n    submitted by    /u/Sith_vader3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1772yxj/a_question/",
          "publishedOn": "2023-10-13T16:40:37.000Z",
          "wordCount": 2521,
          "title": "A question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/176tp60/neural_networks_project/",
          "author": null,
          "description": "Hi ! My group (4 people) has chosen to make an application that translates ancient stone inscriptions to modern languages as our university project . We can use external libraries to process images that we are going to translate but as we understood we have to build the neural network ourselves from scratch. My questions are 1) is this possible to do within 10 months? 2) if so how would you approach it ?\n    submitted by    /u/sakith123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/176tp60/neural_networks_project/",
          "publishedOn": "2023-10-13T08:10:35.000Z",
          "wordCount": null,
          "title": "Neural Networks project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/176kek2/how_are_memories_stored_in_neural_networks_the/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/176kek2/how_are_memories_stored_in_neural_networks_the/",
          "publishedOn": "2023-10-12T23:11:47.000Z",
          "wordCount": null,
          "title": "How are memories stored in neural networks? | The Hopfield Network #SoME2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1760j8z/a_question/",
          "author": null,
          "description": "How does the neural network process input that were same but shown different to the network model?\n    submitted by    /u/Sith_vader3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1760j8z/a_question/",
          "publishedOn": "2023-10-12T06:50:58.000Z",
          "wordCount": null,
          "title": "A question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1760in9/i_dont_much_about_nns_is_this_correct/",
          "author": null,
          "description": "i gave chatgpt vision an illustration of neural network from The Principles of Deep Learning Theory. what to know how correct its reponse is\n here is the response: \n https://preview.redd.it/inqe5xukxptb1.png?width=453&format=png&auto=webp&s=6e1079baeae8235b0e03a677e4006d1077af36a8\n    submitted by    /u/YeshwanthRam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1760in9/i_dont_much_about_nns_is_this_correct/",
          "publishedOn": "2023-10-12T06:49:49.000Z",
          "wordCount": null,
          "title": "I don't much about NN's. is this correct ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/175npm5/neural_networks_from_scratch_in_rust/",
          "author": null,
          "description": "submitted by    /u/zezeartix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/175npm5/neural_networks_from_scratch_in_rust/",
          "publishedOn": "2023-10-11T20:15:39.000Z",
          "wordCount": 2523,
          "title": "Neural Networks From Scratch in Rust",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/175kfcg/activation_function_for_generating_shapley_values/",
          "author": null,
          "description": "Hi, I want to train a neural network to calculate Shapley values based on a given characteristic function.\n Depending on a given characteristic function, calculated through a dedicated algorithm, Shapley values can be any number, positive or negative, without a set range.\n Because of this, I am unsure, for the specific application of calculating Shapley values, what activation function to use in a neural network that would calculate them. The relu function, as well as leaky relu function, either cannot give values that are negative or have trouble giving large negative values, and sigmoid or tanh can only give values in a certain range.\n I am aware that there are other commonly used activation functions, but all the ones I could find had one of these issues, which would make training a network to calculate Shapley values difficult.\n Any advice?\n    submitted by    /u/PowNotBigSurprise  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/175kfcg/activation_function_for_generating_shapley_values/",
          "publishedOn": "2023-10-11T17:56:48.000Z",
          "wordCount": 2665,
          "title": "Activation function for generating Shapley values",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17583qj/a_hugging_face_implementation_for_style_gan_to/",
          "author": null,
          "description": "I was thinking to create an app based on style gan which will include facebook , instagram theme and style transfer it with profile pic so shall i create this app or not .I want to know if it will be good idea. \n    submitted by    /u/No_Claim_8651  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17583qj/a_hugging_face_implementation_for_style_gan_to/",
          "publishedOn": "2023-10-11T07:16:48.000Z",
          "wordCount": 2567,
          "title": "A hugging face implementation for style gan to produce user avatar",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/174njqk/riddle_me_this_issues_when_predicting_a_high/",
          "author": null,
          "description": "Hi folks, \n I have observed a strange behavior when implementing a VERY BASIC idea 🙂\n I want to use a fully-connected Neural Network to approximate a sine wave. For that I am sampling 200.000 uniformly distributed points from a wide interval, e.g. [-60,60] and compute the corresponding sin(x) values resulting in the following training data. \n ​\n Training data\n I glimpse into my setup: \n Model:\n nn.Linear(1, 16) nn.Sigmoid() Linear(16, 16) nn.Sigmoid() nn.Linear(16, 8) nn.Sigmoid() nn.Linear(8, 4) nn.Sigmoid() nn.Linear(4, 1) (I also pumped up the network to up to 100 hidden neurons on one layer) \n Number of samples: 200.000 (80% train / 20% test)\n Optimizer: Adam\n Loss: RMSE\n Epochs between 100 - 500\n Learning Rate: 0.02\n Batch Size: 500 - 1000\n ​\n Check out the screenshots below to see the results 😨\n ​\n The predictions are pretty good but the edge areas slow down to a very small value, without any change. This only holds for high-frequency sine waves. If we only consider the train range of [-2*np.pi , 2*np.pi] it works pretty good with small loss.\n ​\n So my questions are: \n 1) Why do we see that behaviour? \n 2) How can we solve it\n ​\n Cheers\n ​\n Prediction 1\n ​\n Prediction 2\n    submitted by    /u/CarKla  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/174njqk/riddle_me_this_issues_when_predicting_a_high/",
          "publishedOn": "2023-10-10T15:08:29.000Z",
          "wordCount": null,
          "title": "Riddle me this: Issues when predicting a high frequency sine wave",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/173asmx/pt_3_inductive_logic_programming_with_lnns/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/173asmx/pt_3_inductive_logic_programming_with_lnns/",
          "publishedOn": "2023-10-08T21:41:32.000Z",
          "wordCount": null,
          "title": "(Pt. 3) Inductive Logic Programming with LNN's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/172yyuh/researchers_create_a_neural_network_for_genomics/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/172yyuh/researchers_create_a_neural_network_for_genomics/",
          "publishedOn": "2023-10-08T13:19:28.000Z",
          "wordCount": null,
          "title": "Researchers create a neural network for genomics that explains how it achieves accurate predictions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/172nugs/decomposing_language_models_into_understandable/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/172nugs/decomposing_language_models_into_understandable/",
          "publishedOn": "2023-10-08T02:27:10.000Z",
          "wordCount": null,
          "title": "Decomposing Language Models Into Understandable Components",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/171etya/sequential_dense_neural_network_for_binary/",
          "author": null,
          "description": "Hello.\n I've developed a simple Neural Recommender System (NRR) with the following architecture:\n  \nInput layer: 38 neurons\n Hidden layer: 19 neurons with ReLU activation function\n Output layer: 1 neuron with a sigmoid activation function\n  \nThe input dataset consists of 39 columns: 38 features and 1 label (with values of 0 or 1). The model is designed to output the probability that a specific input should be classified with label 1.\n Currently, I am experimenting with hyperparameter tuning, adjusting the learning rate, epoch, and batch size. However, I've observed an issue where, with certain combinations of hyperparameters, the maximum probability outputted by the model is not 1, but rather 0.25, for example. How is this possible?\n Thanks\n    submitted by    /u/nllnp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/171etya/sequential_dense_neural_network_for_binary/",
          "publishedOn": "2023-10-06T15:10:25.000Z",
          "wordCount": null,
          "title": "Sequential Dense Neural Network for binary classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/170mb03/openais_justification_for_why_training_data_is/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/170mb03/openais_justification_for_why_training_data_is/",
          "publishedOn": "2023-10-05T16:26:43.000Z",
          "wordCount": null,
          "title": "OpenAI's justification for why training data is fair use, not infringement [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/170lah7/traveling_words_a_geometric_interpretation_of/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/170lah7/traveling_words_a_geometric_interpretation_of/",
          "publishedOn": "2023-10-05T15:45:19.000Z",
          "wordCount": null,
          "title": "Traveling Words: A Geometric Interpretation of Transformers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1700z98/ring_attention_with_blockwise_transformers_for/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1700z98/ring_attention_with_blockwise_transformers_for/",
          "publishedOn": "2023-10-04T22:37:17.000Z",
          "wordCount": null,
          "title": "Ring Attention with Blockwise Transformers for Near-Infinite Context",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16zujr2/think_before_you_speak_training_language_models/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16zujr2/think_before_you_speak_training_language_models/",
          "publishedOn": "2023-10-04T18:20:48.000Z",
          "wordCount": null,
          "title": "Think before you speak: Training Language Models With Pause Tokens",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16zflgl/towards_selfassembling_artificial_neural_networks/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16zflgl/towards_selfassembling_artificial_neural_networks/",
          "publishedOn": "2023-10-04T06:17:09.000Z",
          "wordCount": null,
          "title": "Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16zbvc3/ai_has_been_reading_my_mind/",
          "author": null,
          "description": "I know several people that tell me whenever they say something out loud, they start seeing it advertised to them or on their feed. But for me, if I think of certain things, even if I never said it out loud, it will appear on my feed.. has anything similar been happening to anyone else?\n    submitted by    /u/GuaranteedBigBoy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16zbvc3/ai_has_been_reading_my_mind/",
          "publishedOn": "2023-10-04T02:57:24.000Z",
          "wordCount": null,
          "title": "AI has been reading my mind.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16xxa2r/fishing_with_neural_nets_transforming_ecology/",
          "author": null,
          "description": "submitted by    /u/plutoandmal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16xxa2r/fishing_with_neural_nets_transforming_ecology/",
          "publishedOn": "2023-10-02T13:55:09.000Z",
          "wordCount": 2521,
          "title": "Fishing with Neural Nets | Transforming Ecology with Artificial Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16x87mg/langdiversity_software_to_identify_llm_errors/",
          "author": null,
          "description": "Due to challenges such as hallucination, detecting errors in the output of a given prompt becomes an important challenge. LangDiversity is an implementation of \"diversity measures\" that are domain independent and can be used to measure the uncertainty in the result of a language model.\n ​\n Type pip install langdiversity\n Video: https://www.youtube.com/watch?v=86J_K9mR7lw\n Web: https://neurosymbolic.asu.edu/llm-correction/\n Visit https://github.com/lab-v2/langdiversity\n Read the paper: https://arxiv.org/abs/2308.11189\n https://preview.redd.it/o0v8p9g7tmrb1.png?width=1021&format=png&auto=webp&s=ff1ac672b61f96e4669663410769127066a0674d\n    submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16x87mg/langdiversity_software_to_identify_llm_errors/",
          "publishedOn": "2023-10-01T18:09:41.000Z",
          "wordCount": 2639,
          "title": "LangDiversity: software to identify LLM errors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16ws7ft/equation_for_what_neurons_of_1s_that_attach/",
          "author": null,
          "description": "\" Bio education below *. Summarization: ~1000 IO neurons attach math regions to conscious regions, low cost 1000-electrod microprocessors can run on radio.\n * https://youtube.com/watch?v=bhp2CkNDxME Don't want for self; want for professors and humans who program KUKA's/FANUC's for construction, and for who do calculations/optimizations for CUDA, MS Visual Studio and such, but what go up for experimentation should funds allow.\" sounds fun \n    submitted by    /u/2002LuvAbbaLuvU  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16ws7ft/equation_for_what_neurons_of_1s_that_attach/",
          "publishedOn": "2023-10-01T05:03:19.000Z",
          "wordCount": 2658,
          "title": "Equation for what neurons (of 1s that attach parietal region to conscious brain regions) should attach to microprocessor to offload math functions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16vj0jh/innovative_endeavors_meta_introduces_aipowered/",
          "author": null,
          "description": "submitted by    /u/Allinhalf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16vj0jh/innovative_endeavors_meta_introduces_aipowered/",
          "publishedOn": "2023-09-29T18:16:56.000Z",
          "wordCount": 2594,
          "title": "Innovative Endeavors: Meta Introduces AI-Powered Tools and Smart Glasses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16vcimm/pruning_a_specific_dimension_in_a_neural_network/",
          "author": null,
          "description": "I've been playing around with pruning neural networks. One interesting thing I've found is that pruning the weights with the lowest L1-norm along a specific dimension seems to give better results than simply pruning all of the weights with the lowest L1-norm (which I believe is the standard method; for example this is what torch.nn.utils.prune.l1_unstructured does).\n Does anyone have an explanation for why this might be, or knows of any research in this area?\n I'm aware that structured pruning removes entire channels in a specific dimension. But I'm referring to unstructured pruning here, where I remove a subset of the weights along a specific dimension.\n Admittedly I've only done very limited benchmarking of this. See this repo for my implementation, and some benchmark details.\n    submitted by    /u/Neilf79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16vcimm/pruning_a_specific_dimension_in_a_neural_network/",
          "publishedOn": "2023-09-29T14:04:23.000Z",
          "wordCount": 2708,
          "title": "Pruning a specific dimension in a neural network using L1-norm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16vbmuv/help_understanding_ai_specificaly_cnn_cause_i/",
          "author": null,
          "description": "Hello,\n so i learnt the very basics of ai and im trying to understand how nn works,\n this is what i have figured out so far. \n so if i have a 4x4 image e.g\n 0 1 1 0\n 1 0 0 1\n 1 1 1 1\n 1 0 0 1\n i pass it across a 2x2 kernal e.g\n 1 1\n 0 3\n ​\n and padding it would do \n ​\n dot product of \n 0 1\n 1 0\n ​\n x\n ​\n 1 1\n 0 3\n ​\n is 1\n ​\n ​\n and if we do that to all of them we get a new matrix\n ​\n 1 2 4\n 4 1 3\n 5 4 4\n ​\n ​\n then we have padding same so this becomes\n ​\n 0 0 0 0\n 1 2 4 0\n 4 1 3 0\n 5 4 4 0\n ​\n ​\n we then turn it into a feature map, basically flatenting it to something like this\n 0,0,0,0,1,2,4,0,4,1,3,0,5,4,4,0\n ​\n so the input has 16 features, if we have a layer of 3 nerons that fire with relu activation funciton\n and each weight is alternating between 1 and 2 for simplicity sake . we would do\n 0*1 + 0*2 + 0*1 .... 4*2 + 0*1 = 32\n so if we are using relu, we would do \n is 32 > 0? if so we pass 32 to next neuron if not we pass 0?\n ​\n idk the rest, i guess i forgot what uni taught me 😅 \n ​\n hers a diagram i drew, maybe you can help me figure out hte rest, im confused how the output layer works i guess\n ​\n ​\n ​\n ​\n    submitted by    /u/SaadPaad2003  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16vbmuv/help_understanding_ai_specificaly_cnn_cause_i/",
          "publishedOn": "2023-09-29T13:26:10.000Z",
          "wordCount": 2847,
          "title": "Help understanding ai, Specificaly cnn cause i want to try training a model on mnist data set as my first project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16vbkes/help_understanding_basics_of_neural_networks_cnns/",
          "author": null,
          "description": "Hello,\n so i learnt the very basics of ai and im trying to understand how nn works,\n this is what i have figured out so far. \n so if i have a 4x4 image e.g\n 0 1 1 0\n 1 0 0 1\n 1 1 1 1\n 1 0 0 1\n i pass it across a 2x2 kernal e.g\n 1 1\n 0 3\n ​\n and padding it would do \n ​\n dot product of \n 0 1\n 1 0\n ​\n x\n ​\n 1 1\n 0 3\n ​\n is 1\n ​\n ​\n and if we do that to all of them we get a new matrix\n ​\n 1 2 4\n 4 1 3\n 5 4 4\n ​\n ​\n then we have padding same so this becomes\n ​\n 0 0 0 0\n 1 2 4 0\n 4 1 3 0\n 5 4 4 0\n ​\n ​\n we then turn it into a feature map, basically flatenting it to something like this\n 0,0,0,0,1,2,4,0,4,1,3,0,5,4,4,0\n ​\n so the input has 16 features, if we have a layer of 3 nerons that fire with relu activation funciton\n and each weight is alternating between 1 and 2 for simplicity sake . we would do\n 0*1 + 0*2 + 0*1 .... 4*2 + 0*1 = 32\n so if we are using relu, we would do \n is 32 > 0? if so we pass 32 to next neuron if not we pass 0?\n ​\n idk the rest, i guess i forgot what uni taught me 😅 \n ​\n hers a diagram i drew, maybe you can help me figure out hte rest, im confused how the output layer works i guess\n ​\n ​\n https://preview.redd.it/h07o5y6847rb1.png?width=1859&format=png&auto=webp&s=df1cdf73ea64ff93ac872dfe8248722e8befd31d\n ​\n ​\n    submitted by    /u/WranglerParty5452  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16vbkes/help_understanding_basics_of_neural_networks_cnns/",
          "publishedOn": "2023-09-29T13:23:16.000Z",
          "wordCount": 2836,
          "title": "help understanding basics of neural networks, cnn's to be exact",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16vabmu/adapt_gan/",
          "author": null,
          "description": "Hi everyone,\n Im new to the Neural network and I wanted some advice :\n I wanted to generate grayscale images with certain properties : - distribution of pixels values, space correlation between pixels, etc...\n I already know the type of result that I need, but I wanted to know if a neural network especially a GAN was capable to produce images fitting me requirements.\n I was thinking that maybe I could change the GAN architecture such as :\n 1)the Real data inputs (normally images feed to discriminator) will simply be the statistical parameters that I am expecting.\n 2) I'll add a measure of the various statistical parameters on all the synthetic images generated. \n 3)Finally the discriminator will only based itself on the statistical parameters comparison for weights updates.\n Does such network make sense ? If so I have trouble finding a way of implementing it but that is an other story. Right know I want to know if this is doable ? If not do you have any alternative suggestion for my issue ?\n Thanks all for your advice !\n    submitted by    /u/Hectorite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16vabmu/adapt_gan/",
          "publishedOn": "2023-09-29T12:28:46.000Z",
          "wordCount": 2756,
          "title": "Adapt GAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16v3qvz/why_batch_norm_works/",
          "author": null,
          "description": "submitted by    /u/Personal-Trainer-541  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16v3qvz/why_batch_norm_works/",
          "publishedOn": "2023-09-29T06:11:03.000Z",
          "wordCount": 2576,
          "title": "Why Batch Norm Works",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16tzp4b/how_can_ai_recreate_the_lack_of_information/",
          "author": null,
          "description": "Hey there! Are there guys here who possess a strong grasp of AI neural network logic?\n ​\n I've extracted a character from an anime scene using a mask, and saved it as a PNG sequence which contains solely the anime character along with an alpha (transparent) background.\n ​\n I'm curious about how the Flowframes neural network can recreate the background that was originally behind the character but removed by the mask. It's impossible since the PNG images don't have that background info. \n ​\n Can anyone explain how this works?\n ​\n Attachments: \n - Image #1: \n https://preview.redd.it/z2bypfkstvqb1.png?width=1920&format=png&auto=webp&s=c534167c5ae4129c04f9b8b2fbca3bac350a1d4a\n - Image #2: \n https://preview.redd.it/x5kkzs2ttvqb1.png?width=1920&format=png&auto=webp&s=6838d7ca5e1e4f19ba46c04750fdaea537a787f0\n (Don't mind the black background in the thumbnails, it's a bug, there's actually a transparent background)\n ​\n * Flowframes is a app that utilizes advanced AI frameworks to interpolate videos in order to increase their framerate in the most natural looking way possible.\n    submitted by    /u/drkysqrl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16tzp4b/how_can_ai_recreate_the_lack_of_information/",
          "publishedOn": "2023-09-27T23:25:05.000Z",
          "wordCount": 2713,
          "title": "How can AI recreate the lack of information?",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Seita's Place",
      "feedUrl": "https://danieltakeshi.github.io/feed.xml",
      "siteUrl": "https://danieltakeshi.github.io/",
      "articles": [
        {
          "id": "https://danieltakeshi.github.io/2023/10/09/israel",
          "author": null,
          "description": "I strongly condemn the recent and horrific attack by Hamas against Israel.\nI have some disagreements with the government of Israel. But, I do not support\nsuch an attack.\nAs a point of comparison, I do not always agree with the United States\ngovernment, but I would not be celebrating if Mexico (picking a country at\nrandom) were to suddenly launch bombs towards civilians in Los Angeles and New\nYork City.  Similarly, if the reverse were true, if the United States decided\nto indiscriminately bomb Mexico City, I would oppose that as well.  Feel free\nto replace the relevant actors and repeat as needed.",
          "link": "https://danieltakeshi.github.io/2023/10/09/israel",
          "publishedOn": "2023-10-09T23:00:00.000Z",
          "wordCount": 268,
          "title": "I Condemn the Attack by Hamas",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "VITALab",
      "feedUrl": "https://vitalab.github.io/feed.xml",
      "siteUrl": "https://vitalab.github.io/",
      "articles": []
    },
    {
      "title": "Stories by Andrej Karpathy on Medium",
      "feedUrl": "https://medium.com/feed/@karpathy",
      "siteUrl": "https://medium.com/@karpathy?source=rss-ac9d9a35533e------2",
      "articles": []
    },
    {
      "title": "OpenAI Blog",
      "feedUrl": "https://openai.com/blog/rss",
      "siteUrl": "https://openai.com/blog",
      "articles": [
        {
          "id": "https://openai.com/blog/frontier-risk-and-preparedness",
          "author": null,
          "description": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
          "link": "https://openai.com/blog/frontier-risk-and-preparedness",
          "publishedOn": "2023-10-26T07:00:00.000Z",
          "wordCount": 570,
          "title": "Frontier risk and preparedness",
          "imageUrl": "https://images.openai.com/blob/1f19f98e-798a-4d80-b1c6-431b75d6b41c/frontier-risk-and-preparedness.png?trim=452%2C0%2C443%2C0&width=1000&quality=80"
        },
        {
          "id": "https://openai.com/blog/frontier-model-forum-updates",
          "author": null,
          "description": "Together with Anthropic, Google, and Microsoft, we’re announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
          "link": "https://openai.com/blog/frontier-model-forum-updates",
          "publishedOn": "2023-10-25T07:00:00.000Z",
          "wordCount": 1191,
          "title": "Frontier Model Forum updates",
          "imageUrl": "https://images.openai.com/blob/4d1e00c7-f843-44a2-81a8-890b84b94a2b/frontier-model-forum-updates.png?trim=0%2C0%2C0%2C0&width=1000&quality=80"
        },
        {
          "id": "https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
          "author": null,
          "description": "We developed a safety mitigation stack to ready DALL·E 3 for wider release and are sharing updates on our provenance research.",
          "link": "https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
          "publishedOn": "2023-10-19T07:00:00.000Z",
          "wordCount": 865,
          "title": "DALL·E 3 is now available in ChatGPT Plus and Enterprise",
          "imageUrl": "https://images.openai.com/blob/f698e023-3373-4385-93f3-f0e0a24adbf0/VALERIECloudAstronaut.png?trim=55%2C0%2C45%2C148&width=1000&quality=80"
        },
        {
          "id": "https://openai.com/research/dall-e-3-system-card",
          "author": null,
          "description": "",
          "link": "https://openai.com/research/dall-e-3-system-card",
          "publishedOn": "2023-10-03T07:00:00.000Z",
          "wordCount": 150,
          "title": "DALL·E 3 system card",
          "imageUrl": "https://images.openai.com/blob/de9e8dc2-a39b-46c9-b7a0-54dd5c56b1df/dall-e-3-system-card.png?trim=0%2C0%2C0%2C0&width=1000&quality=80"
        }
      ]
    },
    {
      "title": "Microsoft Research",
      "feedUrl": "https://www.microsoft.com/en-us/research/feed",
      "siteUrl": "https://www.microsoft.com/en-us/research/",
      "articles": [
        {
          "id": "https://www.microsoft.com/en-us/research/?p=978618",
          "author": "Brenda Potts",
          "description": "This research paper was presented at the 29th ACM Symposium on Operating Systems Principles (opens in new tab) (SOSP 2023), the premier forum for the theory and practice of computer systems software. For millennia, data has woven itself into every facet of our lives, from business and academia to personal spheres. Our production of data […]\nThe post Project Silica: Sustainable cloud archival storage in glass appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/project-silica-sustainable-cloud-archival-storage-in-glass/",
          "publishedOn": "2023-10-26T16:00:00.000Z",
          "wordCount": 3066,
          "title": "Project Silica: Sustainable cloud archival storage in glass",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/Project-Silica-2023-TWLIFB-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=978693",
          "author": "Alyssa Hughes",
          "description": "In this issue: Kosmos-2.5: A Multimodal Literate Model; Can vine copulas explain complex relationships of weather variables; New system accelerates the adaptive training process; Structural inequalities and relational labor in the influencer industry.\nThe post Research Focus: Week of October 23, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-23-2023/",
          "publishedOn": "2023-10-25T16:00:00.000Z",
          "wordCount": 3051,
          "title": "Research Focus: Week of October 23, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF27-BlogHeroFeature-1400x788-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=977154",
          "author": "Alyssa Hughes",
          "description": "Today on “Abstracts,” Partner Research Manager Andy Gordon & Senior Researcher Carina Negreanu explore new work introducing co-audit, a term for any tool-assisted experience that helps users of generative AI find and fix mistakes in AI output.\nThe post Abstracts: October 23, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/abstracts-october-23-2023/",
          "publishedOn": "2023-10-23T13:00:00.000Z",
          "wordCount": 4687,
          "title": "Abstracts: October 23, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Episode1_Abstracts_TW_LI_FB_1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=975909",
          "author": "Brenda Potts",
          "description": "In this new Microsoft Research Podcast series What’s Your Story, Lab Director Johannes Gehrke explores the who behind the technical and scientific advancements helping to reshape the world. He talks to members of the research community at Microsoft about what motivates their work and how they got where they are today.  Ranveer Chandra is Managing […]\nThe post What’s Your Story: Ranveer Chandra appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/whats-your-story-ranveer-chandra/",
          "publishedOn": "2023-10-19T13:12:44.000Z",
          "wordCount": 9161,
          "title": "What’s Your Story: Ranveer Chandra",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/Ranveer_WYS_TW_LI_FB_1200x627.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=976521",
          "author": "Brenda Potts",
          "description": "This position research paper was presented at the 26th ACM Conference on Computer-Supported Cooperative Work and Social Computing (opens in new tab) (CSCW 2023), a premier venue for research on the design and use of technologies that affect groups, organizations, and communities. In the business world, measuring success is as critical as selecting the right […]\nThe post Understanding the user: How the Enterprise System Usability Scale aligns with user reality appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/understanding-the-user-how-the-enterprise-system-usability-scale-esus-aligns-with-user-reality/",
          "publishedOn": "2023-10-18T16:00:00.000Z",
          "wordCount": 2867,
          "title": "Understanding the user: How the Enterprise System Usability Scale aligns with user reality",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG-CSCW-2023-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=971940",
          "author": "Alyssa Hughes",
          "description": "How trustworthy are generative pre-trained transformer (GPT) models? To answer this question, University of Illinois Urbana-Champaign, together with Stanford University, University of California, Berkeley, Center for AI Safety, and Microsoft Research, released a comprehensive trustworthiness evaluation platform for large language models (LLMs), which is presented in the recent paper: DecodingTrust: A Comprehensive Assessment of Trustworthiness […]\nThe post DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models/",
          "publishedOn": "2023-10-16T16:00:00.000Z",
          "wordCount": 3278,
          "title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG-TWLIFB-no-text-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/microsoft-at-vl-hcc-2023-focus-on-co-audit-tools-for-spreadsheets/",
          "author": "Brenda Potts",
          "description": "These research papers were presented at the IEEE Symposium on Visual Languages and Human-Centric Computing (opens in new tab) (VL/HCC 2023), a premier forum for design, theory, and application of computing technologies for programming, modelling, and communication. Large language models (LLMs) have revolutionized the way novice programmers and everyday computer users tap into the capabilities […]\nThe post Microsoft at VL/HCC 2023: Focus on co-audit tools for spreadsheets appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/microsoft-at-vl-hcc-2023-focus-on-co-audit-tools-for-spreadsheets/",
          "publishedOn": "2023-10-12T16:00:00.000Z",
          "wordCount": 3033,
          "title": "Microsoft at VL/HCC 2023: Focus on co-audit tools for spreadsheets",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-IEEE-2023-TWLIFB-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-9-2023/",
          "author": "Alyssa Hughes",
          "description": "Research Focus: Principal researcher Lester Mackey recognized for pioneering statistical and ML techniques; Pareto frontiers in neural feature learning; structural inequality in the influencer industry; new research on cardinality estimation.\nThe post Research Focus: Week of October 9, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-9-2023/",
          "publishedOn": "2023-10-11T16:02:41.000Z",
          "wordCount": 2675,
          "title": "Research Focus: Week of October 9, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=970974",
          "author": "Alyssa Hughes",
          "description": "Researcher Dr. Sheng Zhang joins “Abstracts”—your source for cutting-edge research in brief—to discuss a recent paper on distilling large language models into smaller, more efficient ones capable of excelling in broad application classes.\nThe post Abstracts: October 9, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/abstracts-october-9-2023/",
          "publishedOn": "2023-10-09T14:35:09.000Z",
          "wordCount": 3858,
          "title": "Abstracts: October 9, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Episode3_Abstracts_Hero_Feature_No_Text_1400x788.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/efficient-and-hardware-friendly-neural-architecture-search-with-spaceevo/",
          "author": "Alyssa Hughes",
          "description": "A persistent challenge in deep learning is optimizing neural network models for diverse hardware configurations, balancing performance and low latency. Learn how SpaceEvo automates hardware-aware neural architecture search to fine-tune DNN models for swift execution on diverse devices.\nThe post Efficient and hardware-friendly neural architecture search with SpaceEvo appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/efficient-and-hardware-friendly-neural-architecture-search-with-spaceevo/",
          "publishedOn": "2023-10-06T16:00:00.000Z",
          "wordCount": 2958,
          "title": "Efficient and hardware-friendly neural architecture search with SpaceEvo",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ICCV-SpaceEVO-2023-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=972234",
          "author": "Alyssa Hughes",
          "description": "HoloAssist is a new multimodal dataset consisting of 166 hours of interactive task executions with 222 participants. Discover how it offers invaluable data to advance the capabilities of next-gen AI copilots for real-world tasks.\nThe post HoloAssist: A multimodal dataset for next-gen AI copilots for the physical world appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/holoassist-a-multimodal-dataset-for-next-gen-ai-copilots-for-the-physical-world/",
          "publishedOn": "2023-10-05T16:00:00.000Z",
          "wordCount": 3061,
          "title": "HoloAssist: A multimodal dataset for next-gen AI copilots for the physical world",
          "enclosure": {
            "url": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/holoassist4kzoom.mp4",
            "length": "120799231",
            "type": "video/mp4"
          },
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-TWLIFB-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=972015",
          "author": "Alyssa Hughes",
          "description": "Connecting with researchers, collaborating across disciplines, and exploring a new city—PhD students Jennifer Scurrell and Alejandro Cuevas talk to Senior Researcher Madeleine Daepp about the internship experience at Microsoft Research.\nThe post Intern Insights: Dr. Madeleine Daepp with Jennifer Scurrell and Alejandro Cuevas appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/intern-insights-dr-madeleine-daepp-with-jennifer-scurrell-and-alejandro-cuevas/",
          "publishedOn": "2023-10-05T14:31:39.000Z",
          "wordCount": 8728,
          "title": "Intern Insights: Dr. Madeleine Daepp with Jennifer Scurrell and Alejandro Cuevas",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/Madeline_Insights_TW_LI_FB_1200x627.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=971679",
          "author": "Alyssa Hughes",
          "description": "A diverse research ecosystem is essential to realizing the promise of AI. Accelerate Foundation Models Research aims to expand access to powerful models, engaging academics outside of computer science to pursue a broad range of important opportunities.\nThe post Accelerate Foundation Models Research: Supporting a global academic research ecosystem for AI appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/accelerate-foundation-models-research-supporting-a-global-academic-research-ecosystem-for-ai/",
          "publishedOn": "2023-10-03T16:06:59.000Z",
          "wordCount": 3056,
          "title": "Accelerate Foundation Models Research: Supporting a global academic research ecosystem for AI",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/BLG_-AFMR-2023-TWLIFB-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/podcast/ai-frontiers-measuring-and-mitigating-harms-with-hanna-wallach/",
          "author": "Brenda Potts",
          "description": "Powerful large-scale AI models like GPT-4 are showing dramatic improvements in reasoning, problem-solving, and language capabilities. This marks a phase change for artificial intelligence—and a signal of accelerating progress to come.    In this Microsoft Research Podcast series, AI scientist and engineer Ashley Llorens hosts conversations with his collaborators and colleagues about what these models—and the […]\nThe post AI Frontiers: Measuring and mitigating harms with Hanna Wallach appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/ai-frontiers-measuring-and-mitigating-harms-with-hanna-wallach/",
          "publishedOn": "2023-09-28T14:21:56.000Z",
          "wordCount": 8695,
          "title": "AI Frontiers: Measuring and mitigating harms with Hanna Wallach",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Hanna_Wallach_AI_Frontiers_TW_LI_FB_1200x627_With_Name.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-25-2023/",
          "author": "Brenda Potts",
          "description": "Chunked prefills & decode-maximal batching boost LLM inference; DragNUWA combines text, image, and trajectory for fine-grained video content control; reconstructing images from human brain signals; structural inequalities in creator-audience relationships.\nThe post Research Focus: Week of September 25, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-25-2023/",
          "publishedOn": "2023-09-27T16:00:00.000Z",
          "wordCount": 2643,
          "title": "Research Focus: Week of September 25, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/RF25-blog-social-1200x627-1.jpg"
        }
      ]
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "http://feeds.feedburner.com/blogspot/gJZg",
      "siteUrl": "http://blog.research.google/",
      "articles": [
        {
          "id": "http://blog.research.google/2023/10/batch-calibration-rethinking.html",
          "author": null,
          "description": "Posted by Han Zhou, Student Researcher, and Subhrajit Roy, Senior Research Scientist, Google Research\n\n\n\n\n\nPrompting large language models (LLMs) has become an efficient learning paradigm for adapting LLMs to a new task by conditioning on human-designed instructions. The remarkable in-context learning (ICL) ability of LLMs also leads to efficient few-shot learners that can generalize from few-shot input-label pairs. However, the predictions of LLMs are highly sensitive and even biased to the choice of templates, label spaces (such as yes/no, true/false, correct/incorrect), and demonstration examples, resulting in unexpected performance degradation and barriers for pursuing robust LLM applications. To address this problem, calibration methods have been developed to mitigate the effects of t…",
          "link": "http://blog.research.google/2023/10/batch-calibration-rethinking.html",
          "publishedOn": "2023-10-13T18:01:00.000Z",
          "wordCount": 27831,
          "title": "Batch calibration: Rethinking calibration for in-context learning and prompt engineering",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhcUnpQACR3ZhIfLnnazC6jATK0TZkwm-zGcHW0iMGYkd5bOrHtp0UAzDZ51hkI-ZesK4PAW_zn29G7r9hnq6bsNrp54dCEoiinN7l2bkNkIZVOj18ym1WQBk4QZfB_LlJnImIms-LSh6E88bcDP6NZ3yDssRhyJGUFgt2IhZurObVP8jn3Bb4aiAnB_Ysg/w1200-h630-p-k-no-nu/Screenshot%202023-10-13%20at%2010.57.44%20AM.png"
        },
        {
          "id": "http://blog.research.google/2023/10/developing-industrial-use-cases-for.html",
          "author": null,
          "description": "Posted by Nicholas Rubin, Senior Research Scientist, and Ryan Babbush, Head of Quantum Algorithms, Quantum AI Team\n\n\n\n\n\nIf you’ve paid attention to the quantum computing space, you’ve heard the claim that in the future, quantum computers will solve certain problems exponentially more efficiently than classical computers can. They have the potential to transform many industries, from pharmaceuticals to energy.\n\n\n\nFor the most part, these claims have rested on arguments about the asymptotic scaling of algorithms as the problem size approaches infinity, but this tells us very little about the practical performance of quantum computers for finite-sized problems. We want to be more concrete: Exactly which problems are quantum computers more suited to tackle than their classical counterparts, an…",
          "link": "http://blog.research.google/2023/10/developing-industrial-use-cases-for.html",
          "publishedOn": "2023-10-12T20:56:00.002Z",
          "wordCount": 28273,
          "title": "Developing industrial use cases for physical simulation on future error-corrected quantum computers",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEigr1Q582VTmDaeIOT7X-hnXjEJ8QW237xvxICJqe-ZKg2zBAQn9gPfoAbLsJXmG8IFQ5B0ysoh7O60-U4mMKA4mJxB92Tm5MnY50n8B7dWpHwap3lk9_at6c4oEZ0lqjpeS-sqRZyKdyu1UjzJkbb2zRJp9nsZvkikxlK0eTZBjB5hJqvOtbaFPyWe7OfF/w1200-h630-p-k-no-nu/StoppingPower.jpg"
        },
        {
          "id": "http://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html",
          "author": null,
          "description": "Posted by Sagar M. Waghmare, Senior Software Engineer, and Kimberly Wilber, Software Engineer, Google Research, Perception Team\n\n\n\n\nAs most people navigate their everyday world, they process visual input from the environment using an eye-level perspective. Unlike robots and self-driving cars, people don't have any \"out-of-body\" sensors to help guide them. Instead, a person’s sensory input is completely \"egocentric\", or \"from the self.\" This also applies to new technologies that understand the world around us from a human-like perspective, e.g., robots navigating through unknown buildings, AR glasses that highlight objects, or assistive technology to help people run independently.\n\n\n\n\n\nIn computer vision, scene understanding is the subfield that studies how visible objects relate to the sce…",
          "link": "http://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html",
          "publishedOn": "2023-10-09T19:17:00.000Z",
          "wordCount": 27977,
          "title": "SANPO: A Scene understanding, Accessibility, Navigation, Pathfinding, & Obstacle avoidance dataset",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh10zxbymBGZgjXFHDrw-CdxlVL7nRi6yjaI3w3X_x5pjxn8UWA7NnymAqMXomfjSBXWVDQ4czo8nqINhxzIPLVx2Uv1l8RDQAbikuWWjIt9IwxSIuSlEtJ5AJwOJkdaKPwzUdu9BwkJJP1gDj2UJQpkJ15ELGjSKHMl9ce0_470SwRz5snz32lV-vSlMd2/w1200-h630-p-k-no-nu/SANPOHero.gif"
        },
        {
          "id": "http://blog.research.google/2023/10/scalable-spherical-cnns-for-scientific.html",
          "author": null,
          "description": "Posted by Carlos Esteves and Ameesh Makadia, Research Scientists, Google Research, Athena Team\n\n\n\n\nTypical deep learning models for computer vision, like convolutional neural networks (CNNs) and vision transformers (ViT), process signals assuming planar (flat) spaces. For example, digital images are represented as a grid of pixels on a plane. However, this type of data makes up only a fraction of the data we encounter in scientific applications. Variables sampled from the Earth's atmosphere, like temperature and humidity, are naturally represented on the sphere. Some kinds of cosmological data and panoramic photos are also spherical signals, and are better treated as such. \n\n\n\nUsing methods designed for planar images to process spherical signals is problematic for a couple of reasons. Firs…",
          "link": "http://blog.research.google/2023/10/scalable-spherical-cnns-for-scientific.html",
          "publishedOn": "2023-10-04T17:26:00.003Z",
          "wordCount": 27683,
          "title": "Scalable spherical CNNs for scientific applications",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiISXk_mf90TkNUcODcg-c9wYJ70zgm713RvUoRkPkkjnia1fO4P97T1icROacexZlBUsovSg8KCNNHzq2tPacdxHLuwUeW1Q2BIFi6bVw6c1au-9_umDgedCgx2RPogqqhPqDZaP-Xwj1ShADnPFRKBQVS0r1M3oOSQw8WA8nUE-Wa8sAnhTYNuWlwXN57/w1200-h630-p-k-no-nu/image2.gif"
        },
        {
          "id": "http://blog.research.google/2023/10/google-at-iccv-2023.html",
          "author": null,
          "description": "Posted by Shaina Mehta, Program Manager, Google\n\n\n\n\nGoogle is proud to be a Platinum Sponsor of the International Conference on Computer Vision (ICCV 2023), a premier annual conference, which is being held this week in Paris, France. As a leader in computer vision research, Google has a strong presence at this year’s conference with 60 accepted papers and active involvement in 27 workshops and tutorials. Google is also proud to be a Platinum Sponsor for the LatinX in CV workshop. We look forward to sharing some of our extensive computer vision research and expanding our partnership with the broader research community. \n\n\n\nAttending ICCV 2023? We hope you’ll visit the Google booth to chat with researchers who are actively pursuing the latest innovations in computer vision, and check out som…",
          "link": "http://blog.research.google/2023/10/google-at-iccv-2023.html",
          "publishedOn": "2023-10-02T07:51:00.001Z",
          "wordCount": 28288,
          "title": "Google at ICCV 2023",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhVnC8dDc8c44GFT7cAZh8PfC8_Mpt4h1rhl-uNMNGoGlNCAZVsT51z89pMqEcVgwa7UPUuvXlr07PpOJlxomCAyRRTOEssXQxDwm4SX8J4JC_63fKWKywHLuqPHBLRZLl4yYIC311eAXC4r47i1zeZoPg2OXhjxuBmzVXCFn5MrJtH7QhZtMLKzzFvXyvx/w1200-h630-p-k-no-nu/ICCV%20hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/09/dynibar-space-time-view-synthesis-from.html",
          "author": null,
          "description": "Posted by Zhengqi Li and Noah Snavely, Research Scientists, Google Research\n\n\n\n\n\n\n\nA mobile phone’s camera is a powerful tool for capturing everyday moments. However, capturing a dynamic scene using a single camera is fundamentally limited. For instance, if we wanted to adjust the camera motion or timing of a recorded video (e.g., to freeze time while sweeping the camera around to highlight a dramatic moment), we would typically need an expensive Hollywood setup with a synchronized camera rig. Would it be possible to achieve similar effects solely from a video captured using a mobile phone’s camera, without a Hollywood budget?\n\n\n\nIn “DynIBaR: Neural Dynamic Image-Based Rendering”, a best paper honorable mention at CVPR 2023, we describe a new method that generates photorealistic free-viewp…",
          "link": "http://blog.research.google/2023/09/dynibar-space-time-view-synthesis-from.html",
          "publishedOn": "2023-09-28T20:01:00.000Z",
          "wordCount": 27708,
          "title": "DynIBaR: Space-time view synthesis from videos of dynamic scenes",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGX53UfU9eWiSTRWdkrUWNln3KGyagkwfUi_38zEihOJ2qLkmQ-3yNsuJJ7SkJ-BTLlVrxJlyoEYl7-tAer6v4MnIAw49TWLGWa8cFgl_c_2WUJqw1O3J8nVhU-VtVwO5Z-bq7rH6pZj7APe5yDZCUSZyeDO39shlGFkVsSQDd1ZWYUT0eDmeJ9JLoWlA3/w1200-h630-p-k-no-nu/hero.gif"
        },
        {
          "id": "http://blog.research.google/2023/09/re-weighted-gradient-descent-via.html",
          "author": null,
          "description": "Ramnath Kumar, Pre-Doctoral Researcher, and Arun Sai Suggala, Research Scientist, Google Research\n\n\n\n\n\nDeep neural networks (DNNs) have become essential for solving a wide range of tasks, from standard supervised learning (image classification using ViT) to meta-learning. The most commonly-used paradigm for learning DNNs is empirical risk minimization (ERM), which aims to identify a network that minimizes the average loss on training data points. Several algorithms, including stochastic gradient descent (SGD), Adam, and Adagrad, have been proposed for solving ERM. However, a drawback of ERM is that it weights all the samples equally, often ignoring the rare and more difficult samples, and focusing on the easier and abundant samples. This leads to suboptimal performance on unseen data, espe…",
          "link": "http://blog.research.google/2023/09/re-weighted-gradient-descent-via.html",
          "publishedOn": "2023-09-28T18:16:00.002Z",
          "wordCount": 27704,
          "title": "Re-weighted gradient descent via distributionally robust optimization",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhONjsYNtXi5AX4ZZ6qPfdY2Gwt2W5xZy1PF1m9ZaxucZtRZ5ZzmsNzHNNWkCKcpX1_n15DkZCR59ivF_uDCUUmbdijaAuiK3tlC9HahtKc1s1r6pQWwbwMhnuNK3Guu5G5QigWU6p4yaJXCBLvIosDHXwtyhxMVfplzK4wTXiwCwOGo1B2aFidcgtaZfN_/w1200-h630-p-k-no-nu/hero%20RGD.jpg"
        }
      ]
    },
    {
      "title": "fast.ai",
      "feedUrl": "https://www.fast.ai/atom.xml",
      "siteUrl": "https://www.fast.ai/atom.xml",
      "articles": [
        {
          "id": "https://www.fast.ai/2022/09/06/homeschooling/",
          "author": null,
          "description": "My husband Jeremy and I never intended to homeschool, and yet we have now, unexpectedly, committed to homeschooling long-term. Prior to the pandemic, we both worked full-time in careers that we loved and found meaningful, and we sent our daughter to a full-day Montessori school. Although I struggled with significant health issues, I felt unbelievably lucky and fulfilled in both my family life and my professional life. The pandemic upended my careful balance. Every family is different, with different needs, circumstances, and constraints, and what works for one may not work for others. My intention here is primarily to share the journey of my own (very privileged) family.\n\n  \n\n\nOur unplanned introduction to homeschooling\nFor the first year of the pandemic, most schools in California, where …",
          "link": "https://www.fast.ai/2022/09/06/homeschooling/",
          "publishedOn": "2022-09-05T14:00:00.000Z",
          "wordCount": 2118,
          "title": "My family's unlikely homeschooling journey",
          "imageUrl": null
        },
        {
          "id": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "author": null,
          "description": "Jupyter notebooks don’t work with git by default. With nbdev2, the Jupyter+git problem has been totally solved. It provides a set of hooks which provide clean git diffs, solve most git conflicts automatically, and ensure that any remaining conflicts can be resolved entirely within the standard Jupyter notebook environment. To get started, follow the directions on Git-friendly Jupyter.\nContents\nThe Jupyter+git problem\nThe solution    \nThe nbdev2 git merge driver\nThe nbdev2 Jupyter save hook\nBackground\nThe result\nPostscript: other Jupyter+git tools    \nReviewNB\nAn alternative solution: Jupytext\nnbdime\nThe Jupyter+git problem\nJupyter notebooks are a powerful tool for scientists, engineers, technical writers, students, teachers, and more. They provide an ideal notebook environment for interact…",
          "link": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "publishedOn": "2022-08-24T14:00:00.000Z",
          "wordCount": 2227,
          "title": "The Jupyter+git problem is now solved",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Reinforcement Learning",
      "feedUrl": "https://www.reddit.com/r/reinforcementlearning/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/reinforcementlearning/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17h3l5c/where_to_start_with_debugging/",
          "author": null,
          "description": "I am working on a project using reinforcement learning, where a tensorflow DQN agent is being trained to choose from an action space of 16 different actions. The agent exhibits the following behavior during evaluation: for each evaluation run the agent only chooses one action regardless of the state, the action could change or remain the same for the following runs, however, for any specific run the action chosen is the same.\n Where should I start debugging?\n    submitted by    /u/Realistic_Mobile_183  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17h3l5c/where_to_start_with_debugging/",
          "publishedOn": "2023-10-26T18:51:08.000Z",
          "wordCount": null,
          "title": "Where to start with debugging?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17h2xoe/how_to_cluster_with_respect_to_the_transition/",
          "author": null,
          "description": "Hello, I have an environment in which the transition function changed depending on which state I am.\n I want to be able to cluster with respect to it. I have been trying to do this since quite a while but cannot find a way to do it, do you have any hints or suggestions?\n    submitted by    /u/Fragore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17h2xoe/how_to_cluster_with_respect_to_the_transition/",
          "publishedOn": "2023-10-26T18:22:31.000Z",
          "wordCount": null,
          "title": "How to cluster with respect to the transition function of a RL environment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17h2vjh/stuck_with_windowswsl_environment_help_needed/",
          "author": null,
          "description": "So I've started on trying to work on a custom game environment, and for the most part it's *mostly* done. One issue I have is getting MARLlib to run on windows. I know that it's not meant to, so I tried to use WSL to do it, but unfortunately pydirectinput doesn't work via WSL, so I don't know how to proceed further. Do I need to find a way to connect my windows machine which will play the game, and wsl which will probably run MARLlib? If so could anyone guide me to any resources for this? Trying a VM is a no go because the game is old and doesn't run on linux.\n Any help would be much appreciated.\n    submitted by    /u/EquivalentCurious745  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17h2vjh/stuck_with_windowswsl_environment_help_needed/",
          "publishedOn": "2023-10-26T18:19:59.000Z",
          "wordCount": null,
          "title": "Stuck with windows/wsl environment - help needed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17g2d3r/the_right_to_perform_rl_on_games/",
          "author": null,
          "description": "Hi all,\n I'm new to learning RL. I want to train an agent to clear a game such as vampire survivor, super mario brothers, etc, as my first research/project. I talked with my tutor , he reminded me to pay attention to copyright issues and that I needed a permission to use these works for training.\n I guess I could get permission by asking the game's author directly, but before that, or for games produced by some big companies, where can I find information about the rights?\n Although reading the game's memory is a challenge for me, it's cool to see a agent clear a game.\n    submitted by    /u/Ruine_fff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17g2d3r/the_right_to_perform_rl_on_games/",
          "publishedOn": "2023-10-25T11:16:08.000Z",
          "wordCount": null,
          "title": "The right to perform RL on games",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17g0snq/building_doom_with_ai_enemies/",
          "author": null,
          "description": "I'm planning to go down the rabbit hole of using RL to train agents in doom/vizdoom\n The goal would be to create a version of doom where the enemies have AI and are adaptive.\n Doom and Doom 2 are some of my all time classic favorites. There are people still making maps to this day!\n Let me know on what you think about the idea?\n Project plan - Nov 2023 : RL refresher from the David Silver RL course on YouTube Dec 2023 : start working on openAI and stablebaselines3 and watch Nicholas Renotte's videos Jan 2024 : play around with the Doom WAD and try to see if you can make changes to the doom engine + Training and setting up custom env Feb 2024 : hopefully first level with enemy AI created Mar 2024 : release fully completed open source version of the game\n Background: I work at a hedge fund, have some basics on reimbursement learning, although it has been a long long time.\n Time is a bit limited after 12 hours or work and 2 hours of gym (the real human world one) so kinda stretching this out\n Any suggestions are welcome. Any courses, books, libraries and tools you'd suggest?\n    submitted by    /u/Sahil231090  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17g0snq/building_doom_with_ai_enemies/",
          "publishedOn": "2023-10-25T09:25:38.000Z",
          "wordCount": null,
          "title": "Building Doom with AI enemies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17frz4s/surprise_for_learning/",
          "author": null,
          "description": "I was recently listening to a TalkRL podcast where Danijar Hafner explains that Minecraft as a learning environment is hard because of sparse rewards (30k steps before finding a diamond). Coincidentally, I was reading a collection neuroscience articles today where surprise or novel events are a major factor in learning and encoding memory.\n Does anyone know of RL algorithms that learn based on prediction error (i.e. \"surprise\") in addition to rewards?\n    submitted by    /u/CognitoIngeniarius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17frz4s/surprise_for_learning/",
          "publishedOn": "2023-10-25T00:27:09.000Z",
          "wordCount": null,
          "title": "\"Surprise\" for learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17fp4yj/rewards_in_montezumas_revenge/",
          "author": null,
          "description": "Hello all, \n I'm working on Montezuma's Revenge using the Gymnasium API. I wonder if there's anyone here that knows the numerical value of the rewards? And if so, how they are typically scaled down. \n ​\n Thanks!\n ​\n G_bes \n    submitted by    /u/G_bes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17fp4yj/rewards_in_montezumas_revenge/",
          "publishedOn": "2023-10-24T22:17:22.000Z",
          "wordCount": null,
          "title": "Rewards in Montezuma's Revenge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17fef8r/the_n_implementation_details_of_rlhf_with_ppo/",
          "author": null,
          "description": "submitted by    /u/vwxyzjn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17fef8r/the_n_implementation_details_of_rlhf_with_ppo/",
          "publishedOn": "2023-10-24T14:41:23.000Z",
          "wordCount": null,
          "title": "The N Implementation Details of RLHF with PPO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17f6ewb/creating_a_custom_environment_in_unreal_engine_5/",
          "author": null,
          "description": "Hello, I would like to create my own environment (Maze), in which I would like to train my drone using reinforcement learning, I am kind of new and I don't know how can I set the state space, rewards, and if I would like to use BS3 for training then how can I connect the environment? And for the agent which is the drone, should i just do the AirSim build.cmd and take the agent from there and place the starting position flag or what? I am a bit lost and I can't find tutorials on how to do this, I'd appreciate it if you could provide some guidance. Thanks in advance.\n    submitted by    /u/Gabii99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17f6ewb/creating_a_custom_environment_in_unreal_engine_5/",
          "publishedOn": "2023-10-24T06:37:19.000Z",
          "wordCount": null,
          "title": "Creating a Custom Environment in Unreal Engine 5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17eslsx/how_to_properly_evaluate_competitive_marl/",
          "author": null,
          "description": "Hello, everyone! I'm building a MARL agent for a zero-sum game and I'm having a hard time evaluating it.\n I managed to quickly train it for a simple case and I could manually verify that it was actually learning the optimal decision making because I already know how the game works and, for this simple case, I know that there actually is a mathematically correct way to play it (from both sides) and how it should be played, but that isn't true for most cases (and even if it was, I wouldn't be able to manually verify thousands of games). To complicate things even more, there are billions and billions of possible initial states.\n For single-agent RL, I could set a reward threshold (if I knew which was the maximum reward possible) or at least I could set a maximum time of \"no improvement\" but, in a zero-sum game, the sum of the policy rewards is, well, zero.\n I could think of two solutions:\n  \nEvaluate convergence to Nash Equilibrium on a subset of the possible initial states, which could be a problem because I'm not sure if the game dynamics guarantee the existance of Nash Equilibria;\n Evaluate convergence of the winrate of the trained agent against a \"hand-crafted\" baseline agent, which could be a problem because the quality of this evaluation method could depend on how well I can make this baseline agent (which won't be even close to optimal, otherwise I wouldn't be training an agent).\n  \nAny thoughts?\n    submitted by    /u/victorsevero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17eslsx/how_to_properly_evaluate_competitive_marl/",
          "publishedOn": "2023-10-23T19:20:29.000Z",
          "wordCount": null,
          "title": "How to properly evaluate competitive MARL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17er4jp/programmatic_backdoors_dnns_can_use_sgd_to_run/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17er4jp/programmatic_backdoors_dnns_can_use_sgd_to_run/",
          "publishedOn": "2023-10-23T18:18:22.000Z",
          "wordCount": null,
          "title": "Programmatic backdoors: DNNs can use SGD to run arbitrary stateful computation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17eqj5i/in_your_opinion_which_is_the_most_beautiful_form/",
          "author": null,
          "description": "Didn't see anything about this kind of post in the rules\n I'm asking for a tattoo idea haha\n    submitted by    /u/victorsevero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17eqj5i/in_your_opinion_which_is_the_most_beautiful_form/",
          "publishedOn": "2023-10-23T17:53:06.000Z",
          "wordCount": null,
          "title": "In your opinion, which is the most beautiful form of the Bellman Equation and why?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ej7ri/inverted_pendulum_swingup_problem_not_converging/",
          "author": null,
          "description": "I am making a thesis about using RL to solve the inverted pendulum swing-up problem. I have tried using TD3, SAC, and TD3-Fork. In my testing, TD3-Fork worked best, I think SAC would also work if I am able to tune the hyperparameters correctly. \n I would like a similar trained agent to td3 converged where the agent balances the pole almost indefinitely. I have tried the hyperparameters from the website and also different hyperparameters but it has not converged. I am wondering if I am missing something or if there is anything I can do to improve the agent. I have been thinking of using HER instead of FORK. Any help or advice would be appreciated.\n training reward data\n The 'maximum' reward that I could get in the simulation is >880. The reward function that I used is -[cos(theta) + 10(|x| > 0.9) + 10(|theta_dt| > 18)]. However, from the data above it only converges to about 837 max and rarely reaches >900.\n trained td3 fork agent\n    submitted by    /u/YEEETTT0708  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ej7ri/inverted_pendulum_swingup_problem_not_converging/",
          "publishedOn": "2023-10-23T12:29:00.000Z",
          "wordCount": null,
          "title": "Inverted pendulum swing-up problem not converging to global optimum using SAC or TD3.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17egoiw/godot_enables_me_to_do_pure_c_deep_reinforcement/",
          "author": null,
          "description": "submitted by    /u/Vae94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17egoiw/godot_enables_me_to_do_pure_c_deep_reinforcement/",
          "publishedOn": "2023-10-23T09:55:36.000Z",
          "wordCount": null,
          "title": "Godot enables me to do pure C# Deep reinforcement learning.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17e8no8/r_demo_of_flowlenia_towards_openended_evolution/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17e8no8/r_demo_of_flowlenia_towards_openended_evolution/",
          "publishedOn": "2023-10-23T01:19:37.000Z",
          "wordCount": null,
          "title": "[R] Demo of “Flow-Lenia: Towards open-ended evolution in cellular automata through mass conservation and parameter localization” (link to paper in the comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17dzk9i/how_the_self_play_algorithm_masters_multiagent_ai/",
          "author": null,
          "description": "submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17dzk9i/how_the_self_play_algorithm_masters_multiagent_ai/",
          "publishedOn": "2023-10-22T18:17:02.000Z",
          "wordCount": null,
          "title": "How the Self Play algorithm masters Multi-Agent AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17dpqyl/mujoco_rl_robotic_arm/",
          "author": null,
          "description": "Hi everyone, I'm new to robotic arms and I want to learn more about how to implement them using mujoco env. I'm looking for some open-source projects on github that I can run and understand. I tried MuJoCo_RL_UR5 repo but it didn't work well for me, it only deployed a random agent. Do you have any recommendations for good repos that are beginner-friendly and well-documented?\n    submitted by    /u/satyamstar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17dpqyl/mujoco_rl_robotic_arm/",
          "publishedOn": "2023-10-22T09:51:10.000Z",
          "wordCount": null,
          "title": "Mujoco RL Robotic Arm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17dkoyc/why_does_bellman_equation_converge/",
          "author": null,
          "description": "After multiple iterations the value function converge by bellaman updates (vale iteration algorithm). Can someone provide a intuitive reasoning why the value converges?\n    submitted by    /u/RaceCondition01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17dkoyc/why_does_bellman_equation_converge/",
          "publishedOn": "2023-10-22T04:01:40.000Z",
          "wordCount": null,
          "title": "Why does bellman equation converge?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17dcz2j/policy_evaluation/",
          "author": null,
          "description": "I know that given a policy, I can find the value function using iterative policy evaluation. \n Can I, given the value function, find the policy?\n    submitted by    /u/MomoSolar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17dcz2j/policy_evaluation/",
          "publishedOn": "2023-10-21T21:30:17.000Z",
          "wordCount": null,
          "title": "Policy Evaluation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17dburc/question_on_advantage_recomputation_for_ppo/",
          "author": null,
          "description": "Hi,\n I've been re-reading the \"What matters in on-policy reinforcement learning\" paper (https://arxiv.org/abs/2006.05990), and noticed that they suggest to recompute advantages at the beginning of each epoch (choice C5, see section 3.5 and appendix B.1). I was wondering:\n  \nif someone here had already tried this and seen a significant improvement (which is what the paper suggests) ?\n if it did not also suppose to recompute the value targets at the beginning of each epoch, which could lead to some sort of moving target issue ?\n  \nBest,\n    submitted by    /u/Scrimbibete  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17dburc/question_on_advantage_recomputation_for_ppo/",
          "publishedOn": "2023-10-21T20:39:03.000Z",
          "wordCount": null,
          "title": "Question on advantage (re-)computation for PPO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17d8gmx/in_rl_how_can_we_reward_an_action_taken_5_steps/",
          "author": null,
          "description": "Let us say we are building a model that will learn how to play a computer game like DOTA or league of legends.\n If model for example, buys weapon A, and use the item's ability on opponent B, it should learn what damage it gives to opponent given the items opponent B is wearing. But we would have done a lot of other actions in between before being able to use that weapon to reward the model on what it does / how much damage it made.\n How does do you do delayed reward for specific action made X number of steps ago?\n Thank you.\n    submitted by    /u/oniongarlic88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17d8gmx/in_rl_how_can_we_reward_an_action_taken_5_steps/",
          "publishedOn": "2023-10-21T18:02:12.000Z",
          "wordCount": null,
          "title": "In RL, how can we reward an action taken 5 steps ago?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17cyih8/zoomposium_with_professor_dr_petra_ritter_the/",
          "author": null,
          "description": "Zoomposium with Professor Dr. Petra Ritter: \"The simulation of brains\" \n In another installment in our \"Zoomposium Series\" on the topic of \"Brain Research\", my colleague Axel Stöcker of the \"Blog der großen Fragen\" and I had the great honor and pleasure of conducting an interview with the very well-known and renowned German medical doctor and neuroscientist Professor Dr. Petra Ritter. \n In this context, Ms. Ritter became a co-founder and leader of the co-design project \"The Virtual Brain\", which is a component of the European Open Science Cloud (EOSC) and is \"a neuroinformatics platform for simulating whole brain networks using biologically realistic connectivity\". \n She is leading the development of a virtual research environment as a collaborative research platform for sensitive health data and head of the \"German National Neuroscience Research Infrastructure Initiative (NFDI-Neuroscince)\" and involved in the development of the \"Health Data Cloud EBRAINS\". \n Petra Ritter has been Johanna Quandt Professor and Head of the Section for Brain Simulation at the Department of Neurology with Experimental Neurology at Charité - Universitätsmedizin Berlin since 2017. \n There, Professor Ritter and her team are involved in the \"Simulation of Brains\". \n More at: https://philosophies.de/index.php/2023/09/17/die-simulation-von-gehirnen/ \n ​\n https://preview.redd.it/937m7mtyvivb1.jpg?width=1000&format=pjpg&auto=webp&s=22d1a7576f2ebbe7904f0187bd7c0234df7ddb8f\n    submitted by    /u/philosophiesde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17cyih8/zoomposium_with_professor_dr_petra_ritter_the/",
          "publishedOn": "2023-10-21T09:15:07.000Z",
          "wordCount": null,
          "title": "Zoomposium with Professor Dr. Petra Ritter: \"The simulation of brains\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17cmdzb/dqn_with_a_binary_vector_as_output/",
          "author": null,
          "description": "Heey everyone!\n I hope you're doing well.\n I need your help guys.\n I'm working on a DQN that outputs a binary vector of length L (I just applied sigmoid function on the ouptut layer and take p>0.5 as 1 and 0 otherwise). In this setting, how can modify the below code to update my DQN: \n def update(self):\n states, actions, rewards, next_states, dones = self.memory.sample(self.batch_size)\n states = torch.FloatTensor(np.array(states))\n actions = torch.LongTensor(np.array(actions))\n rewards = torch.FloatTensor(np.array(rewards))\n next_states = torch.FloatTensor(np.array(next_states))\n dones = torch.FloatTensor(np.array(dones))\n q_values = self.model(states)\n q_values = q_values.gather(1, actions.unsqueeze(1))\n next_q_values = self.target_model(next_states).detach()\n expected_q_values = rewards + self.gamma * (1 - dones) * next_q_values.max(1)[0]\n expected_q_values = expected_q_values.unsqueeze(1) \n loss = nn.BCELoss(q_values, expected_q_values)\n self.optimizer.zero_grad()\n loss.backward()\n self.optimizer.step()\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17cmdzb/dqn_with_a_binary_vector_as_output/",
          "publishedOn": "2023-10-20T21:45:20.000Z",
          "wordCount": null,
          "title": "DQN with a binary vector as output",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17cm8bg/is_the_deadly_triad_even_real/",
          "author": null,
          "description": "Sutton and Barto’s textbook mentions that combing off-policy learning, bootstrapping, and function approximation leads to extreme instability and should be avoided. Yet when I encounter a reinforcement problem in the wild and look how people go about solving it, if someone’s solution involves bootstrapping more often than not it’s some variation of deep Q-learning. Why is this?\n    submitted by    /u/BiasedEstimators  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17cm8bg/is_the_deadly_triad_even_real/",
          "publishedOn": "2023-10-20T21:38:31.000Z",
          "wordCount": null,
          "title": "Is the “Deadly Triad” even real?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17cdk6i/dead_simple_explanations_of_popular_rl_concepts/",
          "author": null,
          "description": "Hey everyone!\n I just started an open-source repo for RL explanations. https://github.com/DenseLayers/densewiki\n Many people, especially beginners struggle to develop the intuition around concepts (like actor-critic vs advantage actor-critic, GAE, PPO, etc).\n Often it's nice to see what's happening at a high level first, before we dive deeper into the math. That's what I'm trying to do here.\n But I can't do it alone, so I'm posting here to get help from others in the community to make sure the explanations are clear, extremely approachable, and accurate.\n If you'd like to work with me on this (whether you're a complete beginner or very knowledgeable), please reach out!\n ​\n    submitted by    /u/mngrwl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17cdk6i/dead_simple_explanations_of_popular_rl_concepts/",
          "publishedOn": "2023-10-20T15:11:14.000Z",
          "wordCount": null,
          "title": "Dead simple explanations of popular RL concepts (open source)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17c9q7t/reinforement_learning_on_the_game_quarto/",
          "author": null,
          "description": "hello, i am working on solving this board game called \"Quarto\" where we have 16 different pieces. but these pieces have attributes in common they black or white, short or tall, hollow top or closed top, and square shaped or circle shaped pieces each piece has four attributes. the winning condition is to place 4 pieces consecutively in a 4X4 board with at least one attribute in common to win. and also we hadve to choose the piece for the opponent to make and then opponent places that piece and gives us a piece to move. so there are two actions. i have made the action space as 256 + 16 where 256=16*16 as all pieces can be place anywhere on the board and the last 16 is the last possible move that is the move which leads to a terminating state so the next_piece for the opponent would be blank …",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17c9q7t/reinforement_learning_on_the_game_quarto/",
          "publishedOn": "2023-10-20T12:06:55.000Z",
          "wordCount": null,
          "title": "Reinforement learning on the game \"Quarto\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17c60uy/what_is_the_optimal_way_to_train_a_ppo/",
          "author": null,
          "description": "Hello!\n I've got a really simple question, i'm training a PPO algorithm and I wanna know what is the best way to train my model?\n Sorry, I'll try to be clear!\n So right now what i'm doing is :\n  \nI'm loading a previously trained PPO model\n Train the model on 20000 timesteps\n Evaluate the reward of the newly trained PPO model at the end of the timesteps and compare it to the reward from the model loaded in 1\n If the reward is greater then i'm going back to step 1 and using the new model\n  \nIf not then i'm going back to step 1.\n Is it a correct way to do so? \n Thanks a lot and have a great day!\n    submitted by    /u/PointNo1904  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17c60uy/what_is_the_optimal_way_to_train_a_ppo/",
          "publishedOn": "2023-10-20T08:10:21.000Z",
          "wordCount": null,
          "title": "What is the optimal way to train a PPO?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17by3my/new_chess_dataset_32b_games_608b_moves_generated/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17by3my/new_chess_dataset_32b_games_608b_moves_generated/",
          "publishedOn": "2023-10-20T00:25:50.000Z",
          "wordCount": null,
          "title": "new chess dataset: 3.2b games (608b moves) generated by 2500-ELO Stockfish selfplay {LAION}",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17bpy32/dreamerv2_stochastic_decoders/",
          "author": null,
          "description": "Hello,\n I am implementing the code for the paper DreamerV2, and there are some things that look a bit strange to me.\n The predictors and, in particular, the image and the reward predictors are stochastic and they output Normal distributions. Both the normal distributions have the mean, which is the output of the respective models, and the variance is 1. \n Usually, in RL we normalize observations and rewards to be between 0 and 1, and in such a case I don't know if it's reasonable to sample from a Gaussian with variance one.\n I don't know about the specific preprocessing done in DreamerV2, except in the paper DreamerV1, where in section 6 (Control tasks), they say that the reward ranges from 0 to 1. \n Do you know what are the advantages of using a stochastic decoder and when to use it?\n    submitted by    /u/ZioFranco1404  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17bpy32/dreamerv2_stochastic_decoders/",
          "publishedOn": "2023-10-19T18:27:55.000Z",
          "wordCount": null,
          "title": "DreamerV2 stochastic decoders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17bgf4v/reinforcement_learning_on_steam_games/",
          "author": null,
          "description": "Does anyone have any idea how to get game details such as character movements, environment information using api calls, as I want to use to do my reinforcement learning.\n    submitted by    /u/Important_Ad_55  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17bgf4v/reinforcement_learning_on_steam_games/",
          "publishedOn": "2023-10-19T10:58:44.000Z",
          "wordCount": null,
          "title": "Reinforcement learning on steam games",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17b4w0w/mujoco_with_openai_gym/",
          "author": null,
          "description": "Hello,\n I'm trying to use OpenAI's spinning up to learn about RL. Spinning up requires OpenAI gym, instead of the new gymnasium package. \n Trying to install MuJoCo with gym, I'm getting an error that I'm missing a MuJoCo liscense key. But MuJoCo is free now, right? So what is the status with backward compatibility with it? Is there some global license key that can be used? Or is it simply not backward compatible?\n Thanks a lot.\n    submitted by    /u/mega_monkey_mind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17b4w0w/mujoco_with_openai_gym/",
          "publishedOn": "2023-10-18T23:40:32.000Z",
          "wordCount": 2634,
          "title": "MuJoCo with OpenAI gym",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17axl9u/dqn_in_a_non_markovian_environment/",
          "author": null,
          "description": "Hello there,\n I am working on a school project in which we want to implement a RL algorithm on a simple problem.\n The goal is to maximise the heart rate of a person using a vibrator by setting its frequency.\n We wrote a simulator that outputs the new heart rate based on the vibration frequency. It implements several different classes of users: for example one for which the heart rate increases when the vibration frequency stays the same, another that prefers when it increases over time, etc.\n We determined that we need to have as a state the current heart rate but also a table of the k previous heart rates and the actions associated. Without that memory, we would not be able to tell apart the different profiles as in the same state, we would need to do different actions to satisfy them both. We then have a correlation between previous samples and the action we make at current state, which I have read makes the problem non markovian.\n Is there a way to solve this problem using a DQN algorithm, given that we need to memorize the previous samples linearly which seems to go against the algorithm behavior and the usage of a replay memory? Are there more suited algorithms?\n    submitted by    /u/Outrageous-Subject38  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17axl9u/dqn_in_a_non_markovian_environment/",
          "publishedOn": "2023-10-18T18:24:05.000Z",
          "wordCount": 2770,
          "title": "DQN in a non markovian environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17atv3b/best_books_to_learn_reinforcement_learning/",
          "author": null,
          "description": "submitted by    /u/Lakshmireddys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17atv3b/best_books_to_learn_reinforcement_learning/",
          "publishedOn": "2023-10-18T15:45:20.000Z",
          "wordCount": 2566,
          "title": "Best Books to Learn Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17artxz/gpt_learning_to_learn_with_generative_models_of/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17artxz/gpt_learning_to_learn_with_generative_models_of/",
          "publishedOn": "2023-10-18T14:14:15.000Z",
          "wordCount": 2584,
          "title": "\"gp.t: Learning to Learn with Generative Models of Neural Network Checkpoints\", Peebles et al 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17aqxgp/autonomous_driving_ellipsoidal_constrained_agent/",
          "author": null,
          "description": "submitted by    /u/shani_786  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17aqxgp/autonomous_driving_ellipsoidal_constrained_agent/",
          "publishedOn": "2023-10-18T13:33:34.000Z",
          "wordCount": 2969,
          "title": "Autonomous Driving: Ellipsoidal Constrained Agent Navigation | Swaayatt Robots | Motion Planning Research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17amiju/dqn_agent_stuck_at_local_minima_probably/",
          "author": null,
          "description": "I'm attempting to address a Day Ahead Electricity Market bidding problem. The concept revolves around purchasing electricity during the lowest price hours and selling it during the highest price hours to maximize profit. I possess 5 years of data featuring variables such as predicted wind speed, predicted temperature, predicted net load, predicted price, and more. I'm employing reinforcement learning and have made attempts to implement Deep Q Learning using the stablebaselin3 library. Each episode consists of 24 steps, corresponding to the 24 hours in a day, with each step representing the progression to the next hour. The ultimate objective is to maximize profits by the end of the day.\n ​\n Here are the configuration settings:\n - Learning rate: 0.0001\n - Gamma: 1.0\n - Exploration start: 1.…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17amiju/dqn_agent_stuck_at_local_minima_probably/",
          "publishedOn": "2023-10-18T09:26:34.000Z",
          "wordCount": null,
          "title": "DQN Agent stuck at local Minima (Probably)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17ahjo6/6dof_simulation_rl_capability/",
          "author": null,
          "description": "I have a 6DOF simulink model of a Autonomous underwater vehicle that has properties [u v w p q r x y z phi theta psi] and two inputs [theta1 theta2] that govern the angle of control surfaces. Ocean current and depth are taken into account. \n How feasible would it be to use RL to reach waypoints at various [x, y, z] positions? I have a feeling hyper paremeter tuning might play a larger role in this? I expect training times to increase exponentially as well? \n I have done this using a single randomly spawned waypoint with a simple Unicycle Kinematic model, in both simulink/matlab and python with a vectorized/parallel environment using SB3/PettingZoo/Gym.\n    submitted by    /u/VisionZUS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17ahjo6/6dof_simulation_rl_capability/",
          "publishedOn": "2023-10-18T03:56:28.000Z",
          "wordCount": null,
          "title": "6DOF Simulation RL Capability",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17aflqu/recommended_seeding_approach_when/",
          "author": null,
          "description": "Dear all,\n As part of my studies, I am running some RL experiments in which I want to compare some different catastrophic forgetting approaches in sequential task learning. I am using PPO as a baseline. What is the usual experimental setting in relation to seeds used during training and evaluation? If I do for example 3 trainings for a given approach using a different seed for each training, what is the best way of doing the evaluation afterwards?\n Let's say I have Approach/algorithm A -> train 3 times with 3 seeds -> model_A1, model_A2, model_A3\n Then I would like to use 3 different seeds for the evaluation, so to evaluate each of the previously trained models over a set of episodes (deterministic) for each evaluation seed, and get averaged rewards (or median).\n I wonder whether I might be over complicating things, so I would like to ask you for suggestions. To give a bit of context, this is not intended for a paper, but as part of my master studies, so conditions are a bit more relaxed.\n Thanks in advance for your insights and suggestions\n    submitted by    /u/cotorritaloca80  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17aflqu/recommended_seeding_approach_when/",
          "publishedOn": "2023-10-18T02:15:57.000Z",
          "wordCount": null,
          "title": "Recommended 'seeding' approach when training/evaluating an experiment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17a0ds4/starc_a_general_framework_for_quantifying/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17a0ds4/starc_a_general_framework_for_quantifying/",
          "publishedOn": "2023-10-17T15:01:48.000Z",
          "wordCount": null,
          "title": "\"STARC: A General Framework For Quantifying Differences Between Reward Functions\", Skalse et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17a06ra/goodharts_law_in_reinforcement_learning_karwoski/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17a06ra/goodharts_law_in_reinforcement_learning_karwoski/",
          "publishedOn": "2023-10-17T14:53:02.000Z",
          "wordCount": null,
          "title": "\"Goodhart's Law in Reinforcement Learning\", Karwoski et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/179vtbg/dynamic_state_and_action_space/",
          "author": null,
          "description": "Hello, I’m working on a scenario that involves many systems and each system involves many subsystems. At each decision time and according to the system that requests the decision, the RL agent must select a subsystem. Nevertheless, each system has a different number of subsystems which makes the action space and the state space dynamic since the each neurone in the output represents a subsystem. Can I use the maximal number of subsystems (not the total number) as the number of the output and masking some neurones according to the current system ?\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/179vtbg/dynamic_state_and_action_space/",
          "publishedOn": "2023-10-17T11:05:37.000Z",
          "wordCount": null,
          "title": "Dynamic state and action space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/179p0gv/offline_rl_interpreting_policy/",
          "author": null,
          "description": "I am new to RL and have a naive question. How interpretable would the policy be from building a rl algorithm in an offline setting? Could I make inferences about what the optimal sequences would be?\n    submitted by    /u/kwsunshine123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/179p0gv/offline_rl_interpreting_policy/",
          "publishedOn": "2023-10-17T03:29:38.000Z",
          "wordCount": null,
          "title": "Offline rl- interpreting policy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/179k124/article_key_concepts_and_open_questions_in_a/",
          "author": null,
          "description": "submitted by    /u/Stanford_Online  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/179k124/article_key_concepts_and_open_questions_in_a/",
          "publishedOn": "2023-10-16T23:26:23.000Z",
          "wordCount": null,
          "title": "Article: Key Concepts and Open Questions in a Golden Age for Natural Language Understanding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17973ri/dexcatch_learning_to_catch_arbitrary_objects_with/",
          "author": null,
          "description": "🌟 Excited to share our recent research, DexCatch!\n Pick-and-place is slow and boring, while throw-catching is a behaviour towards more human-like manipulation.\n We propose a new model-free framework that can catch diverse objects of daily life with dexterous hands in the air. This ability to catch anything from a cup to a banana, and a pen, can help the hand quickly manipulate objects without transporting objects to their destination -- and even generalize to unseen objects. Video demonstrations of learned behaviors and the code can be found at https://dexcatch.github.io/.\n ​\n https://reddit.com/link/17973ri/video/i4xdo39d4lub1/player\n    submitted by    /u/Shengjie_Wang  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17973ri/dexcatch_learning_to_catch_arbitrary_objects_with/",
          "publishedOn": "2023-10-16T14:21:03.000Z",
          "wordCount": null,
          "title": "DexCatch: Learning to Catch Arbitrary Objects with Dexterous Hands",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1794m95/help_with_model_based_policy_optimization/",
          "author": null,
          "description": "I am reading this paper and came across the following paragraph - \n ​\n \"Model usage. Many recent model-based algorithms have focused on the setting in which model\n rollouts begin from the initial state distribution (Kurutach et al., 2018; Clavera et al., 2018). While\n this may be a more faithful interpretation of Algorithm 1, as it is optimizing a policy purely under\n the state distribution of the model, this approach entangles the model rollout length with the task\n horizon. Because compounding model errors make extended rollouts difficult, these works evaluate\n on truncated versions of benchmarks. The branching strategy described in Section 4.2, in which\n model rollouts begin from the state distribution of a different policy under the true environment\n dynamics, effectively relieves this limitation. In practice, branching replaces few long rollouts from\n the initial state distribution with many short rollouts starting from replay buffer states.\"\n ​\n  \nWhat does state distribtion mean over here?\n Also in line 8 of the image, I don't understand what's the relation between model rollout and policy \\pi_t. Is it saying, use the model free algorithm to take future steps from that state? What does the model have to do with that?\n \n ​\n https://preview.redd.it/twlej5my3kub1.png?width=1182&format=png&auto=webp&s=4a515c8d237c963052bc1b60a9e7dda53a33f001\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1794m95/help_with_model_based_policy_optimization/",
          "publishedOn": "2023-10-16T12:17:10.000Z",
          "wordCount": null,
          "title": "Help with Model Based Policy Optimization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/178ttjc/math_prerequisites_for_reinforcement_learning/",
          "author": null,
          "description": "hi all! \n i’m an undergraduate that is really interested in pursuing a PhD. i think reinforcement learning is especially interesting, causal reinforcement learning in particular. for my current research job, which unfortunately doesn’t really involve ML, i read a little about causal inference and it really intrigued me. \n what mathematics courses should i take to get into RL research at a theoretical/algorithmic level? i am currently taking proof-based linear algebra, and have taken all the computational calculus offered. i imagine prob. theory/math stats is pretty important, too; what else?\n    submitted by    /u/treeman0469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/178ttjc/math_prerequisites_for_reinforcement_learning/",
          "publishedOn": "2023-10-16T00:52:15.000Z",
          "wordCount": null,
          "title": "math prerequisites for reinforcement learning research?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/178ifk9/hi_everyone_i_was_following_an_online_rl_tutorial/",
          "author": null,
          "description": "I was following Nicholas Renotte's RL in 3 hours tutorial and I ran into this issue at time stamp 1:10:00 while testing my trained Agent.\n ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n This is my code for testing my environment:\n episodes=5 for episode in range(1,episodes+1): obs=env.reset() done=False score=0 print(obs) while not done: env.render() action, _ = model.predict(obs) #Now using model here obs, reward, done, truncated, info = env.step(action) score += reward print('Episode:{} Score:{}'.format(episode,score)) env.close() \n And this is the environment I am using :\n environment_name = 'CartPole-v1' env=gym.make(environment_name,render_mode=\"human\") \n the model variable has my trained model stored in it and is initialized as such :\n model =PPO.load(PPO_Path, env=env) \n The print(obs) function returns this value :\n (array([ 0.03954345, -0.04975226, -0.02942382, -0.02261402], dtype=float32), {}) \n I am running this code in a Notebook on VS code on an M2 Macbook running MacOS 13.5, I am using Python 3.9.15 and the latest version of all the other libraries and dependencies. Please help\n    submitted by    /u/Straight-Knowledge83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/178ifk9/hi_everyone_i_was_following_an_online_rl_tutorial/",
          "publishedOn": "2023-10-15T15:58:29.000Z",
          "wordCount": 2737,
          "title": "Hi everyone , I was following an online RL tutorial that uses Stable baselines3 and Open AI's gym to implement a Cart Pole environment but I have ran into some problems. Can anyone of you please help me?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/178hk80/reinforcement_learning_platform_for_uavs/",
          "author": null,
          "description": "I'm doing a project that aims to use reinforcement learning (PPO variations) with UAVs. What are the most up to date tools are for implementing and trying new RL algorithms in this space?\n I've looked at AirSim, and it seems to no longer be supported by Micrsosoft. I've also been heavily looking at Flightmare, which is almost exactly what I want, but getting the tool that hasn't been maintained for years up and running is giving me headaches (and the documentation is not great/up to date either).\n Ultimately, what I'm looking for is: * Physics simulation * Photo-realistic vision * Built-in integration with Gym would be awesome * Python platform preferred, C++ also ok\n I've also used ROS/Gazebo with PyTorch previously, and that is my backup plan I suppose, but it's not photo-realistic and is kind of slow in my experience.\n    submitted by    /u/zeus_the_transistor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/178hk80/reinforcement_learning_platform_for_uavs/",
          "publishedOn": "2023-10-15T15:16:21.000Z",
          "wordCount": 2667,
          "title": "Reinforcement Learning Platform for UAVs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/178doj5/training_a_rl_model_with_continuous_state_action/",
          "author": null,
          "description": "Hello everyone,\n I'm a Data Science student diving into an exciting thesis topic: using reinforcement learning to stabilize boats in rough seas by adjusting a keel's angle. But I am a bit concerned about the high complexity of the problem and the given situation: \n  \nAction Space: Continuous, representing the keel's angle adjustments.\n State Space: Continuous, capturing the dynamic behavior of the sea, including waves.\n Training Environment: Currently, the company only has a real-world water tank setup to simulate the sea conditions. There's no computer simulation available.\n  \nGiven this setup, I have a couple of concerns:\n  \nIs it possible to train an RL model effectively in such a complex real-world scenario without first having a computer simulation? And if yes, what would be your initial steps in doing so?\n Are there possibilities to reduce the problem's complexity while training exclusively in the real-world water tank simulation? (i.e. transforming the action space into a discrete action space?)\n  \nAny insights or advice would be greatly appreciated!\n    submitted by    /u/No-Wasabi3556  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/178doj5/training_a_rl_model_with_continuous_state_action/",
          "publishedOn": "2023-10-15T11:46:52.000Z",
          "wordCount": 2701,
          "title": "Training a RL Model with Continuous State & Action Space in a Real-World Scenario",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1786bec/supercharging_reinforcement_learning_with_logic/",
          "author": null,
          "description": "Deep reinforcement learning has led to a variety of compelling results. However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly. Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.\n ​\n https://preview.redd.it/6wmg0qnlaaub1.png?width=1786&format=png&auto=webp&s=01f82cf24de79b317b6f9406b0b6379b949a34d3\n We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).\n ​\n https://preview.redd.it/u8f44fskaaub1.png?width=1636&format=png&auto=webp&s=9509f03a936f41cd0131388564833b86a39c295a\n However, the benefits of our semantic proxy go well beyond performance. The use of temporal logic programming has two crucial beneficial by-products such as symbolic explainability and modularity. PyReason provides an explainable symbolic trace that captures the evolution of the environment in a precise manner while modularity allows us to add or remove aspects of the logic program – allowing for adjustments to the simulation based on a library of behaviors. PyReason is well-suited to model simulated environments for other reasons – namely the ability to directly capture non-Markovian relationships and the open-world nature (defaults are “uncertain” instead of true or false). We have demonstrated that agents can be trained using standard RL techniques such as DQN using this framework.\n Preprint: https://arxiv.org/abs/2310.06835\n Video: https://youtu.be/9e6ZHJEJzgw\n Code for PyReason-as-a-Sim (integration with DQN): https://github.com/lab-v2/pyreason-rl-sim\n Code for PyReason Gym: https://github.com/lab-v2/pyreason-gym\n PyReason Home: neurosymbolic.asu.edu/pyreason/\n ​\n    submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1786bec/supercharging_reinforcement_learning_with_logic/",
          "publishedOn": "2023-10-15T03:16:49.000Z",
          "wordCount": 2765,
          "title": "Supercharging reinforcement learning with logic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1785s73/actorcritic_on_piecewise_constant_reward_function/",
          "author": null,
          "description": "I made a environment with piece wise constant reward function for testing the network architecture. And its episode length is 1.\n The critic will try to learn this and become a piecewise constant function. And have a gradient close to 0 making the gradient vanish for the policy. \n I can think of some solutions: - Change the reward function to a dense reward\n But i wanted some other views; has anyone solved such problems?\n    submitted by    /u/Automatic-Web8429  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1785s73/actorcritic_on_piecewise_constant_reward_function/",
          "publishedOn": "2023-10-15T02:46:32.000Z",
          "wordCount": null,
          "title": "Actor-critic on piecewise constant reward function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1785h5n/help_understanding_the_pets_algorithm/",
          "author": null,
          "description": "I am trying to read this paper and I am unable to get the big picture over here. Can someone please explain what's going on in the Propagation and Planning stage? In the Model stage, I understand that they are using a Probabilistic Model to handle uncertainty.\n ​\n https://preview.redd.it/idenqd492aub1.png?width=945&format=png&auto=webp&s=40da9bf53b21dbed63b70571f3833b0fe3a9dabb\n For instance, what does Particle mean in this paper? \n This big picture here is that I am trying to understand the Model Based Policy Optimization paper and it seemed like they built upon the above paper. \n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1785h5n/help_understanding_the_pets_algorithm/",
          "publishedOn": "2023-10-15T02:29:49.000Z",
          "wordCount": null,
          "title": "Help understanding the PETS algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/177q2l0/pitfalls_of_learning_a_reward_function_online/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/177q2l0/pitfalls_of_learning_a_reward_function_online/",
          "publishedOn": "2023-10-14T13:53:36.000Z",
          "wordCount": null,
          "title": "\"Pitfalls of learning a reward function online\", Armstrong et al 2020 {DM}",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1770iav/introducing_ppo_and_rainbow_dqn_to_our_super_fast/",
          "author": null,
          "description": "Hi, we've just released a new version of AgileRL, our evolutionary hyperparameter optimisation framework built for RL that is 10x faster than SOTA.\n We've introduced PPO, Rainbow DQN, some sophisticated replay buffers, and also collaborated with the Farama Foundation to create some tutorials (more on the way).\n Please check it out and take it for a spin. We're also looking for contributors so get in touch if you would like to be involved!\n https://github.com/AgileRL/AgileRL\n    submitted by    /u/nicku_a  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1770iav/introducing_ppo_and_rainbow_dqn_to_our_super_fast/",
          "publishedOn": "2023-10-13T14:50:39.000Z",
          "wordCount": null,
          "title": "Introducing PPO and Rainbow DQN to our super fast evolutionary HPO reinforcement learning framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176zs5e/masking_state_transitions_in_policy_updates_for/",
          "author": null,
          "description": "I am currently dealing with an environment, that most of the time (90% of all state transitions) clips the action selected from the agent. Sometimes even down to the point where the action selected by the agent is completly ignored. \n This causes a lot of problems, because for example the entropy bonus does not works, since the agent learns to select any action, when it doesn't matter anyway but selects the same action (low entropy) when the actions have an effect. \n Using the PPO algorithm I was thinking of masking the state transitions in the policy updates, according to how much the action was clipped in the environment. And I thought V(s) should be masked, because it can still learn from the state transitions even if the action was effectively ignored by the environment. \n    submitted by    /u/flxh13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176zs5e/masking_state_transitions_in_policy_updates_for/",
          "publishedOn": "2023-10-13T14:16:57.000Z",
          "wordCount": null,
          "title": "Masking state transitions in policy updates for invalid actions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176zir9/a_question_about_deterministic_action_selection/",
          "author": null,
          "description": "I'm training some agents using fairly vanilla PPO on a hand-made environment. These agents learn to perform the task pretty well, but while I was examining their action probabilities during an evaluation episode, I had the idea to turn off deterministic action selection. \n To my surprise, allowing probabilistic action selection (as opposed to argmax action selection) actually improved performance in some cases. I had always thought that deterministic actions during evaluation was fairly standard, but now am thinking that maybe I missed something and that there are cases where you wouldn't want determinism?\n My question is: how common is it actually to use deterministic actions vs. probabilistic ones at evaluation time, and does anyone know of studies/papers/examples where the authors found probabilistic evaluation to outperform determinism?\n    submitted by    /u/Impallion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176zir9/a_question_about_deterministic_action_selection/",
          "publishedOn": "2023-10-13T14:04:30.000Z",
          "wordCount": null,
          "title": "A question about deterministic action selection at evaluation time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176wi8b/a_simple_openloop_baseline_for_reinforcement/",
          "author": null,
          "description": "submitted by    /u/atooo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176wi8b/a_simple_openloop_baseline_for_reinforcement/",
          "publishedOn": "2023-10-13T11:25:32.000Z",
          "wordCount": null,
          "title": "\"A Simple Open-Loop Baseline for Reinforcement Learning Locomotion Tasks\" Raffin et al. 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176w3eu/looking_for_some_advice_regarding_universal/",
          "author": null,
          "description": "Hey, \n So I am working on reinforcement learning package in C# (currently under heavy development):\n https://github.com/asieradzk/RL_Matrix \n My goal is to create something superior to unity's ML Agents for Godot to democratize access to reinforcement learning for people (without having them know what a tensor is)\n So far I've added some barebones DQN and PPO that (only output single discrete action) as proof of concept to test my code architecture. So I am going through the daunting task of having some universal workflow for setting up environments. For any shape observations and any count actions, both discrete and continuous. \n As I am finishing my multi-head multi-action output I've come to realise that there are many possible architectures I could setup multi head outputs, for instanc…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176w3eu/looking_for_some_advice_regarding_universal/",
          "publishedOn": "2023-10-13T11:00:11.000Z",
          "wordCount": null,
          "title": "Looking for some advice regarding universal multi-head outputs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176v8qb/next_state_in_turn_based_game/",
          "author": null,
          "description": "To my knowledge, when using the Q Learning family algorithm, we must know the next state as well as the action spaces in couple with that observation in order to evaluate the reward for the next state with the target network.\n But I have some problem when trying to define this next state in turn turn-based game in which the agent have to make a certain number of actions and then wait for the opponent to do some actions before it can interact with the environment again. We can take Hearthstone as an example that each player have to wait for other to play a number of cards before can take any action.\n Currently, I have two options for this: \n - Treat the environment right after the agent's turn ended, which will lack the action space.\n - Treat the environment just before the agent's turn begins, which will have all the actions available that it can choose from but this will make the agent's last action very noisy. That state could be a good state if the opponent playing badly or they are very good and make our last decision seem like a very bad choice. \n Thanks in advance for any suggestions. If my problem is a common task that others have already solved many times, I will be very thankful for that keyword.\n    submitted by    /u/No-Concentrate-6037  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176v8qb/next_state_in_turn_based_game/",
          "publishedOn": "2023-10-13T10:02:23.000Z",
          "wordCount": null,
          "title": "Next state in turn based game",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176n5iv/small_batch_deep_reinforcement_learning/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176n5iv/small_batch_deep_reinforcement_learning/",
          "publishedOn": "2023-10-13T01:28:58.000Z",
          "wordCount": null,
          "title": "\"Small batch deep reinforcement learning\", Obando-Ceron et al 2023 {DM} (value-based agents explore & regularize better with small n)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176amv1/deepmind_2022_full_accounts_financial_report_2022/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176amv1/deepmind_2022_full_accounts_financial_report_2022/",
          "publishedOn": "2023-10-12T16:10:00.000Z",
          "wordCount": null,
          "title": "DeepMind 2022 'full accounts' financial report: 2022 budget: £1,081 million ($1.3b) (decreased by a fifth from 2021)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/176a3re/rl_for_nonpython_environments/",
          "author": null,
          "description": "Most real world applications for RL (robotics, game dev, finance) are in not normally done in Python, yet all major RL frameworks are written in Python. Is there a good/high-performance cross-language framework to do RL in other languages like C++/.Net/Java? If not, do you think people would be interested in such a framework?\n ​\n    submitted by    /u/xor24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/176a3re/rl_for_nonpython_environments/",
          "publishedOn": "2023-10-12T15:47:23.000Z",
          "wordCount": null,
          "title": "RL for non-Python environments?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1769e0g/reinforcement_learning_agents_that_adhere_to_a/",
          "author": null,
          "description": "Do you know any work that tries to develop RL agents that exploit some sort of high-level model of the problem (it could also be given by an expert human) to learn faster or operate on out-of-distribution scenarios?\n I'm particularly interested in Causal Models, but any similar thing could be interesting for me\n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1769e0g/reinforcement_learning_agents_that_adhere_to_a/",
          "publishedOn": "2023-10-12T15:16:14.000Z",
          "wordCount": null,
          "title": "Reinforcement learning agents that adhere to a causal model of the problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1767v70/what_is_the_intuitive_explanation_for_using_log/",
          "author": null,
          "description": "submitted by    /u/aabra__ka__daabra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1767v70/what_is_the_intuitive_explanation_for_using_log/",
          "publishedOn": "2023-10-12T14:09:07.000Z",
          "wordCount": null,
          "title": "What is the intuitive explanation for using log probabilities in Policy gradient methods instead of simple probabilities? does it improve gradient descent optimization ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1763ixm/why_does_drqv2_sample_from_replay_by_episode_then/",
          "author": null,
          "description": "I've been looking at DrQ-v2 (https://github.com/facebookresearch/drqv2) recently and it samples from replay in a way that seems odd to me but may have a purpose I don't understand.\n They store experiences in a compressed file by episode, this makes some sense since it means they don't have to store everything in RAM and they delay disk writes until the end of the episode so they don't slow down the sim operation. \n On sampling, they randomly select an episode then randomly select an experience from the episode, calculating the n-step reward dynamically at sample time instead of at experience storage time. This is then fed to the model by a pytorch DataLoader. This means a _lot_ of disk reads during the optimization step which can't be ideal but I'll put that aside. \n What is the advantage of doing this selection by episode? It may give a better spread across episodes in each update, but I'm not sure that makes up for the potential downsides of making prioritization and other replay tricks much harder. Any ideas?\n    submitted by    /u/EDMismyO2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1763ixm/why_does_drqv2_sample_from_replay_by_episode_then/",
          "publishedOn": "2023-10-12T10:16:40.000Z",
          "wordCount": null,
          "title": "Why does Drq-v2 sample from replay by episode then experience?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/175utfv/can_reinforcement_learning_models_learn_to_rank/",
          "author": null,
          "description": "I have a very simple observation: a list of random value state = [random.uniform(-0.2, 0.2) for _ in range(200)]\n reward = state * actions . The reward is not using the next state, it's using the previous state i gave to the model.\n So basically i already give the answer to the model, the best action is : if state > 0 action =1, if state < 0 action = -1\n I tried using PPO, but it seem not learning at all.\n My test_env.py is here:\n ``` import gymnasium as gym import numpy as np from gymnasium import spaces from gymnasium.utils import seeding from stable_baselines3.common.vec_env import DummyVecEnv import random\n class TestEnv(gym.Env): \n metadata = {\"render.modes\": [\"human\"]} def __init__( self, item_count, test_steps, is_train = True, ): self.is_train = is_train self.test_steps = test_step…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/175utfv/can_reinforcement_learning_models_learn_to_rank/",
          "publishedOn": "2023-10-12T01:31:23.000Z",
          "wordCount": null,
          "title": "Can reinforcement learning models learn to rank?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/175898n/gain_and_bias_params_in_mujoco/",
          "author": null,
          "description": "Hi! I'm new to Mujoco and robot dynamics.\n When I read the Mujoco document, I'm confused about the gainprm and biasprm parameters. I want to understand the meaning of these parameters and tune the actuation speed of my actuator. An easy-to-understand explanation or supporting material would be appreciated. \n Thanks in advance.\n    submitted by    /u/UpperSearch4172  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/175898n/gain_and_bias_params_in_mujoco/",
          "publishedOn": "2023-10-11T07:27:54.000Z",
          "wordCount": null,
          "title": "Gain and bias params in Mujoco",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17557z7/loopquest_a_githublike_platform_to_host/",
          "author": null,
          "description": "Hello everyone! Here is my pet project, https://www.loopquest.ai/. I am trying to build a platform like Github to let people upload their simulation environments so people can train their AI agents by interacting with the environments created by others. Here is a 2-min demo, https://youtu.be/d53NFjkU7JA. It is not launched yet but would love to get some early feedbacks.\n Here is the corresponding Github repo https://github.com/LoopMind-AI/loopquest. For now, the package can log env-agent interaction data by adding one extra line of code. You can think of it similar to https://github.com/google-deepmind/envlogger but with much better backend and frontend support.\n Any feedbacks are appreciated :)\n    submitted by    /u/jxx123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17557z7/loopquest_a_githublike_platform_to_host/",
          "publishedOn": "2023-10-11T04:08:39.000Z",
          "wordCount": null,
          "title": "LoopQuest, A Github-like platform to host simulation environments for AI training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174vpzw/issue_with_mujoco_simulation_robot_penetrates_the/",
          "author": null,
          "description": "Hello everyone,\n I'm working on simulating a modified humanoid robot, \"DARwIn OP 3\", using MuJoCo through dm_control in Python. My goal is to train the model to ascend stairs rapidly but these are the first steps. However, I've encountered a problem where the robot appears to sink into the ground and is then ejected with significant force under specific conditions.\n ​\n https://reddit.com/link/174vpzw/video/u636vf49tftb1/player\n  \nEnvironment: MuJoCo via dm_control.\n Issue Description: When the robot falls and its feet move, it behaves as though one of its motors sinks into the floor.\n Attempts: I've tweaked contact parameters and ground properties with no luck. Interestingly, this doesn't occur in the standalone MuJoCo simulator.\n Visual Aid: I've attached a video to illustrate the problem…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174vpzw/issue_with_mujoco_simulation_robot_penetrates_the/",
          "publishedOn": "2023-10-10T20:46:50.000Z",
          "wordCount": null,
          "title": "Issue with MuJoCo Simulation: Robot Penetrates the Ground",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174u530/algorithms_for_average_reward_reinforcement/",
          "author": null,
          "description": "I see that discounted reward reinforcement learning has been extensively studied in the literature. However, the average reward metric receives less attention, and it looks like algorithms for this metric (R-learning, H-learning, SMART, etc.) are much less than the discount metric. Could you suggest any algorithms for average reward reinforcement learning for continuous/general state-action space?\n    submitted by    /u/S1gnature  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174u530/algorithms_for_average_reward_reinforcement/",
          "publishedOn": "2023-10-10T19:42:48.000Z",
          "wordCount": null,
          "title": "Algorithms for average reward reinforcement learning in continuous/general state-action space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174trnk/how_disney_packed_big_emotion_into_a_little_robot/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174trnk/how_disney_packed_big_emotion_into_a_little_robot/",
          "publishedOn": "2023-10-10T19:27:55.000Z",
          "wordCount": null,
          "title": "\"How Disney Packed Big Emotion Into a Little Robot\" (sim2real)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174ldr6/i_took_openais_paper_about_defeating_dota2_world/",
          "author": null,
          "description": "submitted by    /u/mngrwl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174ldr6/i_took_openais_paper_about_defeating_dota2_world/",
          "publishedOn": "2023-10-10T13:34:59.000Z",
          "wordCount": null,
          "title": "I took OpenAI's paper about defeating Dota2 world champions, and explained it paragraph-by-paragraph.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1747p76/whats_your_view_on_the_recent_rtx_effortsscaling/",
          "author": null,
          "description": "With recent RT-X efforts from Deepmind, it seems the community has been shifting towards the development of a more generalized foundational model, combining with visions and languages, and scaling via imitation learning. \n I know RL algorithms are expensive to train and hard to scale due to the way the samples are generated, but I am still fascinated by the intelligence behind their philosophies. What do you think the future would look like? Like NLP or CV, having a big foundational model pre-trained via IL, and fine-tune on different tasks via RL? How can we tell if a task is simple enough that we don't need to leverage the power of a foundational model?\n    submitted by    /u/Old_Reading_669  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1747p76/whats_your_view_on_the_recent_rtx_effortsscaling/",
          "publishedOn": "2023-10-10T00:27:16.000Z",
          "wordCount": null,
          "title": "What's your view on the recent RT-X efforts/scaling via IL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173u9fn/switching_off_a_specified_rotor_in_airsim/",
          "author": null,
          "description": "Hello Everyone,\n I am working on a project to train a Reinforcement Learning agent to recover a quadrotor after any of the rotor’s failures. I am using AirSim for my project, but I can’t find a way to adjust the quad-rotor so that only 3 of the four rotors are working. \n Any suggestions? I appreciate any help you can provide.\n    submitted by    /u/audaciouslion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173u9fn/switching_off_a_specified_rotor_in_airsim/",
          "publishedOn": "2023-10-09T15:11:51.000Z",
          "wordCount": null,
          "title": "Switching off a specified rotor in AirSim",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173hbka/i_trained_a_reinforcement_learning_agent_to_play/",
          "author": null,
          "description": "Hi all, over the last couple years I've been training a reinforcement learning agent to play pokemon red. I put together a video which analyzes the AI's learning, as well as documenting my process and quite a bit of technical details. Enjoy! \n Video:\n https://youtu.be/DcYLT37ImBY\n Code:\n https://github.com/PWhiddy/PokemonRedExperiments\n https://preview.redd.it/4dw3yasqb3tb1.jpg?width=1280&format=pjpg&auto=webp&s=bdef1aa0d24d75ab548f3944c558840667ff0ed5\n    submitted by    /u/Pwhids  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173hbka/i_trained_a_reinforcement_learning_agent_to_play/",
          "publishedOn": "2023-10-09T02:50:51.000Z",
          "wordCount": null,
          "title": "I trained a reinforcement learning agent to play pokemon red!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173fpzz/feature_importance_in_ray_rllib/",
          "author": null,
          "description": "I am training an RL agent using Ray RLlib. Does anyone know how I can find which features (observations) help the agent learn the policy? I found this: https://discuss.ray.io/t/feature-importance/10362/2, but I'd really appreciate if someone could expand on this a bit more. Thank you!\n    submitted by    /u/greenteabiitch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173fpzz/feature_importance_in_ray_rllib/",
          "publishedOn": "2023-10-09T01:30:55.000Z",
          "wordCount": null,
          "title": "Feature Importance in Ray RLlib",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173dkt0/my_first_multiagent_rl_model/",
          "author": null,
          "description": "Hey Reddit,\n I am new to reinforcement learning. I have sufficient knowledge on supervised learning, but I am yet to stumble onto a cheat sheet for RL and from what I can tell, my use case is less common. \n I'm reaching out to the community in hopes of getting guidance and assistance in cutting through the noise of redundant and irrelevant information so I can attempt to built a toy model to validate my use case. I am deeply grateful for any help in advance.\n ​\n From what I can tell, here are the conditions I need to work with for my use case.\n  \nI'm trying to train a simulator.\n This is a multi-agent problem, perhaps with more than 2 agents. Each agent is responding based on it's own state, the state of the other agent[s], and historical context.\n Both the action space and state space are highly dimensional and highly dynamic based on the dataset and all agents' decisions. I still haven't figured out how the feature engineering will work yet, but I assume (but PLEASE correct my ignorance) I will need a DNN architecture that is more complex than the average deep RL algorithm, and I have considering using CNNs as a component.\n At scale, the datasets can and will be very large, random, and dynamic.\n  \n​\n Note to reader: I am self-taught. If I stare at technical equations long enough and google for additional resources, I can figure out what I am looking at, but I am very comfortable with technical concepts being shared as if I was a 5 year old. \n    submitted by    /u/CoggFest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173dkt0/my_first_multiagent_rl_model/",
          "publishedOn": "2023-10-08T23:44:07.000Z",
          "wordCount": null,
          "title": "My First [Multi-Agent] RL model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/172w0a5/why_do_more_mujoco_mj_steps_lead_to_inaccurate/",
          "author": null,
          "description": "Hi!\n I tried to construct a simulation env following fetch_pick_and_place. I noticed that the following code is used to initialize the env:\n  for _ in range(10): self._mujoco.mj_step(self.model, self.data, nstep=self.n_substeps) \n Similarly, I followed the above code to initialize my own env with Mujoco menagerie Franka arm but got inaccurate configurations. As I reduced the number of loops, I got configurations closer to the desired configuration.\n Paradoxically, I need to randomize the position of the object in the air and give enough mj_step at the initial stage to make the object fall on the table. If I reduce the number of loops to reduce the number of times mj_step is executed, I can tell from the height value of the object that it doesn't quite fall on the table.\n So, my confusion is why more mj_steps lead to inaccurate simulation results, and how to make the object fall on the table and obtain the most accurate arm configuration.\n Thanks in advance!\n    submitted by    /u/UpperSearch4172  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/172w0a5/why_do_more_mujoco_mj_steps_lead_to_inaccurate/",
          "publishedOn": "2023-10-08T10:35:46.000Z",
          "wordCount": null,
          "title": "Why do more Mujoco mj_steps lead to inaccurate arm configurations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/172c1ra/need_help_on_state_space_design_adding/",
          "author": null,
          "description": "Hello, \n I am designing an environment for a robotic task. It's a relatively straightforward task so I started with proprioceptive inputs only. I have a policy working well on a completely flat surface. But once I started to add small bumps to make the surface uneven, neither the policy nor the training strategy worked anymore, even though those bumps are really really small. \n This is a little confusing since I imagine if this is a task for human, should be able to handle those changes even without exteroceptive inputs. So I am debating should I modify my reward design, pick a more efficient algorithm, or expand the state space directly with exoceptive sensors. \n ​\n Any advices would be appreciated!\n    submitted by    /u/Old_Reading_669  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/172c1ra/need_help_on_state_space_design_adding/",
          "publishedOn": "2023-10-07T17:38:23.000Z",
          "wordCount": 2671,
          "title": "Need help on state space design - Adding exteroceptive sensors or not?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1726e4o/what_is_the_exact_purpose_of_clip_function_in_ppo/",
          "author": null,
          "description": "submitted by    /u/aabra__ka__daabra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1726e4o/what_is_the_exact_purpose_of_clip_function_in_ppo/",
          "publishedOn": "2023-10-07T13:28:02.000Z",
          "wordCount": 2603,
          "title": "What is the exact purpose of clip function in PPO algorithm? PPO imposes policy ratio, r(θ) to stay within a small interval around 1. In the above equation, the function clip truncates the policy ratio between the range [1-ϵ, 1+ϵ]. If epsilon is taken as 0.2 or 0.25, what exactly is happening ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16zppdr/why_dqn_method_is_only_suitable_for_small/",
          "author": null,
          "description": "submitted by    /u/aabra__ka__daabra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16zppdr/why_dqn_method_is_only_suitable_for_small/",
          "publishedOn": "2023-10-04T15:08:34.000Z",
          "wordCount": null,
          "title": "Why DQN method is only suitable for small discrete action space? What is the issue if action space is large and continous?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16zjeka/up_to_date_metaworld_documentation/",
          "author": null,
          "description": "Hello everyone, I want to start experimenting with the domain of multi-tasking and meta-learning, thus I pip installed metaworld which is currently on version 2.0.0 if I'm not mistaken.\n I wanted to ask in case anybody knows, if there's any recent updated documentation, because the farama foundation on GIthub which is probably responsible for maintaining the Metaworld, has outdated code and documentation. (for example, presented code on Github's README has the command env.step(a) which returns 4 values instead of 5 that newer version outputs).\n From what I understand, they gather contributors for a big push regarding code and documentation on GItHub, where they will make up things up to date again but this announcement was 7 months ago.\n Sorry for the potentially wrong format of this question-post, I'm relatively new to reddit.\n I would appreciate any further knowledge on this topic and thanks everyone who's taking the time to read it!\n ​\n Metaworld Distribution from Farama Foundation on Github:\n https://github.com/Farama-Foundation/Metaworld\n    submitted by    /u/South_Book_5625  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16zjeka/up_to_date_metaworld_documentation/",
          "publishedOn": "2023-10-04T10:19:18.000Z",
          "wordCount": null,
          "title": "Up to date Metaworld documentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16zgs7x/the_future_of_game_testing_is_here_and_it_is/",
          "author": null,
          "description": "Hi everyone!\n We used our opensource library SheepRL 🐑 and our PyTorch implementation of DreamerV3 on Crafter, an open-world survival game, featuring randomly generated 2D worlds, in which players have the freedom to explore a large and expansive map and need to forage for food, collect materials, build tools and find shelter. Here is a short video 👉 https://youtu.be/7XEBT2msUUQ\n In open-world games, ensuring they are playable and bug-free is crucial, but is becoming increasingly difficult and time-consuming using manual game testing. Maximizing exploration using Reinforcement Learning is extremely useful for testing games at scale, because of the wide variety of gameplay scenes the player may encounter.\n Why is the test on Crafter so interesting for game testing?\n Because Crafter evaluates a large number of general capabilities related to the RL agent, like strong ability to generalise (new generated maps for each episode), to deal with partial observability (each input image reveals only a small part of the world) and to long-term reasoning and survival.\n These abilities are very useful for testing games at scale, providing developers with insights to optimise gameplay and player experience.\n The future of game testing is here, and it is powered by Artificial Intelligence! 🔥\n ---\n ❌ Are you interested in joining the project community? Get in touch 👉 https://github.com/Eclectic-Sheep/sheeprl ❌\n SheepRL 🐑 is open-source, fully written in PyTorch and accelerated with LightningFabric - by Lightning AI. Feel free to use it for your AI projects, and if you want to contribute, we are more than happy to accept your pull requests! ❤️\n    submitted by    /u/Manu_Orobix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16zgs7x/the_future_of_game_testing_is_here_and_it_is/",
          "publishedOn": "2023-10-04T07:31:09.000Z",
          "wordCount": null,
          "title": "The future of game testing is here, and it is powered by Artificial Intelligence! 🔥",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16zfr1n/can_i_use_continuous_algorithms_eg_td3_for/",
          "author": null,
          "description": "My environment has hybrid action spaces and I was wondering if I can use continuous algorithms for discrete action spaces. I'm asking this because, well, agent can't learn and I'm trying to find the source of error. I was wondering if this was the source of problem.\n ​\n My Assumptions On Solving This Problem:\n - Discrete is subspace of continuous, thus continuous algorithms will be able to handle discrete action spaces as well.\n - A non-hybrid action-space algorithm will be simpler than hybrid-action-space algorithms.\n ​\n Method (I'm only describing the discrete action here):\n - Use TD3 as the training algorithm. No modification from the original training code. TD3 algorithm has been verified on Pendulum and other environments created for unit test purposes.\n - Policy network outputs the a…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16zfr1n/can_i_use_continuous_algorithms_eg_td3_for/",
          "publishedOn": "2023-10-04T06:26:36.000Z",
          "wordCount": null,
          "title": "Can I use Continuous algorithms (e.g. TD3) for Discrete Action spaces?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16z6hfk/help_restricting_actions/",
          "author": null,
          "description": "Hello, I am new to RL, I am currently working on a school project that requires it. I am working on making a model to play a game very similar to wordle, so for the function of this post it may as well be wordle. \n Right now I am trying to get it to work with this gym https://github.com/zach-lawless/gym-wordle, and I will make my tweaks later. This gym has a multi discrete action space, which makes sense to me for a word, IDK if thats best. To validate words, it has its own exception type. I am trying to train this with stable_baselines3, but the exception keeps being raised, since it is trying to guess garbled words like \"xcjhr\". \n Is there a way I can validate actions before they are made so the model is restricted to only guessing valid words? Is there a better way to do this? It doesnt need to be the best, it really only has to sorta work. Any help is appreciated, thanks!\n    submitted by    /u/ClackHack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16z6hfk/help_restricting_actions/",
          "publishedOn": "2023-10-03T23:00:49.000Z",
          "wordCount": 2705,
          "title": "Help Restricting Actions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16z4cuy/looking_for_advice_on_training_and_reward/",
          "author": null,
          "description": "Hi Everyone,\n I'm venturing into a new territory of Reinforcement Learning (RL) through a personal project, despite having a solid background in various other ML domains. I'm developing an RL agent to play Skyjo, a turn-based card game, and I'm encountering some challenges related to reward optimization and game-ending decisions by the agents. I'd appreciate any advice or insights you might have!\n Project Overview:\n  \nObjective: Develop an RL model to play Skyjo competitively.\n Environment: Built using Gymnasium and Pytorch.\n Agents: Two agents working in tandem - one for card selection (discard/draw) and the other for action and location selection.\n Training: 4-8 agent instances play against each other.\n Repository: https://github.com/grantslewis/auto_skyjo\n  \nReward Structure:\n  \nSmall p…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16z4cuy/looking_for_advice_on_training_and_reward/",
          "publishedOn": "2023-10-03T21:38:49.000Z",
          "wordCount": 2858,
          "title": "Looking For Advice on Training and Reward Functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16yw4ji/my_frustration_level_with_torchkerastensorflow/",
          "author": null,
          "description": "RANT:\n I've tried every possible example I can get my hands on. I've looked at reference examples. I've looked at Medium articles. I've looked at stuff written by college freshmen. Every example I find for a DQN written either for torch or tensorflow (and either tf_agents or keras), seems to either have a nasty bug preventing it to work or such a severe memory leak that it is unusable. \n I tried Torch recently and was doing some simple gridworlds. It does fine for tiny gridworlds like 5x5. I decided to push it a little (not much at all) to a known 21x21 gridworld from recognized papers - reference example died and ran out of memory after 3000 episodes - I mean - really? 3000 episodes? I ran on CPU and gave it 64GB. I don't know how much memory this SHOULD take. I can do it in a Q-Table for…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16yw4ji/my_frustration_level_with_torchkerastensorflow/",
          "publishedOn": "2023-10-03T16:14:51.000Z",
          "wordCount": 2990,
          "title": "My frustration level with Torch/Keras/Tensorflow and DQNs is killing me",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16yuhto/advice_to_improve_outcome_on_a_turnbased_strategy/",
          "author": null,
          "description": "Hello everyone, \n I'm a total beginner in the reinforcement learning (RL) community, and I would appreciate some advice on a problem I'm currently facing. I've created a simple 2D turn-based game with only movement at the moment (I will also add combat features when I have success with training an AI for the movements).\n Game\n The rules are simple :\n  \nA grid of 14x40 (560 cells in total)\n 1 Agent with a limited number of Move Point (MP) \n 1 Target that does not move (atm)\n The agent can end its turn to get its MP back\n  \nI already implemented a pathfinding algorithm using A* which works really well but I would like to train an AI to reach the target as fast as possible (turn-wise).\n Here is a simulation of a state : \n ​\n https://preview.redd.it/0p5yijnb60sb1.png?width=442&format=png&auto=…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16yuhto/advice_to_improve_outcome_on_a_turnbased_strategy/",
          "publishedOn": "2023-10-03T15:11:41.000Z",
          "wordCount": 3031,
          "title": "Advice to improve outcome on a turn-based strategy game",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16yt6el/cleanba_our_new_distributed_drl_platform_is/",
          "author": null,
          "description": "submitted by    /u/vwxyzjn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16yt6el/cleanba_our_new_distributed_drl_platform_is/",
          "publishedOn": "2023-10-03T14:19:14.000Z",
          "wordCount": 2544,
          "title": "Cleanba, our new distributed DRL platform is finally out 🤗",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16y8sre/d_rl_agenda_after_llms_or_s4/",
          "author": null,
          "description": "Many other students in my research institution are pretty worried after ChatGPT / LLMs about continuing work in RL and are thinking of leaving the field.\n What are main the open problems in RL after LLMs and S4 can solve a hefty chunk of sequence learning problems?\n    submitted by    /u/Cultural-Average3959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16y8sre/d_rl_agenda_after_llms_or_s4/",
          "publishedOn": "2023-10-02T21:20:13.000Z",
          "wordCount": 2585,
          "title": "[D] RL agenda after LLMs or S4?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16xv79l/rlhf_without_gae/",
          "author": null,
          "description": "If I already have a trained reward model, say a sentiment classification model, that I'd like to use for PPO-based RLHF, I believe the standard method would be to instantiate the Critic/value function using the reward model, and train it further during PPO, correct?\n Would it even make sense to try PPO for RLHF without using the GAE term and thus without the value function, and just directly using the reward model's output as the advantage?\n It seems that this would be require viewing the entire generation as a single action (rather than each token's generation as an action), but most of the articles I've read on RLHF seem to treat it that way. On the other hand, all the code implementations I've seen have an Actor-Critic model producing values at each token, which I think implies that each token is an action.\n Edit: Apologies if any of this is just me having fundamental gaps in my understanding!\n    submitted by    /u/ganzzahl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16xv79l/rlhf_without_gae/",
          "publishedOn": "2023-10-02T12:20:04.000Z",
          "wordCount": 2695,
          "title": "RLHF without GAE",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16xr5l2/3player_graph_pursuit_game/",
          "author": null,
          "description": "So I am trying to find NE using rl algorithms for a turn based deterministic graph pursuit game. I have a way of checking if the strategies of players 1,2,3 are a NE and thought of using Q-Learning and see if it converges to a NE. Thus far it doesnt seem to work and I wonder if I made a mistake.\n The state is described as: St = [x1 x2 x3 p] where current player is p and x1,x2,x3 are the locations of the players in the graph\n Players have value functions Q^1(St), Q^2(St), Q^3(St)\n The way I update my value function is:\n player i choose e-greedy action a_t and the new state St_new\n Q^i(St) = (1-alpha)*Q^i(St)+alpha*gamma*Q(St_new)\n I have tried using a memory buffer but I havent improve the convergence success. I check if the if the values are a NE every 1000 iterations. It only converges for simple graphs.\n Do you think the way I update my value function is correct? Do you have any other traditional algorithms to suggest? Shall I move to deep learning? I am worried if simple algorithms cant converge the neural networks wont either... \n I tried to implemenet Nash Q learning following the paper:https://www.jmlr.org/papers/volume4/hu03a/hu03a.pdf\n but I am not sure if implemented correctly for a turn based game\n    submitted by    /u/__gp_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16xr5l2/3player_graph_pursuit_game/",
          "publishedOn": "2023-10-02T08:29:28.000Z",
          "wordCount": 2744,
          "title": "3-player graph pursuit game",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16x5ilz/reinforcement_learning_computer_vision_listing/",
          "author": null,
          "description": "Hello everyone!\n A while back, I stumbled upon an interesting paper that applied Reinforcement Learning to Object Localization. I got fascinated by how computer vision tasks could be transformed into a reinforcement learning problem, making it feel like a Markov decision process !\n So, i've decided to create a repository to compile all the existing (published) papers that delve into Reinforcement Learning in Computer Vision : https://github.com/rayanramoul/RLCV-Papers\n If you have any papers in mind or recommendations to enhance the repository, please don't hesitate to share them. Your input would be greatly appreciated!\n Thank you! :)\n    submitted by    /u/raysamram  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16x5ilz/reinforcement_learning_computer_vision_listing/",
          "publishedOn": "2023-10-01T16:23:54.000Z",
          "wordCount": 2697,
          "title": "Reinforcement Learning + Computer Vision listing papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16wmbbu/multiagent_dqn_not_learning_for_clean_up_game/",
          "author": null,
          "description": "The environment of the Clean Up game is simple: in a 25*18 grid world, there's dirt spawning on the left side and apples spawning on the other. Agents get a +1 reward for eating an apple (by stepping onto it). Agents clean the dirt also by stepping on it (no reward). Agent can go up, down, left, right. The game goes on for 1000 steps. Apple's spawn probability depends on the amount of dirt (less dirt, higher the probability). Currently, the observation for each agent has the manhatten distance to their closest apple and dirt.\n I have tried multiple ways of training this, including changing the observation space of the agents. But it seems the result does not outperform random agents by any significant amount.\n The network is simple, it tries to take in all the observations for all the agen…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16wmbbu/multiagent_dqn_not_learning_for_clean_up_game/",
          "publishedOn": "2023-10-01T00:09:19.000Z",
          "wordCount": 3039,
          "title": "Multi-Agent DQN not learning for Clean Up Game - Reward slowly decreasing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16w5lug/testing_rnn_with_rllib/",
          "author": null,
          "description": "Hi folks! Since you've saved my ass before, maybe you have an idea about my issue here, too. I'm training and testing a custom RNN, but I receive the following error message: \n File \"/home/.conda/envs/ray/lib/python3.9/site-packages/ray/rllib/utils/threading.py\", line 24, in wrapper return func(self, *a, **k)\n File \"/home/.conda/envs/ray/lib/python3.9/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 1291, in _compute_action_helper\n dist_inputs, state_out = self.model(input_dict, state_batches, seq_lens)\n File \"/home/.conda/envs/ray/lib/python3.9/site-packages/ray/rllib/models/modelv2.py\", line 259, in __call__\n res = self.forward(restored, state or [], seq_lens)\n File \"/home/.conda/envs/ray/lib/python3.9/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 92, in forward\n i…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16w5lug/testing_rnn_with_rllib/",
          "publishedOn": "2023-09-30T12:30:53.000Z",
          "wordCount": 2775,
          "title": "Testing RNN with RLlib",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16viyo6/metas_technological_marvel_aipowered_tools_and/",
          "author": null,
          "description": "submitted by    /u/Allinhalf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16viyo6/metas_technological_marvel_aipowered_tools_and/",
          "publishedOn": "2023-09-29T18:15:04.000Z",
          "wordCount": 2615,
          "title": "Meta's Technological Marvel: AI-Powered Tools and Intuitive Smart Glasses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16vfyzd/why_is_dyna_q_not_outperforming_q_learning_in/",
          "author": null,
          "description": "I coded a dyna Q implementation based on the algorithm given in Sutton's book over here. However, it seems like both are equally sample efficient on the cliff walking environment. Here is my code.\n These are my results -\n ​\n ​\n https://preview.redd.it/z7xwow5hz7rb1.png?width=585&format=png&auto=webp&s=90b33eb4c754e199e9bf15499a78e0f42e05f5d2\n The only think that came to my mind was to increase the model sampling rate (`n_iters`). Even after assigning a large value to it, the performance doesn't change.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16vfyzd/why_is_dyna_q_not_outperforming_q_learning_in/",
          "publishedOn": "2023-09-29T16:18:03.000Z",
          "wordCount": 2675,
          "title": "Why is dyna Q not outperforming Q learning in terms of sample efficiency?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16vcuno/how_can_i_config_and_build_mjpc_c_software/",
          "author": null,
          "description": "I'm trying to install and run this open-source project https://github.com/google-deepmind/mujoco_mpc. It's called MJPC, and it's a C++ software that displays a real-time interactive interface. I've cloned the code, installed CMake, and gcc version 13.1.0 to run C++20. I've also installed the CMake Tools and C/C++ extensions in VSCode as instructed. However, I'm not sure what to do next. I have no experience with C++ and software coding, configuring in VSCode, or building it. Please help me if you can, provide detailed guidance. \n    submitted by    /u/Nghiattk27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16vcuno/how_can_i_config_and_build_mjpc_c_software/",
          "publishedOn": "2023-09-29T14:17:21.000Z",
          "wordCount": 2686,
          "title": "How can I config and build MJPC c++ software?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16val6g/llm_agents_for_rl_envs/",
          "author": null,
          "description": "Has anyone here tried using LLM Agents to solve RL environments? I'm curious about your experiences. Considering that performing a single action involves a chain of thoughts, how fast did your experiments go? Please feel free to add any additional comments about this. \n Cheers!\n    submitted by    /u/stinoco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16val6g/llm_agents_for_rl_envs/",
          "publishedOn": "2023-09-29T12:40:31.000Z",
          "wordCount": 2638,
          "title": "LLM Agents for RL envs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16v7chi/shape_formation_with_multiagent_reinforcement/",
          "author": null,
          "description": "Hey everyone,\n I'm trying to write MARL code with MAPPO policy to train three agents to form a triangle shape. \n I'm relatively new to RL, having completed the fundamentals, but I'm struggling to come up with suitable resources which can teach me how to implement codes on python.\n I'd be really greatful if someone could share some insights or useful resources where I can learn to code and implement MARL.\n    submitted by    /u/The_One263  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16v7chi/shape_formation_with_multiagent_reinforcement/",
          "publishedOn": "2023-09-29T09:55:38.000Z",
          "wordCount": 2672,
          "title": "Shape Formation with Multi-Agent Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16v7ch4/shape_formation_with_multiagent_reinforcement/",
          "author": null,
          "description": "Hey everyone,\n I'm trying to write MARL code with MAPPO policy to train three agents to form a triangle shape. \n I'm relatively new to RL, having completed the fundamentals, but I'm struggling to come up with suitable resources which can teach me how to implement codes on python.\n I'd be really greatful if someone could share some insights or useful resources where I can learn to code and implement MARL.\n    submitted by    /u/The_One263  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16v7ch4/shape_formation_with_multiagent_reinforcement/",
          "publishedOn": "2023-09-29T09:55:36.000Z",
          "wordCount": 2672,
          "title": "Shape Formation with Multi-Agent Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16v13v5/curiosity_exploration_with_rllib/",
          "author": null,
          "description": "Hi! I’ve been training a MultiAgentEnv with Curiosity, but I’d like to extend my action space to be a Dictionary. Are there any similar modules I could use instead or is there any way to use Curiosity with a Dictionary consisting of a Box and a Discrete action space.\n Thank you!\n    submitted by    /u/tessherelurkingnow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16v13v5/curiosity_exploration_with_rllib/",
          "publishedOn": "2023-09-29T03:46:35.000Z",
          "wordCount": 2643,
          "title": "Curiosity/ Exploration with Rllib",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16urp5l/modern_reinforcement_learning_for_video_game_npcs/",
          "author": null,
          "description": "submitted by    /u/akliyen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16urp5l/modern_reinforcement_learning_for_video_game_npcs/",
          "publishedOn": "2023-09-28T21:08:14.000Z",
          "wordCount": 2599,
          "title": "Modern reinforcement learning for video game NPCs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16uht6v/reinforcement_learning_in_automating_game_testing/",
          "author": null,
          "description": "The role of Reinforcement learning in automating game testing is becoming increasingly crucial, making it more efficient and effective. Manual testing, while essential, is extremely time-consuming and subject to human error. \n Our opensource library SheepRL 🐑 can be used to test whether the game dynamics is well defined: what if a player can finish the game with just a few moves? 🎮\n This video shows that our agent (Kasumi, on the left) is able to win the game in the hardest modality by standing down and throwing kicks. 🥊\n This can be helpful for a game developer to:\n ​\n  \nunderstand where and how intervene to achieve a more playful game\n \npredict and correct bugs early in the game development process\n enhance the gaming experience and final product quality\n reduce time and resources spent on debugging.\n  \nThe game has changed 🔥 and it is up to us to play it with (human + artificial) intelligence!\n Thanks to u/DIAMBRA_AIArena for the video!\n ---\n ❌ Are you interested in joining the project community? Get in touch ❌\n SheepRL 🐑 is open-source, fully written in PyTorch and accelerated with LightningFabric - by Lightning AI\n Feel free to use it for your Artificial Intelligence projects, and if you want to contribute, we are more than happy to accept your pull requests! ❤️\n https://reddit.com/link/16uht6v/video/ve3derxsc0rb1/player\n    submitted by    /u/Manu_Orobix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16uht6v/reinforcement_learning_in_automating_game_testing/",
          "publishedOn": "2023-09-28T14:39:36.000Z",
          "wordCount": 2813,
          "title": "Reinforcement learning in automating game testing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16u44zq/proofs_in_the_original_qlearning_technical_notes/",
          "author": null,
          "description": "I'm not sure it's the right place for this, but I was going through the proofs in the \"original\" 1992 technical notes of Q-learning, and a couple of points raised some questions:\n 1) In the Proof of lemma B.4:\n https://preview.redd.it/7g6pputdqwqb1.png?width=1006&format=png&auto=webp&s=fe4afeac3b06deee6c80105b280a0085bdcfbe51\n where do P_{xy}^2(a_2) and R_x(a_2) come from? If we apply the definitions of Q'(x, a_1, a_2) and Q(x, a_1, a_2) to get the bound, P_{xy}^2(a_2) and R_x(a_2) should not be there. Are they just notation errors or is it correct and I'm missing something?\n ​\n 2) I don't quite get how the bounds on P and R are computed in Section 3.2:\n https://preview.redd.it/p06ysjewqwqb1.png?width=962&format=png&auto=webp&s=a5929e701099dc6e4543efe7681f96f12f543fa8\n Considering the results in B.4 (i.e., the bounds for the distance between the chain's P, R and the real ones), I don't understand how they arrive at this conclusion. \n ​\n I'd greatly appreciate any intuitions about these, or if someone can point me in the right direction :)\n    submitted by    /u/Beautiful_Zebra_198  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16u44zq/proofs_in_the_original_qlearning_technical_notes/",
          "publishedOn": "2023-09-28T02:37:03.000Z",
          "wordCount": 2744,
          "title": "Proofs in the original Q-Learning technical notes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16tv288/online_training_from_demonstrations/",
          "author": null,
          "description": "I would like to embark on online training for an F1TENTH racing car, starting from scratch and leveraging demonstration data. Currently, it appears that DDPGfD is a promising approach. Does anyone have any research papers they can recommend or suggestions on how to get started?\n    submitted by    /u/anointedninja  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16tv288/online_training_from_demonstrations/",
          "publishedOn": "2023-09-27T20:27:12.000Z",
          "wordCount": 2640,
          "title": "Online Training from Demonstrations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16tlhxw/what_if_the_robots_were_very_nice_while_they_took/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16tlhxw/what_if_the_robots_were_very_nice_while_they_took/",
          "publishedOn": "2023-09-27T14:03:38.000Z",
          "wordCount": 2624,
          "title": "\"What If the Robots Were Very Nice While They Took Over the World?\" (reflections on CICERO & _Diplomacy_)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "RL News",
      "feedUrl": "https://www.getrevue.co/profile/seungjaeryanlee?format=rss",
      "siteUrl": "http://rlnews.ryanlee.ai/",
      "articles": []
    },
    {
      "title": "Damian Bogunowicz - dtransposed",
      "feedUrl": "https://dtransposed.github.io/feed.xml",
      "siteUrl": "http://dtransposed.github.io/",
      "articles": []
    },
    {
      "title": "Data Science Central",
      "feedUrl": "http://feeds.feedburner.com/FeaturedBlogPosts-DataScienceCentral?format=xml",
      "siteUrl": "https://www.datasciencecentral.com/",
      "articles": [
        {
          "id": "https://www.datasciencecentral.com/?p=63412",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 24 October 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-24-october-2023/",
          "publishedOn": "2023-10-24T19:58:44.000Z",
          "wordCount": 6187,
          "title": "DSC Weekly 24 October 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63372",
          "author": "Venkata Nori",
          "description": "Written by Venkata Nori and Kshitij Gopali. Introduction As technology is evolving, most companies in the world are adopting advanced mechanisms for their daily tasks of storing/updating data, project management & tracking, incident management, version control, etc. Periodically, these companies’ business stakeholders would want to extract and analyze the data to see how the business… Read More »Seamless integration of data from unconventional source systems into Business Intelligence using data science techniques\nThe post Seamless integration of data from unconventional source systems into Business Intelligence using data science techniques appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/seamless-integration-of-data-from-unconventional-source-systems-into-business-intelligence-using-data-science-techniques/",
          "publishedOn": "2023-10-24T16:45:26.000Z",
          "wordCount": 7441,
          "title": "Seamless integration of data from unconventional source systems into Business Intelligence using data science techniques",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Picture-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63366",
          "author": "Evan Morris",
          "description": "A recent interview by Medical Device Network with GlobalData medical analyst Alexandra Murdoch shares interesting insights into cybersecurity for medical devices.\nThe post How data science and medical device cybersecurity cross paths to protect patients and enhance healthcare appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-data-science-and-medical-device-cybersecurity-cross-paths-to-protect-patients-and-enhance-healthcare/",
          "publishedOn": "2023-10-24T16:02:02.000Z",
          "wordCount": 6523,
          "title": "How data science and medical device cybersecurity cross paths to protect patients and enhance healthcare",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/healthcare.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63396",
          "author": "Erika Balla",
          "description": "In the contemporary business landscape, where data is heralded as the new oil, Business Analytics has emerged as a pivotal domain, steering organizations towards informed decision-making and strategic planning. business analytics encompasses the utilization of data, statistical algorithms, and machine learning techniques to comprehend the business context, forecast future trends, and facilitate optimal decision-making. The… Read More »Skills required to excel in a business analytics career\nThe post Skills required to excel in a business analytics career appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/skills-required-to-excel-in-a-business-analytics-career/",
          "publishedOn": "2023-10-24T15:34:44.000Z",
          "wordCount": 6560,
          "title": "Skills required to excel in a business analytics career",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/img2-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63386",
          "author": "Yana Ihnatchyck",
          "description": "In an era where data drives decisions, GenAI emerges as a prodigy force in the realm of data analytics. According to Statista, LLM’s market size is expected to show an annual growth rate of 24%, resulting in a market volume of $207 bn by the end of 2030.  This cutting-edge technology, built on sophisticated algorithms… Read More »GenAI: The game-changer in data analytics\nThe post GenAI: The game-changer in data analytics appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/genai-the-game-changer-in-data-analytics/",
          "publishedOn": "2023-10-24T13:30:15.000Z",
          "wordCount": 6453,
          "title": "GenAI: The game-changer in data analytics",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/ai-software.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63389",
          "author": "Bill Schmarzo",
          "description": "I recently wrote the book “AI & Data Literacy: Empowering Citizens of Data Science” to help non-data scientists – which is most of the world – understand the risks associated with how companies capture and use your personal data to influence your viewing and buying habits… and even your political and societal beliefs.  And while… Read More »Grade School & Preteen AI & Data Literacy\nThe post Grade School & Preteen AI & Data Literacy appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/grade-school-preteen-ai-data-literacy/",
          "publishedOn": "2023-10-21T12:19:58.000Z",
          "wordCount": 6518,
          "title": "Grade School & Preteen AI & Data Literacy",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Slide1-6.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63364",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 17 October 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-17-october-2023/",
          "publishedOn": "2023-10-17T19:28:23.000Z",
          "wordCount": 5919,
          "title": "DSC Weekly 17 October 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63362",
          "author": "Michael Peres",
          "description": "In a recent podcast episode, Lex Freedman and Mark Zuckerberg convened in the Metaverse, where the digital realm intertwines with reality. Their astonishingly realistic interaction, while highlighting technological advancements, also prompted deeper contemplations. As the line between digital recreations and reality becomes increasingly blurred, it beckons questions about the definitions of identity and consciousness and… Read More »Uncharted digital landscapes and the quest for timeless identity\nThe post Uncharted digital landscapes and the quest for timeless identity appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/uncharted-digital-landscapes-and-the-quest-for-timeless-identity/",
          "publishedOn": "2023-10-17T19:09:16.000Z",
          "wordCount": 6558,
          "title": "Uncharted digital landscapes and the quest for timeless identity",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Mark-Zuckerberg-and-Lex-Fridman-on-Lex-Fridmans-recent-podcast.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63356",
          "author": "Kartik Gandhi, Dr. Suraj Pardeshi",
          "description": "Introduction to Internet of Things (IOT): Internet of Things (IoT) represents the fourth-generation technology that facilitates the connection and transformation of products into smart, intelligent and communicative entities. IoT has already established its footprint in various business verticals such as medical, heath care, automobile, and industrial applications. IoT empowers the collection, analysis, and transmission of… Read More »Internet Of Things (IOT):  Application In Hazardous Locations\nThe post Internet Of Things (IOT):  Application In Hazardous Locations appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/internet-of-things-iot-application-in-hazardous-locations/",
          "publishedOn": "2023-10-17T19:03:35.000Z",
          "wordCount": 6890,
          "title": "Internet Of Things (IOT):  Application In Hazardous Locations",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/AdobeStock_370505641-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63354",
          "author": "Jeremy Bowen",
          "description": "Long before passengers sit back, relax, and enjoy their flight, data has played a critical role in getting them to their seats. It has been a cornerstone of the aviation industry since the early days of air travel. Indeed, from the early 20th century, data was collected through manual processes such as pilots logging information… Read More »The digital evolution in aviation: how big data and analytics are transforming the industry\nThe post <strong>The digital evolution in aviation: how big data and analytics are transforming the industry</strong> appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-digital-evolution-in-aviation-how-big-data-and-analytics-are-transforming-the-industry/",
          "publishedOn": "2023-10-17T18:50:27.000Z",
          "wordCount": 5966,
          "title": "The digital evolution in aviation: how big data and analytics are transforming the industry",
          "imageUrl": null
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63347",
          "author": "Shanthababu Pandian",
          "description": "Introduction Hello AI&ML Engineers, as you all know, Artificial Intelligence (AI) and Machine Learning Engineering are the fastest growing fields, and almost all industries are adopting them to enhance and expedite their business decisions and needs; for the same, they are working on various aspects and preparing the data for the AIML platform with the help of SMEs… Read More »Explainable Artificial Intelligence (XAI) for AI & ML Engineers\nThe post Explainable Artificial Intelligence (XAI) for AI & ML Engineers appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/explainable-artificial-intelligence-xai-for-ai-ml-engineers/",
          "publishedOn": "2023-10-16T15:26:13.000Z",
          "wordCount": 6934,
          "title": "Explainable Artificial Intelligence (XAI) for AI & ML Engineers",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/14775XMI.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63348",
          "author": "Bill Schmarzo",
          "description": "The ability of Generative AI (GenAI) tools to deliver accurate and reliable outputs entirely depends on the accuracy and reliability of the data used to train the Large Language Models (LLMs) that power the GenAI tool. Unfortunately, the Law of GIGO – Garbage In, Garbage Out – threatens the widespread adoption of GenAI.  Whether generating… Read More »AI’s Kryptonite: Data Quality\nThe post AI’s Kryptonite: Data Quality appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ais-kryptonite-data-quality/",
          "publishedOn": "2023-10-14T18:53:32.000Z",
          "wordCount": 6730,
          "title": "AI’s Kryptonite: Data Quality",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Slide1-5.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63333",
          "author": "Ryan Williamson",
          "description": "Artificial Intelligence (AI) is emerging as a formidable force, revolutionizing how we conceive, create, and deliver software solutions. As technology advances at an unprecedented pace, the role of AI in this domain has become increasingly significant. It’s no longer just a buzzword; it’s a fundamental tool that promises to reshape the entire software development process.… Read More »Significance of AI in the development of software products\nThe post Significance of AI in the development of software products appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/significance-of-ai-in-the-development-of-software-products/",
          "publishedOn": "2023-10-13T17:35:00.000Z",
          "wordCount": 5838,
          "title": "Significance of AI in the development of software products",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Significance-of-AI-in-Development-of-Software-Products-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63341",
          "author": "Aileen Scott",
          "description": "Companies, more often, pay attention to automation and innovation over proficiency and productivity. However, firms can maintain a balance between both due to the extensive usage of AI and data science programs. Here are the stats that show the impact of AI and data science in diverse sectors: Applications of AI and data science have… Read More »Future of AI and data science – How to secure a bright career\nThe post Future of AI and data science – How to secure a bright career appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/future-of-ai-and-data-science-how-to-secure-a-bright-career/",
          "publishedOn": "2023-10-13T15:47:39.000Z",
          "wordCount": 6348,
          "title": "Future of AI and data science – How to secure a bright career",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Future-of-AI-and-Data-Science-How-to-Secure-A-Bright-Career.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63337",
          "author": "Roger Brown",
          "description": "The advent of generative AI is empowering everyone alike – organizations, small businesses, individuals, students, and medical professionals, to name a few. The last couple of years have been revolutionary for artificial intelligence innovation and transformation. How will 2024 shape up for AI, AI tools, and related professionals? Let’s analyze the trends that are most… Read More »12 Generative AI Trends to Watch Out for\nThe post 12 Generative AI Trends to Watch Out for appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/12-generative-ai-trends-to-watch-out-for/",
          "publishedOn": "2023-10-12T11:03:08.000Z",
          "wordCount": 6148,
          "title": "12 Generative AI Trends to Watch Out for",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/3-Month-for-2024-12-Generative-AI-Trends-to-Watch-Out-for.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63331",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 10 October 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-10-october-2023/",
          "publishedOn": "2023-10-10T18:50:24.000Z",
          "wordCount": 6038,
          "title": "DSC Weekly 10 October 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63034",
          "author": "Ovais Naseem",
          "description": "Introduction  In an era where data is often termed the ‘new oil,’ its security holds unparalleled importance for businesses across industries. With the proliferation of digital platforms, sharing business-critical information has become routine yet perilous. From financial records to customer data, organizations frequently exchange sensitive information that, if compromised, could have dire consequences. Given the… Read More »How to ensure data security when sharing business-critical information\nThe post How to ensure data security when sharing business-critical information appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-to-ensure-data-security-when-sharing-business-critical-information/",
          "publishedOn": "2023-10-10T18:12:57.000Z",
          "wordCount": 6274,
          "title": "How to ensure data security when sharing business-critical information",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/images.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63303",
          "author": "John Lee",
          "description": "Gartner predicts blockchain’s economic impact to reach $176 billion by 2025 and $3.1 trillion by 2030. The AI software market is expected to reach $134.8 billion by 2025. Blockchain and AI benefit businesses. AI models process data, extract insights, and make decisions. Blockchain ensures data integrity and trust among participants. Read on to discover the… Read More »How does combining blockchain and AI create new business opportunities?\nThe post How does combining blockchain and AI create new business opportunities? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-does-combining-blockchain-and-ai-create-new-business-opportunities/",
          "publishedOn": "2023-10-10T16:23:00.000Z",
          "wordCount": 6505,
          "title": "How does combining blockchain and AI create new business opportunities?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/blockchain.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63315",
          "author": "Erika Balla",
          "description": "In the contemporary digital landscape, data has emerged as a critical asset for organizations aiming to make informed decisions and foster innovation. Data analytics can unlock a treasure trove of insights, driving competitive advantage and operational excellence by leveraging the vast amounts of data generated every second. As a consequence, the demand for skilled professionals… Read More »Understanding the difference: Data analyst, data scientist, and data engineer\nThe post Understanding the difference: Data analyst, data scientist, and data engineer appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/understanding-the-difference-data-analyst-data-scientist-and-data-engineer/",
          "publishedOn": "2023-10-10T13:30:40.000Z",
          "wordCount": 7123,
          "title": "Understanding the difference: Data analyst, data scientist, and data engineer",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/1_iY8FOlPv0CJ3AOxQ7t8zHw.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63320",
          "author": "Bill Schmarzo",
          "description": "I’ve been in this industry for over 40 years (yes, I just started in the data and analytics industry when I was 11), and I have NEVER seen anything like Artificial Intelligence (AI) and Generative AI (GenAI) capture the attention of CEOs (and the dystopic fear of everyone else). Is AI a game-changer?  Definitely!  Will… Read More »11 Questions Every CEO Should Ask about AI / Generative AI\nThe post 11 Questions Every CEO Should Ask about AI / Generative AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/11-questions-every-ceo-should-ask-about-ai-generative-ai/",
          "publishedOn": "2023-10-10T11:44:54.000Z",
          "wordCount": 6813,
          "title": "11 Questions Every CEO Should Ask about AI / Generative AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Slide1-4.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63300",
          "author": "Evan Rogen",
          "description": "This cutting-edge area of AI focuses on building models that can create original material, including music, images, text, and even entire virtual worlds.\nThe post Revolutionizing business: A look at generative AI’s real-world impact appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/revolutionizing-business-a-look-at-generative-ais-real-world-impact/",
          "publishedOn": "2023-10-09T12:38:10.000Z",
          "wordCount": 6119,
          "title": "Revolutionizing business: A look at generative AI’s real-world impact",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Revolutionizing-Business-A-Look-at-Generative-AIs-Real-World-Impact.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63293",
          "author": "ajitjaokar",
          "description": "One of my students asked me: “Which is the best area/s for Gen AI start-ups?” This is not an easy question – mainly due to the dynamic nature of AI, but here are two reference points. The first is a Generative AI Tools Landscape from DataCamp. This gives both the categories and the subcategories for… Read More »Generative AI megatrends: Gen AI start-up ecosystem\nThe post Generative AI megatrends: Gen AI start-up ecosystem appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-gen-ai-start-up-ecosystem/",
          "publishedOn": "2023-10-05T23:14:16.000Z",
          "wordCount": 5699,
          "title": "Generative AI megatrends: Gen AI start-up ecosystem",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/AdobeStock_611053470-1024x574.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63291",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 3 October 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-3-october-2023/",
          "publishedOn": "2023-10-03T19:44:08.000Z",
          "wordCount": 5974,
          "title": "DSC Weekly 3 October 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63279",
          "author": "ajitjaokar",
          "description": "One of the most impressive generative AI applications I have seen is viperGPT. The image / site explains it best. The steps are: This example, earlier this year, showed the potential of multimodal LLMs And as of last week, that future is upon us ChatGPT can now see, hear & speak. What are the implications… Read More »Generative AI Megatrends: ChatGPT can see, hear and speak – but what does it mean when ChatGPT can think?\nThe post Generative AI Megatrends: ChatGPT can see, hear and speak – but what does it mean when ChatGPT can think? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-chatgpt-can-see-hear-and-speak-but-what-does-it-mean-when-chatgpt-can-think/",
          "publishedOn": "2023-10-03T19:33:40.000Z",
          "wordCount": 5992,
          "title": "Generative AI Megatrends: ChatGPT can see, hear and speak – but what does it mean when ChatGPT can think?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Screenshot-2023-10-02-22.03.21-1-1024x372.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63283",
          "author": "Erika Balla",
          "description": "In the ever-evolving landscape of the digital era, the relentless quest for deriving actionable insights from a sea of information has become the cornerstone of innovation and strategy. As businesses and organizations strive to navigate the complex corridors of big data, the spotlight invariably falls upon the expertise of data scientists, the modern-day architects of… Read More »Cracking the code: The rising demand for data scientists in various industries\nThe post Cracking the code: The rising demand for data scientists in various industries appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/cracking-the-code-the-rising-demand-for-data-scientists-in-various-industries/",
          "publishedOn": "2023-10-03T19:32:39.000Z",
          "wordCount": 6387,
          "title": "Cracking the code: The rising demand for data scientists in various industries",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/The-Rising-Demand-for-Data-Scientists-in-Various-Industries.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63277",
          "author": "ajitjaokar",
          "description": "I recently subscribed to openAI GPT4 for the OpenAI Code Interpreter/Advanced data analytics. We are using it in our class at the University of Oxford.  Its really cool and we are also waiting the multimodal openAI features Recently, a well known AI critic said that he does not see how Generative AI companies could be… Read More »Generative AI megatrends: How many LLMs would you subscribe to?\nThe post Generative AI megatrends: How many LLMs would you subscribe to? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-how-many-llms-would-you-subscribe-to/",
          "publishedOn": "2023-10-03T19:31:10.000Z",
          "wordCount": 5667,
          "title": "Generative AI megatrends: How many LLMs would you subscribe to?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/cash-register-1885558_1280-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63259",
          "author": "Alan Morrison",
          "description": "Large language models (LLMs) for generating text and vision models for generating images are notoriously inefficient. The larger they get, the more power hungry they become.   Kisaco Research in September hosted a one-day event in Santa Clara dedicated to the topic of generative artificial intelligence (GAI) efficiency, followed by a three-day Summit on Hardware and… Read More »A few highlights of the Efficient Generative AI Summit (EGAIS)\nThe post A few highlights of the Efficient Generative AI Summit (EGAIS) appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-few-highlights-of-the-efficient-generative-ai-summit-egais/",
          "publishedOn": "2023-10-03T14:51:13.000Z",
          "wordCount": 6170,
          "title": "A few highlights of the Efficient Generative AI Summit (EGAIS)",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/image-from-rawpixel-id-5945466-jpeg-1024x310-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63273",
          "author": "Bill Schmarzo",
          "description": "We must move beyond just taming…to monetizing Language Models! In part 1 of this series on Small Language Models (“Use Case Language Models: Taming the LLM Beast – Part 1”), I explored the business and operational value of Use Case-specific Small Language Models (Use Case Language Models). Use case language models are trained or adapted… Read More »Entity Language Models: Monetizing Language Models – Part 2\nThe post <strong>Entity</strong> Language Models: <strong>Monetizing</strong> Language Models – Part 2 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/entity-language-models-monetizing-language-models-part-2/",
          "publishedOn": "2023-10-01T12:32:30.000Z",
          "wordCount": 6813,
          "title": "Entity Language Models: Monetizing Language Models – Part 2",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Slide4-2.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63254",
          "author": "Rytis Ulys",
          "description": "Big data has been around for some time now, becoming a more or less common concept in business. However, recent developments in AI technology have shaken up an already volatile field, inviting us to reconsider our projections of how the big data market will look in the future. We can already see the signs that… Read More »How will the Big Data market evolve in the future?\nThe post How will the Big Data market evolve in the future? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-will-the-big-data-market-evolve-in-the-future/",
          "publishedOn": "2023-09-28T17:53:26.000Z",
          "wordCount": 6494,
          "title": "How will the Big Data market evolve in the future?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_245562438-scaled.jpeg"
        }
      ]
    },
    {
      "title": "John D. Cook",
      "feedUrl": "https://www.johndcook.com/blog/feed",
      "siteUrl": "https://www.johndcook.com/blog",
      "articles": [
        {
          "id": "https://www.johndcook.com/blog/?p=215216",
          "author": "John",
          "description": "A couple days ago I wrote about the likelihood of the better team winning a best-of-five or best-of-seven series. That is, if the probability of X winning a game against Y is p > ½, how likely is it that X will win a majority of 5 games or a majority of 7 games. This […]\nBest of N series first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/24/best-of-n-series-2/",
          "publishedOn": "2023-10-24T14:13:38.000Z",
          "wordCount": 1678,
          "title": "Best of N series",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=215197",
          "author": "John",
          "description": "I discovered the Space Rocket History Podcast a while back and listened to all the episodes on the Apollo program. I’m now listening to the episodes on Skylab as they come out. I came for Apollo; I stayed for Skylab. I would not have sought out the episodes on Skylab, and that would have been […]\nLessons from Skylab first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/24/skylab/",
          "publishedOn": "2023-10-24T13:08:45.000Z",
          "wordCount": 1752,
          "title": "Lessons from Skylab",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=215183",
          "author": "John",
          "description": "This post will compute the center of curvature for an object described in the previous post. In order to do that we first need to describe principle curvature and Gauss curvature, and we’ll throw in mean curvature while we’re at it. Let S be a surface sitting in three dimensional space. No need for more […]\nCurvature: principal, Gauss, and mean first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/24/curvature/",
          "publishedOn": "2023-10-24T11:44:01.000Z",
          "wordCount": 1670,
          "title": "Curvature: principal, Gauss, and mean",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=215107",
          "author": "John",
          "description": "One year ago I wrote about a variant of the squircle that is quantitatively close to the customary definition but that has nicer algebraic properties. That post used the term p-squircle for the usual squircle with equation where p > 2, and the term s-squircle for the variation with equation where s is between 0 […]\nAn algebraic superegg first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/23/an-algebraic-superegg/",
          "publishedOn": "2023-10-24T01:32:55.000Z",
          "wordCount": 1564,
          "title": "An algebraic superegg",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=215014",
          "author": "John",
          "description": "What is nonlinear algebra? Negations are tricky. They may be the largest source of bugs in database queries. You have to carefully think about what exactly are you negating. Any time you see “non-” attached to something, you have to ask what the context is in which the negation takes place. For example, if you […]\nNonlinear algebra first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/23/nonlinear-algebra/",
          "publishedOn": "2023-10-23T15:04:45.000Z",
          "wordCount": 1769,
          "title": "Nonlinear algebra",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=214834",
          "author": "John",
          "description": "Three weeks ago I wrote about supereggs, a shape popularized by Piet Hein. One aspect of supereggs that I did not address is their stability. Looking at the photo above, you could imagine that if you gave the object a slight nudge it would not fall over. Your intuition would be right: supereggs are stable. […]\nStability of a superegg first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/22/stability-of-a-superegg/",
          "publishedOn": "2023-10-22T20:55:45.000Z",
          "wordCount": 1837,
          "title": "Stability of a superegg",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=214825",
          "author": "John",
          "description": "Suppose that when Team X and Team Y play, the probability that X will win a single game is p and the probability that Y will win is q = 1 − p. What is the probability that X will win the majority of a series of N games for some odd number N? We know intuitively […]\nBest-of-five versus Best-of-seven first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/22/best-of-n-series/",
          "publishedOn": "2023-10-22T16:30:05.000Z",
          "wordCount": 1566,
          "title": "Best-of-five versus Best-of-seven",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=214424",
          "author": "John",
          "description": "The HIPAA Safe Harbor provision says that data can be considered deidentified if 18 kinds of data are removed or reported at low resolution. At the end of the list of 18 items, there is an extra category, sometimes informally called the 19th rule: The covered entity does not have actual knowledge that the information […]\nThe 19th rule of HIPAA Safe Harbor first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/20/hipaa-safe-harbor/",
          "publishedOn": "2023-10-20T11:59:58.000Z",
          "wordCount": 1586,
          "title": "The 19th rule of HIPAA Safe Harbor",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=214248",
          "author": "John",
          "description": "I saw a comment from Christos Argyropoulos on Twitter implying that there’s a good scientific community on Bluesky, so I went there and looked around a little bit. I have account, but I haven’t done much with it. I was surprised that a fair number of people had followed me on Bluesky even though I […]\nBluesky first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/18/bluesky/",
          "publishedOn": "2023-10-19T02:22:55.000Z",
          "wordCount": 1460,
          "title": "Bluesky",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=214059",
          "author": "John",
          "description": "The -i flag to ask sed to edit a file in place works differently on Linux and MacOS. If you want to create a backup of your file before you edit it, say with the extension .bak, then on Linux you would run sed -i.bak myfile but for the version of sed that ships with […]\nPortable sed -i across MacOS and Linux first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/18/portable-sed-i/",
          "publishedOn": "2023-10-18T12:00:25.000Z",
          "wordCount": 1895,
          "title": "Portable sed -i across MacOS and Linux",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=213816",
          "author": "John",
          "description": "From Love What Lasts, Joshua Gibbs: … there are too many things in the world to care equally about them all. The sheer volume of things … demands that we have hierarchical standards by which to judge their value, or else we are condemned to give our lives over entirely to what is nearest, easiest, […]\nNearest, easiest, and most accessible first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/16/nearest/",
          "publishedOn": "2023-10-16T13:06:04.000Z",
          "wordCount": 1321,
          "title": "Nearest, easiest, and most accessible",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=213692",
          "author": "John",
          "description": "Draw three circles of radius r that intersect at a single point. Then draw a triangle connecting the remaining three points of intersection. (Each pair of circles intersects in two points, one of which is the point where all three circles intersect, so there are three other intersection points.) Then the circumcircle of the triangle, […]\nJohnson circle theorem first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/15/johnson-circle-theorem/",
          "publishedOn": "2023-10-15T21:28:36.000Z",
          "wordCount": 1556,
          "title": "Johnson circle theorem",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=213505",
          "author": "John",
          "description": "Let Q be a convex quadrilateral with at most two parallel sides. Draw the two diagonals then draw a line through their midpoints. This line is called the Newton line. (The requirement that at most two sides are parallel insures that the midpoints are distinct and so there is a unique line joining them.) In […]\nNewton line first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/14/newton-line/",
          "publishedOn": "2023-10-14T13:32:45.000Z",
          "wordCount": 1440,
          "title": "Newton line",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=213221",
          "author": "John",
          "description": "This post is a follow-on to a discussion that started on Twitter yesterday. This tweet must have resonated with a lot of people because it’s had over 230,000 views so far. You almost have to study advanced math to solve basic math problems. Sometimes a high school student can solve a real world problem that […]\nHomework problems are rigged first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/12/homework-problems-are-rigged/",
          "publishedOn": "2023-10-12T14:19:56.000Z",
          "wordCount": 2095,
          "title": "Homework problems are rigged",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=213076",
          "author": "John",
          "description": "The last couple article have looked at various kinds of mean. The Python code for four of these means is trivial: gm = lambda a, b: (a*b)**0.5 am = lambda a, b: (a + b)/2 hm = lambda a, b: 2*a*b/(a+b) chm = lambda a, b: (a**2 + b**2)/(a + b) But the arithmetic-geometric mean […]\nPython code for means first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/11/python-agm/",
          "publishedOn": "2023-10-11T16:05:18.000Z",
          "wordCount": 1572,
          "title": "Python code for means",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212976",
          "author": "John",
          "description": "in an earlier post I said that the arithmetic mean of two frequencies an octave apart is an interval of a perfect fifth, and the geometric mean gives a tritone. This post will look at a few other means. Intervals The harmonic mean (HM) gives a perfect fourth. The arithmetic-geometric mean (AGM) gives a pitch […]\nMore ways of splitting the octave first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/octave-means/",
          "publishedOn": "2023-10-11T02:53:02.000Z",
          "wordCount": 1801,
          "title": "More ways of splitting the octave",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212960",
          "author": "John",
          "description": "This afternoon I wrote a brief post about Terence Tao’s new paper A Maclaurin type inequality. That paper builds on two classical inequalities: Newton’s inequality and Maclaurin’s inequality. The previous post expanded a bit on Newton’s inequality. This post will do the same for Maclaurin’s inequality. As before, let x be a list of real […]\nMaclaurin’s inequality first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/maclaurins-inequality/",
          "publishedOn": "2023-10-11T01:12:29.000Z",
          "wordCount": 1371,
          "title": "Maclaurin’s inequality",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212956",
          "author": "John",
          "description": "The previous post mentioned Newton’s inequality. This post will explore this inequality. Let x be a list of real numbers and define Sn(x) to be the average over all products of n elements from x. Newton’s inequality says that Sn−1 Sn+1 ≤ S²n In more terminology more recent than Newton, we say that the sequence […]\nNewton’s inequality and log concave sequences first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/newton-logconcave/",
          "publishedOn": "2023-10-11T00:54:38.000Z",
          "wordCount": 1442,
          "title": "Newton’s inequality and log concave sequences",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212924",
          "author": "John",
          "description": "Terence Tao has a new paper out that relates to a couple things I’ve written about recently. Elementary symmetric polynomials came up when developing the general equations for tangent sum and hyperbolic tangent sum. The latter post goes into more detail. Before that, means of symmetric functions, not necessarily elementary polynomials or even polynomials, came up […]\nU statistics and a new paper by Terence Tao first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/statistics-and-tao/",
          "publishedOn": "2023-10-10T19:10:57.000Z",
          "wordCount": 1417,
          "title": "U statistics and a new paper by Terence Tao",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212884",
          "author": "John",
          "description": "The latest episode of Erik Seligman’s podcast is entitled The Grim State of Modern Pizza. Although you might not realize it from the title, the post is about fraud detection. GRIM stands for Granularity-Related Inconsistency of Means. In a nutshell, the test looks for means (averages) that are not possible on number theoretic grounds. If […]\nDetecting fraud with the GRIM test first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/grim-test/",
          "publishedOn": "2023-10-10T14:51:10.000Z",
          "wordCount": 1557,
          "title": "Detecting fraud with the GRIM test",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212860",
          "author": "John",
          "description": "A few weeks ago I wrote about how the dissonance of a musical interval is related to the complexity of the frequency ratio as a fraction, where complexity is measured by the sum of the numerator and denominator. Consonant intervals have simple frequency ratios and dissonant intervals have complex frequency ratios. By this measure, the […]\nTritone first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/tritone/",
          "publishedOn": "2023-10-10T13:42:14.000Z",
          "wordCount": 1784,
          "title": "Tritone",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212781",
          "author": "John",
          "description": "The relation between a function and its power series is subtle. In a calculus class you’ll see equations of the form “series = function” which may need some footnotes. Maybe the series only represents the function over part of its domain: the function extends further than the power series representation. Starting with the power series, […]\nWhen a function cannot be extended first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/09/when-a-function-cannot-be-extended/",
          "publishedOn": "2023-10-10T01:23:50.000Z",
          "wordCount": 1609,
          "title": "When a function cannot be extended",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212347",
          "author": "John",
          "description": "Yesterday I wrote a post that looked at the hyperbolic tangent sum for x and y strictly between −1 and 1. This sum arises when adding velocities in special relativity. The post ended with a description of the expression for in terms of elementary symmetric polynomials but did not offer a proof. This post will […]\nTanh and elementary symmetric polynomials first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/07/tanh-sum-proof/",
          "publishedOn": "2023-10-07T10:14:56.000Z",
          "wordCount": 1446,
          "title": "Tanh and elementary symmetric polynomials",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212270",
          "author": "John",
          "description": "Earlier this week I wrote about several ways to generalize trig functions. Since trig functions have addition theorems like a natural question is whether generalized trig functions also have addition theorems. Hyperbolic functions have well-known addition theorems analogous to the addition theorems above. This isn’t too surprising since circular and hyperbolic functions are fundamentally two […]\nAddition theorems first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/06/addition-theorems/",
          "publishedOn": "2023-10-06T20:26:55.000Z",
          "wordCount": 1704,
          "title": "Addition theorems",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212235",
          "author": "John",
          "description": "In the previous post I said I was trying remember where I’d seen the tangent sum applied. I mentioned a couple near misses, and it turns out that what I was trying to remember was another near miss. What I’d seen before was not the tangent sum but the hyperbolic tangent sum. Several people suggested […]\nHyperbolic tangent sum first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/06/hyperbolic-tangent-sum/",
          "publishedOn": "2023-10-06T13:01:26.000Z",
          "wordCount": 1534,
          "title": "Hyperbolic tangent sum",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212105",
          "author": "John",
          "description": "When I was writing my post on lemniscate functions yesterday, a line from the Wikipedia article seemed familiar for reasons I cannot place. Defining a tangent-sum operator as a ⊕ b := tan(arctan ⁡ a + arctan ⁡ b) gives cl² z ⊕ sl² z = 1. I feel like I’ve seen this tangent-sum used before, but […]\nTangent sum first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/05/tangent-sum/",
          "publishedOn": "2023-10-05T16:10:12.000Z",
          "wordCount": 1904,
          "title": "Tangent sum",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212049",
          "author": "John",
          "description": "We begin with a couple examples. First, the set of linear transformations from one vector space to another is itself a vector space. Second, the set of continuous linear operators from one Banach space to another is itself a Banach space. Or maybe better, this set can be made into a Banach space. In the […]\nEnriched categories first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/05/enriched-categories/",
          "publishedOn": "2023-10-05T16:05:10.000Z",
          "wordCount": 1839,
          "title": "Enriched categories",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212037",
          "author": "John",
          "description": "This is the fourth post in a series on generalizations of sine and cosine. The first post looked at defining sine as the inverse of the inverse sine. The reason for this unusual approach is that the inverse sine is given in terms of an arc length and an integral. We can generalize sine by […]\np-norm trig functions and “squigonometry” first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/04/p-norm-trig/",
          "publishedOn": "2023-10-05T01:19:58.000Z",
          "wordCount": 1551,
          "title": "p-norm trig functions and “squigonometry”",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212026",
          "author": "John",
          "description": "This is the third post in a series on generalizing sine and cosine. The previous post looked at a generalization of the sine and cosine functions that come from replacing a circle with a lemniscate, a curve that looks like a figure eight. This post looks at replacing the circle with a hyperbola. On the […]\nGeometric derivation of hyperbolic trig functions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/04/hyperbolic-trig/",
          "publishedOn": "2023-10-05T00:29:43.000Z",
          "wordCount": 1541,
          "title": "Geometric derivation of hyperbolic trig functions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212000",
          "author": "John",
          "description": "In the previous post I said that you could define the inverse sine as the function that gives the arc length along a circle, then define sine to be the inverse of the inverse sine. The purpose of such a backward definition is that it generalizes to other curves besides the circle. For example, it […]\nLemniscate functions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/04/lemniscate-functions/",
          "publishedOn": "2023-10-04T21:28:36.000Z",
          "wordCount": 1502,
          "title": "Lemniscate functions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211932",
          "author": "John",
          "description": "In a recent post I mentioned in passing that trigonometry can be generalized from functions associated with a circle to functions associated with other curves. This post will go into that a little further. The equation of the unit circle is and so in the first quadrant The length of an arc from (1, 0) […]\nGeneralized trigonometry first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/04/generalized-trigonometry/",
          "publishedOn": "2023-10-04T14:28:06.000Z",
          "wordCount": 1566,
          "title": "Generalized trigonometry",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211792",
          "author": "John",
          "description": "Let G be a directed graph whose nodes are the positive integers and whose edges represent relations between two integers. In our first example we’ll draw an edge from x to y if x is a multiple of y. In our second example we’ll draw an edge from x to y if x ≥ y. […]\nFrom graph theory to category theory first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/03/graph-to-category/",
          "publishedOn": "2023-10-03T14:24:32.000Z",
          "wordCount": 1850,
          "title": "From graph theory to category theory",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211786",
          "author": "John",
          "description": "Test functions are how you can make sense of functions that aren’t really functions. The canonical example is the Dirac delta “function” that is infinite at the origin, zero everywhere else, and integrates to 1. That description is contradictory: a function that is 0 almost everywhere integrates to 0, even if you work in extended […]\nTest functions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/03/test-functions/",
          "publishedOn": "2023-10-03T13:09:12.000Z",
          "wordCount": 1666,
          "title": "Test functions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211753",
          "author": "John",
          "description": "This article will probably only be of interest to a small number of readers. Those unfamiliar with category theory may find it bewildering, and those well versed in category theory may find it trivial. My hope is that someone in between, someone just starting to get a handle on category theory, will find it helpful. […]\nGroups vs Abelian groups: Pedantic or profound? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/03/abelian-groups/",
          "publishedOn": "2023-10-03T11:54:54.000Z",
          "wordCount": 1999,
          "title": "Groups vs Abelian groups: Pedantic or profound?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211669",
          "author": "John",
          "description": "The Depths of Wikipedia twitter account posted a screenshot about supereggs that’s popular at the moment. It says there’s no way this is real. they must be making these words up above a screenshot from the Wikipedia article on supereggs saying The definition can be changed to have an equality rather than an inequality; this […]\nSupereggs, squigonometry, and squircles first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/02/supereggs/",
          "publishedOn": "2023-10-02T16:14:32.000Z",
          "wordCount": 1602,
          "title": "Supereggs, squigonometry, and squircles",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211654",
          "author": "John",
          "description": "Meredith Whittaker posted on Twitter that In addition to being the best in privacy, Signal is also the best in not subjecting you to corny ‘AI’ features no one asked for or wants. I love the phrase “corny AI.” That’s exactly what a lot of AI features are. “Would you like help composing that tweet?” […]\nCorny AI first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/02/corny-ai/",
          "publishedOn": "2023-10-02T13:36:03.000Z",
          "wordCount": 1421,
          "title": "Corny AI",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211618",
          "author": "John",
          "description": "The star-like image above is today’s exponential sum. The exponential sum page on my site generates a new image each day by putting the numbers of the day’s month, day, and year into the equation and connecting the partial sums in the complex plane. Here m is the month, d is the day, and y […]\nToday’s star first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/02/todays-star/",
          "publishedOn": "2023-10-02T12:00:04.000Z",
          "wordCount": 1589,
          "title": "Today’s star",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211224",
          "author": "John",
          "description": "Coupon collector problem Suppose you have a bag of balls labeled 1 through 1,000. You draw draw balls one at a time and put them back after each draw. How many draws would you have to make before you’ve seen every ball at least once? This is the coupon collector problem with N = 1000, […]\nConsecutive coupon collector problem first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/30/consecutive-coupon-collector-problem/",
          "publishedOn": "2023-09-30T15:53:33.000Z",
          "wordCount": 1946,
          "title": "Consecutive coupon collector problem",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=210990",
          "author": "John",
          "description": "Monte Carlo integration is not as simple in practice as it is often introduced. A homework problem might as you to integrate a function of two variables by selecting random points from a cube and counting how many of the points fall below the graph of the function. This would indeed give you an estimate […]\nRegular solids and Monte Carlo integration first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/29/platonic-solids-and-integration/",
          "publishedOn": "2023-09-29T15:20:23.000Z",
          "wordCount": 1838,
          "title": "Regular solids and Monte Carlo integration",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=210860",
          "author": "John",
          "description": "The previous post describes the hoops I jumped through to enter Unicode characters on a Mac. Here’s a script to run from the command line that will copy Unicode characters to the system clipboard. It runs anywhere the Python module pyperclip runs. #!/usr/bin/env python3 import sys import pyperclip cp = sys.argv[1] ch = eval(f\"chr(0x{cp})\") print(ch) […]\nCross-platform way to enter Unicode characters first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/28/cross-platform-unicode/",
          "publishedOn": "2023-09-28T23:24:34.000Z",
          "wordCount": 1355,
          "title": "Cross-platform way to enter Unicode characters",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=210849",
          "author": "John",
          "description": "Setting up Unicode on my MacBook took some research, so I’m leaving myself a note here if I need to do it again. Maybe it’ll help someone else too. From the System Settings dialog, go to Keyboard and click the Edit button next to Input Sources. Click on the + sign in the lower left […]\nUsing Unicode on MacOS first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/28/macos-unicode/",
          "publishedOn": "2023-09-28T23:21:11.000Z",
          "wordCount": 1538,
          "title": "Using Unicode on MacOS",
          "imageUrl": null
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}