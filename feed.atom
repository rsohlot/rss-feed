<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://rsohlot.github.io/rss-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2022-01-06T00:40:25.620Z</updated>
    <generator>osmosfeed 1.11.3</generator>
    <link rel="alternate" href="https://rsohlot.github.io/rss-feed/index.html"/>
    <link rel="self" href="https://rsohlot.github.io/rss-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Hierarchical Learning to Solve Partial Differential Equations Using Physics-Informed Neural Networks. (arXiv:2112.01254v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.01254</id>
        <link href="http://arxiv.org/abs/2112.01254"/>
        <updated>2022-01-06T00:40:23.770Z</updated>
        <summary type="html"><![CDATA[The neural network-based approach to solving partial differential equations
has attracted considerable attention due to its simplicity and flexibility in
representing the solution of the partial differential equation. In training a
neural network, the network learns global features corresponding to
low-frequency components while high-frequency components are approximated at a
much slower rate. For a class of equations in which the solution contains a
wide range of scales, the network training process can suffer from slow
convergence and low accuracy due to its inability to capture the high-frequency
components. In this work, we propose a hierarchical approach to improve the
convergence rate and accuracy of the neural network solution to partial
differential equations. The proposed method comprises multi-training levels in
which a newly introduced neural network is guided to learn the residual of the
previous level approximation. By the nature of neural networks' training
process, the high-level correction is inclined to capture the high-frequency
components. We validate the efficiency and robustness of the proposed
hierarchical approach through a suite of linear and nonlinear partial
differential equations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1"&gt;Jihun Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1"&gt;Yoonsang Lee&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Deeper Deep Reinforcement Learning with Spectral Normalization. (arXiv:2106.01151v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.01151</id>
        <link href="http://arxiv.org/abs/2106.01151"/>
        <updated>2022-01-06T00:40:23.765Z</updated>
        <summary type="html"><![CDATA[In computer vision and natural language processing, innovations in model
architecture that increase model capacity have reliably translated into gains
in performance. In stark contrast with this trend, state-of-the-art
reinforcement learning (RL) algorithms often use small MLPs, and gains in
performance typically originate from algorithmic innovations. It is natural to
hypothesize that small datasets in RL necessitate simple models to avoid
overfitting; however, this hypothesis is untested. In this paper we investigate
how RL agents are affected by exchanging the small MLPs with larger modern
networks with skip connections and normalization, focusing specifically on
actor-critic algorithms. We empirically verify that naively adopting such
architectures leads to instabilities and poor performance, likely contributing
to the popularity of simple models in practice. However, we show that dataset
size is not the limiting factor, and instead argue that instability from taking
gradients through the critic is the culprit. We demonstrate that spectral
normalization (SN) can mitigate this issue and enable stable training with
large modern architectures. After smoothing with SN, larger models yield
significant performance improvements -- suggesting that more "easy" gains may
be had by focusing on model architectures in addition to algorithmic
innovations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bjorck_J/0/1/0/all/0/1"&gt;Johan Bjorck&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1"&gt;Carla P. Gomes&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1"&gt;Kilian Q. Weinberger&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive and Multiple Time-scale Eligibility Traces for Online Deep Reinforcement Learning. (arXiv:2008.10040v2 [cs.RO] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2008.10040</id>
        <link href="http://arxiv.org/abs/2008.10040"/>
        <updated>2022-01-06T00:40:23.759Z</updated>
        <summary type="html"><![CDATA[Deep reinforcement learning (DRL) is one promising approach to teaching
robots to perform complex tasks. Because methods that directly reuse the stored
experience data cannot follow the change of the environment in robotic problems
with a time-varying environment, online DRL is required. The eligibility traces
method is well known as an online learning technique for improving sample
efficiency in traditional reinforcement learning with linear regressors rather
than DRL. The dependency between parameters of deep neural networks would
destroy the eligibility traces, which is why they are not integrated with DRL.
Although replacing the gradient with the most influential one rather than
accumulating the gradients as the eligibility traces can alleviate this
problem, the replacing operation reduces the number of reuses of previous
experiences. To address these issues, this study proposes a new eligibility
traces method that can be used even in DRL while maintaining high sample
efficiency. When the accumulated gradients differ from those computed using the
latest parameters, the proposed method takes into account the divergence
between the past and latest parameters to adaptively decay the eligibility
traces. Bregman divergences between outputs computed by the past and latest
parameters are exploited due to the infeasible computational cost of the
divergence between the past and latest parameters. In addition, a generalized
method with multiple time-scale traces is designed for the first time. This
design allows for the replacement of the most influential adaptively
accumulated (decayed) eligibility traces.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kobayashi_T/0/1/0/all/0/1"&gt;Taisuke Kobayashi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Object Removal and Spatio-Temporal RGB-D Inpainting via Geometry-Aware Adversarial Learning. (arXiv:2008.05058v4 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2008.05058</id>
        <link href="http://arxiv.org/abs/2008.05058"/>
        <updated>2022-01-06T00:40:23.754Z</updated>
        <summary type="html"><![CDATA[Dynamic objects have a significant impact on the robot's perception of the
environment which degrades the performance of essential tasks such as
localization and mapping. In this work, we address this problem by synthesizing
plausible color, texture and geometry in regions occluded by dynamic objects.
We propose the novel geometry-aware DynaFill architecture that follows a
coarse-to-fine topology and incorporates our gated recurrent feedback mechanism
to adaptively fuse information from previous timesteps. We optimize our
architecture using adversarial training to synthesize fine realistic textures
which enables it to hallucinate color and depth structure in occluded regions
online in a spatially and temporally coherent manner, without relying on future
frame information. Casting our inpainting problem as an image-to-image
translation task, our model also corrects regions correlated with the presence
of dynamic objects in the scene, such as shadows or reflections. We introduce a
large-scale hyperrealistic dataset with RGB-D images, semantic segmentation
labels, camera poses as well as groundtruth RGB-D information of occluded
regions. Extensive quantitative and qualitative evaluations show that our
approach achieves state-of-the-art performance, even in challenging weather
conditions. Furthermore, we present results for retrieval-based visual
localization with the synthesized images that demonstrate the utility of our
approach.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Besic_B/0/1/0/all/0/1"&gt;Borna Be&amp;#x161;i&amp;#x107;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1"&gt;Abhinav Valada&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interpretable Low-Resource Legal Decision Making. (arXiv:2201.01164v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01164</id>
        <link href="http://arxiv.org/abs/2201.01164"/>
        <updated>2022-01-06T00:40:23.747Z</updated>
        <summary type="html"><![CDATA[Over the past several years, legal applications of deep learning have been on
the rise. However, as with other high-stakes decision making areas, the
requirement for interpretability is of crucial importance. Current models
utilized by legal practitioners are more of the conventional machine learning
type, wherein they are inherently interpretable, yet unable to harness the
performance capabilities of data-driven deep learning models. In this work, we
utilize deep learning models in the area of trademark law to shed light on the
issue of likelihood of confusion between trademarks. Specifically, we introduce
a model-agnostic interpretable intermediate layer, a technique which proves to
be effective for legal documents. Furthermore, we utilize weakly supervised
learning by means of a curriculum learning strategy, effectively demonstrating
the improved performance of a deep learning model. This is in contrast to the
conventional models which are only able to utilize the limited number of
expensive manually-annotated samples by legal experts. Although the methods
presented in this work tackles the task of risk of confusion for trademarks, it
is straightforward to extend them to other fields of law, or more generally, to
other similar high-stakes application scenarios.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bhambhoria_R/0/1/0/all/0/1"&gt;Rohan Bhambhoria&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1"&gt;Hui Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dahan_S/0/1/0/all/0/1"&gt;Samuel Dahan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1"&gt;Xiaodan Zhu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trusting Machine Learning Results from Medical Procedures in the Operating Room. (arXiv:2201.01060v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01060</id>
        <link href="http://arxiv.org/abs/2201.01060"/>
        <updated>2022-01-06T00:40:23.725Z</updated>
        <summary type="html"><![CDATA[Machine learning can be used to analyse physiological data for several
purposes. Detection of cerebral ischemia is an achievement that would have high
impact on patient care. We attempted to study if collection of continous
physiological data from non-invasive monitors, and analysis with machine
learning could detect cerebral ischemia in tho different setting, during
surgery for carotid endarterectomy and during endovascular thrombectomy in
acute stroke. We compare the results from the two different group and one
patient from each group in details. While results from CEA-patients are
consistent, those from thrombectomy patients are not and frequently contain
extreme values such as 1.0 in accuracy. We conlcude that this is a result of
short duration of the procedure and abundance of data with bad quality
resulting in small data sets. These results can therefore not be trusted.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+El_Merhi_A/0/1/0/all/0/1"&gt;Ali El-Merhi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Herges_H/0/1/0/all/0/1"&gt;Helena Odenstedt Herg&amp;#xe9;s&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Block_L/0/1/0/all/0/1"&gt;Linda Block&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Elam_M/0/1/0/all/0/1"&gt;Mikael Elam&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vithal_R/0/1/0/all/0/1"&gt;Richard Vithal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liljencrantz_J/0/1/0/all/0/1"&gt;Jaquette Liljencrantz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Staron_M/0/1/0/all/0/1"&gt;Miroslaw Staron&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Transfer Learning for Repairing Security Vulnerabilities in C Code. (arXiv:2104.08308v3 [cs.SE] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.08308</id>
        <link href="http://arxiv.org/abs/2104.08308"/>
        <updated>2022-01-06T00:40:23.717Z</updated>
        <summary type="html"><![CDATA[In this paper, we address the problem of automatic repair of software
vulnerabilities with deep learning. The major problem with data-driven
vulnerability repair is that the few existing datasets of known confirmed
vulnerabilities consist of only a few thousand examples. However, training a
deep learning model often requires hundreds of thousands of examples. In this
work, we leverage the intuition that the bug fixing task and the vulnerability
fixing task are related and that the knowledge learned from bug fixes can be
transferred to fixing vulnerabilities. In the machine learning community, this
technique is called transfer learning. In this paper, we propose an approach
for repairing security vulnerabilities named VRepair which is based on transfer
learning. VRepair is first trained on a large bug fix corpus and is then tuned
on a vulnerability fix dataset, which is an order of magnitude smaller. In our
experiments, we show that a model trained only on a bug fix corpus can already
fix some vulnerabilities. Then, we demonstrate that transfer learning improves
the ability to repair vulnerable C functions. We also show that the transfer
learning model performs better than a model trained with a denoising task and
fine-tuned on the vulnerability fixing task. To sum up, this paper shows that
transfer learning works well for repairing security vulnerabilities in C
compared to learning on a small dataset.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"&gt;Zimin Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kommrusch_S/0/1/0/all/0/1"&gt;Steve Kommrusch&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Monperrus_M/0/1/0/all/0/1"&gt;Martin Monperrus&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially Private Transferrable Deep Learning with Membership-Mappings. (arXiv:2105.04615v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.04615</id>
        <link href="http://arxiv.org/abs/2105.04615"/>
        <updated>2022-01-06T00:40:23.710Z</updated>
        <summary type="html"><![CDATA[This paper considers the problem of differentially private semi-supervised
transfer and multi-task learning. The notion of \emph{membership-mapping} has
been developed using measure theory basis to learn data representation via a
fuzzy membership function. An alternative conception of deep autoencoder,
referred to as \emph{Conditionally Deep Membership-Mapping Autoencoder
(CDMMA)}, is considered for transferrable deep learning. Under
practice-oriented settings, an analytical solution for the learning of CDMMA
can be derived by means of variational optimization. The paper proposes a
transfer and multi-task learning approach that combines CDMMA with a tailored
noise adding mechanism to achieve a given level of privacy-loss bound with the
minimum perturbation of the data. Numerous experiments were carried out using
MNIST, USPS, Office, and Caltech256 datasets to verify the competitive robust
performance of the proposed methodology.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1"&gt;Mohit Kumar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Minimal Adversarial Perturbation for Deep Neural Networks with Provable Estimation Error. (arXiv:2201.01235v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01235</id>
        <link href="http://arxiv.org/abs/2201.01235"/>
        <updated>2022-01-06T00:40:23.703Z</updated>
        <summary type="html"><![CDATA[Although Deep Neural Networks (DNNs) have shown incredible performance in
perceptive and control tasks, several trustworthy issues are still open. One of
the most discussed topics is the existence of adversarial perturbations, which
has opened an interesting research line on provable techniques capable of
quantifying the robustness of a given input. In this regard, the Euclidean
distance of the input from the classification boundary denotes a well-proved
robustness assessment as the minimal affordable adversarial perturbation.
Unfortunately, computing such a distance is highly complex due the non-convex
nature of NNs. Despite several methods have been proposed to address this
issue, to the best of our knowledge, no provable results have been presented to
estimate and bound the error committed. This paper addresses this issue by
proposing two lightweight strategies to find the minimal adversarial
perturbation. Differently from the state-of-the-art, the proposed approach
allows formulating an error estimation theory of the approximate distance with
respect to the theoretical one. Finally, a substantial set of experiments is
reported to evaluate the performance of the algorithms and support the
theoretical findings. The obtained results show that the proposed strategies
approximate the theoretical distance for samples close to the classification
boundary, leading to provable robustness guarantees against any adversarial
attacks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Brau_F/0/1/0/all/0/1"&gt;Fabio Brau&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rossolini_G/0/1/0/all/0/1"&gt;Giulio Rossolini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Biondi_A/0/1/0/all/0/1"&gt;Alessandro Biondi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Buttazzo_G/0/1/0/all/0/1"&gt;Giorgio Buttazzo&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[COVID-19 Disease Progression Prediction via Audio Signals: A Longitudinal Study. (arXiv:2201.01232v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2201.01232</id>
        <link href="http://arxiv.org/abs/2201.01232"/>
        <updated>2022-01-06T00:40:23.685Z</updated>
        <summary type="html"><![CDATA[Recent work has shown the potential of the use of audio data in screening for
COVID-19. However, very little exploration has been done of monitoring disease
progression, especially recovery in COVID-19 through audio. Tracking disease
progression characteristics and patterns of recovery could lead to tremendous
insights and more timely treatment or treatment adjustment, as well as better
resources management in health care systems.

The primary objective of this study is to explore the potential of
longitudinal audio dynamics for COVID-19 monitoring using sequential deep
learning techniques, focusing on prediction of disease progression and,
especially, recovery trend prediction. We analysed crowdsourced respiratory
audio data from 212 individuals over 5 days to 385 days, alongside their
self-reported COVID-19 test results. We first explore the benefits of capturing
longitudinal dynamics of audio biomarkers for COVID-19 detection. The strong
performance, yielding an AUC-ROC of 0.79, sensitivity of 0.75 and specificity
of 0.70, supports the effectiveness of the approach compared to methods that do
not leverage longitudinal dynamics. We further examine the predicted disease
progression trajectory, which displays high consistency with the longitudinal
test results with a correlation of 0.76 in the test cohort, and 0.86 in a
subset of the test cohort with 12 participants who report disease recovery.

Our findings suggest that monitoring COVID-19 progression via longitudinal
audio data has enormous potential in the tracking of individuals' disease
progression and recovery.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1"&gt;Ting Dang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1"&gt;Jing Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1"&gt;Tong Xia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Spathis_D/0/1/0/all/0/1"&gt;Dimitris Spathis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bondareva_E/0/1/0/all/0/1"&gt;Erika Bondareva&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Brown_C/0/1/0/all/0/1"&gt;Chlo&amp;#xeb; Brown&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chauhan_J/0/1/0/all/0/1"&gt;Jagmohan Chauhan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grammenos_A/0/1/0/all/0/1"&gt;Andreas Grammenos&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hasthanasombat_A/0/1/0/all/0/1"&gt;Apinan Hasthanasombat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Floto_A/0/1/0/all/0/1"&gt;Andres Floto&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cicuta_P/0/1/0/all/0/1"&gt;Pietro Cicuta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mascolo_C/0/1/0/all/0/1"&gt;Cecilia Mascolo&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fast Approximation of the Sliced-Wasserstein Distance Using Concentration of Random Projections. (arXiv:2106.15427v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.15427</id>
        <link href="http://arxiv.org/abs/2106.15427"/>
        <updated>2022-01-06T00:40:23.680Z</updated>
        <summary type="html"><![CDATA[The Sliced-Wasserstein distance (SW) is being increasingly used in machine
learning applications as an alternative to the Wasserstein distance and offers
significant computational and statistical benefits. Since it is defined as an
expectation over random projections, SW is commonly approximated by Monte
Carlo. We adopt a new perspective to approximate SW by making use of the
concentration of measure phenomenon: under mild assumptions, one-dimensional
projections of a high-dimensional random vector are approximately Gaussian.
Based on this observation, we develop a simple deterministic approximation for
SW. Our method does not require sampling a number of random projections, and is
therefore both accurate and easy to use compared to the usual Monte Carlo
approximation. We derive nonasymptotical guarantees for our approach, and show
that the approximation error goes to zero as the dimension increases, under a
weak dependence condition on the data distribution. We validate our theoretical
findings on synthetic datasets, and illustrate the proposed approximation on a
generative modeling problem.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Nadjahi_K/0/1/0/all/0/1"&gt;Kimia Nadjahi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1"&gt;Alain Durmus&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Jacob_P/0/1/0/all/0/1"&gt;Pierre E. Jacob&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Badeau_R/0/1/0/all/0/1"&gt;Roland Badeau&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1"&gt;Umut &amp;#x15e;im&amp;#x15f;ekli&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Template Enhancement for Improved Person Recognition using Small Datasets. (arXiv:2201.01218v1 [eess.SP])]]></title>
        <id>http://arxiv.org/abs/2201.01218</id>
        <link href="http://arxiv.org/abs/2201.01218"/>
        <updated>2022-01-06T00:40:23.674Z</updated>
        <summary type="html"><![CDATA[A novel instance-based method for the classification of
electroencephalography (EEG) signals is presented and evaluated in this paper.
The non-stationary nature of the EEG signals, coupled with the demanding task
of pattern recognition with limited training data as well as the potentially
noisy signal acquisition conditions, have motivated the work reported in this
study. The proposed adaptive template enhancement mechanism transforms the
feature-level instances by treating each feature dimension separately, hence
resulting in improved class separation and better query-class matching. The
proposed new instance-based learning algorithm is compared with a few related
algorithms in a number of scenarios. A clinical grade 64-electrode EEG
database, as well as a low-quality (high-noise level) EEG database obtained
with a low-cost system using a single dry sensor have been used for evaluations
in biometric person recognition. The proposed approach demonstrates
significantly improved classification accuracy in both identification and
verification scenarios. In particular, this new method is seen to provide a
good classification performance for noisy EEG data, indicating its potential
suitability for a wide range of applications.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Yang_S/0/1/0/all/0/1"&gt;Su Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Hoque_S/0/1/0/all/0/1"&gt;Sanaul Hoque&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Deravi_F/0/1/0/all/0/1"&gt;Farzin Deravi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Survey on the Convergence of Machine Learning and Blockchain. (arXiv:2201.00976v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00976</id>
        <link href="http://arxiv.org/abs/2201.00976"/>
        <updated>2022-01-06T00:40:23.668Z</updated>
        <summary type="html"><![CDATA[Machine learning (ML) has been pervasively researched nowadays and it has
been applied in many aspects of real life. Nevertheless, issues of model and
data still accompany the development of ML. For instance, training of
traditional ML models is limited to the access of data sets, which are
generally proprietary; published ML models may soon be out of date without
update of new data and continuous training; malicious data contributors may
upload wrongly labeled data that leads to undesirable training results; and the
abuse of private data and data leakage also exit. With the utilization of
blockchain, an emerging and swiftly developing technology, these problems can
be efficiently solved. In this paper, we conduct a survey of the convergence of
collaborative ML and blockchain. We investigate different ways of combination
of these two technologies, and their fields of application. We also discuss the
limitations of current research and their future directions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1"&gt;Shengwen Ding&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1"&gt;Chenhui Hu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FROTE: Feedback Rule-Driven Oversampling for Editing Models. (arXiv:2201.01070v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01070</id>
        <link href="http://arxiv.org/abs/2201.01070"/>
        <updated>2022-01-06T00:40:23.662Z</updated>
        <summary type="html"><![CDATA[Machine learning models may involve decision boundaries that change over time
due to updates to rules and regulations, such as in loan approvals or claims
management. However, in such scenarios, it may take time for sufficient
training data to accumulate in order to retrain the model to reflect the new
decision boundaries. While work has been done to reinforce existing decision
boundaries, very little has been done to cover these scenarios where decision
boundaries of the ML models should change in order to reflect new rules. In
this paper, we focus on user-provided feedback rules as a way to expedite the
ML models update process, and we formally introduce the problem of
pre-processing training data to edit an ML model in response to feedback rules
such that once the model is retrained on the pre-processed data, its decision
boundaries align more closely with the rules. To solve this problem, we propose
a novel data augmentation method, the Feedback Rule-Based Oversampling
Technique. Extensive experiments using different ML models and real world
datasets demonstrate the effectiveness of the method, in particular the benefit
of augmentation and the ability to handle many feedback rules.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Alkan_O/0/1/0/all/0/1"&gt;&amp;#xd6;znur Alkan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1"&gt;Dennis Wei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Matteti_M/0/1/0/all/0/1"&gt;Massimiliano Matteti&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nair_R/0/1/0/all/0/1"&gt;Rahul Nair&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Daly_E/0/1/0/all/0/1"&gt;Elizabeth M. Daly&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Saha_D/0/1/0/all/0/1"&gt;Diptikalyan Saha&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepVisualInsight: Time-Travelling Visualization for Spatio-Temporal Causality of Deep Classification Training. (arXiv:2201.01155v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01155</id>
        <link href="http://arxiv.org/abs/2201.01155"/>
        <updated>2022-01-06T00:40:23.657Z</updated>
        <summary type="html"><![CDATA[Understanding how the predictions of deep learning models are formed during
the training process is crucial to improve model performance and fix model
defects, especially when we need to investigate nontrivial training strategies
such as active learning, and track the root cause of unexpected training
results such as performance degeneration.

In this work, we propose a time-travelling visual solution DeepVisualInsight
(DVI), aiming to manifest the spatio-temporal causality while training a deep
learning image classifier. The spatio-temporal causality demonstrates how the
gradient-descent algorithm and various training data sampling techniques can
influence and reshape the layout of learnt input representation and the
classification boundaries in consecutive epochs. Such causality allows us to
observe and analyze the whole learning process in the visible low dimensional
space. Technically, we propose four spatial and temporal properties and design
our visualization solution to satisfy them. These properties preserve the most
important information when inverse-)projecting input samples between the
visible low-dimensional and the invisible high-dimensional space, for causal
analyses. Our extensive experiments show that, comparing to baseline
approaches, we achieve the best visualization performance regarding the
spatial/temporal properties and visualization efficiency. Moreover, our case
study shows that our visual solution can well reflect the characteristics of
various training scenarios, showing good potential of DVI as a debugging tool
for analyzing deep learning training processes.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1"&gt;Xianglin Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1"&gt;Yun Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1"&gt;Ruofan Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1"&gt;Zhenfeng He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1"&gt;Chao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1"&gt;Jin Song Dong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1"&gt;Hong Mei&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Discovering Diverse Nearly Optimal Policies with Successor Features. (arXiv:2106.00669v2 [cs.AI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.00669</id>
        <link href="http://arxiv.org/abs/2106.00669"/>
        <updated>2022-01-06T00:40:23.635Z</updated>
        <summary type="html"><![CDATA[Finding different solutions to the same problem is a key aspect of
intelligence associated with creativity and adaptation to novel situations. In
reinforcement learning, a set of diverse policies can be useful for
exploration, transfer, hierarchy, and robustness. We propose Diverse Successive
Policies, a method for discovering policies that are diverse in the space of
Successor Features, while assuring that they are near optimal. We formalize the
problem as a Constrained Markov Decision Process (CMDP) where the goal is to
find policies that maximize diversity, characterized by an intrinsic diversity
reward, while remaining near-optimal with respect to the extrinsic reward of
the MDP. We also analyze how recently proposed robustness and discrimination
rewards perform and find that they are sensitive to the initialization of the
procedure and may converge to sub-optimal solutions. To alleviate this, we
propose new explicit diversity rewards that aim to minimize the correlation
between the Successor Features of the policies in the set. We compare the
different diversity mechanisms in the DeepMind Control Suite and find that the
type of explicit diversity we are proposing is important to discover distinct
behavior, like for example different locomotion patterns.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zahavy_T/0/1/0/all/0/1"&gt;Tom Zahavy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1"&gt;Brendan O&amp;#x27;Donoghue&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Barreto_A/0/1/0/all/0/1"&gt;Andre Barreto&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mnih_V/0/1/0/all/0/1"&gt;Volodymyr Mnih&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Flennerhag_S/0/1/0/all/0/1"&gt;Sebastian Flennerhag&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1"&gt;Satinder Singh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Biased Hypothesis Formation From Projection Pursuit. (arXiv:2201.00889v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00889</id>
        <link href="http://arxiv.org/abs/2201.00889"/>
        <updated>2022-01-06T00:40:23.628Z</updated>
        <summary type="html"><![CDATA[The effect of bias on hypothesis formation is characterized for an automated
data-driven projection pursuit neural network to extract and select features
for binary classification of data streams. This intelligent exploratory process
partitions a complete vector state space into disjoint subspaces to create
working hypotheses quantified by similarities and differences observed between
two groups of labeled data streams. Data streams are typically time sequenced,
and may exhibit complex spatio-temporal patterns. For example, given atomic
trajectories from molecular dynamics simulation, the machine's task is to
quantify dynamical mechanisms that promote function by comparing protein
mutants, some known to function while others are nonfunctional. Utilizing
synthetic two-dimensional molecules that mimic the dynamics of functional and
nonfunctional proteins, biases are identified and controlled in both the
machine learning model and selected training data under different contexts. The
refinement of a working hypothesis converges to a statistically robust
multivariate perception of the data based on a context-dependent perspective.
Including diverse perspectives during data exploration enhances
interpretability of the multivariate characterization of similarities and
differences.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Patterson_J/0/1/0/all/0/1"&gt;John Patterson&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Avery_C/0/1/0/all/0/1"&gt;Chris Avery&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grear_T/0/1/0/all/0/1"&gt;Tyler Grear&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1"&gt;Donald J. Jacobs&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine Learning-Based COVID-19 Patients Triage Algorithm using Patient-Generated Health Data from Nationwide Multicenter Database. (arXiv:2109.09001v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.09001</id>
        <link href="http://arxiv.org/abs/2109.09001"/>
        <updated>2022-01-06T00:40:23.622Z</updated>
        <summary type="html"><![CDATA[A model that can immediately measure the severity of an epidemic would be of
great help to the medical system. In this paper, we will use machine learning
to create and analyze a model that can immediately measure the severity of
SARS-CoV-2 patients. Since our model uses nationwide dataset that consists of
basic personal information of patients, it is of great significance for the
patient to be able to check their own severity. Moreover, based on the
predicted severity score, we use our model to inform the patients to visit the
appropriate clinic center.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hwang_H/0/1/0/all/0/1"&gt;Hyung Ju Hwang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1"&gt;Seyoung Jung&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1"&gt;Min Sue Park&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jo_H/0/1/0/all/0/1"&gt;Hyeontae Jo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1"&gt;Haeun Lee&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Homological Time Series Analysis of Sensor Signals from Power Plants. (arXiv:2106.02493v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.02493</id>
        <link href="http://arxiv.org/abs/2106.02493"/>
        <updated>2022-01-06T00:40:23.616Z</updated>
        <summary type="html"><![CDATA[In this paper, we use topological data analysis techniques to construct a
suitable neural network classifier for the task of learning sensor signals of
entire power plants according to their reference designation system. We use
representations of persistence diagrams to derive necessary preprocessing steps
and visualize the large amounts of data. We derive deep architectures with
one-dimensional convolutional layers combined with stacked long short-term
memories as residual networks suitable for processing the persistence features.
We combine three separate sub-networks, obtaining as input the time series
itself and a representation of the persistent homology for the zeroth and first
dimension. We give a mathematical derivation for most of the used
hyper-parameters. For validation, numerical experiments were performed with
sensor data from four power plants of the same construction type.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Melodia_L/0/1/0/all/0/1"&gt;Luciano Melodia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lenz_R/0/1/0/all/0/1"&gt;Richard Lenz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CEMENT: Incomplete Multi-View Weak-Label Learning with Long Tail Labels. (arXiv:2201.01079v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01079</id>
        <link href="http://arxiv.org/abs/2201.01079"/>
        <updated>2022-01-06T00:40:23.595Z</updated>
        <summary type="html"><![CDATA[A variety of modern applications exhibit multi-view multi-label learning,
where each sample has multi-view features, and multiple labels are correlated
via common views. In recent years, several methods have been proposed to cope
with it and achieve much success, but still suffer from two key problems: 1)
lack the ability to deal with the incomplete multi-view weak-label data, in
which only a subset of features and labels are provided for each sample; 2)
ignore the presence of noisy views and tail labels usually occurring in
real-world problems. In this paper, we propose a novel method, named CEMENT, to
overcome the limitations. For 1), CEMENT jointly embeds incomplete views and
weak labels into distinct low-dimensional subspaces, and then correlates them
via Hilbert-Schmidt Independence Criterion (HSIC). For 2), CEMEMT adaptively
learns the weights of embeddings to capture noisy views, and explores an
additional sparse component to model tail labels, making the low-rankness
available in the multi-label setting. We develop an alternating algorithm to
solve the proposed optimization problem. Experimental results on seven
real-world datasets demonstrate the effectiveness of the proposed method.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"&gt;Zhiwei Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1"&gt;Lu Sun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classifying Autism from Crowdsourced Semi-Structured Speech Recordings: A Machine Learning Approach. (arXiv:2201.00927v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2201.00927</id>
        <link href="http://arxiv.org/abs/2201.00927"/>
        <updated>2022-01-06T00:40:23.589Z</updated>
        <summary type="html"><![CDATA[Autism spectrum disorder (ASD) is a neurodevelopmental disorder which results
in altered behavior, social development, and communication patterns. In past
years, autism prevalence has tripled, with 1 in 54 children now affected. Given
that traditional diagnosis is a lengthy, labor-intensive process, significant
attention has been given to developing systems that automatically screen for
autism. Prosody abnormalities are among the clearest signs of autism, with
affected children displaying speech idiosyncrasies including echolalia,
monotonous intonation, atypical pitch, and irregular linguistic stress
patterns. In this work, we present a suite of machine learning approaches to
detect autism in self-recorded speech audio captured from autistic and
neurotypical (NT) children in home environments. We consider three methods to
detect autism in child speech: first, Random Forests trained on extracted audio
features (including Mel-frequency cepstral coefficients); second, convolutional
neural networks (CNNs) trained on spectrograms; and third, fine-tuned wav2vec
2.0--a state-of-the-art Transformer-based ASR model. We train our classifiers
on our novel dataset of cellphone-recorded child speech audio curated from
Stanford's Guess What? mobile game, an app designed to crowdsource videos of
autistic and neurotypical children in a natural home environment. The Random
Forest classifier achieves 70% accuracy, the fine-tuned wav2vec 2.0 model
achieves 77% accuracy, and the CNN achieves 79% accuracy when classifying
children's audio as either ASD or NT. Our models were able to predict autism
status when training on a varied selection of home audio clips with
inconsistent recording quality, which may be more generalizable to real world
conditions. These results demonstrate that machine learning methods offer
promise in detecting autism automatically from speech without specialized
equipment.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chi_N/0/1/0/all/0/1"&gt;Nathan A. Chi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Washington_P/0/1/0/all/0/1"&gt;Peter Washington&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kline_A/0/1/0/all/0/1"&gt;Aaron Kline&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Husic_A/0/1/0/all/0/1"&gt;Arman Husic&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hou_C/0/1/0/all/0/1"&gt;Cathy Hou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1"&gt;Chloe He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dunlap_K/0/1/0/all/0/1"&gt;Kaitlyn Dunlap&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wall_D/0/1/0/all/0/1"&gt;Dennis Wall&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Fair Recommendation in Two-Sided Platforms. (arXiv:2201.01180v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2201.01180</id>
        <link href="http://arxiv.org/abs/2201.01180"/>
        <updated>2022-01-06T00:40:23.583Z</updated>
        <summary type="html"><![CDATA[Many online platforms today (such as Amazon, Netflix, Spotify, LinkedIn, and
AirBnB) can be thought of as two-sided markets with producers and customers of
goods and services. Traditionally, recommendation services in these platforms
have focused on maximizing customer satisfaction by tailoring the results
according to the personalized preferences of individual customers. However, our
investigation reinforces the fact that such customer-centric design of these
services may lead to unfair distribution of exposure to the producers, which
may adversely impact their well-being. On the other hand, a pure
producer-centric design might become unfair to the customers. As more and more
people are depending on such platforms to earn a living, it is important to
ensure fairness to both producers and customers. In this work, by mapping a
fair personalized recommendation problem to a constrained version of the
problem of fairly allocating indivisible goods, we propose to provide fairness
guarantees for both sides. Formally, our proposed {\em FairRec} algorithm
guarantees Maxi-Min Share ($\alpha$-MMS) of exposure for the producers, and
Envy-Free up to One Item (EF1) fairness for the customers. Extensive
evaluations over multiple real-world datasets show the effectiveness of {\em
FairRec} in ensuring two-sided fairness while incurring a marginal loss in
overall recommendation quality. Finally, we present a modification of FairRec
(named as FairRecPlus) that at the cost of additional computation time,
improves the recommendation performance for the customers, while maintaining
the same fairness guarantees.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Biswas_A/0/1/0/all/0/1"&gt;Arpita Biswas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Patro_G/0/1/0/all/0/1"&gt;Gourab K Patro&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1"&gt;Niloy Ganguly&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gummadi_K/0/1/0/all/0/1"&gt;Krishna P. Gummadi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1"&gt;Abhijnan Chakraborty&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nipping in the Bud: Detection, Diffusion and Mitigation of Hate Speech on Social Media. (arXiv:2201.00961v1 [cs.SI])]]></title>
        <id>http://arxiv.org/abs/2201.00961</id>
        <link href="http://arxiv.org/abs/2201.00961"/>
        <updated>2022-01-06T00:40:23.578Z</updated>
        <summary type="html"><![CDATA[Since the proliferation of social media usage, hate speech has become a major
crisis. Hateful content can spread quickly and create an environment of
distress and hostility. Further, what can be considered hateful is contextual
and varies with time. While online hate speech reduces the ability of already
marginalised groups to participate in discussion freely, offline hate speech
leads to hate crimes and violence against individuals and communities. The
multifaceted nature of hate speech and its real-world impact have already
piqued the interest of the data mining and machine learning communities.
Despite our best efforts, hate speech remains an evasive issue for researchers
and practitioners alike. This article presents methodological challenges that
hinder building automated hate mitigation systems. These challenges inspired
our work in the broader area of combating hateful content on the web. We
discuss a series of our proposed solutions to limit the spread of hate speech
on social media.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1"&gt;Tanmoy Chakraborty&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Masud_S/0/1/0/all/0/1"&gt;Sarah Masud&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CHERRY: a Computational metHod for accuratE pRediction of virus-pRokarYotic interactions using a graph encoder-decoder model. (arXiv:2201.01018v1 [q-bio.GN])]]></title>
        <id>http://arxiv.org/abs/2201.01018</id>
        <link href="http://arxiv.org/abs/2201.01018"/>
        <updated>2022-01-06T00:40:23.572Z</updated>
        <summary type="html"><![CDATA[Prokaryotic viruses, which infect bacteria and archaea, are key players in
microbial communities. Predicting the hosts of prokaryotic viruses helps
decipher the dynamic relationship between microbes. Although there are
experimental methods for host identification, they are either labor-intensive
or require the cultivation of the host cells, creating a need for computational
host prediction. Despite some promising results, computational host prediction
remains a challenge because of the limited known interactions and the sheer
amount of sequenced phages by high-throughput sequencing technologies. The
state-of-the-art methods can only achieve 43% accuracy at the species level.
This work presents CHERRY, a tool formulating host prediction as link
prediction in a knowledge graph. As a virus-prokaryotic interaction prediction
tool, CHERRY can be applied to predict hosts for newly discovered viruses and
also the viruses infecting antibiotic-resistant bacteria. We demonstrated the
utility of CHERRY for both applications and compared its performance with the
state-of-the-art methods in different scenarios. To our best knowledge, CHERRY
has the highest accuracy in identifying virus-prokaryote interactions. It
outperforms all the existing methods at the species level with an accuracy
increase of 37%. In addition, CHERRY's performance is more stable on short
contigs than other tools.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/q-bio/1/au:+Shang_J/0/1/0/all/0/1"&gt;Jiayu Shang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Sun_Y/0/1/0/all/0/1"&gt;Yanni Sun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Extending CLIP for Category-to-image Retrieval in E-commerce. (arXiv:2112.11294v2 [cs.IR] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.11294</id>
        <link href="http://arxiv.org/abs/2112.11294"/>
        <updated>2022-01-06T00:40:23.551Z</updated>
        <summary type="html"><![CDATA[E-commerce provides rich multimodal data that is barely leveraged in
practice. One aspect of this data is a category tree that is being used in
search and recommendation. However, in practice, during a user's session there
is often a mismatch between a textual and a visual representation of a given
category. Motivated by the problem, we introduce the task of category-to-image
retrieval in e-commerce and propose a model for the task, CLIP-ITA. The model
leverages information from multiple modalities (textual, visual, and attribute
modality) to create product representations. We explore how adding information
from multiple modalities (textual, visual, and attribute modality) impacts the
model's performance. In particular, we observe that CLIP-ITA significantly
outperforms a comparable model that leverages only the visual modality and a
comparable model that leverages the visual and attribute modality.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hendriksen_M/0/1/0/all/0/1"&gt;Mariya Hendriksen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bleeker_M/0/1/0/all/0/1"&gt;Maurits Bleeker&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vakulenko_S/0/1/0/all/0/1"&gt;Svitlana Vakulenko&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Noord_N/0/1/0/all/0/1"&gt;Nanne van Noord&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kuiper_E/0/1/0/all/0/1"&gt;Ernst Kuiper&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1"&gt;Maarten de Rijke&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Aligning Domain-specific Distribution and Classifier for Cross-domain Classification from Multiple Sources. (arXiv:2201.01003v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01003</id>
        <link href="http://arxiv.org/abs/2201.01003"/>
        <updated>2022-01-06T00:40:23.521Z</updated>
        <summary type="html"><![CDATA[While Unsupervised Domain Adaptation (UDA) algorithms, i.e., there are only
labeled data from source domains, have been actively studied in recent years,
most algorithms and theoretical results focus on Single-source Unsupervised
Domain Adaptation (SUDA). However, in the practical scenario, labeled data can
be typically collected from multiple diverse sources, and they might be
different not only from the target domain but also from each other. Thus,
domain adapters from multiple sources should not be modeled in the same way.
Recent deep learning based Multi-source Unsupervised Domain Adaptation (MUDA)
algorithms focus on extracting common domain-invariant representations for all
domains by aligning distribution of all pairs of source and target domains in a
common feature space. However, it is often very hard to extract the same
domain-invariant representations for all domains in MUDA. In addition, these
methods match distributions without considering domain-specific decision
boundaries between classes. To solve these problems, we propose a new framework
with two alignment stages for MUDA which not only respectively aligns the
distributions of each pair of source and target domains in multiple specific
feature spaces, but also aligns the outputs of classifiers by utilizing the
domain-specific decision boundaries. Extensive experiments demonstrate that our
method can achieve remarkable results on popular benchmark datasets for image
classification.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1"&gt;Yongchun Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1"&gt;Fuzhen Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1"&gt;Deqing Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Heterogeneous In-Memory Computing Cluster For Flexible End-to-End Inference of Real-World Deep Neural Networks. (arXiv:2201.01089v1 [cs.AR])]]></title>
        <id>http://arxiv.org/abs/2201.01089</id>
        <link href="http://arxiv.org/abs/2201.01089"/>
        <updated>2022-01-06T00:40:23.513Z</updated>
        <summary type="html"><![CDATA[Deployment of modern TinyML tasks on small battery-constrained IoT devices
requires high computational energy efficiency. Analog In-Memory Computing (IMC)
using non-volatile memory (NVM) promises major efficiency improvements in deep
neural network (DNN) inference and serves as on-chip memory storage for DNN
weights. However, IMC's functional flexibility limitations and their impact on
performance, energy, and area efficiency are not yet fully understood at the
system level. To target practical end-to-end IoT applications, IMC arrays must
be enclosed in heterogeneous programmable systems, introducing new system-level
challenges which we aim at addressing in this work. We present a heterogeneous
tightly-coupled clustered architecture integrating 8 RISC-V cores, an in-memory
computing accelerator (IMA), and digital accelerators. We benchmark the system
on a highly heterogeneous workload such as the Bottleneck layer from a
MobileNetV2, showing 11.5x performance and 9.5x energy efficiency improvements,
compared to highly optimized parallel execution on the cores. Furthermore, we
explore the requirements for end-to-end inference of a full mobile-grade DNN
(MobileNetV2) in terms of IMC array resources, by scaling up our heterogeneous
architecture to a multi-array accelerator. Our results show that our solution,
on the end-to-end inference of the MobileNetV2, is one order of magnitude
better in terms of execution latency than existing programmable architectures
and two orders of magnitude better than state-of-the-art heterogeneous
solutions integrating in-memory computing analog cores.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Garofalo_A/0/1/0/all/0/1"&gt;Angelo Garofalo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ottavi_G/0/1/0/all/0/1"&gt;Gianmarco Ottavi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Conti_F/0/1/0/all/0/1"&gt;Francesco Conti&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Karunaratne_G/0/1/0/all/0/1"&gt;Geethan Karunaratne&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Boybat_I/0/1/0/all/0/1"&gt;Irem Boybat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1"&gt;Luca Benini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rossi_D/0/1/0/all/0/1"&gt;Davide Rossi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Neural Networks With Lifting-based Adaptive Graph Wavelets. (arXiv:2108.01660v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2108.01660</id>
        <link href="http://arxiv.org/abs/2108.01660"/>
        <updated>2022-01-06T00:40:23.484Z</updated>
        <summary type="html"><![CDATA[Spectral-based graph neural networks (SGNNs) have been attracting increasing
attention in graph representation learning. However, existing SGNNs are limited
in implementing graph filters with rigid transforms (e.g., graph Fourier or
predefined graph wavelet transforms) and cannot adapt to signals residing on
graphs and tasks at hand. In this paper, we propose a novel class of graph
neural networks that realizes graph filters with adaptive graph wavelets.
Specifically, the adaptive graph wavelets are learned with neural
network-parameterized lifting structures, where structure-aware attention-based
lifting operations (i.e., prediction and update operations) are developed to
jointly consider graph structures and node features. We propose to lift based
on diffusion wavelets to alleviate the structural information loss induced by
partitioning non-bipartite graphs. By design, the locality and sparsity of the
resulting wavelet transform as well as the scalability of the lifting structure
are guaranteed. We further derive a soft-thresholding filtering operation by
learning sparse graph representations in terms of the learned wavelets,
yielding a localized, efficient, and scalable wavelet-based graph filters. To
ensure that the learned graph representations are invariant to node
permutations, a layer is employed at the input of the networks to reorder the
nodes according to their local topology information. We evaluate the proposed
networks in both node-level and graph-level representation learning tasks on
benchmark citation and bioinformatics graph datasets. Extensive experiments
demonstrate the superiority of the proposed networks over existing SGNNs in
terms of accuracy, efficiency, and scalability.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1"&gt;Mingxing Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1"&gt;Wenrui Dai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1"&gt;Chenglin Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1"&gt;Junni Zou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1"&gt;Hongkai Xiong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1"&gt;Pascal Frossard&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Submix: Practical Private Prediction for Large-Scale Language Models. (arXiv:2201.00971v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00971</id>
        <link href="http://arxiv.org/abs/2201.00971"/>
        <updated>2022-01-06T00:40:23.456Z</updated>
        <summary type="html"><![CDATA[Recent data-extraction attacks have exposed that language models can memorize
some training samples verbatim. This is a vulnerability that can compromise the
privacy of the model's training data. In this work, we introduce SubMix: a
practical protocol for private next-token prediction designed to prevent
privacy violations by language models that were fine-tuned on a private corpus
after pre-training on a public corpus. We show that SubMix limits the leakage
of information that is unique to any individual user in the private corpus via
a relaxation of group differentially private prediction. Importantly, SubMix
admits a tight, data-dependent privacy accounting mechanism, which allows it to
thwart existing data-extraction attacks while maintaining the utility of the
language model. SubMix is the first protocol that maintains privacy even when
publicly releasing tens of thousands of next-token predictions made by large
transformer-based models such as GPT-2.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ginart_A/0/1/0/all/0/1"&gt;Antonio Ginart&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Maaten_L/0/1/0/all/0/1"&gt;Laurens van der Maaten&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1"&gt;James Zou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1"&gt;Chuan Guo&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rxn Hypergraph: a Hypergraph Attention Model for Chemical Reaction Representation. (arXiv:2201.01196v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01196</id>
        <link href="http://arxiv.org/abs/2201.01196"/>
        <updated>2022-01-06T00:40:23.413Z</updated>
        <summary type="html"><![CDATA[It is fundamental for science and technology to be able to predict chemical
reactions and their properties. To achieve such skills, it is important to
develop good representations of chemical reactions, or good deep learning
architectures that can learn such representations automatically from the data.
There is currently no universal and widely adopted method for robustly
representing chemical reactions. Most existing methods suffer from one or more
drawbacks, such as: (1) lacking universality; (2) lacking robustness; (3)
lacking interpretability; or (4) requiring excessive manual pre-processing.
Here we exploit graph-based representations of molecular structures to develop
and test a hypergraph attention neural network approach to solve at once the
reaction representation and property-prediction problems, alleviating the
aforementioned drawbacks. We evaluate this hypergraph representation in three
experiments using three independent data sets of chemical reactions. In all
experiments, the hypergraph-based approach matches or outperforms other
representations and their corresponding models of chemical reactions while
yielding interpretable multi-level representations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tavakoli_M/0/1/0/all/0/1"&gt;Mohammadamin Tavakoli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shmakov_A/0/1/0/all/0/1"&gt;Alexander Shmakov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ceccarelli_F/0/1/0/all/0/1"&gt;Francesco Ceccarelli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Baldi_P/0/1/0/all/0/1"&gt;Pierre Baldi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Finding General Equilibria in Many-Agent Economic Simulations Using Deep Reinforcement Learning. (arXiv:2201.01163v1 [cs.GT])]]></title>
        <id>http://arxiv.org/abs/2201.01163</id>
        <link href="http://arxiv.org/abs/2201.01163"/>
        <updated>2022-01-06T00:40:23.412Z</updated>
        <summary type="html"><![CDATA[Real economies can be seen as a sequential imperfect-information game with
many heterogeneous, interacting strategic agents of various agent types, such
as consumers, firms, and governments. Dynamic general equilibrium models are
common economic tools to model the economic activity, interactions, and
outcomes in such systems. However, existing analytical and computational
methods struggle to find explicit equilibria when all agents are strategic and
interact, while joint learning is unstable and challenging. Amongst others, a
key reason is that the actions of one economic agent may change the reward
function of another agent, e.g., a consumer's expendable income changes when
firms change prices or governments change taxes. We show that multi-agent deep
reinforcement learning (RL) can discover stable solutions that are epsilon-Nash
equilibria for a meta-game over agent types, in economic simulations with many
agents, through the use of structured learning curricula and efficient GPU-only
simulation and training. Conceptually, our approach is more flexible and does
not need unrealistic assumptions, e.g., market clearing, that are commonly used
for analytical tractability. Our GPU implementation enables training and
analyzing economies with a large number of agents within reasonable time
frames, e.g., training completes within a day. We demonstrate our approach in
real-business-cycle models, a representative family of DGE models, with 100
worker-consumers, 10 firms, and a government who taxes and redistributes. We
validate the learned meta-game epsilon-Nash equilibria through approximate
best-response analyses, show that RL policies align with economic intuitions,
and that our approach is constructive, e.g., by explicitly learning a spectrum
of meta-game epsilon-Nash equilibria in open RBC models.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Curry_M/0/1/0/all/0/1"&gt;Michael Curry&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Trott_A/0/1/0/all/0/1"&gt;Alexander Trott&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Phade_S/0/1/0/all/0/1"&gt;Soham Phade&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1"&gt;Yu Bai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1"&gt;Stephan Zheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Positional Encoding Augmented GAN for the Assessment of Wind Flow for Pedestrian Comfort in Urban Areas. (arXiv:2112.08447v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.08447</id>
        <link href="http://arxiv.org/abs/2112.08447"/>
        <updated>2022-01-06T00:40:23.408Z</updated>
        <summary type="html"><![CDATA[Approximating wind flows using computational fluid dynamics (CFD) methods can
be time-consuming. Creating a tool for interactively designing prototypes while
observing the wind flow change requires simpler models to simulate faster.
Instead of running numerical approximations resulting in detailed calculations,
data-driven methods and deep learning might be able to give similar results in
a fraction of the time. This work rephrases the problem from computing 3D flow
fields using CFD to a 2D image-to-image translation-based problem on the
building footprints to predict the flow field at pedestrian height level. We
investigate the use of generative adversarial networks (GAN), such as Pix2Pix
[1] and CycleGAN [2] representing state-of-the-art for image-to-image
translation task in various domains as well as U-Net autoencoder [3]. The
models can learn the underlying distribution of a dataset in a data-driven
manner, which we argue can help the model learn the underlying
Reynolds-averaged Navier-Stokes (RANS) equations from CFD. We experiment on
novel simulated datasets on various three-dimensional bluff-shaped buildings
with and without height information. Moreover, we present an extensive
qualitative and quantitative evaluation of the generated images for a selection
of models and compare their performance with the simulations delivered by CFD.
We then show that adding positional data to the input can produce more accurate
results by proposing a general framework for injecting such information on the
different architectures. Furthermore, we show that the models performances
improve by applying attention mechanisms and spectral normalization to
facilitate stable training.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hoeiness_H/0/1/0/all/0/1"&gt;Henrik Hoeiness&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gjerde_K/0/1/0/all/0/1"&gt;Kristoffer Gjerde&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Oggiano_L/0/1/0/all/0/1"&gt;Luca Oggiano&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Giljarhus_K/0/1/0/all/0/1"&gt;Knut Erik Teigen Giljarhus&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ruocco_M/0/1/0/all/0/1"&gt;Massimiliano Ruocco&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantifying Uncertainty in Deep Learning Approaches to Radio Galaxy Classification. (arXiv:2201.01203v1 [astro-ph.CO])]]></title>
        <id>http://arxiv.org/abs/2201.01203</id>
        <link href="http://arxiv.org/abs/2201.01203"/>
        <updated>2022-01-06T00:40:23.407Z</updated>
        <summary type="html"><![CDATA[In this work we use variational inference to quantify the degree of
uncertainty in deep learning model predictions of radio galaxy classification.
We show that the level of model posterior variance for individual test samples
is correlated with human uncertainty when labelling radio galaxies. We explore
the model performance and uncertainty calibration for a variety of different
weight priors and suggest that a sparse prior produces more well-calibrated
uncertainty estimates. Using the posterior distributions for individual
weights, we show that we can prune 30% of the fully-connected layer weights
without significant loss of performance by removing the weights with the lowest
signal-to-noise ratio (SNR). We demonstrate that a larger degree of pruning can
be achieved using a Fisher information based ranking, but we note that both
pruning methods affect the uncertainty calibration for Fanaroff-Riley type I
and type II radio galaxies differently. Finally we show that, like other work
in this field, we experience a cold posterior effect, whereby the posterior
must be down-weighted to achieve good predictive performance. We examine
whether adapting the cost function to accommodate model misspecification can
compensate for this effect, but find that it does not make a significant
difference. We also examine the effect of principled data augmentation and find
that this improves upon the baseline but also does not compensate for the
observed effect. We interpret this as the cold posterior effect being due to
the overly effective curation of our training sample leading to likelihood
misspecification, and raise this as a potential issue for Bayesian deep
learning approaches to radio galaxy classification in future.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/astro-ph/1/au:+Mohan_D/0/1/0/all/0/1"&gt;Devina Mohan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/astro-ph/1/au:+Scaife_A/0/1/0/all/0/1"&gt;Anna M. M. Scaife&lt;/a&gt;, &lt;a href="http://arxiv.org/find/astro-ph/1/au:+Porter_F/0/1/0/all/0/1"&gt;Fiona Porter&lt;/a&gt;, &lt;a href="http://arxiv.org/find/astro-ph/1/au:+Walmsley_M/0/1/0/all/0/1"&gt;Mike Walmsley&lt;/a&gt;, &lt;a href="http://arxiv.org/find/astro-ph/1/au:+Bowles_M/0/1/0/all/0/1"&gt;Micah Bowles&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Delving into Sample Loss Curve to Embrace Noisy and Imbalanced Data. (arXiv:2201.00849v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00849</id>
        <link href="http://arxiv.org/abs/2201.00849"/>
        <updated>2022-01-06T00:40:23.403Z</updated>
        <summary type="html"><![CDATA[Corrupted labels and class imbalance are commonly encountered in practically
collected training data, which easily leads to over-fitting of deep neural
networks (DNNs). Existing approaches alleviate these issues by adopting a
sample re-weighting strategy, which is to re-weight sample by designing
weighting function. However, it is only applicable for training data containing
only either one type of data biases. In practice, however, biased samples with
corrupted labels and of tailed classes commonly co-exist in training data. How
to handle them simultaneously is a key but under-explored problem. In this
paper, we find that these two types of biased samples, though have similar
transient loss, have distinguishable trend and characteristics in loss curves,
which could provide valuable priors for sample weight assignment. Motivated by
this, we delve into the loss curves and propose a novel probe-and-allocate
training strategy: In the probing stage, we train the network on the whole
biased training data without intervention, and record the loss curve of each
sample as an additional attribute; In the allocating stage, we feed the
resulting attribute to a newly designed curve-perception network, named
CurveNet, to learn to identify the bias type of each sample and assign proper
weights through meta-learning adaptively. The training speed of meta learning
also blocks its application. To solve it, we propose a method named skip layer
meta optimization (SLMO) to accelerate training speed by skipping the bottom
layers. Extensive synthetic and real experiments well validate the proposed
method, which achieves state-of-the-art performance on multiple challenging
benchmarks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1"&gt;Shenwang Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"&gt;Jianan Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Ying Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1"&gt;Bo Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1"&gt;Zhang Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1"&gt;Tingfa Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interactive Attention AI to translate low light photos to captions for night scene understanding in women safety. (arXiv:2201.00969v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.00969</id>
        <link href="http://arxiv.org/abs/2201.00969"/>
        <updated>2022-01-06T00:40:23.393Z</updated>
        <summary type="html"><![CDATA[There is amazing progress in Deep Learning based models for Image captioning
and Low Light image enhancement. For the first time in literature, this paper
develops a Deep Learning model that translates night scenes to sentences,
opening new possibilities for AI applications in the safety of visually
impaired women. Inspired by Image Captioning and Visual Question Answering, a
novel Interactive Image Captioning is developed. A user can make the AI focus
on any chosen person of interest by influencing the attention scoring.
Attention context vectors are computed from CNN feature vectors and
user-provided start word. The Encoder-Attention-Decoder neural network learns
to produce captions from low brightness images. This paper demonstrates how
women safety can be enabled by researching a novel AI capability in the
Interactive Vision-Language model for perception of the environment in the
night.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+A_R/0/1/0/all/0/1"&gt;Rajagopal A&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+V_N/0/1/0/all/0/1"&gt;Nirmala V&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vedamanickam_A/0/1/0/all/0/1"&gt;Arun Muthuraj Vedamanickam&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multimodal Co-learning: Challenges, Applications with Datasets, Recent Advances and Future Directions. (arXiv:2107.13782v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2107.13782</id>
        <link href="http://arxiv.org/abs/2107.13782"/>
        <updated>2022-01-06T00:40:23.392Z</updated>
        <summary type="html"><![CDATA[Multimodal deep learning systems which employ multiple modalities like text,
image, audio, video, etc., are showing better performance in comparison with
individual modalities (i.e., unimodal) systems. Multimodal machine learning
involves multiple aspects: representation, translation, alignment, fusion, and
co-learning. In the current state of multimodal machine learning, the
assumptions are that all modalities are present, aligned, and noiseless during
training and testing time. However, in real-world tasks, typically, it is
observed that one or more modalities are missing, noisy, lacking annotated
data, have unreliable labels, and are scarce in training or testing and or
both. This challenge is addressed by a learning paradigm called multimodal
co-learning. The modeling of a (resource-poor) modality is aided by exploiting
knowledge from another (resource-rich) modality using transfer of knowledge
between modalities, including their representations and predictive models.
Co-learning being an emerging area, there are no dedicated reviews explicitly
focusing on all challenges addressed by co-learning. To that end, in this work,
we provide a comprehensive survey on the emerging area of multimodal
co-learning that has not been explored in its entirety yet. We review
implementations that overcome one or more co-learning challenges without
explicitly considering them as co-learning challenges. We present the
comprehensive taxonomy of multimodal co-learning based on the challenges
addressed by co-learning and associated implementations. The various techniques
employed to include the latest ones are reviewed along with some of the
applications and datasets. Our final goal is to discuss challenges and
perspectives along with the important ideas and directions for future work that
we hope to be beneficial for the entire research community focusing on this
exciting domain.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Rahate_A/0/1/0/all/0/1"&gt;Anil Rahate&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Walambe_R/0/1/0/all/0/1"&gt;Rahee Walambe&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ramanna_S/0/1/0/all/0/1"&gt;Sheela Ramanna&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kotecha_K/0/1/0/all/0/1"&gt;Ketan Kotecha&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Super-resolution in Molecular Dynamics Trajectory Reconstruction with Bi-Directional Neural Networks. (arXiv:2201.01195v1 [physics.comp-ph])]]></title>
        <id>http://arxiv.org/abs/2201.01195</id>
        <link href="http://arxiv.org/abs/2201.01195"/>
        <updated>2022-01-06T00:40:23.390Z</updated>
        <summary type="html"><![CDATA[Molecular dynamics simulations are a cornerstone in science, allowing to
investigate from the system's thermodynamics to analyse intricate molecular
interactions. In general, to create extended molecular trajectories can be a
computationally expensive process, for example, when running $ab-initio$
simulations. Hence, repeating such calculations to either obtain more accurate
thermodynamics or to get a higher resolution in the dynamics generated by a
fine-grained quantum interaction can be time- and computationally-consuming. In
this work, we explore different machine learning (ML) methodologies to increase
the resolution of molecular dynamics trajectories on-demand within a
post-processing step. As a proof of concept, we analyse the performance of
bi-directional neural networks such as neural ODEs, Hamiltonian networks,
recurrent neural networks and LSTMs, as well as the uni-directional variants as
a reference, for molecular dynamics simulations (here: the MD17 dataset). We
have found that Bi-LSTMs are the best performing models; by utilizing the local
time-symmetry of thermostated trajectories they can even learn long-range
correlations and display high robustness to noisy dynamics across molecular
complexity. Our models can reach accuracies of up to 10$^{-4}$ angstroms in
trajectory interpolation, while faithfully reconstructing several full cycles
of unseen intricate high-frequency molecular vibrations, rendering the
comparison between the learned and reference trajectories indistinguishable.
The results reported in this work can serve (1) as a baseline for larger
systems, as well as (2) for the construction of better MD integrators.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Winkler_L/0/1/0/all/0/1"&gt;Ludwig Winkler&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Muller_K/0/1/0/all/0/1"&gt;Klaus-Robert M&amp;#xfc;ller&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Sauceda_H/0/1/0/all/0/1"&gt;Huziel E. Sauceda&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Runway Extraction and Improved Mapping from Space Imagery. (arXiv:2201.00848v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.00848</id>
        <link href="http://arxiv.org/abs/2201.00848"/>
        <updated>2022-01-06T00:40:23.389Z</updated>
        <summary type="html"><![CDATA[Change detection methods applied to monitoring key infrastructure like
airport runways represent an important capability for disaster relief and urban
planning. The present work identifies two generative adversarial networks (GAN)
architectures that translate reversibly between plausible runway maps and
satellite imagery. We illustrate the training capability using paired images
(satellite-map) from the same point of view and using the Pix2Pix architecture
or conditional GANs. In the absence of available pairs, we likewise show that
CycleGAN architectures with four network heads (discriminator-generator pairs)
can also provide effective style transfer from raw image pixels to outline or
feature maps. To emphasize the runway and tarmac boundaries, we experimentally
show that the traditional grey-tan map palette is not a required training input
but can be augmented by higher contrast mapping palettes (red-black) for
sharper runway boundaries. We preview a potentially novel use case (called
"sketch2satellite") where a human roughly draws the current runway boundaries
and automates the machine output of plausible satellite images. Finally, we
identify examples of faulty runway maps where the published satellite and
mapped runways disagree but an automated update renders the correct map using
GANs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1"&gt;David A. Noever&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Representation Adaptation Network for Cross-domain Image Classification. (arXiv:2201.01002v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.01002</id>
        <link href="http://arxiv.org/abs/2201.01002"/>
        <updated>2022-01-06T00:40:23.367Z</updated>
        <summary type="html"><![CDATA[In image classification, it is often expensive and time-consuming to acquire
sufficient labels. To solve this problem, domain adaptation often provides an
attractive option given a large amount of labeled data from a similar nature
but different domain. Existing approaches mainly align the distributions of
representations extracted by a single structure and the representations may
only contain partial information, e.g., only contain part of the saturation,
brightness, and hue information. Along this line, we propose
Multi-Representation Adaptation which can dramatically improve the
classification accuracy for cross-domain image classification and specially
aims to align the distributions of multiple representations extracted by a
hybrid structure named Inception Adaptation Module (IAM). Based on this, we
present Multi-Representation Adaptation Network (MRAN) to accomplish the
cross-domain image classification task via multi-representation alignment which
can capture the information from different aspects. In addition, we extend
Maximum Mean Discrepancy (MMD) to compute the adaptation loss. Our approach can
be easily implemented by extending most feed-forward models with IAM, and the
network can be trained efficiently via back-propagation. Experiments conducted
on three benchmark image datasets demonstrate the effectiveness of MRAN. The
code has been available at https://github.com/easezyc/deep-transfer-learning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1"&gt;Yongchun Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1"&gt;Fuzhen Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"&gt;Jindong Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"&gt;Jingwu Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1"&gt;Zhiping Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1"&gt;Wenjuan Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1"&gt;Qing He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-supervised representation learning from 12-lead ECG data. (arXiv:2103.12676v2 [eess.SP] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.12676</id>
        <link href="http://arxiv.org/abs/2103.12676"/>
        <updated>2022-01-06T00:40:23.353Z</updated>
        <summary type="html"><![CDATA[Clinical 12-lead electrocardiography (ECG) is one of the most widely
encountered kinds of biosignals. Despite the increased availability of public
ECG datasets, label scarcity remains a central challenge in the field.
Self-supervised learning represents a promising way to alleviate this issue. In
this work, we put forward the first comprehensive assessment of self-supervised
representation learning from clinical 12-lead ECG data. To this end, we adapt
state-of-the-art self-supervised methods based on instance discrimination and
latent forecasting to the ECG domain. In a first step, we learn contrastive
representations and evaluate their quality based on linear evaluation
performance on a recently established, comprehensive, clinical ECG
classification task. In a second step, we analyze the impact of self-supervised
pretraining on finetuned ECG classifiers as compared to purely supervised
performance. For the best-performing method, an adaptation of contrastive
predictive coding, we find a linear evaluation performance only 0.5% below
supervised performance. For the finetuned models, we find improvements in
downstream performance of roughly 1% compared to supervised performance, label
efficiency, as well as robustness against physiological noise. This work
clearly establishes the feasibility of extracting discriminative
representations from ECG data via self-supervised learning and the numerous
advantages when finetuning such representations on downstream tasks as compared
to purely supervised training. As first comprehensive assessment of its kind in
the ECG domain carried out exclusively on publicly available datasets, we hope
to establish a first step towards reproducible progress in the rapidly evolving
field of representation learning for biosignals.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Mehari_T/0/1/0/all/0/1"&gt;Temesgen Mehari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Strodthoff_N/0/1/0/all/0/1"&gt;Nils Strodthoff&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transfer Learning for Retinal Vascular Disease Detection: A Pilot Study with Diabetic Retinopathy and Retinopathy of Prematurity. (arXiv:2201.01250v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01250</id>
        <link href="http://arxiv.org/abs/2201.01250"/>
        <updated>2022-01-06T00:40:23.349Z</updated>
        <summary type="html"><![CDATA[Retinal vascular diseases affect the well-being of human body and sometimes
provide vital signs of otherwise undetected bodily damage. Recently, deep
learning techniques have been successfully applied for detection of diabetic
retinopathy (DR). The main obstacle of applying deep learning techniques to
detect most other retinal vascular diseases is the limited amount of data
available. In this paper, we propose a transfer learning technique that aims to
utilize the feature similarities for detecting retinal vascular diseases. We
choose the well-studied DR detection as a source task and identify the early
detection of retinopathy of prematurity (ROP) as the target task. Our
experimental results demonstrate that our DR-pretrained approach dominates in
all metrics the conventional ImageNet-pretrained transfer learning approach,
currently adopted in medical image analysis. Moreover, our approach is more
robust with respect to the stochasticity in the training process and with
respect to reduced training samples. This study suggests the potential of our
proposed transfer learning approach for a broad range of retinal vascular
diseases or pathologies, where data is limited.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1"&gt;Guan Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kikuchi_Y/0/1/0/all/0/1"&gt;Yusuke Kikuchi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1"&gt;Jinglin Yi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zou_Q/0/1/0/all/0/1"&gt;Qiong Zou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1"&gt;Rui Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1"&gt;Xin Guo&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Marginal likelihood computation for model selection and hypothesis testing: an extensive review. (arXiv:2005.08334v4 [stat.CO] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2005.08334</id>
        <link href="http://arxiv.org/abs/2005.08334"/>
        <updated>2022-01-06T00:40:23.345Z</updated>
        <summary type="html"><![CDATA[This is an up-to-date introduction to, and overview of, marginal likelihood
computation for model selection and hypothesis testing. Computing normalizing
constants of probability models (or ratio of constants) is a fundamental issue
in many applications in statistics, applied mathematics, signal processing and
machine learning. This article provides a comprehensive study of the
state-of-the-art of the topic. We highlight limitations, benefits, connections
and differences among the different techniques. Problems and possible solutions
with the use of improper priors are also described. Some of the most relevant
methodologies are compared through theoretical comparisons and numerical
experiments.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Llorente_F/0/1/0/all/0/1"&gt;Fernando Llorente&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Martino_L/0/1/0/all/0/1"&gt;Luca Martino&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Delgado_D/0/1/0/all/0/1"&gt;David Delgado&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Lopez_Santiago_J/0/1/0/all/0/1"&gt;Javier Lopez-Santiago&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning. (arXiv:2201.01221v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01221</id>
        <link href="http://arxiv.org/abs/2201.01221"/>
        <updated>2022-01-06T00:40:23.344Z</updated>
        <summary type="html"><![CDATA[Centralized Training for Decentralized Execution, where training is done in a
centralized offline fashion, has become a popular solution paradigm in
Multi-Agent Reinforcement Learning. Many such methods take the form of
actor-critic with state-based critics, since centralized training allows access
to the true system state, which can be useful during training despite not being
available at execution time. State-based critics have become a common empirical
choice, albeit one which has had limited theoretical justification or analysis.
In this paper, we show that state-based critics can introduce bias in the
policy gradient estimates, potentially undermining the asymptotic guarantees of
the algorithm. We also show that, even if the state-based critics do not
introduce any bias, they can still result in a larger gradient variance,
contrary to the common intuition. Finally, we show the effects of the theories
in practice by comparing different forms of centralized critics on a wide range
of common benchmarks, and detail how various environmental properties are
related to the effectiveness of different types of critics.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1"&gt;Xueguang Lyu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Baisero_A/0/1/0/all/0/1"&gt;Andrea Baisero&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1"&gt;Yuchen Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1"&gt;Christopher Amato&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kendall transformation: a robust representation of continuous data for information theory. (arXiv:2006.15991v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2006.15991</id>
        <link href="http://arxiv.org/abs/2006.15991"/>
        <updated>2022-01-06T00:40:23.344Z</updated>
        <summary type="html"><![CDATA[Kendall transformation is a conversion of an ordered feature into a vector of
pairwise order relations between individual values. This way, it preserves
ranking of observations and represents it in a categorical form.

Such transformation allows for generalisation of methods requiring strictly
categorical input, especially in the limit of small number of observations,
when discretisation becomes problematic. In particular, many approaches of
information theory can be directly applied to Kendall-transformed continuous
data without relying on differential entropy or any additional parameters.
Moreover, by filtering information to this contained in ranking, Kendall
transformation leads to a better robustness at a reasonable cost of dropping
sophisticated interactions which are anyhow unlikely to be correctly estimated.

In bivariate analysis, Kendall transformation can be related to popular
non-parametric methods, showing the soundness of the approach. The paper also
demonstrates its efficiency in multivariate problems, as well as provides an
example analysis of a real-world data.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kursa_M/0/1/0/all/0/1"&gt;Miron Bartosz Kursa&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modelling Cournot Games as Multi-agent Multi-armed Bandits. (arXiv:2201.01182v1 [cs.GT])]]></title>
        <id>http://arxiv.org/abs/2201.01182</id>
        <link href="http://arxiv.org/abs/2201.01182"/>
        <updated>2022-01-06T00:40:23.343Z</updated>
        <summary type="html"><![CDATA[We investigate the use of a multi-agent multi-armed bandit (MA-MAB) setting
for modeling repeated Cournot oligopoly games, where the firms acting as agents
choose from the set of arms representing production quantity (a discrete
value). Agents interact with separate and independent bandit problems. In this
formulation, each agent makes sequential choices among arms to maximize its own
reward. Agents do not have any information about the environment; they can only
see their own rewards after taking an action. However, the market demand is a
stationary function of total industry output, and random entry or exit from the
market is not allowed. Given these assumptions, we found that an
$\epsilon$-greedy approach offers a more viable learning mechanism than other
traditional MAB approaches, as it does not require any additional knowledge of
the system to operate. We also propose two novel approaches that take advantage
of the ordered action space: $\epsilon$-greedy+HL and $\epsilon$-greedy+EL.
These new approaches help firms to focus on more profitable actions by
eliminating less profitable choices and hence are designed to optimize the
exploration. We use computer simulations to study the emergence of various
equilibria in the outcomes and do the empirical analysis of joint cumulative
regrets.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Taywade_K/0/1/0/all/0/1"&gt;Kshitija Taywade&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Harrison_B/0/1/0/all/0/1"&gt;Brent Harrison&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bagh_A/0/1/0/all/0/1"&gt;Adib Bagh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Quantum Feature Extraction for CNN-based Learning. (arXiv:2201.01246v1 [quant-ph])]]></title>
        <id>http://arxiv.org/abs/2201.01246</id>
        <link href="http://arxiv.org/abs/2201.01246"/>
        <updated>2022-01-06T00:40:23.342Z</updated>
        <summary type="html"><![CDATA[Recent work has begun to explore the potential of parametrized quantum
circuits (PQCs) as general function approximators. In this work, we propose a
quantum-classical deep network structure to enhance classical CNN model
discriminability. The convolutional layer uses linear filters to scan the input
data. Moreover, we build PQC, which is a more potent function approximator,
with more complex structures to capture the features within the receptive
field. The feature maps are obtained by sliding the PQCs over the input in a
similar way as CNN. We also give a training algorithm for the proposed model.
The hybrid models used in our design are validated by numerical simulation. We
demonstrate the reasonable classification performances on MNIST and we compare
the performances with models in different settings. The results disclose that
the model with ansatz in high expressibility achieves lower cost and higher
accuracy.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/quant-ph/1/au:+Dou_T/0/1/0/all/0/1"&gt;Tong Dou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/quant-ph/1/au:+Zhang_G/0/1/0/all/0/1"&gt;Guofeng Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/quant-ph/1/au:+Cui_W/0/1/0/all/0/1"&gt;Wei Cui&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Operators with Coupled Attention. (arXiv:2201.01032v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01032</id>
        <link href="http://arxiv.org/abs/2201.01032"/>
        <updated>2022-01-06T00:40:23.340Z</updated>
        <summary type="html"><![CDATA[Supervised operator learning is an emerging machine learning paradigm with
applications to modeling the evolution of spatio-temporal dynamical systems and
approximating general black-box relationships between functional data. We
propose a novel operator learning method, LOCA (Learning Operators with Coupled
Attention), motivated from the recent success of the attention mechanism. In
our architecture, the input functions are mapped to a finite set of features
which are then averaged with attention weights that depend on the output query
locations. By coupling these attention weights together with an integral
transform, LOCA is able to explicitly learn correlations in the target output
functions, enabling us to approximate nonlinear operators even when the number
of output function in the training set measurements is very small. Our
formulation is accompanied by rigorous approximation theoretic guarantees on
the universal expressiveness of the proposed model. Empirically, we evaluate
the performance of LOCA on several operator learning scenarios involving
systems governed by ordinary and partial differential equations, as well as a
black-box climate prediction problem. Through these scenarios we demonstrate
state of the art accuracy, robustness with respect to noisy input data, and a
consistently small spread of errors over testing data sets, even for
out-of-distribution prediction tasks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kissas_G/0/1/0/all/0/1"&gt;Georgios Kissas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Seidman_J/0/1/0/all/0/1"&gt;Jacob Seidman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guilhoto_L/0/1/0/all/0/1"&gt;Leonardo Ferreira Guilhoto&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Preciado_V/0/1/0/all/0/1"&gt;Victor M. Preciado&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1"&gt;George J. Pappas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1"&gt;Paris Perdikaris&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-directed Machine Learning. (arXiv:2201.01289v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01289</id>
        <link href="http://arxiv.org/abs/2201.01289"/>
        <updated>2022-01-06T00:40:23.339Z</updated>
        <summary type="html"><![CDATA[Conventional machine learning (ML) relies heavily on manual design from
machine learning experts to decide learning tasks, data, models, optimization
algorithms, and evaluation metrics, which is labor-intensive, time-consuming,
and cannot learn autonomously like humans. In education science, self-directed
learning, where human learners select learning tasks and materials on their own
without requiring hands-on guidance, has been shown to be more effective than
passive teacher-guided learning. Inspired by the concept of self-directed human
learning, we introduce the principal concept of Self-directed Machine Learning
(SDML) and propose a framework for SDML. Specifically, we design SDML as a
self-directed learning process guided by self-awareness, including internal
awareness and external awareness. Our proposed SDML process benefits from self
task selection, self data selection, self model selection, self optimization
strategy selection and self evaluation metric selection through self-awareness
without human guidance. Meanwhile, the learning performance of the SDML process
serves as feedback to further improve self-awareness. We propose a mathematical
formulation for SDML based on multi-level optimization. Furthermore, we present
case studies together with potential applications of SDML, followed by
discussing future research directions. We expect that SDML could enable
machines to conduct human-like self-directed learning and provide a new
perspective towards artificial general intelligence.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1"&gt;Wenwu Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"&gt;Xin Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1"&gt;Pengtao Xie&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep learning architectures for nonlinear operator functions and nonlinear inverse problems. (arXiv:1912.11090v3 [math.OC] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1912.11090</id>
        <link href="http://arxiv.org/abs/1912.11090"/>
        <updated>2022-01-06T00:40:23.307Z</updated>
        <summary type="html"><![CDATA[We develop a theoretical analysis for special neural network architectures,
termed operator recurrent neural networks, for approximating nonlinear
functions whose inputs are linear operators. Such functions commonly arise in
solution algorithms for inverse boundary value problems. Traditional neural
networks treat input data as vectors, and thus they do not effectively capture
the multiplicative structure associated with the linear operators that
correspond to the data in such inverse problems. We therefore introduce a new
family that resembles a standard neural network architecture, but where the
input data acts multiplicatively on vectors. Motivated by compact operators
appearing in boundary control and the analysis of inverse boundary value
problems for the wave equation, we promote structure and sparsity in selected
weight matrices in the network. After describing this architecture, we study
its representation properties as well as its approximation properties. We
furthermore show that an explicit regularization can be introduced that can be
derived from the mathematical analysis of the mentioned inverse problems, and
which leads to certain guarantees on the generalization properties. We observe
that the sparsity of the weight matrices improves the generalization estimates.
Lastly, we discuss how operator recurrent networks can be viewed as a deep
learning analogue to deterministic algorithms such as boundary control for
reconstructing the unknown wavespeed in the acoustic wave equation from
boundary measurements.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Hoop_M/0/1/0/all/0/1"&gt;Maarten V. de Hoop&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Lassas_M/0/1/0/all/0/1"&gt;Matti Lassas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Wong_C/0/1/0/all/0/1"&gt;Christopher A. Wong&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[McXai: Local model-agnostic explanation as two games. (arXiv:2201.01044v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01044</id>
        <link href="http://arxiv.org/abs/2201.01044"/>
        <updated>2022-01-06T00:40:23.306Z</updated>
        <summary type="html"><![CDATA[To this day, a variety of approaches for providing local interpretability of
black-box machine learning models have been introduced. Unfortunately, all of
these methods suffer from one or more of the following deficiencies: They are
either difficult to understand themselves, they work on a per-feature basis and
ignore the dependencies between features and/or they only focus on those
features asserting the decision made by the model. To address these points,
this work introduces a reinforcement learning-based approach called Monte Carlo
tree search for eXplainable Artificial Intelligent (McXai) to explain the
decisions of any black-box classification model (classifier). Our method
leverages Monte Carlo tree search and models the process of generating
explanations as two games. In one game, the reward is maximized by finding
feature sets that support the decision of the classifier, while in the second
game, finding feature sets leading to alternative decisions maximizes the
reward. The result is a human friendly representation as a tree structure, in
which each node represents a set of features to be studied with smaller
explanations at the top of the tree. Our experiments show, that the features
found by our method are more informative with respect to classifications than
those found by classical approaches like LIME and SHAP. Furthermore, by also
identifying misleading features, our approach is able to guide towards improved
robustness of the black-box model in many situations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1"&gt;Yiran Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schaal_N/0/1/0/all/0/1"&gt;Nicole Schaal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hefenbrock_M/0/1/0/all/0/1"&gt;Michael Hefenbrock&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1"&gt;Yexu Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Riedel_T/0/1/0/all/0/1"&gt;Till Riedel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1"&gt;Likun Fang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Beigl_M/0/1/0/all/0/1"&gt;Michael Beigl&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images. (arXiv:2201.01266v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2201.01266</id>
        <link href="http://arxiv.org/abs/2201.01266"/>
        <updated>2022-01-06T00:40:23.306Z</updated>
        <summary type="html"><![CDATA[Semantic segmentation of brain tumors is a fundamental medical image analysis
task involving multiple MRI imaging modalities that can assist clinicians in
diagnosing the patient and successively studying the progression of the
malignant entity. In recent years, Fully Convolutional Neural Networks (FCNNs)
approaches have become the de facto standard for 3D medical image segmentation.
The popular "U-shaped" network architecture has achieved state-of-the-art
performance benchmarks on different 2D and 3D semantic segmentation tasks and
across various imaging modalities. However, due to the limited kernel size of
convolution layers in FCNNs, their performance of modeling long-range
information is sub-optimal, and this can lead to deficiencies in the
segmentation of tumors with variable sizes. On the other hand, transformer
models have demonstrated excellent capabilities in capturing such long-range
information in multiple domains, including natural language processing and
computer vision. Inspired by the success of vision transformers and their
variants, we propose a novel segmentation model termed Swin UNEt TRansformers
(Swin UNETR). Specifically, the task of 3D brain tumor semantic segmentation is
reformulated as a sequence to sequence prediction problem wherein multi-modal
input data is projected into a 1D sequence of embedding and used as an input to
a hierarchical Swin transformer as the encoder. The swin transformer encoder
extracts features at five different resolutions by utilizing shifted windows
for computing self-attention and is connected to an FCNN-based decoder at each
resolution via skip connections. We have participated in BraTS 2021
segmentation challenge, and our proposed model ranks among the top-performing
approaches in the validation phase. Code: https://monai.io/research/swin-unetr]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Hatamizadeh_A/0/1/0/all/0/1"&gt;Ali Hatamizadeh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Nath_V/0/1/0/all/0/1"&gt;Vishwesh Nath&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Tang_Y/0/1/0/all/0/1"&gt;Yucheng Tang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yang_D/0/1/0/all/0/1"&gt;Dong Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Roth_H/0/1/0/all/0/1"&gt;Holger Roth&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Xu_D/0/1/0/all/0/1"&gt;Daguang Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Parity-based Cumulative Fairness-aware Boosting. (arXiv:2201.01148v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01148</id>
        <link href="http://arxiv.org/abs/2201.01148"/>
        <updated>2022-01-06T00:40:23.305Z</updated>
        <summary type="html"><![CDATA[Data-driven AI systems can lead to discrimination on the basis of protected
attributes like gender or race. One reason for this behavior is the encoded
societal biases in the training data (e.g., females are underrepresented),
which is aggravated in the presence of unbalanced class distributions (e.g.,
"granted" is the minority class). State-of-the-art fairness-aware machine
learning approaches focus on preserving the \emph{overall} classification
accuracy while improving fairness. In the presence of class-imbalance, such
methods may further aggravate the problem of discrimination by denying an
already underrepresented group (e.g., \textit{females}) the fundamental rights
of equal social privileges (e.g., equal credit opportunity).

To this end, we propose AdaFair, a fairness-aware boosting ensemble that
changes the data distribution at each round, taking into account not only the
class errors but also the fairness-related performance of the model defined
cumulatively based on the partial ensemble. Except for the in-training boosting
of the group discriminated over each round, AdaFair directly tackles imbalance
during the post-training phase by optimizing the number of ensemble learners
for balanced error performance (BER). AdaFair can facilitate different
parity-based fairness notions and mitigate effectively discriminatory outcomes.
Our experiments show that our approach can achieve parity in terms of
statistical parity, equal opportunity, and disparate mistreatment while
maintaining good predictive performance for all classes.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Iosifidis_V/0/1/0/all/0/1"&gt;Vasileios Iosifidis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1"&gt;Arjun Roy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1"&gt;Eirini Ntoutsi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Mean Discrepancy for Efficient Out-of-Distribution Detection. (arXiv:2104.11408v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.11408</id>
        <link href="http://arxiv.org/abs/2104.11408"/>
        <updated>2022-01-06T00:40:23.304Z</updated>
        <summary type="html"><![CDATA[Various approaches have been proposed for out-of-distribution (OOD) detection
by augmenting models, input examples, training sets, and optimization
objectives. Deviating from existing work, we have a simple hypothesis that
standard off-the-shelf models may already contain sufficient information about
the training set distribution which can be leveraged for reliable OOD
detection. Our empirical study on validating this hypothesis, which measures
the model activation's mean for OOD and in-distribution (ID) mini-batches,
surprisingly finds that activation means of OOD mini-batches consistently
deviate more from those of the training data. In addition, training data's
activation means can be computed offline efficiently or retrieved from batch
normalization layers as a `free lunch'. Based upon this observation, we propose
a novel metric called Neural Mean Discrepancy (NMD), which compares neural
means of the input examples and training data. Leveraging the simplicity of
NMD, we propose an efficient OOD detector that computes neural means by a
standard forward pass followed by a lightweight classifier. Extensive
experiments show that NMD outperforms state-of-the-art OOD approaches across
multiple datasets and model architectures in terms of both detection accuracy
and computational cost.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1"&gt;Xin Dong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1"&gt;Junfeng Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1"&gt;Ang Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ting_W/0/1/0/all/0/1"&gt;Wei-Te Ting&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1"&gt;Cong Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kung_H/0/1/0/all/0/1"&gt;H.T. Kung&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Profile Guided Optimization without Profiles: A Machine Learning Approach. (arXiv:2112.14679v2 [cs.PL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.14679</id>
        <link href="http://arxiv.org/abs/2112.14679"/>
        <updated>2022-01-06T00:40:23.303Z</updated>
        <summary type="html"><![CDATA[Profile guided optimization is an effective technique for improving the
optimization ability of compilers based on dynamic behavior, but collecting
profile data is expensive, cumbersome, and requires regular updating to remain
fresh. We present a novel statistical approach to inferring branch
probabilities that improves the performance of programs that are compiled
without profile guided optimizations. We perform offline training using
information that is collected from a large corpus of binaries that have branch
probabilities information. The learned model is used by the compiler to predict
the branch probabilities of regular uninstrumented programs, which the compiler
can then use to inform optimization decisions. We integrate our technique
directly in LLVM, supplementing the existing human-engineered compiler
heuristics. We evaluate our technique on a suite of benchmarks, demonstrating
some gains over compiling without profile information. In deployment, our
technique requires no profiling runs and has negligible effect on compilation
time.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Rotem_N/0/1/0/all/0/1"&gt;Nadav Rotem&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cummins_C/0/1/0/all/0/1"&gt;Chris Cummins&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modeling Users' Behavior Sequences with Hierarchical Explainable Network for Cross-domain Fraud Detection. (arXiv:2201.01004v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01004</id>
        <link href="http://arxiv.org/abs/2201.01004"/>
        <updated>2022-01-06T00:40:23.302Z</updated>
        <summary type="html"><![CDATA[With the explosive growth of the e-commerce industry, detecting online
transaction fraud in real-world applications has become increasingly important
to the development of e-commerce platforms. The sequential behavior history of
users provides useful information in differentiating fraudulent payments from
regular ones. Recently, some approaches have been proposed to solve this
sequence-based fraud detection problem. However, these methods usually suffer
from two problems: the prediction results are difficult to explain and the
exploitation of the internal information of behaviors is insufficient. To
tackle the above two problems, we propose a Hierarchical Explainable Network
(HEN) to model users' behavior sequences, which could not only improve the
performance of fraud detection but also make the inference process
interpretable. Meanwhile, as e-commerce business expands to new domains, e.g.,
new countries or new markets, one major problem for modeling user behavior in
fraud detection systems is the limitation of data collection, e.g., very few
data/labels available. Thus, in this paper, we further propose a transfer
framework to tackle the cross-domain fraud detection problem, which aims to
transfer knowledge from existing domains (source domains) with enough and
mature data to improve the performance in the new domain (target domain). Our
proposed method is a general transfer framework that could not only be applied
upon HEN but also various existing models in the Embedding & MLP paradigm.
Based on 90 transfer task experiments, we also demonstrate that our transfer
framework could not only contribute to the cross-domain fraud detection task
with HEN, but also be universal and expandable for various existing models.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1"&gt;Yongchun Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xi_D/0/1/0/all/0/1"&gt;Dongbo Xi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1"&gt;Bowen Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1"&gt;Fuzhen Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1"&gt;Shuai Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1"&gt;Xi Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1"&gt;Qing He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multivariate Time Series Regression with Graph Neural Networks. (arXiv:2201.00818v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00818</id>
        <link href="http://arxiv.org/abs/2201.00818"/>
        <updated>2022-01-06T00:40:23.298Z</updated>
        <summary type="html"><![CDATA[Machine learning, with its advances in Deep Learning has shown great
potential in analysing time series in the past. However, in many scenarios,
additional information is available that can potentially improve predictions,
by incorporating it into the learning methods. This is crucial for data that
arises from e.g., sensor networks that contain information about sensor
locations. Then, such spatial information can be exploited by modeling it via
graph structures, along with the sequential (time) information. Recent advances
in adapting Deep Learning to graphs have shown promising potential in various
graph-related tasks. However, these methods have not been adapted for time
series related tasks to a great extent. Specifically, most attempts have
essentially consolidated around Spatial-Temporal Graph Neural Networks for time
series forecasting with small sequence lengths. Generally, these architectures
are not suited for regression or classification tasks that contain large
sequences of data. Therefore, in this work, we propose an architecture capable
of processing these long sequences in a multivariate time series regression
task, using the benefits of Graph Neural Networks to improve predictions. Our
model is tested on two seismic datasets that contain earthquake waveforms,
where the goal is to predict intensity measurements of ground shaking at a set
of stations. Our findings demonstrate promising results of our approach, which
are discussed in depth with an additional ablation study.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bloemheuvel_S/0/1/0/all/0/1"&gt;Stefan Bloemheuvel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hoogen_J/0/1/0/all/0/1"&gt;Jurgen van den Hoogen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jozinovic_D/0/1/0/all/0/1"&gt;Dario Jozinovi&amp;#x107;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Michelini_A/0/1/0/all/0/1"&gt;Alberto Michelini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Atzmueller_M/0/1/0/all/0/1"&gt;Martin Atzmueller&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Value Functions Factorization with Latent State Information Sharing in Decentralized Multi-Agent Policy Gradients. (arXiv:2201.01247v1 [cs.MA])]]></title>
        <id>http://arxiv.org/abs/2201.01247</id>
        <link href="http://arxiv.org/abs/2201.01247"/>
        <updated>2022-01-06T00:40:23.298Z</updated>
        <summary type="html"><![CDATA[Value function factorization via centralized training and decentralized
execution is promising for solving cooperative multi-agent reinforcement tasks.
One of the approaches in this area, QMIX, has become state-of-the-art and
achieved the best performance on the StarCraft II micromanagement benchmark.
However, the monotonic-mixing of per agent estimates in QMIX is known to
restrict the joint action Q-values it can represent, as well as the
insufficient global state information for single agent value function
estimation, often resulting in suboptimality. To this end, we present LSF-SAC,
a novel framework that features a variational inference-based
information-sharing mechanism as extra state information to assist individual
agents in the value function factorization. We demonstrate that such latent
individual state information sharing can significantly expand the power of
value function factorization, while fully decentralized execution can still be
maintained in LSF-SAC through a soft-actor-critic design. We evaluate LSF-SAC
on the StarCraft II micromanagement challenge and demonstrate that it
outperforms several state-of-the-art methods in challenging collaborative
tasks. We further set extensive ablation studies for locating the key factors
accounting for its performance improvements. We believe that this new insight
can lead to new local value estimation methods and variational deep learning
algorithms. A demo video and code of implementation can be found at
https://sites.google.com/view/sacmm.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1"&gt;Hanhan Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lan_T/0/1/0/all/0/1"&gt;Tian Lan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1"&gt;Vaneet Aggarwal&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automated Graph Machine Learning: Approaches, Libraries and Directions. (arXiv:2201.01288v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01288</id>
        <link href="http://arxiv.org/abs/2201.01288"/>
        <updated>2022-01-06T00:40:23.298Z</updated>
        <summary type="html"><![CDATA[Graph machine learning has been extensively studied in both academic and
industry. However, as the literature on graph learning booms with a vast number
of emerging methods and techniques, it becomes increasingly difficult to
manually design the optimal machine learning algorithm for different
graph-related tasks. To tackle the challenge, automated graph machine learning,
which aims at discovering the best hyper-parameter and neural architecture
configuration for different graph tasks/data without manual design, is gaining
an increasing number of attentions from the research community. In this paper,
we extensively discuss automated graph machine approaches, covering
hyper-parameter optimization (HPO) and neural architecture search (NAS) for
graph machine learning. We briefly overview existing libraries designed for
either graph machine learning or automated machine learning respectively, and
further in depth introduce AutoGL, our dedicated and the world's first
open-source library for automated graph machine learning. Last but not least,
we share our insights on future research directions for automated graph machine
learning. This paper is the first systematic and comprehensive discussion of
approaches, libraries as well as directions for automated graph machine
learning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"&gt;Xin Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1"&gt;Ziwei Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1"&gt;Wenwu Zhu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Multi-Organ Segmentation Using SpatialConfiguration-Net with Low GPU Memory Requirements. (arXiv:2111.13630v2 [eess.IV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.13630</id>
        <link href="http://arxiv.org/abs/2111.13630"/>
        <updated>2022-01-06T00:40:23.297Z</updated>
        <summary type="html"><![CDATA[Even though many semantic segmentation methods exist that are able to perform
well on many medical datasets, often, they are not designed for direct use in
clinical practice. The two main concerns are generalization to unseen data with
a different visual appearance, e.g., images acquired using a different scanner,
and efficiency in terms of computation time and required Graphics Processing
Unit (GPU) memory. In this work, we employ a multi-organ segmentation model
based on the SpatialConfiguration-Net (SCN), which integrates prior knowledge
of the spatial configuration among the labelled organs to resolve spurious
responses in the network outputs. Furthermore, we modified the architecture of
the segmentation model to reduce its memory footprint as much as possible
without drastically impacting the quality of the predictions. Lastly, we
implemented a minimal inference script for which we optimized both, execution
time and required GPU memory.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Thaler_F/0/1/0/all/0/1"&gt;Franz Thaler&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Payer_C/0/1/0/all/0/1"&gt;Christian Payer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Bischof_H/0/1/0/all/0/1"&gt;Horst Bischof&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Stern_D/0/1/0/all/0/1"&gt;Darko Stern&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resilience Aspects in Distributed Wireless Electroencephalographic Sampling. (arXiv:2201.01272v1 [eess.SP])]]></title>
        <id>http://arxiv.org/abs/2201.01272</id>
        <link href="http://arxiv.org/abs/2201.01272"/>
        <updated>2022-01-06T00:40:23.293Z</updated>
        <summary type="html"><![CDATA[Resilience aspects of remote electroencephalography sampling are considered.
The possibility to use motion sensors data and measurement of industrial power
network interference for detection of failed sampling channels is demonstrated.
No significant correlation between signals of failed channels and motion
sensors data is shown. Level of 50 Hz spectral component from failed channels
significantly differs from level of 50 Hz component of normally operating
channel. Conclusions about application of these results for increasing
resilience of electroencephalography sampling is made.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Natarov_R/0/1/0/all/0/1"&gt;R. Natarov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Sudakov_O/0/1/0/all/0/1"&gt;O. Sudakov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Dyka_Z/0/1/0/all/0/1"&gt;Z. Dyka&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Kabin_I/0/1/0/all/0/1"&gt;I. Kabin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Maksymyuk_O/0/1/0/all/0/1"&gt;O. Maksymyuk&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Iegorova_O/0/1/0/all/0/1"&gt;O. Iegorova&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Krishtal_O/0/1/0/all/0/1"&gt;O. Krishtal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Langendorfer_P/0/1/0/all/0/1"&gt;P. Langend&amp;#xf6;rfer&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Compensation Learning. (arXiv:2107.11921v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2107.11921</id>
        <link href="http://arxiv.org/abs/2107.11921"/>
        <updated>2022-01-06T00:40:23.288Z</updated>
        <summary type="html"><![CDATA[Weighting strategy prevails in machine learning. For example, a common
approach in robust machine learning is to exert lower weights on samples which
are likely to be noisy or quite hard. This study reveals another undiscovered
strategy, namely, compensating. Various incarnations of compensating have been
utilized but it has not been explicitly revealed. Learning with compensating is
called compensation learning and a systematic taxonomy is constructed for it in
this study. In our taxonomy, compensation learning is divided on the basis of
the compensation targets, directions, inference manners, and granularity
levels. Many existing learning algorithms including some classical ones can be
viewed or understood at least partially as compensation techniques.
Furthermore, a family of new learning algorithms can be obtained by plugging
the compensation learning into existing learning algorithms. Specifically, two
concrete new learning algorithms are proposed for robust machine learning.
Extensive experiments on image classification and text sentiment analysis
verify the effectiveness of the two new algorithms. Compensation learning can
also be used in other various learning scenarios, such as imbalance learning,
clustering, regression, and so on.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yao_R/0/1/0/all/0/1"&gt;Rujing Yao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_O/0/1/0/all/0/1"&gt;Ou Wu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Common Misconceptions about Population Data. (arXiv:2112.10912v2 [cs.DB] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.10912</id>
        <link href="http://arxiv.org/abs/2112.10912"/>
        <updated>2022-01-06T00:40:23.288Z</updated>
        <summary type="html"><![CDATA[Databases covering all individuals of a population are increasingly used for
research studies in domains ranging from public health to the social sciences.
There is also growing interest by governments and businesses to use population
data to support data-driven decision making. The massive size of such databases
is often mistaken as a guarantee for valid inferences on the population of
interest. However, population data have characteristics that make them
challenging to use, including various assumptions being made how such data were
collected and what types of processing have been applied to them. Furthermore,
the full potential of population data can often only be unlocked when such data
are linked to other databases, a process that adds fresh challenges. This
article discusses a diverse range of misconceptions about population data that
we believe anybody who works with such data needs to be aware of. Many of these
misconceptions are not well documented in scientific publications but only
discussed anecdotally among researchers and practitioners. We conclude with a
set of recommendations for inference when using population data.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Christen_P/0/1/0/all/0/1"&gt;Peter Christen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schnell_R/0/1/0/all/0/1"&gt;Rainer Schnell&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building a great multi-lingual teacher with sparsely-gated mixture of experts for speech recognition. (arXiv:2112.05820v3 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.05820</id>
        <link href="http://arxiv.org/abs/2112.05820"/>
        <updated>2022-01-06T00:40:23.287Z</updated>
        <summary type="html"><![CDATA[The sparsely-gated Mixture of Experts (MoE) can magnify a network capacity
with a little computational complexity. In this work, we investigate how
multi-lingual Automatic Speech Recognition (ASR) networks can be scaled up with
a simple routing algorithm in order to achieve better accuracy. More
specifically, we apply the sparsely-gated MoE technique to two types of
networks: Sequence-to-Sequence Transformer (S2S-T) and Transformer Transducer
(T-T). We demonstrate through a set of ASR experiments on multiple language
data that the MoE networks can reduce the relative word error rates by 16.3%
and 4.6% with the S2S-T and T-T, respectively. Moreover, we thoroughly
investigate the effect of the MoE on the T-T architecture in various
conditions: streaming mode, non-streaming mode, the use of language ID and the
label decoder with the MoE.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kumatani_K/0/1/0/all/0/1"&gt;Kenichi Kumatani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gmyr_R/0/1/0/all/0/1"&gt;Robert Gmyr&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Salinas_F/0/1/0/all/0/1"&gt;Felipe Cruz Salinas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1"&gt;Linquan Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1"&gt;Wei Zuo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1"&gt;Devang Patel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_E/0/1/0/all/0/1"&gt;Eric Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1"&gt;Yu Shi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Semi-supervised Federated Learning for Images Automatic Recognition in Internet of Drones. (arXiv:2201.01230v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01230</id>
        <link href="http://arxiv.org/abs/2201.01230"/>
        <updated>2022-01-06T00:40:23.286Z</updated>
        <summary type="html"><![CDATA[Air access networks have been recognized as a significant driver of various
Internet of Things (IoT) services and applications. In particular, the aerial
computing network infrastructure centered on the Internet of Drones has set off
a new revolution in automatic image recognition. This emerging technology
relies on sharing ground truth labeled data between Unmanned Aerial Vehicle
(UAV) swarms to train a high-quality automatic image recognition model.
However, such an approach will bring data privacy and data availability
challenges. To address these issues, we first present a Semi-supervised
Federated Learning (SSFL) framework for privacy-preserving UAV image
recognition. Specifically, we propose model parameters mixing strategy to
improve the naive combination of FL and semi-supervised learning methods under
two realistic scenarios (labels-at-client and labels-at-server), which is
referred to as Federated Mixing (FedMix). Furthermore, there are significant
differences in the number, features, and distribution of local data collected
by UAVs using different camera modules in different environments, i.e.,
statistical heterogeneity. To alleviate the statistical heterogeneity problem,
we propose an aggregation rule based on the frequency of the client's
participation in training, namely the FedFreq aggregation rule, which can
adjust the weight of the corresponding local model according to its frequency.
Numerical results demonstrate that the performance of our proposed method is
significantly better than those of the current baseline and is robust to
different non-IID levels of client data.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1"&gt;Zhe Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1"&gt;Shiyao Ma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1"&gt;Zhaohui Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1"&gt;Zehui Xiong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1"&gt;Jiawen Kang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1"&gt;Yi Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1"&gt;Kejia Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1"&gt;Dusit Niyato&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Two-level Graph Neural Network. (arXiv:2201.01190v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01190</id>
        <link href="http://arxiv.org/abs/2201.01190"/>
        <updated>2022-01-06T00:40:23.004Z</updated>
        <summary type="html"><![CDATA[Graph Neural Networks (GNNs) are recently proposed neural network structures
for the processing of graph-structured data. Due to their employed neighbor
aggregation strategy, existing GNNs focus on capturing node-level information
and neglect high-level information. Existing GNNs therefore suffer from
representational limitations caused by the Local Permutation Invariance (LPI)
problem. To overcome these limitations and enrich the features captured by
GNNs, we propose a novel GNN framework, referred to as the Two-level GNN
(TL-GNN). This merges subgraph-level information with node-level information.
Moreover, we provide a mathematical analysis of the LPI problem which
demonstrates that subgraph-level information is beneficial to overcoming the
problems associated with LPI. A subgraph counting method based on the dynamic
programming algorithm is also proposed, and this has time complexity is O(n^3),
n is the number of nodes of a graph. Experiments show that TL-GNN outperforms
existing GNNs and achieves state-of-the-art performance.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ai_X/0/1/0/all/0/1"&gt;Xing Ai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1"&gt;Chengyu Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1"&gt;Zhihong Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hancock_E/0/1/0/all/0/1"&gt;Edwin R Hancock&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Combat Data Shift in Few-shot Learning with Knowledge Graph. (arXiv:2101.11354v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2101.11354</id>
        <link href="http://arxiv.org/abs/2101.11354"/>
        <updated>2022-01-06T00:40:22.989Z</updated>
        <summary type="html"><![CDATA[Many few-shot learning approaches have been designed under the meta-learning
framework, which learns from a variety of learning tasks and generalizes to new
tasks. These meta-learning approaches achieve the expected performance in the
scenario where all samples are drawn from the same distributions (i.i.d.
observations). However, in real-world applications, few-shot learning paradigm
often suffers from data shift, i.e., samples in different tasks, even in the
same task, could be drawn from various data distributions. Most existing
few-shot learning approaches are not designed with the consideration of data
shift, and thus show downgraded performance when data distribution shifts.
However, it is non-trivial to address the data shift problem in few-shot
learning, due to the limited number of labeled samples in each task. Targeting
at addressing this problem, we propose a novel metric-based meta-learning
framework to extract task-specific representations and task-shared
representations with the help of knowledge graph. The data shift within/between
tasks can thus be combated by the combination of task-shared and task-specific
representations. The proposed model is evaluated on popular benchmarks and two
constructed new challenging datasets. The evaluation results demonstrate its
remarkable performance.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1"&gt;Yongchun Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1"&gt;Fuzhen Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"&gt;Xiangliang Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1"&gt;Zhiyuan Qi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1"&gt;Zhiping Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1"&gt;Juan Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1"&gt;Qing He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks. (arXiv:2110.03825v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.03825</id>
        <link href="http://arxiv.org/abs/2110.03825"/>
        <updated>2022-01-06T00:40:22.989Z</updated>
        <summary type="html"><![CDATA[Deep neural networks (DNNs) are known to be vulnerable to adversarial
attacks. A range of defense methods have been proposed to train adversarially
robust DNNs, among which adversarial training has demonstrated promising
results. However, despite preliminary understandings developed for adversarial
training, it is still not clear, from the architectural perspective, what
configurations can lead to more robust DNNs. In this paper, we address this gap
via a comprehensive investigation on the impact of network width and depth on
the robustness of adversarially trained DNNs. Specifically, we make the
following key observations: 1) more parameters (higher model capacity) does not
necessarily help adversarial robustness; 2) reducing capacity at the last stage
(the last group of blocks) of the network can actually improve adversarial
robustness; and 3) under the same parameter budget, there exists an optimal
architectural configuration for adversarial robustness. We also provide a
theoretical analysis explaning why such network configuration can help
robustness. These architectural insights can help design adversarially robust
DNNs. Code is available at \url{https://github.com/HanxunH/RobustWRN}.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1"&gt;Hanxun Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yisen Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Erfani_S/0/1/0/all/0/1"&gt;Sarah Monazam Erfani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bailey_J/0/1/0/all/0/1"&gt;James Bailey&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1"&gt;Xingjun Ma&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks. (arXiv:2110.03825v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.03825</id>
        <link href="http://arxiv.org/abs/2110.03825"/>
        <updated>2022-01-06T00:40:22.981Z</updated>
        <summary type="html"><![CDATA[Deep neural networks (DNNs) are known to be vulnerable to adversarial
attacks. A range of defense methods have been proposed to train adversarially
robust DNNs, among which adversarial training has demonstrated promising
results. However, despite preliminary understandings developed for adversarial
training, it is still not clear, from the architectural perspective, what
configurations can lead to more robust DNNs. In this paper, we address this gap
via a comprehensive investigation on the impact of network width and depth on
the robustness of adversarially trained DNNs. Specifically, we make the
following key observations: 1) more parameters (higher model capacity) does not
necessarily help adversarial robustness; 2) reducing capacity at the last stage
(the last group of blocks) of the network can actually improve adversarial
robustness; and 3) under the same parameter budget, there exists an optimal
architectural configuration for adversarial robustness. We also provide a
theoretical analysis explaning why such network configuration can help
robustness. These architectural insights can help design adversarially robust
DNNs. Code is available at \url{https://github.com/HanxunH/RobustWRN}.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1"&gt;Hanxun Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yisen Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Erfani_S/0/1/0/all/0/1"&gt;Sarah Monazam Erfani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bailey_J/0/1/0/all/0/1"&gt;James Bailey&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1"&gt;Xingjun Ma&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PluGeN: Multi-Label Conditional Generation From Pre-Trained Models. (arXiv:2109.09011v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.09011</id>
        <link href="http://arxiv.org/abs/2109.09011"/>
        <updated>2022-01-06T00:40:22.957Z</updated>
        <summary type="html"><![CDATA[Modern generative models achieve excellent quality in a variety of tasks
including image or text generation and chemical molecule modeling. However,
existing methods often lack the essential ability to generate examples with
requested properties, such as the age of the person in the photo or the weight
of the generated molecule. Incorporating such additional conditioning factors
would require rebuilding the entire architecture and optimizing the parameters
from scratch. Moreover, it is difficult to disentangle selected attributes so
that to perform edits of only one attribute while leaving the others unchanged.
To overcome these limitations we propose PluGeN (Plugin Generative Network), a
simple yet effective generative technique that can be used as a plugin to
pre-trained generative models. The idea behind our approach is to transform the
entangled latent representation using a flow-based module into a
multi-dimensional space where the values of each attribute are modeled as an
independent one-dimensional distribution. In consequence, PluGeN can generate
new samples with desired attributes as well as manipulate labeled attributes of
existing examples. Due to the disentangling of the latent representation, we
are even able to generate samples with rare or unseen combinations of
attributes in the dataset, such as a young person with gray hair, men with
make-up, or women with beards. We combined PluGeN with GAN and VAE models and
applied it to conditional generation and manipulation of images and chemical
molecule modeling. Experiments demonstrate that PluGeN preserves the quality of
backbone models while adding the ability to control the values of labeled
attributes.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wolczyk_M/0/1/0/all/0/1"&gt;Maciej Wo&amp;#x142;czyk&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Proszewska_M/0/1/0/all/0/1"&gt;Magdalena Proszewska&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Maziarka_L/0/1/0/all/0/1"&gt;&amp;#x141;ukasz Maziarka&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zieba_M/0/1/0/all/0/1"&gt;Maciej Zi&amp;#x119;ba&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wielopolski_P/0/1/0/all/0/1"&gt;Patryk Wielopolski&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kurczab_R/0/1/0/all/0/1"&gt;Rafa&amp;#x142; Kurczab&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1"&gt;Marek &amp;#x15a;mieja&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerated Zeroth-Order and First-Order Momentum Methods from Mini to Minimax Optimization. (arXiv:2008.08170v5 [math.OC] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2008.08170</id>
        <link href="http://arxiv.org/abs/2008.08170"/>
        <updated>2022-01-06T00:40:22.935Z</updated>
        <summary type="html"><![CDATA[In the paper, we propose a class of accelerated zeroth-order and first-order
momentum methods for both nonconvex mini-optimization and minimax-optimization.
Specifically, we propose a new accelerated zeroth-order momentum (Acc-ZOM)
method for black-box mini-optimization. Moreover, we prove that our Acc-ZOM
method achieves a lower query complexity of $\tilde{O}(d^{3/4}\epsilon^{-3})$
for finding an $\epsilon$-stationary point, which improves the best known
result by a factor of $O(d^{1/4})$ where $d$ denotes the variable dimension. In
particular, the Acc-ZOM does not require large batches required in the existing
zeroth-order stochastic algorithms. Meanwhile, we propose an accelerated
\textbf{zeroth-order} momentum descent ascent (Acc-ZOMDA) method for
\textbf{black-box} minimax-optimization, which obtains a query complexity of
$\tilde{O}((d_1+d_2)^{3/4}\kappa_y^{4.5}\epsilon^{-3})$ without large batches
for finding an $\epsilon$-stationary point, where $d_1$ and $d_2$ denote
variable dimensions and $\kappa_y$ is condition number. Moreover, we propose an
accelerated \textbf{first-order} momentum descent ascent (Acc-MDA) method for
\textbf{white-box} minimax optimization, which has a gradient complexity of
$\tilde{O}(\kappa_y^{4.5}\epsilon^{-3})$ without large batches for finding an
$\epsilon$-stationary point. In particular, our Acc-MDA can obtain a lower
gradient complexity of $\tilde{O}(\kappa_y^{2.5}\epsilon^{-3})$ with a batch
size $O(\kappa_y^4)$. Extensive experimental results on the black-box
adversarial attack to deep neural networks (DNNs) and poisoning attack
demonstrate efficiency of our algorithms.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Huang_F/0/1/0/all/0/1"&gt;Feihu Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Gao_S/0/1/0/all/0/1"&gt;Shangqian Gao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Pei_J/0/1/0/all/0/1"&gt;Jian Pei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Huang_H/0/1/0/all/0/1"&gt;Heng Huang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Generate Novel Classes for Deep Metric Learning. (arXiv:2201.01008v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.01008</id>
        <link href="http://arxiv.org/abs/2201.01008"/>
        <updated>2022-01-06T00:40:22.931Z</updated>
        <summary type="html"><![CDATA[Deep metric learning aims to learn an embedding space where the distance
between data reflects their class equivalence, even when their classes are
unseen during training. However, the limited number of classes available in
training precludes generalization of the learned embedding space. Motivated by
this, we introduce a new data augmentation approach that synthesizes novel
classes and their embedding vectors. Our approach can provide rich semantic
information to an embedding model and improve its generalization by augmenting
training data with novel classes unavailable in the original data. We implement
this idea by learning and exploiting a conditional generative model, which,
given a class label and a noise, produces a random embedding vector of the
class. Our proposed generator allows the loss to use richer class relations by
augmenting realistic and diverse classes, resulting in better generalization to
unseen samples. Experimental results on public benchmark datasets demonstrate
that our method clearly enhances the performance of proxy-based losses.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1"&gt;Kyungmoon Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1"&gt;Sungyeon Kim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1"&gt;Seunghoon Hong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kwak_S/0/1/0/all/0/1"&gt;Suha Kwak&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-relaxed Gromov-Wasserstein divergence with applications on graphs. (arXiv:2110.02753v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.02753</id>
        <link href="http://arxiv.org/abs/2110.02753"/>
        <updated>2022-01-06T00:40:22.923Z</updated>
        <summary type="html"><![CDATA[Comparing structured objects such as graphs is a fundamental operation
involved in many learning tasks. To this end, the Gromov-Wasserstein (GW)
distance, based on Optimal Transport (OT), has proven to be successful in
handling the specific nature of the associated objects. More specifically,
through the nodes connectivity relations, GW operates on graphs, seen as
probability measures over specific spaces. At the core of OT is the idea of
conservation of mass, which imposes a coupling between all the nodes from the
two considered graphs. We argue in this paper that this property can be
detrimental for tasks such as graph dictionary or partition learning, and we
relax it by proposing a new semi-relaxed Gromov-Wasserstein divergence. Aside
from immediate computational benefits, we discuss its properties, and show that
it can lead to an efficient graph dictionary learning algorithm. We empirically
demonstrate its relevance for complex tasks on graphs such as partitioning,
clustering and completion.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Vincent_Cuaz_C/0/1/0/all/0/1"&gt;C&amp;#xe9;dric Vincent-Cuaz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Flamary_R/0/1/0/all/0/1"&gt;R&amp;#xe9;mi Flamary&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Corneli_M/0/1/0/all/0/1"&gt;Marco Corneli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vayer_T/0/1/0/all/0/1"&gt;Titouan Vayer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Courty_N/0/1/0/all/0/1"&gt;Nicolas Courty&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration. (arXiv:2109.14285v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.14285</id>
        <link href="http://arxiv.org/abs/2109.14285"/>
        <updated>2022-01-06T00:40:22.919Z</updated>
        <summary type="html"><![CDATA[Despite Graph Neural Networks (GNNs) have achieved remarkable accuracy,
whether the results are trustworthy is still unexplored. Previous studies
suggest that many modern neural networks are over-confident on the predictions,
however, surprisingly, we discover that GNNs are primarily in the opposite
direction, i.e., GNNs are under-confident. Therefore, the confidence
calibration for GNNs is highly desired. In this paper, we propose a novel
trustworthy GNN model by designing a topology-aware post-hoc calibration
function. Specifically, we first verify that the confidence distribution in a
graph has homophily property, and this finding inspires us to design a
calibration GNN model (CaGCN) to learn the calibration function. CaGCN is able
to obtain a unique transformation from logits of GNNs to the calibrated
confidence for each node, meanwhile, such transformation is able to preserve
the order between classes, satisfying the accuracy-preserving property.
Moreover, we apply the calibration GNN to self-training framework, showing that
more trustworthy pseudo labels can be obtained with the calibrated confidence
and further improve the performance. Extensive experiments demonstrate the
effectiveness of our proposed model in terms of both calibration and accuracy.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"&gt;Xiao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1"&gt;Hongrui Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1"&gt;Chuan Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1"&gt;Cheng Yang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Play No-Press Diplomacy with Best Response Policy Iteration. (arXiv:2006.04635v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2006.04635</id>
        <link href="http://arxiv.org/abs/2006.04635"/>
        <updated>2022-01-06T00:40:22.917Z</updated>
        <summary type="html"><![CDATA[Recent advances in deep reinforcement learning (RL) have led to considerable
progress in many 2-player zero-sum games, such as Go, Poker and Starcraft. The
purely adversarial nature of such games allows for conceptually simple and
principled application of RL methods. However real-world settings are
many-agent, and agent interactions are complex mixtures of common-interest and
competitive aspects. We consider Diplomacy, a 7-player board game designed to
accentuate dilemmas resulting from many-agent interactions. It also features a
large combinatorial action space and simultaneous moves, which are challenging
for RL algorithms. We propose a simple yet effective approximate best response
operator, designed to handle large combinatorial action spaces and simultaneous
moves. We also introduce a family of policy iteration methods that approximate
fictitious play. With these methods, we successfully apply RL to Diplomacy: we
show that our agents convincingly outperform the previous state-of-the-art, and
game theoretic equilibrium analysis shows that the new process yields
consistent improvements.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Anthony_T/0/1/0/all/0/1"&gt;Thomas Anthony&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Eccles_T/0/1/0/all/0/1"&gt;Tom Eccles&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tacchetti_A/0/1/0/all/0/1"&gt;Andrea Tacchetti&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kramar_J/0/1/0/all/0/1"&gt;J&amp;#xe1;nos Kram&amp;#xe1;r&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gemp_I/0/1/0/all/0/1"&gt;Ian Gemp&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hudson_T/0/1/0/all/0/1"&gt;Thomas C. Hudson&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Porcel_N/0/1/0/all/0/1"&gt;Nicolas Porcel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lanctot_M/0/1/0/all/0/1"&gt;Marc Lanctot&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Perolat_J/0/1/0/all/0/1"&gt;Julien P&amp;#xe9;rolat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Everett_R/0/1/0/all/0/1"&gt;Richard Everett&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Werpachowski_R/0/1/0/all/0/1"&gt;Roman Werpachowski&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1"&gt;Satinder Singh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Graepel_T/0/1/0/all/0/1"&gt;Thore Graepel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bachrach_Y/0/1/0/all/0/1"&gt;Yoram Bachrach&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Survey On Universal Adversarial Attack. (arXiv:2103.01498v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.01498</id>
        <link href="http://arxiv.org/abs/2103.01498"/>
        <updated>2022-01-06T00:40:22.906Z</updated>
        <summary type="html"><![CDATA[The intriguing phenomenon of adversarial examples has attracted significant
attention in machine learning and what might be more surprising to the
community is the existence of universal adversarial perturbations (UAPs), i.e.
a single perturbation to fool the target DNN for most images. With the focus on
UAP against deep classifiers, this survey summarizes the recent progress on
universal adversarial attacks, discussing the challenges from both the attack
and defense sides, as well as the reason for the existence of UAP. We aim to
extend this work as a dynamic survey that will regularly update its content to
follow new works regarding UAP or universal attack in a wide range of domains,
such as image, audio, video, text, etc. Relevant updates will be discussed at:
https://bit.ly/2SbQlLG. We welcome authors of future works in this field to
contact us for including your new finding.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1"&gt;Chaoning Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Benz_P/0/1/0/all/0/1"&gt;Philipp Benz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1"&gt;Chenguo Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Karjauv_A/0/1/0/all/0/1"&gt;Adil Karjauv&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"&gt;Jing Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1"&gt;In So Kweon&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the effectiveness of adversarial training against common corruptions. (arXiv:2103.02325v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.02325</id>
        <link href="http://arxiv.org/abs/2103.02325"/>
        <updated>2022-01-06T00:40:22.898Z</updated>
        <summary type="html"><![CDATA[The literature on robustness towards common corruptions shows no consensus on
whether adversarial training can improve the performance in this setting.
First, we show that, when used with an appropriately selected perturbation
radius, $\ell_p$ adversarial training can serve as a strong baseline against
common corruptions improving both accuracy and calibration. Then we explain why
adversarial training performs better than data augmentation with simple
Gaussian noise which has been observed to be a meaningful baseline on common
corruptions. Related to this, we identify the $\sigma$-overfitting phenomenon
when Gaussian augmentation overfits to a particular standard deviation used for
training which has a significant detrimental effect on common corruption
accuracy. We discuss how to alleviate this problem and then how to further
enhance $\ell_p$ adversarial training by introducing an efficient relaxation of
adversarial training with learned perceptual image patch similarity as the
distance metric. Through experiments on CIFAR-10 and ImageNet-100, we show that
our approach does not only improve the $\ell_p$ adversarial training baseline
but also has cumulative gains with data augmentation methods such as AugMix,
DeepAugment, ANT, and SIN, leading to state-of-the-art performance on common
corruptions.

The code of our experiments is publicly available at
https://github.com/tml-epfl/adv-training-corruptions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kireev_K/0/1/0/all/0/1"&gt;Klim Kireev&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Andriushchenko_M/0/1/0/all/0/1"&gt;Maksym Andriushchenko&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1"&gt;Nicolas Flammarion&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[3DVSR: 3D EPI Volume-based Approach for Angular and Spatial Light field Image Super-resolution. (arXiv:2201.01294v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.01294</id>
        <link href="http://arxiv.org/abs/2201.01294"/>
        <updated>2022-01-06T00:40:22.869Z</updated>
        <summary type="html"><![CDATA[Light field (LF) imaging, which captures both spatial and angular information
of a scene, is undoubtedly beneficial to numerous applications. Although
various techniques have been proposed for LF acquisition, achieving both
angularly and spatially high-resolution LF remains a technology challenge. In
this paper, a learning-based approach applied to 3D epipolar image (EPI) is
proposed to reconstruct high-resolution LF. Through a 2-stage super-resolution
framework, the proposed approach effectively addresses various LF
super-resolution (SR) problems, i.e., spatial SR, angular SR, and
angular-spatial SR. While the first stage provides flexible options to
up-sample EPI volume to the desired resolution, the second stage, which
consists of a novel EPI volume-based refinement network (EVRN), substantially
enhances the quality of the high-resolution EPI volume. An extensive evaluation
on 90 challenging synthetic and real-world light field scenes from 7 published
datasets shows that the proposed approach outperforms state-of-the-art methods
to a large extend for both spatial and angular super-resolution problem, i.e.,
an average peak signal to noise ratio improvement of more than 2.0 dB, 1.4 dB,
and 3.14 dB in spatial SR $\times 2$, spatial SR $\times 4$, and angular SR
respectively. The reconstructed 4D light field demonstrates a balanced
performance distribution across all perspective images and presents superior
visual quality compared to the previous works.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1"&gt;Trung-Hieu Tran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Berberich_J/0/1/0/all/0/1"&gt;Jan Berberich&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Simon_S/0/1/0/all/0/1"&gt;Sven Simon&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign Overfitting. (arXiv:2106.09276v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.09276</id>
        <link href="http://arxiv.org/abs/2106.09276"/>
        <updated>2022-01-06T00:40:22.861Z</updated>
        <summary type="html"><![CDATA[We consider interpolation learning in high-dimensional linear regression with
Gaussian data, and prove a generic uniform convergence guarantee on the
generalization error of interpolators in an arbitrary hypothesis class in terms
of the class's Gaussian width. Applying the generic bound to Euclidean norm
balls recovers the consistency result of Bartlett et al. (2020) for
minimum-norm interpolators, and confirms a prediction of Zhou et al. (2020) for
near-minimal-norm interpolators in the special case of Gaussian data. We
demonstrate the generality of the bound by applying it to the simplex,
obtaining a novel consistency result for minimum l1-norm interpolators (basis
pursuit). Our results show how norm-based generalization bounds can explain and
be used to analyze benign overfitting, at least in some settings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Koehler_F/0/1/0/all/0/1"&gt;Frederic Koehler&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhou_L/0/1/0/all/0/1"&gt;Lijia Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1"&gt;Danica J. Sutherland&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Srebro_N/0/1/0/all/0/1"&gt;Nathan Srebro&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fast Approximation of the Sliced-Wasserstein Distance Using Concentration of Random Projections. (arXiv:2106.15427v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.15427</id>
        <link href="http://arxiv.org/abs/2106.15427"/>
        <updated>2022-01-06T00:40:22.853Z</updated>
        <summary type="html"><![CDATA[The Sliced-Wasserstein distance (SW) is being increasingly used in machine
learning applications as an alternative to the Wasserstein distance and offers
significant computational and statistical benefits. Since it is defined as an
expectation over random projections, SW is commonly approximated by Monte
Carlo. We adopt a new perspective to approximate SW by making use of the
concentration of measure phenomenon: under mild assumptions, one-dimensional
projections of a high-dimensional random vector are approximately Gaussian.
Based on this observation, we develop a simple deterministic approximation for
SW. Our method does not require sampling a number of random projections, and is
therefore both accurate and easy to use compared to the usual Monte Carlo
approximation. We derive nonasymptotical guarantees for our approach, and show
that the approximation error goes to zero as the dimension increases, under a
weak dependence condition on the data distribution. We validate our theoretical
findings on synthetic datasets, and illustrate the proposed approximation on a
generative modeling problem.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Nadjahi_K/0/1/0/all/0/1"&gt;Kimia Nadjahi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1"&gt;Alain Durmus&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Jacob_P/0/1/0/all/0/1"&gt;Pierre E. Jacob&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Badeau_R/0/1/0/all/0/1"&gt;Roland Badeau&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1"&gt;Umut &amp;#x15e;im&amp;#x15f;ekli&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Predicting Influenza A Viral Host Using PSSM and Word Embeddings. (arXiv:2201.01140v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2201.01140</id>
        <link href="http://arxiv.org/abs/2201.01140"/>
        <updated>2022-01-06T00:40:22.847Z</updated>
        <summary type="html"><![CDATA[The rapid mutation of the influenza virus threatens public health.
Reassortment among viruses with different hosts can lead to a fatal pandemic.
However, it is difficult to detect the original host of the virus during or
after an outbreak as influenza viruses can circulate between different species.
Therefore, early and rapid detection of the viral host would help reduce the
further spread of the virus. We use various machine learning models with
features derived from the position-specific scoring matrix (PSSM) and features
learned from word embedding and word encoding to infer the origin host of
viruses. The results show that the performance of the PSSM-based model reaches
the MCC around 95%, and the F1 around 96%. The MCC obtained using the model
with word embedding is around 96%, and the F1 is around 97%.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1"&gt;Yanhua Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wojtczak_D/0/1/0/all/0/1"&gt;Dominik Wojtczak&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual Microfossil Identification via Deep Metric Learning. (arXiv:2112.09490v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.09490</id>
        <link href="http://arxiv.org/abs/2112.09490"/>
        <updated>2022-01-06T00:40:22.839Z</updated>
        <summary type="html"><![CDATA[We apply deep metric learning for the first time to the prob-lem of
classifying planktic foraminifer shells on microscopic images. This species
recognition task is an important information source and scientific pillar for
reconstructing past climates. All foraminifer CNN recognition pipelines in the
literature produce black-box classifiers that lack visualisation options for
human experts and cannot be applied to open set problems. Here, we benchmark
metric learning against these pipelines, produce the first scientific
visualisation of the phenotypic planktic foraminifer morphology space, and
demonstrate that metric learning can be used to cluster species unseen during
training. We show that metric learning out-performs all published CNN-based
state-of-the-art benchmarks in this domain. We evaluate our approach on the
34,640 expert-annotated images of the Endless Forams public library of 35
modern planktic foraminifera species. Our results on this data show leading 92%
accuracy (at 0.84 F1-score) in reproducing expert labels on withheld test data,
and 66.5% accuracy (at 0.70 F1-score) when clustering species never encountered
in training. We conclude that metric learning is highly effective for this
domain and serves as an important tool towards expert-in-the-loop automation of
microfossil identification. Key code, network weights, and data splits are
published with this paper for full reproducibility.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Karaderi_T/0/1/0/all/0/1"&gt;Tayfun Karaderi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Burghardt_T/0/1/0/all/0/1"&gt;Tilo Burghardt&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hsiang_A/0/1/0/all/0/1"&gt;Allison Y. Hsiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ramaer_J/0/1/0/all/0/1"&gt;Jacob Ramaer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schmidt_D/0/1/0/all/0/1"&gt;Daniela N. Schmidt&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ExAID: A Multimodal Explanation Framework for Computer-Aided Diagnosis of Skin Lesions. (arXiv:2201.01249v1 [cs.AI])]]></title>
        <id>http://arxiv.org/abs/2201.01249</id>
        <link href="http://arxiv.org/abs/2201.01249"/>
        <updated>2022-01-06T00:40:22.838Z</updated>
        <summary type="html"><![CDATA[One principal impediment in the successful deployment of AI-based
Computer-Aided Diagnosis (CAD) systems in clinical workflows is their lack of
transparent decision making. Although commonly used eXplainable AI methods
provide some insight into opaque algorithms, such explanations are usually
convoluted and not readily comprehensible except by highly trained experts. The
explanation of decisions regarding the malignancy of skin lesions from
dermoscopic images demands particular clarity, as the underlying medical
problem definition is itself ambiguous. This work presents ExAID (Explainable
AI for Dermatology), a novel framework for biomedical image analysis, providing
multi-modal concept-based explanations consisting of easy-to-understand textual
explanations supplemented by visual maps justifying the predictions. ExAID
relies on Concept Activation Vectors to map human concepts to those learnt by
arbitrary Deep Learning models in latent space, and Concept Localization Maps
to highlight concepts in the input space. This identification of relevant
concepts is then used to construct fine-grained textual explanations
supplemented by concept-wise location information to provide comprehensive and
coherent multi-modal explanations. All information is comprehensively presented
in a diagnostic interface for use in clinical routines. An educational mode
provides dataset-level explanation statistics and tools for data and model
exploration to aid medical research and education. Through rigorous
quantitative and qualitative evaluation of ExAID, we show the utility of
multi-modal explanations for CAD-assisted scenarios even in case of wrong
predictions. We believe that ExAID will provide dermatologists an effective
screening tool that they both understand and trust. Moreover, it will be the
basis for similar applications in other biomedical imaging fields.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lucieri_A/0/1/0/all/0/1"&gt;Adriano Lucieri&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bajwa_M/0/1/0/all/0/1"&gt;Muhammad Naseer Bajwa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Braun_S/0/1/0/all/0/1"&gt;Stephan Alexander Braun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Malik_M/0/1/0/all/0/1"&gt;Muhammad Imran Malik&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1"&gt;Andreas Dengel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1"&gt;Sheraz Ahmed&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards a Rigorous Evaluation of Time-series Anomaly Detection. (arXiv:2109.05257v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.05257</id>
        <link href="http://arxiv.org/abs/2109.05257"/>
        <updated>2022-01-06T00:40:22.828Z</updated>
        <summary type="html"><![CDATA[In recent years, proposed studies on time-series anomaly detection (TAD)
report high F1 scores on benchmark TAD datasets, giving the impression of clear
improvements in TAD. However, most studies apply a peculiar evaluation protocol
called point adjustment (PA) before scoring. In this paper, we theoretically
and experimentally reveal that the PA protocol has a great possibility of
overestimating the detection performance; that is, even a random anomaly score
can easily turn into a state-of-the-art TAD method. Therefore, the comparison
of TAD methods after applying the PA protocol can lead to misguided rankings.
Furthermore, we question the potential of existing TAD methods by showing that
an untrained model obtains comparable detection performance to the existing
methods even when PA is forbidden. Based on our findings, we propose a new
baseline and an evaluation protocol. We expect that our study will help a
rigorous evaluation of TAD and lead to further improvement in future
researches.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1"&gt;Siwon Kim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1"&gt;Kukjin Choi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1"&gt;Hyun-Soo Choi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1"&gt;Byunghan Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1"&gt;Sungroh Yoon&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Neural Networks: a bibliometrics overview. (arXiv:2201.01188v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01188</id>
        <link href="http://arxiv.org/abs/2201.01188"/>
        <updated>2022-01-06T00:40:22.797Z</updated>
        <summary type="html"><![CDATA[Recently, graph neural networks have become a hot topic in machine learning
community. This paper presents a Scopus based bibliometric overview of the GNNs
research since 2004, when GNN papers were first published. The study aims to
evaluate GNN research trend, both quantitatively and qualitatively. We provide
the trend of research, distribution of subjects, active and influential authors
and institutions, sources of publications, most cited documents, and hot
topics. Our investigations reveal that the most frequent subject categories in
this field are computer science, engineering, telecommunications, linguistics,
operations research and management science, information science and library
science, business and economics, automation and control systems, robotics, and
social sciences. In addition, the most active source of GNN publications is
Lecture Notes in Computer Science. The most prolific or impactful institutions
are found in the United States, China, and Canada. We also provide must read
papers and future directions. Finally, the application of graph convolutional
networks and attention mechanism are now among hot topics of GNN research.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Keramatfar_A/0/1/0/all/0/1"&gt;Abdalsamad Keramatfar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rafiee_M/0/1/0/all/0/1"&gt;Mohadeseh Rafiee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Amirkhani_H/0/1/0/all/0/1"&gt;Hossein Amirkhani&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The cluster structure function. (arXiv:2201.01222v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01222</id>
        <link href="http://arxiv.org/abs/2201.01222"/>
        <updated>2022-01-06T00:40:22.787Z</updated>
        <summary type="html"><![CDATA[For each partition of a data set into a given number of parts there is a
partition such that every part is as much as possible a good model (an
"algorithmic sufficient statistic") for the data in that part. Since this can
be done for every number between one and the number of data, the result is a
function, the cluster structure function. It maps the number of parts of a
partition to values related to the deficiencies of being good models by the
parts. Such a function starts with a value at least zero for no partition of
the data set and descents to zero for the partition of the data set into
singleton parts. The optimal clustering is the one chosen to minimize the
cluster structure function. The theory behind the method is expressed in
algorithmic information theory (Kolmogorov complexity). In practice the
Kolmogorov complexities involved are approximated by a concrete compressor. We
give examples using real data sets: the MNIST handwritten digits and the
segmentation of real cells as used in stem cell research.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1"&gt;Andrew R. Cohen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vitanyi_P/0/1/0/all/0/1"&gt;Paul M.B. Vit&amp;#xe1;nyi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AutoBalance: Optimized Loss Functions for Imbalanced Data. (arXiv:2201.01212v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01212</id>
        <link href="http://arxiv.org/abs/2201.01212"/>
        <updated>2022-01-06T00:40:22.769Z</updated>
        <summary type="html"><![CDATA[Imbalanced datasets are commonplace in modern machine learning problems. The
presence of under-represented classes or groups with sensitive attributes
results in concerns about generalization and fairness. Such concerns are
further exacerbated by the fact that large capacity deep nets can perfectly fit
the training data and appear to achieve perfect accuracy and fairness during
training, but perform poorly during test. To address these challenges, we
propose AutoBalance, a bi-level optimization framework that automatically
designs a training loss function to optimize a blend of accuracy and
fairness-seeking objectives. Specifically, a lower-level problem trains the
model weights, and an upper-level problem tunes the loss function by monitoring
and optimizing the desired objective over the validation data. Our loss design
enables personalized treatment for classes/groups by employing a parametric
cross-entropy loss and individualized data augmentation schemes. We evaluate
the benefits and performance of our approach for the application scenarios of
imbalanced and group-sensitive classification. Extensive empirical evaluations
demonstrate the benefits of AutoBalance over state-of-the-art approaches. Our
experimental findings are complemented with theoretical insights on loss
function design and the benefits of train-validation split. All code is
available open-source.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1"&gt;Mingchen Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"&gt;Xuechen Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1"&gt;Christos Thrampoulidis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"&gt;Jiasi Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1"&gt;Samet Oymak&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sequoia: A Software Framework to Unify Continual Learning Research. (arXiv:2108.01005v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2108.01005</id>
        <link href="http://arxiv.org/abs/2108.01005"/>
        <updated>2022-01-06T00:40:22.757Z</updated>
        <summary type="html"><![CDATA[The field of Continual Learning (CL) seeks to develop algorithms that
accumulate knowledge and skills over time through interaction with
non-stationary environments. In practice, a plethora of evaluation procedures
(settings) and algorithmic solutions (methods) exist, each with their own
potentially disjoint set of assumptions. This variety makes measuring progress
in CL difficult. We propose a taxonomy of settings, where each setting is
described as a set of assumptions. A tree-shaped hierarchy emerges from this
view, where more general settings become the parents of those with more
restrictive assumptions. This makes it possible to use inheritance to share and
reuse research, as developing a method for a given setting also makes it
directly applicable onto any of its children. We instantiate this idea as a
publicly available software framework called Sequoia, which features a wide
variety of settings from both the Continual Supervised Learning (CSL) and
Continual Reinforcement Learning (CRL) domains. Sequoia also includes a growing
suite of methods which are easy to extend and customize, in addition to more
specialized methods from external libraries. We hope that this new paradigm and
its first implementation can help unify and accelerate research in CL. You can
help us grow the tree by visiting github.com/lebrice/Sequoia.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Normandin_F/0/1/0/all/0/1"&gt;Fabrice Normandin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Golemo_F/0/1/0/all/0/1"&gt;Florian Golemo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ostapenko_O/0/1/0/all/0/1"&gt;Oleksiy Ostapenko&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rodriguez_P/0/1/0/all/0/1"&gt;Pau Rodriguez&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Riemer_M/0/1/0/all/0/1"&gt;Matthew D Riemer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hurtado_J/0/1/0/all/0/1"&gt;Julio Hurtado&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Khetarpal_K/0/1/0/all/0/1"&gt;Khimya Khetarpal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lindeborg_R/0/1/0/all/0/1"&gt;Ryan Lindeborg&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cecchi_L/0/1/0/all/0/1"&gt;Lucas Cecchi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lesort_T/0/1/0/all/0/1"&gt;Timoth&amp;#xe9;e Lesort&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Charlin_L/0/1/0/all/0/1"&gt;Laurent Charlin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1"&gt;Irina Rish&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Caccia_M/0/1/0/all/0/1"&gt;Massimo Caccia&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Discovering Diverse Nearly Optimal Policies with Successor Features. (arXiv:2106.00669v2 [cs.AI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.00669</id>
        <link href="http://arxiv.org/abs/2106.00669"/>
        <updated>2022-01-06T00:40:22.737Z</updated>
        <summary type="html"><![CDATA[Finding different solutions to the same problem is a key aspect of
intelligence associated with creativity and adaptation to novel situations. In
reinforcement learning, a set of diverse policies can be useful for
exploration, transfer, hierarchy, and robustness. We propose Diverse Successive
Policies, a method for discovering policies that are diverse in the space of
Successor Features, while assuring that they are near optimal. We formalize the
problem as a Constrained Markov Decision Process (CMDP) where the goal is to
find policies that maximize diversity, characterized by an intrinsic diversity
reward, while remaining near-optimal with respect to the extrinsic reward of
the MDP. We also analyze how recently proposed robustness and discrimination
rewards perform and find that they are sensitive to the initialization of the
procedure and may converge to sub-optimal solutions. To alleviate this, we
propose new explicit diversity rewards that aim to minimize the correlation
between the Successor Features of the policies in the set. We compare the
different diversity mechanisms in the DeepMind Control Suite and find that the
type of explicit diversity we are proposing is important to discover distinct
behavior, like for example different locomotion patterns.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zahavy_T/0/1/0/all/0/1"&gt;Tom Zahavy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1"&gt;Brendan O&amp;#x27;Donoghue&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Barreto_A/0/1/0/all/0/1"&gt;Andre Barreto&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mnih_V/0/1/0/all/0/1"&gt;Volodymyr Mnih&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Flennerhag_S/0/1/0/all/0/1"&gt;Sebastian Flennerhag&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1"&gt;Satinder Singh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variance-Aware Off-Policy Evaluation with Linear Function Approximation. (arXiv:2106.11960v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.11960</id>
        <link href="http://arxiv.org/abs/2106.11960"/>
        <updated>2022-01-06T00:40:22.711Z</updated>
        <summary type="html"><![CDATA[We study the off-policy evaluation (OPE) problem in reinforcement learning
with linear function approximation, which aims to estimate the value function
of a target policy based on the offline data collected by a behavior policy. We
propose to incorporate the variance information of the value function to
improve the sample efficiency of OPE. More specifically, for time-inhomogeneous
episodic linear Markov decision processes (MDPs), we propose an algorithm,
VA-OPE, which uses the estimated variance of the value function to reweight the
Bellman residual in Fitted Q-Iteration. We show that our algorithm achieves a
tighter error bound than the best-known result. We also provide a fine-grained
characterization of the distribution shift between the behavior policy and the
target policy. Extensive numerical experiments corroborate our theory.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Min_Y/0/1/0/all/0/1"&gt;Yifei Min&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1"&gt;Tianhao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Supervised Homogeneity Fusion: a Combinatorial Approach. (arXiv:2201.01036v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2201.01036</id>
        <link href="http://arxiv.org/abs/2201.01036"/>
        <updated>2022-01-06T00:40:22.701Z</updated>
        <summary type="html"><![CDATA[Fusing regression coefficients into homogenous groups can unveil those
coefficients that share a common value within each group. Such groupwise
homogeneity reduces the intrinsic dimension of the parameter space and
unleashes sharper statistical accuracy. We propose and investigate a new
combinatorial grouping approach called $L_0$-Fusion that is amenable to mixed
integer optimization (MIO). On the statistical aspect, we identify a
fundamental quantity called grouping sensitivity that underpins the difficulty
of recovering the true groups. We show that $L_0$-Fusion achieves grouping
consistency under the weakest possible requirement of the grouping sensitivity:
if this requirement is violated, then the minimax risk of group
misspecification will fail to converge to zero. Moreover, we show that in the
high-dimensional regime, one can apply $L_0$-Fusion coupled with a sure
screening set of features without any essential loss of statistical efficiency,
while reducing the computational cost substantially. On the algorithmic aspect,
we provide a MIO formulation for $L_0$-Fusion along with a warm start strategy.
Simulation and real data analysis demonstrate that $L_0$-Fusion exhibits
superiority over its competitors in terms of grouping accuracy.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Wang_W/0/1/0/all/0/1"&gt;Wen Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Wu_S/0/1/0/all/0/1"&gt;Shihao Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhu_Z/0/1/0/all/0/1"&gt;Ziwei Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhou_L/0/1/0/all/0/1"&gt;Ling Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Song_P/0/1/0/all/0/1"&gt;Peter X.-K. Song&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-supervised representation learning from 12-lead ECG data. (arXiv:2103.12676v2 [eess.SP] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.12676</id>
        <link href="http://arxiv.org/abs/2103.12676"/>
        <updated>2022-01-06T00:40:22.694Z</updated>
        <summary type="html"><![CDATA[Clinical 12-lead electrocardiography (ECG) is one of the most widely
encountered kinds of biosignals. Despite the increased availability of public
ECG datasets, label scarcity remains a central challenge in the field.
Self-supervised learning represents a promising way to alleviate this issue. In
this work, we put forward the first comprehensive assessment of self-supervised
representation learning from clinical 12-lead ECG data. To this end, we adapt
state-of-the-art self-supervised methods based on instance discrimination and
latent forecasting to the ECG domain. In a first step, we learn contrastive
representations and evaluate their quality based on linear evaluation
performance on a recently established, comprehensive, clinical ECG
classification task. In a second step, we analyze the impact of self-supervised
pretraining on finetuned ECG classifiers as compared to purely supervised
performance. For the best-performing method, an adaptation of contrastive
predictive coding, we find a linear evaluation performance only 0.5% below
supervised performance. For the finetuned models, we find improvements in
downstream performance of roughly 1% compared to supervised performance, label
efficiency, as well as robustness against physiological noise. This work
clearly establishes the feasibility of extracting discriminative
representations from ECG data via self-supervised learning and the numerous
advantages when finetuning such representations on downstream tasks as compared
to purely supervised training. As first comprehensive assessment of its kind in
the ECG domain carried out exclusively on publicly available datasets, we hope
to establish a first step towards reproducible progress in the rapidly evolving
field of representation learning for biosignals.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Mehari_T/0/1/0/all/0/1"&gt;Temesgen Mehari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Strodthoff_N/0/1/0/all/0/1"&gt;Nils Strodthoff&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kendall transformation: a robust representation of continuous data for information theory. (arXiv:2006.15991v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2006.15991</id>
        <link href="http://arxiv.org/abs/2006.15991"/>
        <updated>2022-01-06T00:40:22.687Z</updated>
        <summary type="html"><![CDATA[Kendall transformation is a conversion of an ordered feature into a vector of
pairwise order relations between individual values. This way, it preserves
ranking of observations and represents it in a categorical form.

Such transformation allows for generalisation of methods requiring strictly
categorical input, especially in the limit of small number of observations,
when discretisation becomes problematic. In particular, many approaches of
information theory can be directly applied to Kendall-transformed continuous
data without relying on differential entropy or any additional parameters.
Moreover, by filtering information to this contained in ranking, Kendall
transformation leads to a better robustness at a reasonable cost of dropping
sophisticated interactions which are anyhow unlikely to be correctly estimated.

In bivariate analysis, Kendall transformation can be related to popular
non-parametric methods, showing the soundness of the approach. The paper also
demonstrates its efficiency in multivariate problems, as well as provides an
example analysis of a real-world data.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kursa_M/0/1/0/all/0/1"&gt;Miron Bartosz Kursa&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deriving discriminative classifiers from generative models. (arXiv:2201.00844v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2201.00844</id>
        <link href="http://arxiv.org/abs/2201.00844"/>
        <updated>2022-01-06T00:40:22.667Z</updated>
        <summary type="html"><![CDATA[We deal with Bayesian generative and discriminative classifiers. Given a
model distribution $p(x, y)$, with the observation $y$ and the target $x$, one
computes generative classifiers by firstly considering $p(x, y)$ and then using
the Bayes rule to calculate $p(x | y)$. A discriminative model is directly
given by $p(x | y)$, which is used to compute discriminative classifiers.
However, recent works showed that the Bayesian Maximum Posterior classifier
defined from the Naive Bayes (NB) or Hidden Markov Chain (HMC), both generative
models, can also match the discriminative classifier definition. Thus, there
are situations in which dividing classifiers into "generative" and
"discriminative" is somewhat misleading. Indeed, such a distinction is rather
related to the way of computing classifiers, not to the classifiers themselves.
We present a general theoretical result specifying how a generative classifier
induced from a generative model can also be computed in a discriminative way
from the same model. Examples of NB and HMC are found again as particular
cases, and we apply the general result to two original extensions of NB, and
two extensions of HMC, one of which being original. Finally, we shortly
illustrate the interest of the new discriminative way of computing classifiers
in the Natural Language Processing (NLP) framework.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Azeraf_E/0/1/0/all/0/1"&gt;Elie Azeraf&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Monfrini_E/0/1/0/all/0/1"&gt;Emmanuel Monfrini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Pieczynski_W/0/1/0/all/0/1"&gt;Wojciech Pieczynski&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open Access Dataset for Electromyography based Multi-code Biometric Authentication. (arXiv:2201.01051v1 [cs.CR])]]></title>
        <id>http://arxiv.org/abs/2201.01051</id>
        <link href="http://arxiv.org/abs/2201.01051"/>
        <updated>2022-01-06T00:40:22.633Z</updated>
        <summary type="html"><![CDATA[Recently, surface electromyogram (EMG) has been proposed as a novel biometric
trait for addressing some key limitations of current biometrics, such as
spoofing and liveness. The EMG signals possess a unique characteristic: they
are inherently different for individuals (biometrics), and they can be
customized to realize multi-length codes or passwords (for example, by
performing different gestures). However, current EMG-based biometric research
has two critical limitations: 1) a small subject pool, compared to other more
established biometric traits, and 2) limited to single-session or single-day
data sets. In this study, forearm and wrist EMG data were collected from 43
participants over three different days with long separation while they
performed static hand and wrist gestures. The multi-day biometric
authentication resulted in a median EER of 0.017 for the forearm setup and
0.025 for the wrist setup, comparable to well-established biometric traits
suggesting consistent performance over multiple days. The presented
large-sample multi-day data set and findings could facilitate further research
on EMG-based biometrics and other gesture recognition-based applications.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pradhan_A/0/1/0/all/0/1"&gt;Ashirbad Pradhan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1"&gt;Jiayuan He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1"&gt;Ning Jiang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Estimation of Statistical Divergences. (arXiv:2110.03652v2 [math.ST] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.03652</id>
        <link href="http://arxiv.org/abs/2110.03652"/>
        <updated>2022-01-06T00:40:22.626Z</updated>
        <summary type="html"><![CDATA[Statistical divergences (SDs), which quantify the dissimilarity between
probability distributions, are a basic constituent of statistical inference and
machine learning. A modern method for estimating those divergences relies on
parametrizing an empirical variational form by a neural network (NN) and
optimizing over parameter space. Such neural estimators are abundantly used in
practice, but corresponding performance guarantees are partial and call for
further exploration. In particular, there is a fundamental tradeoff between the
two sources of error involved: approximation and empirical estimation. While
the former needs the NN class to be rich and expressive, the latter relies on
controlling complexity. We explore this tradeoff for an estimator based on a
shallow NN by means of non-asymptotic error bounds, focusing on four popular
$\mathsf{f}$-divergences -- Kullback-Leibler, chi-squared, squared Hellinger,
and total variation. Our analysis relies on non-asymptotic function
approximation theorems and tools from empirical process theory. The bounds
reveal the tension between the NN size and the number of samples, and enable to
characterize scaling rates thereof that ensure consistency. For compactly
supported distributions, we further show that neural estimators of the first
three divergences above with appropriate NN growth-rate are near minimax
rate-optimal, achieving the parametric rate up to logarithmic factors.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Sreekumar_S/0/1/0/all/0/1"&gt;Sreejith Sreekumar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Goldfeld_Z/0/1/0/all/0/1"&gt;Ziv Goldfeld&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal design of the Barker proposal and other locally-balanced Metropolis-Hastings algorithms. (arXiv:2201.01123v1 [stat.CO])]]></title>
        <id>http://arxiv.org/abs/2201.01123</id>
        <link href="http://arxiv.org/abs/2201.01123"/>
        <updated>2022-01-06T00:40:22.612Z</updated>
        <summary type="html"><![CDATA[We study the class of first-order locally-balanced Metropolis--Hastings
algorithms introduced in Livingstone & Zanella (2021). To choose a specific
algorithm within the class the user must select a balancing function
$g:\mathbb{R} \to \mathbb{R}$ satisfying $g(t) = tg(1/t)$, and a noise
distribution for the proposal increment. Popular choices within the class are
the Metropolis-adjusted Langevin algorithm and the recently introduced Barker
proposal. We first establish a universal limiting optimal acceptance rate of
57% and scaling of $n^{-1/3}$ as the dimension $n$ tends to infinity among all
members of the class under mild smoothness assumptions on $g$ and when the
target distribution for the algorithm is of the product form. In particular we
obtain an explicit expression for the asymptotic efficiency of an arbitrary
algorithm in the class, as measured by expected squared jumping distance. We
then consider how to optimise this expression under various constraints. We
derive an optimal choice of noise distribution for the Barker proposal, optimal
choice of balancing function under a Gaussian noise distribution, and optimal
choice of first-order locally-balanced algorithm among the entire class, which
turns out to depend on the specific target distribution. Numerical simulations
confirm our theoretical findings and in particular show that a bi-modal choice
of noise distribution in the Barker proposal gives rise to a practical
algorithm that is consistently more efficient than the original Gaussian
version.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Vogrinc_J/0/1/0/all/0/1"&gt;Jure Vogrinc&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Livingstone_S/0/1/0/all/0/1"&gt;Samuel Livingstone&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zanella_G/0/1/0/all/0/1"&gt;Giacomo Zanella&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Play No-Press Diplomacy with Best Response Policy Iteration. (arXiv:2006.04635v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2006.04635</id>
        <link href="http://arxiv.org/abs/2006.04635"/>
        <updated>2022-01-06T00:40:22.594Z</updated>
        <summary type="html"><![CDATA[Recent advances in deep reinforcement learning (RL) have led to considerable
progress in many 2-player zero-sum games, such as Go, Poker and Starcraft. The
purely adversarial nature of such games allows for conceptually simple and
principled application of RL methods. However real-world settings are
many-agent, and agent interactions are complex mixtures of common-interest and
competitive aspects. We consider Diplomacy, a 7-player board game designed to
accentuate dilemmas resulting from many-agent interactions. It also features a
large combinatorial action space and simultaneous moves, which are challenging
for RL algorithms. We propose a simple yet effective approximate best response
operator, designed to handle large combinatorial action spaces and simultaneous
moves. We also introduce a family of policy iteration methods that approximate
fictitious play. With these methods, we successfully apply RL to Diplomacy: we
show that our agents convincingly outperform the previous state-of-the-art, and
game theoretic equilibrium analysis shows that the new process yields
consistent improvements.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Anthony_T/0/1/0/all/0/1"&gt;Thomas Anthony&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Eccles_T/0/1/0/all/0/1"&gt;Tom Eccles&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tacchetti_A/0/1/0/all/0/1"&gt;Andrea Tacchetti&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kramar_J/0/1/0/all/0/1"&gt;J&amp;#xe1;nos Kram&amp;#xe1;r&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gemp_I/0/1/0/all/0/1"&gt;Ian Gemp&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hudson_T/0/1/0/all/0/1"&gt;Thomas C. Hudson&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Porcel_N/0/1/0/all/0/1"&gt;Nicolas Porcel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lanctot_M/0/1/0/all/0/1"&gt;Marc Lanctot&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Perolat_J/0/1/0/all/0/1"&gt;Julien P&amp;#xe9;rolat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Everett_R/0/1/0/all/0/1"&gt;Richard Everett&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Werpachowski_R/0/1/0/all/0/1"&gt;Roman Werpachowski&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1"&gt;Satinder Singh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Graepel_T/0/1/0/all/0/1"&gt;Thore Graepel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bachrach_Y/0/1/0/all/0/1"&gt;Yoram Bachrach&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Descriptive vs. inferential community detection: pitfalls, myths and half-truths. (arXiv:2112.00183v3 [physics.soc-ph] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.00183</id>
        <link href="http://arxiv.org/abs/2112.00183"/>
        <updated>2022-01-06T00:40:22.585Z</updated>
        <summary type="html"><![CDATA[Community detection is one of the most important methodological fields of
network science, and one which has attracted a significant amount of attention
over the past decades. This area deals with the automated division of a network
into fundamental building blocks, with the objective of providing a summary of
its large-scale structure. Despite its importance and widespread adoption,
there is a noticeable gap between what is considered the state-of-the-art and
the methods that are actually used in practice in a variety of fields. Here we
attempt to address this discrepancy by dividing existing methods according to
whether they have a "descriptive" or an "inferential" goal. While descriptive
methods find patterns in networks based on intuitive notions of community
structure, inferential methods articulate a precise generative model, and
attempt to fit it to data. In this way, they are able to provide insights into
the mechanisms of network formation, and separate structure from randomness in
a manner supported by statistical evidence. We review how employing descriptive
methods with inferential aims is riddled with pitfalls and misleading answers,
and thus should be in general avoided. We argue that inferential methods are
more typically aligned with clearer scientific questions, yield more robust
results, and should be in many cases preferred. We attempt to dispel some myths
and half-truths often believed when community detection is employed in
practice, in an effort to improve both the use of such methods as well as the
interpretation of their results.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Peixoto_T/0/1/0/all/0/1"&gt;Tiago P. Peixoto&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the effectiveness of adversarial training against common corruptions. (arXiv:2103.02325v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.02325</id>
        <link href="http://arxiv.org/abs/2103.02325"/>
        <updated>2022-01-06T00:40:22.575Z</updated>
        <summary type="html"><![CDATA[The literature on robustness towards common corruptions shows no consensus on
whether adversarial training can improve the performance in this setting.
First, we show that, when used with an appropriately selected perturbation
radius, $\ell_p$ adversarial training can serve as a strong baseline against
common corruptions improving both accuracy and calibration. Then we explain why
adversarial training performs better than data augmentation with simple
Gaussian noise which has been observed to be a meaningful baseline on common
corruptions. Related to this, we identify the $\sigma$-overfitting phenomenon
when Gaussian augmentation overfits to a particular standard deviation used for
training which has a significant detrimental effect on common corruption
accuracy. We discuss how to alleviate this problem and then how to further
enhance $\ell_p$ adversarial training by introducing an efficient relaxation of
adversarial training with learned perceptual image patch similarity as the
distance metric. Through experiments on CIFAR-10 and ImageNet-100, we show that
our approach does not only improve the $\ell_p$ adversarial training baseline
but also has cumulative gains with data augmentation methods such as AugMix,
DeepAugment, ANT, and SIN, leading to state-of-the-art performance on common
corruptions.

The code of our experiments is publicly available at
https://github.com/tml-epfl/adv-training-corruptions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kireev_K/0/1/0/all/0/1"&gt;Klim Kireev&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Andriushchenko_M/0/1/0/all/0/1"&gt;Maksym Andriushchenko&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1"&gt;Nicolas Flammarion&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Biased Hypothesis Formation From Projection Pursuit. (arXiv:2201.00889v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00889</id>
        <link href="http://arxiv.org/abs/2201.00889"/>
        <updated>2022-01-06T00:40:22.564Z</updated>
        <summary type="html"><![CDATA[The effect of bias on hypothesis formation is characterized for an automated
data-driven projection pursuit neural network to extract and select features
for binary classification of data streams. This intelligent exploratory process
partitions a complete vector state space into disjoint subspaces to create
working hypotheses quantified by similarities and differences observed between
two groups of labeled data streams. Data streams are typically time sequenced,
and may exhibit complex spatio-temporal patterns. For example, given atomic
trajectories from molecular dynamics simulation, the machine's task is to
quantify dynamical mechanisms that promote function by comparing protein
mutants, some known to function while others are nonfunctional. Utilizing
synthetic two-dimensional molecules that mimic the dynamics of functional and
nonfunctional proteins, biases are identified and controlled in both the
machine learning model and selected training data under different contexts. The
refinement of a working hypothesis converges to a statistically robust
multivariate perception of the data based on a context-dependent perspective.
Including diverse perspectives during data exploration enhances
interpretability of the multivariate characterization of similarities and
differences.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Patterson_J/0/1/0/all/0/1"&gt;John Patterson&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Avery_C/0/1/0/all/0/1"&gt;Chris Avery&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grear_T/0/1/0/all/0/1"&gt;Tyler Grear&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1"&gt;Donald J. Jacobs&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control. (arXiv:2106.02019v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.02019</id>
        <link href="http://arxiv.org/abs/2106.02019"/>
        <updated>2022-01-06T00:40:22.478Z</updated>
        <summary type="html"><![CDATA[We propose Neural Actor (NA), a new method for high-quality synthesis of
humans from arbitrary viewpoints and under arbitrary controllable poses. Our
method is built upon recent neural scene representation and rendering works
which learn representations of geometry and appearance from only 2D images.
While existing works demonstrated compelling rendering of static scenes and
playback of dynamic scenes, photo-realistic reconstruction and rendering of
humans with neural implicit methods, in particular under user-controlled novel
poses, is still difficult. To address this problem, we utilize a coarse body
model as the proxy to unwarp the surrounding 3D space into a canonical pose. A
neural radiance field learns pose-dependent geometric deformations and pose-
and view-dependent appearance effects in the canonical space from multi-view
video input. To synthesize novel views of high fidelity dynamic geometry and
appearance, we leverage 2D texture maps defined on the body model as latent
variables for predicting residual deformations and the dynamic appearance.
Experiments demonstrate that our method achieves better quality than the
state-of-the-arts on playback as well as novel pose synthesis, and can even
generalize well to new poses that starkly differ from the training poses.
Furthermore, our method also supports body shape control of the synthesized
results.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1"&gt;Lingjie Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Habermann_M/0/1/0/all/0/1"&gt;Marc Habermann&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rudnev_V/0/1/0/all/0/1"&gt;Viktor Rudnev&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sarkar_K/0/1/0/all/0/1"&gt;Kripasindhu Sarkar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1"&gt;Jiatao Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1"&gt;Christian Theobalt&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Monitoring and Anomaly Detection Actor-Critic Based Controlled Sensing. (arXiv:2201.00879v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00879</id>
        <link href="http://arxiv.org/abs/2201.00879"/>
        <updated>2022-01-06T00:40:21.511Z</updated>
        <summary type="html"><![CDATA[We address the problem of monitoring a set of binary stochastic processes and
generating an alert when the number of anomalies among them exceeds a
threshold. For this, the decision-maker selects and probes a subset of the
processes to obtain noisy estimates of their states (normal or anomalous).
Based on the received observations, the decisionmaker first determines whether
to declare that the number of anomalies has exceeded the threshold or to
continue taking observations. When the decision is to continue, it then decides
whether to collect observations at the next time instant or defer it to a later
time. If it chooses to collect observations, it further determines the subset
of processes to be probed. To devise this three-step sequential decision-making
process, we use a Bayesian formulation wherein we learn the posterior
probability on the states of the processes. Using the posterior probability, we
construct a Markov decision process and solve it using deep actor-critic
reinforcement learning. Via numerical experiments, we demonstrate the superior
performance of our algorithm compared to the traditional model-based
algorithms.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Joseph_G/0/1/0/all/0/1"&gt;Geethu Joseph&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gursoy_M/0/1/0/all/0/1"&gt;M. Cenk Gursoy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Varshney_P/0/1/0/all/0/1"&gt;Pramod K. Varshney&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variance-Aware Off-Policy Evaluation with Linear Function Approximation. (arXiv:2106.11960v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.11960</id>
        <link href="http://arxiv.org/abs/2106.11960"/>
        <updated>2022-01-06T00:40:21.505Z</updated>
        <summary type="html"><![CDATA[We study the off-policy evaluation (OPE) problem in reinforcement learning
with linear function approximation, which aims to estimate the value function
of a target policy based on the offline data collected by a behavior policy. We
propose to incorporate the variance information of the value function to
improve the sample efficiency of OPE. More specifically, for time-inhomogeneous
episodic linear Markov decision processes (MDPs), we propose an algorithm,
VA-OPE, which uses the estimated variance of the value function to reweight the
Bellman residual in Fitted Q-Iteration. We show that our algorithm achieves a
tighter error bound than the best-known result. We also provide a fine-grained
characterization of the distribution shift between the behavior policy and the
target policy. Extensive numerical experiments corroborate our theory.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Min_Y/0/1/0/all/0/1"&gt;Yifei Min&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1"&gt;Tianhao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Piecewise-Constant Delay Differential Equations. (arXiv:2201.00960v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00960</id>
        <link href="http://arxiv.org/abs/2201.00960"/>
        <updated>2022-01-06T00:40:21.498Z</updated>
        <summary type="html"><![CDATA[Continuous-depth neural networks, such as the Neural Ordinary Differential
Equations (ODEs), have aroused a great deal of interest from the communities of
machine learning and data science in recent years, which bridge the connection
between deep neural networks and dynamical systems. In this article, we
introduce a new sort of continuous-depth neural network, called the Neural
Piecewise-Constant Delay Differential Equations (PCDDEs). Here, unlike the
recently proposed framework of the Neural Delay Differential Equations (DDEs),
we transform the single delay into the piecewise-constant delay(s). The Neural
PCDDEs with such a transformation, on one hand, inherit the strength of
universal approximating capability in Neural DDEs. On the other hand, the
Neural PCDDEs, leveraging the contributions of the information from the
multiple previous time steps, further promote the modeling capability without
augmenting the network dimension. With such a promotion, we show that the
Neural PCDDEs do outperform the several existing continuous-depth neural
frameworks on the one-dimensional piecewise-constant delay population dynamics
and real-world datasets, including MNIST, CIFAR10, and SVHN.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1"&gt;Qunxi Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1"&gt;Yifei Shen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1"&gt;Dongsheng Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1"&gt;Wei Lin&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evolutionary Multitasking AUC Optimization. (arXiv:2201.01145v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01145</id>
        <link href="http://arxiv.org/abs/2201.01145"/>
        <updated>2022-01-06T00:40:21.441Z</updated>
        <summary type="html"><![CDATA[Learning to optimize the area under the receiver operating characteristics
curve (AUC) performance for imbalanced data has attracted much attention in
recent years. Although there have been several methods of AUC optimization,
scaling up AUC optimization is still an open issue due to its pairwise learning
style. Maximizing AUC in the large-scale dataset can be considered as a
non-convex and expensive problem. Inspired by the characteristic of pairwise
learning, the cheap AUC optimization task with a small-scale dataset sampled
from the large-scale dataset is constructed to promote the AUC accuracy of the
original, large-scale, and expensive AUC optimization task. This paper develops
an evolutionary multitasking framework (termed EMTAUC) to make full use of
information among the constructed cheap and expensive tasks to obtain higher
performance. In EMTAUC, one mission is to optimize AUC from the sampled
dataset, and the other is to maximize AUC from the original dataset. Moreover,
due to the cheap task containing limited knowledge, a strategy for dynamically
adjusting the data structure of inexpensive tasks is proposed to introduce more
knowledge into the multitasking AUC optimization environment. The performance
of the proposed method is evaluated on a series of binary classification
datasets. The experimental results demonstrate that EMTAUC is highly
competitive to single task methods and online methods. Supplementary materials
and source code implementation of EMTAUC can be accessed at
https://github.com/xiaofangxd/EMTAUC.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1"&gt;Chao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1"&gt;Kai Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"&gt;Jing Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Supervised Homogeneity Fusion: a Combinatorial Approach. (arXiv:2201.01036v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2201.01036</id>
        <link href="http://arxiv.org/abs/2201.01036"/>
        <updated>2022-01-06T00:40:21.402Z</updated>
        <summary type="html"><![CDATA[Fusing regression coefficients into homogenous groups can unveil those
coefficients that share a common value within each group. Such groupwise
homogeneity reduces the intrinsic dimension of the parameter space and
unleashes sharper statistical accuracy. We propose and investigate a new
combinatorial grouping approach called $L_0$-Fusion that is amenable to mixed
integer optimization (MIO). On the statistical aspect, we identify a
fundamental quantity called grouping sensitivity that underpins the difficulty
of recovering the true groups. We show that $L_0$-Fusion achieves grouping
consistency under the weakest possible requirement of the grouping sensitivity:
if this requirement is violated, then the minimax risk of group
misspecification will fail to converge to zero. Moreover, we show that in the
high-dimensional regime, one can apply $L_0$-Fusion coupled with a sure
screening set of features without any essential loss of statistical efficiency,
while reducing the computational cost substantially. On the algorithmic aspect,
we provide a MIO formulation for $L_0$-Fusion along with a warm start strategy.
Simulation and real data analysis demonstrate that $L_0$-Fusion exhibits
superiority over its competitors in terms of grouping accuracy.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Wang_W/0/1/0/all/0/1"&gt;Wen Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Wu_S/0/1/0/all/0/1"&gt;Shihao Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhu_Z/0/1/0/all/0/1"&gt;Ziwei Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhou_L/0/1/0/all/0/1"&gt;Ling Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Song_P/0/1/0/all/0/1"&gt;Peter X.-K. Song&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Myerson Auction for Truthful and Energy-Efficient Autonomous Aerial Data Delivery. (arXiv:2201.01170v1 [cs.GT])]]></title>
        <id>http://arxiv.org/abs/2201.01170</id>
        <link href="http://arxiv.org/abs/2201.01170"/>
        <updated>2022-01-06T00:40:21.361Z</updated>
        <summary type="html"><![CDATA[A successful deployment of drones provides an ideal solution for surveillance
systems. Using drones for surveillance can provide access to areas that may be
difficult or impossible to reach by humans or in-land vehicles gathering images
or video recordings of a specific target in their coverage. Therefore, we
introduces a data delivery drone to transfer collected surveillance data in
harsh communication conditions. This paper proposes a Myerson auction-based
asynchronous data delivery in an aerial distributed data platform in
surveillance systems taking battery limitation and long flight constraints into
account. In this paper, multiple delivery drones compete to offer data transfer
to a single fixed-location surveillance drone. Our proposed Myerson
auction-based algorithm, which uses the truthful second-price auction (SPA) as
a baseline, is to maximize the seller's revenue while meeting several desirable
properties, i.e., individual rationality and incentive compatibility while
pursuing truthful operations. On top of these SPA-based operations, a deep
learning-based framework is additionally designed for delivery performance
improvements.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1"&gt;Haemin Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1"&gt;Sean Kwon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1"&gt;Soyi Jung&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1"&gt;Joongheon Kim&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An unfeasability view of neural network learning. (arXiv:2201.00945v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00945</id>
        <link href="http://arxiv.org/abs/2201.00945"/>
        <updated>2022-01-06T00:40:21.355Z</updated>
        <summary type="html"><![CDATA[We define the notion of a continuously differentiable perfect learning
algorithm for multilayer neural network architectures and show that such
algorithms don't exist provided that the length of the data set exceeds the
number of involved parameters and the activation functions are logistic, tanh
or sin.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Heintz_J/0/1/0/all/0/1"&gt;Joos Heintz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ocar_H/0/1/0/all/0/1"&gt;Hvara Ocar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pardo_L/0/1/0/all/0/1"&gt;Luis Miguel Pardo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Paredes_A/0/1/0/all/0/1"&gt;Andres Rojas Paredes&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Segura_E/0/1/0/all/0/1"&gt;Enrique Carlos Segura&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign Overfitting. (arXiv:2106.09276v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.09276</id>
        <link href="http://arxiv.org/abs/2106.09276"/>
        <updated>2022-01-06T00:40:21.311Z</updated>
        <summary type="html"><![CDATA[We consider interpolation learning in high-dimensional linear regression with
Gaussian data, and prove a generic uniform convergence guarantee on the
generalization error of interpolators in an arbitrary hypothesis class in terms
of the class's Gaussian width. Applying the generic bound to Euclidean norm
balls recovers the consistency result of Bartlett et al. (2020) for
minimum-norm interpolators, and confirms a prediction of Zhou et al. (2020) for
near-minimal-norm interpolators in the special case of Gaussian data. We
demonstrate the generality of the bound by applying it to the simplex,
obtaining a novel consistency result for minimum l1-norm interpolators (basis
pursuit). Our results show how norm-based generalization bounds can explain and
be used to analyze benign overfitting, at least in some settings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Koehler_F/0/1/0/all/0/1"&gt;Frederic Koehler&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhou_L/0/1/0/all/0/1"&gt;Lijia Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1"&gt;Danica J. Sutherland&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Srebro_N/0/1/0/all/0/1"&gt;Nathan Srebro&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep neural networks for smooth approximation of physics with higher order and continuity B-spline base functions. (arXiv:2201.00904v1 [math.NA])]]></title>
        <id>http://arxiv.org/abs/2201.00904</id>
        <link href="http://arxiv.org/abs/2201.00904"/>
        <updated>2022-01-06T00:40:21.241Z</updated>
        <summary type="html"><![CDATA[This paper deals with the following important research question.
Traditionally, the neural network employs non-linear activation functions
concatenated with linear operators to approximate a given physical phenomenon.
They "fill the space" with the concatenations of the activation functions and
linear operators and adjust their coefficients to approximate the physical
phenomena. We claim that it is better to "fill the space" with linear
combinations of smooth higher-order B-splines base functions as employed by
isogeometric analysis and utilize the neural networks to adjust the
coefficients of linear combinations. In other words, the possibilities of using
neural networks for approximating the B-spline base functions' coefficients and
by approximating the solution directly are evaluated. Solving differential
equations with neural networks has been proposed by Maziar Raissi et al. in
2017 by introducing Physics-informed Neural Networks (PINN), which naturally
encode underlying physical laws as prior information. Approximation of
coefficients using a function as an input leverages the well-known capability
of neural networks being universal function approximators. In essence, in the
PINN approach the network approximates the value of the given field at a given
point. We present an alternative approach, where the physcial quantity is
approximated as a linear combination of smooth B-spline basis functions, and
the neural network approximates the coefficients of B-splines. This research
compares results from the DNN approximating the coefficients of the linear
combination of B-spline basis functions, with the DNN approximating the
solution directly. We show that our approach is cheaper and more accurate when
approximating smooth physical fields.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Doleglo_K/0/1/0/all/0/1"&gt;Kamil Doleg&amp;#x142;o&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Paszynska_A/0/1/0/all/0/1"&gt;Anna Paszy&amp;#x144;ska&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Paszynski_M/0/1/0/all/0/1"&gt;Maciej Paszy&amp;#x144;ski&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Demkowicz_L/0/1/0/all/0/1"&gt;Leszek Demkowicz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convolutional Normalization: Improving Deep Convolutional Network Robustness and Training. (arXiv:2103.00673v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.00673</id>
        <link href="http://arxiv.org/abs/2103.00673"/>
        <updated>2022-01-06T00:40:21.219Z</updated>
        <summary type="html"><![CDATA[Normalization techniques have become a basic component in modern
convolutional neural networks (ConvNets). In particular, many recent works
demonstrate that promoting the orthogonality of the weights helps train deep
models and improve robustness. For ConvNets, most existing methods are based on
penalizing or normalizing weight matrices derived from concatenating or
flattening the convolutional kernels. These methods often destroy or ignore the
benign convolutional structure of the kernels; therefore, they are often
expensive or impractical for deep ConvNets. In contrast, we introduce a simple
and efficient "Convolutional Normalization" (ConvNorm) method that can fully
exploit the convolutional structure in the Fourier domain and serve as a simple
plug-and-play module to be conveniently incorporated into any ConvNets. Our
method is inspired by recent work on preconditioning methods for convolutional
sparse coding and can effectively promote each layer's channel-wise isometry.
Furthermore, we show that our ConvNorm can reduce the layerwise spectral norm
of the weight matrices and hence improve the Lipschitzness of the network,
leading to easier training and improved robustness for deep ConvNets. Applied
to classification under noise corruptions and generative adversarial network
(GAN), we show that the ConvNorm improves the robustness of common ConvNets
such as ResNet and the performance of GAN. We verify our findings via numerical
experiments on CIFAR and ImageNet.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1"&gt;Sheng Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"&gt;Xiao Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1"&gt;Yuexiang Zhai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1"&gt;Chong You&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1"&gt;Zhihui Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fernandez_Granda_C/0/1/0/all/0/1"&gt;Carlos Fernandez-Granda&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qu_Q/0/1/0/all/0/1"&gt;Qing Qu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[APReL: A Library for Active Preference-based Reward Learning Algorithms. (arXiv:2108.07259v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2108.07259</id>
        <link href="http://arxiv.org/abs/2108.07259"/>
        <updated>2022-01-06T00:40:21.160Z</updated>
        <summary type="html"><![CDATA[Reward learning is a fundamental problem in human-robot interaction to have
robots that operate in alignment with what their human user wants. Many
preference-based learning algorithms and active querying techniques have been
proposed as a solution to this problem. In this paper, we present APReL, a
library for active preference-based reward learning algorithms, which enable
researchers and practitioners to experiment with the existing techniques and
easily develop their own algorithms for various modules of the problem. APReL
is available at https://github.com/Stanford-ILIAD/APReL.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Biyik_E/0/1/0/all/0/1"&gt;Erdem B&amp;#x131;y&amp;#x131;k&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Talati_A/0/1/0/all/0/1"&gt;Aditi Talati&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1"&gt;Dorsa Sadigh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deriving discriminative classifiers from generative models. (arXiv:2201.00844v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2201.00844</id>
        <link href="http://arxiv.org/abs/2201.00844"/>
        <updated>2022-01-06T00:40:21.119Z</updated>
        <summary type="html"><![CDATA[We deal with Bayesian generative and discriminative classifiers. Given a
model distribution $p(x, y)$, with the observation $y$ and the target $x$, one
computes generative classifiers by firstly considering $p(x, y)$ and then using
the Bayes rule to calculate $p(x | y)$. A discriminative model is directly
given by $p(x | y)$, which is used to compute discriminative classifiers.
However, recent works showed that the Bayesian Maximum Posterior classifier
defined from the Naive Bayes (NB) or Hidden Markov Chain (HMC), both generative
models, can also match the discriminative classifier definition. Thus, there
are situations in which dividing classifiers into "generative" and
"discriminative" is somewhat misleading. Indeed, such a distinction is rather
related to the way of computing classifiers, not to the classifiers themselves.
We present a general theoretical result specifying how a generative classifier
induced from a generative model can also be computed in a discriminative way
from the same model. Examples of NB and HMC are found again as particular
cases, and we apply the general result to two original extensions of NB, and
two extensions of HMC, one of which being original. Finally, we shortly
illustrate the interest of the new discriminative way of computing classifiers
in the Natural Language Processing (NLP) framework.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Azeraf_E/0/1/0/all/0/1"&gt;Elie Azeraf&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Monfrini_E/0/1/0/all/0/1"&gt;Emmanuel Monfrini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Pieczynski_W/0/1/0/all/0/1"&gt;Wojciech Pieczynski&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Low dosage 3D volume fluorescence microscopy imaging using compressive sensing. (arXiv:2201.00820v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2201.00820</id>
        <link href="http://arxiv.org/abs/2201.00820"/>
        <updated>2022-01-06T00:40:20.669Z</updated>
        <summary type="html"><![CDATA[Fluorescence microscopy has been a significant tool to observe long-term
imaging of embryos (in vivo) growth over time. However, cumulative exposure is
phototoxic to such sensitive live samples. While techniques like light-sheet
fluorescence microscopy (LSFM) allow for reduced exposure, it is not well
suited for deep imaging models. Other computational techniques are
computationally expensive and often lack restoration quality. To address this
challenge, one can use various low-dosage imaging techniques that are developed
to achieve the 3D volume reconstruction using a few slices in the axial
direction (z-axis); however, they often lack restoration quality. Also,
acquiring dense images (with small steps) in the axial direction is
computationally expensive. To address this challenge, we present a compressive
sensing (CS) based approach to fully reconstruct 3D volumes with the same
signal-to-noise ratio (SNR) with less than half of the excitation dosage. We
present the theory and experimentally validate the approach. To demonstrate our
technique, we capture a 3D volume of the RFP labeled neurons in the zebrafish
embryo spinal cord (30um thickness) with the axial sampling of 0.1um using a
confocal microscope. From the results, we observe the CS-based approach
achieves accurate 3D volume reconstruction from less than 20% of the entire
stack optical sections. The developed CS-based methodology in this work can be
easily applied to other deep imaging modalities such as two-photon and
light-sheet microscopy, where reducing sample photo-toxicity is a critical
challenge.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Mannam_V/0/1/0/all/0/1"&gt;Varun Mannam&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Brandt_J/0/1/0/all/0/1"&gt;Jacob Brandt&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Smith_C/0/1/0/all/0/1"&gt;Cody J. Smith&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Howard_S/0/1/0/all/0/1"&gt;Scott Howard&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generating synthetic mobility data for a realistic population with RNNs to improve utility and privacy. (arXiv:2201.01139v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.01139</id>
        <link href="http://arxiv.org/abs/2201.01139"/>
        <updated>2022-01-06T00:40:20.619Z</updated>
        <summary type="html"><![CDATA[Location data collected from mobile devices represent mobility behaviors at
individual and societal levels. These data have important applications ranging
from transportation planning to epidemic modeling. However, issues must be
overcome to best serve these use cases: The data often represent a limited
sample of the population and use of the data jeopardizes privacy.

To address these issues, we present and evaluate a system for generating
synthetic mobility data using a deep recurrent neural network (RNN) which is
trained on real location data. The system takes a population distribution as
input and generates mobility traces for a corresponding synthetic population.

Related generative approaches have not solved the challenges of capturing
both the patterns and variability in individuals' mobility behaviors over
longer time periods, while also balancing the generation of realistic data with
privacy. Our system leverages RNNs' ability to generate complex and novel
sequences while retaining patterns from training data. Also, the model
introduces randomness used to calibrate the variation between the synthetic and
real data at the individual level. This is to both capture variability in human
mobility, and protect user privacy.

Location based services (LBS) data from more than 22,700 mobile devices were
used in an experimental evaluation across utility and privacy metrics. We show
the generated mobility data retain the characteristics of the real data, while
varying from the real data at the individual level, and where this amount of
variation matches the variation within the real data.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Berke_A/0/1/0/all/0/1"&gt;Alex Berke&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Doorley_R/0/1/0/all/0/1"&gt;Ronan Doorley&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Larson_K/0/1/0/all/0/1"&gt;Kent Larson&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Moro_E/0/1/0/all/0/1"&gt;Esteban Moro&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] How to correctly use batch norm in pre-loaded architectures?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rx1c4c/d_how_to_correctly_use_batch_norm_in_preloaded/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rx1c4c/d_how_to_correctly_use_batch_norm_in_preloaded/"/>
        <updated>2022-01-06T00:27:33.000Z</updated>
        <summary type="html"><![CDATA[I have tried using a few pre-loaded architectures in Tensorflow including tf.keras.applications.efficientnet.EfficientNetB3
 and tf.keras.applications.MobileNetV3Large
 . I am working on medical images so I am not any pretrained ImageNet weights. I manage to reach a decent accuracy during the training epoch (eg 75%), but my validation accuracy doesn't cross random performance (eg 3%). Upon closer inspection I have identified the cause as being the batch normalization layers - If I run the evaluation batches w/ training=True
 on the BatchNorm layers, I am able to reproduce the training set accuracy. I have tried playing with the momentum parameter and changing it from its default value of .999 to .75 or even .5 but with no effect.
 My question is what may be causing this and how can I fix it? 
 On a larger note, do most people find that they can use pre-loaded architectures out-of-the-box or are there various parameters that they need to modify to get it to work properly?
    submitted by    /u/rsandler  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[One diagram, two completely different meanings]]></title>
        <id>https://www.johndcook.com/blog/?p=93749</id>
        <link href="https://www.johndcook.com/blog/2022/01/05/diagrams/"/>
        <updated>2022-01-05T23:12:51.000Z</updated>
        <summary type="html"><![CDATA[I was thumbing through a new book on causal inference, The Effect by Nick Huntington-Klein, and the following diagram caught my eye. Then it made my head hurt. It looks like a category theory diagram. Whats that doing in a book on causal inference? And if it is a category theory diagram, somethings wrong. Either []
One diagram, two completely different meanings first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Simulation environment to real life. Is the brain of RL still flexible enough to learn in real life env?]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rwzfef/simulation_environment_to_real_life_is_the_brain/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rwzfef/simulation_environment_to_real_life_is_the_brain/"/>
        <updated>2022-01-05T23:04:12.000Z</updated>
        <summary type="html"><![CDATA[I am planning to train TD3/DDPG using a simulation environment, and then continue the learning on to a real-life environment. I hope to reduce the timestep required to converge in real-life environment as it is costly and time-consuming.
 I am new to RL and I am curious as to: 'Would the algorithm still be flexible enough to continue learning?'
 I am slightly afraid about how the algorithm is going to think that it finished learning during the simulation environment, but then when it comes to real-life environment, it would not be flexible enough to learn on top of what it has already learned.
 Is this a trivial concern and is something that I should just let the algorithm learn by itself
    submitted by    /u/KoreaNuclear  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Teamwork Makes AVs Work: NVIDIA and Deloitte Deliver Turnkey Solutions for AV Developers]]></title>
        <id>https://blogs.nvidia.com/?p=54929</id>
        <link href="https://blogs.nvidia.com/blog/2022/01/05/deloitte-turnkey-solutions-av-developers/"/>
        <updated>2022-01-05T22:33:23.000Z</updated>
        <summary type="html"><![CDATA[Autonomous vehicles are born in the data center, which is why NVIDIA and Deloitte are delivering a strong foundation for developers to deploy robust self-driving technology. At CES this week, the companies detailed their collaboration, which is aimed at easing the biggest pain points in AV development. Deloitte, a leading global consulting firm, is pairing Read article >
The post Teamwork Makes AVs Work: NVIDIA and Deloitte Deliver Turnkey Solutions for AV Developers appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Norm Marks</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Legal use of functions in Pytorch or Tensorflow]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwxt8r/d_legal_use_of_functions_in_pytorch_or_tensorflow/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwxt8r/d_legal_use_of_functions_in_pytorch_or_tensorflow/"/>
        <updated>2022-01-05T21:55:02.000Z</updated>
        <summary type="html"><![CDATA[Does anybody know, is it legal to use Dropout or BatchNorm from Pytorch and Tensorflow due to Google's patents of these two functions? Did some library avoided patent infringement in its implementation of those functions?
    submitted by    /u/Nos_per  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Search engine for time series]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwxmw4/d_search_engine_for_time_series/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwxmw4/d_search_engine_for_time_series/"/>
        <updated>2022-01-05T21:46:11.000Z</updated>
        <summary type="html"><![CDATA[Hi,
 Last year I developed a passenger flow forecasting model. Passenger flows are heavily influenced by lockdown measures and the weather, so I wanted to incorporate features relating to that into my model. Doing so, I encountered various frustrations:
 
  
Data providers generally focus on a specific domain (e.g. covid, weather, ecommerce). Forecasts however can be influenced by data from many domains. Finding these providers, signing up, and reading documentation is very time consuming.
 It takes a lot of code just to get the data you want. For example, to get covid data for my province, I first had to call a /list endpoint, then retrieve the province identifier, and then loop over the data endpoint because the maximum range was 2 months. I think the core problem is that APIs (as the ]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Log Object]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rwxeof/log_object/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rwxeof/log_object/"/>
        <updated>2022-01-05T21:34:22.000Z</updated>
        <summary type="html"><![CDATA[Does anybody know what a log object is?
    submitted by    /u/Theverybest196  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Wix empowers customer care with AI capabilities using Amazon Transcribe]]></title>
        <id>adf2202cf0c47a7020764a4818e842b90c266b2b</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/how-wix-empowers-customer-care-with-ai-capabilities-using-amazon-transcribe/"/>
        <updated>2022-01-05T21:21:03.000Z</updated>
        <summary type="html"><![CDATA[With over 200 million users worldwide, Wix is a leading cloud-based development platform for building fully personalized, high-quality websites. Wix makes it easy for anyone to create a beautiful and professional web presence. When Wix started, it was easy to understand user sentiment and identify product improvement opportunities because the user base was small. Such []]]></summary>
        <author>
            <name>Assaf Elovic</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beginning Transition to Word Press]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087546</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087546"/>
        <updated>2022-01-05T20:52:39.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9984763058?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9984763058?profile=RESIZE_710x" width="720"></img></a></p>
<p><span style="font-size: 12pt;"><strong>Data Science Central is transitioning over to a new platform on January 10, 2022.</strong></span></p>
<p>In order to complete this migration, we will not be accepting any new submissions for publication after today, January 4th, 2022 at 4:00PM EST. Regular writers will be notified by email about logging into the</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] (A paper suggests) Most Time Series Anomaly Detection Papers are Wrong]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwwjal/d_a_paper_suggests_most_time_series_anomaly/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwwjal/d_a_paper_suggests_most_time_series_anomaly/"/>
        <updated>2022-01-05T20:49:37.000Z</updated>
        <summary type="html"><![CDATA[I just stumbled on this very nice paper [a], which will appear in AAAI-22. 
 The title seems much too modest, they show that a random algorithm can achieve apparent SOTA results in this domain. This seems to be a stunning result, that casts doubt on the contribution of dozens of papers. 
 For some reason, the area of Time Series Anomaly Detection seems to be the wild west of dubious papers and sloppy thinking. 
 As an aside, there is a benchmark set of 250 datasets here [b] that can be evaluated in a way that is free of the flaw.
 (my post title reflects my understanding of the paper, the authors may have a different preferred claim).
 [a] Towards a Rigorous Evaluation of Time-series Anomaly Detection https://arxiv.org/pdf/2109.05257.pdf
 [b] www.cs.ucr.edu/\~eamonn/time\_series\_data\_2018/UCR\_TimeSeriesAnomalyDatasets2021.zip
    submitted by    /u/eamonnkeogh  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Multi-agent Deep Reinforcement learning]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwwdh0/d_multiagent_deep_reinforcement_learning/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwwdh0/d_multiagent_deep_reinforcement_learning/"/>
        <updated>2022-01-05T20:40:20.000Z</updated>
        <summary type="html"><![CDATA[Hello!
 I hope youre doing well.
 I am working on a multi-agent system with MADDPG.At time t when an agent asks for a task, the other agents are busy (i.e., the busy agents are those that are still processing a task, they didnt finish it yet).So with this configuration, in the learning phase, I dont know how to mask the state of the busy agents when injecting the state and action pair to the critic network.
 Thank you.
    submitted by    /u/GuavaAgreeable208  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to approach conversation design with Amazon Lex: Building and testing (Part 3)]]></title>
        <id>5d353acdae2f243b026ada3aa895ab14d5fa6849</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/part-3-how-to-approach-conversation-design-with-amazon-lex-building-and-testing/"/>
        <updated>2022-01-05T20:21:59.000Z</updated>
        <summary type="html"><![CDATA[In parts one and two of our guide to conversation design with Amazon Lex, we discussed how to gather requirements for your conversational AI application and draft conversational flows. In this post, we help you bring all the pieces together. Youll learn how draft an interaction model to deliver natural conversational experiences, and how to []]]></summary>
        <author>
            <name>Nancy Clarke</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deploying ML models using SageMaker Serverless Inference (Preview)]]></title>
        <id>6215bf2285e9eb14f54e8dbcb388d71380ff4a0f</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/deploying-ml-models-using-sagemaker-serverless-inference-preview/"/>
        <updated>2022-01-05T20:03:57.000Z</updated>
        <summary type="html"><![CDATA[Amazon SageMaker Serverless Inference (Preview) was recently announced at re:Invent 2021 as a new model hosting feature that lets customers serve model predictions without having to explicitly provision compute instances or configure scaling policies to handle traffic variations. Serverless Inference is a new deployment capability that complements SageMakers existing options for deployment that include: SageMaker []]]></summary>
        <author>
            <name>Ram Vegiraju</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Build and visualize a real-time fraud prevention system using Amazon Fraud Detector]]></title>
        <id>e56da2bbbc39a5d38180fb8551687ecd6f8a781c</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/build-and-visualize-a-real-time-fraud-prevention-system-using-amazon-fraud-detector/"/>
        <updated>2022-01-05T19:58:41.000Z</updated>
        <summary type="html"><![CDATA[Were living in a world of everything-as-an-online-service. Service providers from almost every industry are in the race to feature the best user experience for their online channels like web portals and mobile applications. This raises a new challenge. How do we stop illegal and fraudulent behaviors without impacting typical legitimate interactions? This challenge is even []]]></summary>
        <author>
            <name>Ahmed Saef Zamzam</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] VQ-VAE: Are there heuristics for the number of embeddings and the embedding dimension?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwumjj/d_vqvae_are_there_heuristics_for_the_number_of/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwumjj/d_vqvae_are_there_heuristics_for_the_number_of/"/>
        <updated>2022-01-05T19:15:26.000Z</updated>
        <summary type="html"><![CDATA[Hi r/MachineLearning, does anyone with experience training VQ-VAEs know if there are good rules of thumb for the embedding size?
 E.g. given data of dimension N, use M embeddings of size P
 Thanks for any help!
    submitted by    /u/Natural_Profession_8  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Preparing for a Comprehensive Exam in ML]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwtpxv/d_preparing_for_a_comprehensive_exam_in_ml/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwtpxv/d_preparing_for_a_comprehensive_exam_in_ml/"/>
        <updated>2022-01-05T18:37:16.000Z</updated>
        <summary type="html"><![CDATA[I am a PhD student based in Canada and have a comprehensive exam coming up in 4-6 months. This is an exam I have been nervous about since I began my PhD. I am fairly confident about the actual proposal and answering questions related to my field. What concerns me more is fundamental/background question as ML and statistics is so broad. Plus, I am a little on the older side and my memory is a little poor.
 Have any students here taken a comprehensive exam? If so, what was your experience and how did you prepare? Is reading/making notes from a textbook a good idea? Or is preparing a list of topics and reading extensively about them a better option?
    submitted by    /u/ConfusedNoobie  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Features of features of samples to features of samples?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwsh49/d_features_of_features_of_samples_to_features_of/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwsh49/d_features_of_features_of_samples_to_features_of/"/>
        <updated>2022-01-05T17:44:08.000Z</updated>
        <summary type="html"><![CDATA[I have a mxn matrix, m observations and n variables. Along with that, I have another dataset which are the features of the variables, a nxp matrix.
 What could be a way to get an mxp matrix (without naive matrix multiplication)? I wish to relate the observations to the features of variable.
    submitted by    /u/l34df4rm3r  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] What is the format of full paper presentations in general ML conferences like IJCAI and AAAI?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwseha/d_what_is_the_format_of_full_paper_presentations/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwseha/d_what_is_the_format_of_full_paper_presentations/"/>
        <updated>2022-01-05T17:40:54.000Z</updated>
        <summary type="html"><![CDATA[Hi all,
 This is my first conference season, so I am curious about how do author of full papers (not extended abstracts or student-track, not invited speeches) present in conferences like ICML, AAAI and IJCAI?
 I mean, for instance: are presentations performed in a panel with 3-5 presenters using slides, or are they all presented as posters where authors stay available for a duration of time for the interested readers to show up and discuss? Or something else?
    submitted by    /u/briannaszvenska  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modzy launched on Product Hunt!]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rws0j7/modzy_launched_on_product_hunt/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rws0j7/modzy_launched_on_product_hunt/"/>
        <updated>2022-01-05T17:23:44.000Z</updated>
        <summary type="html"><![CDATA[The Modzy ModelOps platform accelerates the deployment, integration, and governance of production-ready AI. Supported by a growing community of data scientists and developers, Modzy solves the toughest problem with using AI at scale.
 Check out our post linked here, where you can sign up to test out our free version!
    submitted by    /u/modzykirsten  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Can you recommend funny papper like "Single Headed Attention RNN: Stop Thinking With Your Head"]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwrnk2/d_can_you_recommend_funny_papper_like_single/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwrnk2/d_can_you_recommend_funny_papper_like_single/"/>
        <updated>2022-01-05T17:07:29.000Z</updated>
        <summary type="html"><![CDATA[I really enjoyed reading this for a change to the textbook papers.
  
Abstract The leading approaches in language modeling are all obsessed with TV shows of my youth - namely Transformers and Sesame Street. Transformers this, Transformers that, and over here a bonfire worth of GPU-TPU-neuromorphic wafer scale sil- icon. We opt for the lazy path of old and proven techniques with a fancy crypto1 inspired acronym: the Single Headed Attention RNN (SHA-RNN). The authors lone goal is to show that the entire field might have evolved a different direction if we had instead been obsessed with a slightly differ- ent acronym and slightly different result. We take a previously strong language model based only on boring LSTMs and get it to within a stones throw of a stones throw of state-of-the-art byte level language model results on enwik8. This work has undergone no intensive hyperparameter optimization and lived entirely on a commodity desktop machine that made the authors small stu- dio apartment far too warm in the midst of a San Franciscan summer2 . The final results are achiev- able in plus or minus 24 hours on a single GPU as the author is impatient. The attention mechanism is also readily extended to large contexts with minimal computation. Take that Sesame Street.
  
https://arxiv.org/abs/1911.11423
    submitted by    /u/Puzzled-Bite-8467  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Finding General Equilibria in Many-Agent Economic Simulations Using Deep Reinforcement Learning", Curry et al 2022]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rwqym5/finding_general_equilibria_in_manyagent_economic/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rwqym5/finding_general_equilibria_in_manyagent_economic/"/>
        <updated>2022-01-05T16:36:53.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/gwern  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Final reward! Help!]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rwqjk9/final_reward_help/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rwqjk9/final_reward_help/"/>
        <updated>2022-01-05T16:18:13.000Z</updated>
        <summary type="html"><![CDATA[Hellooo,
 I have a question and Ill be glad if someone could help me.
 The question is : in episodic tasks, can we work with two rewards, one during the steps of an episode and the other as the final reward at the end of the episode?
 Thank you!
    submitted by    /u/LeatherCredit7148  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Normalizing flows for distributions with finit support]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwq3tb/d_normalizing_flows_for_distributions_with_finit/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwq3tb/d_normalizing_flows_for_distributions_with_finit/"/>
        <updated>2022-01-05T15:59:33.000Z</updated>
        <summary type="html"><![CDATA[I need to learn a map from Gaussain distribution to Gamma distribution with some custom parameters. So for both distributions, I can sample and evaluate probability density. The first thing, that came to my mind is using normalizing flow. 
 Most approaches include log target probability density evaluation in the loss function. Obviously, normalizing flow sometimes returns negative values, and this term equals to infinity. "Positivation" functions on top of the NF break bijection properties for some regions of space (if not theoretically, but numerically - defenetely). 
 Does NF approach is inapplicable from the box for such a simple problem or I'm missing something?
    submitted by    /u/likan_blk  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] Yale & IBM Propose KerGNNs: Interpretable GNNs with Graph Kernels That Achieve SOTA-Competitive Performance]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rwpjyn/r_yale_ibm_propose_kergnns_interpretable_gnns/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rwpjyn/r_yale_ibm_propose_kergnns_interpretable_gnns/"/>
        <updated>2022-01-05T15:34:09.000Z</updated>
        <summary type="html"><![CDATA[A research team from Yale and IBM presents Kernel Graph Neural Networks (KerGNNs), which integrate graph kernels into the message passing process of GNNs in one framework, achieving performance comparable to state-of-the-art methods and significantly improving model interpretability compared with conventional GNNs. 
 Here is a quick read: Yale & IBM Propose KerGNNs: Interpretable GNNs with Graph Kernels That Achieve SOTA-Competitive Performance.
 The paper KerGNNs: Interpretable Graph Neural Networks with Graph Kernels is on arXiv.
    submitted by    /u/Yuqing7  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some questions on Deep Reinforcement Learning (DRL)]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rwp5sd/some_questions_on_deep_reinforcement_learning_drl/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rwp5sd/some_questions_on_deep_reinforcement_learning_drl/"/>
        <updated>2022-01-05T15:15:27.000Z</updated>
        <summary type="html"><![CDATA[Hello,
 I hope you are doing well.
 I am working on DRL and therere still some unclear points for me:
 - How we tune the hyperparameters of the network (is there a method to simplify the task)
 - How to know that we formulated the best state for the agent? 
 - In the case of collaborative multi-agent system, when an agent selects a task and the other agents are busy, will the reward be 0 for the busy agents or will be the reward of the agent that selects the task?
    submitted by    /u/GuavaAgreeable208  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memorable techniques]]></title>
        <id>https://www.johndcook.com/blog/?p=93700</id>
        <link href="https://www.johndcook.com/blog/2022/01/05/memorable-techniques/"/>
        <updated>2022-01-05T15:01:41.000Z</updated>
        <summary type="html"><![CDATA[My favorite part of this post by Ian Miellis the introduction. The article is about shell commands, but the introduction brings up a more general point.  there are thousands of reusable patterns Ive picked up  Unfortunately, Ive forgotten about 95% of them.  The point is to reflect on what actually stuck, so []
Memorable techniques first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Methods to create monolingual language model from pretrained multilingual model]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwots2/d_methods_to_create_monolingual_language_model/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwots2/d_methods_to_create_monolingual_language_model/"/>
        <updated>2022-01-05T14:59:47.000Z</updated>
        <summary type="html"><![CDATA[Apart from just fine-tuning the pretrained multilingual language model on the target language, is there anything more sophisticated that people are doing?
    submitted by    /u/learning-machinist  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI Dungeon Creator Nick Walton Uses AI to Generate Infinite Gaming Storylines]]></title>
        <id>https://blogs.nvidia.com/?p=54743</id>
        <link href="https://blogs.nvidia.com/blog/2022/01/05/nick-walton-ai-podcast/"/>
        <updated>2022-01-05T14:00:44.000Z</updated>
        <summary type="html"><![CDATA[What started as Nick Waltons college hackathon project grew into AI Dungeon, a popular text adventure game with over 1.5 million users. Walton is the co-founder and CEO of Latitude, a Utah-based startup that uses AI to create unique gaming storylines. He spoke with NVIDIA AI Podcast host Noah Kravitz about how natural language processing Read article >
The post AI Dungeon Creator Nick Walton Uses AI to Generate Infinite Gaming Storylines appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Angie Lee</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How do you measure fairness without access to demographic data?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rwn86o/how_do_you_measure_fairness_without_access_to/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rwn86o/how_do_you_measure_fairness_without_access_to/"/>
        <updated>2022-01-05T13:44:23.000Z</updated>
        <summary type="html"><![CDATA[Hi all! I'm working on a paper about measuring algorithmic fairness in cases where you don't have direct access to demographic data (for example, if you want to see whether a lender is discriminating against a particular race but the lender is not collecting/releasing race data of loan applicants).
 If you have ~10 minutes and work in the ethical AI space, it would be a great help to hear from this community on whether/how often you have faced this issue in practice and what you think should be done to mitigate.
 Survey link is here: https://cambridge.eu.qualtrics.com/jfe/form/SV_e9czBBKDitlglaC 
    submitted by    /u/emmharv  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] Blogs on fundamentals of Score-based and Diffusion Probabilistic Models]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwmvn7/p_blogs_on_fundamentals_of_scorebased_and/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwmvn7/p_blogs_on_fundamentals_of_scorebased_and/"/>
        <updated>2022-01-05T13:26:31.000Z</updated>
        <summary type="html"><![CDATA[This two-part blog describes the theoretical fundamentals of Score based models, Diffusion Probabilstic models and their relationship. It is written to be a coherent documentation of the theoretical developements in this new class of generative model. Rigorous mathematical proofs are excluded in order to make it more readable. Sharing it in case anyone finds it useful.
  
Part 1: Score-base models
 Part 2: Diffusion Probabilistic Models
  
   submitted by    /u/dasayan05  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Use this new year to start learning something new! Whether it is machine learning or piano, just give it a try for 5 minutes tonight! If it is ML-related, this video might help out, and you can start there!]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rwmr0f/use_this_new_year_to_start_learning_something_new/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rwmr0f/use_this_new_year_to_start_learning_something_new/"/>
        <updated>2022-01-05T13:19:54.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/OnlyProggingForFun  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Pretraining the discriminator of a Least Squares GAN]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwl4xl/d_pretraining_the_discriminator_of_a_least/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwl4xl/d_pretraining_the_discriminator_of_a_least/"/>
        <updated>2022-01-05T11:49:55.000Z</updated>
        <summary type="html"><![CDATA[I am trying to train a GAN to generate human poses in 3D space using the Humans 3.6M dataset. The output of the GAN is thus the 3D coordinates of the human joints. I have been experimenting with vanilla GANs but the output is quite noisy.
 I am now looking into Least Squares GAN but was wondering if it is a good idea to pretrain the discriminator of a Least Squares GAN since LSGANs address the problem of vanishing gradients and loss saturation?
    submitted by    /u/I_am_a_robot_  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Changing Gender and Race in Image Search Results With Machine Learning]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rwkskg/changing_gender_and_race_in_image_search_results/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rwkskg/changing_gender_and_race_in_image_search_results/"/>
        <updated>2022-01-05T11:28:42.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/DaveBowman1975  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Minimum Corpus Size for Word Embedding Extraction]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwju9t/d_minimum_corpus_size_for_word_embedding/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwju9t/d_minimum_corpus_size_for_word_embedding/"/>
        <updated>2022-01-05T10:29:13.000Z</updated>
        <summary type="html"><![CDATA[Dear all,
 I have a smallish ~100MB corpus (of historical text in a non-mainstream language), on which I want to apply word embedding.
 - Is that enough? Shall I only consider "frequent" words? How frequent? does it help if I do some preprocessing such as stemming etc...?
 - How do I choose the parameters, especially the embedding dimensionality?
 - Any libraries recommended?
 - Are there some language-agnostic, unsupervised ways to evaluate the embeddings?
 
 Thanks
    submitted by    /u/ihatebeinganonymous  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Ideal deep learning library]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwj813/d_ideal_deep_learning_library/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwj813/d_ideal_deep_learning_library/"/>
        <updated>2022-01-05T09:48:44.000Z</updated>
        <summary type="html"><![CDATA[From researcher perspective: - What do you miss in libraries like PyTorch or TensorFlow? - What could be improved?
 Some possible examples: - The way how autodiff works - Debugging features - Working with axes, einops - Something that just feel awkward, inconvenient or incomplete
 I would very much appreciate it if you could share your thoughts on this.
    submitted by    /u/u6785  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phonesites: Launch Pages in Minutes from Your Phone]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rwi961/phonesites_launch_pages_in_minutes_from_your_phone/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rwi961/phonesites_launch_pages_in_minutes_from_your_phone/"/>
        <updated>2022-01-05T08:43:48.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/belqassim  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Workshops on AI and RL by Shaastra, IIT Madras]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rwhq5k/workshops_on_ai_and_rl_by_shaastra_iit_madras/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rwhq5k/workshops_on_ai_and_rl_by_shaastra_iit_madras/"/>
        <updated>2022-01-05T08:06:33.000Z</updated>
        <summary type="html"><![CDATA[Workshops from Shaastra, IIT Madras about AI and Reinforcement Learning
 Certificates and recordings will be provided on registering in Shaastra's Website
    submitted by    /u/RowEmbarrassed4756  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Would it be possible to create an AI which can recognize your voice in the middle of a crowd or a somewhat noisy environment?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rwhk9u/would_it_be_possible_to_create_an_ai_which_can/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rwhk9u/would_it_be_possible_to_create_an_ai_which_can/"/>
        <updated>2022-01-05T07:55:48.000Z</updated>
        <summary type="html"><![CDATA[I know some software can already recognize specific voices, like Siri. However, Siri in particular cant recognize it beyond the Hey Siri keywords I believe. Is it possible to create an AI which can continuously recognize x-persons voice in a group of people or a loud environment (loud restaurant, construction nearby, concert, etc) in real time?
  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Predicting future labels where the future values of only some features are known (RNNs, time series)[D]]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwcikx/predicting_future_labels_where_the_future_values/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwcikx/predicting_future_labels_where_the_future_values/"/>
        <updated>2022-01-05T03:09:46.000Z</updated>
        <summary type="html"><![CDATA[I've done a fair bit of work with RNNs and Time series data, but I now realize there may be a fundamental gap in my knowledge. I was reading through this and it raised some questions about the different kinds of time forecasting problems. 
 So, this is my summary of how it all works. Please correct me if Im wrong. 
 Scenario 1: You want to predict the value of some stocks into the future. Lets say you have k stocks and n days of data. You dont have features/labels stocks, rather the input is each stocks current and previous values, and the output is each stocks future values. 
 Your two main options are the auto-regressive approach where you predict the values one step at a time and feed them back in, or single shot approach where you predict all values a fixed amount of time step]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] Classification with imbalanced datasets question]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwc7zy/p_classification_with_imbalanced_datasets_question/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwc7zy/p_classification_with_imbalanced_datasets_question/"/>
        <updated>2022-01-05T02:55:25.000Z</updated>
        <summary type="html"><![CDATA[I've been working on a medical classification project with an imbalanced tabular dataset. I have 3 classes, and each class has 44, 16, and 14 rows of data respectively. When I train a random forest classifier, I see that my model is only predicting the dominant class for all test instances most of the time. How can I get around to this? Also, are there any recommendations you can give me for dealing with imbalanced datasets? Thank you
    submitted by    /u/chazy07  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] I implemented Conformer: Convolution-augmented Transformer]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rwc10x/p_i_implemented_conformer_convolutionaugmented/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rwc10x/p_i_implemented_conformer_convolutionaugmented/"/>
        <updated>2022-01-05T02:45:59.000Z</updated>
        <summary type="html"><![CDATA[I implemented Google AI's "Conformer: Convolution-augmented Transformer for Speech Recognition" paper, it achieves the best of both worlds by combining CNNs and transformers to model both local and global dependencies and improves the local inductive bias in Transformers.
 https://github.com/Rishit-dagli/Conformer
    submitted by    /u/Rishit-dagli  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dumb-yet-sentient AI]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rwakko/dumbyetsentient_ai/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rwakko/dumbyetsentient_ai/"/>
        <updated>2022-01-05T01:36:23.000Z</updated>
        <summary type="html"><![CDATA[It seems like most people associate sentient AI with Artificial General Intelligence, or AGI, but why should they be related? Wikipedia defines sentience as the "ability to be aware of feelings and sensations", and this doesn't seem to require any specific level of intelligence, does it? Couldn't we build a sentient AI bot, for example, out of "dumb" neural networks (e.g. relatively small transformers and/or CNN/RNN models), so long as they connect together in a way that involves sensing a world around them (in whatever dimensions that world has, not necessarily the same as ours), using these sensations to construct some sort of internal "state", and identifying that state accurately enough to drive subsequent action--or interaction with the world?
    submitted by    /u/mm_maybe  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Real life Reinforcement learning]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rwahe9/real_life_reinforcement_learning/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rwahe9/real_life_reinforcement_learning/"/>
        <updated>2022-01-05T01:32:02.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/odinnotdoit  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Intelligent Gateways Applications For Greenfield and Brownfield Environments]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086942</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086942"/>
        <updated>2022-01-05T01:03:09.000Z</updated>
        <summary type="html"><![CDATA[<p><span><a href="https://storage.ning.com/topology/rest/1.0/file/get/9977680695?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9977680695?profile=RESIZE_710x" width="720"></img></a></span></p>
<p><span>The Internet of Things has led to the rise of a new era of computing where intelligent applications are continuously monitored. Also, connected devices need to be efficiently controlled, thereby continuously transforming information into knowledge. By intelligently gathering and analyzing huge amounts of data, smart systems can</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Can OTT platforms succeed with machine learning services? An insight]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085735</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085735"/>
        <updated>2022-01-05T01:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p style="margin: 0in; margin-bottom: .0001pt; text-align: justify;"><span style="font-family: 'Cambria','serif'; color: #0e101a;"><a href="https://storage.ning.com/topology/rest/1.0/file/get/9982564869?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9982564869?profile=RESIZE_710x" width="720"></img></a></span></p>
<p>Whether you're acquainted with devices such as the Amazon Fire Stick, Chromecast, Spotify, Youtube, or SlingTV, you presumably already have a general understanding of what over-the-top (OTT) television is. Numerous</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Equivalent framework as Gin for PyTorch]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rw9obd/equivalent_framework_as_gin_for_pytorch/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rw9obd/equivalent_framework_as_gin_for_pytorch/"/>
        <updated>2022-01-05T00:53:13.000Z</updated>
        <summary type="html"><![CDATA[Hi, does any of you know is there is an equivalent of this framework (https://github.com/google/gin-config) for PyTorch? 
 Thanks
    submitted by    /u/No_Possibility_7588  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trends Towards 2022]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086893</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086893"/>
        <updated>2022-01-05T00:50:54.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9982552264?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9982552264?profile=RESIZE_710x" width="720"></img></a></p>
<p>It's the last week of the year. The gifts have been opened (well, the ones that aren't currently still sitting in a dock in Los Angeles after being ordered in November), the cats have been teaching tree ornaments the meaning of the word gravity, and the cookies which tasted so good on Christmas Eve are getting more than a bit stale. In short, it's</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalar reward is not enough]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rw9kci/scalar_reward_is_not_enough/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rw9kci/scalar_reward_is_not_enough/"/>
        <updated>2022-01-05T00:47:54.000Z</updated>
        <summary type="html"><![CDATA[Check out this paper which discusses the idea that a scalar reward is not enough to create agi.
 https://arxiv.org/abs/2112.15422
 What are your thoughts on this?
    submitted by    /u/Longjumping-Chart-34  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Identify comorbidities associated with recurrent ED and in-patient visits. (arXiv:2110.13769v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.13769</id>
        <link href="http://arxiv.org/abs/2110.13769"/>
        <updated>2022-01-05T00:39:37.220Z</updated>
        <summary type="html"><![CDATA[In the hospital setting, a small percentage of recurrent frequent patients
contribute to a disproportional amount of healthcare resource usage. Moreover,
in many of these cases, patient outcomes can be greatly improved by reducing
reoccurring visits, especially when they are associated with substance abuse,
mental health, and medical factors that could be improved by social-behavioral
interventions, outpatient or preventative care. Additionally, health care costs
can be reduced significantly with fewer preventable recurrent visits.

To address this, we developed a computationally efficient and interpretable
framework that both identifies recurrent patients with high utilization and
determines which comorbidities contribute most to their recurrent visits.
Specifically, we present a novel algorithm, called the minimum similarity
association rules (MSAR), balancing confidence-support trade-off, to determine
the conditions most associated with reoccurring Emergency department (ED) and
inpatient visits. We validate MSAR on a large Electric Health Record (EHR)
dataset.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Liu_L/0/1/0/all/0/1"&gt;Luoluo Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Simhon_E/0/1/0/all/0/1"&gt;Eran Simhon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Kulkarni_C/0/1/0/all/0/1"&gt;Chaitanya Kulkarni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Noren_D/0/1/0/all/0/1"&gt;David Noren&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Mans_R/0/1/0/all/0/1"&gt;Ronny Mans&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GCN-Geo: A Graph Convolution Network-based Fine-grained IP Geolocation System. (arXiv:2112.10767v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.10767</id>
        <link href="http://arxiv.org/abs/2112.10767"/>
        <updated>2022-01-05T00:39:37.194Z</updated>
        <summary type="html"><![CDATA[Fine-grained IP geolocation systems often rely on some linear delay-distance
rules. They are not easy to generalize in network environments where the
delay-distance relationship is non-linear. Recently, researchers begin to pay
attention to learning-based IP geolocation systems. These data-driven
algorithms leverage multi-layer perceptron (MLP) to model non-linear
relationships. However, MLP is not so suitable for modeling computer networks
because networks are fundamentally graph-typed data. MLP-based IP geolocation
systems only treat IP addresses as isolated data instances, forgoing the
connection information between IP addresses. This would lead to sub-optimal
representations and limit the geolocation performance.

Graph convolutional network (GCN) is an emerging deep learning method for
graph-typed data presentation. In this work, we research how to model computer
networks for fine-grained IP geolocation with GCN. First, we formulate the IP
geolocation task as an attributed graph node regression problem. Then, a
GCN-based IP geolocation system named GCN-Geo is proposed to predict the
location of each IP address. GCN-Geo consists of a preprocessor, an encoder,
graph convolutional (GC) layers and a decoder. The preprocessor and the encoder
transform raw measurement data into the initial graph embeddings. GC layers
refine the initial graph node embeddings by explicitly modeling the connection
information between IP addresses. The proposed decoder can relieve the
converging problem of GCN-Geo by considering some prior knowledge about target
IP addresses. Finally, the experimental results in three real-world datasets
show that: GCN-Geo clearly outperforms the state-of-art rule-based and
learning-based baselines on all three datasets w.r.t. average, median and max
error distances. This work verifies the potential of GCN in fine-grained IP
geolocation.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1"&gt;Shichang Ding&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1"&gt;Xiangyang Luo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"&gt;Jinwei Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiong_N/0/1/0/all/0/1"&gt;Neal Naixue Xiong&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Comprehensive Survey of Logging in Software: From Logging Statements Automation to Log Mining and Analysis. (arXiv:2110.12489v2 [cs.SE] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.12489</id>
        <link href="http://arxiv.org/abs/2110.12489"/>
        <updated>2022-01-05T00:39:37.193Z</updated>
        <summary type="html"><![CDATA[Logs are widely used to record runtime information of software systems, such
as the timestamp and the importance of an event, the unique ID of the source of
the log, and a part of the state of a task's execution. The rich information of
logs enables system developers (and operators) to monitor the runtime behaviors
of their systems and further track down system problems and perform analysis on
log data in production settings. However, the prior research on utilizing logs
is scattered and that limits the ability of new researchers in this field to
quickly get to the speed and hampers currently active researchers to advance
this field further. Therefore, this paper surveys and provides a systematic
literature review and mapping of the contemporary logging practices and log
statements' mining and monitoring techniques and their applications such as in
system failure detection and diagnosis. We study a large number of conference
and journal papers that appeared on top-level peer-reviewed venues.
Additionally, we draw high-level trends of ongoing research and categorize
publications into subdivisions. In the end, and based on our holistic
observations during this survey, we provide a set of challenges and
opportunities that will lead the researchers in academia and industry in moving
the field forward.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Gholamian_S/0/1/0/all/0/1"&gt;Sina Gholamian&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ward_P/0/1/0/all/0/1"&gt;Paul A. S. Ward&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fracture Detection in Wrist X-ray Images Using Deep Learning-Based Object Detection Models. (arXiv:2111.07355v2 [eess.IV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.07355</id>
        <link href="http://arxiv.org/abs/2111.07355"/>
        <updated>2022-01-05T00:39:37.178Z</updated>
        <summary type="html"><![CDATA[Wrist fractures are common cases in hospitals, particularly in emergency
services. Physicians need images from various medical devices, and patients
medical history and physical examination to diagnose these fractures correctly
and apply proper treatment. This study aims to perform fracture detection using
deep learning on wrist Xray images to assist physicians not specialized in the
field, working in emergency services in particular, in diagnosis of fractures.
For this purpose, 20 different detection procedures were performed using deep
learning based object detection models on dataset of wrist Xray images obtained
from Gazi University Hospital. DCN, Dynamic R_CNN, Faster R_CNN, FSAF, Libra
R_CNN, PAA, RetinaNet, RegNet and SABL deep learning based object detection
models with various backbones were used herein. To further improve detection
procedures in the study, 5 different ensemble models were developed, which were
later used to reform an ensemble model to develop a detection model unique to
our study, titled wrist fracture detection combo (WFD_C). Based on 26 different
models for fracture detection, the highest result of detection was 0.8639
average precision (AP50) in WFD_C model developed. This study is supported by
Huawei Turkey R&D Center within the scope of the ongoing cooperation project
coded 071813 among Gazi University, Huawei and Medskor.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Hardalac_F/0/1/0/all/0/1"&gt;F&amp;#x131;rat Hardala&amp;#xe7;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Uysal_F/0/1/0/all/0/1"&gt;Fatih Uysal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Peker_O/0/1/0/all/0/1"&gt;Ozan Peker&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Ciceklidag_M/0/1/0/all/0/1"&gt;Murat &amp;#xc7;i&amp;#xe7;eklida&amp;#x11f;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Tolunay_T/0/1/0/all/0/1"&gt;Tolga Tolunay&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Tokgoz_N/0/1/0/all/0/1"&gt;Nil Tokg&amp;#xf6;z&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Kutbay_U/0/1/0/all/0/1"&gt;U&amp;#x11f;urhan Kutbay&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Demirciler_B/0/1/0/all/0/1"&gt;Boran Demirciler&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Mert_F/0/1/0/all/0/1"&gt;Fatih Mert&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SoK: Privacy-preserving Deep Learning with Homomorphic Encryption. (arXiv:2112.12855v2 [cs.CR] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.12855</id>
        <link href="http://arxiv.org/abs/2112.12855"/>
        <updated>2022-01-05T00:39:37.172Z</updated>
        <summary type="html"><![CDATA[Outsourced computation for neural networks allows users access to state of
the art models without needing to invest in specialized hardware and know-how.
The problem is that the users lose control over potentially privacy sensitive
data. With homomorphic encryption (HE) computation can be performed on
encrypted data without revealing its content. In this systematization of
knowledge, we take an in-depth look at approaches that combine neural networks
with HE for privacy preservation. We categorize the changes to neural network
models and architectures to make them computable over HE and how these changes
impact performance. We find numerous challenges to HE based privacy-preserving
deep learning such as computational overhead, usability, and limitations posed
by the encryption schemes.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Podschwadt_R/0/1/0/all/0/1"&gt;Robert Podschwadt&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Takabi_D/0/1/0/all/0/1"&gt;Daniel Takabi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1"&gt;Peizhao Hu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mimicking the Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning. (arXiv:2112.04731v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.04731</id>
        <link href="http://arxiv.org/abs/2112.04731"/>
        <updated>2022-01-05T00:39:37.161Z</updated>
        <summary type="html"><![CDATA[Class Incremental Learning (CIL) aims at learning a multi-class classifier in
a phase-by-phase manner, in which only data of a subset of the classes are
provided at each phase. Previous works mainly focus on mitigating forgetting in
phases after the initial one. However, we find that improving CIL at its
initial phase is also a promising direction. Specifically, we experimentally
show that directly encouraging CIL Learner at the initial phase to output
similar representations as the model jointly trained on all classes can greatly
boost the CIL performance. Motivated by this, we study the difference between a
na\"ively-trained initial-phase model and the oracle model. Specifically, since
one major difference between these two models is the number of training
classes, we investigate how such difference affects the model representations.
We find that, with fewer training classes, the data representations of each
class lie in a long and narrow region; with more training classes, the
representations of each class scatter more uniformly. Inspired by this
observation, we propose Class-wise Decorrelation (CwD) that effectively
regularizes representations of each class to scatter more uniformly, thus
mimicking the model jointly trained with all classes (i.e., the oracle model).
Our CwD is simple to implement and easy to plug into existing methods.
Extensive experiments on various benchmark datasets show that CwD consistently
and significantly improves the performance of existing state-of-the-art methods
by around 1\% to 3\%. Code will be released.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1"&gt;Yujun Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1"&gt;Kuangqi Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1"&gt;Jian Liang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1"&gt;Zihang Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1"&gt;Jiashi Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1"&gt;Philip Torr&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1"&gt;Song Bai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1"&gt;Vincent Y. F. Tan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning. (arXiv:2106.03760v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.03760</id>
        <link href="http://arxiv.org/abs/2106.03760"/>
        <updated>2022-01-05T00:39:37.159Z</updated>
        <summary type="html"><![CDATA[The Mixture-of-Experts (MoE) architecture is showing promising results in
improving parameter sharing in multi-task learning (MTL) and in scaling
high-capacity neural networks. State-of-the-art MoE models use a trainable
sparse gate to select a subset of the experts for each input example. While
conceptually appealing, existing sparse gates, such as Top-k, are not smooth.
The lack of smoothness can lead to convergence and statistical performance
issues when training with gradient-based methods. In this paper, we develop
DSelect-k: a continuously differentiable and sparse gate for MoE, based on a
novel binary encoding formulation. The gate can be trained using first-order
methods, such as stochastic gradient descent, and offers explicit control over
the number of experts to select. We demonstrate the effectiveness of DSelect-k
on both synthetic and real MTL datasets with up to $128$ tasks. Our experiments
indicate that DSelect-k can achieve statistically significant improvements in
prediction and expert selection over popular MoE gates. Notably, on a
real-world, large-scale recommender system, DSelect-k achieves over $22\%$
improvement in predictive performance compared to Top-k. We provide an
open-source implementation of DSelect-k.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hazimeh_H/0/1/0/all/0/1"&gt;Hussein Hazimeh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1"&gt;Zhe Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chowdhery_A/0/1/0/all/0/1"&gt;Aakanksha Chowdhery&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sathiamoorthy_M/0/1/0/all/0/1"&gt;Maheswaran Sathiamoorthy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yihua Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mazumder_R/0/1/0/all/0/1"&gt;Rahul Mazumder&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1"&gt;Lichan Hong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1"&gt;Ed H. Chi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Provable Generalization of Recurrent Neural Networks. (arXiv:2109.14142v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.14142</id>
        <link href="http://arxiv.org/abs/2109.14142"/>
        <updated>2022-01-05T00:39:37.157Z</updated>
        <summary type="html"><![CDATA[Recurrent Neural Network (RNN) is a fundamental structure in deep learning.
Recently, some works study the training process of over-parameterized neural
networks, and show that over-parameterized networks can learn functions in some
notable concept classes with a provable generalization error bound. In this
paper, we analyze the training and generalization for RNNs with random
initialization, and provide the following improvements over recent works:

1) For a RNN with input sequence $x=(X_1,X_2,...,X_L)$, previous works study
to learn functions that are summation of $f(\beta^T_lX_l)$ and require
normalized conditions that $||X_l||\leq\epsilon$ with some very small
$\epsilon$ depending on the complexity of $f$. In this paper, using detailed
analysis about the neural tangent kernel matrix, we prove a generalization
error bound to learn such functions without normalized conditions and show that
some notable concept classes are learnable with the numbers of iterations and
samples scaling almost-polynomially in the input length $L$.

2) Moreover, we prove a novel result to learn N-variables functions of input
sequence with the form $f(\beta^T[X_{l_1},...,X_{l_N}])$, which do not belong
to the "additive" concept class, i,e., the summation of function $f(X_l)$. And
we show that when either $N$ or $l_0=\max(l_1,..,l_N)-\min(l_1,..,l_N)$ is
small, $f(\beta^T[X_{l_1},...,X_{l_N}])$ will be learnable with the number
iterations and samples scaling almost-polynomially in the input length $L$.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"&gt;Lifu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1"&gt;Bo Shen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1"&gt;Bo Hu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1"&gt;Xing Cao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Layer-wise Adaptive Model Aggregation for Scalable Federated Learning. (arXiv:2110.10302v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.10302</id>
        <link href="http://arxiv.org/abs/2110.10302"/>
        <updated>2022-01-05T00:39:37.157Z</updated>
        <summary type="html"><![CDATA[In Federated Learning, a common approach for aggregating local models across
clients is periodic averaging of the full model parameters. It is, however,
known that different layers of neural networks can have a different degree of
model discrepancy across the clients. The conventional full aggregation scheme
does not consider such a difference and synchronizes the whole model parameters
at once, resulting in inefficient network bandwidth consumption. Aggregating
the parameters that are similar across the clients does not make meaningful
training progress while increasing the communication cost. We propose FedLAMA,
a layer-wise model aggregation scheme for scalable Federated Learning. FedLAMA
adaptively adjusts the aggregation interval in a layer-wise manner, jointly
considering the model discrepancy and the communication cost. The layer-wise
aggregation method enables to finely control the aggregation interval to relax
the aggregation frequency without a significant impact on the model accuracy.
Our empirical study shows that FedLAMA reduces the communication cost by up to
60% for IID data and 70% for non-IID data while achieving a comparable accuracy
to FedAvg.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1"&gt;Sunwoo Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1"&gt;Tuo Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1"&gt;Chaoyang He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1"&gt;Salman Avestimehr&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Optimizing Interventions in Shared Autonomy. (arXiv:2112.09169v2 [cs.AI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.09169</id>
        <link href="http://arxiv.org/abs/2112.09169"/>
        <updated>2022-01-05T00:39:37.156Z</updated>
        <summary type="html"><![CDATA[Shared autonomy refers to approaches for enabling an autonomous agent to
collaborate with a human with the aim of improving human performance. However,
besides improving performance, it may often also be beneficial that the agent
concurrently accounts for preserving the user's experience or satisfaction of
collaboration. In order to address this additional goal, we examine approaches
for improving the user experience by constraining the number of interventions
by the autonomous agent. We propose two model-free reinforcement learning
methods that can account for both hard and soft constraints on the number of
interventions. We show that not only does our method outperform the existing
baseline, but also eliminates the need to manually tune a black-box
hyperparameter for controlling the level of assistance. We also provide an
in-depth analysis of intervention scenarios in order to further illuminate
system understanding.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1"&gt;Weihao Tan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Koleczek_D/0/1/0/all/0/1"&gt;David Koleczek&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pradhan_S/0/1/0/all/0/1"&gt;Siddhant Pradhan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Perello_N/0/1/0/all/0/1"&gt;Nicholas Perello&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chettiar_V/0/1/0/all/0/1"&gt;Vivek Chettiar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rohra_V/0/1/0/all/0/1"&gt;Vishal Rohra&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rajaram_A/0/1/0/all/0/1"&gt;Aaslesha Rajaram&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1"&gt;Soundararajan Srinivasan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hossain_H/0/1/0/all/0/1"&gt;H M Sajjad Hossain&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chandak_Y/0/1/0/all/0/1"&gt;Yash Chandak&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[User-Level Label Leakage from Gradients in Federated Learning. (arXiv:2105.09369v4 [cs.CR] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.09369</id>
        <link href="http://arxiv.org/abs/2105.09369"/>
        <updated>2022-01-05T00:39:37.154Z</updated>
        <summary type="html"><![CDATA[Federated learning enables multiple users to build a joint model by sharing
their model updates (gradients), while their raw data remains local on their
devices. In contrast to the common belief that this provides privacy benefits,
we here add to the very recent results on privacy risks when sharing gradients.
Specifically, we investigate Label Leakage from Gradients (LLG), a novel attack
to extract the labels of the users' training data from their shared gradients.
The attack exploits the direction and magnitude of gradients to determine the
presence or absence of any label. LLG is simple yet effective, capable of
leaking potential sensitive information represented by labels, and scales well
to arbitrary batch sizes and multiple classes. We mathematically and
empirically demonstrate the validity of the attack under different settings.
Moreover, empirical results show that LLG successfully extracts labels with
high accuracy at the early stages of model training. We also discuss different
defense mechanisms against such leakage. Our findings suggest that gradient
compression is a practical technique to mitigate the attack.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wainakh_A/0/1/0/all/0/1"&gt;Aidmar Wainakh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ventola_F/0/1/0/all/0/1"&gt;Fabrizio Ventola&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mussig_T/0/1/0/all/0/1"&gt;Till M&amp;#xfc;&amp;#xdf;ig&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Keim_J/0/1/0/all/0/1"&gt;Jens Keim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cordero_C/0/1/0/all/0/1"&gt;Carlos Garcia Cordero&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zimmer_E/0/1/0/all/0/1"&gt;Ephraim Zimmer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grube_T/0/1/0/all/0/1"&gt;Tim Grube&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1"&gt;Kristian Kersting&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Muhlhauser_M/0/1/0/all/0/1"&gt;Max M&amp;#xfc;hlh&amp;#xe4;user&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provably Efficient Reinforcement Learning with Linear Function Approximation Under Adaptivity Constraints. (arXiv:2101.02195v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2101.02195</id>
        <link href="http://arxiv.org/abs/2101.02195"/>
        <updated>2022-01-05T00:39:37.091Z</updated>
        <summary type="html"><![CDATA[We study reinforcement learning (RL) with linear function approximation under
the adaptivity constraint. We consider two popular limited adaptivity models:
the batch learning model and the rare policy switch model, and propose two
efficient online RL algorithms for episodic linear Markov decision processes,
where the transition probability and the reward function can be represented as
a linear function of some known feature mapping. In specific, for the batch
learning model, our proposed LSVI-UCB-Batch algorithm achieves an $\tilde
O(\sqrt{d^3H^3T} + dHT/B)$ regret, where $d$ is the dimension of the feature
mapping, $H$ is the episode length, $T$ is the number of interactions and $B$
is the number of batches. Our result suggests that it suffices to use only
$\sqrt{T/dH}$ batches to obtain $\tilde O(\sqrt{d^3H^3T})$ regret. For the rare
policy switch model, our proposed LSVI-UCB-RareSwitch algorithm enjoys an
$\tilde O(\sqrt{d^3H^3T[1+T/(dH)]^{dH/B}})$ regret, which implies that $dH\log
T$ policy switches suffice to obtain the $\tilde O(\sqrt{d^3H^3T})$ regret. Our
algorithms achieve the same regret as the LSVI-UCB algorithm (Jin et al.,
2019), yet with a substantially smaller amount of adaptivity. We also establish
a lower bound for the batch learning model, which suggests that the dependency
on $B$ in our regret bound is tight.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1"&gt;Tianhao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BM-NAS: Bilevel Multimodal Neural Architecture Search. (arXiv:2104.09379v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.09379</id>
        <link href="http://arxiv.org/abs/2104.09379"/>
        <updated>2022-01-05T00:39:37.091Z</updated>
        <summary type="html"><![CDATA[Deep neural networks (DNNs) have shown superior performances on various
multimodal learning problems. However, it often requires huge efforts to adapt
DNNs to individual multimodal tasks by manually engineering unimodal features
and designing multimodal feature fusion strategies. This paper proposes Bilevel
Multimodal Neural Architecture Search (BM-NAS) framework, which makes the
architecture of multimodal fusion models fully searchable via a bilevel
searching scheme. At the upper level, BM-NAS selects the inter/intra-modal
feature pairs from the pretrained unimodal backbones. At the lower level,
BM-NAS learns the fusion strategy for each feature pair, which is a combination
of predefined primitive operations. The primitive operations are elaborately
designed and they can be flexibly combined to accommodate various effective
feature fusion modules such as multi-head attention (Transformer) and Attention
on Attention (AoA). Experimental results on three multimodal tasks demonstrate
the effectiveness and efficiency of the proposed BM-NAS framework. BM-NAS
achieves competitive performances with much less search time and fewer model
parameters in comparison with the existing generalized multimodal NAS methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1"&gt;Yihang Yin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1"&gt;Siyu Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"&gt;Xiang Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nearly Minimax Optimal Reinforcement Learning for Discounted MDPs. (arXiv:2010.00587v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.00587</id>
        <link href="http://arxiv.org/abs/2010.00587"/>
        <updated>2022-01-05T00:39:37.090Z</updated>
        <summary type="html"><![CDATA[We study the reinforcement learning problem for discounted Markov Decision
Processes (MDPs) under the tabular setting. We propose a model-based algorithm
named UCBVI-$\gamma$, which is based on the \emph{optimism in the face of
uncertainty principle} and the Bernstein-type bonus. We show that
UCBVI-$\gamma$ achieves an $\tilde{O}\big({\sqrt{SAT}}/{(1-\gamma)^{1.5}}\big)$
regret, where $S$ is the number of states, $A$ is the number of actions,
$\gamma$ is the discount factor and $T$ is the number of steps. In addition, we
construct a class of hard MDPs and show that for any algorithm, the expected
regret is at least $\tilde{\Omega}\big({\sqrt{SAT}}/{(1-\gamma)^{1.5}}\big)$.
Our upper bound matches the minimax lower bound up to logarithmic factors,
which suggests that UCBVI-$\gamma$ is nearly minimax optimal for discounted
MDPs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1"&gt;Jiafan He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NCVX: A User-Friendly and Scalable Package for Nonconvex Optimization in Machine Learning. (arXiv:2111.13984v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.13984</id>
        <link href="http://arxiv.org/abs/2111.13984"/>
        <updated>2022-01-05T00:39:37.090Z</updated>
        <summary type="html"><![CDATA[Optimizing nonconvex (NCVX) problems, especially nonsmooth and constrained
ones, is an essential part of machine learning. However, it can be hard to
reliably solve such problems without optimization expertise. Existing
general-purpose NCVX optimization packages are powerful but typically cannot
handle nonsmoothness. GRANSO is among the first optimization solvers targeting
general nonsmooth NCVX problems with nonsmooth constraints, but, as it is
implemented in MATLAB and requires the user to provide analytical gradients,
GRANSO is often not a convenient choice in machine learning (especially deep
learning) applications. To greatly lower the technical barrier, we introduce a
new software package called NCVX, whose initial release contains the solver
PyGRANSO, a PyTorch-enabled port of GRANSO incorporating auto-differentiation,
GPU acceleration, tensor input, and support for new QP solvers. NCVX is built
on freely available and widely used open-source frameworks, and as a highlight,
can solve general constrained deep learning problems, the first of its kind.
NCVX is available at https://ncvx.org, with detailed documentation and numerous
examples from machine learning and other fields.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liang_B/0/1/0/all/0/1"&gt;Buyun Liang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mitchell_T/0/1/0/all/0/1"&gt;Tim Mitchell&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1"&gt;Ju Sun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Pointer Neural Networks. (arXiv:2110.00973v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.00973</id>
        <link href="http://arxiv.org/abs/2110.00973"/>
        <updated>2022-01-05T00:39:37.086Z</updated>
        <summary type="html"><![CDATA[Graph Neural Networks (GNNs) have shown advantages in various graph-based
applications. Most existing GNNs assume strong homophily of graph structure and
apply permutation-invariant local aggregation of neighbors to learn a
representation for each node. However, they fail to generalize to heterophilic
graphs, where most neighboring nodes have different labels or features, and the
relevant nodes are distant. Few recent studies attempt to address this problem
by combining multiple hops of hidden representations of central nodes (i.e.,
multi-hop-based approaches) or sorting the neighboring nodes based on attention
scores (i.e., ranking-based approaches). As a result, these approaches have
some apparent limitations. On the one hand, multi-hop-based approaches do not
explicitly distinguish relevant nodes from a large number of multi-hop
neighborhoods, leading to a severe over-smoothing problem. On the other hand,
ranking-based models do not joint-optimize node ranking with end tasks and
result in sub-optimal solutions. In this work, we present Graph Pointer Neural
Networks (GPNN) to tackle the challenges mentioned above. We leverage a pointer
network to select the most relevant nodes from a large amount of multi-hop
neighborhoods, which constructs an ordered sequence according to the
relationship with the central node. 1D convolution is then applied to extract
high-level features from the node sequence. The pointer-network-based ranker in
GPNN is joint-optimized with other parts in an end-to-end manner. Extensive
experiments are conducted on six public node classification datasets with
heterophilic graphs. The results show that GPNN significantly improves the
classification performance of state-of-the-art methods. In addition, analyses
also reveal the privilege of the proposed GPNN in filtering out irrelevant
neighbors and reducing over-smoothing.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1"&gt;Tianmeng Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yujing Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1"&gt;Zhihan Yue&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"&gt;Yaming Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1"&gt;Yunhai Tong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1"&gt;Jing Bai&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Survey of Generalisation in Deep Reinforcement Learning. (arXiv:2111.09794v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.09794</id>
        <link href="http://arxiv.org/abs/2111.09794"/>
        <updated>2022-01-05T00:39:37.086Z</updated>
        <summary type="html"><![CDATA[The study of generalisation in deep Reinforcement Learning (RL) aims to
produce RL algorithms whose policies generalise well to novel unseen situations
at deployment time, avoiding overfitting to their training environments.
Tackling this is vital if we are to deploy reinforcement learning algorithms in
real world scenarios, where the environment will be diverse, dynamic and
unpredictable. This survey is an overview of this nascent field. We provide a
unifying formalism and terminology for discussing different generalisation
problems, building upon previous works. We go on to categorise existing
benchmarks for generalisation, as well as current methods for tackling the
generalisation problem. Finally, we provide a critical discussion of the
current state of the field, including recommendations for future work. Among
other conclusions, we argue that taking a purely procedural content generation
approach to benchmark design is not conducive to progress in generalisation, we
suggest fast online adaptation and tackling RL-specific problems as some areas
for future work on methods for generalisation, and we recommend building
benchmarks in underexplored problem settings such as offline RL generalisation
and reward-function variation.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kirk_R/0/1/0/all/0/1"&gt;Robert Kirk&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1"&gt;Amy Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grefenstette_E/0/1/0/all/0/1"&gt;Edward Grefenstette&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1"&gt;Tim Rockt&amp;#xe4;schel&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sample Complexity of Learning Parametric Quantum Circuits. (arXiv:2107.09078v2 [quant-ph] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2107.09078</id>
        <link href="http://arxiv.org/abs/2107.09078"/>
        <updated>2022-01-05T00:39:37.081Z</updated>
        <summary type="html"><![CDATA[Quantum computers hold unprecedented potentials for machine learning
applications. Here, we prove that physical quantum circuits are PAC (probably
approximately correct) learnable on a quantum computer via empirical risk
minimization: to learn a parametric quantum circuit with at most $n^c$ gates
and each gate acting on a constant number of qubits, the sample complexity is
bounded by $\tilde{O}(n^{c+1})$. In particular, we explicitly construct a
family of variational quantum circuits with $O(n^{c+1})$ elementary gates
arranged in a fixed pattern, which can represent all physical quantum circuits
consisting of at most $n^c$ elementary gates. Our results provide a valuable
guide for quantum machine learning in both theory and practice.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/quant-ph/1/au:+Cai_H/0/1/0/all/0/1"&gt;Haoyuan Cai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/quant-ph/1/au:+Ye_Q/0/1/0/all/0/1"&gt;Qi Ye&lt;/a&gt;, &lt;a href="http://arxiv.org/find/quant-ph/1/au:+Deng_D/0/1/0/all/0/1"&gt;Dong-Ling Deng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High-dimensional Bayesian Optimization Algorithm with Recurrent Neural Network for Disease Control Models in Time Series. (arXiv:2201.00147v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00147</id>
        <link href="http://arxiv.org/abs/2201.00147"/>
        <updated>2022-01-05T00:39:37.080Z</updated>
        <summary type="html"><![CDATA[Bayesian Optimization algorithm has become a promising approach for nonlinear
global optimization problems and many machine learning applications. Over the
past few years, improvements and enhancements have been brought forward and
they have shown some promising results in solving the complex dynamic problems,
systems of ordinary differential equations where the objective functions are
computationally expensive to evaluate. Besides, the straightforward
implementation of the Bayesian Optimization algorithm performs well merely for
optimization problems with 10-20 dimensions. The study presented in this paper
proposes a new high dimensional Bayesian Optimization algorithm combining
Recurrent neural networks, which is expected to predict the optimal solution
for the global optimization problems with high dimensional or time series
decision models. The proposed RNN-BO algorithm can solve the optimal control
problems in the lower dimension space and then learn from the historical data
using the recurrent neural network to learn the historical optimal solution
data and predict the optimal control strategy for any new initial system value
setting. In addition, accurately and quickly providing the optimal control
strategy is essential to effectively and efficiently control the epidemic
spread while minimizing the associated financial costs. Therefore, to verify
the effectiveness of the proposed algorithm, computational experiments are
carried out on a deterministic SEIR epidemic model and a stochastic SIS optimal
control model. Finally, we also discuss the impacts of different numbers of the
RNN layers and training epochs on the trade-off between solution quality and
related computational efforts.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yuyang Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bi_K/0/1/0/all/0/1"&gt;Kaiming Bi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1"&gt;Chih-Hang J. Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ben_Arieh_D/0/1/0/all/0/1"&gt;David Ben-Arieh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1"&gt;Ashesh Sinha&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FUSeg: The Foot Ulcer Segmentation Challenge. (arXiv:2201.00414v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2201.00414</id>
        <link href="http://arxiv.org/abs/2201.00414"/>
        <updated>2022-01-05T00:39:37.079Z</updated>
        <summary type="html"><![CDATA[Acute and chronic wounds with varying etiologies burden the healthcare
systems economically. The advanced wound care market is estimated to reach $22
billion by 2024. Wound care professionals provide proper diagnosis and
treatment with heavy reliance on images and image documentation. Segmentation
of wound boundaries in images is a key component of the care and diagnosis
protocol since it is important to estimate the area of the wound and provide
quantitative measurement for the treatment. Unfortunately, this process is very
time-consuming and requires a high level of expertise. Recently automatic wound
segmentation methods based on deep learning have shown promising performance
but require large datasets for training and it is unclear which methods perform
better. To address these issues, we propose the Foot Ulcer Segmentation
challenge (FUSeg) organized in conjunction with the 2021 International
Conference on Medical Image Computing and Computer Assisted Intervention
(MICCAI). We built a wound image dataset containing 1,210 foot ulcer images
collected over 2 years from 889 patients. It is pixel-wise annotated by wound
care experts and split into a training set with 1010 images and a testing set
with 200 images for evaluation. Teams around the world developed automated
methods to predict wound segmentations on the testing set of which annotations
were kept private. The predictions were evaluated and ranked based on the
average Dice coefficient. The FUSeg challenge remains an open challenge as a
benchmark for wound segmentation after the conference.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1"&gt;Chuanbo Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Mahbod_A/0/1/0/all/0/1"&gt;Amirreza Mahbod&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Ellinger_I/0/1/0/all/0/1"&gt;Isabella Ellinger&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Galdran_A/0/1/0/all/0/1"&gt;Adrian Galdran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Gopalakrishnan_S/0/1/0/all/0/1"&gt;Sandeep Gopalakrishnan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Niezgoda_J/0/1/0/all/0/1"&gt;Jeffrey Niezgoda&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yu_Z/0/1/0/all/0/1"&gt;Zeyun Yu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Representation Learning with an Information-theoretic Loss. (arXiv:2111.12950v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.12950</id>
        <link href="http://arxiv.org/abs/2111.12950"/>
        <updated>2022-01-05T00:39:37.079Z</updated>
        <summary type="html"><![CDATA[This paper proposes an information-theoretic loss for learning deep neural
networks. We propose a loss function based on the Information Bottleneck
principle and a max-margin loss with an aim to increase the class separability
in the embedded space. While deep neural network models have excelled in
supervised learning tasks with large-scale labeled data available, they are
prone to practical issues in testing samples outside of classes shown in
training, e.g., anomaly detection and out-of-distribution detection. In such
tasks, it is not sufficient to merely discriminate between known classes. Our
intuition is to represent the known classes in compact and separated embedded
regions in order to decrease the possibility of known and unseen classes
largely overlapping in the embedded space. We show that the IB-based loss
function reflects the inter-class distances as well as the compactness within
classes, thus will extend the extending models of the existing deep data
description models. Our empirical study shows that the proposed model improves
the segmentation of normal classes in the deep feature space which contributes
to identifying the out-of-distribution samples.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ando_S/0/1/0/all/0/1"&gt;Shin Ando&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rank-1 Similarity Matrix Decomposition For Modeling Changes in Antivirus Consensus Through Time. (arXiv:2201.00757v1 [cs.CR])]]></title>
        <id>http://arxiv.org/abs/2201.00757</id>
        <link href="http://arxiv.org/abs/2201.00757"/>
        <updated>2022-01-05T00:39:37.078Z</updated>
        <summary type="html"><![CDATA[Although groups of strongly correlated antivirus engines are known to exist,
at present there is limited understanding of how or why these correlations came
to be. Using a corpus of 25 million VirusTotal reports representing over a
decade of antivirus scan data, we challenge prevailing wisdom that these
correlations primarily originate from "first-order" interactions such as
antivirus vendors copying the labels of leading vendors. We introduce the
Temporal Rank-1 Similarity Matrix decomposition (R1SM-T) in order to
investigate the origins of these correlations and to model how consensus
amongst antivirus engines changes over time. We reveal that first-order
interactions do not explain as much behavior in antivirus correlation as
previously thought, and that the relationships between antivirus engines are
highly volatile. We make recommendations on items in need of future study and
consideration based on our findings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Joyce_R/0/1/0/all/0/1"&gt;Robert J. Joyce&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1"&gt;Edward Raff&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1"&gt;Charles Nicholas&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Feature matching as improved transfer learning technique for wearable EEG. (arXiv:2201.00644v1 [eess.SP])]]></title>
        <id>http://arxiv.org/abs/2201.00644</id>
        <link href="http://arxiv.org/abs/2201.00644"/>
        <updated>2022-01-05T00:39:37.076Z</updated>
        <summary type="html"><![CDATA[Objective: With the rapid rise of wearable sleep monitoring devices with
non-conventional electrode configurations, there is a need for automated
algorithms that can perform sleep staging on configurations with small amounts
of labeled data. Transfer learning has the ability to adapt neural network
weights from a source modality (e.g. standard electrode configuration) to a new
target modality (e.g. non-conventional electrode configuration). Methods: We
propose feature matching, a new transfer learning strategy as an alternative to
the commonly used finetuning approach. This method consists of training a model
with larger amounts of data from the source modality and few paired samples of
source and target modality. For those paired samples, the model extracts
features of the target modality, matching these to the features from the
corresponding samples of the source modality. Results: We compare feature
matching to finetuning for three different target domains, with two different
neural network architectures, and with varying amounts of training data.
Particularly on small cohorts (i.e. 2 - 5 labeled recordings in the
non-conventional recording setting), feature matching systematically
outperforms finetuning with mean relative differences in accuracy ranging from
0.4% to 4.7% for the different scenarios and datasets. Conclusion: Our findings
suggest that feature matching outperforms finetuning as a transfer learning
approach, especially in very low data regimes. Significance: As such, we
conclude that feature matching is a promising new method for wearable sleep
staging with novel devices.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Heremans_E/0/1/0/all/0/1"&gt;Elisabeth R. M. Heremans&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Phan_H/0/1/0/all/0/1"&gt;Huy Phan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Ansari_A/0/1/0/all/0/1"&gt;Amir H. Ansari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Borzee_P/0/1/0/all/0/1"&gt;Pascal Borz&amp;#xe9;e&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Buyse_B/0/1/0/all/0/1"&gt;Bertien Buyse&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Testelmans_D/0/1/0/all/0/1"&gt;Dries Testelmans&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Vos_M/0/1/0/all/0/1"&gt;Maarten De Vos&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Applications for Lung Cancer Diagnosis: A systematic review. (arXiv:2201.00227v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2201.00227</id>
        <link href="http://arxiv.org/abs/2201.00227"/>
        <updated>2022-01-05T00:39:37.075Z</updated>
        <summary type="html"><![CDATA[Lung cancer has been one of the most prevalent disease in recent years.
According to the research of this field, more than 200,000 cases are identified
each year in the US. Uncontrolled multiplication and growth of the lung cells
result in malignant tumour formation. Recently, deep learning algorithms,
especially Convolutional Neural Networks (CNN), have become a superior way to
automatically diagnose disease. The purpose of this article is to review
different models that lead to different accuracy and sensitivity in the
diagnosis of early-stage lung cancer and to help physicians and researchers in
this field. The main purpose of this work is to identify the challenges that
exist in lung cancer based on deep learning. The survey is systematically
written that combines regular mapping and literature review to review 32
conference and journal articles in the field from 2016 to 2021. After analysing
and reviewing the articles, the questions raised in the articles are being
answered. This research is superior to other review articles in this field due
to the complete review of relevant articles and systematic write up.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Hosseini_H/0/1/0/all/0/1"&gt;Hesamoddin Hosseini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Monsefi_R/0/1/0/all/0/1"&gt;Reza Monsefi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Shadroo_S/0/1/0/all/0/1"&gt;Shabnam Shadroo&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization Bounds for Noisy Iterative Algorithms Using Properties of Additive Noise Channels. (arXiv:2102.02976v3 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.02976</id>
        <link href="http://arxiv.org/abs/2102.02976"/>
        <updated>2022-01-05T00:39:37.075Z</updated>
        <summary type="html"><![CDATA[Machine learning models trained by different optimization algorithms under
different data distributions can exhibit distinct generalization behaviors. In
this paper, we analyze the generalization of models trained by noisy iterative
algorithms. We derive distribution-dependent generalization bounds by
connecting noisy iterative algorithms to additive noise channels found in
communication and information theory. Our generalization bounds shed light on
several applications, including differentially private stochastic gradient
descent (DP-SGD), federated learning, and stochastic gradient Langevin dynamics
(SGLD). We demonstrate our bounds through numerical experiments, showing that
they can help understand recent empirical observations of the generalization
phenomena of neural networks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Wang_H/0/1/0/all/0/1"&gt;Hao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Gao_R/0/1/0/all/0/1"&gt;Rui Gao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Calmon_F/0/1/0/all/0/1"&gt;Flavio P. Calmon&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provable Meta-Learning of Linear Representations. (arXiv:2002.11684v5 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2002.11684</id>
        <link href="http://arxiv.org/abs/2002.11684"/>
        <updated>2022-01-05T00:39:37.065Z</updated>
        <summary type="html"><![CDATA[Meta-learning, or learning-to-learn, seeks to design algorithms that can
utilize previous experience to rapidly learn new skills or adapt to new
environments. Representation learning -- a key tool for performing
meta-learning -- learns a data representation that can transfer knowledge
across multiple tasks, which is essential in regimes where data is scarce.
Despite a recent surge of interest in the practice of meta-learning, the
theoretical underpinnings of meta-learning algorithms are lacking, especially
in the context of learning transferable representations. In this paper, we
focus on the problem of multi-task linear regression -- in which multiple
linear regression models share a common, low-dimensional linear representation.
Here, we provide provably fast, sample-efficient algorithms to address the dual
challenges of (1) learning a common set of features from multiple, related
tasks, and (2) transferring this knowledge to new, unseen tasks. Both are
central to the general problem of meta-learning. Finally, we complement these
results by providing information-theoretic lower bounds on the sample
complexity of learning these linear features.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tripuraneni_N/0/1/0/all/0/1"&gt;Nilesh Tripuraneni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1"&gt;Chi Jin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1"&gt;Michael I. Jordan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Audiogmenter: a MATLAB Toolbox for Audio Data Augmentation. (arXiv:1912.05472v4 [eess.AS] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1912.05472</id>
        <link href="http://arxiv.org/abs/1912.05472"/>
        <updated>2022-01-05T00:39:37.064Z</updated>
        <summary type="html"><![CDATA[Audio data augmentation is a key step in training deep neural networks for
solving audio classification tasks. In this paper, we introduce Audiogmenter, a
novel audio data augmentation library in MATLAB. We provide 15 different
augmentation algorithms for raw audio data and 8 for spectrograms. We
efficiently implemented several augmentation techniques whose usefulness has
been extensively proved in the literature. To the best of our knowledge, this
is the largest MATLAB audio data augmentation library freely available. We
validate the efficiency of our algorithms evaluating them on the ESC-50
dataset. The toolbox and its documentation can be downloaded at
https://github.com/LorisNanni/Audiogmenter.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Maguolo_G/0/1/0/all/0/1"&gt;Gianluca Maguolo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Paci_M/0/1/0/all/0/1"&gt;Michelangelo Paci&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Nanni_L/0/1/0/all/0/1"&gt;Loris Nanni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Bonan_L/0/1/0/all/0/1"&gt;Ludovico Bonan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[VDPC: Variational Density Peak Clustering Algorithm. (arXiv:2201.00641v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00641</id>
        <link href="http://arxiv.org/abs/2201.00641"/>
        <updated>2022-01-05T00:39:37.063Z</updated>
        <summary type="html"><![CDATA[The widely applied density peak clustering (DPC) algorithm makes an intuitive
cluster formation assumption that cluster centers are often surrounded by data
points with lower local density and far away from other data points with higher
local density. However, this assumption suffers from one limitation that it is
often problematic when identifying clusters with lower density because they
might be easily merged into other clusters with higher density. As a result,
DPC may not be able to identify clusters with variational density. To address
this issue, we propose a variational density peak clustering (VDPC) algorithm,
which is designed to systematically and autonomously perform the clustering
task on datasets with various types of density distributions. Specifically, we
first propose a novel method to identify the representatives among all data
points and construct initial clusters based on the identified representatives
for further analysis of the clusters' property. Furthermore, we divide all data
points into different levels according to their local density and propose a
unified clustering framework by combining the advantages of both DPC and
DBSCAN. Thus, all the identified initial clusters spreading across different
density levels are systematically processed to form the final clusters. To
evaluate the effectiveness of the proposed VDPC algorithm, we conduct extensive
experiments using 20 datasets including eight synthetic, six real-world and six
image datasets. The experimental results show that VDPC outperforms two
classical algorithms (i.e., DPC and DBSCAN) and four state-of-the-art extended
DPC algorithms.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yizhang Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1"&gt;Di Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1"&gt;You Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"&gt;Xiaofeng Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Quek_C/0/1/0/all/0/1"&gt;Chai Quek&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SLURP: Side Learning Uncertainty for Regression Problems. (arXiv:2110.11182v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.11182</id>
        <link href="http://arxiv.org/abs/2110.11182"/>
        <updated>2022-01-05T00:39:37.062Z</updated>
        <summary type="html"><![CDATA[It has become critical for deep learning algorithms to quantify their output
uncertainties to satisfy reliability constraints and provide accurate results.
Uncertainty estimation for regression has received less attention than
classification due to the more straightforward standardized output of the
latter class of tasks and their high importance. However, regression problems
are encountered in a wide range of applications in computer vision. We propose
SLURP, a generic approach for regression uncertainty estimation via a side
learner that exploits the output and the intermediate representations generated
by the main task model. We test SLURP on two critical regression tasks in
computer vision: monocular depth and optical flow estimation. In addition, we
conduct exhaustive benchmarks comprising transfer to different datasets and the
addition of aleatoric noise. The results show that our proposal is generic and
readily applicable to various regression problems and has a low computational
cost with respect to existing solutions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1"&gt;Xuanlong Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Franchi_G/0/1/0/all/0/1"&gt;Gianni Franchi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Aldea_E/0/1/0/all/0/1"&gt;Emanuel Aldea&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Continuous Submodular Maximization: Boosting via Non-oblivious Function. (arXiv:2201.00703v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00703</id>
        <link href="http://arxiv.org/abs/2201.00703"/>
        <updated>2022-01-05T00:39:37.061Z</updated>
        <summary type="html"><![CDATA[In this paper, we revisit the constrained and stochastic continuous
submodular maximization in both offline and online settings. For each
$\gamma$-weakly DR-submodular function $f$, we use the factor-revealing
optimization equation to derive an optimal auxiliary function $F$, whose
stationary points provide a $(1-e^{-\gamma})$-approximation to the global
maximum value (denoted as $OPT$) of problem
$\max_{\boldsymbol{x}\in\mathcal{C}}f(\boldsymbol{x})$. Naturally, the
projected (mirror) gradient ascent relied on this non-oblivious function
achieves $(1-e^{-\gamma}-\epsilon^{2})OPT-\epsilon$ after $O(1/\epsilon^{2})$
iterations, beating the traditional
$(\frac{\gamma^{2}}{1+\gamma^{2}})$-approximation gradient ascent
\citep{hassani2017gradient} for submodular maximization. Similarly, based on
$F$, the classical Frank-Wolfe algorithm equipped with variance reduction
technique \citep{mokhtari2018conditional} also returns a solution with
objective value larger than $(1-e^{-\gamma}-\epsilon^{2})OPT-\epsilon$ after
$O(1/\epsilon^{3})$ iterations. In the online setting, we first consider the
adversarial delays for stochastic gradient feedback, under which we propose a
boosting online gradient algorithm with the same non-oblivious search,
achieving a regret of $\sqrt{D}$ (where $D$ is the sum of delays of gradient
feedback) against a $(1-e^{-\gamma})$-approximation to the best feasible
solution in hindsight. Finally, extensive numerical experiments demonstrate the
efficiency of our boosting methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1"&gt;Qixin Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1"&gt;Zengde Deng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"&gt;Zaiyi Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"&gt;Yu Yang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space. (arXiv:2201.00814v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.00814</id>
        <link href="http://arxiv.org/abs/2201.00814"/>
        <updated>2022-01-05T00:39:37.057Z</updated>
        <summary type="html"><![CDATA[This paper explores the feasibility of finding an optimal sub-model from a
vision transformer and introduces a pure vision transformer slimming (ViT-Slim)
framework that can search such a sub-structure from the original model
end-to-end across multiple dimensions, including the input tokens, MHSA and MLP
modules with state-of-the-art performance. Our method is based on a learnable
and unified l1 sparsity constraint with pre-defined factors to reflect the
global importance in the continuous searching space of different dimensions.
The searching process is highly efficient through a single-shot training
scheme. For instance, on DeiT-S, ViT-Slim only takes ~43 GPU hours for
searching process, and the searched structure is flexible with diverse
dimensionalities in different modules. Then, a budget threshold is employed
according to the requirements of accuracy-FLOPs trade-off on running devices,
and a re-training process is performed to obtain the final models. The
extensive experiments show that our ViT-Slim can compress up to 40% of
parameters and 40% FLOPs on various vision transformers while increasing the
accuracy by ~0.6% on ImageNet. We also demonstrate the advantage of our
searched models on several downstream datasets. Our source code will be
publicly available.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chavan_A/0/1/0/all/0/1"&gt;Arnav Chavan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1"&gt;Zhiqiang Shen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"&gt;Zhuang Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"&gt;Zechun Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1"&gt;Kwang-Ting Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1"&gt;Eric Xing&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Detecting Misclassification Errors in Neural Networks with a Gaussian Process Model. (arXiv:2010.02065v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.02065</id>
        <link href="http://arxiv.org/abs/2010.02065"/>
        <updated>2022-01-05T00:39:37.056Z</updated>
        <summary type="html"><![CDATA[As neural network classifiers are deployed in real-world applications, it is
crucial that their failures can be detected reliably. One practical solution is
to assign confidence scores to each prediction, then use these scores to filter
out possible misclassifications. However, existing confidence metrics are not
yet sufficiently reliable for this role. This paper presents a new framework
that produces a quantitative metric for detecting misclassification errors.
This framework, RED, builds an error detector on top of the base classifier and
estimates uncertainty of the detection scores using Gaussian Processes.
Experimental comparisons with other error detection methods on 125 UCI datasets
demonstrate that this approach is effective. Further implementations on two
probabilistic base classifiers and two large deep learning architecture in
vision tasks further confirm that the method is robust and scalable. Third, an
empirical analysis of RED with out-of-distribution and adversarial samples
shows that the method can be used not only to detect errors but also to
understand where they come from. RED can thereby be used to improve
trustworthiness of neural network classifiers more broadly in the future.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1"&gt;Xin Qiu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1"&gt;Risto Miikkulainen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine learning moment closure models for the radiative transfer equation I: directly learning a gradient based closure. (arXiv:2105.05690v2 [math.NA] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.05690</id>
        <link href="http://arxiv.org/abs/2105.05690"/>
        <updated>2022-01-05T00:39:37.056Z</updated>
        <summary type="html"><![CDATA[In this paper, we take a data-driven approach and apply machine learning to
the moment closure problem for radiative transfer equation in slab geometry.
Instead of learning the unclosed high order moment, we propose to directly
learn the gradient of the high order moment using neural networks. This new
approach is consistent with the exact closure we derive for the free streaming
limit and also provides a natural output normalization. A variety of benchmark
tests, including the variable scattering problem, the Gaussian source problem
with both periodic and reflecting boundaries, and the two-material problem,
show both good accuracy and generalizability of our machine learning closure
model.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Huang_J/0/1/0/all/0/1"&gt;Juntao Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Cheng_Y/0/1/0/all/0/1"&gt;Yingda Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Christlieb_A/0/1/0/all/0/1"&gt;Andrew J. Christlieb&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Roberts_L/0/1/0/all/0/1"&gt;Luke F. Roberts&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Estimating Causal Effects of Multi-Aspect Online Reviews with Multi-Modal Proxies. (arXiv:2112.10274v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.10274</id>
        <link href="http://arxiv.org/abs/2112.10274"/>
        <updated>2022-01-05T00:39:37.055Z</updated>
        <summary type="html"><![CDATA[Online reviews enable consumers to engage with companies and provide
important feedback. Due to the complexity of the high-dimensional text, these
reviews are often simplified as a single numerical score, e.g., ratings or
sentiment scores. This work empirically examines the causal effects of
user-generated online reviews on a granular level: we consider multiple
aspects, e.g., the Food and Service of a restaurant. Understanding consumers'
opinions toward different aspects can help evaluate business performance in
detail and strategize business operations effectively. Specifically, we aim to
answer interventional questions such as What will the restaurant popularity be
if the quality w.r.t. its aspect Service is increased by 10%? The defining
challenge of causal inference with observational data is the presence of
"confounder", which might not be observed or measured, e.g., consumers'
preference to food type, rendering the estimated effects biased and
high-variance. To address this challenge, we have recourse to the multi-modal
proxies such as the consumer profile information and interactions between
consumers and businesses. We show how to effectively leverage the rich
information to identify and estimate causal effects of multiple aspects
embedded in online reviews. Empirical evaluations on synthetic and real-world
data corroborate the efficacy and shed light on the actionable insight of the
proposed approach.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1"&gt;Lu Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1"&gt;Ruocheng Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1"&gt;Huan Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Attention Score Based Attacker for Black-box NLP Classifier. (arXiv:2112.11660v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.11660</id>
        <link href="http://arxiv.org/abs/2112.11660"/>
        <updated>2022-01-05T00:39:37.055Z</updated>
        <summary type="html"><![CDATA[Deep neural networks have a wide range of applications in solving various
real-world tasks and have achieved satisfactory results, in domains such as
computer vision, image classification, and natural language processing.
Meanwhile, the security and robustness of neural networks have become
imperative, as diverse researches have shown the vulnerable aspects of neural
networks. Case in point, in Natural language processing tasks, the neural
network may be fooled by an attentively modified text, which has a high
similarity to the original one. As per previous research, most of the studies
are focused on the image domain; Different from image adversarial attacks, the
text is represented in a discrete sequence, traditional image attack methods
are not applicable in the NLP field. In this paper, we propose a word-level NLP
sentiment classifier attack model, which includes a self-attention
mechanism-based word selection method and a greedy search algorithm for word
substitution. We experiment with our attack model by attacking GRU and 1D-CNN
victim models on IMDB datasets. Experimental results demonstrate that our model
achieves a higher attack success rate and more efficient than previous methods
due to the efficient word selection algorithms are employed and minimized the
word substitute number. Also, our model is transferable, which can be used in
the image domain with several modifications.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yueyang Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1"&gt;Hunmin Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1"&gt;Zhipeng Cai&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Execute Order 66: Targeted Data Poisoning for Reinforcement Learning. (arXiv:2201.00762v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00762</id>
        <link href="http://arxiv.org/abs/2201.00762"/>
        <updated>2022-01-05T00:39:37.051Z</updated>
        <summary type="html"><![CDATA[Data poisoning for reinforcement learning has historically focused on general
performance degradation, and targeted attacks have been successful via
perturbations that involve control of the victim's policy and rewards. We
introduce an insidious poisoning attack for reinforcement learning which causes
agent misbehavior only at specific target states - all while minimally
modifying a small fraction of training observations without assuming any
control over policy or reward. We accomplish this by adapting a recent
technique, gradient alignment, to reinforcement learning. We test our method
and demonstrate success in two Atari games of varying difficulty.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Foley_H/0/1/0/all/0/1"&gt;Harrison Foley&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fowl_L/0/1/0/all/0/1"&gt;Liam Fowl&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1"&gt;Tom Goldstein&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1"&gt;Gavin Taylor&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Online Regularization towards Always-Valid High-Dimensional Dynamic Pricing. (arXiv:2007.02470v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2007.02470</id>
        <link href="http://arxiv.org/abs/2007.02470"/>
        <updated>2022-01-05T00:39:37.050Z</updated>
        <summary type="html"><![CDATA[Devising dynamic pricing policy with always valid online statistical learning
procedure is an important and as yet unresolved problem. Most existing dynamic
pricing policy, which focus on the faithfulness of adopted customer choice
models, exhibit a limited capability for adapting the online uncertainty of
learned statistical model during pricing process. In this paper, we propose a
novel approach for designing dynamic pricing policy based regularized online
statistical learning with theoretical guarantees. The new approach overcomes
the challenge of continuous monitoring of online Lasso procedure and possesses
several appealing properties. In particular, we make the decisive observation
that the always-validity of pricing decisions builds and thrives on the online
regularization scheme. Our proposed online regularization scheme equips the
proposed optimistic online regularized maximum likelihood pricing (OORMLP)
pricing policy with three major advantages: encode market noise knowledge into
pricing process optimism; empower online statistical learning with
always-validity over all decision points; envelop prediction error process with
time-uniform non-asymptotic oracle inequalities. This type of non-asymptotic
inference results allows us to design more sample-efficient and robust dynamic
pricing algorithms in practice. In theory, the proposed OORMLP algorithm
exploits the sparsity structure of high-dimensional models and secures a
logarithmic regret in a decision horizon. These theoretical advances are made
possible by proposing an optimistic online Lasso procedure that resolves
dynamic pricing problems at the process level, based on a novel use of
non-asymptotic martingale concentration. In experiments, we evaluate OORMLP in
different synthetic and real pricing problem settings, and demonstrate that
OORMLP advances the state-of-the-art methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1"&gt;Chi-Hua Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zhanyu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1"&gt;Will Wei Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1"&gt;Guang Cheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Randomized Signature Layers for Signal Extraction in Time Series Data. (arXiv:2201.00384v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00384</id>
        <link href="http://arxiv.org/abs/2201.00384"/>
        <updated>2022-01-05T00:39:37.042Z</updated>
        <summary type="html"><![CDATA[Time series analysis is a widespread task in Natural Sciences, Social
Sciences, and Engineering. A fundamental problem is finding an expressive yet
efficient-to-compute representation of the input time series to use as a
starting point to perform arbitrary downstream tasks. In this paper, we build
upon recent works that use the Signature of a path as a feature map and
investigate a computationally efficient technique to approximate these features
based on linear random projections. We present several theoretical results to
justify our approach and empirically validate that our random projections can
effectively retrieve the underlying Signature of a path. We show the surprising
performance of the proposed random features on several tasks, including (1)
mapping the controls of stochastic differential equations to the corresponding
solutions and (2) using the Randomized Signatures as time series representation
for classification tasks. When compared to corresponding truncated Signature
approaches, our Randomizes Signatures are more computationally efficient in
high dimensions and often lead to better accuracy and faster training. Besides
providing a new tool to extract Signatures and further validating the high
level of expressiveness of such features, we believe our results provide
interesting conceptual links between several existing research areas,
suggesting new intriguing directions for future investigations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Compagnoni_E/0/1/0/all/0/1"&gt;Enea Monzio Compagnoni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Biggio_L/0/1/0/all/0/1"&gt;Luca Biggio&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Orvieto_A/0/1/0/all/0/1"&gt;Antonio Orvieto&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1"&gt;Thomas Hofmann&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Teichmann_J/0/1/0/all/0/1"&gt;Josef Teichmann&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural combinatorial optimization beyond the TSP: Existing architectures under-represent graph structure. (arXiv:2201.00668v1 [cs.AI])]]></title>
        <id>http://arxiv.org/abs/2201.00668</id>
        <link href="http://arxiv.org/abs/2201.00668"/>
        <updated>2022-01-05T00:39:37.042Z</updated>
        <summary type="html"><![CDATA[Recent years have witnessed the promise that reinforcement learning, coupled
with Graph Neural Network (GNN) architectures, could learn to solve hard
combinatorial optimization problems: given raw input data and an evaluator to
guide the process, the idea is to automatically learn a policy able to return
feasible and high-quality outputs. Recent work have shown promising results but
the latter were mainly evaluated on the travelling salesman problem (TSP) and
similar abstract variants such as Split Delivery Vehicle Routing Problem
(SDVRP). In this paper, we analyze how and whether recent neural architectures
can be applied to graph problems of practical importance. We thus set out to
systematically "transfer" these architectures to the Power and Channel
Allocation Problem (PCAP), which has practical relevance for, e.g., radio
resource allocation in wireless networks. Our experimental results suggest that
existing architectures (i) are still incapable of capturing graph structural
features and (ii) are not suitable for problems where the actions on the graph
change the graph attributes. On a positive note, we show that augmenting the
structural representation of problems with Distance Encoding is a promising
step towards the still-ambitious goal of learning multi-purpose autonomous
solvers.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Boffa_M/0/1/0/all/0/1"&gt;Matteo Boffa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Houidi_Z/0/1/0/all/0/1"&gt;Zied Ben Houidi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krolikowski_J/0/1/0/all/0/1"&gt;Jonatan Krolikowski&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rossi_D/0/1/0/all/0/1"&gt;Dario Rossi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Momentum Contrastive Voxel-wise Representation Learning for Semi-supervised Volumetric Medical Image Segmentation. (arXiv:2105.07059v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.07059</id>
        <link href="http://arxiv.org/abs/2105.07059"/>
        <updated>2022-01-05T00:39:37.038Z</updated>
        <summary type="html"><![CDATA[Automated segmentation in medical image analysis is a challenging task that
requires a large amount of manually labeled data. However, manually annotating
medical data is often laborious, and most existing learning-based approaches
fail to accurately delineate object boundaries without effective geometric
constraints. Contrastive learning, a sub-area of self-supervised learning, has
recently been noted as a promising direction in multiple application fields. In
this work, we present a novel Contrastive Voxel-wise Representation
Distillation (CVRD) method with geometric constraints to learn global-local
visual representations for volumetric medical image segmentation with limited
annotations. Our framework can effectively learn global and local features by
capturing 3D spatial context and rich anatomical information. Specifically, we
introduce a voxel-to-volume contrastive algorithm to learn global information
from 3D images, and propose to perform local voxel-to-voxel distillation to
explicitly make use of local cues in the embedding space. Moreover, we
integrate an elastic interaction-based active contour model as a geometric
regularization term to enable fast and reliable object delineations in an
end-to-end learning manner. Results on the Atrial Segmentation Challenge
dataset demonstrate superiority of our proposed scheme, especially in a setting
with a very limited number of annotated data. The code will be available at
https://github.com/charlesyou999648/CVRD.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1"&gt;Chenyu You&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1"&gt;Ruihan Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Staib_L/0/1/0/all/0/1"&gt;Lawrence Staib&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Duncan_J/0/1/0/all/0/1"&gt;James S. Duncan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Contrastive Learning Using Negative Samples with Diminished Semantics. (arXiv:2110.14189v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.14189</id>
        <link href="http://arxiv.org/abs/2110.14189"/>
        <updated>2022-01-05T00:39:37.035Z</updated>
        <summary type="html"><![CDATA[Unsupervised learning has recently made exceptional progress because of the
development of more effective contrastive learning methods. However, CNNs are
prone to depend on low-level features that humans deem non-semantic. This
dependency has been conjectured to induce a lack of robustness to image
perturbations or domain shift. In this paper, we show that by generating
carefully designed negative samples, contrastive learning can learn more robust
representations with less dependence on such features. Contrastive learning
utilizes positive pairs that preserve semantic information while perturbing
superficial features in the training images. Similarly, we propose to generate
negative samples in a reversed way, where only the superfluous instead of the
semantic features are preserved. We develop two methods, texture-based and
patch-based augmentations, to generate negative samples. These samples achieve
better generalization, especially under out-of-domain settings. We also analyze
our method and the generated texture-based samples, showing that texture
features are indispensable in classifying particular ImageNet classes and
especially finer classes. We also show that model bias favors texture and shape
features differently under different test settings. Our code, trained models,
and ImageNet-Texture dataset can be found at
https://github.com/SongweiGe/Contrastive-Learning-with-Non-Semantic-Negatives.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1"&gt;Songwei Ge&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1"&gt;Shlok Mishra&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"&gt;Haohan Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1"&gt;Chun-Liang Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1"&gt;David Jacobs&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Snowflake: Scaling GNNs to High-Dimensional Continuous Control via Parameter Freezing. (arXiv:2103.01009v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.01009</id>
        <link href="http://arxiv.org/abs/2103.01009"/>
        <updated>2022-01-05T00:39:37.012Z</updated>
        <summary type="html"><![CDATA[Recent research has shown that graph neural networks (GNNs) can learn
policies for locomotion control that are as effective as a typical multi-layer
perceptron (MLP), with superior transfer and multi-task performance (Wang et
al., 2018; Huang et al., 2020). Results have so far been limited to training on
small agents, with the performance of GNNs deteriorating rapidly as the number
of sensors and actuators grows. A key motivation for the use of GNNs in the
supervised learning setting is their applicability to large graphs, but this
benefit has not yet been realised for locomotion control. We identify the
weakness with a common GNN architecture that causes this poor scaling:
overfitting in the MLPs within the network that encode, decode, and propagate
messages. To combat this, we introduce Snowflake, a GNN training method for
high-dimensional continuous control that freezes parameters in parts of the
network that suffer from overfitting. Snowflake significantly boosts the
performance of GNNs for locomotion control on large agents, now matching the
performance of MLPs, and with superior transfer properties.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Blake_C/0/1/0/all/0/1"&gt;Charlie Blake&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kurin_V/0/1/0/all/0/1"&gt;Vitaly Kurin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Igl_M/0/1/0/all/0/1"&gt;Maximilian Igl&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1"&gt;Shimon Whiteson&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rethinking the Implementation Tricks and Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2102.03479v18 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.03479</id>
        <link href="http://arxiv.org/abs/2102.03479"/>
        <updated>2022-01-05T00:39:37.011Z</updated>
        <summary type="html"><![CDATA[Many complex multi-agent systems such as robot swarms control and autonomous
vehicle coordination can be modeled as Multi-Agent Reinforcement Learning
(MARL) tasks. QMIX, a widely popular MARL algorithm, has been used as a
baseline for the benchmark environments, e.g., Starcraft Multi-Agent Challenge
(SMAC), Difficulty-Enhanced Predator-Prey (DEPP). Recent variants of QMIX
target relaxing the monotonicity constraint of QMIX, allowing for performance
improvement in SMAC. In this paper, we investigate the code-level optimizations
of these variants and the monotonicity constraint. (1) We find that such
improvements of the variants are significantly affected by various code-level
optimizations. (2) The experiment results show that QMIX with normalized
optimizations outperforms other works in SMAC; (3) beyond the common wisdom
from these works, the monotonicity constraint can improve sample efficiency in
SMAC and DEPP. We also discuss why monotonicity constraints work well in purely
cooperative tasks with a theoretical analysis. We open-source the code at
\url{https://github.com/hijkzzz/pymarl2}.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1"&gt;Jian Hu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1"&gt;Siyang Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Harding_S/0/1/0/all/0/1"&gt;Seth Austin Harding&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1"&gt;Haibin Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1"&gt;Shih-wei Liao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Cluster-Based Trip Prediction Graph Neural Network Model for Bike Sharing Systems. (arXiv:2201.00720v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00720</id>
        <link href="http://arxiv.org/abs/2201.00720"/>
        <updated>2022-01-05T00:39:37.010Z</updated>
        <summary type="html"><![CDATA[Bike Sharing Systems (BSSs) are emerging as an innovative transportation
service. Ensuring the proper functioning of a BSS is crucial given that these
systems are committed to eradicating many of the current global concerns, by
promoting environmental and economic sustainability and contributing to
improving the life quality of the population. Good knowledge of users'
transition patterns is a decisive contribution to the quality and operability
of the service. The analogous and unbalanced users' transition patterns cause
these systems to suffer from bicycle imbalance, leading to a drastic customer
loss in the long term. Strategies for bicycle rebalancing become important to
tackle this problem and for this, bicycle traffic prediction is essential, as
it allows to operate more efficiently and to react in advance. In this work, we
propose a bicycle trips predictor based on Graph Neural Network embeddings,
taking into consideration station groupings, meteorology conditions,
geographical distances, and trip patterns. We evaluated our approach in the New
York City BSS (CitiBike) data and compared it with four baselines, including
the non-clustered approach. To address our problem's specificities, we
developed the Adaptive Transition Constraint Clustering Plus (AdaTC+)
algorithm, eliminating shortcomings of previous work. Our experiments evidence
the clustering pertinence (88% accuracy compared with 83% without clustering)
and which clustering technique best suits this problem. Accuracy on the Link
Prediction task is always higher for AdaTC+ than benchmark clustering methods
when the stations are the same, while not degrading performance when the
network is upgraded, in a mismatch with the trained model.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tavares_B/0/1/0/all/0/1"&gt;B&amp;#xe1;rbara Tavares&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Soares_C/0/1/0/all/0/1"&gt;Cl&amp;#xe1;udia Soares&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Marques_M/0/1/0/all/0/1"&gt;Manuel Marques&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AutoDES: AutoML Pipeline Generation of Classification with Dynamic Ensemble Strategy Selection. (arXiv:2201.00207v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00207</id>
        <link href="http://arxiv.org/abs/2201.00207"/>
        <updated>2022-01-05T00:39:37.005Z</updated>
        <summary type="html"><![CDATA[Automating machine learning has achieved remarkable technological
developments in recent years, and building an automated machine learning
pipeline is now an essential task. The model ensemble is the technique of
combining multiple models to get a better and more robust model. However,
existing automated machine learning tends to be simplistic in handling the
model ensemble, where the ensemble strategy is fixed, such as stacked
generalization. There have been many techniques on different ensemble methods,
especially ensemble selection, and the fixed ensemble strategy limits the upper
limit of the model's performance. In this article, we present a novel framework
for automated machine learning. Our framework incorporates advances in dynamic
ensemble selection, and to our best knowledge, our approach is the first in the
field of AutoML to search and optimize ensemble strategies. In the comparison
experiments, our method outperforms the state-of-the-art automated machine
learning frameworks with the same CPU time in 42 classification datasets from
the OpenML platform. Ablation experiments on our framework validate the
effectiveness of our proposed method.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1"&gt;Yunpu Zhao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Characterizing Speech Adversarial Examples Using Self-Attention U-Net Enhancement. (arXiv:2003.13917v2 [eess.AS] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2003.13917</id>
        <link href="http://arxiv.org/abs/2003.13917"/>
        <updated>2022-01-05T00:39:37.005Z</updated>
        <summary type="html"><![CDATA[Recent studies have highlighted adversarial examples as ubiquitous threats to
the deep neural network (DNN) based speech recognition systems. In this work,
we present a U-Net based attention model, U-Net$_{At}$, to enhance adversarial
speech signals. Specifically, we evaluate the model performance by
interpretable speech recognition metrics and discuss the model performance by
the augmented adversarial training. Our experiments show that our proposed
U-Net$_{At}$ improves the perceptual evaluation of speech quality (PESQ) from
1.13 to 2.78, speech transmission index (STI) from 0.65 to 0.75, short-term
objective intelligibility (STOI) from 0.83 to 0.96 on the task of speech
enhancement with adversarial speech examples. We conduct experiments on the
automatic speech recognition (ASR) task with adversarial audio attacks. We find
that (i) temporal features learned by the attention network are capable of
enhancing the robustness of DNN based ASR models; (ii) the generalization power
of DNN based ASR model could be enhanced by applying adversarial training with
an additive adversarial data augmentation. The ASR metric on word-error-rates
(WERs) shows that there is an absolute 2.22 $\%$ decrease under gradient-based
perturbation, and an absolute 2.03 $\%$ decrease, under evolutionary-optimized
perturbation, which suggests that our enhancement models with adversarial
training can further secure a resilient ASR system.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Yang_C/0/1/0/all/0/1"&gt;Chao-Han Huck Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Qi_J/0/1/0/all/0/1"&gt;Jun Qi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Chen_P/0/1/0/all/0/1"&gt;Pin-Yu Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Ma_X/0/1/0/all/0/1"&gt;Xiaoli Ma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Lee_C/0/1/0/all/0/1"&gt;Chin-Hui Lee&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Near-Optimal Algorithm for Debiasing Trained Machine Learning Models. (arXiv:2106.12887v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.12887</id>
        <link href="http://arxiv.org/abs/2106.12887"/>
        <updated>2022-01-05T00:39:37.004Z</updated>
        <summary type="html"><![CDATA[We present a scalable post-processing algorithm for debiasing trained models,
including deep neural networks (DNNs), which we prove to be near-optimal by
bounding its excess Bayes risk. We empirically validate its advantages on
standard benchmark datasets across both classical algorithms as well as modern
DNN architectures and demonstrate that it outperforms previous post-processing
methods while performing on par with in-processing. In addition, we show that
the proposed algorithm is particularly effective for models trained at scale
where post-processing is a natural and practical choice.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Alabdulmohsin_I/0/1/0/all/0/1"&gt;Ibrahim Alabdulmohsin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1"&gt;Mario Lucic&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DDPG car-following model with real-world human driving experience in CARLA. (arXiv:2112.14602v1 [cs.RO] CROSS LISTED)]]></title>
        <id>http://arxiv.org/abs/2112.14602</id>
        <link href="http://arxiv.org/abs/2112.14602"/>
        <updated>2022-01-05T00:39:37.003Z</updated>
        <summary type="html"><![CDATA[In the autonomous driving field, the fusion of human knowledge into Deep
Reinforcement Learning (DRL) is often based on the human demonstration recorded
in the simulated environment. This limits the generalization and the
feasibility of application in real-world traffic. We proposed a two-stage DRL
method, that learns from real-world human driving to achieve performance that
is superior to the pure DRL agent. Training a DRL agent is done within a
framework for CARLA with Robot Operating System (ROS). For evaluation, we
designed different real-world driving scenarios to compare the proposed
two-stage DRL agent with the pure DRL agent. After extracting the 'good'
behavior from the human driver, such as anticipation in a signalized
intersection, the agent becomes more efficient and drives safer, which makes
this autonomous agent more adapt to Human-Robot Interaction (HRI) traffic.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1"&gt;Dianzhao Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Okhrin_O/0/1/0/all/0/1"&gt;Ostap Okhrin&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Embedding of ReLU Networks and an Analysis of their Identifiability. (arXiv:2107.09370v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2107.09370</id>
        <link href="http://arxiv.org/abs/2107.09370"/>
        <updated>2022-01-05T00:39:37.000Z</updated>
        <summary type="html"><![CDATA[Neural networks with the Rectified Linear Unit (ReLU) nonlinearity are
described by a vector of parameters $\theta$, and realized as a piecewise
linear continuous function $R_{\theta}: x \in \mathbb R^{d} \mapsto
R_{\theta}(x) \in \mathbb R^{k}$. Natural scalings and permutations operations
on the parameters $\theta$ leave the realization unchanged, leading to
equivalence classes of parameters that yield the same realization. These
considerations in turn lead to the notion of identifiability -- the ability to
recover (the equivalence class of) $\theta$ from the sole knowledge of its
realization $R_{\theta}$. The overall objective of this paper is to introduce
an embedding for ReLU neural networks of any depth, $\Phi(\theta)$, that is
invariant to scalings and that provides a locally linear parameterization of
the realization of the network. Leveraging these two key properties, we derive
some conditions under which a deep ReLU network is indeed locally identifiable
from the knowledge of the realization on a finite set of samples $x_{i} \in
\mathbb R^{d}$. We study the shallow case in more depth, establishing necessary
and sufficient conditions for the network to be identifiable from a bounded
subset $\mathcal X \subseteq \mathbb R^{d}$.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Stock_P/0/1/0/all/0/1"&gt;Pierre Stock&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gribonval_R/0/1/0/all/0/1"&gt;R&amp;#xe9;mi Gribonval&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Flip Side of the Reweighted Coin: Duality of Adaptive Dropout and Regularization. (arXiv:2106.07769v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.07769</id>
        <link href="http://arxiv.org/abs/2106.07769"/>
        <updated>2022-01-05T00:39:36.997Z</updated>
        <summary type="html"><![CDATA[Among the most successful methods for sparsifying deep (neural) networks are
those that adaptively mask the network weights throughout training. By
examining this masking, or dropout, in the linear case, we uncover a duality
between such adaptive methods and regularization through the so-called
"$\eta$-trick" that casts both as iteratively reweighted optimizations. We show
that any dropout strategy that adapts to the weights in a monotonic way
corresponds to an effective subquadratic regularization penalty, and therefore
leads to sparse solutions. We obtain the effective penalties for several
popular sparsification strategies, which are remarkably similar to classical
penalties commonly used in sparse optimization. Considering variational dropout
as a case study, we demonstrate similar empirical behavior between the adaptive
dropout method and classical methods on the task of deep network
sparsification, validating our theory.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+LeJeune_D/0/1/0/all/0/1"&gt;Daniel LeJeune&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Javadi_H/0/1/0/all/0/1"&gt;Hamid Javadi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1"&gt;Richard G. Baraniuk&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AHAR: Adaptive CNN for Energy-efficient Human Activity Recognition in Low-power Edge Devices. (arXiv:2102.01875v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.01875</id>
        <link href="http://arxiv.org/abs/2102.01875"/>
        <updated>2022-01-05T00:39:36.995Z</updated>
        <summary type="html"><![CDATA[Human Activity Recognition (HAR) is one of the key applications of health
monitoring that requires continuous use of wearable devices to track daily
activities. This paper proposes an Adaptive CNN for energy-efficient HAR (AHAR)
suitable for low-power edge devices. Unlike traditional early exit architecture
that makes the exit decision based on classification confidence, AHAR proposes
a novel adaptive architecture that uses an output block predictor to select a
portion of the baseline architecture to use during the inference phase.
Experimental results show that traditional early exit architectures suffer from
performance loss whereas our adaptive architecture provides similar or better
performance as the baseline one while being energy-efficient. We validate our
methodology in classifying locomotion activities from two datasets- Opportunity
and w-HAR. Compared to the fog/cloud computing approaches for the Opportunity
dataset, our baseline and adaptive architecture shows a comparable weighted F1
score of 91.79%, and 91.57%, respectively. For the w-HAR dataset, our baseline
and adaptive architecture outperforms the state-of-the-art works with a
weighted F1 score of 97.55%, and 97.64%, respectively. Evaluation on real
hardware shows that our baseline architecture is significantly energy-efficient
(422.38x less) and memory-efficient (14.29x less) compared to the works on the
Opportunity dataset. For the w-HAR dataset, our baseline architecture requires
2.04x less energy and 2.18x less memory compared to the state-of-the-art work.
Moreover, experimental results show that our adaptive architecture is 12.32%
(Opportunity) and 11.14% (w-HAR) energy-efficient than our baseline while
providing similar (Opportunity) or better (w-HAR) performance with no
significant memory overhead.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Rashid_N/0/1/0/all/0/1"&gt;Nafiul Rashid&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Demirel_B/0/1/0/all/0/1"&gt;Berken Utku Demirel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Faruque_M/0/1/0/all/0/1"&gt;Mohammad Abdullah Al Faruque&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection. (arXiv:2201.00763v1 [cs.CR])]]></title>
        <id>http://arxiv.org/abs/2201.00763</id>
        <link href="http://arxiv.org/abs/2201.00763"/>
        <updated>2022-01-05T00:39:36.993Z</updated>
        <summary type="html"><![CDATA[Federated Learning (FL) allows multiple clients to collaboratively train a
Neural Network (NN) model on their private data without revealing the data.
Recently, several targeted poisoning attacks against FL have been introduced.
These attacks inject a backdoor into the resulting model that allows
adversary-controlled inputs to be misclassified. Existing countermeasures
against backdoor attacks are inefficient and often merely aim to exclude
deviating models from the aggregation. However, this approach also removes
benign models of clients with deviating data distributions, causing the
aggregated model to perform poorly for such clients.

To address this problem, we propose DeepSight, a novel model filtering
approach for mitigating backdoor attacks. It is based on three novel techniques
that allow to characterize the distribution of data used to train model updates
and seek to measure fine-grained differences in the internal structure and
outputs of NNs. Using these techniques, DeepSight can identify suspicious model
updates. We also develop a scheme that can accurately cluster model updates.
Combining the results of both components, DeepSight is able to identify and
eliminate model clusters containing poisoned models with high attack impact. We
also show that the backdoor contributions of possibly undetected poisoned
models can be effectively mitigated with existing weight clipping-based
defenses. We evaluate the performance and effectiveness of DeepSight and show
that it can mitigate state-of-the-art backdoor attacks with a negligible impact
on the model's performance on benign data.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Rieger_P/0/1/0/all/0/1"&gt;Phillip Rieger&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1"&gt;Thien Duc Nguyen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Miettinen_M/0/1/0/all/0/1"&gt;Markus Miettinen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sadeghi_A/0/1/0/all/0/1"&gt;Ahmad-Reza Sadeghi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Class-Incremental Continual Learning into the eXtended DER-verse. (arXiv:2201.00766v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00766</id>
        <link href="http://arxiv.org/abs/2201.00766"/>
        <updated>2022-01-05T00:39:36.990Z</updated>
        <summary type="html"><![CDATA[The staple of human intelligence is the capability of acquiring knowledge in
a continuous fashion. In stark contrast, Deep Networks forget catastrophically
and, for this reason, the sub-field of Class-Incremental Continual Learning
fosters methods that learn a sequence of tasks incrementally, blending
sequentially-gained knowledge into a comprehensive prediction.

This work aims at assessing and overcoming the pitfalls of our previous
proposal Dark Experience Replay (DER), a simple and effective approach that
combines rehearsal and Knowledge Distillation. Inspired by the way our minds
constantly rewrite past recollections and set expectations for the future, we
endow our model with the abilities to i) revise its replay memory to welcome
novel information regarding past data ii) pave the way for learning yet unseen
classes.

We show that the application of these strategies leads to remarkable
improvements; indeed, the resulting method - termed eXtended-DER (X-DER) -
outperforms the state of the art on both standard benchmarks (such as CIFAR-100
and miniImagenet) and a novel one here introduced. To gain a better
understanding, we further provide extensive ablation studies that corroborate
and extend the findings of our previous research (e.g. the value of Knowledge
Distillation and flatter minima in continual learning setups).]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Boschini_M/0/1/0/all/0/1"&gt;Matteo Boschini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bonicelli_L/0/1/0/all/0/1"&gt;Lorenzo Bonicelli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Buzzega_P/0/1/0/all/0/1"&gt;Pietro Buzzega&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Porrello_A/0/1/0/all/0/1"&gt;Angelo Porrello&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Calderara_S/0/1/0/all/0/1"&gt;Simone Calderara&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning. (arXiv:2106.01854v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.01854</id>
        <link href="http://arxiv.org/abs/2106.01854"/>
        <updated>2022-01-05T00:39:36.990Z</updated>
        <summary type="html"><![CDATA[Large sparse linear systems of equations are ubiquitous in science and
engineering, such as those arising from discretizations of partial differential
equations. Algebraic multigrid (AMG) methods are one of the most common methods
of solving such linear systems, with an extensive body of underlying
mathematical theory. A system of linear equations defines a graph on the set of
unknowns and each level of a multigrid solver requires the selection of an
appropriate coarse graph along with restriction and interpolation operators
that map to and from the coarse representation. The efficiency of the multigrid
solver depends critically on this selection and many selection methods have
been developed over the years. Recently, it has been demonstrated that it is
possible to directly learn the AMG interpolation and restriction operators,
given a coarse graph selection. In this paper, we consider the complementary
problem of learning to coarsen graphs for a multigrid solver, a necessary step
in developing fully learnable AMG methods. We propose a method using a
reinforcement learning (RL) agent based on graph neural networks (GNNs), which
can learn to perform graph coarsening on small planar training graphs and then
be applied to unstructured large planar graphs, assuming bounded node degree.
We demonstrate that this method can produce better coarse graphs than existing
algorithms, even as the graph size increases and other properties of the graph
are varied. We also propose an efficient inference procedure for performing
graph coarsening that results in linear time complexity in graph size.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Taghibakhshi_A/0/1/0/all/0/1"&gt;Ali Taghibakhshi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+MacLachlan_S/0/1/0/all/0/1"&gt;Scott MacLachlan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Olson_L/0/1/0/all/0/1"&gt;Luke Olson&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+West_M/0/1/0/all/0/1"&gt;Matthew West&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges. (arXiv:2201.00680v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00680</id>
        <link href="http://arxiv.org/abs/2201.00680"/>
        <updated>2022-01-05T00:39:36.989Z</updated>
        <summary type="html"><![CDATA[Fifth generation (5G) networks and beyond envisions massive Internet of
Things (IoT) rollout to support disruptive applications such as extended
reality (XR), augmented/virtual reality (AR/VR), industrial automation,
autonomous driving, and smart everything which brings together massive and
diverse IoT devices occupying the radio frequency (RF) spectrum. Along with
spectrum crunch and throughput challenges, such a massive scale of wireless
devices exposes unprecedented threat surfaces. RF fingerprinting is heralded as
a candidate technology that can be combined with cryptographic and zero-trust
security measures to ensure data privacy, confidentiality, and integrity in
wireless networks. Motivated by the relevance of this subject in the future
communication networks, in this work, we present a comprehensive survey of RF
fingerprinting approaches ranging from a traditional view to the most recent
deep learning (DL) based algorithms. Existing surveys have mostly focused on a
constrained presentation of the wireless fingerprinting approaches, however,
many aspects remain untold. In this work, however, we mitigate this by
addressing every aspect - background on signal intelligence (SIGINT),
applications, relevant DL algorithms, systematic literature review of RF
fingerprinting techniques spanning the past two decades, discussion on
datasets, and potential research avenues - necessary to elucidate this topic to
the reader in an encyclopedic manner.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jagannath_A/0/1/0/all/0/1"&gt;Anu Jagannath&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jagannath_J/0/1/0/all/0/1"&gt;Jithin Jagannath&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1"&gt;Prem Sagar Pattanshetty Vasanth Kumar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improved Topic modeling in Twitter through Community Pooling. (arXiv:2201.00690v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2201.00690</id>
        <link href="http://arxiv.org/abs/2201.00690"/>
        <updated>2022-01-05T00:39:36.986Z</updated>
        <summary type="html"><![CDATA[Social networks play a fundamental role in propagation of information and
news. Characterizing the content of the messages becomes vital for different
tasks, like breaking news detection, personalized message recommendation, fake
users detection, information flow characterization and others. However, Twitter
posts are short and often less coherent than other text documents, which makes
it challenging to apply text mining algorithms to these datasets efficiently.
Tweet-pooling (aggregating tweets into longer documents) has been shown to
improve automatic topic decomposition, but the performance achieved in this
task varies depending on the pooling method.

In this paper, we propose a new pooling scheme for topic modeling in Twitter,
which groups tweets whose authors belong to the same community (group of users
who mainly interact with each other but not with other groups) on a user
interaction graph. We present a complete evaluation of this methodology, state
of the art schemes and previous pooling models in terms of the cluster quality,
document retrieval tasks performance and supervised machine learning
classification score. Results show that our Community polling method
outperformed other methods on the majority of metrics in two heterogeneous
datasets, while also reducing the running time. This is useful when dealing
with big amounts of noisy and short user-generated social media texts. Overall,
our findings contribute to an improved methodology for identifying the latent
topics in a Twitter dataset, without the need of modifying the basic machinery
of a topic decomposition model.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Albanese_F/0/1/0/all/0/1"&gt;Federico Albanese&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feuerstein_E/0/1/0/all/0/1"&gt;Esteban Feuerstein&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning cortical representations through perturbed and adversarial dreaming. (arXiv:2109.04261v2 [q-bio.NC] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.04261</id>
        <link href="http://arxiv.org/abs/2109.04261"/>
        <updated>2022-01-05T00:39:36.985Z</updated>
        <summary type="html"><![CDATA[Humans and other animals learn to extract general concepts from sensory
experience without extensive teaching. This ability is thought to be
facilitated by offline states like sleep where previous experiences are
systemically replayed. However, the characteristic creative nature of dreams
suggests that learning semantic representations may go beyond merely replaying
previous experiences. We support this hypothesis by implementing a cortical
architecture inspired by generative adversarial networks (GANs). Learning in
our model is organized across three different global brain states mimicking
wakefulness, NREM and REM sleep, optimizing different, but complementary
objective functions. We train the model on standard datasets of natural images
and evaluate the quality of the learned representations. Our results suggest
that generating new, virtual sensory inputs via adversarial dreaming during REM
sleep is essential for extracting semantic concepts, while replaying episodic
memories via perturbed dreaming during NREM sleep improves the robustness of
latent representations. The model provides a new computational perspective on
sleep states, memory replay and dreams and suggests a cortical implementation
of GANs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/q-bio/1/au:+Deperrois_N/0/1/0/all/0/1"&gt;Nicolas Deperrois&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Petrovici_M/0/1/0/all/0/1"&gt;Mihai A. Petrovici&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Senn_W/0/1/0/all/0/1"&gt;Walter Senn&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Jordan_J/0/1/0/all/0/1"&gt;Jakob Jordan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Game of GANs: Game-Theoretical Models for Generative Adversarial Networks. (arXiv:2106.06976v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.06976</id>
        <link href="http://arxiv.org/abs/2106.06976"/>
        <updated>2022-01-05T00:39:36.981Z</updated>
        <summary type="html"><![CDATA[Generative Adversarial Networks (GANs) have recently attracted considerable
attention in the AI community due to its ability to generate high-quality data
of significant statistical resemblance to real data. Fundamentally, GAN is a
game between two neural networks trained in an adversarial manner to reach a
zero-sum Nash equilibrium profile. Despite the improvement accomplished in GANs
in the last few years, several issues remain to be solved. This paper reviews
the literature on the game theoretic aspects of GANs and addresses how game
theory models can address specific challenges of generative model and improve
the GAN's performance. We first present some preliminaries, including the basic
GAN model and some game theory background. We then present taxonomy to classify
state-of-the-art solutions into three main categories: modified game models,
modified architectures, and modified learning methods. The classification is
based on modifications made to the basic GAN model by proposed game-theoretic
approaches in the literature. We then explore the objectives of each category
and discuss recent works in each category. Finally, we discuss the remaining
challenges in this field and present future research directions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Moghadam_M/0/1/0/all/0/1"&gt;Monireh Mohebbi Moghadam&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Boroomand_B/0/1/0/all/0/1"&gt;Bahar Boroomand&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jalali_M/0/1/0/all/0/1"&gt;Mohammad Jalali&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zareian_A/0/1/0/all/0/1"&gt;Arman Zareian&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+DaeiJavad_A/0/1/0/all/0/1"&gt;Alireza DaeiJavad&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Manshaei_M/0/1/0/all/0/1"&gt;Mohammad Hossein Manshaei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krunz_M/0/1/0/all/0/1"&gt;Marwan Krunz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine learning approaches for localized lockdown during COVID-19: a case study analysis. (arXiv:2201.00715v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00715</id>
        <link href="http://arxiv.org/abs/2201.00715"/>
        <updated>2022-01-05T00:39:36.975Z</updated>
        <summary type="html"><![CDATA[At the end of 2019, the latest novel coronavirus Sars-CoV-2 emerged as a
significant acute respiratory disease that has become a global pandemic.
Countries like Brazil have had difficulty in dealing with the virus due to the
high socioeconomic difference of states and municipalities. Therefore, this
study presents a new approach using different machine learning and deep
learning algorithms applied to Brazilian COVID-19 data. First, a clustering
algorithm is used to identify counties with similar sociodemographic behavior,
while Benford's law is used to check for data manipulation. Based on these
results we are able to correctly model SARIMA models based on the clusters to
predict new daily cases. The unsupervised machine learning techniques optimized
the process of defining the parameters of the SARIMA model. This framework can
also be useful to propose confinement scenarios during the so-called second
wave. We have used the 645 counties from S\~ao Paulo state, the most populous
state in Brazil. However, this methodology can be used in other states or
countries. This paper demonstrates how different techniques of machine
learning, deep learning, data mining and statistics can be used together to
produce important results when dealing with pandemic data. Although the
findings cannot be used exclusively to assess and influence policy decisions,
they offer an alternative to the ineffective measures that have been used.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Malvar_S/0/1/0/all/0/1"&gt;Sara Malvar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Meneghini_J/0/1/0/all/0/1"&gt;Julio Romano Meneghini&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving Actor-Critic Reinforcement Learning via Hamiltonian Monte Carlo Method. (arXiv:2103.12020v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.12020</id>
        <link href="http://arxiv.org/abs/2103.12020"/>
        <updated>2022-01-05T00:39:36.972Z</updated>
        <summary type="html"><![CDATA[The actor-critic RL is widely used in various robotic control tasks. By
viewing the actor-critic RL from the perspective of variational inference (VI),
the policy network is trained to obtain the approximate posterior of actions
given the optimality criteria. However, in practice, the actor-critic RL may
yield suboptimal policy estimates due to the amortization gap and insufficient
exploration. In this work, inspired by the previous use of Hamiltonian Monte
Carlo (HMC) in VI, we propose to integrate the policy network of actor-critic
RL with HMC, which is termed as {\it Hamiltonian Policy}. As such we propose to
evolve actions from the base policy according to HMC, and our proposed method
has many benefits. First, HMC can improve the policy distribution to better
approximate the posterior and hence reduce the amortization gap. Second, HMC
can also guide the exploration more to the regions of action spaces with higher
Q values, enhancing the exploration efficiency. Further, instead of directly
applying HMC into RL, we propose a new leapfrog operator to simulate the
Hamiltonian dynamics. Finally, in safe RL problems, we find that the proposed
method can not only improve the achieved return, but also reduce safety
constraint violations by discarding potentially unsafe actions. With
comprehensive empirical experiments on continuous control baselines, including
MuJoCo and PyBullet Roboschool, we show that the proposed approach is a
data-efficient and easy-to-implement improvement over previous actor-critic
methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1"&gt;Duo Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fekri_F/0/1/0/all/0/1"&gt;Faramarz Fekri&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Efficient and Accurate Rough Set for Feature Selection, Classification and Knowledge Representation. (arXiv:2201.00436v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00436</id>
        <link href="http://arxiv.org/abs/2201.00436"/>
        <updated>2022-01-05T00:39:36.950Z</updated>
        <summary type="html"><![CDATA[This paper present a strong data mining method based on rough set, which can
realize feature selection, classification and knowledge representation at the
same time. Rough set has good interpretability, and is a popular method for
feature selections. But low efficiency and low accuracy are its main drawbacks
that limits its application ability. In this paper,corresponding to the
accuracy, we first find the ineffectiveness of rough set because of
overfitting, especially in processing noise attribute, and propose a robust
measurement for an attribute, called relative importance.we proposed the
concept of "rough concept tree" for knowledge representation and
classification. Experimental results on public benchmark data sets show that
the proposed framework achieves higher accurcy than seven popular or the
state-of-the-art feature selection methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1"&gt;Shuyin Xia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1"&gt;Xinyu Bai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1"&gt;Guoyin Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1"&gt;Deyu Meng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1"&gt;Xinbo Gao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"&gt;Zizhong Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Giem_E/0/1/0/all/0/1"&gt;Elisabeth Giem&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Sampling Gaps for Adaptive Submodular Maximization. (arXiv:2104.01750v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.01750</id>
        <link href="http://arxiv.org/abs/2104.01750"/>
        <updated>2022-01-05T00:39:36.945Z</updated>
        <summary type="html"><![CDATA[Running machine learning algorithms on large and rapidly growing volumes of
data is often computationally expensive, one common trick to reduce the size of
a data set, and thus reduce the computational cost of machine learning
algorithms, is \emph{probability sampling}. It creates a sampled data set by
including each data point from the original data set with a known probability.
Although the benefit of running machine learning algorithms on the reduced data
set is obvious, one major concern is that the performance of the solution
obtained from samples might be much worse than that of the optimal solution
when using the full data set. In this paper, we examine the performance loss
caused by probability sampling in the context of adaptive submodular
maximization. We consider a simple probability sampling method which selects
each data point with probability $r\in[0,1]$. If we set the sampling rate
$r=1$, our problem reduces to finding a solution based on the original full
data set. We define sampling gap as the largest ratio between the optimal
solution obtained from the full data set and the optimal solution obtained from
the samples, over independence systems. %It captures the performance loss of
the optimal solution caused by the probability sampling. Our main contribution
is to show that if the utility function is policywise submodular, then for a
given sampling rate $r$, the sampling gap is both upper bounded and lower
bounded by $1/r$. One immediate implication of our result is that if we can
find an $\alpha$-approximation solution based on a sampled data set (which is
sampled at sampling rate $r$), then this solution achieves an $\alpha r$
approximation ratio against the optimal solution when using the full data set.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1"&gt;Shaojie Tang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1"&gt;Jing Yuan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification. (arXiv:2112.13236v2 [cs.CR] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.13236</id>
        <link href="http://arxiv.org/abs/2112.13236"/>
        <updated>2022-01-05T00:39:36.944Z</updated>
        <summary type="html"><![CDATA[Classification of malware families is crucial for a comprehensive
understanding of how they can infect devices, computers, or systems. Thus,
malware identification enables security researchers and incident responders to
take precautions against malware and accelerate mitigation. API call sequences
made by malware are widely utilized features by machine and deep learning
models for malware classification as these sequences represent the behavior of
malware. However, traditional machine and deep learning models remain incapable
of capturing sequence relationships between API calls. On the other hand, the
transformer-based models process sequences as a whole and learn relationships
between API calls due to multi-head attention mechanisms and positional
embeddings. Our experiments demonstrate that the transformer model with one
transformer block layer surpassed the widely used base architecture, LSTM.
Moreover, BERT or CANINE, pre-trained transformer models, outperformed in
classifying highly imbalanced malware families according to evaluation metrics,
F1-score, and AUC score. Furthermore, the proposed bagging-based random
transformer forest (RTF), an ensemble of BERT or CANINE, has reached the
state-of-the-art evaluation scores on three out of four datasets, particularly
state-of-the-art F1-score of 0.6149 on one of the commonly used benchmark
dataset.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Demirkiran_F/0/1/0/all/0/1"&gt;Ferhat Demirk&amp;#x131;ran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cayir_A/0/1/0/all/0/1"&gt;Aykut &amp;#xc7;ay&amp;#x131;r&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Unal_U/0/1/0/all/0/1"&gt;U&amp;#x11f;ur &amp;#xdc;nal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dag_H/0/1/0/all/0/1"&gt;Hasan Da&amp;#x11f;&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Logic Shrinkage: Learned FPGA Netlist Sparsity for Efficient Neural Network Inference. (arXiv:2112.02346v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.02346</id>
        <link href="http://arxiv.org/abs/2112.02346"/>
        <updated>2022-01-05T00:39:36.938Z</updated>
        <summary type="html"><![CDATA[FPGA-specific DNN architectures using the native LUTs as independently
trainable inference operators have been shown to achieve favorable
area-accuracy and energy-accuracy tradeoffs. The first work in this area,
LUTNet, exhibited state-of-the-art performance for standard DNN benchmarks. In
this paper, we propose the learned optimization of such LUT-based topologies,
resulting in higher-efficiency designs than via the direct use of
off-the-shelf, hand-designed networks. Existing implementations of this class
of architecture require the manual specification of the number of inputs per
LUT, K. Choosing appropriate K a priori is challenging, and doing so at even
high granularity, e.g. per layer, is a time-consuming and error-prone process
that leaves FPGAs' spatial flexibility underexploited. Furthermore, prior works
see LUT inputs connected randomly, which does not guarantee a good choice of
network topology. To address these issues, we propose logic shrinkage, a
fine-grained netlist pruning methodology enabling K to be automatically learned
for every LUT in a neural network targeted for FPGA inference. By removing LUT
inputs determined to be of low importance, our method increases the efficiency
of the resultant accelerators. Our GPU-friendly solution to LUT input removal
is capable of processing large topologies during their training with negligible
slowdown. With logic shrinkage, we better the area and energy efficiency of the
best-performing LUTNet implementation of the CNV network classifying CIFAR-10
by 1.54x and 1.31x, respectively, while matching its accuracy. This
implementation also reaches 2.71x the area efficiency of an equally accurate,
heavily pruned BNN. On ImageNet with the Bi-Real Net architecture, employment
of logic shrinkage results in a post-synthesis area reduction of 2.67x vs
LUTNet, allowing for implementation that was previously impossible on today's
largest FPGAs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1"&gt;Erwei Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1"&gt;James J. Davis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Stavrou_G/0/1/0/all/0/1"&gt;Georgios-Ilias Stavrou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheung_P/0/1/0/all/0/1"&gt;Peter Y. K. Cheung&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Constantinides_G/0/1/0/all/0/1"&gt;George A. Constantinides&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Abdelfattah_M/0/1/0/all/0/1"&gt;Mohamed S. Abdelfattah&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Pharma News Categorization. (arXiv:2201.00688v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2201.00688</id>
        <link href="http://arxiv.org/abs/2201.00688"/>
        <updated>2022-01-05T00:39:36.937Z</updated>
        <summary type="html"><![CDATA[We use a text dataset consisting of 23 news categories relevant to pharma
information science, in order to compare the fine-tuning performance of
multiple transformer models in a classification task. Using a well-balanced
dataset with multiple autoregressive and autocoding transformation models, we
compare their fine-tuning performance. To validate the winning approach, we
perform diagnostics of model behavior on mispredicted instances, including
inspection of category-wise metrics, evaluation of prediction certainty and
assessment of latent space representations. Lastly, we propose an ensemble
model consisting of the top performing individual predictors and demonstrate
that this approach offers a modest improvement in the F1 metric.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Adaszewski_S/0/1/0/all/0/1"&gt;Stanislaw Adaszewski&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kuner_P/0/1/0/all/0/1"&gt;Pascal Kuner&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jaeger_R/0/1/0/all/0/1"&gt;Ralf J. Jaeger&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conditional Selective Inference for Robust Regression and Outlier Detection using Piecewise-Linear Homotopy Continuation. (arXiv:2104.10840v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.10840</id>
        <link href="http://arxiv.org/abs/2104.10840"/>
        <updated>2022-01-05T00:39:36.935Z</updated>
        <summary type="html"><![CDATA[In practical data analysis under noisy environment, it is common to first use
robust methods to identify outliers, and then to conduct further analysis after
removing the outliers. In this paper, we consider statistical inference of the
model estimated after outliers are removed, which can be interpreted as a
selective inference (SI) problem. To use conditional SI framework, it is
necessary to characterize the events of how the robust method identifies
outliers. Unfortunately, the existing methods cannot be directly used here
because they are applicable to the case where the selection events can be
represented by linear/quadratic constraints. In this paper, we propose a
conditional SI method for popular robust regressions by using homotopy method.
We show that the proposed conditional SI method is applicable to a wide class
of robust regression and outlier detection methods and has good empirical
performance on both synthetic data and real data experiments.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Tsukurimichi_T/0/1/0/all/0/1"&gt;Toshiaki Tsukurimichi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Inatsu_Y/0/1/0/all/0/1"&gt;Yu Inatsu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Duy_V/0/1/0/all/0/1"&gt;Vo Nguyen Le Duy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1"&gt;Ichiro Takeuchi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods. (arXiv:1907.09358v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1907.09358</id>
        <link href="http://arxiv.org/abs/1907.09358"/>
        <updated>2022-01-05T00:39:36.934Z</updated>
        <summary type="html"><![CDATA[Interest in Artificial Intelligence (AI) and its applications has seen
unprecedented growth in the last few years. This success can be partly
attributed to the advancements made in the sub-fields of AI such as machine
learning, computer vision, and natural language processing. Much of the growth
in these fields has been made possible with deep learning, a sub-area of
machine learning that uses artificial neural networks. This has created
significant interest in the integration of vision and language. In this survey,
we focus on ten prominent tasks that integrate language and vision by
discussing their problem formulation, methods, existing datasets, evaluation
measures, and compare the results obtained with corresponding state-of-the-art
methods. Our efforts go beyond earlier surveys which are either task-specific
or concentrate only on one type of visual content, i.e., image or video.
Furthermore, we also provide some potential future directions in this field of
research with an anticipation that this survey stimulates innovative thoughts
and ideas to address the existing challenges and build new applications.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Mogadala_A/0/1/0/all/0/1"&gt;Aditya Mogadala&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kalimuthu_M/0/1/0/all/0/1"&gt;Marimuthu Kalimuthu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1"&gt;Dietrich Klakow&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalable semi-supervised dimensionality reduction with GPU-accelerated EmbedSOM. (arXiv:2201.00701v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00701</id>
        <link href="http://arxiv.org/abs/2201.00701"/>
        <updated>2022-01-05T00:39:36.928Z</updated>
        <summary type="html"><![CDATA[Dimensionality reduction methods have found vast application as visualization
tools in diverse areas of science. Although many different methods exist, their
performance is often insufficient for providing quick insight into many
contemporary datasets, and the unsupervised mode of use prevents the users from
utilizing the methods for dataset exploration and fine-tuning the details for
improved visualization quality. We present BlosSOM, a high-performance
semi-supervised dimensionality reduction software for interactive
user-steerable visualization of high-dimensional datasets with millions of
individual data points. BlosSOM builds on a GPU-accelerated implementation of
the EmbedSOM algorithm, complemented by several landmark-based algorithms for
interfacing the unsupervised model learning algorithms with the user
supervision. We show the application of BlosSOM on realistic datasets, where it
helps to produce high-quality visualizations that incorporate user-specified
layout and focus on certain features. We believe the semi-supervised
dimensionality reduction will improve the data visualization possibilities for
science areas such as single-cell cytometry, and provide a fast and efficient
base methodology for new directions in dataset exploration and annotation.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Smelko_A/0/1/0/all/0/1"&gt;Adam &amp;#x160;melko&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Molnarova_S/0/1/0/all/0/1"&gt;So&amp;#x148;a Moln&amp;#xe1;rov&amp;#xe1;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kratochvil_M/0/1/0/all/0/1"&gt;Miroslav Kratochv&amp;#xed;l&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Koladiya_A/0/1/0/all/0/1"&gt;Abhishek Koladiya&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Musil_J/0/1/0/all/0/1"&gt;Jan Musil&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krulis_M/0/1/0/all/0/1"&gt;Martin Kruli&amp;#x161;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vondrasek_J/0/1/0/all/0/1"&gt;Ji&amp;#x159;&amp;#xed; Vondr&amp;#xe1;&amp;#x161;ek&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Family of Deep Learning Architectures for Channel Estimation and Hybrid Beamforming in Multi-Carrier mm-Wave Massive MIMO. (arXiv:1912.10036v6 [eess.SP] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1912.10036</id>
        <link href="http://arxiv.org/abs/1912.10036"/>
        <updated>2022-01-05T00:39:36.927Z</updated>
        <summary type="html"><![CDATA[Hybrid analog and digital beamforming transceivers are instrumental in
addressing the challenge of expensive hardware and high training overheads in
the next generation millimeter-wave (mm-Wave) massive MIMO (multiple-input
multiple-output) systems. However, lack of fully digital beamforming in hybrid
architectures and short coherence times at mm-Wave impose additional
constraints on the channel estimation. Prior works on addressing these
challenges have focused largely on narrowband channels wherein
optimization-based or greedy algorithms were employed to derive hybrid
beamformers. In this paper, we introduce a deep learning (DL) approach for
channel estimation and hybrid beamforming for frequency-selective, wideband
mm-Wave systems. In particular, we consider a massive MIMO Orthogonal Frequency
Division Multiplexing (MIMO-OFDM) system and propose three different DL
frameworks comprising convolutional neural networks (CNNs), which accept the
raw data of received signal as input and yield channel estimates and the hybrid
beamformers at the output. We also introduce both offline and online prediction
schemes. Numerical experiments demonstrate that, compared to the current
state-of-the-art optimization and DL methods, our approach provides higher
spectral efficiency, lesser computational cost and fewer number of pilot
signals, and higher tolerance against the deviations in the received pilot
data, corrupted channel matrix, and propagation environment.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Elbir_A/0/1/0/all/0/1"&gt;Ahmet M. Elbir&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Mishra_K/0/1/0/all/0/1"&gt;Kumar Vijay Mishra&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Shankar_M/0/1/0/all/0/1"&gt;M. R. Bhavani Shankar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Ottersten_B/0/1/0/all/0/1"&gt;Bj&amp;#xf6;rn Ottersten&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convergence of Random Reshuffling Under The Kurdyka-{\L}ojasiewicz Inequality. (arXiv:2110.04926v2 [math.OC] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.04926</id>
        <link href="http://arxiv.org/abs/2110.04926"/>
        <updated>2022-01-05T00:39:36.927Z</updated>
        <summary type="html"><![CDATA[We study the random reshuffling (RR) method for smooth nonconvex optimization
problems with a finite-sum structure. Though this method is widely utilized in
practice such as the training of neural networks, its convergence behavior is
only understood in several limited settings. In this paper, under the
well-known Kurdyka-Lojasiewicz (KL) inequality, we establish strong limit-point
convergence results for RR with appropriate diminishing step sizes, namely, the
whole sequence of iterates generated by RR is convergent and converges to a
single stationary point in an almost sure sense. In addition, we derive the
corresponding rate of convergence, depending on the KL exponent and the
suitably selected diminishing step sizes. When the KL exponent lies in
$[0,\frac12]$, the convergence is at a rate of $\mathcal{O}(t^{-1})$ with $t$
counting the iteration number. When the KL exponent belongs to $(\frac12,1)$,
our derived convergence rate is of the form $\mathcal{O}(t^{-q})$ with $q\in
(0,1)$ depending on the KL exponent. The standard KL inequality-based
convergence analysis framework only applies to algorithms with a certain
descent property. We conduct a novel convergence analysis for the non-descent
RR method with diminishing step sizes based on the KL inequality, which
generalizes the standard KL framework. We summarize our main steps and core
ideas in an informal analysis framework, which is of independent interest. As a
direct application of this framework, we also establish similar strong
limit-point convergence results for the reshuffled proximal point method.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Li_X/0/1/0/all/0/1"&gt;Xiao Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Milzarek_A/0/1/0/all/0/1"&gt;Andre Milzarek&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Qiu_J/0/1/0/all/0/1"&gt;Junwen Qiu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Boosting Contrastive Self-Supervised Learning with False Negative Cancellation. (arXiv:2011.11765v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2011.11765</id>
        <link href="http://arxiv.org/abs/2011.11765"/>
        <updated>2022-01-05T00:39:36.926Z</updated>
        <summary type="html"><![CDATA[Self-supervised representation learning has made significant leaps fueled by
progress in contrastive learning, which seeks to learn transformations that
embed positive input pairs nearby, while pushing negative pairs far apart.
While positive pairs can be generated reliably (e.g., as different views of the
same image), it is difficult to accurately establish negative pairs, defined as
samples from different images regardless of their semantic content or visual
features. A fundamental problem in contrastive learning is mitigating the
effects of false negatives. Contrasting false negatives induces two critical
issues in representation learning: discarding semantic information and slow
convergence. In this paper, we propose novel approaches to identify false
negatives, as well as two strategies to mitigate their effect, i.e. false
negative elimination and attraction, while systematically performing rigorous
evaluations to study this problem in detail. Our method exhibits consistent
improvements over existing contrastive learning-based methods. Without labels,
we identify false negatives with 40% accuracy among 1000 semantic classes on
ImageNet, and achieve 5.8% absolute improvement in top-1 accuracy over the
previous state-of-the-art when finetuning with 1% labels. Our code is available
at https://github.com/google-research/fnc.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Huynh_T/0/1/0/all/0/1"&gt;Tri Huynh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kornblith_S/0/1/0/all/0/1"&gt;Simon Kornblith&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Walter_M/0/1/0/all/0/1"&gt;Matthew R. Walter&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Maire_M/0/1/0/all/0/1"&gt;Michael Maire&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Khademi_M/0/1/0/all/0/1"&gt;Maryam Khademi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI. (arXiv:2201.00650v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00650</id>
        <link href="http://arxiv.org/abs/2201.00650"/>
        <updated>2022-01-05T00:39:36.922Z</updated>
        <summary type="html"><![CDATA[The second edition of Deep Learning Interviews is home to hundreds of
fully-solved problems, from a wide range of key topics in AI. It is designed to
both rehearse interview or exam specific topics and provide machine learning
M.Sc./Ph.D. students, and those awaiting an interview a well-organized overview
of the field. The problems it poses are tough enough to cut your teeth on and
to dramatically improve your skills-but they're framed within thought-provoking
questions and engaging stories. That is what makes the volume so specifically
valuable to students and job seekers: it provides them with the ability to
speak confidently and quickly on any relevant topic, to answer technical
questions clearly and correctly, and to fully understand the purpose and
meaning of interview questions and answers. Those are powerful, indispensable
advantages to have when walking into the interview room. The book's contents is
a large inventory of numerous topics relevant to DL job interviews and graduate
level exams. That places this work at the forefront of the growing trend in
science to teach a core set of practical mathematical and computational skills.
It is widely accepted that the training of every computer scientist must
include the fundamental theorems of ML, and AI appears in the curriculum of
nearly every university. This volume is designed as an excellent reference for
graduates of such programs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kashani_S/0/1/0/all/0/1"&gt;Shlomo Kashani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ivry_A/0/1/0/all/0/1"&gt;Amir Ivry&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Boosting the Certified Robustness of L-infinity Distance Nets. (arXiv:2110.06850v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.06850</id>
        <link href="http://arxiv.org/abs/2110.06850"/>
        <updated>2022-01-05T00:39:36.917Z</updated>
        <summary type="html"><![CDATA[Recently, Zhang et al.(2021) developed a new neural network architecture
based on $\ell_\infty$-distance functions, which naturally possesses certified
$\ell_\infty$ robustness by its construction. Despite rigorous theoretical
guarantees, the model so far can only achieve comparable performance to
conventional networks. In this paper, we make the following two contributions:
$\mathrm{(i)}$ We demonstrate that $\ell_\infty$-distance nets enjoy a
fundamental advantage in certified robustness over conventional networks (under
typical certification approaches); $\mathrm{(ii)}$ With an improved training
process we are able to significantly boost the certified accuracy of
$\ell_\infty$-distance nets. Our training approach largely alleviates the
optimization problem that arose in the previous training scheme, in particular,
the unexpected large Lipschitz constant due to the use of a crucial trick
called $\ell_p$-relaxation. The core of our training approach is a novel
objective function that combines scaled cross-entropy loss and clipped hinge
loss with a decaying mixing coefficient. Experiments show that using the
proposed training strategy, the certified accuracy of $\ell_\infty$-distance
net can be dramatically improved from 33.30% to 40.06% on CIFAR-10
($\epsilon=8/255$), meanwhile outperforming other approaches in this area by a
large margin. Our results clearly demonstrate the effectiveness and potential
of $\ell_\infty$-distance net for certified robustness. Codes are available at
https://github.com/zbh2047/L_inf-dist-net-v2.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1"&gt;Bohang Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1"&gt;Du Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1"&gt;Di He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"&gt;Liwei Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resource-Efficient and Delay-Aware Federated Learning Design under Edge Heterogeneity. (arXiv:2112.13926v2 [cs.NI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.13926</id>
        <link href="http://arxiv.org/abs/2112.13926"/>
        <updated>2022-01-05T00:39:36.915Z</updated>
        <summary type="html"><![CDATA[Federated learning (FL) has emerged as a popular methodology for distributing
machine learning across wireless edge devices. In this work, we consider
optimizing the tradeoff between model performance and resource utilization in
FL, under device-server communication delays and device computation
heterogeneity. Our proposed StoFedDelAv algorithm incorporates a local-global
model combiner into the FL synchronization step. We theoretically characterize
the convergence behavior of StoFedDelAv and obtain the optimal combiner
weights, which consider the global model delay and expected local gradient
error at each device. We then formulate a network-aware optimization problem
which tunes the minibatch sizes of the devices to jointly minimize energy
consumption and machine learning training loss, and solve the non-convex
problem through a series of convex approximations. Our simulations reveal that
StoFedDelAv outperforms the current art in FL in terms of model convergence
speed and network resource utilization when the minibatch size and the combiner
weights are adjusted. Additionally, our method can reduce the number of uplink
communication rounds required during the model training period to reach the
same accuracy.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Nickel_D/0/1/0/all/0/1"&gt;David Nickel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1"&gt;Frank Po-Chen Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1"&gt;Seyyedali Hosseinalipour&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Michelusi_N/0/1/0/all/0/1"&gt;Nicolo Michelusi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1"&gt;Christopher G. Brinton&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AugMax: Adversarial Composition of Random Augmentations for Robust Training. (arXiv:2110.13771v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.13771</id>
        <link href="http://arxiv.org/abs/2110.13771"/>
        <updated>2022-01-05T00:39:36.914Z</updated>
        <summary type="html"><![CDATA[Data augmentation is a simple yet effective way to improve the robustness of
deep neural networks (DNNs). Diversity and hardness are two complementary
dimensions of data augmentation to achieve robustness. For example, AugMix
explores random compositions of a diverse set of augmentations to enhance
broader coverage, while adversarial training generates adversarially hard
samples to spot the weakness. Motivated by this, we propose a data augmentation
framework, termed AugMax, to unify the two aspects of diversity and hardness.
AugMax first randomly samples multiple augmentation operators and then learns
an adversarial mixture of the selected operators. Being a stronger form of data
augmentation, AugMax leads to a significantly augmented input distribution
which makes model training more challenging. To solve this problem, we further
design a disentangled normalization module, termed DuBIN
(Dual-Batch-and-Instance Normalization), that disentangles the instance-wise
feature heterogeneity arising from AugMax. Experiments show that AugMax-DuBIN
leads to significantly improved out-of-distribution robustness, outperforming
prior arts by 3.03%, 3.49%, 1.82% and 0.71% on CIFAR10-C, CIFAR100-C, Tiny
ImageNet-C and ImageNet-C. Codes and pretrained models are available:
https://github.com/VITA-Group/AugMax.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"&gt;Haotao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1"&gt;Chaowei Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kossaifi_J/0/1/0/all/0/1"&gt;Jean Kossaifi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1"&gt;Zhiding Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1"&gt;Anima Anandkumar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zhangyang Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Parkour Spot ID: Feature Matching in Satellite and Street view images using Deep Learning. (arXiv:2201.00377v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.00377</id>
        <link href="http://arxiv.org/abs/2201.00377"/>
        <updated>2022-01-05T00:39:36.911Z</updated>
        <summary type="html"><![CDATA[How to find places that are not indexed by Google Maps? We propose an
intuitive method and framework to locate places based on their distinctive
spatial features. The method uses satellite and street view images in machine
vision approaches to classify locations. If we can classify locations, we just
need to repeat for non-overlapping locations in our area of interest. We assess
the proposed system in finding Parkour spots in the campus of Arizona State
University. The results are very satisfactory, having found more than 25 new
Parkour spots, with a rate of true positives above 60%.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Morais_J/0/1/0/all/0/1"&gt;Jo&amp;#xe3;o Morais&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rathi_K/0/1/0/all/0/1"&gt;Kaushal Rathi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mohan_B/0/1/0/all/0/1"&gt;Bhuvaneshwar Mohan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rajesh_S/0/1/0/all/0/1"&gt;Shantanu Rajesh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Model-free Neural Counterfactual Regret Minimization with Bootstrap Learning. (arXiv:2012.01870v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.01870</id>
        <link href="http://arxiv.org/abs/2012.01870"/>
        <updated>2022-01-05T00:39:36.910Z</updated>
        <summary type="html"><![CDATA[Counterfactual Regret Minimization (CFR) has achieved many fascinating
results in solving large-scale Imperfect Information Games (IIGs). Neural
network approximation CFR (neural CFR) is one of the promising techniques that
can reduce computation and memory consumption by generalizing decision
information between similar states. Current neural CFR algorithms have to
approximate cumulative regrets. However, efficient and accurate approximation
in a large-scale IIG is still a tough challenge. In this paper, a new CFR
variant, Recursive CFR (ReCFR), is proposed. In ReCFR, Recursive Substitute
Values (RSVs) are learned and used to replace cumulative regrets. It is proven
that ReCFR can converge to a Nash equilibrium at a rate of
$O(\frac{1}{\sqrt{T}})$. Based on ReCFR, a new model-free neural CFR with
bootstrap learning, Neural ReCFR-B, is proposed. Due to the recursive and
non-cumulative nature of RSVs, Neural ReCFR-B has lower-variance training
targets than other neural CFRs. Experimental results show that Neural ReCFR-B
is competitive with the state-of-the-art neural CFR algorithms at a much lower
training cost.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1"&gt;Weiming Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1"&gt;Bin Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1"&gt;Julian Togelius&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MHATC: Autism Spectrum Disorder identification utilizing multi-head attention encoder along with temporal consolidation modules. (arXiv:2201.00404v1 [q-bio.NC])]]></title>
        <id>http://arxiv.org/abs/2201.00404</id>
        <link href="http://arxiv.org/abs/2201.00404"/>
        <updated>2022-01-05T00:39:36.908Z</updated>
        <summary type="html"><![CDATA[Resting-state fMRI is commonly used for diagnosing Autism Spectrum Disorder
(ASD) by using network-based functional connectivity. It has been shown that
ASD is associated with brain regions and their inter-connections. However,
discriminating based on connectivity patterns among imaging data of the control
population and that of ASD patients' brains is a non-trivial task. In order to
tackle said classification task, we propose a novel deep learning architecture
(MHATC) consisting of multi-head attention and temporal consolidation modules
for classifying an individual as a patient of ASD. The devised architecture
results from an in-depth analysis of the limitations of current deep neural
network solutions for similar applications. Our approach is not only robust but
computationally efficient, which can allow its adoption in a variety of other
research and clinical settings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/q-bio/1/au:+Jha_R/0/1/0/all/0/1"&gt;Ranjeet Ranjan Jha&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Bhardwaj_A/0/1/0/all/0/1"&gt;Abhishek Bhardwaj&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Garg_D/0/1/0/all/0/1"&gt;Devin Garg&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Bhavsar_A/0/1/0/all/0/1"&gt;Arnav Bhavsar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Nigam_A/0/1/0/all/0/1"&gt;Aditya Nigam&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MORAL: Aligning AI with Human Norms through Multi-Objective Reinforced Active Learning. (arXiv:2201.00012v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00012</id>
        <link href="http://arxiv.org/abs/2201.00012"/>
        <updated>2022-01-05T00:39:36.901Z</updated>
        <summary type="html"><![CDATA[Inferring reward functions from demonstrations and pairwise preferences are
auspicious approaches for aligning Reinforcement Learning (RL) agents with
human intentions. However, state-of-the art methods typically focus on learning
a single reward model, thus rendering it difficult to trade off different
reward functions from multiple experts. We propose Multi-Objective Reinforced
Active Learning (MORAL), a novel method for combining diverse demonstrations of
social norms into a Pareto-optimal policy. Through maintaining a distribution
over scalarization weights, our approach is able to interactively tune a deep
RL agent towards a variety of preferences, while eliminating the need for
computing multiple policies. We empirically demonstrate the effectiveness of
MORAL in two scenarios, which model a delivery and an emergency task that
require an agent to act in the presence of normative conflicts. Overall, we
consider our research a step towards multi-objective RL with learned rewards,
bridging the gap between current reward learning and machine ethics literature.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Peschl_M/0/1/0/all/0/1"&gt;Markus Peschl&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zgonnikov_A/0/1/0/all/0/1"&gt;Arkady Zgonnikov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Oliehoek_F/0/1/0/all/0/1"&gt;Frans A. Oliehoek&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Siebert_L/0/1/0/all/0/1"&gt;Luciano C. Siebert&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[maskGRU: Tracking Small Objects in the Presence of Large Background Motions. (arXiv:2201.00467v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.00467</id>
        <link href="http://arxiv.org/abs/2201.00467"/>
        <updated>2022-01-05T00:39:36.898Z</updated>
        <summary type="html"><![CDATA[We propose a recurrent neural network-based spatio-temporal framework named
maskGRU for the detection and tracking of small objects in videos. While there
have been many developments in the area of object tracking in recent years,
tracking a small moving object amid other moving objects and actors (such as a
ball amid moving players in sports footage) continues to be a difficult task.
Existing spatio-temporal networks, such as convolutional Gated Recurrent Units
(convGRUs), are difficult to train and have trouble accurately tracking small
objects under such conditions. To overcome these difficulties, we developed the
maskGRU framework that uses a weighted sum of the internal hidden state
produced by a convGRU and a 3-channel mask of the tracked object's predicted
bounding box as the hidden state to be used at the next time step of the
underlying convGRU. We believe the technique of incorporating a mask into the
hidden state through a weighted sum has two benefits: controlling the effect of
exploding gradients and introducing an attention-like mechanism into the
network by indicating where in the previous video frame the object is located.
Our experiments show that maskGRU outperforms convGRU at tracking objects that
are small relative to the video resolution even in the presence of other moving
objects.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Roros_C/0/1/0/all/0/1"&gt;Constantine J. Roros&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kak_A/0/1/0/all/0/1"&gt;Avinash C. Kak&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformer Embeddings of Irregularly Spaced Events and Their Participants. (arXiv:2201.00044v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00044</id>
        <link href="http://arxiv.org/abs/2201.00044"/>
        <updated>2022-01-05T00:39:36.897Z</updated>
        <summary type="html"><![CDATA[We propose an approach to modeling irregularly spaced sequences of discrete
events. We begin with a continuous-time variant of the Transformer, which was
originally formulated (Vaswani et al., 2017) for sequences without timestamps.
We embed a possible event (or other boolean fact) at time $t$ by using
attention over the events that occurred at times $< t$ (and the facts that were
true when they occurred). We control this attention using pattern-matching
logic rules that relate events and facts that share participants. These rules
determine which previous events will be attended to, as well as how to
transform the embeddings of the events and facts into the attentional queries,
keys, and values. Other logic rules describe how to change the set of facts in
response to events. Our approach closely follows Mei et al. (2020a), and adopts
their Datalog Through Time formalism for logic rules. As in that work, a domain
expert first writes a set of logic rules that establishes the set of possible
events and other facts at each time $t$. Each possible event or other fact is
embedded using a neural architecture that is derived from the rules that
established it. Our only difference from Mei et al. (2020a) is that we derive a
flatter, attention-based neural architecture whereas they used a more serial
LSTM architecture. We find that our attention-based approach performs about
equally well on the RoboCup dataset, where the logic rules play an important
role in improving performance. We also compared these two methods with two
previous attention-based methods (Zuo et al., 2020; Zhang et al., 2020a) on
simpler synthetic and real domains without logic rules, and found our proposed
approach to be at least as good, and sometimes better, than each of the other
three methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1"&gt;Chenghao Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1"&gt;Hongyuan Mei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1"&gt;Jason Eisner&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The DONUT Approach to EnsembleCombination Forecasting. (arXiv:2201.00426v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00426</id>
        <link href="http://arxiv.org/abs/2201.00426"/>
        <updated>2022-01-05T00:39:36.896Z</updated>
        <summary type="html"><![CDATA[This paper presents an ensemble forecasting method that shows strong results
on the M4Competition dataset by decreasing feature and model selection
assumptions, termed DONUT(DO Not UTilize human assumptions). Our assumption
reductions, consisting mainly of auto-generated features and a more diverse
model pool for the ensemble, significantly outperforms the
statistical-feature-based ensemble method FFORMA by Montero-Manso et al.
(2020). Furthermore, we investigate feature extraction with a Long short-term
memory Network(LSTM) Autoencoder and find that such features contain crucial
information not captured by traditional statistical feature approaches. The
ensemble weighting model uses both LSTM features and statistical features to
combine the models accurately. Analysis of feature importance and interaction
show a slight superiority for LSTM features over the statistical ones alone.
Clustering analysis shows that different essential LSTM features are different
from most statistical features and each other. We also find that increasing the
solution space of the weighting model by augmenting the ensemble with new
models is something the weighting model learns to use, explaining part of the
accuracy gains. Lastly, we present a formal ex-post-facto analysis of optimal
combination and selection for ensembles, quantifying differences through linear
optimization on the M4 dataset. We also include a short proof that model
combination is superior to model selection, a posteriori.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ankile_L/0/1/0/all/0/1"&gt;Lars Lien Ankile&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krange_K/0/1/0/all/0/1"&gt;Kjartan Krange&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Have I done enough planning or should I plan more?. (arXiv:2201.00764v1 [cs.AI])]]></title>
        <id>http://arxiv.org/abs/2201.00764</id>
        <link href="http://arxiv.org/abs/2201.00764"/>
        <updated>2022-01-05T00:39:36.896Z</updated>
        <summary type="html"><![CDATA[People's decisions about how to allocate their limited computational
resources are essential to human intelligence. An important component of this
metacognitive ability is deciding whether to continue thinking about what to do
and move on to the next decision. Here, we show that people acquire this
ability through learning and reverse-engineer the underlying learning
mechanisms. Using a process-tracing paradigm that externalises human planning,
we find that people quickly adapt how much planning they perform to the cost
and benefit of planning. To discover the underlying metacognitive learning
mechanisms we augmented a set of reinforcement learning models with
metacognitive features and performed Bayesian model selection. Our results
suggest that the metacognitive ability to adjust the amount of planning might
be learned through a policy-gradient mechanism that is guided by metacognitive
pseudo-rewards that communicate the value of planning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1"&gt;Ruiqi He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jain_Y/0/1/0/all/0/1"&gt;Yash Raj Jain&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lieder_F/0/1/0/all/0/1"&gt;Falk Lieder&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Confidence-Aware Multi-Teacher Knowledge Distillation. (arXiv:2201.00007v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00007</id>
        <link href="http://arxiv.org/abs/2201.00007"/>
        <updated>2022-01-05T00:39:36.895Z</updated>
        <summary type="html"><![CDATA[Knowledge distillation is initially introduced to utilize additional
supervision from a single teacher model for the student model training. To
boost the student performance, some recent variants attempt to exploit diverse
knowledge sources from multiple teachers. However, existing studies mainly
integrate knowledge from diverse sources by averaging over multiple teacher
predictions or combining them using other various label-free strategies, which
may mislead student in the presence of low-quality teacher predictions. To
tackle this problem, we propose Confidence-Aware Multi-teacher Knowledge
Distillation (CA-MKD), which adaptively assigns sample-wise reliability for
each teacher prediction with the help of ground-truth labels, with those
teacher predictions close to one-hot labels assigned large weights. Besides,
CA-MKD incorporates intermediate layers to further improve student performance.
Extensive experiments show that our CA-MKD consistently outperforms all
compared state-of-the-art methods across various teacher-student architectures.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1"&gt;Hailin Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1"&gt;Defang Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1"&gt;Can Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLOps -- Definitions, Tools and Challenges. (arXiv:2201.00162v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00162</id>
        <link href="http://arxiv.org/abs/2201.00162"/>
        <updated>2022-01-05T00:39:36.895Z</updated>
        <summary type="html"><![CDATA[This paper is an overview of the Machine Learning Operations (MLOps) area.
Our aim is to define the operation and the components of such systems by
highlighting the current problems and trends. In this context, we present the
different tools and their usefulness in order to provide the corresponding
guidelines. Moreover, the connection between MLOps and AutoML (Automated
Machine Learning) is identified and how this combination could work is
proposed.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Symeonidis_G/0/1/0/all/0/1"&gt;G. Symeonidis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nerantzis_E/0/1/0/all/0/1"&gt;E. Nerantzis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kazakis_A/0/1/0/all/0/1"&gt;A. Kazakis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Papakostas_G/0/1/0/all/0/1"&gt;G.A. Papakostas&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PowerGraph: Using neural networks and principal components to multivariate statistical power trade-offs. (arXiv:2201.00719v1 [stat.ME])]]></title>
        <id>http://arxiv.org/abs/2201.00719</id>
        <link href="http://arxiv.org/abs/2201.00719"/>
        <updated>2022-01-05T00:39:36.894Z</updated>
        <summary type="html"><![CDATA[It is increasingly acknowledged that a priori statistical power estimation
for planned studies with multiple model parameters is inherently a multivariate
problem. Power for individual parameters of interest cannot be reliably
estimated univariately because sampling variably in, correlation with, and
variance explained relative to one parameter will impact the power for another
parameter, all usual univariate considerations being equal. Explicit solutions
in such cases, especially for models with many parameters, are either
impractical or impossible to solve, leaving researchers with the prevailing
method of simulating power. However, point estimates for a vector of model
parameters are uncertain, and the impact of inaccuracy is unknown. In such
cases, sensitivity analysis is recommended such that multiple combinations of
possible observable parameter vectors are simulated to understand power
trade-offs. A limitation to this approach is that it is computationally
expensive to generate sufficient sensitivity combinations to accurately map the
power trade-off function in increasingly high dimensional spaces for the models
that social scientists estimate. This paper explores the efficient estimation
and graphing of statistical power for a study over varying model parameter
combinations. Optimally powering a study is crucial to ensure a minimum
probability of finding the hypothesized effect. We first demonstrate the impact
of varying parameter values on power for specific hypotheses of interest and
quantify the computational intensity of computing such a graph for a given
level of precision. Finally, we propose a simple and generalizable machine
learning inspired solution to cut the computational cost to less than 7\% of
what could be called a brute force approach. [abridged]]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Mulay_A/0/1/0/all/0/1"&gt;Ajinkya K Mulay&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Lane_S/0/1/0/all/0/1"&gt;Sean Lane&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Hennes_E/0/1/0/all/0/1"&gt;Erin Hennes&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transfer RL across Observation Feature Spaces via Model-Based Regularization. (arXiv:2201.00248v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00248</id>
        <link href="http://arxiv.org/abs/2201.00248"/>
        <updated>2022-01-05T00:39:36.893Z</updated>
        <summary type="html"><![CDATA[In many reinforcement learning (RL) applications, the observation space is
specified by human developers and restricted by physical realizations, and may
thus be subject to dramatic changes over time (e.g. increased number of
observable features). However, when the observation space changes, the previous
policy will likely fail due to the mismatch of input features, and another
policy must be trained from scratch, which is inefficient in terms of
computation and sample complexity. Following theoretical insights, we propose a
novel algorithm which extracts the latent-space dynamics in the source task,
and transfers the dynamics model to the target task to use as a model-based
regularizer. Our algorithm works for drastic changes of observation space (e.g.
from vector-based observation to image-based observation), without any
inter-task mapping or any prior knowledge of the target task. Empirical results
show that our algorithm significantly improves the efficiency and stability of
learning in the target task.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1"&gt;Yanchao Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1"&gt;Ruijie Zheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"&gt;Xiyao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1"&gt;Andrew Cohen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1"&gt;Furong Huang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Swift and Sure: Hardness-aware Contrastive Learning for Low-dimensional Knowledge Graph Embeddings. (arXiv:2201.00565v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00565</id>
        <link href="http://arxiv.org/abs/2201.00565"/>
        <updated>2022-01-05T00:39:36.893Z</updated>
        <summary type="html"><![CDATA[Knowledge graph embedding (KGE) has drawn great attention due to its
potential in automatic knowledge graph (KG) completion and knowledge-driven
tasks. However, recent KGE models suffer from high training cost and large
storage space, thus limiting their practicality in real-world applications. To
address this challenge, based on the latest findings in the field of
Contrastive Learning, we propose a novel KGE training framework called
Hardness-aware Low-dimensional Embedding (HaLE). Instead of the traditional
Negative Sampling, we design a new loss function based on query sampling that
can balance two important training targets, Alignment and Uniformity.
Furthermore, we analyze the hardness-aware ability of recent low-dimensional
hyperbolic models and propose a lightweight hardness-aware activation
mechanism, which can help the KGE models focus on hard instances and speed up
convergence. The experimental results show that in the limited training time,
HaLE can effectively improve the performance and training speed of KGE models
on five commonly-used datasets. The HaLE-trained models can obtain a high
prediction accuracy after training few minutes and are competitive compared to
the state-of-the-art models in both low- and high-dimensional conditions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1"&gt;Kai Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yu Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1"&gt;Quan Z. Sheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lung-Originated Tumor Segmentation from Computed Tomography Scan (LOTUS) Benchmark. (arXiv:2201.00458v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2201.00458</id>
        <link href="http://arxiv.org/abs/2201.00458"/>
        <updated>2022-01-05T00:39:36.892Z</updated>
        <summary type="html"><![CDATA[Lung cancer is one of the deadliest cancers, and in part its effective
diagnosis and treatment depend on the accurate delineation of the tumor.
Human-centered segmentation, which is currently the most common approach, is
subject to inter-observer variability, and is also time-consuming, considering
the fact that only experts are capable of providing annotations. Automatic and
semi-automatic tumor segmentation methods have recently shown promising
results. However, as different researchers have validated their algorithms
using various datasets and performance metrics, reliably evaluating these
methods is still an open challenge. The goal of the Lung-Originated Tumor
Segmentation from Computed Tomography Scan (LOTUS) Benchmark created through
2018 IEEE Video and Image Processing (VIP) Cup competition, is to provide a
unique dataset and pre-defined metrics, so that different researchers can
develop and evaluate their methods in a unified fashion. The 2018 VIP Cup
started with a global engagement from 42 countries to access the competition
data. At the registration stage, there were 129 members clustered into 28 teams
from 10 countries, out of which 9 teams made it to the final stage and 6 teams
successfully completed all the required tasks. In a nutshell, all the
algorithms proposed during the competition, are based on deep learning models
combined with a false positive reduction technique. Methods developed by the
three finalists show promising results in tumor segmentation, however, more
effort should be put into reducing the false positive rate. This competition
manuscript presents an overview of the VIP-Cup challenge, along with the
proposed algorithms and results.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Afshar_P/0/1/0/all/0/1"&gt;Parnian Afshar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Mohammadi_A/0/1/0/all/0/1"&gt;Arash Mohammadi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Plataniotis_K/0/1/0/all/0/1"&gt;Konstantinos N. Plataniotis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Farahani_K/0/1/0/all/0/1"&gt;Keyvan Farahani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Kirby_J/0/1/0/all/0/1"&gt;Justin Kirby&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Oikonomou_A/0/1/0/all/0/1"&gt;Anastasia Oikonomou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Asif_A/0/1/0/all/0/1"&gt;Amir Asif&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Wee_L/0/1/0/all/0/1"&gt;Leonard Wee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Dekker_A/0/1/0/all/0/1"&gt;Andre Dekker&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1"&gt;Xin Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Haque_M/0/1/0/all/0/1"&gt;Mohammad Ariful Haque&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Hossain_S/0/1/0/all/0/1"&gt;Shahruk Hossain&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Hasan_M/0/1/0/all/0/1"&gt;Md. Kamrul Hasan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Kamal_U/0/1/0/all/0/1"&gt;Uday Kamal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Hsu_W/0/1/0/all/0/1"&gt;Winston Hsu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Lin_J/0/1/0/all/0/1"&gt;Jhih-Yuan Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Rahman_M/0/1/0/all/0/1"&gt;M. Sohel Rahman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Ibtehaz_N/0/1/0/all/0/1"&gt;Nabil Ibtehaz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Foisol_S/0/1/0/all/0/1"&gt;Sh. M. Amir Foisol&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Lam_K/0/1/0/all/0/1"&gt;Kin-Man Lam&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Guang_Z/0/1/0/all/0/1"&gt;Zhong Guang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Zhang_R/0/1/0/all/0/1"&gt;Runze Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Channappayya_S/0/1/0/all/0/1"&gt;Sumohana S. Channappayya&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Gupta_S/0/1/0/all/0/1"&gt;Shashank Gupta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Dev_C/0/1/0/all/0/1"&gt;Chander Dev&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural network training under semidefinite constraints. (arXiv:2201.00632v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00632</id>
        <link href="http://arxiv.org/abs/2201.00632"/>
        <updated>2022-01-05T00:39:36.892Z</updated>
        <summary type="html"><![CDATA[This paper is concerned with the training of neural networks (NNs) under
semidefinite constraints. This type of training problems has recently gained
popularity since semidefinite constraints can be used to verify interesting
properties for NNs that include, e.g., the estimation of an upper bound on the
Lipschitz constant, which relates to the robustness of an NN, or the stability
of dynamic systems with NN controllers. The utilized semidefinite constraints
are based on sector constraints satisfied by the underlying activation
functions. Unfortunately, one of the biggest bottlenecks of these new results
is the required computational effort for incorporating the semidefinite
constraints into the training of NNs which is limiting their scalability to
large NNs. We address this challenge by developing interior point methods for
NN training that we implement using barrier functions for semidefinite
constraints. In order to efficiently compute the gradients of the barrier
terms, we exploit the structure of the semidefinite constraints. In
experiments, we demonstrate the superior efficiency of our training method over
previous approaches, which allows us, e.g., to use semidefinite constraints in
the training of Wasserstein generative adversarial networks, where the
discriminator must satisfy a Lipschitz condition.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pauli_P/0/1/0/all/0/1"&gt;Patricia Pauli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Funcke_N/0/1/0/all/0/1"&gt;Niklas Funcke&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gramlich_D/0/1/0/all/0/1"&gt;Dennis Gramlich&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Msalmi_M/0/1/0/all/0/1"&gt;Mohamed Amine Msalmi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Allgower_F/0/1/0/all/0/1"&gt;Frank Allg&amp;#xf6;wer&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Efficient Combinatorial Optimization Model Using Learning-to-Rank Distillation. (arXiv:2201.00695v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2201.00695</id>
        <link href="http://arxiv.org/abs/2201.00695"/>
        <updated>2022-01-05T00:39:36.891Z</updated>
        <summary type="html"><![CDATA[Recently, deep reinforcement learning (RL) has proven its feasibility in
solving combinatorial optimization problems (COPs). The learning-to-rank
techniques have been studied in the field of information retrieval. While
several COPs can be formulated as the prioritization of input items, as is
common in the information retrieval, it has not been fully explored how the
learning-to-rank techniques can be incorporated into deep RL for COPs. In this
paper, we present the learning-to-rank distillation-based COP framework, where
a high-performance ranking policy obtained by RL for a COP can be distilled
into a non-iterative, simple model, thereby achieving a low-latency COP solver.
Specifically, we employ the approximated ranking distillation to render a
score-based ranking model learnable via gradient descent. Furthermore, we use
the efficient sequence sampling to improve the inference performance with a
limited delay. With the framework, we demonstrate that a distilled model not
only achieves comparable performance to its respective, high-performance RL,
but also provides several times faster inferences. We evaluate the framework
with several COPs such as priority-based task scheduling and multidimensional
knapsack, demonstrating the benefits of the framework in terms of inference
latency and performance.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Woo_H/0/1/0/all/0/1"&gt;Honguk Woo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1"&gt;Hyunsung Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1"&gt;Sangwoo Cho&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting. (arXiv:2201.00008v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00008</id>
        <link href="http://arxiv.org/abs/2201.00008"/>
        <updated>2022-01-05T00:39:36.885Z</updated>
        <summary type="html"><![CDATA[We study the forecasting problem for traffic with dynamic, possibly
periodical, and joint spatial-temporal dependency between regions. Given the
aggregated inflow and outflow traffic of regions in a city from time slots 0 to
t-1, we predict the traffic at time t at any region. Prior arts in the area
often consider the spatial and temporal dependencies in a decoupled manner or
are rather computationally intensive in training with a large number of
hyper-parameters to tune. We propose ST-TIS, a novel, lightweight, and accurate
Spatial-Temporal Transformer with information fusion and region sampling for
traffic forecasting. ST-TIS extends the canonical Transformer with information
fusion and region sampling. The information fusion module captures the complex
spatial-temporal dependency between regions. The region sampling module is to
improve the efficiency and prediction accuracy, cutting the computation
complexity for dependency learning from $O(n^2)$ to $O(n\sqrt{n})$, where n is
the number of regions. With far fewer parameters than state-of-the-art models,
the offline training of our model is significantly faster in terms of tuning
and computation (with a reduction of up to $90\%$ on training time and network
parameters). Notwithstanding such training efficiency, extensive experiments
show that ST-TIS is substantially more accurate in online prediction than
state-of-the-art approaches (with an average improvement of up to $11\%$ on
RMSE, $14\%$ on MAPE).]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1"&gt;Guanyao Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1"&gt;Shuhan Zhong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1"&gt;Letian Xiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chan_S/0/1/0/all/0/1"&gt;S.-H. Gary Chan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1"&gt;Ruiyuan Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hung_C/0/1/0/all/0/1"&gt;Chih-Chieh Hung&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1"&gt;Wen-Chih Peng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving Out-of-Distribution Robustness via Selective Augmentation. (arXiv:2201.00299v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00299</id>
        <link href="http://arxiv.org/abs/2201.00299"/>
        <updated>2022-01-05T00:39:36.880Z</updated>
        <summary type="html"><![CDATA[Machine learning algorithms typically assume that training and test examples
are drawn from the same distribution. However, distribution shift is a common
problem in real-world applications and can cause models to perform dramatically
worse at test time. In this paper, we specifically consider the problems of
domain shifts and subpopulation shifts (eg. imbalanced data). While prior works
often seek to explicitly regularize internal representations and predictors of
the model to be domain invariant, we instead aim to regularize the whole
function without restricting the model's internal representations. This leads
to a simple mixup-based technique which learns invariant functions via
selective augmentation called LISA. LISA selectively interpolates samples
either with the same labels but different domains or with the same domain but
different labels. We analyze a linear setting and theoretically show how LISA
leads to a smaller worst-group error. Empirically, we study the effectiveness
of LISA on nine benchmarks ranging from subpopulation shifts to domain shifts,
and we find that LISA consistently outperforms other state-of-the-art methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1"&gt;Huaxiu Yao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1"&gt;Sai Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1"&gt;Linjun Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1"&gt;Weixin Liang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1"&gt;James Zou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1"&gt;Chelsea Finn&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep-learning-based upscaling method for geologic models via theory-guided convolutional neural network. (arXiv:2201.00698v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00698</id>
        <link href="http://arxiv.org/abs/2201.00698"/>
        <updated>2022-01-05T00:39:36.880Z</updated>
        <summary type="html"><![CDATA[Large-scale or high-resolution geologic models usually comprise a huge number
of grid blocks, which can be computationally demanding and time-consuming to
solve with numerical simulators. Therefore, it is advantageous to upscale
geologic models (e.g., hydraulic conductivity) from fine-scale (high-resolution
grids) to coarse-scale systems. Numerical upscaling methods have been proven to
be effective and robust for coarsening geologic models, but their efficiency
remains to be improved. In this work, a deep-learning-based method is proposed
to upscale the fine-scale geologic models, which can assist to improve
upscaling efficiency significantly. In the deep learning method, a deep
convolutional neural network (CNN) is trained to approximate the relationship
between the coarse grid of hydraulic conductivity fields and the hydraulic
heads, which can then be utilized to replace the numerical solvers while
solving the flow equations for each coarse block. In addition, physical laws
(e.g., governing equations and periodic boundary conditions) can also be
incorporated into the training process of the deep CNN model, which is termed
the theory-guided convolutional neural network (TgCNN). With the physical
information considered, dependence on the data volume of training the deep
learning models can be reduced greatly. Several subsurface flow cases are
introduced to test the performance of the proposed deep-learning-based
upscaling method, including 2D and 3D cases, and isotropic and anisotropic
cases. The results show that the deep learning method can provide equivalent
upscaling accuracy to the numerical method, and efficiency can be improved
significantly compared to numerical upscaling.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1"&gt;Nanzhe Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liao_Q/0/1/0/all/0/1"&gt;Qinzhuo Liao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1"&gt;Haibin Chang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1"&gt;Dongxiao Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representation Topology Divergence: A Method for Comparing Neural Network Representations. (arXiv:2201.00058v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00058</id>
        <link href="http://arxiv.org/abs/2201.00058"/>
        <updated>2022-01-05T00:39:36.876Z</updated>
        <summary type="html"><![CDATA[Comparison of data representations is a complex multi-aspect problem that has
not enjoyed a complete solution yet. We propose a method for comparing two data
representations. We introduce the Representation Topology Divergence (RTD),
measuring the dissimilarity in multi-scale topology between two point clouds of
equal size with a one-to-one correspondence between points. The data point
clouds are allowed to lie in different ambient spaces. The RTD is one of the
few TDA-based practical methods applicable to real machine learning datasets.
Experiments show that the proposed RTD agrees with the intuitive assessment of
data representation similarity and is sensitive to its topological structure.
We apply RTD to gain insights on neural networks representations in computer
vision and NLP domains for various problems: training dynamics analysis, data
distribution shift, transfer learning, ensemble learning, disentanglement
assessment.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Barannikov_S/0/1/0/all/0/1"&gt;Serguei Barannikov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Trofimov_I/0/1/0/all/0/1"&gt;Ilya Trofimov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Balabin_N/0/1/0/all/0/1"&gt;Nikita Balabin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1"&gt;Evgeny Burnaev&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Faster Unbalanced Optimal Transport: Translation invariant Sinkhorn and 1-D Frank-Wolfe. (arXiv:2201.00730v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2201.00730</id>
        <link href="http://arxiv.org/abs/2201.00730"/>
        <updated>2022-01-05T00:39:36.874Z</updated>
        <summary type="html"><![CDATA[Unbalanced optimal transport (UOT) extends optimal transport (OT) to take
into account mass variations to compare distributions. This is crucial to make
OT successful in ML applications, making it robust to data normalization and
outliers. The baseline algorithm is Sinkhorn, but its convergence speed might
be significantly slower for UOT than for OT. In this work, we identify the
cause for this deficiency, namely the lack of a global normalization of the
iterates, which equivalently corresponds to a translation of the dual OT
potentials. Our first contribution leverages this idea to develop a provably
accelerated Sinkhorn algorithm (coined 'translation invariant Sinkhorn') for
UOT, bridging the computational gap with OT. Our second contribution focusses
on 1-D UOT and proposes a Frank-Wolfe solver applied to this translation
invariant formulation. The linear oracle of each steps amounts to solving a 1-D
OT problems, resulting in a linear time complexity per iteration. Our last
contribution extends this method to the computation of UOT barycenter of 1-D
measures. Numerical simulations showcase the convergence speed improvement
brought by these three approaches.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Sejourne_T/0/1/0/all/0/1"&gt;Thibault S&amp;#xe9;journ&amp;#xe9;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Vialard_F/0/1/0/all/0/1"&gt;Fran&amp;#xe7;ois-Xavier Vialard&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Peyre_G/0/1/0/all/0/1"&gt;Gabriel Peyr&amp;#xe9;&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users. (arXiv:2007.06823v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2007.06823</id>
        <link href="http://arxiv.org/abs/2007.06823"/>
        <updated>2022-01-05T00:39:36.872Z</updated>
        <summary type="html"><![CDATA[Modern deep learning methods constitute incredibly powerful tools to tackle a
myriad of challenging problems. However, since deep learning methods operate as
black boxes, the uncertainty associated with their predictions is often
challenging to quantify. Bayesian statistics offer a formalism to understand
and quantify the uncertainty associated with deep neural network predictions.
This tutorial provides an overview of the relevant literature and a complete
toolset to design, implement, train, use and evaluate Bayesian Neural Networks,
i.e. Stochastic Artificial Neural Networks trained using Bayesian methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jospin_L/0/1/0/all/0/1"&gt;Laurent Valentin Jospin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1"&gt;Wray Buntine&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Boussaid_F/0/1/0/all/0/1"&gt;Farid Boussaid&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Laga_H/0/1/0/all/0/1"&gt;Hamid Laga&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1"&gt;Mohammed Bennamoun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linear Classifiers in Product Space Forms. (arXiv:2102.10204v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.10204</id>
        <link href="http://arxiv.org/abs/2102.10204"/>
        <updated>2022-01-05T00:39:36.872Z</updated>
        <summary type="html"><![CDATA[Embedding methods for product spaces are powerful techniques for
low-distortion and low-dimensional representation of complex data structures.
Here, we address the new problem of linear classification in product space
forms -- products of Euclidean, spherical, and hyperbolic spaces. First, we
describe novel formulations for linear classifiers on a Riemannian manifold
using geodesics and Riemannian metrics which generalize straight lines and
inner products in vector spaces. Second, we prove that linear classifiers in
$d$-dimensional space forms of any curvature have the same expressive power,
i.e., they can shatter exactly $d+1$ points. Third, we formalize linear
classifiers in product space forms, describe the first known perceptron and
support vector machine classifiers for such spaces and establish rigorous
convergence results for perceptrons. Moreover, we prove that the
Vapnik-Chervonenkis dimension of linear classifiers in a product space form of
dimension $d$ is \emph{at least} $d+1$. We support our theoretical findings
with simulations on several datasets, including synthetic data, image data, and
single-cell RNA sequencing (scRNA-seq) data. The results show that
classification in low-dimensional product space forms for scRNA-seq data
offers, on average, a performance improvement of $\sim15\%$ when compared to
that in Euclidean spaces of the same dimension.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tabaghi_P/0/1/0/all/0/1"&gt;Puoya Tabaghi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1"&gt;Chao Pan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1"&gt;Eli Chien&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1"&gt;Jianhao Peng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1"&gt;Olgica Milenkovic&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-attention Multi-view Representation Learning with Diversity-promoting Complementarity. (arXiv:2201.00168v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00168</id>
        <link href="http://arxiv.org/abs/2201.00168"/>
        <updated>2022-01-05T00:39:36.869Z</updated>
        <summary type="html"><![CDATA[Multi-view learning attempts to generate a model with a better performance by
exploiting the consensus and/or complementarity among multi-view data. However,
in terms of complementarity, most existing approaches only can find
representations with single complementarity rather than complementary
information with diversity. In this paper, to utilize both complementarity and
consistency simultaneously, give free rein to the potential of deep learning in
grasping diversity-promoting complementarity for multi-view representation
learning, we propose a novel supervised multi-view representation learning
algorithm, called Self-Attention Multi-View network with Diversity-Promoting
Complementarity (SAMVDPC), which exploits the consistency by a group of
encoders, uses self-attention to find complementary information entailing
diversity. Extensive experiments conducted on eight real-world datasets have
demonstrated the effectiveness of our proposed method, and show its superiority
over several baseline methods, which only consider single complementary
information.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"&gt;Jian-wei Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1"&gt;Xi-hao Ding&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1"&gt;Run-kun Lu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1"&gt;Xionglin Luo&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Layer-Wise Multi-View Decoding for Improved Natural Language Generation. (arXiv:2005.08081v6 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2005.08081</id>
        <link href="http://arxiv.org/abs/2005.08081"/>
        <updated>2022-01-05T00:39:36.869Z</updated>
        <summary type="html"><![CDATA[In sequence-to-sequence learning, e.g., natural language generation, the
decoder relies on the attention mechanism to efficiently extract information
from the encoder. While it is common practice to draw information from only the
last encoder layer, recent work has proposed to use representations from
different encoder layers for diversified levels of information. Nonetheless,
the decoder still obtains only a single view of the source sequences, which
might lead to insufficient training of the encoder layer stack due to the
hierarchy bypassing problem. In this work, we propose layer-wise multi-view
decoding, where for each decoder layer, together with the representations from
the last encoder layer, which serve as a global view, those from other encoder
layers are supplemented for a stereoscopic view of the source sequences.
Systematic experiments and analyses show that we successfully address the
hierarchy bypassing problem, require almost negligible parameter increase, and
substantially improve the performance of sequence-to-sequence learning with
deep representations on five diverse tasks, i.e., machine translation,
abstractive summarization, image captioning, video captioning, and medical
report generation. In particular, our approach achieves new state-of-the-art
results on eight benchmark datasets, including a low-resource machine
translation dataset and two low-resource medical report generation datasets.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1"&gt;Fenglin Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1"&gt;Xuancheng Ren&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1"&gt;Guangxiang Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1"&gt;Chenyu You&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1"&gt;Xian Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1"&gt;Xu Sun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Descriptors for Machine Learning Model of Generalized Force Field in Condensed Matter Systems. (arXiv:2201.00798v1 [cond-mat.str-el])]]></title>
        <id>http://arxiv.org/abs/2201.00798</id>
        <link href="http://arxiv.org/abs/2201.00798"/>
        <updated>2022-01-05T00:39:36.845Z</updated>
        <summary type="html"><![CDATA[We outline the general framework of machine learning (ML) methods for
multi-scale dynamical modeling of condensed matter systems, and in particular
of strongly correlated electron models. Complex spatial temporal behaviors in
these systems often arise from the interplay between quasi-particles and the
emergent dynamical classical degrees of freedom, such as local lattice
distortions, spins, and order-parameters. Central to the proposed framework is
the ML energy model that, by successfully emulating the time-consuming
electronic structure calculation, can accurately predict a local energy based
on the classical field in the intermediate neighborhood. In order to properly
include the symmetry of the electron Hamiltonian, a crucial component of the ML
energy model is the descriptor that transforms the neighborhood configuration
into invariant feature variables, which are input to the learning model. A
general theory of the descriptor for the classical fields is formulated, and
two types of models are distinguished depending on the presence or absence of
an internal symmetry for the classical field. Several specific approaches to
the descriptor of the classical fields are presented. Our focus is on the
group-theoretical method that offers a systematic and rigorous approach to
compute invariants based on the bispectrum coefficients. We propose an
efficient implementation of the bispectrum method based on the concept of
reference irreducible representations. Finally, the implementations of the
various descriptors are demonstrated on well-known electronic lattice models.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cond-mat/1/au:+Zhang_P/0/1/0/all/0/1"&gt;Puhan Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Zhang_S/0/1/0/all/0/1"&gt;Sheng Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Chern_G/0/1/0/all/0/1"&gt;Gia-Wei Chern&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FIFA ranking: Evaluation and path forward. (arXiv:2201.00691v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2201.00691</id>
        <link href="http://arxiv.org/abs/2201.00691"/>
        <updated>2022-01-05T00:39:36.835Z</updated>
        <summary type="html"><![CDATA[In this work we study the ranking algorithm used by F\'ed\'eration
Internationale de Football Association (FIFA); we analyze the parameters it
currently uses, show the formal probabilistic model from which it can be
derived, and optimize the latter. In particular, analyzing the games since the
introduction of the algorithm in 2018, we conclude that the game's "importance"
(as defined by FIFA) used in the algorithm is counterproductive from the point
of view of the predictive capability of the algorithm. We also postulate the
algorithm to be rooted in the formal modelling principle, where the Davidson
model proposed in 1970 seems to be an excellent candidate, preserving the form
of the algorithm currently used. The results indicate that the predictive
capability of the algorithm is notably improved by using the home-field
advantage and the explicit model for the draws in the game. Moderate, but
notable improvement may be attained by introducing the weighting of the results
with the goal differential, which although not rooted in a formal modelling
principle, is compatible with the current algorithm and can be tuned to the
characteristics of the football competition.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Szczecinski_L/0/1/0/all/0/1"&gt;Leszek Szczecinski&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Roatis_I/0/1/0/all/0/1"&gt;Iris-Ioana Roatis&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Toward the Analysis of Graph Neural Networks. (arXiv:2201.00115v1 [cs.SE])]]></title>
        <id>http://arxiv.org/abs/2201.00115</id>
        <link href="http://arxiv.org/abs/2201.00115"/>
        <updated>2022-01-05T00:39:36.832Z</updated>
        <summary type="html"><![CDATA[Graph Neural Networks (GNNs) have recently emerged as a robust framework for
graph-structured data. They have been applied to many problems such as
knowledge graph analysis, social networks recommendation, and even Covid19
detection and vaccine developments. However, unlike other deep neural networks
such as Feed Forward Neural Networks (FFNNs), few analyses such as verification
and property inferences exist, potentially due to dynamic behaviors of GNNs,
which can take arbitrary graphs as input, whereas FFNNs which only take fixed
size numerical vectors as inputs.

This paper proposes an approach to analyze GNNs by converting them into FFNNs
and reusing existing FFNNs analyses. We discuss various designs to ensure the
scalability and accuracy of the conversions. We illustrate our method on a
study case of node classification. We believe that our approach opens new
research directions for understanding and analyzing GNNs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1"&gt;Thanh-Dat Nguyen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Le_Cong_T/0/1/0/all/0/1"&gt;Thanh Le-Cong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1"&gt;ThanhVu H. Nguyen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Le_X/0/1/0/all/0/1"&gt;Xuan-Bach D. Le&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huynh_Q/0/1/0/all/0/1"&gt;Quyet-Thang Huynh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HarmoFL: Harmonizing Local and Global Drifts in Federated Learning on Heterogeneous Medical Images. (arXiv:2112.10775v2 [eess.IV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.10775</id>
        <link href="http://arxiv.org/abs/2112.10775"/>
        <updated>2022-01-05T00:39:36.830Z</updated>
        <summary type="html"><![CDATA[Multiple medical institutions collaboratively training a model using
federated learning (FL) has become a promising solution for maximizing the
potential of data-driven models, yet the non-independent and identically
distributed (non-iid) data in medical images is still an outstanding challenge
in real-world practice. The feature heterogeneity caused by diverse scanners or
protocols introduces a drift in the learning process, in both local (client)
and global (server) optimizations, which harms the convergence as well as model
performance. Many previous works have attempted to address the non-iid issue by
tackling the drift locally or globally, but how to jointly solve the two
essentially coupled drifts is still unclear. In this work, we concentrate on
handling both local and global drifts and introduce a new harmonizing framework
called HarmoFL. First, we propose to mitigate the local update drift by
normalizing amplitudes of images transformed into the frequency domain to mimic
a unified imaging setting, in order to generate a harmonized feature space
across local clients. Second, based on harmonized features, we design a client
weight perturbation guiding each local model to reach a flat optimum, where a
neighborhood area of the local optimal solution has a uniformly low loss.
Without any extra communication cost, the perturbation assists the global model
to optimize towards a converged optimal solution by aggregating several local
flat optima. We have theoretically analyzed the proposed method and empirically
conducted extensive experiments on three medical image classification and
segmentation tasks, showing that HarmoFL outperforms a set of recent
state-of-the-art methods with promising convergence behavior. Code is available
at https://github.com/med-air/HarmoFL.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Jiang_M/0/1/0/all/0/1"&gt;Meirui Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zirui Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Dou_Q/0/1/0/all/0/1"&gt;Qi Dou&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FamilySeer: Towards Optimized Tensor Codes by Exploiting Computation Subgraph Similarity. (arXiv:2201.00194v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00194</id>
        <link href="http://arxiv.org/abs/2201.00194"/>
        <updated>2022-01-05T00:39:36.829Z</updated>
        <summary type="html"><![CDATA[Deploying various deep learning (DL) models efficiently has boosted the
research on DL compilers. The difficulty of generating optimized tensor codes
drives DL compiler to ask for the auto-tuning approaches, and the increasing
demands require increasing auto-tuning efficiency and quality. Currently, the
DL compilers partition the input DL models into several subgraphs and leverage
the auto-tuning to find the optimal tensor codes of these subgraphs. However,
existing auto-tuning approaches usually regard subgraphs as individual ones and
overlook the similarities across them, and thus fail to exploit better tensor
codes under limited time budgets. We propose FamilySeer, an auto-tuning
framework for DL compilers that can generate better tensor codes even with
limited time budgets. FamilySeer exploits the similarities and differences
among subgraphs can organize them into subgraph families, where the tuning of
one subgraph can also improve other subgraphs within the same family. The cost
model of each family gets more purified training samples generated by the
family and becomes more accurate so that the costly measurements on real
hardware can be replaced with the lightweight estimation through cost model.
Our experiments show that FamilySeer can generate model codes with the same
code performance more efficiently than state-of-the-art auto-tuning frameworks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"&gt;Shanjun Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1"&gt;Mingzhen Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1"&gt;Hailong Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yi Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luan_Z/0/1/0/all/0/1"&gt;Zhongzhi Luan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qian_D/0/1/0/all/0/1"&gt;Depei Qian&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Latent Gaussian Model Boosting. (arXiv:2105.08966v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08966</id>
        <link href="http://arxiv.org/abs/2105.08966"/>
        <updated>2022-01-05T00:39:36.829Z</updated>
        <summary type="html"><![CDATA[Latent Gaussian models and boosting are widely used techniques in statistics
and machine learning. Tree-boosting shows excellent prediction accuracy on many
data sets, but potential drawbacks are that it assumes conditional independence
of samples, produces discontinuous predictions for, e.g., spatial data, and it
can have difficulty with high-cardinality categorical variables. Latent
Gaussian models, such as Gaussian process and grouped random effects models,
are flexible prior models which explicitly model dependence among samples and
which allow for efficient learning of predictor functions and for making
probabilistic predictions. However, existing latent Gaussian models usually
assume either a zero or a linear prior mean function which can be an
unrealistic assumption. This article introduces a novel approach that combines
boosting and latent Gaussian models to remedy the above-mentioned drawbacks and
to leverage the advantages of both techniques. We obtain increased prediction
accuracy compared to existing approaches in both simulated and real-world data
experiments.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sigrist_F/0/1/0/all/0/1"&gt;Fabio Sigrist&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uncertainty Detection in EEG Neural Decoding Models. (arXiv:2201.00627v1 [eess.SP])]]></title>
        <id>http://arxiv.org/abs/2201.00627</id>
        <link href="http://arxiv.org/abs/2201.00627"/>
        <updated>2022-01-05T00:39:36.824Z</updated>
        <summary type="html"><![CDATA[EEG decoding systems based on deep neural networks have been widely used in
decision making of brain computer interfaces (BCI). Their predictions, however,
can be unreliable given the significant variance and noise in EEG signals.
Previous works on EEG analysis mainly focus on the exploration of noise pattern
in the source signal, while the uncertainty during the decoding process is
largely unexplored. Automatically detecting and quantifying such decoding
uncertainty is important for BCI motor imagery applications such as robotic arm
control etc. In this work, we proposed an uncertainty estimation model (UE-EEG)
to explore the uncertainty during the EEG decoding process, which considers
both the uncertainty in the input signal and the uncertainty in the model. The
model utilized dropout oriented method for model uncertainty estimation, and
Bayesian neural network is adopted for modeling the uncertainty of input data.
The model can be integrated into current widely used deep learning classifiers
without change of architecture. We performed extensive experiments for
uncertainty estimation in both intra-subject EEG decoding and cross-subject EEG
decoding on two public motor imagery datasets, where the proposed model
achieves significant improvement on the quality of estimated uncertainty and
demonstrates the proposed UE-EEG is a useful tool for BCI applications.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Duan_T/0/1/0/all/0/1"&gt;Tiehang Duan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zhenyi Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1"&gt;Sheng Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Srihari_S/0/1/0/all/0/1"&gt;Sargur N. Srihari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yang_H/0/1/0/all/0/1"&gt;Hui Yang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Feature Fusion for Mitosis Counting. (arXiv:2002.03781v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2002.03781</id>
        <link href="http://arxiv.org/abs/2002.03781"/>
        <updated>2022-01-05T00:39:36.816Z</updated>
        <summary type="html"><![CDATA[Each woman living in the United States has about 1 in 8 chance of developing
invasive breast cancer. The mitotic cell count is one of the most common tests
to assess the aggressiveness or grade of breast cancer. In this prognosis,
histopathology images must be examined by a pathologist using high-resolution
microscopes to count the cells. Unfortunately, can be an exhaustive task with
poor reproducibility, especially for non-experts. Deep learning networks have
recently been adapted to medical applications which are able to automatically
localize these regions of interest. However, these region-based networks lack
the ability to take advantage of the segmentation features produced by a full
image CNN which are often used as a sole method of detection. Therefore, the
proposed method leverages Faster RCNN for object detection while fusing
segmentation features generated by a UNet with RGB image features to achieve an
F-score of 0.508 on the MITOS-ATYPIA 2014 mitosis counting challenge dataset,
outperforming state-of-the-art methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yancey_R/0/1/0/all/0/1"&gt;Robin Elizabeth Yancey&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reinforcement Learning for Task Specifications with Action-Constraints. (arXiv:2201.00286v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00286</id>
        <link href="http://arxiv.org/abs/2201.00286"/>
        <updated>2022-01-05T00:39:36.805Z</updated>
        <summary type="html"><![CDATA[In this paper, we use concepts from supervisory control theory of discrete
event systems to propose a method to learn optimal control policies for a
finite-state Markov Decision Process (MDP) in which (only) certain sequences of
actions are deemed unsafe (respectively safe). We assume that the set of action
sequences that are deemed unsafe and/or safe are given in terms of a
finite-state automaton; and propose a supervisor that disables a subset of
actions at every state of the MDP so that the constraints on action sequence
are satisfied. Then we present a version of the Q-learning algorithm for
learning optimal policies in the presence of non-Markovian action-sequence and
state constraints, where we use the development of reward machines to handle
the state constraints. We illustrate the method using an example that captures
the utility of automata-based methods for non-Markovian state and action
specifications for reinforcement learning and show the results of simulations
in this setting.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Raman_A/0/1/0/all/0/1"&gt;Arun Raman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shagrithaya_K/0/1/0/all/0/1"&gt;Keerthan Shagrithaya&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bhatnagar_S/0/1/0/all/0/1"&gt;Shalabh Bhatnagar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reconstructing spectral functions via automatic differentiation. (arXiv:2111.14760v2 [hep-ph] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.14760</id>
        <link href="http://arxiv.org/abs/2111.14760"/>
        <updated>2022-01-05T00:39:36.792Z</updated>
        <summary type="html"><![CDATA[Reconstructing spectral functions from Euclidean Green's functions is an
important inverse problem in many-body physics. However, the inversion is
proved to be ill-posed in the realistic systems with noisy Green's functions.
In this Letter, we propose an automatic differentiation(AD) framework as a
generic tool for the spectral reconstruction from propagator observable.
Exploiting the neural networks' regularization as a non-local smoothness
regulator of the spectral function, we represent spectral functions by neural
networks and use the propagator's reconstruction error to optimize the network
parameters unsupervisedly. In the training process, except for the
positive-definite form for the spectral function, there are no other explicit
physical priors embedded into the neural networks. The reconstruction
performance is assessed through relative entropy and mean square error for two
different network representations. Compared to the maximum entropy method, the
AD framework achieves better performance in the large-noise situation. It is
noted that the freedom of introducing non-local regularization is an inherent
advantage of the present framework and may lead to substantial improvements in
solving inverse problems.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/hep-ph/1/au:+Wang_L/0/1/0/all/0/1"&gt;Lingxiao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/hep-ph/1/au:+Shi_S/0/1/0/all/0/1"&gt;Shuzhe Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/hep-ph/1/au:+Zhou_K/0/1/0/all/0/1"&gt;Kai Zhou&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self Punishment and Reward Backfill for Deep Q-Learning. (arXiv:2004.05002v2 [cs.AI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2004.05002</id>
        <link href="http://arxiv.org/abs/2004.05002"/>
        <updated>2022-01-05T00:39:36.758Z</updated>
        <summary type="html"><![CDATA[Reinforcement learning agents learn by encouraging behaviours which maximize
their total reward, usually provided by the environment. In many environments,
however, the reward is provided after a series of actions rather than each
single action, leading the agent to experience ambiguity in terms of whether
those actions are effective, an issue known as the credit assignment problem.
In this paper, we propose two strategies inspired by behavioural psychology to
enable the agent to intrinsically estimate more informative reward values for
actions with no reward. The first strategy, called self-punishment (SP),
discourages the agent from making mistakes that lead to undesirable terminal
states. The second strategy, called the rewards backfill (RB), backpropagates
the rewards between two rewarded actions. We prove that, under certain
assumptions and regardless of the reinforcement learning algorithm used, these
two strategies maintain the order of policies in the space of all possible
policies in terms of their total reward, and, by extension, maintain the
optimal policy. Hence, our proposed strategies integrate with any reinforcement
learning algorithm that learns a value or action-value function through
experience. We incorporated these two strategies into three popular deep
reinforcement learning approaches and evaluated the results on thirty Atari
games. After parameter tuning, our results indicate that the proposed
strategies improve the tested methods in over 65 percent of tested games by up
to over 25 times performance improvement.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bonyadi_M/0/1/0/all/0/1"&gt;Mohammad Reza Bonyadi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1"&gt;Rui Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ziaei_M/0/1/0/all/0/1"&gt;Maryam Ziaei&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mind Your Solver! On Adversarial Attack and Defense for Combinatorial Optimization. (arXiv:2201.00402v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2201.00402</id>
        <link href="http://arxiv.org/abs/2201.00402"/>
        <updated>2022-01-05T00:39:36.720Z</updated>
        <summary type="html"><![CDATA[Combinatorial optimization (CO) is a long-standing challenging task not only
in its inherent complexity (e.g. NP-hard) but also the possible sensitivity to
input conditions. In this paper, we take an initiative on developing the
mechanisms for adversarial attack and defense towards combinatorial
optimization solvers, whereby the solver is treated as a black-box function and
the original problem's underlying graph structure (which is often available and
associated with the problem instance, e.g. DAG, TSP) is attacked under a given
budget. In particular, we present a simple yet effective defense strategy to
modify the graph structure to increase the robustness of solvers, which shows
its universal effectiveness across tasks and solvers.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Lu_H/0/1/0/all/0/1"&gt;Han Lu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Li_Z/0/1/0/all/0/1"&gt;Zenan Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Wang_R/0/1/0/all/0/1"&gt;Runzhong Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Ren_Q/0/1/0/all/0/1"&gt;Qibing Ren&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Yan_J/0/1/0/all/0/1"&gt;Junchi Yan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Yang_X/0/1/0/all/0/1"&gt;Xiaokang Yang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Review of Open-World Learning and Steps Toward Open-World Learning Without Labels. (arXiv:2011.12906v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2011.12906</id>
        <link href="http://arxiv.org/abs/2011.12906"/>
        <updated>2022-01-05T00:39:36.720Z</updated>
        <summary type="html"><![CDATA[In open-world learning, an agent starts with a set of known classes, detects,
and manages things that it does not know, and learns them over time from a
non-stationary stream of data. Open-world learning is related to but also
distinct from a multitude of other learning problems and this paper briefly
analyzes the key differences between a wide range of problems including
incremental learning, generalized novelty discovery, and generalized zero-shot
learning. This paper formalizes various open-world learning problems including
open-world learning without labels. These open-world problems can be addressed
with modifications to known elements, we present a new framework that enables
agents to combine various modules for novelty-detection,
novelty-characterization, incremental learning, and instance management to
learn new classes from a stream of unlabeled data in an unsupervised manner,
survey how to adapt a few state-of-the-art techniques to fit the framework and
use them to define seven baselines for performance on the open-world learning
without labels problem. We then discuss open-world learning quality and analyze
how that can improve instance management. We also discuss some of the general
ambiguity issues that occur in open-world learning without labels.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jafarzadeh_M/0/1/0/all/0/1"&gt;Mohsen Jafarzadeh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dhamija_A/0/1/0/all/0/1"&gt;Akshay Raj Dhamija&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cruz_S/0/1/0/all/0/1"&gt;Steve Cruz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1"&gt;Chunchun Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ahmad_T/0/1/0/all/0/1"&gt;Touqeer Ahmad&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Boult_T/0/1/0/all/0/1"&gt;Terrance E. Boult&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Latent structure blockmodels for Bayesian spectral graph clustering. (arXiv:2107.01734v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2107.01734</id>
        <link href="http://arxiv.org/abs/2107.01734"/>
        <updated>2022-01-05T00:39:36.711Z</updated>
        <summary type="html"><![CDATA[Spectral embedding of network adjacency matrices often produces node
representations living approximately around low-dimensional submanifold
structures. In particular, hidden substructure is expected to arise when the
graph is generated from a latent position model. Furthermore, the presence of
communities within the network might generate community-specific submanifold
structures in the embedding, but this is not explicitly accounted for in most
statistical models for networks. In this article, a class of models called
latent structure block models (LSBM) is proposed to address such scenarios,
allowing for graph clustering when community-specific one dimensional manifold
structure is present. LSBMs focus on a specific class of latent space model,
the random dot product graph (RDPG), and assign a latent submanifold to the
latent positions of each community. A Bayesian model for the embeddings arising
from LSBMs is discussed, and shown to have a good performance on simulated and
real world network data. The model is able to correctly recover the underlying
communities living in a one-dimensional manifold, even when the parametric form
of the underlying curves is unknown, achieving remarkable results on a variety
of real data.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Passino_F/0/1/0/all/0/1"&gt;Francesco Sanna Passino&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Heard_N/0/1/0/all/0/1"&gt;Nicholas A. Heard&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distributed Evolution Strategies Using TPUs for Meta-Learning. (arXiv:2201.00093v1 [cs.NE])]]></title>
        <id>http://arxiv.org/abs/2201.00093</id>
        <link href="http://arxiv.org/abs/2201.00093"/>
        <updated>2022-01-05T00:39:36.710Z</updated>
        <summary type="html"><![CDATA[Meta-learning traditionally relies on backpropagation through entire tasks to
iteratively improve a model's learning dynamics. However, this approach is
computationally intractable when scaled to complex tasks. We propose a
distributed evolutionary meta-learning strategy using Tensor Processing Units
(TPUs) that is highly parallel and scalable to arbitrarily long tasks with no
increase in memory cost. Using a Prototypical Network trained with evolution
strategies on the Omniglot dataset, we achieved an accuracy of 98.4% on a
5-shot classification problem. Our algorithm used as much as 40 times less
memory than automatic differentiation to compute the gradient, with the
resulting model achieving accuracy within 1.3% of a backpropagation-trained
equivalent (99.6%). We observed better classification accuracy as high as 99.1%
with larger population configurations. We further experimentally validate the
stability and performance of ES-ProtoNet across a variety of training
conditions (varying population size, model size, number of workers, shot, way,
ES hyperparameters, etc.). Our contributions are twofold: we provide the first
assessment of evolutionary meta-learning in a supervised setting, and create a
general framework for distributed evolution strategies on TPUs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sheng_A/0/1/0/all/0/1"&gt;Alex Sheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1"&gt;Derek He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Persistent Homology for Brain Networks via Wasserstein Graph Clustering. (arXiv:2201.00087v1 [math.AT])]]></title>
        <id>http://arxiv.org/abs/2201.00087</id>
        <link href="http://arxiv.org/abs/2201.00087"/>
        <updated>2022-01-05T00:39:36.680Z</updated>
        <summary type="html"><![CDATA[We present the novel Wasserstein graph clustering for dynamically changing
graphs. The Wasserstein clustering penalizes the topological discrepancy
between graphs. The Wasserstein clustering is shown to outperform the widely
used k-means clustering. The method applied in more accurate determination of
the state spaces of dynamically changing functional brain networks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Chung_M/0/1/0/all/0/1"&gt;Moo K. Chung&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Huang_S/0/1/0/all/0/1"&gt;Shih-Gu Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Carroll_I/0/1/0/all/0/1"&gt;Ian C. Carroll&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Calhoun_V/0/1/0/all/0/1"&gt;Vince D. Calhoun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Goldsmith_H/0/1/0/all/0/1"&gt;H. Hill Goldsmith&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AutoGCL: Automated Graph Contrastive Learning via Learnable View Generators. (arXiv:2109.10259v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.10259</id>
        <link href="http://arxiv.org/abs/2109.10259"/>
        <updated>2022-01-05T00:39:36.680Z</updated>
        <summary type="html"><![CDATA[Contrastive learning has been widely applied to graph representation
learning, where the view generators play a vital role in generating effective
contrastive samples. Most of the existing contrastive learning methods employ
pre-defined view generation methods, e.g., node drop or edge perturbation,
which usually cannot adapt to input data or preserve the original semantic
structures well. To address this issue, we propose a novel framework named
Automated Graph Contrastive Learning (AutoGCL) in this paper. Specifically,
AutoGCL employs a set of learnable graph view generators orchestrated by an
auto augmentation strategy, where every graph view generator learns a
probability distribution of graphs conditioned by the input. While the graph
view generators in AutoGCL preserve the most representative structures of the
original graph in generation of every contrastive sample, the auto augmentation
learns policies to introduce adequate augmentation variances in the whole
contrastive learning procedure. Furthermore, AutoGCL adopts a joint training
strategy to train the learnable view generators, the graph encoder, and the
classifier in an end-to-end manner, resulting in topological heterogeneity yet
semantic similarity in the generation of contrastive samples. Extensive
experiments on semi-supervised learning, unsupervised learning, and transfer
learning demonstrate the superiority of our AutoGCL framework over the
state-of-the-arts in graph contrastive learning. In addition, the visualization
results further confirm that the learnable view generators can deliver more
compact and semantically meaningful contrastive samples compared against the
existing view generation methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1"&gt;Yihang Yin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1"&gt;Qingzhong Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1"&gt;Siyu Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1"&gt;Haoyi Xiong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"&gt;Xiang Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning shared neural manifolds from multi-subject FMRI data. (arXiv:2201.00622v1 [q-bio.NC])]]></title>
        <id>http://arxiv.org/abs/2201.00622</id>
        <link href="http://arxiv.org/abs/2201.00622"/>
        <updated>2022-01-05T00:39:36.650Z</updated>
        <summary type="html"><![CDATA[Functional magnetic resonance imaging (fMRI) is a notoriously noisy
measurement of brain activity because of the large variations between
individuals, signals marred by environmental differences during collection, and
spatiotemporal averaging required by the measurement resolution. In addition,
the data is extremely high dimensional, with the space of the activity
typically having much lower intrinsic dimension. In order to understand the
connection between stimuli of interest and brain activity, and analyze
differences and commonalities between subjects, it becomes important to learn a
meaningful embedding of the data that denoises, and reveals its intrinsic
structure. Specifically, we assume that while noise varies significantly
between individuals, true responses to stimuli will share common,
low-dimensional features between subjects which are jointly discoverable.
Similar approaches have been exploited previously but they have mainly used
linear methods such as PCA and shared response modeling (SRM). In contrast, we
propose a neural network called MRMD-AE (manifold-regularized multiple decoder,
autoencoder), that learns a common embedding from multiple subjects in an
experiment while retaining the ability to decode to individual raw fMRI
signals. We show that our learned common space represents an extensible
manifold (where new points not seen during training can be mapped), improves
the classification accuracy of stimulus features of unseen timepoints, as well
as improves cross-subject translation of fMRI signals. We believe this
framework can be used for many downstream applications such as guided
brain-computer interface (BCI) training in the future.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/q-bio/1/au:+Huang_J/0/1/0/all/0/1"&gt;Jessie Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Busch_E/0/1/0/all/0/1"&gt;Erica L. Busch&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Wallenstein_T/0/1/0/all/0/1"&gt;Tom Wallenstein&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Gerasimiuk_M/0/1/0/all/0/1"&gt;Michal Gerasimiuk&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Benz_A/0/1/0/all/0/1"&gt;Andrew Benz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Lajoie_G/0/1/0/all/0/1"&gt;Guillaume Lajoie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Wolf_G/0/1/0/all/0/1"&gt;Guy Wolf&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Turk_Browne_N/0/1/0/all/0/1"&gt;Nicholas B. Turk-Browne&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Krishnaswamy_S/0/1/0/all/0/1"&gt;Smita Krishnaswamy&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the convex hull of convex quadratic optimization problems with indicators. (arXiv:2201.00387v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2201.00387</id>
        <link href="http://arxiv.org/abs/2201.00387"/>
        <updated>2022-01-05T00:39:36.649Z</updated>
        <summary type="html"><![CDATA[We consider the convex quadratic optimization problem with indicator
variables and arbitrary constraints on the indicators. We show that a convex
hull description of the associated mixed-integer set in an extended space with
a quadratic number of additional variables consists of a single positive
semidefinite constraint (explicitly stated) and linear constraints. In
particular, convexification of this class of problems reduces to describing a
polyhedral set in an extended formulation. We also give descriptions in the
original space of variables: we provide a description based on an infinite
number of conic-quadratic inequalities, which are "finitely generated." In
particular, it is possible to characterize whether a given inequality is
necessary to describe the convex-hull. The new theory presented here unifies
several previously established results, and paves the way toward utilizing
polyhedral methods to analyze the convex hull of mixed-integer nonlinear sets.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Wei_L/0/1/0/all/0/1"&gt;Linchuan Wei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Atamturk_A/0/1/0/all/0/1"&gt;Alper Atamt&amp;#xfc;rk&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Gomez_A/0/1/0/all/0/1"&gt;Andr&amp;#xe9;s G&amp;#xf3;mez&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Kucukyavuz_S/0/1/0/all/0/1"&gt;Simge K&amp;#xfc;&amp;#xe7;&amp;#xfc;kyavuz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Applications of Gaussian Mutation for Self Adaptation in Evolutionary Genetic Algorithms. (arXiv:2201.00285v1 [cs.NE])]]></title>
        <id>http://arxiv.org/abs/2201.00285</id>
        <link href="http://arxiv.org/abs/2201.00285"/>
        <updated>2022-01-05T00:39:36.648Z</updated>
        <summary type="html"><![CDATA[In recent years, optimization problems have become increasingly more
prevalent due to the need for more powerful computational methods. With the
more recent advent of technology such as artificial intelligence, new
metaheuristics are needed that enhance the capabilities of classical
algorithms. More recently, researchers have been looking at Charles Darwin's
theory of natural selection and evolution as a means of enhancing current
approaches using machine learning. In 1960, the first genetic algorithm was
developed by John H. Holland and his student. We explore the mathematical
intuition of the genetic algorithm in developing systems capable of evolving
using Gaussian mutation, as well as its implications in solving optimization
problems.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bell_O/0/1/0/all/0/1"&gt;Okezue Bell&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Natural Language Processing: Recent Advances, Challenges, and Future Directions. (arXiv:2201.00768v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2201.00768</id>
        <link href="http://arxiv.org/abs/2201.00768"/>
        <updated>2022-01-05T00:39:36.646Z</updated>
        <summary type="html"><![CDATA[Recent natural language processing (NLP) techniques have accomplished high
performance on benchmark datasets, primarily due to the significant improvement
in the performance of deep learning. The advances in the research community
have led to great enhancements in state-of-the-art production systems for NLP
tasks, such as virtual assistants, speech recognition, and sentiment analysis.
However, such NLP systems still often fail when tested with adversarial
attacks. The initial lack of robustness exposed troubling gaps in current
models' language understanding capabilities, creating problems when NLP systems
are deployed in real life. In this paper, we present a structured overview of
NLP robustness research by summarizing the literature in a systemic way across
various dimensions. We then take a deep-dive into the various dimensions of
robustness, across techniques, metrics, embeddings, and benchmarks. Finally, we
argue that robustness should be multi-dimensional, provide insights into
current research, identify gaps in the literature to suggest directions worth
pursuing to address these gaps.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Omar_M/0/1/0/all/0/1"&gt;Marwan Omar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1"&gt;Soohyeon Choi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nyang_D/0/1/0/all/0/1"&gt;DaeHun Nyang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mohaisen_D/0/1/0/all/0/1"&gt;David Mohaisen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Statistical and Topological Properties of Sliced Probability Divergences. (arXiv:2003.05783v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2003.05783</id>
        <link href="http://arxiv.org/abs/2003.05783"/>
        <updated>2022-01-05T00:39:36.645Z</updated>
        <summary type="html"><![CDATA[The idea of slicing divergences has been proven to be successful when
comparing two probability measures in various machine learning applications
including generative modeling, and consists in computing the expected value of
a `base divergence' between one-dimensional random projections of the two
measures. However, the topological, statistical, and computational consequences
of this technique have not yet been well-established. In this paper, we aim at
bridging this gap and derive various theoretical properties of sliced
probability divergences. First, we show that slicing preserves the metric
axioms and the weak continuity of the divergence, implying that the sliced
divergence will share similar topological properties. We then precise the
results in the case where the base divergence belongs to the class of integral
probability metrics. On the other hand, we establish that, under mild
conditions, the sample complexity of a sliced divergence does not depend on the
problem dimension. We finally apply our general results to several base
divergences, and illustrate our theory on both synthetic and real data
experiments.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Nadjahi_K/0/1/0/all/0/1"&gt;Kimia Nadjahi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1"&gt;Alain Durmus&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Chizat_L/0/1/0/all/0/1"&gt;L&amp;#xe9;na&amp;#xef;c Chizat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Kolouri_S/0/1/0/all/0/1"&gt;Soheil Kolouri&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Shahrampour_S/0/1/0/all/0/1"&gt;Shahin Shahrampour&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1"&gt;Umut &amp;#x15e;im&amp;#x15f;ekli&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Elsa: Energy-based learning for semi-supervised anomaly detection. (arXiv:2103.15296v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.15296</id>
        <link href="http://arxiv.org/abs/2103.15296"/>
        <updated>2022-01-05T00:39:36.644Z</updated>
        <summary type="html"><![CDATA[Anomaly detection aims at identifying deviant instances from the normal data
distribution. Many advances have been made in the field, including the
innovative use of unsupervised contrastive learning. However, existing methods
generally assume clean training data and are limited when the data contain
unknown anomalies. This paper presents Elsa, a novel semi-supervised anomaly
detection approach that unifies the concept of energy-based models with
unsupervised contrastive learning. Elsa instills robustness against any data
contamination by a carefully designed fine-tuning step based on the new energy
function that forces the normal data to be divided into classes of prototypes.
Experiments on multiple contamination scenarios show the proposed model
achieves SOTA performance. Extensive analyses also verify the contribution of
each component in the proposed model. Beyond the experiments, we also offer a
theoretical interpretation of why contrastive learning alone cannot detect
anomalies under data contamination.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1"&gt;Sungwon Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1"&gt;Hyeonho Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1"&gt;Seungeon Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1"&gt;Sungwon Park&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cha_M/0/1/0/all/0/1"&gt;Meeyoung Cha&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Risk Bounds for Over-parameterized Maximum Margin Classification on Sub-Gaussian Mixtures. (arXiv:2104.13628v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.13628</id>
        <link href="http://arxiv.org/abs/2104.13628"/>
        <updated>2022-01-05T00:39:36.639Z</updated>
        <summary type="html"><![CDATA[Modern machine learning systems such as deep neural networks are often highly
over-parameterized so that they can fit the noisy training data exactly, yet
they can still achieve small test errors in practice. In this paper, we study
this "benign overfitting" phenomenon of the maximum margin classifier for
linear classification problems. Specifically, we consider data generated from
sub-Gaussian mixtures, and provide a tight risk bound for the maximum margin
linear classifier in the over-parameterized setting. Our results precisely
characterize the condition under which benign overfitting can occur in linear
classification problems, and improve on previous work. They also have direct
implications for over-parameterized logistic regression.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"&gt;Yuan Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Belkin_M/0/1/0/all/0/1"&gt;Mikhail Belkin&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Topic Analysis of Superconductivity Literature by Semantic Non-negative Matrix Factorization. (arXiv:2201.00687v1 [cs.DL])]]></title>
        <id>http://arxiv.org/abs/2201.00687</id>
        <link href="http://arxiv.org/abs/2201.00687"/>
        <updated>2022-01-05T00:39:36.638Z</updated>
        <summary type="html"><![CDATA[We utilize a recently developed topic modeling method called SeNMFk,
extending the standard Non-negative Matrix Factorization (NMF) methods by
incorporating the semantic structure of the text, and adding a robust system
for determining the number of topics. With SeNMFk, we were able to extract
coherent topics validated by human experts. From these topics, a few are
relatively general and cover broad concepts, while the majority can be
precisely mapped to specific scientific effects or measurement techniques. The
topics also differ by ubiquity, with only three topics prevalent in almost 40
percent of the abstract, while each specific topic tends to dominate a small
subset of the abstracts. These results demonstrate the ability of SeNMFk to
produce a layered and nuanced analysis of large scientific corpora.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Stanev_V/0/1/0/all/0/1"&gt;Valentin Stanev&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Skau_E/0/1/0/all/0/1"&gt;Erik Skau&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Takeuchi_I/0/1/0/all/0/1"&gt;Ichiro Takeuchi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Alexandrov_B/0/1/0/all/0/1"&gt;Boian S. Alexandrov&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Non-Stationary Bandits for Learning in Repeated Cournot Games with Non-Stationary Demand. (arXiv:2201.00486v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00486</id>
        <link href="http://arxiv.org/abs/2201.00486"/>
        <updated>2022-01-05T00:39:36.635Z</updated>
        <summary type="html"><![CDATA[Many past attempts at modeling repeated Cournot games assume that demand is
stationary. This does not align with real-world scenarios in which market
demands can evolve over a product's lifetime for a myriad of reasons. In this
paper, we model repeated Cournot games with non-stationary demand such that
firms/agents face separate instances of non-stationary multi-armed bandit
problem. The set of arms/actions that an agent can choose from represents
discrete production quantities; here, the action space is ordered. Agents are
independent and autonomous, and cannot observe anything from the environment;
they can only see their own rewards after taking an action, and only work
towards maximizing these rewards. We propose a novel algorithm 'Adaptive with
Weighted Exploration (AWE) $\epsilon$-greedy' which is remotely based on the
well-known $\epsilon$-greedy approach. This algorithm detects and quantifies
changes in rewards due to varying market demand and varies learning rate and
exploration rate in proportion to the degree of changes in demand, thus
enabling agents to better identify new optimal actions. For efficient
exploration, it also deploys a mechanism for weighing actions that takes
advantage of the ordered action space. We use simulations to study the
emergence of various equilibria in the market. In addition, we study the
scalability of our approach in terms number of total agents in the system and
the size of action space. We consider both symmetric and asymmetric firms in
our models. We found that using our proposed method, agents are able to swiftly
change their course of action according to the changes in demand, and they also
engage in collusive behavior in many simulations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Taywade_K/0/1/0/all/0/1"&gt;Kshitija Taywade&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Harrison_B/0/1/0/all/0/1"&gt;Brent Harrison&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Goldsmith_J/0/1/0/all/0/1"&gt;Judy Goldsmith&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fair Data Representation for Machine Learning at the Pareto Frontier. (arXiv:2201.00292v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2201.00292</id>
        <link href="http://arxiv.org/abs/2201.00292"/>
        <updated>2022-01-05T00:39:36.633Z</updated>
        <summary type="html"><![CDATA[As machine learning powered decision making is playing an increasingly
important role in our daily lives, it is imperative to strive for fairness of
the underlying data processing and algorithms. We propose a pre-processing
algorithm for fair data representation via which L2- objective supervised
learning algorithms result in an estimation of the Pareto frontier between
prediction error and statistical disparity. In particular, the present work
applies the optimal positive definite affine transport maps to approach the
post-processing Wasserstein barycenter characterization of the optimal fair
L2-objective supervised learning via a pre-processing data deformation. We call
the resulting data Wasserstein pseudo-barycenter. Furthermore, we show that the
Wasserstein geodesics from the learning outcome marginals to the barycenter
characterizes the Pareto frontier between L2-loss and total Wasserstein
distance among learning outcome marginals. Thereby, an application of McCann
interpolation generalizes the pseudo-barycenter to a family of data
representations via which L2-objective supervised learning algorithms result in
the Pareto frontier. Numerical simulations underscore the advantages of the
proposed data representation: (1) the pre-processing step is compositive with
arbitrary L2-objective supervised learning methods and unseen data; (2) the
fair representation protects data privacy by preventing the training machine
from direct or indirect access to the sensitive information of the data; (3)
the optimal affine map results in efficient computation of fair supervised
learning on high-dimensional data; (4) experimental results shed light on the
fairness of L2-objective unsupervised learning via the proposed fair data
representation.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Xu_S/0/1/0/all/0/1"&gt;Shizhou Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Strohmer_T/0/1/0/all/0/1"&gt;Thomas Strohmer&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Novelty-based Generalization Evaluation for Traffic Light Detection. (arXiv:2201.00531v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.00531</id>
        <link href="http://arxiv.org/abs/2201.00531"/>
        <updated>2022-01-05T00:39:36.629Z</updated>
        <summary type="html"><![CDATA[The advent of Convolutional Neural Networks (CNNs) has led to their
application in several domains. One noteworthy application is the perception
system for autonomous driving that relies on the predictions from CNNs.
Practitioners evaluate the generalization ability of such CNNs by calculating
various metrics on an independent test dataset. A test dataset is often chosen
based on only one precondition, i.e., its elements are not a part of the
training data. Such a dataset may contain objects that are both similar and
novel w.r.t. the training dataset. Nevertheless, existing works do not reckon
the novelty of the test samples and treat them all equally for evaluating
generalization. Such novelty-based evaluations are of significance to validate
the fitness of a CNN in autonomous driving applications. Hence, we propose a
CNN generalization scoring framework that considers novelty of objects in the
test dataset. We begin with the representation learning technique to reduce the
image data into a low-dimensional space. It is on this space we estimate the
novelty of the test samples. Finally, we calculate the generalization score as
a combination of the test data prediction performance and novelty. We perform
an experimental study of the same for our traffic light detection application.
In addition, we systematically visualize the results for an interpretable
notion of novelty.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Shekar_A/0/1/0/all/0/1"&gt;Arvind Kumar Shekar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lake_L/0/1/0/all/0/1"&gt;Laureen Lake&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gou_L/0/1/0/all/0/1"&gt;Liang Gou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ren_L/0/1/0/all/0/1"&gt;Liu Ren&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rethinking Feature Uncertainty in Stochastic Neural Networks for Adversarial Robustness. (arXiv:2201.00148v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00148</id>
        <link href="http://arxiv.org/abs/2201.00148"/>
        <updated>2022-01-05T00:39:36.610Z</updated>
        <summary type="html"><![CDATA[It is well-known that deep neural networks (DNNs) have shown remarkable
success in many fields. However, when adding an imperceptible magnitude
perturbation on the model input, the model performance might get rapid
decrease. To address this issue, a randomness technique has been proposed
recently, named Stochastic Neural Networks (SNNs). Specifically, SNNs inject
randomness into the model to defend against unseen attacks and improve the
adversarial robustness. However, existed studies on SNNs mainly focus on
injecting fixed or learnable noises to model weights/activations. In this
paper, we find that the existed SNNs performances are largely bottlenecked by
the feature representation ability. Surprisingly, simply maximizing the
variance per dimension of the feature distribution leads to a considerable
boost beyond all previous methods, which we named maximize feature distribution
variance stochastic neural network (MFDV-SNN). Extensive experiments on
well-known white- and black-box attacks show that MFDV-SNN achieves a
significant improvement over existing methods, which indicates that it is a
simple but effective method to improve model robustness.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1"&gt;Hao Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1"&gt;Min Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1"&gt;Zhengfei Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1"&gt;Yun Zhou&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stochastic Weight Averaging Revisited. (arXiv:2201.00519v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00519</id>
        <link href="http://arxiv.org/abs/2201.00519"/>
        <updated>2022-01-05T00:39:36.599Z</updated>
        <summary type="html"><![CDATA[Stochastic weight averaging (SWA) is recognized as a simple while one
effective approach to improve the generalization of stochastic gradient descent
(SGD) for training deep neural networks (DNNs). A common insight to explain its
success is that averaging weights following an SGD process equipped with
cyclical or high constant learning rates can discover wider optima, which then
lead to better generalization. We give a new insight that does not concur with
the above one. We characterize that SWA's performance is highly dependent on to
what extent the SGD process that runs before SWA converges, and the operation
of weight averaging only contributes to variance reduction. This new insight
suggests practical guides on better algorithm design. As an instantiation, we
show that following an SGD process with insufficient convergence, running SWA
more times leads to continual incremental benefits in terms of generalization.
Our findings are corroborated by extensive experiments across different network
architectures, including a baseline CNN, PreResNet-164, WideResNet-28-10,
VGG16, ResNet-50, ResNet-152, DenseNet-161, and different datasets including
CIFAR-{10,100}, and Imagenet.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1"&gt;Hao Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1"&gt;Jiyong Jin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1"&gt;Bin Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Minimum Excess Risk in Bayesian Learning. (arXiv:2012.14868v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.14868</id>
        <link href="http://arxiv.org/abs/2012.14868"/>
        <updated>2022-01-05T00:39:36.599Z</updated>
        <summary type="html"><![CDATA[We analyze the best achievable performance of Bayesian learning under
generative models by defining and upper-bounding the minimum excess risk (MER):
the gap between the minimum expected loss attainable by learning from data and
the minimum expected loss that could be achieved if the model realization were
known. The definition of MER provides a principled way to define different
notions of uncertainties in Bayesian learning, including the aleatoric
uncertainty and the minimum epistemic uncertainty. Two methods for deriving
upper bounds for the MER are presented. The first method, generally suitable
for Bayesian learning with a parametric generative model, upper-bounds the MER
by the conditional mutual information between the model parameters and the
quantity being predicted given the observed data. It allows us to quantify the
rate at which the MER decays to zero as more data becomes available. Under
realizable models, this method also relates the MER to the richness of the
generative function class, notably the VC dimension in binary classification.
The second method, particularly suitable for Bayesian learning with a
parametric predictive model, relates the MER to the minimum estimation error of
the model parameters from data. It explicitly shows how the uncertainty in
model parameter estimation translates to the MER and to the final prediction
uncertainty. We also extend the definition and analysis of MER to the setting
with multiple model families and the setting with nonparametric models. Along
the discussions we draw some comparisons between the MER in Bayesian learning
and the excess risk in frequentist learning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1"&gt;Aolin Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Raginsky_M/0/1/0/all/0/1"&gt;Maxim Raginsky&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Mixed Integer Programming Approach to Training Dense Neural Networks. (arXiv:2201.00723v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00723</id>
        <link href="http://arxiv.org/abs/2201.00723"/>
        <updated>2022-01-05T00:39:36.598Z</updated>
        <summary type="html"><![CDATA[Artificial Neural Networks (ANNs) are prevalent machine learning models that
have been applied across various real world classification tasks. ANNs require
a large amount of data to have strong out of sample performance, and many
algorithms for training ANN parameters are based on stochastic gradient descent
(SGD). However, the SGD ANNs that tend to perform best on prediction tasks are
trained in an end to end manner that requires a large number of model
parameters and random initialization. This means training ANNs is very time
consuming and the resulting models take a lot of memory to deploy. In order to
train more parsimonious ANN models, we propose the use of alternative methods
from the constrained optimization literature for ANN training and pretraining.
In particular, we propose novel mixed integer programming (MIP) formulations
for training fully-connected ANNs. Our formulations can account for both binary
activation and rectified linear unit (ReLU) activation ANNs, and for the use of
a log likelihood loss. We also develop a layer-wise greedy approach, a
technique adapted for reducing the number of layers in the ANN, for model
pretraining using our MIP formulations. We then present numerical experiments
comparing our MIP based methods against existing SGD based approaches and show
that we are able to achieve models with competitive out of sample performance
that are significantly more parsimonious.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Patil_V/0/1/0/all/0/1"&gt;Vrishabh Patil&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mintz_Y/0/1/0/all/0/1"&gt;Yonatan Mintz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Sensitivity of Deep Learning Based Text Classification Algorithms to Practical Input Perturbations. (arXiv:2201.00318v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2201.00318</id>
        <link href="http://arxiv.org/abs/2201.00318"/>
        <updated>2022-01-05T00:39:36.592Z</updated>
        <summary type="html"><![CDATA[Text classification is a fundamental Natural Language Processing task that
has a wide variety of applications, where deep learning approaches have
produced state-of-the-art results. While these models have been heavily
criticized for their black-box nature, their robustness to slight perturbations
in input text has been a matter of concern. In this work, we carry out a
data-focused study evaluating the impact of systematic practical perturbations
on the performance of the deep learning based text classification models like
CNN, LSTM, and BERT-based algorithms. The perturbations are induced by the
addition and removal of unwanted tokens like punctuation and stop-words that
are minimally associated with the final performance of the model. We show that
these deep learning approaches including BERT are sensitive to such legitimate
input perturbations on four standard benchmark datasets SST2, TREC-6, BBC News,
and tweet_eval. We observe that BERT is more susceptible to the removal of
tokens as compared to the addition of tokens. Moreover, LSTM is slightly more
sensitive to input perturbations as compared to CNN based model. The work also
serves as a practical guide to assessing the impact of discrepancies in
train-test conditions on the final performance of models.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Miyajiwala_A/0/1/0/all/0/1"&gt;Aamir Miyajiwala&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ladkat_A/0/1/0/all/0/1"&gt;Arnav Ladkat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jagadale_S/0/1/0/all/0/1"&gt;Samiksha Jagadale&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1"&gt;Raviraj Joshi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SAFL: A Self-Attention Scene Text Recognizer with Focal Loss. (arXiv:2201.00132v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.00132</id>
        <link href="http://arxiv.org/abs/2201.00132"/>
        <updated>2022-01-05T00:39:36.585Z</updated>
        <summary type="html"><![CDATA[In the last decades, scene text recognition has gained worldwide attention
from both the academic community and actual users due to its importance in a
wide range of applications. Despite achievements in optical character
recognition, scene text recognition remains challenging due to inherent
problems such as distortions or irregular layout. Most of the existing
approaches mainly leverage recurrence or convolution-based neural networks.
However, while recurrent neural networks (RNNs) usually suffer from slow
training speed due to sequential computation and encounter problems as
vanishing gradient or bottleneck, CNN endures a trade-off between complexity
and performance. In this paper, we introduce SAFL, a self-attention-based
neural network model with the focal loss for scene text recognition, to
overcome the limitation of the existing approaches. The use of focal loss
instead of negative log-likelihood helps the model focus more on low-frequency
samples training. Moreover, to deal with the distortions and irregular texts,
we exploit Spatial TransformerNetwork (STN) to rectify text before passing to
the recognition network. We perform experiments to compare the performance of
the proposed model with seven benchmarks. The numerical results show that our
model achieves the best performance.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tran_B/0/1/0/all/0/1"&gt;Bao Hieu Tran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Le_Cong_T/0/1/0/all/0/1"&gt;Thanh Le-Cong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1"&gt;Huu Manh Nguyen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1"&gt;Duc Anh Le&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1"&gt;Thanh Hung Nguyen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1"&gt;Phi Le Nguyen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Support vector machines and Radon's theorem. (arXiv:2011.00617v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2011.00617</id>
        <link href="http://arxiv.org/abs/2011.00617"/>
        <updated>2022-01-05T00:39:36.563Z</updated>
        <summary type="html"><![CDATA[A support vector machine (SVM) is an algorithm which finds a hyperplane that
optimally separates labeled data points in $\mathbb{R}^n$ into positive and
negative classes. The data points on the margin of this separating hyperplane
are called support vectors. We connect the possible configurations of support
vectors to Radon's theorem, which provides guarantees for when a set of points
can be divided into two classes (positive and negative) whose convex hulls
intersect. If the convex hulls of the positive and negative support vectors are
projected onto a separating hyperplane, the projections intersect in at least
one point if and only if the hyperplane is optimal. Further, with a particular
type of general position, we show that (a) the projected convex hulls of the
support vectors intersect in exactly one point, (b) the support vectors are
stable under perturbation, (c) there are at most $n+1$ support vectors, and (d)
every number of support vectors from 2 up to $n+1$ is possible. Finally, we
perform computer simulations studying the expected number of support vectors,
and their configurations, for randomly generated data. We observe that as the
distance between classes of points increases for this type of randomly
generated data, configurations with two support vectors become the most likely
configurations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Adams_H/0/1/0/all/0/1"&gt;Henry Adams&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Farnell_E/0/1/0/all/0/1"&gt;Elin Farnell&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Story_B/0/1/0/all/0/1"&gt;Brittany Story&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Continuity of Generalized Entropy and Statistical Learning. (arXiv:2012.15829v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.15829</id>
        <link href="http://arxiv.org/abs/2012.15829"/>
        <updated>2022-01-05T00:39:36.553Z</updated>
        <summary type="html"><![CDATA[We study the continuity property of the generalized entropy as a function of
the underlying probability distribution, defined with an action space and a
loss function, and use this property to answer the basic questions in
statistical learning theory: the excess risk analyses for various learning
methods. We first derive upper and lower bounds for the entropy difference of
two distributions in terms of several commonly used f-divergences, the
Wasserstein distance, a distance that depends on the action space and the loss
function, and the Bregman divergence generated by the entropy, which also
induces bounds in terms of the Euclidean distance between the two
distributions. Examples are given along with the discussion of each general
result, comparisons are made with the existing entropy difference bounds, and
new mutual information upper bounds are derived based on the new results. We
then apply the entropy difference bounds to the theory of statistical learning.
It is shown that the excess risks in the two popular learning paradigms, the
frequentist learning and the Bayesian learning, both can be studied with the
continuity property of different forms of the generalized entropy. The analysis
is then extended to the continuity of generalized conditional entropy. The
extension provides performance bounds for Bayes decision making with mismatched
distributions. It also leads to excess risk bounds for a third paradigm of
learning, where the decision rule is optimally designed under the projection of
the empirical distribution to a predefined family of distributions. We thus
establish a unified method of excess risk analysis for the three major
paradigms of statistical learning, through the continuity of generalized
entropy.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1"&gt;Aolin Xu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Concept Embeddings for Fuzzy Logic Verification of Deep Neural Networks in Perception Tasks. (arXiv:2201.00572v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.00572</id>
        <link href="http://arxiv.org/abs/2201.00572"/>
        <updated>2022-01-05T00:39:36.540Z</updated>
        <summary type="html"><![CDATA[One major drawback of deep neural networks (DNNs) for use in sensitive
application domains is their black-box nature. This makes it hard to verify or
monitor complex, symbolic requirements. In this work, we present a simple, yet
effective, approach to verify whether a trained convolutional neural network
(CNN) respects specified symbolic background knowledge. The knowledge may
consist of any fuzzy predicate logic rules. For this, we utilize methods from
explainable artificial intelligence (XAI): First, using concept embedding
analysis, the output of a computer vision CNN is post-hoc enriched by concept
outputs; second, logical rules from prior knowledge are fuzzified to serve as
continuous-valued functions on the concept outputs. These can be evaluated with
little computational overhead. We demonstrate three diverse use-cases of our
method on stateof-the-art object detectors: Finding corner cases, utilizing the
rules for detecting and localizing DNN misbehavior during runtime, and
comparing the logical consistency of DNNs. The latter is used to find related
differences between EfficientDet D1 and Mask R-CNN object detectors. We show
that this approach benefits from fuzziness and calibrating the concept outputs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Schwalbe_G/0/1/0/all/0/1"&gt;Gesina Schwalbe&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wirth_C/0/1/0/all/0/1"&gt;Christian Wirth&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schmid_U/0/1/0/all/0/1"&gt;Ute Schmid&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Toward Causal-Aware RL: State-Wise Action-Refined Temporal Difference. (arXiv:2201.00354v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00354</id>
        <link href="http://arxiv.org/abs/2201.00354"/>
        <updated>2022-01-05T00:39:36.518Z</updated>
        <summary type="html"><![CDATA[Although it is well known that exploration plays a key role in Reinforcement
Learning (RL), prevailing exploration strategies for continuous control tasks
in RL are mainly based on naive isotropic Gaussian noise regardless of the
causality relationship between action space and the task and consider all
dimensions of actions equally important. In this work, we propose to conduct
interventions on the primal action space to discover the causal relationship
between the action space and the task reward. We propose the method of
State-Wise Action Refined (SWAR), which addresses the issue of action space
redundancy and promote causality discovery in RL. We formulate causality
discovery in RL tasks as a state-dependent action space selection problem and
propose two practical algorithms as solutions. The first approach, TD-SWAR,
detects task-related actions during temporal difference learning, while the
second approach, Dyn-SWAR, reveals important actions through dynamic model
prediction. Empirically, both methods provide approaches to understand the
decisions made by RL agents and improve learning efficiency in action-redundant
tasks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1"&gt;Hao Sun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The complementarity of a diverse range of deep learning features extracted from video content for video recommendation. (arXiv:2011.10834v2 [cs.IR] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2011.10834</id>
        <link href="http://arxiv.org/abs/2011.10834"/>
        <updated>2022-01-05T00:39:36.510Z</updated>
        <summary type="html"><![CDATA[Following the popularisation of media streaming, a number of video streaming
services are continuously buying new video content to mine the potential profit
from them. As such, the newly added content has to be handled well to be
recommended to suitable users. In this paper, we address the new item
cold-start problem by exploring the potential of various deep learning features
to provide video recommendations. The deep learning features investigated
include features that capture the visual-appearance, audio and motion
information from video content. We also explore different fusion methods to
evaluate how well these feature modalities can be combined to fully exploit the
complementary information captured by them. Experiments on a real-world video
dataset for movie recommendations show that deep learning features outperform
hand-crafted features. In particular, recommendations generated with deep
learning audio features and action-centric deep learning features are superior
to MFCC and state-of-the-art iDT features. In addition, the combination of
various deep learning features with hand-crafted features and textual metadata
yields significant improvement in recommendations compared to combining only
the former.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Almeida_A/0/1/0/all/0/1"&gt;Adolfo Almeida&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Villiers_J/0/1/0/all/0/1"&gt;Johan Pieter de Villiers&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1"&gt;Allan De Freitas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Velayudan_M/0/1/0/all/0/1"&gt;Mergandran Velayudan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Operator Deep Q-Learning: Zero-Shot Reward Transferring in Reinforcement Learning. (arXiv:2201.00236v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00236</id>
        <link href="http://arxiv.org/abs/2201.00236"/>
        <updated>2022-01-05T00:39:36.480Z</updated>
        <summary type="html"><![CDATA[Reinforcement learning (RL) has drawn increasing interests in recent years
due to its tremendous success in various applications. However, standard RL
algorithms can only be applied for single reward function, and cannot adapt to
an unseen reward function quickly. In this paper, we advocate a general
operator view of reinforcement learning, which enables us to directly
approximate the operator that maps from reward function to value function. The
benefit of learning the operator is that we can incorporate any new reward
function as input and attain its corresponding value function in a zero-shot
manner. To approximate this special type of operator, we design a number of
novel operator neural network architectures based on its theoretical
properties. Our design of operator networks outperform the existing methods and
the standard design of general purpose operator network, and we demonstrate the
benefit of our operator deep Q-learning framework in several tasks including
reward transferring for offline policy evaluation (OPE) and reward transferring
for offline policy optimization in a range of tasks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1"&gt;Ziyang Tang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1"&gt;Yihao Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1"&gt;Qiang Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Dimensional Model Compression of Vision Transformer. (arXiv:2201.00043v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2201.00043</id>
        <link href="http://arxiv.org/abs/2201.00043"/>
        <updated>2022-01-05T00:39:36.473Z</updated>
        <summary type="html"><![CDATA[Vision transformers (ViT) have recently attracted considerable attentions,
but the huge computational cost remains an issue for practical deployment.
Previous ViT pruning methods tend to prune the model along one dimension
solely, which may suffer from excessive reduction and lead to sub-optimal model
quality. In contrast, we advocate a multi-dimensional ViT compression paradigm,
and propose to harness the redundancy reduction from attention head, neuron and
sequence dimensions jointly. We firstly propose a statistical dependence based
pruning criterion that is generalizable to different dimensions for identifying
deleterious components. Moreover, we cast the multi-dimensional compression as
an optimization, learning the optimal pruning policy across the three
dimensions that maximizes the compressed model's accuracy under a computational
budget. The problem is solved by our adapted Gaussian process search with
expected improvement. Experimental results show that our method effectively
reduces the computational cost of various ViT models. For example, our method
reduces 40\% FLOPs without top-1 accuracy loss for DeiT and T2T-ViT models,
outperforming previous state-of-the-arts.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1"&gt;Zejiang Hou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kung_S/0/1/0/all/0/1"&gt;Sun-Yuan Kung&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Application of Machine Learning Methods in Inferring Surface Water Groundwater Exchanges using High Temporal Resolution Temperature Measurements. (arXiv:2201.00726v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00726</id>
        <link href="http://arxiv.org/abs/2201.00726"/>
        <updated>2022-01-05T00:39:36.466Z</updated>
        <summary type="html"><![CDATA[We examine the ability of machine learning (ML) and deep learning (DL)
algorithms to infer surface/ground exchange flux based on subsurface
temperature observations. The observations and fluxes are produced from a
high-resolution numerical model representing conditions in the Columbia River
near the Department of Energy Hanford site located in southeastern Washington
State. Random measurement error, of varying magnitude, is added to the
synthetic temperature observations. The results indicate that both ML and DL
methods can be used to infer the surface/ground exchange flux. DL methods,
especially convolutional neural networks, outperform the ML methods when used
to interpret noisy temperature data with a smoothing filter applied. However,
the ML methods also performed well and they are can better identify a reduced
number of important observations, which could be useful for measurement network
optimization. Surprisingly, the ML and DL methods better inferred upward flux
than downward flux. This is in direct contrast to previous findings using
numerical models to infer flux from temperature observations and it may suggest
that combined use of ML or DL inference with numerical inference could improve
flux estimation beneath river systems.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Moghaddam_M/0/1/0/all/0/1"&gt;Mohammad A. Moghaddam&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ferre_T/0/1/0/all/0/1"&gt;Ty P. A. Ferre&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"&gt;Xingyuan Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1"&gt;Kewei Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ehsani_M/0/1/0/all/0/1"&gt;Mohammad Reza Ehsani&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA['Moving On' -- Investigating Inventors' Ethnic Origins Using Supervised Learning. (arXiv:2201.00578v1 [econ.GN])]]></title>
        <id>http://arxiv.org/abs/2201.00578</id>
        <link href="http://arxiv.org/abs/2201.00578"/>
        <updated>2022-01-05T00:39:36.460Z</updated>
        <summary type="html"><![CDATA[Patent data provides rich information about technical inventions, but does
not disclose the ethnic origin of inventors. In this paper, I use supervised
learning techniques to infer this information. To do so, I construct a dataset
of 95'202 labeled names and train an artificial recurrent neural network with
long-short-term memory (LSTM) to predict ethnic origins based on names. The
trained network achieves an overall performance of 91% across 17 ethnic
origins. I use this model to classify and investigate the ethnic origins of
2.68 million inventors and provide novel descriptive evidence regarding their
ethnic origin composition over time and across countries and technological
fields. The global ethnic origin composition has become more diverse over the
last decades, which was mostly due to a relative increase of Asian origin
inventors. Furthermore, the prevalence of foreign-origin inventors is
especially high in the USA, but has also increased in other high-income
economies. This increase was mainly driven by an inflow of non-western
inventors into emerging high-technology fields for the USA, but not for other
high-income countries.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/econ/1/au:+Niggli_M/0/1/0/all/0/1"&gt;Matthias Niggli&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-supervised Stance Detection of Tweets Via Distant Network Supervision. (arXiv:2201.00614v1 [cs.SI])]]></title>
        <id>http://arxiv.org/abs/2201.00614</id>
        <link href="http://arxiv.org/abs/2201.00614"/>
        <updated>2022-01-05T00:39:36.452Z</updated>
        <summary type="html"><![CDATA[Detecting and labeling stance in social media text is strongly motivated by
hate speech detection, poll prediction, engagement forecasting, and concerted
propaganda detection. Today's best neural stance detectors need large volumes
of training data, which is difficult to curate given the fast-changing
landscape of social media text and issues on which users opine. Homophily
properties over the social network provide strong signal of coarse-grained
user-level stance. But semi-supervised approaches for tweet-level stance
detection fail to properly leverage homophily. In light of this, We present
SANDS, a new semi-supervised stance detector. SANDS starts from very few
labeled tweets. It builds multiple deep feature views of tweets. It also uses a
distant supervision signal from the social network to provide a surrogate loss
signal to the component learners. We prepare two new tweet datasets comprising
over 236,000 politically tinted tweets from two demographics (US and India)
posted by over 87,000 users, their follower-followee graph, and over 8,000
tweets annotated by linguists. SANDS achieves a macro-F1 score of 0.55 (0.49)
on US (India)-based datasets, outperforming 17 baselines (including variants of
SANDS) substantially, particularly for minority stance labels and noisy text.
Numerous ablation experiments on SANDS disentangle the dynamics of textual and
network-propagated stance signals.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1"&gt;Subhabrata Dutta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Caur_S/0/1/0/all/0/1"&gt;Samiya Caur&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_S/0/1/0/all/0/1"&gt;Soumen Chakrabarti&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1"&gt;Tanmoy Chakraborty&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Memory Networks with Self-supervised Learning for Unsupervised Anomaly Detection. (arXiv:2201.00464v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00464</id>
        <link href="http://arxiv.org/abs/2201.00464"/>
        <updated>2022-01-05T00:39:36.429Z</updated>
        <summary type="html"><![CDATA[Unsupervised anomaly detection aims to build models to effectively detect
unseen anomalies by only training on the normal data. Although previous
reconstruction-based methods have made fruitful progress, their generalization
ability is limited due to two critical challenges. First, the training dataset
only contains normal patterns, which limits the model generalization ability.
Second, the feature representations learned by existing models often lack
representativeness which hampers the ability to preserve the diversity of
normal patterns. In this paper, we propose a novel approach called Adaptive
Memory Network with Self-supervised Learning (AMSL) to address these challenges
and enhance the generalization ability in unsupervised anomaly detection. Based
on the convolutional autoencoder structure, AMSL incorporates a self-supervised
learning module to learn general normal patterns and an adaptive memory fusion
module to learn rich feature representations. Experiments on four public
multivariate time series datasets demonstrate that AMSL significantly improves
the performance compared to other state-of-the-art methods. Specifically, on
the largest CAP sleep stage detection dataset with 900 million samples, AMSL
outperforms the second-best baseline by \textbf{4}\%+ in both accuracy and F1
score. Apart from the enhanced generalization ability, AMSL is also more robust
against input noise.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yuxin Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"&gt;Jindong Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yiqiang Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1"&gt;Han Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1"&gt;Tao Qin&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploiting Bi-directional Global Transition Patterns and Personal Preferences for Missing POI Category Identification. (arXiv:2201.00014v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00014</id>
        <link href="http://arxiv.org/abs/2201.00014"/>
        <updated>2022-01-05T00:39:36.423Z</updated>
        <summary type="html"><![CDATA[Recent years have witnessed the increasing popularity of Location-based
Social Network (LBSN) services, which provides unparalleled opportunities to
build personalized Point-of-Interest (POI) recommender systems. Existing POI
recommendation and location prediction tasks utilize past information for
future recommendation or prediction from a single direction perspective, while
the missing POI category identification task needs to utilize the check-in
information both before and after the missing category. Therefore, a
long-standing challenge is how to effectively identify the missing POI
categories at any time in the real-world check-in data of mobile users. To this
end, in this paper, we propose a novel neural network approach to identify the
missing POI categories by integrating both bi-directional global non-personal
transition patterns and personal preferences of users. Specifically, we
delicately design an attention matching cell to model how well the check-in
category information matches their non-personal transition patterns and
personal preferences. Finally, we evaluate our model on two real-world
datasets, which clearly validate its effectiveness compared with the
state-of-the-art baselines. Furthermore, our model can be naturally extended to
address next POI category recommendation and prediction tasks with competitive
performance.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xi_D/0/1/0/all/0/1"&gt;Dongbo Xi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1"&gt;Fuzhen Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yanchi Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1"&gt;Hengshu Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1"&gt;Pengpeng Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1"&gt;Chang Tan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1"&gt;Qing He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SAE: Sequential Anchored Ensembles. (arXiv:2201.00649v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00649</id>
        <link href="http://arxiv.org/abs/2201.00649"/>
        <updated>2022-01-05T00:39:36.416Z</updated>
        <summary type="html"><![CDATA[Computing the Bayesian posterior of a neural network is a challenging task
due to the high-dimensionality of the parameter space. Anchored ensembles
approximate the posterior by training an ensemble of neural networks on
anchored losses designed for the optima to follow the Bayesian posterior.
Training an ensemble, however, becomes computationally expensive as its number
of members grows since the full training procedure is repeated for each member.
In this note, we present Sequential Anchored Ensembles (SAE), a lightweight
alternative to anchored ensembles. Instead of training each member of the
ensemble from scratch, the members are trained sequentially on losses sampled
with high auto-correlation, hence enabling fast convergence of the neural
networks and efficient approximation of the Bayesian posterior. SAE outperform
anchored ensembles, for a given computational budget, on some benchmarks while
showing comparable performance on the others and achieved 2nd and 3rd place in
the light and extended tracks of the NeurIPS 2021 Approximate Inference in
Bayesian Deep Learning competition.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Delaunoy_A/0/1/0/all/0/1"&gt;Arnaud Delaunoy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Louppe_G/0/1/0/all/0/1"&gt;Gilles Louppe&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Matrix Decomposition and Applications. (arXiv:2201.00145v1 [math.NA])]]></title>
        <id>http://arxiv.org/abs/2201.00145</id>
        <link href="http://arxiv.org/abs/2201.00145"/>
        <updated>2022-01-05T00:39:36.409Z</updated>
        <summary type="html"><![CDATA[In 1954, Alston S. Householder published Principles of Numerical Analysis,
one of the first modern treatments on matrix decomposition that favored a
(block) LU decomposition-the factorization of a matrix into the product of
lower and upper triangular matrices. And now, matrix decomposition has become a
core technology in machine learning, largely due to the development of the back
propagation algorithm in fitting a neural network. The sole aim of this survey
is to give a self-contained introduction to concepts and mathematical tools in
numerical linear algebra and matrix analysis in order to seamlessly introduce
matrix decomposition techniques and their applications in subsequent sections.
However, we clearly realize our inability to cover all the useful and
interesting results concerning matrix decomposition and given the paucity of
scope to present this discussion, e.g., the separated analysis of the Euclidean
space, Hermitian space, Hilbert space, and things in the complex domain. We
refer the reader to literature in the field of linear algebra for a more
detailed introduction to the related fields.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Lu_J/0/1/0/all/0/1"&gt;Jun Lu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Recover the spectrum of covariance matrix: a non-asymptotic iterative method. (arXiv:2201.00230v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2201.00230</id>
        <link href="http://arxiv.org/abs/2201.00230"/>
        <updated>2022-01-05T00:39:36.409Z</updated>
        <summary type="html"><![CDATA[It is well known the sample covariance has a consistent bias in the spectrum,
for example spectrum of Wishart matrix follows the Marchenko-Pastur law. We in
this work introduce an iterative algorithm 'Concent' that actively eliminate
this bias and recover the true spectrum for small and moderate dimensions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1"&gt;Juntao Duan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Popescu_I/0/1/0/all/0/1"&gt;Ionel Popescu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Matzinger_H/0/1/0/all/0/1"&gt;Heinrich Matzinger&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Artificial Intelligence and Statistical Techniques in Short-Term Load Forecasting: A Review. (arXiv:2201.00437v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00437</id>
        <link href="http://arxiv.org/abs/2201.00437"/>
        <updated>2022-01-05T00:39:36.389Z</updated>
        <summary type="html"><![CDATA[Electrical utilities depend on short-term demand forecasting to proactively
adjust production and distribution in anticipation of major variations. This
systematic review analyzes 240 works published in scholarly journals between
2000 and 2019 that focus on applying Artificial Intelligence (AI), statistical,
and hybrid models to short-term load forecasting (STLF). This work represents
the most comprehensive review of works on this subject to date. A complete
analysis of the literature is conducted to identify the most popular and
accurate techniques as well as existing gaps. The findings show that although
Artificial Neural Networks (ANN) continue to be the most commonly used
standalone technique, researchers have been exceedingly opting for hybrid
combinations of different techniques to leverage the combined advantages of
individual methods. The review demonstrates that it is commonly possible with
these hybrid combinations to achieve prediction accuracy exceeding 99%. The
most successful duration for short-term forecasting has been identified as
prediction for a duration of one day at an hourly interval. The review has
identified a deficiency in access to datasets needed for training of the
models. A significant gap has been identified in researching regions other than
Asia, Europe, North America, and Australia.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Nassif_A/0/1/0/all/0/1"&gt;Ali Bou Nassif&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Soudan_B/0/1/0/all/0/1"&gt;Bassel Soudan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Azzeh_M/0/1/0/all/0/1"&gt;Mohammad Azzeh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Attilli_I/0/1/0/all/0/1"&gt;Imtinan Attilli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+AlMulla_O/0/1/0/all/0/1"&gt;Omar AlMulla&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Asymptotic Convergence of Deep Multi-Agent Actor-Critic Algorithms. (arXiv:2201.00570v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00570</id>
        <link href="http://arxiv.org/abs/2201.00570"/>
        <updated>2022-01-05T00:39:36.367Z</updated>
        <summary type="html"><![CDATA[We present sufficient conditions that ensure convergence of the multi-agent
Deep Deterministic Policy Gradient (DDPG) algorithm. It is an example of one of
the most popular paradigms of Deep Reinforcement Learning (DeepRL) for tackling
continuous action spaces: the actor-critic paradigm. In the setting considered
herein, each agent observes a part of the global state space in order to take
local actions, for which it receives local rewards. For every agent, DDPG
trains a local actor (policy) and a local critic (Q-function). The analysis
shows that multi-agent DDPG using neural networks to approximate the local
policies and critics converge to limits with the following properties: The
critic limits minimize the average squared Bellman loss; the actor limits
parameterize a policy that maximizes the local critic's approximation of
$Q_i^*$, where $i$ is the agent index. The averaging is with respect to a
probability distribution over the global state-action space. It captures the
asymptotics of all local training processes. Finally, we extend the analysis to
a fully decentralized setting where agents communicate over a wireless network
prone to delays and losses; a typical scenario in, e.g., robotic applications.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Redder_A/0/1/0/all/0/1"&gt;Adrian Redder&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ramaswamy_A/0/1/0/all/0/1"&gt;Arunselvan Ramaswamy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Karl_H/0/1/0/all/0/1"&gt;Holger Karl&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[KerGNNs: Interpretable Graph Neural Networks with Graph Kernels. (arXiv:2201.00491v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00491</id>
        <link href="http://arxiv.org/abs/2201.00491"/>
        <updated>2022-01-05T00:39:36.357Z</updated>
        <summary type="html"><![CDATA[Graph kernels are historically the most widely-used technique for graph
classification tasks. However, these methods suffer from limited performance
because of the hand-crafted combinatorial features of graphs. In recent years,
graph neural networks (GNNs) have become the state-of-the-art method in
downstream graph-related tasks due to their superior performance. Most GNNs are
based on Message Passing Neural Network (MPNN) frameworks. However, recent
studies show that MPNNs can not exceed the power of the Weisfeiler-Lehman (WL)
algorithm in graph isomorphism test. To address the limitations of existing
graph kernel and GNN methods, in this paper, we propose a novel GNN framework,
termed \textit{Kernel Graph Neural Networks} (KerGNNs), which integrates graph
kernels into the message passing process of GNNs. Inspired by convolution
filters in convolutional neural networks (CNNs), KerGNNs adopt trainable hidden
graphs as graph filters which are combined with subgraphs to update node
embeddings using graph kernels. In addition, we show that MPNNs can be viewed
as special cases of KerGNNs. We apply KerGNNs to multiple graph-related tasks
and use cross-validation to make fair comparisons with benchmarks. We show that
our method achieves competitive performance compared with existing
state-of-the-art methods, demonstrating the potential to increase the
representation ability of GNNs. We also show that the trained graph filters in
KerGNNs can reveal the local graph structures of the dataset, which
significantly improves the model interpretability compared with conventional
GNN models.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Feng_A/0/1/0/all/0/1"&gt;Aosong Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1"&gt;Chenyu You&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"&gt;Shiqiang Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tassiulas_L/0/1/0/all/0/1"&gt;Leandros Tassiulas&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Avoiding Catastrophe: Active Dendrites Enable Multi-Task Learning in Dynamic Environments. (arXiv:2201.00042v1 [cs.NE])]]></title>
        <id>http://arxiv.org/abs/2201.00042</id>
        <link href="http://arxiv.org/abs/2201.00042"/>
        <updated>2022-01-05T00:39:36.349Z</updated>
        <summary type="html"><![CDATA[A key challenge for AI is to build embodied systems that operate in
dynamically changing environments. Such systems must adapt to changing task
contexts and learn continuously. Although standard deep learning systems
achieve state of the art results on static benchmarks, they often struggle in
dynamic scenarios. In these settings, error signals from multiple contexts can
interfere with one another, ultimately leading to a phenomenon known as
catastrophic forgetting. In this article we investigate biologically inspired
architectures as solutions to these problems. Specifically, we show that the
biophysical properties of dendrites and local inhibitory systems enable
networks to dynamically restrict and route information in a context-specific
manner. Our key contributions are as follows. First, we propose a novel
artificial neural network architecture that incorporates active dendrites and
sparse representations into the standard deep learning framework. Next, we
study the performance of this architecture on two separate benchmarks requiring
task-based adaptation: Meta-World, a multi-task reinforcement learning
environment where a robotic agent must learn to solve a variety of manipulation
tasks simultaneously; and a continual learning benchmark in which the model's
prediction task changes throughout training. Analysis on both benchmarks
demonstrates the emergence of overlapping but distinct and sparse subnetworks,
allowing the system to fluidly learn multiple tasks with minimal forgetting.
Our neural implementation marks the first time a single architecture has
achieved competitive results on both multi-task and continual learning
settings. Our research sheds light on how biological properties of neurons can
inform deep learning systems to address dynamic scenarios that are typically
impossible for traditional ANNs to solve.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Iyer_A/0/1/0/all/0/1"&gt;Abhiram Iyer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grewal_K/0/1/0/all/0/1"&gt;Karan Grewal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Velu_A/0/1/0/all/0/1"&gt;Akash Velu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Souza_L/0/1/0/all/0/1"&gt;Lucas Oliveira Souza&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Forest_J/0/1/0/all/0/1"&gt;Jeremy Forest&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ahmad_S/0/1/0/all/0/1"&gt;Subutai Ahmad&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Role of Data Augmentation Strategies in Knowledge Distillation for Wearable Sensor Data. (arXiv:2201.00111v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00111</id>
        <link href="http://arxiv.org/abs/2201.00111"/>
        <updated>2022-01-05T00:39:36.341Z</updated>
        <summary type="html"><![CDATA[Deep neural networks are parametrized by several thousands or millions of
parameters, and have shown tremendous success in many classification problems.
However, the large number of parameters makes it difficult to integrate these
models into edge devices such as smartphones and wearable devices. To address
this problem, knowledge distillation (KD) has been widely employed, that uses a
pre-trained high capacity network to train a much smaller network, suitable for
edge devices. In this paper, for the first time, we study the applicability and
challenges of using KD for time-series data for wearable devices. Successful
application of KD requires specific choices of data augmentation methods during
training. However, it is not yet known if there exists a coherent strategy for
choosing an augmentation approach during KD. In this paper, we report the
results of a detailed study that compares and contrasts various common choices
and some hybrid data augmentation strategies in KD based human activity
analysis. Research in this area is often limited as there are not many
comprehensive databases available in the public domain from wearable devices.
Our study considers databases from small scale publicly available to one
derived from a large scale interventional study into human activity and
sedentary behavior. We find that the choice of data augmentation techniques
during KD have a variable level of impact on end performance, and find that the
optimal network choice as well as data augmentation strategies are specific to
a dataset at hand. However, we also conclude with a general set of
recommendations that can provide a strong baseline performance across
databases.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jeon_E/0/1/0/all/0/1"&gt;Eun Som Jeon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Som_A/0/1/0/all/0/1"&gt;Anirudh Som&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1"&gt;Ankita Shukla&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hasanaj_K/0/1/0/all/0/1"&gt;Kristina Hasanaj&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Buman_M/0/1/0/all/0/1"&gt;Matthew P. Buman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Turaga_P/0/1/0/all/0/1"&gt;Pavan Turaga&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Signal Reconstruction Techniques for IoT Air Pollution Monitoring Platforms. (arXiv:2201.00378v1 [eess.SP])]]></title>
        <id>http://arxiv.org/abs/2201.00378</id>
        <link href="http://arxiv.org/abs/2201.00378"/>
        <updated>2022-01-05T00:39:36.333Z</updated>
        <summary type="html"><![CDATA[Air pollution monitoring platforms play a very important role in preventing
and mitigating the effects of pollution. Recent advances in the field of graph
signal processing have made it possible to describe and analyze air pollution
monitoring networks using graphs. One of the main applications is the
reconstruction of the measured signal in a graph using a subset of sensors.
Reconstructing the signal using information from sensor neighbors can help
improve the quality of network data, examples are filling in missing data with
correlated neighboring nodes, or correcting a drifting sensor with neighboring
sensors that are more accurate. This paper compares the use of various types of
graph signal reconstruction methods applied to real data sets of Spanish air
pollution reference stations. The methods considered are Laplacian
interpolation, graph signal processing low-pass based graph signal
reconstruction, and kernel-based graph signal reconstruction, and are compared
on actual air pollution data sets measuring O3, NO2, and PM10. The ability of
the methods to reconstruct the signal of a pollutant is shown, as well as the
computational cost of this reconstruction. The results indicate the superiority
of methods based on kernel-based graph signal reconstruction, as well as the
difficulties of the methods to scale in an air pollution monitoring network
with a large number of low-cost sensors. However, we show that scalability can
be overcome with simple methods, such as partitioning the network using a
clustering algorithm.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Ferrer_Cid_P/0/1/0/all/0/1"&gt;Pau Ferrer-Cid&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Barcelo_Ordinas_J/0/1/0/all/0/1"&gt;Jose M. Barcelo-Ordinas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Garcia_Vidal_J/0/1/0/all/0/1"&gt;Jorge Garcia-Vidal&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Efficient Federated Distillation Learning System for Multi-task Time Series Classification. (arXiv:2201.00011v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00011</id>
        <link href="http://arxiv.org/abs/2201.00011"/>
        <updated>2022-01-05T00:39:36.311Z</updated>
        <summary type="html"><![CDATA[This paper proposes an efficient federated distillation learning system
(EFDLS) for multi-task time series classification (TSC). EFDLS consists of a
central server and multiple mobile users, where different users may run
different TSC tasks. EFDLS has two novel components, namely a feature-based
student-teacher (FBST) framework and a distance-based weights matching (DBWM)
scheme. Within each user, the FBST framework transfers knowledge from its
teacher's hidden layers to its student's hidden layers via knowledge
distillation, with the teacher and student having identical network structure.
For each connected user, its student model's hidden layers' weights are
uploaded to the EFDLS server periodically. The DBWM scheme is deployed on the
server, with the least square distance used to measure the similarity between
the weights of two given models. This scheme finds a partner for each connected
user such that the user's and its partner's weights are the closest among all
the weights uploaded. The server exchanges and sends back the user's and its
partner's weights to these two users which then load the received weights to
their teachers' hidden layers. Experimental results show that the proposed
EFDLS achieves excellent performance on a set of selected UCR2018 datasets
regarding top-1 accuracy.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xing_H/0/1/0/all/0/1"&gt;Huanlai Xing&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1"&gt;Zhiwen Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qu_R/0/1/0/all/0/1"&gt;Rong Qu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1"&gt;Zonghai Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1"&gt;Bowen Zhao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-Supervised Graph Attention Networks for Event Representation Learning. (arXiv:2201.00363v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00363</id>
        <link href="http://arxiv.org/abs/2201.00363"/>
        <updated>2022-01-05T00:39:36.303Z</updated>
        <summary type="html"><![CDATA[Event analysis from news and social networks is very useful for a wide range
of social studies and real-world applications. Recently, event graphs have been
explored to model event datasets and their complex relationships, where events
are vertices connected to other vertices representing locations, people's
names, dates, and various other event metadata. Graph representation learning
methods are promising for extracting latent features from event graphs to
enable the use of different classification algorithms. However, existing
methods fail to meet essential requirements for event graphs, such as (i)
dealing with semi-supervised graph embedding to take advantage of some labeled
events, (ii) automatically determining the importance of the relationships
between event vertices and their metadata vertices, as well as (iii) dealing
with the graph heterogeneity. This paper presents GNEE (GAT Neural Event
Embeddings), a method that combines Graph Attention Networks and Graph
Regularization. First, an event graph regularization is proposed to ensure that
all graph vertices receive event features, thereby mitigating the graph
heterogeneity drawback. Second, semi-supervised graph embedding with
self-attention mechanism considers existing labeled events, as well as learns
the importance of relationships in the event graph during the representation
learning process. A statistical analysis of experimental results with five
real-world event graphs and six graph embedding methods shows that our GNEE
outperforms state-of-the-art semi-supervised graph embedding methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Mattos_J/0/1/0/all/0/1"&gt;Joao Pedro Rodrigues Mattos&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Marcacini_R/0/1/0/all/0/1"&gt;Ricardo M. Marcacini&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Augmentative eXplanation and the Distributional Gap of Confidence Optimization Score. (arXiv:2201.00009v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00009</id>
        <link href="http://arxiv.org/abs/2201.00009"/>
        <updated>2022-01-05T00:39:36.292Z</updated>
        <summary type="html"><![CDATA[This paper introduces the Confidence Optimization (CO) score to directly
measure the contribution of heatmaps/saliency maps to the classification
performance of a model. Common heatmap generation methods used in the
eXplainable Artificial Intelligence (XAI) community are tested through a
process we call the Augmentative eXplanation (AX). We find a surprising
\textit{gap} in CO scores distribution on these heatmap methods. The gap
potentially serves as a novel indicator for the correctness of deep neural
network (DNN) prediction. We further introduces Generative AX (GAX) method to
generate saliency maps capable of attaining high CO scores. Using GAX, we also
qualitatively demonstrate the unintuitiveness of DNN architectures.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tjoa_E/0/1/0/all/0/1"&gt;Erico Tjoa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Khok_H/0/1/0/all/0/1"&gt;Hong Jing Khok&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chouhan_T/0/1/0/all/0/1"&gt;Tushar Chouhan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cuntai_G/0/1/0/all/0/1"&gt;Guan Cuntai&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Validation and Transparency in AI systems for pharmacovigilance: a case study applied to the medical literature monitoring of adverse events. (arXiv:2201.00692v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2201.00692</id>
        <link href="http://arxiv.org/abs/2201.00692"/>
        <updated>2022-01-05T00:39:36.284Z</updated>
        <summary type="html"><![CDATA[Recent advances in artificial intelligence applied to biomedical text are
opening exciting opportunities for improving pharmacovigilance activities
currently burdened by the ever growing volumes of real world data. To fully
realize these opportunities, existing regulatory guidance and industry best
practices should be taken into consideration in order to increase the overall
trustworthiness of the system and enable broader adoption. In this paper we
present a case study on how to operationalize existing guidance for validated
AI systems in pharmacovigilance focusing on the specific task of medical
literature monitoring (MLM) of adverse events from the scientific literature.
We describe an AI system designed with the goal of reducing effort in MLM
activities built in close collaboration with subject matter experts and
considering guidance for validated systems in pharmacovigilance and AI
transparency. In particular we make use of public disclosures as a useful risk
control measure to mitigate system misuse and earn user trust. In addition we
present experimental results showing the system can significantly remove
screening effort while maintaining high levels of recall (filtering 55% of
irrelevant articles on average, for a target recall of 0.99 on suspected
adverse articles) and provide a robust method for tuning the desired recall to
suit a particular risk profile.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ohana_B/0/1/0/all/0/1"&gt;Bruno Ohana&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sullivan_J/0/1/0/all/0/1"&gt;Jack Sullivan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Baker_N/0/1/0/all/0/1"&gt;Nicole Baker&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Literature Review on Length of Stay Prediction for Stroke Patients using Machine Learning and Statistical Approaches. (arXiv:2201.00005v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00005</id>
        <link href="http://arxiv.org/abs/2201.00005"/>
        <updated>2022-01-05T00:39:36.218Z</updated>
        <summary type="html"><![CDATA[Hospital length of stay (LOS) is one of the most essential healthcare metrics
that reflects the hospital quality of service and helps improve hospital
scheduling and management. LOS prediction helps in cost management because
patients who remain in hospitals usually do so in hospital units where
resources are severely limited. In this study, we reviewed papers on LOS
prediction using machine learning and statistical approaches. Our literature
review considers research studies that focus on LOS prediction for stroke
patients. Some of the surveyed studies revealed that authors reached
contradicting conclusions. For example, the age of the patient was considered
an important predictor of LOS for stroke patients in some studies, while other
studies concluded that age was not a significant factor. Therefore, additional
research is required in this domain to further understand the predictors of LOS
for stroke patients.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Alkhatib_O/0/1/0/all/0/1"&gt;Ola Alkhatib&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Alahmar_A/0/1/0/all/0/1"&gt;Ayman Alahmar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Performance Comparison of Deep Learning Architectures for Artifact Removal in Gastrointestinal Endoscopic Imaging. (arXiv:2201.00084v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2201.00084</id>
        <link href="http://arxiv.org/abs/2201.00084"/>
        <updated>2022-01-05T00:39:36.212Z</updated>
        <summary type="html"><![CDATA[Endoscopic images typically contain several artifacts. The artifacts
significantly impact image analysis result in computer-aided diagnosis.
Convolutional neural networks (CNNs), a type of deep learning, can removes such
artifacts. Various architectures have been proposed for the CNNs, and the
accuracy of artifact removal varies depending on the choice of architecture.
Therefore, it is necessary to determine the artifact removal accuracy,
depending on the selected architecture. In this study, we focus on endoscopic
surgical instruments as artifacts, and determine and discuss the artifact
removal accuracy using seven different CNN architectures.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Watanabe_T/0/1/0/all/0/1"&gt;Taira Watanabe&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Tanioka_K/0/1/0/all/0/1"&gt;Kensuke Tanioka&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Hiwa_S/0/1/0/all/0/1"&gt;Satoru Hiwa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Hiroyasu_T/0/1/0/all/0/1"&gt;Tomoyuki Hiroyasu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How do lexical semantics affect translation? An empirical study. (arXiv:2201.00075v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2201.00075</id>
        <link href="http://arxiv.org/abs/2201.00075"/>
        <updated>2022-01-05T00:39:36.201Z</updated>
        <summary type="html"><![CDATA[Neural machine translation (NMT) systems aim to map text from one language
into another. While there are a wide variety of applications of NMT, one of the
most important is translation of natural language. A distinguishing factor of
natural language is that words are typically ordered according to the rules of
the grammar of a given language. Although many advances have been made in
developing NMT systems for translating natural language, little research has
been done on understanding how the word ordering of and lexical similarity
between the source and target language affect translation performance. Here, we
investigate these relationships on a variety of low-resource language pairs
from the OpenSubtitles2016 database, where the source language is English, and
find that the more similar the target language is to English, the greater the
translation performance. In addition, we study the impact of providing NMT
models with part of speech of words (POS) in the English sequence and find
that, for Transformer-based models, the more dissimilar the target language is
from English, the greater the benefit provided by POS.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Subramanian_V/0/1/0/all/0/1"&gt;Vivek Subramanian&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sundararaman_D/0/1/0/all/0/1"&gt;Dhanasekar Sundararaman&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Covariate-assisted Sparse Tensor Completion. (arXiv:2103.06428v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.06428</id>
        <link href="http://arxiv.org/abs/2103.06428"/>
        <updated>2022-01-05T00:39:36.193Z</updated>
        <summary type="html"><![CDATA[We aim to provably complete a sparse and highly-missing tensor in the
presence of covariate information along tensor modes. Our motivation comes from
online advertising where users click-through-rates (CTR) on ads over various
devices form a CTR tensor that has about 96% missing entries and has many zeros
on non-missing entries, which makes the standalone tensor completion method
unsatisfactory. Beside the CTR tensor, additional ad features or user
characteristics are often available. In this paper, we propose
Covariate-assisted Sparse Tensor Completion (COSTCO) to incorporate covariate
information for the recovery of the sparse tensor. The key idea is to jointly
extract latent components from both the tensor and the covariate matrix to
learn a synthetic representation. Theoretically, we derive the error bound for
the recovered tensor components and explicitly quantify the improvements on
both the reveal probability condition and the tensor recovery accuracy due to
covariates. Finally, we apply COSTCO to an advertisement dataset consisting of
a CTR tensor and ad covariate matrix, leading to 23% accuracy improvement over
the baseline. An important by-product is that ad latent components from COSTCO
reveal interesting ad clusters, which are useful for better ad targeting.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Ibriga_H/0/1/0/all/0/1"&gt;Hilda S Ibriga&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1"&gt;Will Wei Sun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A General Descent Aggregation Framework for Gradient-based Bi-level Optimization. (arXiv:2102.07976v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.07976</id>
        <link href="http://arxiv.org/abs/2102.07976"/>
        <updated>2022-01-05T00:39:36.125Z</updated>
        <summary type="html"><![CDATA[In recent years, a variety of gradient-based methods have been developed to
solve Bi-Level Optimization (BLO) problems in machine learning and computer
vision areas. However, the theoretical correctness and practical effectiveness
of these existing approaches always rely on some restrictive conditions (e.g.,
Lower-Level Singleton, LLS), which could hardly be satisfied in real-world
applications. Moreover, previous literature only proves theoretical results
based on their specific iteration strategies, thus lack a general recipe to
uniformly analyze the convergence behaviors of different gradient-based BLOs.
In this work, we formulate BLOs from an optimistic bi-level viewpoint and
establish a new gradient-based algorithmic framework, named Bi-level Descent
Aggregation (BDA), to partially address the above issues. Specifically, BDA
provides a modularized structure to hierarchically aggregate both the upper-
and lower-level subproblems to generate our bi-level iterative dynamics.
Theoretically, we establish a general convergence analysis template and derive
a new proof recipe to investigate the essential theoretical properties of
gradient-based BLO methods. Furthermore, this work systematically explores the
convergence behavior of BDA in different optimization scenarios, i.e.,
considering various solution qualities (i.e., global/local/stationary solution)
returned from solving approximation subproblems. Extensive experiments justify
our theoretical results and demonstrate the superiority of the proposed
algorithm for hyper-parameter optimization and meta-learning tasks. Source code
is available at https://github.com/vis-opt-group/BDA.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1"&gt;Risheng Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mu_P/0/1/0/all/0/1"&gt;Pan Mu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1"&gt;Xiaoming Yuan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1"&gt;Shangzhi Zeng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1"&gt;Jin Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Succinct Differentiation of Disparate Boosting Ensemble Learning Methods for Prognostication of Polycystic Ovary Syndrome Diagnosis. (arXiv:2201.00418v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00418</id>
        <link href="http://arxiv.org/abs/2201.00418"/>
        <updated>2022-01-05T00:39:36.105Z</updated>
        <summary type="html"><![CDATA[Prognostication of medical problems using the clinical data by leveraging the
Machine Learning techniques with stellar precision is one of the most important
real world challenges at the present time. Considering the medical problem of
Polycystic Ovary Syndrome also known as PCOS is an emerging problem in women
aged from 15 to 49. Diagnosing this disorder by using various Boosting Ensemble
Methods is something we have presented in this paper. A detailed and
compendious differentiation between Adaptive Boost, Gradient Boosting Machine,
XGBoost and CatBoost with their respective performance metrics highlighting the
hidden anomalies in the data and its effects on the result is something we have
presented in this paper. Metrics like Confusion Matrix, Precision, Recall, F1
Score, FPR, RoC Curve and AUC have been used in this paper.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1"&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shetty_S/0/1/0/all/0/1"&gt;Sannidhi Shetty&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1"&gt;Raunak Joshi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Laban_R/0/1/0/all/0/1"&gt;Ronald Melwin Laban&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BARACK: Partially Supervised Group Robustness With Guarantees. (arXiv:2201.00072v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00072</id>
        <link href="http://arxiv.org/abs/2201.00072"/>
        <updated>2022-01-05T00:39:35.414Z</updated>
        <summary type="html"><![CDATA[While neural networks have shown remarkable success on classification tasks
in terms of average-case performance, they often fail to perform well on
certain groups of the data. Such group information may be expensive to obtain;
thus, recent works in robustness and fairness have proposed ways to improve
worst-group performance even when group labels are unavailable for the training
data. However, these methods generally underperform methods that utilize group
information at training time. In this work, we assume access to a small number
of group labels alongside a larger dataset without group labels. We propose
BARACK, a simple two-step framework to utilize this partial group information
to improve worst-group performance: train a model to predict the missing group
labels for the training data, and then use these predicted group labels in a
robust optimization objective. Theoretically, we provide generalization bounds
for our approach in terms of the worst-group performance, showing how the
generalization error scales with respect to both the total number of training
points and the number of training points with group labels. Empirically, our
method outperforms the baselines that do not use group information, even when
only 1-33% of points have group labels. We provide ablation studies to support
the robustness and extensibility of our framework.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sohoni_N/0/1/0/all/0/1"&gt;Nimit Sohoni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1"&gt;Maziar Sanjabi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1"&gt;Nicolas Ballas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1"&gt;Aditya Grover&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nie_S/0/1/0/all/0/1"&gt;Shaoliang Nie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Firooz_H/0/1/0/all/0/1"&gt;Hamed Firooz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1"&gt;Christopher R&amp;#xe9;&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Least-Squares Regression. (arXiv:2201.00228v1 [cs.DS])]]></title>
        <id>http://arxiv.org/abs/2201.00228</id>
        <link href="http://arxiv.org/abs/2201.00228"/>
        <updated>2022-01-05T00:39:35.381Z</updated>
        <summary type="html"><![CDATA[A common challenge in large-scale supervised learning, is how to exploit new
incremental data to a pre-trained model, without re-training the model from
scratch. Motivated by this problem, we revisit the canonical problem of dynamic
least-squares regression (LSR), where the goal is to learn a linear model over
incremental training data. In this setup, data and labels $(\mathbf{A}^{(t)},
\mathbf{b}^{(t)}) \in \mathbb{R}^{t \times d}\times \mathbb{R}^t$ evolve in an
online fashion ($t\gg d$), and the goal is to efficiently maintain an
(approximate) solution to $\min_{\mathbf{x}^{(t)}} \| \mathbf{A}^{(t)}
\mathbf{x}^{(t)} - \mathbf{b}^{(t)} \|_2$ for all $t\in [T]$. Our main result
is a dynamic data structure which maintains an arbitrarily small constant
approximate solution to dynamic LSR with amortized update time $O(d^{1+o(1)})$,
almost matching the running time of the static (sketching-based) solution. By
contrast, for exact (or even $1/\mathrm{poly}(n)$-accuracy) solutions, we show
a separation between the static and dynamic settings, namely, that dynamic LSR
requires $\Omega(d^{2-o(1)})$ amortized update time under the OMv Conjecture
(Henzinger et al., STOC'15). Our data structure is conceptually simple, easy to
implement, and fast both in theory and practice, as corroborated by experiments
over both synthetic and real-world datasets.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1"&gt;Shunhua Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1"&gt;Binghui Peng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Weinstein_O/0/1/0/all/0/1"&gt;Omri Weinstein&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating Deep Music Generation Methods Using Data Augmentation. (arXiv:2201.00052v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2201.00052</id>
        <link href="http://arxiv.org/abs/2201.00052"/>
        <updated>2022-01-05T00:39:35.375Z</updated>
        <summary type="html"><![CDATA[Despite advances in deep algorithmic music generation, evaluation of
generated samples often relies on human evaluation, which is subjective and
costly. We focus on designing a homogeneous, objective framework for evaluating
samples of algorithmically generated music. Any engineered measures to evaluate
generated music typically attempt to define the samples' musicality, but do not
capture qualities of music such as theme or mood. We do not seek to assess the
musical merit of generated music, but instead explore whether generated samples
contain meaningful information pertaining to emotion or mood/theme. We achieve
this by measuring the change in predictive performance of a music mood/theme
classifier after augmenting its training data with generated samples. We
analyse music samples generated by three models -- SampleRNN, Jukebox, and DDSP
-- and employ a homogeneous framework across all methods to allow for objective
comparison. This is the first attempt at augmenting a music genre
classification dataset with conditionally generated music. We investigate the
classification performance improvement using deep music generation and the
ability of the generators to make emotional music by using an additional,
emotion annotation of the dataset. Finally, we use a classifier trained on real
data to evaluate the label validity of class-conditionally generated samples.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Godwin_T/0/1/0/all/0/1"&gt;Toby Godwin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rizos_G/0/1/0/all/0/1"&gt;Georgios Rizos&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Baird_A/0/1/0/all/0/1"&gt;Alice Baird&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Futaisi_N/0/1/0/all/0/1"&gt;Najla D. Al Futaisi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Brisse_V/0/1/0/all/0/1"&gt;Vincent Brisse&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1"&gt;Bjoern W. Schuller&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-view Subspace Adaptive Learning via Autoencoder and Attention. (arXiv:2201.00171v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00171</id>
        <link href="http://arxiv.org/abs/2201.00171"/>
        <updated>2022-01-05T00:39:35.368Z</updated>
        <summary type="html"><![CDATA[Multi-view learning can cover all features of data samples more
comprehensively, so multi-view learning has attracted widespread attention.
Traditional subspace clustering methods, such as sparse subspace clustering
(SSC) and low-ranking subspace clustering (LRSC), cluster the affinity matrix
for a single view, thus ignoring the problem of fusion between views. In our
article, we propose a new Multiview Subspace Adaptive Learning based on
Attention and Autoencoder (MSALAA). This method combines a deep autoencoder and
a method for aligning the self-representations of various views in Multi-view
Low-Rank Sparse Subspace Clustering (MLRSSC), which can not only increase the
capability to non-linearity fitting, but also can meets the principles of
consistency and complementarity of multi-view learning. We empirically observe
significant improvement over existing baseline methods on six real-life
datasets.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"&gt;Jian-wei Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1"&gt;Hao-jie Xie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1"&gt;Run-kun Lu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1"&gt;Xiong-lin Luo&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semantic Search for Large Scale Clinical Ontologies. (arXiv:2201.00118v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2201.00118</id>
        <link href="http://arxiv.org/abs/2201.00118"/>
        <updated>2022-01-05T00:39:35.342Z</updated>
        <summary type="html"><![CDATA[Finding concepts in large clinical ontologies can be challenging when queries
use different vocabularies. A search algorithm that overcomes this problem is
useful in applications such as concept normalisation and ontology matching,
where concepts can be referred to in different ways, using different synonyms.
In this paper, we present a deep learning based approach to build a semantic
search system for large clinical ontologies. We propose a Triplet-BERT model
and a method that generates training data directly from the ontologies. The
model is evaluated using five real benchmark data sets and the results show
that our approach achieves high results on both free text to concept and
concept to concept searching tasks, and outperforms all baseline methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ngo_D/0/1/0/all/0/1"&gt;Duy-Hoa Ngo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kemp_M/0/1/0/all/0/1"&gt;Madonna Kemp&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Truran_D/0/1/0/all/0/1"&gt;Donna Truran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Koopman_B/0/1/0/all/0/1"&gt;Bevan Koopman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Metke_Jimenez_A/0/1/0/all/0/1"&gt;Alejandro Metke-Jimenez&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Robust Graph Neural Networks for Noisy Graphs with Sparse Labels. (arXiv:2201.00232v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00232</id>
        <link href="http://arxiv.org/abs/2201.00232"/>
        <updated>2022-01-05T00:39:35.316Z</updated>
        <summary type="html"><![CDATA[Graph Neural Networks (GNNs) have shown their great ability in modeling graph
structured data. However, real-world graphs usually contain structure noises
and have limited labeled nodes. The performance of GNNs would drop
significantly when trained on such graphs, which hinders the adoption of GNNs
on many applications. Thus, it is important to develop noise-resistant GNNs
with limited labeled nodes. However, the work on this is rather limited.
Therefore, we study a novel problem of developing robust GNNs on noisy graphs
with limited labeled nodes. Our analysis shows that both the noisy edges and
limited labeled nodes could harm the message-passing mechanism of GNNs. To
mitigate these issues, we propose a novel framework which adopts the noisy
edges as supervision to learn a denoised and dense graph, which can down-weight
or eliminate noisy edges and facilitate message passing of GNNs to alleviate
the issue of limited labeled nodes. The generated edges are further used to
regularize the predictions of unlabeled nodes with label smoothness to better
train GNNs. Experimental results on real-world datasets demonstrate the
robustness of the proposed framework on noisy graphs with limited labeled
nodes.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1"&gt;Enyan Dai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+jIN_W/0/1/0/all/0/1"&gt;Wei jIN&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1"&gt;Hui Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"&gt;Suhang Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hybrid intelligence for dynamic job-shop scheduling with deep reinforcement learning and attention mechanism. (arXiv:2201.00548v1 [cs.AI])]]></title>
        <id>http://arxiv.org/abs/2201.00548</id>
        <link href="http://arxiv.org/abs/2201.00548"/>
        <updated>2022-01-05T00:39:35.295Z</updated>
        <summary type="html"><![CDATA[The dynamic job-shop scheduling problem (DJSP) is a class of scheduling tasks
that specifically consider the inherent uncertainties such as changing order
requirements and possible machine breakdown in realistic smart manufacturing
settings. Since traditional methods cannot dynamically generate effective
scheduling strategies in face of the disturbance of environments, we formulate
the DJSP as a Markov decision process (MDP) to be tackled by reinforcement
learning (RL). For this purpose, we propose a flexible hybrid framework that
takes disjunctive graphs as states and a set of general dispatching rules as
the action space with minimum prior domain knowledge. The attention mechanism
is used as the graph representation learning (GRL) module for the feature
extraction of states, and the double dueling deep Q-network with prioritized
replay and noisy networks (D3QPN) is employed to map each state to the most
appropriate dispatching rule. Furthermore, we present Gymjsp, a public
benchmark based on the well-known OR-Library, to provide a standardized
off-the-shelf facility for RL and DJSP research communities. Comprehensive
experiments on various DJSP instances confirm that our proposed framework is
superior to baseline algorithms with smaller makespan across all instances and
provide empirical justification for the validity of the various components in
the hybrid framework.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1"&gt;Yunhui Zeng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liao_Z/0/1/0/all/0/1"&gt;Zijun Liao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1"&gt;Yuanzhi Dai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1"&gt;Rong Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"&gt;Xiu Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1"&gt;Bo Yuan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knowledge intensive state design for traffic signal control. (arXiv:2201.00006v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00006</id>
        <link href="http://arxiv.org/abs/2201.00006"/>
        <updated>2022-01-05T00:39:35.229Z</updated>
        <summary type="html"><![CDATA[There is a general trend of applying reinforcement learning (RL) techniques
for traffic signal control (TSC). Recently, most studies pay attention to the
neural network design and rarely concentrate on the state representation. Does
the design of state representation has a good impact on TSC? In this paper, we
(1) propose an effective state representation as queue length of vehicles with
intensive knowledge; (2) present a TSC method called MaxQueue based on our
state representation approach; (3) develop a general RL-based TSC template
called QL-XLight with queue length as state and reward and generate QL-FRAP,
QL-CoLight, and QL-DQN by our QL-XLight template based on traditional and
latest RL models.Through comprehensive experiments on multiple real-world
datasets, we demonstrate that: (1) our MaxQueue method outperforms the latest
RL based methods; (2) QL-FRAP and QL-CoLight achieves a new state-of-the-art
(SOTA). In general, state representation with intensive knowledge is also
essential for TSC methods. Our code is released on Github.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1"&gt;Liang Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1"&gt;Qiang Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1"&gt;Jianming Deng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ECOD: Unsupervised Outlier Detection Using Empirical Cumulative Distribution Functions. (arXiv:2201.00382v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00382</id>
        <link href="http://arxiv.org/abs/2201.00382"/>
        <updated>2022-01-05T00:39:34.994Z</updated>
        <summary type="html"><![CDATA[Outlier detection refers to the identification of data points that deviate
from a general data distribution. Existing unsupervised approaches often suffer
from high computational cost, complex hyperparameter tuning, and limited
interpretability, especially when working with large, high-dimensional
datasets. To address these issues, we present a simple yet effective algorithm
called ECOD (Empirical-Cumulative-distribution-based Outlier Detection), which
is inspired by the fact that outliers are often the "rare events" that appear
in the tails of a distribution. In a nutshell, ECOD first estimates the
underlying distribution of the input data in a nonparametric fashion by
computing the empirical cumulative distribution per dimension of the data. ECOD
then uses these empirical distributions to estimate tail probabilities per
dimension for each data point. Finally, ECOD computes an outlier score of each
data point by aggregating estimated tail probabilities across dimensions. Our
contributions are as follows: (1) we propose a novel outlier detection method
called ECOD, which is both parameter-free and easy to interpret; (2) we perform
extensive experiments on 30 benchmark datasets, where we find that ECOD
outperforms 11 state-of-the-art baselines in terms of accuracy, efficiency, and
scalability; and (3) we release an easy-to-use and scalable (with distributed
support) Python implementation for accessibility and reproducibility.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"&gt;Zheng Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1"&gt;Yue Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1"&gt;Xiyang Hu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Botta_N/0/1/0/all/0/1"&gt;Nicola Botta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ionescu_C/0/1/0/all/0/1"&gt;Cezar Ionescu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1"&gt;George H. Chen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thinking inside the box: A tutorial on grey-box Bayesian optimization. (arXiv:2201.00272v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00272</id>
        <link href="http://arxiv.org/abs/2201.00272"/>
        <updated>2022-01-05T00:39:34.987Z</updated>
        <summary type="html"><![CDATA[Bayesian optimization (BO) is a framework for global optimization of
expensive-to-evaluate objective functions. Classical BO methods assume that the
objective function is a black box. However, internal information about
objective function computation is often available. For example, when optimizing
a manufacturing line's throughput with simulation, we observe the number of
parts waiting at each workstation, in addition to the overall throughput.
Recent BO methods leverage such internal information to dramatically improve
performance. We call these "grey-box" BO methods because they treat objective
computation as partially observable and even modifiable, blending the black-box
approach with so-called "white-box" first-principles knowledge of objective
function computation. This tutorial describes these methods, focusing on BO of
composite objective functions, where one can observe and selectively evaluate
individual constituents that feed into the overall objective; and
multi-fidelity BO, where one can evaluate cheaper approximations of the
objective function by varying parameters of the evaluation oracle.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Astudillo_R/0/1/0/all/0/1"&gt;Raul Astudillo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Frazier_P/0/1/0/all/0/1"&gt;Peter I. Frazier&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transfer-learning-based Surrogate Model for Thermal Conductivity of Nanofluids. (arXiv:2201.00435v1 [physics.flu-dyn])]]></title>
        <id>http://arxiv.org/abs/2201.00435</id>
        <link href="http://arxiv.org/abs/2201.00435"/>
        <updated>2022-01-05T00:39:34.834Z</updated>
        <summary type="html"><![CDATA[Heat transfer characteristics of nanofluids have been extensively studied
since the 1990s. Research investigations show that the suspended nanoparticles
significantly alter the suspension's thermal properties. The thermal
conductivity of nanofluids is one of the properties that is generally found to
be greater than that of the base fluid. This increase in thermal conductivity
is found to depend on several parameters. Several theories have been proposed
to model the thermal conductivities of nanofluids, but there is no reliable
universal theory yet to model the anomalous thermal conductivity of nanofluids.
In recent years, supervised data-driven methods have been successfully employed
to create surrogate models across various scientific disciplines, especially
for modeling difficult-to-understand phenomena. These supervised learning
methods allow the models to capture highly non-linear phenomena. In this work,
we have taken advantage of existing correlations and used them concurrently
with available experimental results to develop more robust surrogate models for
predicting the thermal conductivity of nanofluids. Artificial neural networks
are trained using the transfer learning approach to predict the thermal
conductivity enhancement of nanofluids with spherical particles for 32
different particle-fluid combinations (8 particles materials and 4 fluids). The
large amount of lower accuracy data generated from correlations is used to
coarse-tune the model parameters, and the limited amount of more trustworthy
experimental data is used to fine-tune the model parameters. The transfer
learning-based models' results are compared with those from baseline models
which are trained only on experimental data using a goodness of fit metric. It
is found that the transfer learning models perform better with goodness of fit
values of 0.93 as opposed to 0.83 from the baseline models.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Pai_S/0/1/0/all/0/1"&gt;Saeel S. Pai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Banthiya_A/0/1/0/all/0/1"&gt;Abhijeet Banthiya&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TransLog: A Unified Transformer-based Framework for Log Anomaly Detection. (arXiv:2201.00016v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00016</id>
        <link href="http://arxiv.org/abs/2201.00016"/>
        <updated>2022-01-05T00:39:34.827Z</updated>
        <summary type="html"><![CDATA[Log anomaly detection is a key component in the field of artificial
intelligence for IT operations (AIOps). Considering log data of variant
domains, retraining the whole network for unknown domains is inefficient in
real industrial scenarios especially for low-resource domains. However,
previous deep models merely focused on extracting the semantics of log sequence
in the same domain, leading to poor generalization on multi-domain logs.
Therefore, we propose a unified Transformer-based framework for log anomaly
detection (\ourmethod{}), which is comprised of the pretraining and
adapter-based tuning stage. Our model is first pretrained on the source domain
to obtain shared semantic knowledge of log data. Then, we transfer the
pretrained model to the target domain via the adapter-based tuning. The
proposed method is evaluated on three public datasets including one source
domain and two target domains. The experimental results demonstrate that our
simple yet efficient approach, with fewer trainable parameters and lower
training costs in the target domain, achieves state-of-the-art performance on
three benchmarks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1"&gt;Hongcheng Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1"&gt;Xingyu Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1"&gt;Jian Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1"&gt;Yi Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1"&gt;Jiaqi Bai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1"&gt;Bo Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1"&gt;Tieqiao Zheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"&gt;Zhoujun Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Overview of the EEG Pilot Subtask at MediaEval 2021: Predicting Media Memorability. (arXiv:2201.00620v1 [q-bio.NC])]]></title>
        <id>http://arxiv.org/abs/2201.00620</id>
        <link href="http://arxiv.org/abs/2201.00620"/>
        <updated>2022-01-05T00:39:34.730Z</updated>
        <summary type="html"><![CDATA[The aim of the Memorability-EEG pilot subtask at MediaEval'2021 is to promote
interest in the use of neural signals -- either alone or in combination with
other data sources -- in the context of predicting video memorability by
highlighting the utility of EEG data. The dataset created consists of
pre-extracted features from EEG recordings of subjects while watching a subset
of videos from Predicting Media Memorability subtask 1. This demonstration
pilot gives interested researchers a sense of how neural signals can be used
without any prior domain knowledge, and enables them to do so in a future
memorability task. The dataset can be used to support the exploration of novel
machine learning and processing strategies for predicting video memorability,
while potentially increasing interdisciplinary interest in the subject of
memorability, and opening the door to new combined EEG-computer vision
approaches.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/q-bio/1/au:+Sweeney_L/0/1/0/all/0/1"&gt;Lorin Sweeney&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Matran_Fernandez_A/0/1/0/all/0/1"&gt;Ana Matran-Fernandez&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Halder_S/0/1/0/all/0/1"&gt;Sebastian Halder&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Herrera_A/0/1/0/all/0/1"&gt;Alba G. Seco de Herrera&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Smeaton_A/0/1/0/all/0/1"&gt;Alan Smeaton&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-bio/1/au:+Healy_G/0/1/0/all/0/1"&gt;Graham Healy&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An analysis of over-sampling labeled data in semi-supervised learning with FixMatch. (arXiv:2201.00604v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00604</id>
        <link href="http://arxiv.org/abs/2201.00604"/>
        <updated>2022-01-05T00:39:34.705Z</updated>
        <summary type="html"><![CDATA[Most semi-supervised learning methods over-sample labeled data when
constructing training mini-batches. This paper studies whether this common
practice improves learning and how. We compare it to an alternative setting
where each mini-batch is uniformly sampled from all the training data, labeled
or not, which greatly reduces direct supervision from true labels in typical
low-label regimes. However, this simpler setting can also be seen as more
general and even necessary in multi-task problems where over-sampling labeled
data would become intractable. Our experiments on semi-supervised CIFAR-10
image classification using FixMatch show a performance drop when using the
uniform sampling approach which diminishes when the amount of labeled data or
the training time increases. Further, we analyse the training dynamics to
understand how over-sampling of labeled data compares to uniform sampling. Our
main finding is that over-sampling is especially beneficial early in training
but gets less important in the later stages when more pseudo-labels become
correct. Nevertheless, we also find that keeping some true labels remains
important to avoid the accumulation of confirmation errors from incorrect
pseudo-labels.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Rabadan_M/0/1/0/all/0/1"&gt;Miquel Mart&amp;#xed; i Rabad&amp;#xe1;n&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bujwid_S/0/1/0/all/0/1"&gt;Sebastian Bujwid&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pieropan_A/0/1/0/all/0/1"&gt;Alessandro Pieropan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Azizpour_H/0/1/0/all/0/1"&gt;Hossein Azizpour&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Maki_A/0/1/0/all/0/1"&gt;Atsuto Maki&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The GatedTabTransformer. An enhanced deep learning architecture for tabular modeling. (arXiv:2201.00199v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00199</id>
        <link href="http://arxiv.org/abs/2201.00199"/>
        <updated>2022-01-05T00:39:34.686Z</updated>
        <summary type="html"><![CDATA[There is an increasing interest in the application of deep learning
architectures to tabular data. One of the state-of-the-art solutions is
TabTransformer which incorporates an attention mechanism to better track
relationships between categorical features and then makes use of a standard MLP
to output its final logits. In this paper we propose multiple modifications to
the original TabTransformer performing better on binary classification tasks
for three separate datasets with more than 1% AUROC gains. Inspired by gated
MLP, linear projections are implemented in the MLP block and multiple
activation functions are tested. We also evaluate the importance of specific
hyper parameters during training.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cholakov_R/0/1/0/all/0/1"&gt;Radostin Cholakov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kolev_T/0/1/0/all/0/1"&gt;Todor Kolev&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Representations for Covariate Shift. (arXiv:2201.00057v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00057</id>
        <link href="http://arxiv.org/abs/2201.00057"/>
        <updated>2022-01-05T00:39:34.517Z</updated>
        <summary type="html"><![CDATA[Machine learning systems often experience a distribution shift between
training and testing. In this paper, we introduce a simple variational
objective whose optima are exactly the set of all representations on which risk
minimizers are guaranteed to be robust to any distribution shift that preserves
the Bayes predictor, e.g., covariate shifts. Our objective has two components.
First, a representation must remain discriminative for the task, i.e., some
predictor must be able to simultaneously minimize the source and target risk.
Second, the representation's marginal support needs to be the same across
source and target. We make this practical by designing self-supervised learning
methods that only use unlabelled data and augmentations to train robust
representations. Our objectives achieve state-of-the-art results on DomainBed,
and give insights into the robustness of recent methods, such as CLIP.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ruan_Y/0/1/0/all/0/1"&gt;Yangjun Ruan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dubois_Y/0/1/0/all/0/1"&gt;Yann Dubois&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1"&gt;Chris J. Maddison&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Revisiting PGD Attacks for Stability Analysis of Large-Scale Nonlinear Systems and Perception-Based Control. (arXiv:2201.00801v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2201.00801</id>
        <link href="http://arxiv.org/abs/2201.00801"/>
        <updated>2022-01-05T00:39:34.508Z</updated>
        <summary type="html"><![CDATA[Many existing region-of-attraction (ROA) analysis tools find difficulty in
addressing feedback systems with large-scale neural network (NN) policies
and/or high-dimensional sensing modalities such as cameras. In this paper, we
tailor the projected gradient descent (PGD) attack method developed in the
adversarial learning community as a general-purpose ROA analysis tool for
large-scale nonlinear systems and end-to-end perception-based control. We show
that the ROA analysis can be approximated as a constrained maximization problem
whose goal is to find the worst-case initial condition which shifts the
terminal state the most. Then we present two PGD-based iterative methods which
can be used to solve the resultant constrained maximization problem. Our
analysis is not based on Lyapunov theory, and hence requires minimum
information of the problem structures. In the model-based setting, we show that
the PGD updates can be efficiently performed using back-propagation. In the
model-free setting (which is more relevant to ROA analysis of perception-based
control), we propose a finite-difference PGD estimate which is general and only
requires a black-box simulator for generating the trajectories of the
closed-loop system given any initial state. We demonstrate the scalability and
generality of our analysis tool on several numerical examples with large-scale
NN policies and high-dimensional image observations. We believe that our
proposed analysis serves as a meaningful initial step toward further
understanding of closed-loop stability of large-scale nonlinear systems and
perception-based control.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Havens_A/0/1/0/all/0/1"&gt;Aaron Havens&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Keivan_D/0/1/0/all/0/1"&gt;Darioush Keivan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Seiler_P/0/1/0/all/0/1"&gt;Peter Seiler&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Dullerud_G/0/1/0/all/0/1"&gt;Geir Dullerud&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Hu_B/0/1/0/all/0/1"&gt;Bin Hu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stochastic convex optimization for provably efficient apprenticeship learning. (arXiv:2201.00039v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00039</id>
        <link href="http://arxiv.org/abs/2201.00039"/>
        <updated>2022-01-05T00:39:34.187Z</updated>
        <summary type="html"><![CDATA[We consider large-scale Markov decision processes (MDPs) with an unknown cost
function and employ stochastic convex optimization tools to address the problem
of imitation learning, which consists of learning a policy from a finite set of
expert demonstrations.

We adopt the apprenticeship learning formalism, which carries the assumption
that the true cost function can be represented as a linear combination of some
known features. Existing inverse reinforcement learning algorithms come with
strong theoretical guarantees, but are computationally expensive because they
use reinforcement learning or planning algorithms as a subroutine. On the other
hand, state-of-the-art policy gradient based algorithms (like IM-REINFORCE,
IM-TRPO, and GAIL), achieve significant empirical success in challenging
benchmark tasks, but are not well understood in terms of theory. With an
emphasis on non-asymptotic guarantees of performance, we propose a method that
directly learns a policy from expert demonstrations, bypassing the intermediate
step of learning the cost function, by formulating the problem as a single
convex optimization problem over occupancy measures. We develop a
computationally efficient algorithm and derive high confidence regret bounds on
the quality of the extracted policy, utilizing results from stochastic convex
optimization and recent works in approximate linear programming for solving
forward MDPs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kamoutsi_A/0/1/0/all/0/1"&gt;Angeliki Kamoutsi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Banjac_G/0/1/0/all/0/1"&gt;Goran Banjac&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lygeros_J/0/1/0/all/0/1"&gt;John Lygeros&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Nonparametric Estimation of Operators between Infinite Dimensional Spaces. (arXiv:2201.00217v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2201.00217</id>
        <link href="http://arxiv.org/abs/2201.00217"/>
        <updated>2022-01-05T00:39:34.181Z</updated>
        <summary type="html"><![CDATA[Learning operators between infinitely dimensional spaces is an important
learning task arising in wide applications in machine learning, imaging
science, mathematical modeling and simulations, etc. This paper studies the
nonparametric estimation of Lipschitz operators using deep neural networks.
Non-asymptotic upper bounds are derived for the generalization error of the
empirical risk minimizer over a properly chosen network class. Under the
assumption that the target operator exhibits a low dimensional structure, our
error bounds decay as the training sample size increases, with an attractive
fast rate depending on the intrinsic dimension in our estimation. Our
assumptions cover most scenarios in real applications and our results give rise
to fast rates by exploiting low dimensional structures of data in operator
estimation. We also investigate the influence of network structures (e.g.,
network width, depth, and sparsity) on the generalization error of the neural
network estimator and propose a general suggestion on the choice of network
structures to maximize the learning efficiency quantitatively.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Liu_H/0/1/0/all/0/1"&gt;Hao Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Yang_H/0/1/0/all/0/1"&gt;Haizhao Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Chen_M/0/1/0/all/0/1"&gt;Minshuo Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhao_T/0/1/0/all/0/1"&gt;Tuo Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Liao_W/0/1/0/all/0/1"&gt;Wenjing Liao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Experiment Based Crafting and Analyzing of Machine Learning Solutions. (arXiv:2201.00355v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00355</id>
        <link href="http://arxiv.org/abs/2201.00355"/>
        <updated>2022-01-05T00:39:34.173Z</updated>
        <summary type="html"><![CDATA[The crafting of machine learning (ML) based systems requires statistical
control throughout its life cycle. Careful quantification of business
requirements and identification of key factors that impact the business
requirements reduces the risk of a project failure. The quantification of
business requirements results in the definition of random variables
representing the system key performance indicators that need to be analyzed
through statistical experiments. In addition, available data for training and
experiment results impact the design of the system. Once the system is
developed, it is tested and continually monitored to ensure it meets its
business requirements. This is done through the continued application of
statistical experiments to analyze and control the key performance indicators.
This book teaches the art of crafting and developing ML based systems. It
advocates an "experiment first" approach stressing the need to define
statistical experiments from the beginning of the project life cycle. It also
discusses in detail how to apply statistical control on the ML based system
throughout its lifecycle.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ackerman_S/0/1/0/all/0/1"&gt;Samuel Ackerman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Farchi_E/0/1/0/all/0/1"&gt;Eitan Farchi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Raz_O/0/1/0/all/0/1"&gt;Orna Raz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shehory_O/0/1/0/all/0/1"&gt;Onn Shehory&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Croesus: Multi-Stage Processing and Transactions for Video-Analytics in Edge-Cloud Systems. (arXiv:2201.00063v1 [eess.SY])]]></title>
        <id>http://arxiv.org/abs/2201.00063</id>
        <link href="http://arxiv.org/abs/2201.00063"/>
        <updated>2022-01-05T00:39:34.154Z</updated>
        <summary type="html"><![CDATA[Emerging edge applications require both a fast response latency and complex
processing. This is infeasible without expensive hardware that can process
complex operations -- such as object detection -- within a short time. Many
approach this problem by addressing the complexity of the models -- via model
compression, pruning and quantization -- or compressing the input. In this
paper, we propose a different perspective when addressing the performance
challenges. Croesus is a multi-stage approach to edge-cloud systems that
provides the ability to find the balance between accuracy and performance.
Croesus consists of two stages (that can be generalized to multiple stages): an
initial and a final stage. The initial stage performs the computation in
real-time using approximate/best-effort computation at the edge. The final
stage performs the full computation at the cloud, and uses the results to
correct any errors made at the initial stage. In this paper, we demonstrate the
implications of such an approach on a video analytics use-case and show how
multi-stage processing yields a better balance between accuracy and
performance. Moreover, we study the safety of multi-stage transactions via two
proposals: multi-stage serializability (MS-SR) and multi-stage invariant
confluence with Apologies (MS-IA).]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Gazzaz_S/0/1/0/all/0/1"&gt;Samaa Gazzaz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Chakraborty_V/0/1/0/all/0/1"&gt;Vishal Chakraborty&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Nawab_F/0/1/0/all/0/1"&gt;Faisal Nawab&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Actor-Critic Network for Q&A in an Adversarial Environment. (arXiv:2201.00455v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2201.00455</id>
        <link href="http://arxiv.org/abs/2201.00455"/>
        <updated>2022-01-05T00:39:34.147Z</updated>
        <summary type="html"><![CDATA[Significant work has been placed in the Q&A NLP space to build models that
are more robust to adversarial attacks. Two key areas of focus are in
generating adversarial data for the purposes of training against these
situations or modifying existing architectures to build robustness within. This
paper introduces an approach that joins these two ideas together to train a
critic model for use in an almost reinforcement learning framework. Using the
Adversarial SQuAD "Add One Sent" dataset we show that there are some promising
signs for this method in protecting against Adversarial attacks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sadeghian_B/0/1/0/all/0/1"&gt;Bejan Sadeghian&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents. (arXiv:2201.00308v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00308</id>
        <link href="http://arxiv.org/abs/2201.00308"/>
        <updated>2022-01-05T00:39:34.141Z</updated>
        <summary type="html"><![CDATA[Diffusion Probabilistic models have been shown to generate state-of-the-art
results on several competitive image synthesis benchmarks but lack a
low-dimensional, interpretable latent space, and are slow at generation. On the
other hand, Variational Autoencoders (VAEs) typically have access to a
low-dimensional latent space but exhibit poor sample quality. Despite recent
advances, VAEs usually require high-dimensional hierarchies of the latent codes
to generate high-quality samples. We present DiffuseVAE, a novel generative
framework that integrates VAE within a diffusion model framework, and leverage
this to design a novel conditional parameterization for diffusion models. We
show that the resulting model can improve upon the unconditional diffusion
model in terms of sampling efficiency while also equipping diffusion models
with the low-dimensional VAE inferred latent code. Furthermore, we show that
the proposed model can generate high-resolution samples and exhibits synthesis
quality comparable to state-of-the-art models on standard benchmarks. Lastly,
we show that the proposed method can be used for controllable image synthesis
and also exhibits out-of-the-box capabilities for downstream tasks like image
super-resolution and denoising. For reproducibility, our source code is
publicly available at \url{https://github.com/kpandey008/DiffuseVAE}.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pandey_K/0/1/0/all/0/1"&gt;Kushagra Pandey&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1"&gt;Avideep Mukherjee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rai_P/0/1/0/all/0/1"&gt;Piyush Rai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1"&gt;Abhishek Kumar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Near-Optimal Algorithm for Debiasing Trained Machine Learning Models. (arXiv:2106.12887v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.12887</id>
        <link href="http://arxiv.org/abs/2106.12887"/>
        <updated>2022-01-05T00:39:34.072Z</updated>
        <summary type="html"><![CDATA[We present a scalable post-processing algorithm for debiasing trained models,
including deep neural networks (DNNs), which we prove to be near-optimal by
bounding its excess Bayes risk. We empirically validate its advantages on
standard benchmark datasets across both classical algorithms as well as modern
DNN architectures and demonstrate that it outperforms previous post-processing
methods while performing on par with in-processing. In addition, we show that
the proposed algorithm is particularly effective for models trained at scale
where post-processing is a natural and practical choice.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Alabdulmohsin_I/0/1/0/all/0/1"&gt;Ibrahim Alabdulmohsin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1"&gt;Mario Lucic&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalable semi-supervised dimensionality reduction with GPU-accelerated EmbedSOM. (arXiv:2201.00701v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00701</id>
        <link href="http://arxiv.org/abs/2201.00701"/>
        <updated>2022-01-05T00:39:34.066Z</updated>
        <summary type="html"><![CDATA[Dimensionality reduction methods have found vast application as visualization
tools in diverse areas of science. Although many different methods exist, their
performance is often insufficient for providing quick insight into many
contemporary datasets, and the unsupervised mode of use prevents the users from
utilizing the methods for dataset exploration and fine-tuning the details for
improved visualization quality. We present BlosSOM, a high-performance
semi-supervised dimensionality reduction software for interactive
user-steerable visualization of high-dimensional datasets with millions of
individual data points. BlosSOM builds on a GPU-accelerated implementation of
the EmbedSOM algorithm, complemented by several landmark-based algorithms for
interfacing the unsupervised model learning algorithms with the user
supervision. We show the application of BlosSOM on realistic datasets, where it
helps to produce high-quality visualizations that incorporate user-specified
layout and focus on certain features. We believe the semi-supervised
dimensionality reduction will improve the data visualization possibilities for
science areas such as single-cell cytometry, and provide a fast and efficient
base methodology for new directions in dataset exploration and annotation.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Smelko_A/0/1/0/all/0/1"&gt;Adam &amp;#x160;melko&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Molnarova_S/0/1/0/all/0/1"&gt;So&amp;#x148;a Moln&amp;#xe1;rov&amp;#xe1;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kratochvil_M/0/1/0/all/0/1"&gt;Miroslav Kratochv&amp;#xed;l&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Koladiya_A/0/1/0/all/0/1"&gt;Abhishek Koladiya&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Musil_J/0/1/0/all/0/1"&gt;Jan Musil&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Krulis_M/0/1/0/all/0/1"&gt;Martin Kruli&amp;#x161;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vondrasek_J/0/1/0/all/0/1"&gt;Ji&amp;#x159;&amp;#xed; Vondr&amp;#xe1;&amp;#x161;ek&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Sampling Gaps for Adaptive Submodular Maximization. (arXiv:2104.01750v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.01750</id>
        <link href="http://arxiv.org/abs/2104.01750"/>
        <updated>2022-01-05T00:39:34.059Z</updated>
        <summary type="html"><![CDATA[Running machine learning algorithms on large and rapidly growing volumes of
data is often computationally expensive, one common trick to reduce the size of
a data set, and thus reduce the computational cost of machine learning
algorithms, is \emph{probability sampling}. It creates a sampled data set by
including each data point from the original data set with a known probability.
Although the benefit of running machine learning algorithms on the reduced data
set is obvious, one major concern is that the performance of the solution
obtained from samples might be much worse than that of the optimal solution
when using the full data set. In this paper, we examine the performance loss
caused by probability sampling in the context of adaptive submodular
maximization. We consider a simple probability sampling method which selects
each data point with probability $r\in[0,1]$. If we set the sampling rate
$r=1$, our problem reduces to finding a solution based on the original full
data set. We define sampling gap as the largest ratio between the optimal
solution obtained from the full data set and the optimal solution obtained from
the samples, over independence systems. %It captures the performance loss of
the optimal solution caused by the probability sampling. Our main contribution
is to show that if the utility function is policywise submodular, then for a
given sampling rate $r$, the sampling gap is both upper bounded and lower
bounded by $1/r$. One immediate implication of our result is that if we can
find an $\alpha$-approximation solution based on a sampled data set (which is
sampled at sampling rate $r$), then this solution achieves an $\alpha r$
approximation ratio against the optimal solution when using the full data set.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1"&gt;Shaojie Tang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1"&gt;Jing Yuan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Provable Generalization of Recurrent Neural Networks. (arXiv:2109.14142v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.14142</id>
        <link href="http://arxiv.org/abs/2109.14142"/>
        <updated>2022-01-05T00:39:34.028Z</updated>
        <summary type="html"><![CDATA[Recurrent Neural Network (RNN) is a fundamental structure in deep learning.
Recently, some works study the training process of over-parameterized neural
networks, and show that over-parameterized networks can learn functions in some
notable concept classes with a provable generalization error bound. In this
paper, we analyze the training and generalization for RNNs with random
initialization, and provide the following improvements over recent works:

1) For a RNN with input sequence $x=(X_1,X_2,...,X_L)$, previous works study
to learn functions that are summation of $f(\beta^T_lX_l)$ and require
normalized conditions that $||X_l||\leq\epsilon$ with some very small
$\epsilon$ depending on the complexity of $f$. In this paper, using detailed
analysis about the neural tangent kernel matrix, we prove a generalization
error bound to learn such functions without normalized conditions and show that
some notable concept classes are learnable with the numbers of iterations and
samples scaling almost-polynomially in the input length $L$.

2) Moreover, we prove a novel result to learn N-variables functions of input
sequence with the form $f(\beta^T[X_{l_1},...,X_{l_N}])$, which do not belong
to the "additive" concept class, i,e., the summation of function $f(X_l)$. And
we show that when either $N$ or $l_0=\max(l_1,..,l_N)-\min(l_1,..,l_N)$ is
small, $f(\beta^T[X_{l_1},...,X_{l_N}])$ will be learnable with the number
iterations and samples scaling almost-polynomially in the input length $L$.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"&gt;Lifu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1"&gt;Bo Shen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1"&gt;Bo Hu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1"&gt;Xing Cao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Online Regularization towards Always-Valid High-Dimensional Dynamic Pricing. (arXiv:2007.02470v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2007.02470</id>
        <link href="http://arxiv.org/abs/2007.02470"/>
        <updated>2022-01-05T00:39:34.020Z</updated>
        <summary type="html"><![CDATA[Devising dynamic pricing policy with always valid online statistical learning
procedure is an important and as yet unresolved problem. Most existing dynamic
pricing policy, which focus on the faithfulness of adopted customer choice
models, exhibit a limited capability for adapting the online uncertainty of
learned statistical model during pricing process. In this paper, we propose a
novel approach for designing dynamic pricing policy based regularized online
statistical learning with theoretical guarantees. The new approach overcomes
the challenge of continuous monitoring of online Lasso procedure and possesses
several appealing properties. In particular, we make the decisive observation
that the always-validity of pricing decisions builds and thrives on the online
regularization scheme. Our proposed online regularization scheme equips the
proposed optimistic online regularized maximum likelihood pricing (OORMLP)
pricing policy with three major advantages: encode market noise knowledge into
pricing process optimism; empower online statistical learning with
always-validity over all decision points; envelop prediction error process with
time-uniform non-asymptotic oracle inequalities. This type of non-asymptotic
inference results allows us to design more sample-efficient and robust dynamic
pricing algorithms in practice. In theory, the proposed OORMLP algorithm
exploits the sparsity structure of high-dimensional models and secures a
logarithmic regret in a decision horizon. These theoretical advances are made
possible by proposing an optimistic online Lasso procedure that resolves
dynamic pricing problems at the process level, based on a novel use of
non-asymptotic martingale concentration. In experiments, we evaluate OORMLP in
different synthetic and real pricing problem settings, and demonstrate that
OORMLP advances the state-of-the-art methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1"&gt;Chi-Hua Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zhanyu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1"&gt;Will Wei Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1"&gt;Guang Cheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conditional Selective Inference for Robust Regression and Outlier Detection using Piecewise-Linear Homotopy Continuation. (arXiv:2104.10840v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.10840</id>
        <link href="http://arxiv.org/abs/2104.10840"/>
        <updated>2022-01-05T00:39:33.954Z</updated>
        <summary type="html"><![CDATA[In practical data analysis under noisy environment, it is common to first use
robust methods to identify outliers, and then to conduct further analysis after
removing the outliers. In this paper, we consider statistical inference of the
model estimated after outliers are removed, which can be interpreted as a
selective inference (SI) problem. To use conditional SI framework, it is
necessary to characterize the events of how the robust method identifies
outliers. Unfortunately, the existing methods cannot be directly used here
because they are applicable to the case where the selection events can be
represented by linear/quadratic constraints. In this paper, we propose a
conditional SI method for popular robust regressions by using homotopy method.
We show that the proposed conditional SI method is applicable to a wide class
of robust regression and outlier detection methods and has good empirical
performance on both synthetic data and real data experiments.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Tsukurimichi_T/0/1/0/all/0/1"&gt;Toshiaki Tsukurimichi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Inatsu_Y/0/1/0/all/0/1"&gt;Yu Inatsu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Duy_V/0/1/0/all/0/1"&gt;Vo Nguyen Le Duy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1"&gt;Ichiro Takeuchi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Application of Machine Learning Methods in Inferring Surface Water Groundwater Exchanges using High Temporal Resolution Temperature Measurements. (arXiv:2201.00726v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00726</id>
        <link href="http://arxiv.org/abs/2201.00726"/>
        <updated>2022-01-05T00:39:33.948Z</updated>
        <summary type="html"><![CDATA[We examine the ability of machine learning (ML) and deep learning (DL)
algorithms to infer surface/ground exchange flux based on subsurface
temperature observations. The observations and fluxes are produced from a
high-resolution numerical model representing conditions in the Columbia River
near the Department of Energy Hanford site located in southeastern Washington
State. Random measurement error, of varying magnitude, is added to the
synthetic temperature observations. The results indicate that both ML and DL
methods can be used to infer the surface/ground exchange flux. DL methods,
especially convolutional neural networks, outperform the ML methods when used
to interpret noisy temperature data with a smoothing filter applied. However,
the ML methods also performed well and they are can better identify a reduced
number of important observations, which could be useful for measurement network
optimization. Surprisingly, the ML and DL methods better inferred upward flux
than downward flux. This is in direct contrast to previous findings using
numerical models to infer flux from temperature observations and it may suggest
that combined use of ML or DL inference with numerical inference could improve
flux estimation beneath river systems.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Moghaddam_M/0/1/0/all/0/1"&gt;Mohammad A. Moghaddam&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ferre_T/0/1/0/all/0/1"&gt;Ty P. A. Ferre&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"&gt;Xingyuan Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1"&gt;Kewei Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ehsani_M/0/1/0/all/0/1"&gt;Mohammad Reza Ehsani&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provable Meta-Learning of Linear Representations. (arXiv:2002.11684v5 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2002.11684</id>
        <link href="http://arxiv.org/abs/2002.11684"/>
        <updated>2022-01-05T00:39:30.797Z</updated>
        <summary type="html"><![CDATA[Meta-learning, or learning-to-learn, seeks to design algorithms that can
utilize previous experience to rapidly learn new skills or adapt to new
environments. Representation learning -- a key tool for performing
meta-learning -- learns a data representation that can transfer knowledge
across multiple tasks, which is essential in regimes where data is scarce.
Despite a recent surge of interest in the practice of meta-learning, the
theoretical underpinnings of meta-learning algorithms are lacking, especially
in the context of learning transferable representations. In this paper, we
focus on the problem of multi-task linear regression -- in which multiple
linear regression models share a common, low-dimensional linear representation.
Here, we provide provably fast, sample-efficient algorithms to address the dual
challenges of (1) learning a common set of features from multiple, related
tasks, and (2) transferring this knowledge to new, unseen tasks. Both are
central to the general problem of meta-learning. Finally, we complement these
results by providing information-theoretic lower bounds on the sample
complexity of learning these linear features.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tripuraneni_N/0/1/0/all/0/1"&gt;Nilesh Tripuraneni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1"&gt;Chi Jin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1"&gt;Michael I. Jordan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Statistical Inference with Local Optima. (arXiv:1807.04431v2 [math.ST] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1807.04431</id>
        <link href="http://arxiv.org/abs/1807.04431"/>
        <updated>2022-01-05T00:39:30.790Z</updated>
        <summary type="html"><![CDATA[We study the statistical properties of an estimator derived by applying a
gradient ascent method with multiple initializations to a multi-modal
likelihood function. We derive the population quantity that is the target of
this estimator and study the properties of confidence intervals (CIs)
constructed from asymptotic normality and the bootstrap approach. In
particular, we analyze the coverage deficiency due to finite number of random
initializations. We also investigate the CIs by inverting the likelihood ratio
test, the score test, and the Wald test, and we show that the resulting CIs may
be very different. We propose a two-sample test procedure even when the MLE is
intractable. In addition, we analyze the performance of the EM algorithm under
random initializations and derive the coverage of a CI with a finite number of
initializations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yen-Chi Chen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kernel Two-Sample Tests in High Dimension: Interplay Between Moment Discrepancy and Dimension-and-Sample Orders. (arXiv:2201.00073v1 [math.ST])]]></title>
        <id>http://arxiv.org/abs/2201.00073</id>
        <link href="http://arxiv.org/abs/2201.00073"/>
        <updated>2022-01-05T00:39:30.783Z</updated>
        <summary type="html"><![CDATA[Motivated by the increasing use of kernel-based metrics for high-dimensional
and large-scale data, we study the asymptotic behavior of kernel two-sample
tests when the dimension and sample sizes both diverge to infinity. We focus on
the maximum mean discrepancy (MMD) with the kernel of the form
$k(x,y)=f(\|x-y\|_{2}^{2}/\gamma)$, including MMD with the Gaussian kernel and
the Laplacian kernel, and the energy distance as special cases. We derive
asymptotic expansions of the kernel two-sample statistics, based on which we
establish the central limit theorem (CLT) under both the null hypothesis and
the local and fixed alternatives. The new non-null CLT results allow us to
perform asymptotic exact power analysis, which reveals a delicate interplay
between the moment discrepancy that can be detected by the kernel two-sample
tests and the dimension-and-sample orders. The asymptotic theory is further
corroborated through numerical studies. Our findings complement those in the
recent literature and shed new light on the use of kernel two-sample tests for
high-dimensional and large-scale data.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Yan_J/0/1/0/all/0/1"&gt;Jian Yan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Zhang_X/0/1/0/all/0/1"&gt;Xianyang Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Robust Probabilistic Principal Component Analysis using Multivariate $t$-Distributions. (arXiv:2010.10786v2 [stat.ME] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.10786</id>
        <link href="http://arxiv.org/abs/2010.10786"/>
        <updated>2022-01-05T00:39:30.777Z</updated>
        <summary type="html"><![CDATA[Probabilistic principal component analysis (PPCA) is a probabilistic
reformulation of principal component analysis (PCA), under the framework of a
Gaussian latent variable model. To improve the robustness of PPCA, it has been
proposed to change the underlying Gaussian distributions to multivariate
$t$-distributions. Based on the representation of $t$-distribution as a scale
mixture of Gaussian distributions, a hierarchical model is used for
implementation. However, in the existing literature, the hierarchical model
implemented does not yield the equivalent interpretation.

In this paper, we present two sets of equivalent relationships between the
high-level multivariate $t$-PPCA framework and the hierarchical model used for
implementation. In doing so, we clarify a current misrepresentation in the
literature, by specifying the correct correspondence. In addition, we discuss
the performance of different multivariate $t$ robust PPCA methods both in
theory and simulation studies, and propose a novel Monte Carlo
expectation-maximization (MCEM) algorithm to implement one general type of such
models.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Guo_Y/0/1/0/all/0/1"&gt;Yiping Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Bondell_H/0/1/0/all/0/1"&gt;Howard D. Bondell&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Nonparametric Estimation of Operators between Infinite Dimensional Spaces. (arXiv:2201.00217v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2201.00217</id>
        <link href="http://arxiv.org/abs/2201.00217"/>
        <updated>2022-01-05T00:39:30.771Z</updated>
        <summary type="html"><![CDATA[Learning operators between infinitely dimensional spaces is an important
learning task arising in wide applications in machine learning, imaging
science, mathematical modeling and simulations, etc. This paper studies the
nonparametric estimation of Lipschitz operators using deep neural networks.
Non-asymptotic upper bounds are derived for the generalization error of the
empirical risk minimizer over a properly chosen network class. Under the
assumption that the target operator exhibits a low dimensional structure, our
error bounds decay as the training sample size increases, with an attractive
fast rate depending on the intrinsic dimension in our estimation. Our
assumptions cover most scenarios in real applications and our results give rise
to fast rates by exploiting low dimensional structures of data in operator
estimation. We also investigate the influence of network structures (e.g.,
network width, depth, and sparsity) on the generalization error of the neural
network estimator and propose a general suggestion on the choice of network
structures to maximize the learning efficiency quantitatively.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Liu_H/0/1/0/all/0/1"&gt;Hao Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Yang_H/0/1/0/all/0/1"&gt;Haizhao Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Chen_M/0/1/0/all/0/1"&gt;Minshuo Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Zhao_T/0/1/0/all/0/1"&gt;Tuo Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Liao_W/0/1/0/all/0/1"&gt;Wenjing Liao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Global convergence of optimized adaptive importance samplers. (arXiv:2201.00409v1 [stat.CO])]]></title>
        <id>http://arxiv.org/abs/2201.00409</id>
        <link href="http://arxiv.org/abs/2201.00409"/>
        <updated>2022-01-05T00:39:30.750Z</updated>
        <summary type="html"><![CDATA[We analyze the optimized adaptive importance sampler (OAIS) for performing
Monte Carlo integration with general proposals. We leverage a classical result
which shows that the bias and the mean-squared error (MSE) of the importance
sampling scales with the $\chi^2$-divergence between the target and the
proposal and develop a scheme which performs global optimization of
$\chi^2$-divergence. While it is known that this quantity is convex for
exponential family proposals, the case of the general proposals has been an
open problem. We close this gap by utilizing stochastic gradient Langevin
dynamics (SGLD) and its underdamped counterpart for the global optimization of
$\chi^2$-divergence and derive nonasymptotic bounds for the MSE by leveraging
recent results from non-convex optimization literature. The resulting AIS
schemes have explicit theoretical guarantees uniform in the number of
iterations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Akyildiz_O/0/1/0/all/0/1"&gt;&amp;#xd6;mer Deniz Akyildiz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ECOD: Unsupervised Outlier Detection Using Empirical Cumulative Distribution Functions. (arXiv:2201.00382v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00382</id>
        <link href="http://arxiv.org/abs/2201.00382"/>
        <updated>2022-01-05T00:39:30.742Z</updated>
        <summary type="html"><![CDATA[Outlier detection refers to the identification of data points that deviate
from a general data distribution. Existing unsupervised approaches often suffer
from high computational cost, complex hyperparameter tuning, and limited
interpretability, especially when working with large, high-dimensional
datasets. To address these issues, we present a simple yet effective algorithm
called ECOD (Empirical-Cumulative-distribution-based Outlier Detection), which
is inspired by the fact that outliers are often the "rare events" that appear
in the tails of a distribution. In a nutshell, ECOD first estimates the
underlying distribution of the input data in a nonparametric fashion by
computing the empirical cumulative distribution per dimension of the data. ECOD
then uses these empirical distributions to estimate tail probabilities per
dimension for each data point. Finally, ECOD computes an outlier score of each
data point by aggregating estimated tail probabilities across dimensions. Our
contributions are as follows: (1) we propose a novel outlier detection method
called ECOD, which is both parameter-free and easy to interpret; (2) we perform
extensive experiments on 30 benchmark datasets, where we find that ECOD
outperforms 11 state-of-the-art baselines in terms of accuracy, efficiency, and
scalability; and (3) we release an easy-to-use and scalable (with distributed
support) Python implementation for accessibility and reproducibility.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"&gt;Zheng Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1"&gt;Yue Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1"&gt;Xiyang Hu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Botta_N/0/1/0/all/0/1"&gt;Nicola Botta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ionescu_C/0/1/0/all/0/1"&gt;Cezar Ionescu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1"&gt;George H. Chen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cluster Stability Selection. (arXiv:2201.00494v1 [stat.ME])]]></title>
        <id>http://arxiv.org/abs/2201.00494</id>
        <link href="http://arxiv.org/abs/2201.00494"/>
        <updated>2022-01-05T00:39:30.735Z</updated>
        <summary type="html"><![CDATA[Stability selection (Meinshausen and Buhlmann, 2010) makes any feature
selection method more stable by returning only those features that are
consistently selected across many subsamples. We prove (in what is, to our
knowledge, the first result of its kind) that for data containing highly
correlated proxies for an important latent variable, the lasso typically
selects one proxy, yet stability selection with the lasso can fail to select
any proxy, leading to worse predictive performance than the lasso alone.

We introduce cluster stability selection, which exploits the practitioner's
knowledge that highly correlated clusters exist in the data, resulting in
better feature rankings than stability selection in this setting. We consider
several feature-combination approaches, including taking a weighted average of
the features in each important cluster where weights are determined by the
frequency with which cluster members are selected, which we show leads to
better predictive models than previous proposals.

We present generalizations of theoretical guarantees from Meinshausen and
Buhlmann (2010) and Shah and Samworth (2012) to show that cluster stability
selection retains the same guarantees. In summary, cluster stability selection
enjoys the best of both worlds, yielding a sparse selected set that is both
stable and has good predictive performance.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Faletto_G/0/1/0/all/0/1"&gt;Gregory Faletto&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Bien_J/0/1/0/all/0/1"&gt;Jacob Bien&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Risk Bounds for Over-parameterized Maximum Margin Classification on Sub-Gaussian Mixtures. (arXiv:2104.13628v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.13628</id>
        <link href="http://arxiv.org/abs/2104.13628"/>
        <updated>2022-01-05T00:39:30.729Z</updated>
        <summary type="html"><![CDATA[Modern machine learning systems such as deep neural networks are often highly
over-parameterized so that they can fit the noisy training data exactly, yet
they can still achieve small test errors in practice. In this paper, we study
this "benign overfitting" phenomenon of the maximum margin classifier for
linear classification problems. Specifically, we consider data generated from
sub-Gaussian mixtures, and provide a tight risk bound for the maximum margin
linear classifier in the over-parameterized setting. Our results precisely
characterize the condition under which benign overfitting can occur in linear
classification problems, and improve on previous work. They also have direct
implications for over-parameterized logistic regression.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"&gt;Yuan Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Belkin_M/0/1/0/all/0/1"&gt;Mikhail Belkin&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification. (arXiv:2112.13236v2 [cs.CR] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.13236</id>
        <link href="http://arxiv.org/abs/2112.13236"/>
        <updated>2022-01-05T00:39:30.723Z</updated>
        <summary type="html"><![CDATA[Classification of malware families is crucial for a comprehensive
understanding of how they can infect devices, computers, or systems. Thus,
malware identification enables security researchers and incident responders to
take precautions against malware and accelerate mitigation. API call sequences
made by malware are widely utilized features by machine and deep learning
models for malware classification as these sequences represent the behavior of
malware. However, traditional machine and deep learning models remain incapable
of capturing sequence relationships between API calls. On the other hand, the
transformer-based models process sequences as a whole and learn relationships
between API calls due to multi-head attention mechanisms and positional
embeddings. Our experiments demonstrate that the transformer model with one
transformer block layer surpassed the widely used base architecture, LSTM.
Moreover, BERT or CANINE, pre-trained transformer models, outperformed in
classifying highly imbalanced malware families according to evaluation metrics,
F1-score, and AUC score. Furthermore, the proposed bagging-based random
transformer forest (RTF), an ensemble of BERT or CANINE, has reached the
state-of-the-art evaluation scores on three out of four datasets, particularly
state-of-the-art F1-score of 0.6149 on one of the commonly used benchmark
dataset.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Demirkiran_F/0/1/0/all/0/1"&gt;Ferhat Demirk&amp;#x131;ran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cayir_A/0/1/0/all/0/1"&gt;Aykut &amp;#xc7;ay&amp;#x131;r&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Unal_U/0/1/0/all/0/1"&gt;U&amp;#x11f;ur &amp;#xdc;nal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dag_H/0/1/0/all/0/1"&gt;Hasan Da&amp;#x11f;&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Covariate-assisted Sparse Tensor Completion. (arXiv:2103.06428v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.06428</id>
        <link href="http://arxiv.org/abs/2103.06428"/>
        <updated>2022-01-05T00:39:30.716Z</updated>
        <summary type="html"><![CDATA[We aim to provably complete a sparse and highly-missing tensor in the
presence of covariate information along tensor modes. Our motivation comes from
online advertising where users click-through-rates (CTR) on ads over various
devices form a CTR tensor that has about 96% missing entries and has many zeros
on non-missing entries, which makes the standalone tensor completion method
unsatisfactory. Beside the CTR tensor, additional ad features or user
characteristics are often available. In this paper, we propose
Covariate-assisted Sparse Tensor Completion (COSTCO) to incorporate covariate
information for the recovery of the sparse tensor. The key idea is to jointly
extract latent components from both the tensor and the covariate matrix to
learn a synthetic representation. Theoretically, we derive the error bound for
the recovered tensor components and explicitly quantify the improvements on
both the reveal probability condition and the tensor recovery accuracy due to
covariates. Finally, we apply COSTCO to an advertisement dataset consisting of
a CTR tensor and ad covariate matrix, leading to 23% accuracy improvement over
the baseline. An important by-product is that ad latent components from COSTCO
reveal interesting ad clusters, which are useful for better ad targeting.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Ibriga_H/0/1/0/all/0/1"&gt;Hilda S Ibriga&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1"&gt;Will Wei Sun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning. (arXiv:2106.03760v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.03760</id>
        <link href="http://arxiv.org/abs/2106.03760"/>
        <updated>2022-01-05T00:39:30.698Z</updated>
        <summary type="html"><![CDATA[The Mixture-of-Experts (MoE) architecture is showing promising results in
improving parameter sharing in multi-task learning (MTL) and in scaling
high-capacity neural networks. State-of-the-art MoE models use a trainable
sparse gate to select a subset of the experts for each input example. While
conceptually appealing, existing sparse gates, such as Top-k, are not smooth.
The lack of smoothness can lead to convergence and statistical performance
issues when training with gradient-based methods. In this paper, we develop
DSelect-k: a continuously differentiable and sparse gate for MoE, based on a
novel binary encoding formulation. The gate can be trained using first-order
methods, such as stochastic gradient descent, and offers explicit control over
the number of experts to select. We demonstrate the effectiveness of DSelect-k
on both synthetic and real MTL datasets with up to $128$ tasks. Our experiments
indicate that DSelect-k can achieve statistically significant improvements in
prediction and expert selection over popular MoE gates. Notably, on a
real-world, large-scale recommender system, DSelect-k achieves over $22\%$
improvement in predictive performance compared to Top-k. We provide an
open-source implementation of DSelect-k.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hazimeh_H/0/1/0/all/0/1"&gt;Hussein Hazimeh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1"&gt;Zhe Zhao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chowdhery_A/0/1/0/all/0/1"&gt;Aakanksha Chowdhery&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sathiamoorthy_M/0/1/0/all/0/1"&gt;Maheswaran Sathiamoorthy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yihua Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mazumder_R/0/1/0/all/0/1"&gt;Rahul Mazumder&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1"&gt;Lichan Hong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1"&gt;Ed H. Chi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Class-Incremental Continual Learning into the eXtended DER-verse. (arXiv:2201.00766v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00766</id>
        <link href="http://arxiv.org/abs/2201.00766"/>
        <updated>2022-01-05T00:39:30.691Z</updated>
        <summary type="html"><![CDATA[The staple of human intelligence is the capability of acquiring knowledge in
a continuous fashion. In stark contrast, Deep Networks forget catastrophically
and, for this reason, the sub-field of Class-Incremental Continual Learning
fosters methods that learn a sequence of tasks incrementally, blending
sequentially-gained knowledge into a comprehensive prediction.

This work aims at assessing and overcoming the pitfalls of our previous
proposal Dark Experience Replay (DER), a simple and effective approach that
combines rehearsal and Knowledge Distillation. Inspired by the way our minds
constantly rewrite past recollections and set expectations for the future, we
endow our model with the abilities to i) revise its replay memory to welcome
novel information regarding past data ii) pave the way for learning yet unseen
classes.

We show that the application of these strategies leads to remarkable
improvements; indeed, the resulting method - termed eXtended-DER (X-DER) -
outperforms the state of the art on both standard benchmarks (such as CIFAR-100
and miniImagenet) and a novel one here introduced. To gain a better
understanding, we further provide extensive ablation studies that corroborate
and extend the findings of our previous research (e.g. the value of Knowledge
Distillation and flatter minima in continual learning setups).]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Boschini_M/0/1/0/all/0/1"&gt;Matteo Boschini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bonicelli_L/0/1/0/all/0/1"&gt;Lorenzo Bonicelli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Buzzega_P/0/1/0/all/0/1"&gt;Pietro Buzzega&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Porrello_A/0/1/0/all/0/1"&gt;Angelo Porrello&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Calderara_S/0/1/0/all/0/1"&gt;Simone Calderara&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Network Middle-Term Probabilistic Forecasting of Daily Power Consumption. (arXiv:2006.16388v2 [stat.ME] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2006.16388</id>
        <link href="http://arxiv.org/abs/2006.16388"/>
        <updated>2022-01-05T00:39:30.683Z</updated>
        <summary type="html"><![CDATA[Middle-term horizon (months to a year) power consumption prediction is a main
challenge in the energy sector, in particular when probabilistic forecasting is
considered. We propose a new modelling approach that incorporates trend,
seasonality and weather conditions, as explicative variables in a shallow
Neural Network with an autoregressive feature. We obtain excellent results for
density forecast on the one-year test set applying it to the daily power
consumption in New England U.S.A.. The quality of the achieved power
consumption probabilistic forecasting has been verified, on the one hand,
comparing the results to other standard models for density forecasting and, on
the other hand, considering measures that are frequently used in the energy
sector as pinball loss and CI backtesting.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Azzone_M/0/1/0/all/0/1"&gt;Michele Azzone&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Baviera_R/0/1/0/all/0/1"&gt;Roberto Baviera&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Identify comorbidities associated with recurrent ED and in-patient visits. (arXiv:2110.13769v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.13769</id>
        <link href="http://arxiv.org/abs/2110.13769"/>
        <updated>2022-01-05T00:39:30.672Z</updated>
        <summary type="html"><![CDATA[In the hospital setting, a small percentage of recurrent frequent patients
contribute to a disproportional amount of healthcare resource usage. Moreover,
in many of these cases, patient outcomes can be greatly improved by reducing
reoccurring visits, especially when they are associated with substance abuse,
mental health, and medical factors that could be improved by social-behavioral
interventions, outpatient or preventative care. Additionally, health care costs
can be reduced significantly with fewer preventable recurrent visits.

To address this, we developed a computationally efficient and interpretable
framework that both identifies recurrent patients with high utilization and
determines which comorbidities contribute most to their recurrent visits.
Specifically, we present a novel algorithm, called the minimum similarity
association rules (MSAR), balancing confidence-support trade-off, to determine
the conditions most associated with reoccurring Emergency department (ED) and
inpatient visits. We validate MSAR on a large Electric Health Record (EHR)
dataset.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Liu_L/0/1/0/all/0/1"&gt;Luoluo Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Simhon_E/0/1/0/all/0/1"&gt;Eran Simhon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Kulkarni_C/0/1/0/all/0/1"&gt;Chaitanya Kulkarni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Noren_D/0/1/0/all/0/1"&gt;David Noren&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Mans_R/0/1/0/all/0/1"&gt;Ronny Mans&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linear Classifiers in Product Space Forms. (arXiv:2102.10204v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.10204</id>
        <link href="http://arxiv.org/abs/2102.10204"/>
        <updated>2022-01-05T00:39:30.324Z</updated>
        <summary type="html"><![CDATA[Embedding methods for product spaces are powerful techniques for
low-distortion and low-dimensional representation of complex data structures.
Here, we address the new problem of linear classification in product space
forms -- products of Euclidean, spherical, and hyperbolic spaces. First, we
describe novel formulations for linear classifiers on a Riemannian manifold
using geodesics and Riemannian metrics which generalize straight lines and
inner products in vector spaces. Second, we prove that linear classifiers in
$d$-dimensional space forms of any curvature have the same expressive power,
i.e., they can shatter exactly $d+1$ points. Third, we formalize linear
classifiers in product space forms, describe the first known perceptron and
support vector machine classifiers for such spaces and establish rigorous
convergence results for perceptrons. Moreover, we prove that the
Vapnik-Chervonenkis dimension of linear classifiers in a product space form of
dimension $d$ is \emph{at least} $d+1$. We support our theoretical findings
with simulations on several datasets, including synthetic data, image data, and
single-cell RNA sequencing (scRNA-seq) data. The results show that
classification in low-dimensional product space forms for scRNA-seq data
offers, on average, a performance improvement of $\sim15\%$ when compared to
that in Euclidean spaces of the same dimension.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tabaghi_P/0/1/0/all/0/1"&gt;Puoya Tabaghi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1"&gt;Chao Pan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1"&gt;Eli Chien&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1"&gt;Jianhao Peng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1"&gt;Olgica Milenkovic&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provably Efficient Reinforcement Learning with Linear Function Approximation Under Adaptivity Constraints. (arXiv:2101.02195v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2101.02195</id>
        <link href="http://arxiv.org/abs/2101.02195"/>
        <updated>2022-01-05T00:39:30.316Z</updated>
        <summary type="html"><![CDATA[We study reinforcement learning (RL) with linear function approximation under
the adaptivity constraint. We consider two popular limited adaptivity models:
the batch learning model and the rare policy switch model, and propose two
efficient online RL algorithms for episodic linear Markov decision processes,
where the transition probability and the reward function can be represented as
a linear function of some known feature mapping. In specific, for the batch
learning model, our proposed LSVI-UCB-Batch algorithm achieves an $\tilde
O(\sqrt{d^3H^3T} + dHT/B)$ regret, where $d$ is the dimension of the feature
mapping, $H$ is the episode length, $T$ is the number of interactions and $B$
is the number of batches. Our result suggests that it suffices to use only
$\sqrt{T/dH}$ batches to obtain $\tilde O(\sqrt{d^3H^3T})$ regret. For the rare
policy switch model, our proposed LSVI-UCB-RareSwitch algorithm enjoys an
$\tilde O(\sqrt{d^3H^3T[1+T/(dH)]^{dH/B}})$ regret, which implies that $dH\log
T$ policy switches suffice to obtain the $\tilde O(\sqrt{d^3H^3T})$ regret. Our
algorithms achieve the same regret as the LSVI-UCB algorithm (Jin et al.,
2019), yet with a substantially smaller amount of adaptivity. We also establish
a lower bound for the batch learning model, which suggests that the dependency
on $B$ in our regret bound is tight.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1"&gt;Tianhao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Boosting the Certified Robustness of L-infinity Distance Nets. (arXiv:2110.06850v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.06850</id>
        <link href="http://arxiv.org/abs/2110.06850"/>
        <updated>2022-01-05T00:39:30.176Z</updated>
        <summary type="html"><![CDATA[Recently, Zhang et al.(2021) developed a new neural network architecture
based on $\ell_\infty$-distance functions, which naturally possesses certified
$\ell_\infty$ robustness by its construction. Despite rigorous theoretical
guarantees, the model so far can only achieve comparable performance to
conventional networks. In this paper, we make the following two contributions:
$\mathrm{(i)}$ We demonstrate that $\ell_\infty$-distance nets enjoy a
fundamental advantage in certified robustness over conventional networks (under
typical certification approaches); $\mathrm{(ii)}$ With an improved training
process we are able to significantly boost the certified accuracy of
$\ell_\infty$-distance nets. Our training approach largely alleviates the
optimization problem that arose in the previous training scheme, in particular,
the unexpected large Lipschitz constant due to the use of a crucial trick
called $\ell_p$-relaxation. The core of our training approach is a novel
objective function that combines scaled cross-entropy loss and clipped hinge
loss with a decaying mixing coefficient. Experiments show that using the
proposed training strategy, the certified accuracy of $\ell_\infty$-distance
net can be dramatically improved from 33.30% to 40.06% on CIFAR-10
($\epsilon=8/255$), meanwhile outperforming other approaches in this area by a
large margin. Our results clearly demonstrate the effectiveness and potential
of $\ell_\infty$-distance net for certified robustness. Codes are available at
https://github.com/zbh2047/L_inf-dist-net-v2.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1"&gt;Bohang Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1"&gt;Du Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1"&gt;Di He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"&gt;Liwei Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A General Framework for Treatment Effect Estimation in Semi-Supervised and High Dimensional Settings. (arXiv:2201.00468v1 [stat.ME])]]></title>
        <id>http://arxiv.org/abs/2201.00468</id>
        <link href="http://arxiv.org/abs/2201.00468"/>
        <updated>2022-01-05T00:39:30.026Z</updated>
        <summary type="html"><![CDATA[In this article, we aim to provide a general and complete understanding of
semi-supervised (SS) causal inference for treatment effects. Specifically, we
consider two such estimands: (a) the average treatment effect and (b) the
quantile treatment effect, as prototype cases, in an SS setting, characterized
by two available data sets: (i) a labeled data set of size $n$, providing
observations for a response and a set of high dimensional covariates, as well
as a binary treatment indicator; and (ii) an unlabeled data set of size $N$,
much larger than $n$, but without the response observed. Using these two data
sets, we develop a family of SS estimators which are ensured to be: (1) more
robust and (2) more efficient than their supervised counterparts based on the
labeled data set only. Beyond the 'standard' double robustness results (in
terms of consistency) that can be achieved by supervised methods as well, we
further establish root-n consistency and asymptotic normality of our SS
estimators whenever the propensity score in the model is correctly specified,
without requiring specific forms of the nuisance functions involved. Such an
improvement of robustness arises from the use of the massive unlabeled data, so
it is generally not attainable in a purely supervised setting. In addition, our
estimators are shown to be semi-parametrically efficient as long as all the
nuisance functions are correctly specified. Moreover, as an illustration of the
nuisance estimators, we consider inverse-probability-weighting type kernel
smoothing estimators involving unknown covariate transformation mechanisms, and
establish in high dimensional scenarios novel results on their uniform
convergence rates, which should be of independent interest. Numerical results
on both simulated and real data validate the advantage of our methods over
their supervised counterparts with respect to both robustness and efficiency.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Chakrabortty_A/0/1/0/all/0/1"&gt;Abhishek Chakrabortty&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Dai_G/0/1/0/all/0/1"&gt;Guorong Dai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Tchetgen_E/0/1/0/all/0/1"&gt;Eric Tchetgen Tchetgen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization Bounds for Noisy Iterative Algorithms Using Properties of Additive Noise Channels. (arXiv:2102.02976v3 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.02976</id>
        <link href="http://arxiv.org/abs/2102.02976"/>
        <updated>2022-01-05T00:39:30.019Z</updated>
        <summary type="html"><![CDATA[Machine learning models trained by different optimization algorithms under
different data distributions can exhibit distinct generalization behaviors. In
this paper, we analyze the generalization of models trained by noisy iterative
algorithms. We derive distribution-dependent generalization bounds by
connecting noisy iterative algorithms to additive noise channels found in
communication and information theory. Our generalization bounds shed light on
several applications, including differentially private stochastic gradient
descent (DP-SGD), federated learning, and stochastic gradient Langevin dynamics
(SGLD). We demonstrate our bounds through numerical experiments, showing that
they can help understand recent empirical observations of the generalization
phenomena of neural networks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Wang_H/0/1/0/all/0/1"&gt;Hao Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Gao_R/0/1/0/all/0/1"&gt;Rui Gao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Calmon_F/0/1/0/all/0/1"&gt;Flavio P. Calmon&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Minimum Excess Risk in Bayesian Learning. (arXiv:2012.14868v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.14868</id>
        <link href="http://arxiv.org/abs/2012.14868"/>
        <updated>2022-01-05T00:39:30.001Z</updated>
        <summary type="html"><![CDATA[We analyze the best achievable performance of Bayesian learning under
generative models by defining and upper-bounding the minimum excess risk (MER):
the gap between the minimum expected loss attainable by learning from data and
the minimum expected loss that could be achieved if the model realization were
known. The definition of MER provides a principled way to define different
notions of uncertainties in Bayesian learning, including the aleatoric
uncertainty and the minimum epistemic uncertainty. Two methods for deriving
upper bounds for the MER are presented. The first method, generally suitable
for Bayesian learning with a parametric generative model, upper-bounds the MER
by the conditional mutual information between the model parameters and the
quantity being predicted given the observed data. It allows us to quantify the
rate at which the MER decays to zero as more data becomes available. Under
realizable models, this method also relates the MER to the richness of the
generative function class, notably the VC dimension in binary classification.
The second method, particularly suitable for Bayesian learning with a
parametric predictive model, relates the MER to the minimum estimation error of
the model parameters from data. It explicitly shows how the uncertainty in
model parameter estimation translates to the MER and to the final prediction
uncertainty. We also extend the definition and analysis of MER to the setting
with multiple model families and the setting with nonparametric models. Along
the discussions we draw some comparisons between the MER in Bayesian learning
and the excess risk in frequentist learning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1"&gt;Aolin Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Raginsky_M/0/1/0/all/0/1"&gt;Maxim Raginsky&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nearly Minimax Optimal Reinforcement Learning for Discounted MDPs. (arXiv:2010.00587v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.00587</id>
        <link href="http://arxiv.org/abs/2010.00587"/>
        <updated>2022-01-05T00:39:29.994Z</updated>
        <summary type="html"><![CDATA[We study the reinforcement learning problem for discounted Markov Decision
Processes (MDPs) under the tabular setting. We propose a model-based algorithm
named UCBVI-$\gamma$, which is based on the \emph{optimism in the face of
uncertainty principle} and the Bernstein-type bonus. We show that
UCBVI-$\gamma$ achieves an $\tilde{O}\big({\sqrt{SAT}}/{(1-\gamma)^{1.5}}\big)$
regret, where $S$ is the number of states, $A$ is the number of actions,
$\gamma$ is the discount factor and $T$ is the number of steps. In addition, we
construct a class of hard MDPs and show that for any algorithm, the expected
regret is at least $\tilde{\Omega}\big({\sqrt{SAT}}/{(1-\gamma)^{1.5}}\big)$.
Our upper bound matches the minimax lower bound up to logarithmic factors,
which suggests that UCBVI-$\gamma$ is nearly minimax optimal for discounted
MDPs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1"&gt;Jiafan He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Flip Side of the Reweighted Coin: Duality of Adaptive Dropout and Regularization. (arXiv:2106.07769v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.07769</id>
        <link href="http://arxiv.org/abs/2106.07769"/>
        <updated>2022-01-05T00:39:29.988Z</updated>
        <summary type="html"><![CDATA[Among the most successful methods for sparsifying deep (neural) networks are
those that adaptively mask the network weights throughout training. By
examining this masking, or dropout, in the linear case, we uncover a duality
between such adaptive methods and regularization through the so-called
"$\eta$-trick" that casts both as iteratively reweighted optimizations. We show
that any dropout strategy that adapts to the weights in a monotonic way
corresponds to an effective subquadratic regularization penalty, and therefore
leads to sparse solutions. We obtain the effective penalties for several
popular sparsification strategies, which are remarkably similar to classical
penalties commonly used in sparse optimization. Considering variational dropout
as a case study, we demonstrate similar empirical behavior between the adaptive
dropout method and classical methods on the task of deep network
sparsification, validating our theory.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+LeJeune_D/0/1/0/all/0/1"&gt;Daniel LeJeune&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Javadi_H/0/1/0/all/0/1"&gt;Hamid Javadi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1"&gt;Richard G. Baraniuk&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users. (arXiv:2007.06823v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2007.06823</id>
        <link href="http://arxiv.org/abs/2007.06823"/>
        <updated>2022-01-05T00:39:29.977Z</updated>
        <summary type="html"><![CDATA[Modern deep learning methods constitute incredibly powerful tools to tackle a
myriad of challenging problems. However, since deep learning methods operate as
black boxes, the uncertainty associated with their predictions is often
challenging to quantify. Bayesian statistics offer a formalism to understand
and quantify the uncertainty associated with deep neural network predictions.
This tutorial provides an overview of the relevant literature and a complete
toolset to design, implement, train, use and evaluate Bayesian Neural Networks,
i.e. Stochastic Artificial Neural Networks trained using Bayesian methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jospin_L/0/1/0/all/0/1"&gt;Laurent Valentin Jospin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1"&gt;Wray Buntine&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Boussaid_F/0/1/0/all/0/1"&gt;Farid Boussaid&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Laga_H/0/1/0/all/0/1"&gt;Hamid Laga&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1"&gt;Mohammed Bennamoun&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Recover the spectrum of covariance matrix: a non-asymptotic iterative method. (arXiv:2201.00230v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2201.00230</id>
        <link href="http://arxiv.org/abs/2201.00230"/>
        <updated>2022-01-05T00:39:29.971Z</updated>
        <summary type="html"><![CDATA[It is well known the sample covariance has a consistent bias in the spectrum,
for example spectrum of Wishart matrix follows the Marchenko-Pastur law. We in
this work introduce an iterative algorithm 'Concent' that actively eliminate
this bias and recover the true spectrum for small and moderate dimensions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1"&gt;Juntao Duan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Popescu_I/0/1/0/all/0/1"&gt;Ionel Popescu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Matzinger_H/0/1/0/all/0/1"&gt;Heinrich Matzinger&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Statistical and Topological Properties of Sliced Probability Divergences. (arXiv:2003.05783v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2003.05783</id>
        <link href="http://arxiv.org/abs/2003.05783"/>
        <updated>2022-01-05T00:39:29.955Z</updated>
        <summary type="html"><![CDATA[The idea of slicing divergences has been proven to be successful when
comparing two probability measures in various machine learning applications
including generative modeling, and consists in computing the expected value of
a `base divergence' between one-dimensional random projections of the two
measures. However, the topological, statistical, and computational consequences
of this technique have not yet been well-established. In this paper, we aim at
bridging this gap and derive various theoretical properties of sliced
probability divergences. First, we show that slicing preserves the metric
axioms and the weak continuity of the divergence, implying that the sliced
divergence will share similar topological properties. We then precise the
results in the case where the base divergence belongs to the class of integral
probability metrics. On the other hand, we establish that, under mild
conditions, the sample complexity of a sliced divergence does not depend on the
problem dimension. We finally apply our general results to several base
divergences, and illustrate our theory on both synthetic and real data
experiments.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Nadjahi_K/0/1/0/all/0/1"&gt;Kimia Nadjahi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1"&gt;Alain Durmus&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Chizat_L/0/1/0/all/0/1"&gt;L&amp;#xe9;na&amp;#xef;c Chizat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Kolouri_S/0/1/0/all/0/1"&gt;Soheil Kolouri&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Shahrampour_S/0/1/0/all/0/1"&gt;Shahin Shahrampour&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1"&gt;Umut &amp;#x15e;im&amp;#x15f;ekli&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fair Data Representation for Machine Learning at the Pareto Frontier. (arXiv:2201.00292v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2201.00292</id>
        <link href="http://arxiv.org/abs/2201.00292"/>
        <updated>2022-01-05T00:39:29.948Z</updated>
        <summary type="html"><![CDATA[As machine learning powered decision making is playing an increasingly
important role in our daily lives, it is imperative to strive for fairness of
the underlying data processing and algorithms. We propose a pre-processing
algorithm for fair data representation via which L2- objective supervised
learning algorithms result in an estimation of the Pareto frontier between
prediction error and statistical disparity. In particular, the present work
applies the optimal positive definite affine transport maps to approach the
post-processing Wasserstein barycenter characterization of the optimal fair
L2-objective supervised learning via a pre-processing data deformation. We call
the resulting data Wasserstein pseudo-barycenter. Furthermore, we show that the
Wasserstein geodesics from the learning outcome marginals to the barycenter
characterizes the Pareto frontier between L2-loss and total Wasserstein
distance among learning outcome marginals. Thereby, an application of McCann
interpolation generalizes the pseudo-barycenter to a family of data
representations via which L2-objective supervised learning algorithms result in
the Pareto frontier. Numerical simulations underscore the advantages of the
proposed data representation: (1) the pre-processing step is compositive with
arbitrary L2-objective supervised learning methods and unseen data; (2) the
fair representation protects data privacy by preventing the training machine
from direct or indirect access to the sensitive information of the data; (3)
the optimal affine map results in efficient computation of fair supervised
learning on high-dimensional data; (4) experimental results shed light on the
fairness of L2-objective unsupervised learning via the proposed fair data
representation.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Xu_S/0/1/0/all/0/1"&gt;Shizhou Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Strohmer_T/0/1/0/all/0/1"&gt;Thomas Strohmer&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Latent structure blockmodels for Bayesian spectral graph clustering. (arXiv:2107.01734v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2107.01734</id>
        <link href="http://arxiv.org/abs/2107.01734"/>
        <updated>2022-01-05T00:39:29.942Z</updated>
        <summary type="html"><![CDATA[Spectral embedding of network adjacency matrices often produces node
representations living approximately around low-dimensional submanifold
structures. In particular, hidden substructure is expected to arise when the
graph is generated from a latent position model. Furthermore, the presence of
communities within the network might generate community-specific submanifold
structures in the embedding, but this is not explicitly accounted for in most
statistical models for networks. In this article, a class of models called
latent structure block models (LSBM) is proposed to address such scenarios,
allowing for graph clustering when community-specific one dimensional manifold
structure is present. LSBMs focus on a specific class of latent space model,
the random dot product graph (RDPG), and assign a latent submanifold to the
latent positions of each community. A Bayesian model for the embeddings arising
from LSBMs is discussed, and shown to have a good performance on simulated and
real world network data. The model is able to correctly recover the underlying
communities living in a one-dimensional manifold, even when the parametric form
of the underlying curves is unknown, achieving remarkable results on a variety
of real data.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Passino_F/0/1/0/all/0/1"&gt;Francesco Sanna Passino&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Heard_N/0/1/0/all/0/1"&gt;Nicholas A. Heard&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Parallel sequential Monte Carlo for stochastic gradient-free nonconvex optimization. (arXiv:1811.09469v4 [stat.CO] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1811.09469</id>
        <link href="http://arxiv.org/abs/1811.09469"/>
        <updated>2022-01-05T00:39:29.936Z</updated>
        <summary type="html"><![CDATA[We introduce and analyze a parallel sequential Monte Carlo methodology for
the numerical solution of optimization problems that involve the minimization
of a cost function that consists of the sum of many individual components. The
proposed scheme is a stochastic zeroth order optimization algorithm which
demands only the capability to evaluate small subsets of components of the cost
function. It can be depicted as a bank of samplers that generate particle
approximations of several sequences of probability measures. These measures are
constructed in such a way that they have associated probability density
functions whose global maxima coincide with the global minima of the original
cost function. The algorithm selects the best performing sampler and uses it to
approximate a global minimum of the cost function. We prove analytically that
the resulting estimator converges to a global minimum of the cost function
almost surely and provide explicit convergence rates in terms of the number of
generated Monte Carlo samples and the dimension of the search space. We show,
by way of numerical examples, that the algorithm can tackle cost functions with
multiple minima or with broad "flat" regions which are hard to minimize using
gradient-based techniques.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Akyildiz_O/0/1/0/all/0/1"&gt;&amp;#xd6;mer Deniz Akyildiz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Crisan_D/0/1/0/all/0/1"&gt;Dan Crisan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Miguez_J/0/1/0/all/0/1"&gt;Joaqu&amp;#xed;n M&amp;#xed;guez&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural network training under semidefinite constraints. (arXiv:2201.00632v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00632</id>
        <link href="http://arxiv.org/abs/2201.00632"/>
        <updated>2022-01-05T00:39:29.929Z</updated>
        <summary type="html"><![CDATA[This paper is concerned with the training of neural networks (NNs) under
semidefinite constraints. This type of training problems has recently gained
popularity since semidefinite constraints can be used to verify interesting
properties for NNs that include, e.g., the estimation of an upper bound on the
Lipschitz constant, which relates to the robustness of an NN, or the stability
of dynamic systems with NN controllers. The utilized semidefinite constraints
are based on sector constraints satisfied by the underlying activation
functions. Unfortunately, one of the biggest bottlenecks of these new results
is the required computational effort for incorporating the semidefinite
constraints into the training of NNs which is limiting their scalability to
large NNs. We address this challenge by developing interior point methods for
NN training that we implement using barrier functions for semidefinite
constraints. In order to efficiently compute the gradients of the barrier
terms, we exploit the structure of the semidefinite constraints. In
experiments, we demonstrate the superior efficiency of our training method over
previous approaches, which allows us, e.g., to use semidefinite constraints in
the training of Wasserstein generative adversarial networks, where the
discriminator must satisfy a Lipschitz condition.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pauli_P/0/1/0/all/0/1"&gt;Patricia Pauli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Funcke_N/0/1/0/all/0/1"&gt;Niklas Funcke&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gramlich_D/0/1/0/all/0/1"&gt;Dennis Gramlich&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Msalmi_M/0/1/0/all/0/1"&gt;Mohamed Amine Msalmi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Allgower_F/0/1/0/all/0/1"&gt;Frank Allg&amp;#xf6;wer&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Feature Fusion for Mitosis Counting. (arXiv:2002.03781v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2002.03781</id>
        <link href="http://arxiv.org/abs/2002.03781"/>
        <updated>2022-01-05T00:39:29.911Z</updated>
        <summary type="html"><![CDATA[Each woman living in the United States has about 1 in 8 chance of developing
invasive breast cancer. The mitotic cell count is one of the most common tests
to assess the aggressiveness or grade of breast cancer. In this prognosis,
histopathology images must be examined by a pathologist using high-resolution
microscopes to count the cells. Unfortunately, can be an exhaustive task with
poor reproducibility, especially for non-experts. Deep learning networks have
recently been adapted to medical applications which are able to automatically
localize these regions of interest. However, these region-based networks lack
the ability to take advantage of the segmentation features produced by a full
image CNN which are often used as a sole method of detection. Therefore, the
proposed method leverages Faster RCNN for object detection while fusing
segmentation features generated by a UNet with RGB image features to achieve an
F-score of 0.508 on the MITOS-ATYPIA 2014 mitosis counting challenge dataset,
outperforming state-of-the-art methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yancey_R/0/1/0/all/0/1"&gt;Robin Elizabeth Yancey&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving Actor-Critic Reinforcement Learning via Hamiltonian Monte Carlo Method. (arXiv:2103.12020v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.12020</id>
        <link href="http://arxiv.org/abs/2103.12020"/>
        <updated>2022-01-05T00:39:29.905Z</updated>
        <summary type="html"><![CDATA[The actor-critic RL is widely used in various robotic control tasks. By
viewing the actor-critic RL from the perspective of variational inference (VI),
the policy network is trained to obtain the approximate posterior of actions
given the optimality criteria. However, in practice, the actor-critic RL may
yield suboptimal policy estimates due to the amortization gap and insufficient
exploration. In this work, inspired by the previous use of Hamiltonian Monte
Carlo (HMC) in VI, we propose to integrate the policy network of actor-critic
RL with HMC, which is termed as {\it Hamiltonian Policy}. As such we propose to
evolve actions from the base policy according to HMC, and our proposed method
has many benefits. First, HMC can improve the policy distribution to better
approximate the posterior and hence reduce the amortization gap. Second, HMC
can also guide the exploration more to the regions of action spaces with higher
Q values, enhancing the exploration efficiency. Further, instead of directly
applying HMC into RL, we propose a new leapfrog operator to simulate the
Hamiltonian dynamics. Finally, in safe RL problems, we find that the proposed
method can not only improve the achieved return, but also reduce safety
constraint violations by discarding potentially unsafe actions. With
comprehensive empirical experiments on continuous control baselines, including
MuJoCo and PyBullet Roboschool, we show that the proposed approach is a
data-efficient and easy-to-implement improvement over previous actor-critic
methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1"&gt;Duo Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fekri_F/0/1/0/all/0/1"&gt;Faramarz Fekri&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Latent Gaussian Model Boosting. (arXiv:2105.08966v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.08966</id>
        <link href="http://arxiv.org/abs/2105.08966"/>
        <updated>2022-01-05T00:39:29.898Z</updated>
        <summary type="html"><![CDATA[Latent Gaussian models and boosting are widely used techniques in statistics
and machine learning. Tree-boosting shows excellent prediction accuracy on many
data sets, but potential drawbacks are that it assumes conditional independence
of samples, produces discontinuous predictions for, e.g., spatial data, and it
can have difficulty with high-cardinality categorical variables. Latent
Gaussian models, such as Gaussian process and grouped random effects models,
are flexible prior models which explicitly model dependence among samples and
which allow for efficient learning of predictor functions and for making
probabilistic predictions. However, existing latent Gaussian models usually
assume either a zero or a linear prior mean function which can be an
unrealistic assumption. This article introduces a novel approach that combines
boosting and latent Gaussian models to remedy the above-mentioned drawbacks and
to leverage the advantages of both techniques. We obtain increased prediction
accuracy compared to existing approaches in both simulated and real-world data
experiments.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sigrist_F/0/1/0/all/0/1"&gt;Fabio Sigrist&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thinking inside the box: A tutorial on grey-box Bayesian optimization. (arXiv:2201.00272v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00272</id>
        <link href="http://arxiv.org/abs/2201.00272"/>
        <updated>2022-01-05T00:39:29.892Z</updated>
        <summary type="html"><![CDATA[Bayesian optimization (BO) is a framework for global optimization of
expensive-to-evaluate objective functions. Classical BO methods assume that the
objective function is a black box. However, internal information about
objective function computation is often available. For example, when optimizing
a manufacturing line's throughput with simulation, we observe the number of
parts waiting at each workstation, in addition to the overall throughput.
Recent BO methods leverage such internal information to dramatically improve
performance. We call these "grey-box" BO methods because they treat objective
computation as partially observable and even modifiable, blending the black-box
approach with so-called "white-box" first-principles knowledge of objective
function computation. This tutorial describes these methods, focusing on BO of
composite objective functions, where one can observe and selectively evaluate
individual constituents that feed into the overall objective; and
multi-fidelity BO, where one can evaluate cheaper approximations of the
objective function by varying parameters of the evaluation oracle.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Astudillo_R/0/1/0/all/0/1"&gt;Raul Astudillo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Frazier_P/0/1/0/all/0/1"&gt;Peter I. Frazier&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep-learning-based upscaling method for geologic models via theory-guided convolutional neural network. (arXiv:2201.00698v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00698</id>
        <link href="http://arxiv.org/abs/2201.00698"/>
        <updated>2022-01-05T00:39:29.886Z</updated>
        <summary type="html"><![CDATA[Large-scale or high-resolution geologic models usually comprise a huge number
of grid blocks, which can be computationally demanding and time-consuming to
solve with numerical simulators. Therefore, it is advantageous to upscale
geologic models (e.g., hydraulic conductivity) from fine-scale (high-resolution
grids) to coarse-scale systems. Numerical upscaling methods have been proven to
be effective and robust for coarsening geologic models, but their efficiency
remains to be improved. In this work, a deep-learning-based method is proposed
to upscale the fine-scale geologic models, which can assist to improve
upscaling efficiency significantly. In the deep learning method, a deep
convolutional neural network (CNN) is trained to approximate the relationship
between the coarse grid of hydraulic conductivity fields and the hydraulic
heads, which can then be utilized to replace the numerical solvers while
solving the flow equations for each coarse block. In addition, physical laws
(e.g., governing equations and periodic boundary conditions) can also be
incorporated into the training process of the deep CNN model, which is termed
the theory-guided convolutional neural network (TgCNN). With the physical
information considered, dependence on the data volume of training the deep
learning models can be reduced greatly. Several subsurface flow cases are
introduced to test the performance of the proposed deep-learning-based
upscaling method, including 2D and 3D cases, and isotropic and anisotropic
cases. The results show that the deep learning method can provide equivalent
upscaling accuracy to the numerical method, and efficiency can be improved
significantly compared to numerical upscaling.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1"&gt;Nanzhe Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liao_Q/0/1/0/all/0/1"&gt;Qinzhuo Liao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1"&gt;Haibin Chang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1"&gt;Dongxiao Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Operator Deep Q-Learning: Zero-Shot Reward Transferring in Reinforcement Learning. (arXiv:2201.00236v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00236</id>
        <link href="http://arxiv.org/abs/2201.00236"/>
        <updated>2022-01-05T00:39:29.878Z</updated>
        <summary type="html"><![CDATA[Reinforcement learning (RL) has drawn increasing interests in recent years
due to its tremendous success in various applications. However, standard RL
algorithms can only be applied for single reward function, and cannot adapt to
an unseen reward function quickly. In this paper, we advocate a general
operator view of reinforcement learning, which enables us to directly
approximate the operator that maps from reward function to value function. The
benefit of learning the operator is that we can incorporate any new reward
function as input and attain its corresponding value function in a zero-shot
manner. To approximate this special type of operator, we design a number of
novel operator neural network architectures based on its theoretical
properties. Our design of operator networks outperform the existing methods and
the standard design of general purpose operator network, and we demonstrate the
benefit of our operator deep Q-learning framework in several tasks including
reward transferring for offline policy evaluation (OPE) and reward transferring
for offline policy optimization in a range of tasks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1"&gt;Ziyang Tang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1"&gt;Yihao Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1"&gt;Qiang Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modeling Advection on Directed Graphs using Mat\'ern Gaussian Processes for Traffic Flow. (arXiv:2201.00001v1 [math.NA])]]></title>
        <id>http://arxiv.org/abs/2201.00001</id>
        <link href="http://arxiv.org/abs/2201.00001"/>
        <updated>2022-01-05T00:39:28.413Z</updated>
        <summary type="html"><![CDATA[The transport of traffic flow can be modeled by the advection equation.
Finite difference and finite volumes methods have been used to numerically
solve this hyperbolic equation on a mesh. Advection has also been modeled
discretely on directed graphs using the graph advection operator [4, 18]. In
this paper, we first show that we can reformulate this graph advection operator
as a finite difference scheme. We then propose the Directed Graph Advection
Mat\'ern Gaussian Process (DGAMGP) model that incorporates the dynamics of this
graph advection operator into the kernel of a trainable Mat\'ern Gaussian
Process to effectively model traffic flow and its uncertainty as an advective
process on a directed graph.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Maddix_D/0/1/0/all/0/1"&gt;Danielle C Maddix&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Saad_N/0/1/0/all/0/1"&gt;Nadim Saad&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yuyang Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Representations for Covariate Shift. (arXiv:2201.00057v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2201.00057</id>
        <link href="http://arxiv.org/abs/2201.00057"/>
        <updated>2022-01-05T00:39:28.406Z</updated>
        <summary type="html"><![CDATA[Machine learning systems often experience a distribution shift between
training and testing. In this paper, we introduce a simple variational
objective whose optima are exactly the set of all representations on which risk
minimizers are guaranteed to be robust to any distribution shift that preserves
the Bayes predictor, e.g., covariate shifts. Our objective has two components.
First, a representation must remain discriminative for the task, i.e., some
predictor must be able to simultaneously minimize the source and target risk.
Second, the representation's marginal support needs to be the same across
source and target. We make this practical by designing self-supervised learning
methods that only use unlabelled data and augmentations to train robust
representations. Our objectives achieve state-of-the-art results on DomainBed,
and give insights into the robustness of recent methods, such as CLIP.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ruan_Y/0/1/0/all/0/1"&gt;Yangjun Ruan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dubois_Y/0/1/0/all/0/1"&gt;Yann Dubois&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1"&gt;Chris J. Maddison&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] ray-skorch - distributed PyTorch on Ray with sklearn API]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rw8jxd/p_rayskorch_distributed_pytorch_on_ray_with/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rw8jxd/p_rayskorch_distributed_pytorch_on_ray_with/"/>
        <updated>2022-01-04T23:59:25.000Z</updated>
        <summary type="html"><![CDATA[tl;dr: train PyTorch models on large tabular datasets with a scikit-learn (skorch) API
 Hi r/MachineLearning,
 I'm the principal author of ray-skorch, a library that lets you run distributed PyTorch training on large-scale datasets while providing a familiar, scikit-learn compatible skorch API, integrating well with the rest of the scikit-learn ecosystem.
 Under the hood, ray-skorch uses Ray Train for distributed PyTorch training and Ray Data for handling and shuffling large datasets.
 ray-skorch works only with tabular data. Currently, it can use numpy arrays, pandas dataframes and Ray Data Datasets.
 pip install ray-skorch
 You can switch your skorch code to ray-skorch just by changing a few lines:
 import numpy as np from sklearn.datasets import make_classification from torch import nn # pip install pytorch_tabnet from pytorch_tabnet.tab_network import TabNet from ray_skorch import RayTrainNeuralNet X, y = make_classification(1000, 20, n_informative=10, random_state=0) X = X.astype(np.float32) y = y.astype(np.int64) net = RayTrainNeuralNet( TabNet, num_workers=2, # the only new mandatory argument criterion=nn.CrossEntropyLoss, max_epochs=10, lr=0.1, # TabNet specific arguments module__input_dim=20, module__output_dim=2, # required for classification loss funcs iterator_train__unsqueeze_label_tensor=False, iterator_valid__unsqueeze_label_tensor=False, ) net.fit(X, y) # predict_proba returns a ray.data.Dataset y_proba = net.predict_proba(X).to_pandas() 
 More examples, including ones on bigger datasets, can be found here - https://github.com/Yard1/ray-skorch/tree/main/examples
 The package is experimental, and Id love to hear your feedback - both on the package itself and on the concept of distributed training on tabular data with simple, familiar APIs. Any comments, suggestions or bug reports are hugely appreciated!
    submitted by    /u/Yard1PL  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Stargate sequence from Stanley Kubrick's 2001: A Space Odyssey, remade using AI, in the style of visionary artist Alex Grey.]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rw7vcw/the_stargate_sequence_from_stanley_kubricks_2001/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rw7vcw/the_stargate_sequence_from_stanley_kubricks_2001/"/>
        <updated>2022-01-04T23:26:02.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/glenniszen  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Training with multiple agents.]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rw7dpf/training_with_multiple_agents/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rw7dpf/training_with_multiple_agents/"/>
        <updated>2022-01-04T23:03:33.000Z</updated>
        <summary type="html"><![CDATA[Does anyone know if any of the open source RL libraries support multi-agent training in which agents can have different actions spaces?
    submitted by    /u/YearPersonal5709  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Deep Learning is the future of gaming.]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rw50hg/d_deep_learning_is_the_future_of_gaming/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rw50hg/d_deep_learning_is_the_future_of_gaming/"/>
        <updated>2022-01-04T21:18:30.000Z</updated>
        <summary type="html"><![CDATA[Hey everybody --- I know this isn't hard core AI research but I have been thinking a lot about deep learning and gaming recently and put together a little presentation on how I see things unfolding. Lots of cool research featured in the video.
 https://www.youtube.com/watch?v=JDL8rZzYVwQ
 I go over:
  
Photorealistic neural rendering
 Deepfakes for gaming (https://www.youtube.com/watch?v=RR7u11ANDWE is a better example than the obama one I used)
 GAN theft auto and dreaming up game engines with neural networks
 Large language models for building realistic NPCs and storytelling
 Using OpenAI Codex to automatically program games.
  
It's really clear that deep learning is the most important technology to impact gaming since the advent of 3D graphics. Would love to talk with anybody who is working on stuff in this space.
    submitted by    /u/sabalaba  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Good Object-recognition pre-trained models]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rw4tfx/good_objectrecognition_pretrained_models/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rw4tfx/good_objectrecognition_pretrained_models/"/>
        <updated>2022-01-04T21:10:00.000Z</updated>
        <summary type="html"><![CDATA[I used yolov5 for object recognition and it does a fair job, but it also sees my hand as a bird in a lot of situations and leaves a lot to be desired. I know if they're driving off of similar computer vision models, there's gotta be a better one out there for detecting objects.
 PS I've been using pytorch for this so if you find a good model please also drop a link on how to get it up and running if you have it.
    submitted by    /u/acraber  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Take advantage of advanced deployment strategies using Amazon SageMaker deployment guardrails]]></title>
        <id>f4ffa85e5d7f589e9c9df6e2fe62e7dddb6842c3</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/take-advantage-of-advanced-deployment-strategies-using-amazon-sagemaker-deployment-guardrails/"/>
        <updated>2022-01-04T20:43:55.000Z</updated>
        <summary type="html"><![CDATA[Deployment guardrails in Amazon SageMaker provide a new set of deployment capabilities allowing you to implement advanced deployment strategies that minimize risk when deploying new model versions on SageMaker hosting. Depending on your use case, you can use a variety of deployment strategies to release new model versions. Each of these strategies relies on a []]]></summary>
        <author>
            <name>Raghu Ramesha</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I gave it the gameplay section of the Geometry Dash wikipedia article, this is what I got]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rw3njq/i_gave_it_the_gameplay_section_of_the_geometry/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rw3njq/i_gave_it_the_gameplay_section_of_the_geometry/"/>
        <updated>2022-01-04T20:18:40.000Z</updated>
        <summary type="html"><![CDATA[Geometry Dash features an hourglass timer with three sections in the shape of circles and triangles. The timer starts in the upper left corner of the in-game map and ends when it falls into the lower right corner, allowing players to use up their time. When it falls to the bottom center of the map, a demon car appears and must be navigated. The demon is a curved ramp for the player's icon, and every time the player's icon touches a portion of the demon, its ramp is altered. Also, the demon's top speed increases by 7x every time the player touches the bottom center. If the player touches the edge of the demon, then the demon will fall, taking a 5x amount of coins from the player's meter. At the end of the level, the demon car drops into a pit.[5]
    submitted by    /u/Alternative-Ad-3041  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Style Transfer with Noise Vector]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rw2uac/d_style_transfer_with_noise_vector/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rw2uac/d_style_transfer_with_noise_vector/"/>
        <updated>2022-01-04T19:43:09.000Z</updated>
        <summary type="html"><![CDATA[Hi everyone, I'm looking for a model which can perform style transfer, but also takes an auxiliary noise vector similar to that for StyleGAN to generate many stylized images for a single input image. Is anyone aware of any model meeting these requirements? My best idea so far is to first embed the image into the StyleGAN latent space with this paper, and then add noise to that vector.
    submitted by    /u/Sebass13  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Train graph neural nets for millions of proteins on Amazon SageMaker and Amazon DocumentDB (with MongoDB compatibility)]]></title>
        <id>a821bb05fde90c047b723f7476b9e6ee8a5f4267</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/train-graph-neural-nets-for-millions-of-proteins-on-amazon-sagemaker-and-amazon-documentdb-with-mongodb-compatibility/"/>
        <updated>2022-01-04T18:48:58.000Z</updated>
        <summary type="html"><![CDATA[There are over 180,000 unique proteins with 3D structures determined, with tens of thousands new structures resolved every year. This is only a small fraction of the 200 million known proteins with distinctive sequences. Recent deep learning algorithms such as AlphaFold can accurately predict 3D structures of proteins using their sequences, which help scale the []]]></summary>
        <author>
            <name>Zichen Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meet the 2021-22 Accenture Fellows]]></title>
        <id>https://news.mit.edu/2022/meet-2021-22-accenture-fellows-0104</id>
        <link href="https://news.mit.edu/2022/meet-2021-22-accenture-fellows-0104"/>
        <updated>2022-01-04T18:40:00.000Z</updated>
        <summary type="html"><![CDATA[The 2021-22 Accenture Fellows are bolstering research and igniting ideas to help transform global business.]]></summary>
        <author>
            <name>Emma Foehringer Merchant | School of Engineering</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DSC Weekly Digest 28 December 2021: An Auld Lang Syne (and Cosyne Too)]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087093</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087093"/>
        <updated>2022-01-04T18:30:00.000Z</updated>
        <summary type="html"><![CDATA[<div class="dsc_primaryImage"><span style="font-family: arial, helvetica, sans-serif;"><a href="https://www.datasciencecentral.com/profiles/blog/list?tag=dsc_newsletter" rel="noopener" target="_blank"><img class="align-full" src="https://multimedia.getresponse360.com/datascience-B/photos/4ee6c094-435c-447f-b0b5-a0ec4f4c769a.jpg?profile=RESIZE_710x" width="720"></img></a></span></div>
<table style="width: 726px;">
<tbody><tr><td><div><p dir="ltr">The last week of the year has traditionally been about reflections and planning, taking stock of the old (or auld), and preparing for the changes of the new. I've added my own thoughts about what 2022 will</p>
</div>
</td>
</tr>
</tbody>
</table>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EndlessVN open alpha in march 2022]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rw0pb8/endlessvn_open_alpha_in_march_2022/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rw0pb8/endlessvn_open_alpha_in_march_2022/"/>
        <updated>2022-01-04T18:09:52.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/roblox22y  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Difference between cooperative games and stochastic games]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rw0l8j/difference_between_cooperative_games_and/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rw0l8j/difference_between_cooperative_games_and/"/>
        <updated>2022-01-04T18:04:55.000Z</updated>
        <summary type="html"><![CDATA[Some say that cooperative games are a subset of stochastic games. But I don't find how. In cooperative games, all the agents have a team reward and have different states whereas in stochastic games, all the agents receives individual reward and they have the same state in a particular time step. Can someone help me understand the difference between these two games?
    submitted by    /u/j0ker_70  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Interpolation, Extrapolation and Linearisation (Prof. Yann LeCun, Dr. Randall Balestriero)]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvzhnh/d_interpolation_extrapolation_and_linearisation/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvzhnh/d_interpolation_extrapolation_and_linearisation/"/>
        <updated>2022-01-04T17:17:46.000Z</updated>
        <summary type="html"><![CDATA[Special machine learning street talk episode! Yann LeCun thinks that it's specious to say neural network models are interpolating because in high dimensions, everything is extrapolation. Recently Dr. Randall Balestriero, Dr. Jerome Pesente and prof. Yann LeCun released their paper learning in high dimensions always amounts to extrapolation. This discussion has completely changed how we think about neural networks and their behaviour. 
 In the intro we talk about the spline theory of NNs, interpolation in NNs and the curse of dimensionality. 
 YT: https://youtu.be/86ib0sfdFtw
 Pod: https://anchor.fm/machinelearningstreettalk/episodes/061-Interpolation--Extrapolation-and-Linearisation-Prof--Yann-LeCun--Dr--Randall-Balestriero-e1cgdr0
 References: 
 Learning in High Dimension Always Amounts to Extrapolation [Randall Balestriero, Jerome Pesenti, Yann LeCun]
 https://arxiv.org/abs/2110.09485 
 A Spline Theory of Deep Learning [Dr. Balestriero, baraniuk] https://proceedings.mlr.press/v80/balestriero18b.html 
 Neural Decision Trees [Dr. Balestriero]
 https://arxiv.org/pdf/1702.07360.pdf 
 Interpolation of Sparse High-Dimensional Data [Dr. Thomas Lux] https://tchlux.github.io/papers/tchlux-2020-NUMA.pdf
    submitted by    /u/timscarfe  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Neural Networks using a generic GPU framework]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvz50d/d_neural_networks_using_a_generic_gpu_framework/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvz50d/d_neural_networks_using_a_generic_gpu_framework/"/>
        <updated>2022-01-04T17:02:38.000Z</updated>
        <summary type="html"><![CDATA[I have a (personal) ML project that uses CNNs but I have two little problems: 1. not everyone has a NVidia GPU at home (myself included, sadly); 2. The CNN needs to be trained every time it is used (it's photo to photo style transfer).
 So, what would be a good framework to implement the CNN for training (targeting desktop only)? I thought about using OpenGL, but I don't know if using GLSL shaders would be a good fit for it.
    submitted by    /u/crimsom_king  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NVIDIA Builds Isaac AMR Platform to Aid $9 Trillion Logistics Industry]]></title>
        <id>https://blogs.nvidia.com/?p=54794</id>
        <link href="https://blogs.nvidia.com/blog/2022/01/04/isaac-amr-platform/"/>
        <updated>2022-01-04T17:00:40.000Z</updated>
        <summary type="html"><![CDATA[Manufacturing and fulfillment centers are profoundly complex. Whenever new earbuds or socks land at your doorstep in hours or a vehicle rolls off an assembly line, a maze of magic happens with AI-driven logistics. Massive facilities like these are constantly in flux. Robots travel miles of aisles to roll up millions of products to assist Read article >
The post NVIDIA Builds Isaac AMR Platform to Aid $9 Trillion Logistics Industry appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Shri Sundaram</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gamers, Creators, Drivers Feel GeForce RTX, NVIDIA AI Everywhere]]></title>
        <id>https://blogs.nvidia.com/?p=54745</id>
        <link href="https://blogs.nvidia.com/blog/2022/01/04/ces-rtx-3080ti-laptops-gfn-att-tusimple/"/>
        <updated>2022-01-04T17:00:11.000Z</updated>
        <summary type="html"><![CDATA[Putting the power of graphics and AI at the fingertips of more users than ever, NVIDIA announced today new laptops and autonomous vehicles using GeForce RTX and NVIDIA AI platforms and expanded reach for GeForce NOW cloud gaming across Samsung TVs and the AT&T network. A virtual address prior to CES showed next-gen games, new Read article >
The post Gamers, Creators, Drivers Feel GeForce RTX, NVIDIA AI Everywhere appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Rick Merritt</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NVIDIA Canvas Updated With New AI Model Delivering 4x Resolution and More Materials]]></title>
        <id>https://blogs.nvidia.com/?p=54854</id>
        <link href="https://blogs.nvidia.com/blog/2022/01/04/studio-canvas-update-gaugan2-ces/"/>
        <updated>2022-01-04T16:53:33.000Z</updated>
        <summary type="html"><![CDATA[As art evolves and artists abilities grow, so must their creative tools. NVIDIA Canvas, the free beta app and part of the NVIDIA Studio suite of creative apps and tools, has brought the real-time painting tool GauGAN to anyone with an NVIDIA RTX GPU. Artists use advanced AI to quickly turn simple brushstrokes into realistic Read article >
The post NVIDIA Canvas Updated With New AI Model Delivering 4x Resolution and More Materials appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Stanley Tack</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Groundbreaking Updates to NVIDIA Studio Power the 3D Virtual Worlds of Tomorrow, Today]]></title>
        <id>https://blogs.nvidia.com/?p=54838</id>
        <link href="https://blogs.nvidia.com/blog/2022/01/04/studio-laptops-omniverse-canvas/"/>
        <updated>2022-01-04T16:53:27.000Z</updated>
        <summary type="html"><![CDATA[Were at the dawn of the next digital frontier. Creativity is fueling new developments in design, innovation and virtual worlds. For the creators driving this future, weve built NVIDIA Studio, a fully accelerated platform with high-performance GPUs as the heartbeat for laptops and desktops. This hardware is paired with exclusive NVIDIA RTX-accelerated software optimizations in Read article >
The post Groundbreaking Updates to NVIDIA Studio Power the 3D Virtual Worlds of Tomorrow, Today appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Stanley Tack</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NVIDIA Makes Free Version of Omniverse Available to Millions of Individual Creators and Artists Worldwide]]></title>
        <id>https://blogs.nvidia.com/?p=54731</id>
        <link href="https://blogs.nvidia.com/blog/2022/01/04/omniverse-available-free-to-creators/"/>
        <updated>2022-01-04T16:53:05.000Z</updated>
        <summary type="html"><![CDATA[Designed to be the foundation that connects virtual worlds, NVIDIA Omniverse is now available to millions of individual NVIDIA Studio creators using GeForce RTX and NVIDIA RTX GPUs. In a special address at CES, NVIDIA also announced new platform developments for Omniverse Machinima and Omniverse Audio2Face, new platform features like Nucleus Cloud and 3D marketplaces, Read article >
The post NVIDIA Makes Free Version of Omniverse Available to Millions of Individual Creators and Artists Worldwide appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Richard Kerris</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Autonomous Era Arrives at CES 2022 With NVIDIA DRIVE Hyperion and Omniverse Avatar]]></title>
        <id>https://blogs.nvidia.com/?p=54754</id>
        <link href="https://blogs.nvidia.com/blog/2022/01/04/autonomous-era-ces-2022-drive-hyperion/"/>
        <updated>2022-01-04T16:52:57.000Z</updated>
        <summary type="html"><![CDATA[CES has long been a showcase on whats coming down the technology pipeline. This year, NVIDIA is showing the radical innovation happening now. During a special virtual address at the show, Ali Kani, vice president and general manager of Automotive at NVIDIA, detailed the capabilities of DRIVE Hyperion and the many ways the industry is Read article >
The post Autonomous Era Arrives at CES 2022 With NVIDIA DRIVE Hyperion and Omniverse Avatar appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Danny Shapiro</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GeForce NOW Delivers Legendary GeForce Gaming With More Games on More Networks to More Devices]]></title>
        <id>https://blogs.nvidia.com/?p=54785</id>
        <link href="https://blogs.nvidia.com/blog/2022/01/04/geforce-now-ea-att-samsung-ces/"/>
        <updated>2022-01-04T16:52:33.000Z</updated>
        <summary type="html"><![CDATA[GeForce NOW is kicking off the new year by bringing more games, more devices and more networks to our cloud gaming ecosystem. The next pair of Electronic Arts games, Battlefield 4 and Battlefield V, is streaming on GeForce NOW. Were also working closely with a few titans in their respective industries: AT&T and Samsung. AT&T Read article >
The post GeForce NOW Delivers Legendary GeForce Gaming With More Games on More Networks to More Devices appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Phil Eisler</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] What are interviews usually like for ML positions?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvyuhb/d_what_are_interviews_usually_like_for_ml/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvyuhb/d_what_are_interviews_usually_like_for_ml/"/>
        <updated>2022-01-04T16:50:10.000Z</updated>
        <summary type="html"><![CDATA[For context, I'm applying for PhD level positions. Should I expect technical interviews including coding challenges similar to SWE?
 Any advice on prepping?
    submitted by    /u/_Dark_Forest  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding "Stochastic Value Gradients (SVG)"]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rvyiix/understanding_stochastic_value_gradients_svg/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rvyiix/understanding_stochastic_value_gradients_svg/"/>
        <updated>2022-01-04T16:35:07.000Z</updated>
        <summary type="html"><![CDATA[Hi, I have a hard time understanding the paper "Learning Continuous Control Policies by Stochastic Value Gradients" (https://arxiv.org/pdf/1510.09142.pdf). 
 So, in my understanding is that the stochastic value gradient could be computed easily on imagined ("planned") data, where we rollout the policy in the learned world model. However, this seems undesirable due to compounding model errors. So far, so good.
 The above issue is fixed when we use real environment samples, although the noise variables  and  required to calculate the stochastic value gradient are then unknown. The paper then applies the Bayes rule to reformulate the stochastic value gradient to a tractable formulation.
 My issue: to compute the stochastic value gradient, the noise variables must be inferred. On this issue, the paper simply states "... infer the missing noise variables, possibly by sampling from p(,|s, a, s)". How can we sample these noise variables? How can we infer the noise variables?
 Any help would be greatly appreciated!
    submitted by    /u/Internal-Brush4929  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is there a AI which is able to edit images to make them look drawn?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rvy4i3/is_there_a_ai_which_is_able_to_edit_images_to/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rvy4i3/is_there_a_ai_which_is_able_to_edit_images_to/"/>
        <updated>2022-01-04T16:18:41.000Z</updated>
        <summary type="html"><![CDATA[With small mistakes, and only some different colors?
    submitted by    /u/xXLisa28Xx  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Training Data]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rvxb9k/training_data/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rvxb9k/training_data/"/>
        <updated>2022-01-04T15:43:28.000Z</updated>
        <summary type="html"><![CDATA[Hi,
 i'm pretty new to this kind of learning task and i found hard to understand some base concepts. I'm studying the Decision Transformer paper and for an university problem i need to train that model using the MiniWorld environment.
 While i was looking at the code that is provided by the author of MiniWorld i got a question. How i get training data? 
 The authors of Decision Transformer uses d4rl that provide some offline dataset. How can create training data in a similar way using my environment?
    submitted by    /u/maverik75  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BadA$$ Kittays - Generated with Cyborg Love]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rvx5dz/bada_kittays_generated_with_cyborg_love/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rvx5dz/bada_kittays_generated_with_cyborg_love/"/>
        <updated>2022-01-04T15:36:23.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/NeurogenicArtist  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] A Neural Network Solves, Grades & Generates University-Level Mathematics Problems by Program Synthesis]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rvx26y/r_a_neural_network_solves_grades_generates/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rvx26y/r_a_neural_network_solves_grades_generates/"/>
        <updated>2022-01-04T15:32:20.000Z</updated>
        <summary type="html"><![CDATA[In the new paper A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More, a research team from MIT, Columbia University, Harvard University and University of Waterloo proposes a neural network that can solve university-level mathematics problems via program synthesis. 
 Here is a quick read: A Neural Network Solves, Grades & Generates University-Level Mathematics Problems by Program Synthesis.
 The paper A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More is on arXiv.
    submitted by    /u/Yuqing7  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvwehk/deep_learning_interviews_hundreds_of_fully_solved/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvwehk/deep_learning_interviews_hundreds_of_fully_solved/"/>
        <updated>2022-01-04T15:04:16.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/pit_station  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[N] Launching DagsHub 2.0  Git-integrated data labeling and smart ML discussions]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvw0rv/n_launching_dagshub_20_gitintegrated_data/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvw0rv/n_launching_dagshub_20_gitintegrated_data/"/>
        <updated>2022-01-04T14:46:59.000Z</updated>
        <summary type="html"><![CDATA[TL;DR  DagsHub is integrated with Label Studio, and you can now open datasets from Git and DVC remotes, label them and commit labels back, without doing any DevOps. You can also comment on labels, bounding boxes, or any file. Check out the example project, or try out the tutorial.
 Comparing annotations
 Hi r/ML! I'm one of the creators of DagsHub (https://www.dagshub.com). We help ML practitioners create a central repository for their projects, where they can leverage open-source tools to version datasets and models, track experiments, and starting today  label data, and comment on anything. Like GitHub for machine learning (you probably heard that before, but we mean it).
 Our vision is that anyone could jump into an open-source data science project and contribute code, data, labeling,]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Why is VAE used instead of AutoEncoder in the World Models paper (https://arxiv.org/pdf/1803.10122.pdf)?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvvfoa/d_why_is_vae_used_instead_of_autoencoder_in_the/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvvfoa/d_why_is_vae_used_instead_of_autoencoder_in_the/"/>
        <updated>2022-01-04T14:19:29.000Z</updated>
        <summary type="html"><![CDATA[Hi All,
 I was just reading this paper and was wondering if we just want to achieve a compact version of the original representation we could just use a traditional AutoEncoder. Is there any specific reason the VAE is used?
 Thanks!
    submitted by    /u/StageTraditional636  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Anyone using RL for Trading stocks?]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rvushn/anyone_using_rl_for_trading_stocks/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rvushn/anyone_using_rl_for_trading_stocks/"/>
        <updated>2022-01-04T13:48:47.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/GarantBM  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why a Data Science Career Is Worth Pursuing]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087157</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087157"/>
        <updated>2022-01-04T12:00:00.000Z</updated>
        <summary type="html"><![CDATA[<div><a href="https://storage.ning.com/topology/rest/1.0/file/get/9982440260?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9982440260?profile=RESIZE_710x" width="720"></img></a></div>
<blockquote><p style="text-align: left;"></p>
<p>There were five exabytes of information created between the dawn of civilization through 2003, but that much information is now created every two days.</p>
</blockquote>
<p>~Eric Schmidt (Executive Chairman at Google)</p>
<p>The term<a href="https://www.dasca.org/">data science</a>was first</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Top AI Trends of 2022]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rvsci0/top_ai_trends_of_2022/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rvsci0/top_ai_trends_of_2022/"/>
        <updated>2022-01-04T11:33:15.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/Beautiful-Credit-868  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Top Social Media Content Moderation Trends that Will Reign Supreme in 2022]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087084</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087084"/>
        <updated>2022-01-04T11:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9982542074?profile=original" rel="noopener" target="_blank"><font size="4"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9982542074?profile=RESIZE_710x" width="720"></img></font></a></p>
<p><font size="4">The technique of managing desired information from online platforms such as social media networking sites is known as <b>content</b> <b>moderation</b>. It's also known as <b>social moderation</b>, and it's used to control various forms of content that aren't appropriate for a general audience.</font></p>
<p></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] Play against an AI to detect fake audio]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvqr95/r_play_against_an_ai_to_detect_fake_audio/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvqr95/r_play_against_an_ai_to_detect_fake_audio/"/>
        <updated>2022-01-04T09:51:57.000Z</updated>
        <summary type="html"><![CDATA[Hi everybody,
 i'm a PhD student interested in audio spoofs (voice recordings faked with the help of AI), and have developed an online game: You play against an artificial intelligence and try to distinguish spoofed from real audio recordings.
 It's fun, and very much supports my research. All partificpation (i.e. playing the game), comments or suggestions are welcome!
 https://deepfake-demo.aisec.fraunhofer.de/
    submitted by    /u/mummni  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to make gym a parallel environment?]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rvq1yt/how_to_make_gym_a_parallel_environment/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rvq1yt/how_to_make_gym_a_parallel_environment/"/>
        <updated>2022-01-04T09:01:56.000Z</updated>
        <summary type="html"><![CDATA[I'm run gym environment CartPole-v0, but my GPU usage is low. I get a resolution that I can use N same policy Networks to get actions for N envs.
 I tried agymc, but it can't satisfy my need. Because it can only copy the envs, and cannot use N Networks.
 neural.py (github.com)
 So I write a code as above, but I get this error as below, how can I repair the bug:
 Exception in thread Thread-7:
 File "C:\Users\afuler\AppData\Local\Programs\Python\Python39\lib\threading.py", line 973, in _bootstrap_inner
 self.run()
 File "C:\Users\afuler\AppData\Local\Programs\Python\Python39\lib\threading.py", line 910, in run
 self._target(*self._args, **self._kwargs)
 File "d:\workspace\rl\nonnueral\nonnueralrl.py", line 271, in predict
 envList[worker_num].render()
 File "C:\Users\afuler\AppData\Local\Pro]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] What are the reviewers' score of the submissions nominated for best paper award in top ML conferences such as NeurIPS, ICML, AISTATS, etc.?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvol2l/d_what_are_the_reviewers_score_of_the_submissions/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvol2l/d_what_are_the_reviewers_score_of_the_submissions/"/>
        <updated>2022-01-04T07:21:23.000Z</updated>
        <summary type="html"><![CDATA[I submitted a paper to AISTATS 2022 that can be a breakthrough with outstanding contributions. The paper received 876 scores from reviewers that could only improve to 877 after the rebuttals. What are the chances that our submission enters the short list for best paper recognition? What are the average reviewers' score of the ones getting nominated in these top conferences?
    submitted by    /u/Cyrus_the-great  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Could we Live in a Universe with Fewer than Three Dimensions?]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087061</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087061"/>
        <updated>2022-01-04T06:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9979868266?profile=original" rel="noopener" target="_blank"><img class="align-center" src="https://storage.ning.com/topology/rest/1.0/file/get/9979868266?profile=RESIZE_710x" width="600"></img></a></p>
<p>No, I am not a flat-earther. Quite the contrary, the ideas suggested here assume advanced scientific knowledge, such as quantum physics. The famous Cambridge-based physicist Stephen Hawking suggested that we may live in a universe with 11 dimensions. What I discuss here is not conflicting with that statement, as we shall see.</p>
<p>It all started</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data science and analytics: the future implications]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086868</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086868"/>
        <updated>2022-01-04T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9979780878?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9979780878?profile=RESIZE_710x" width="720"></img></a></p>
<p>Data science is a domain that combines data-bound analytical techniques and scientific theory to generate insights for business stakeholders. Its shape, elements, and size allow organizations to optimize operations, identify new business opportunities, and reduce the functional performance of departments such as marketing and sales.</p>
<p>Simply put,</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D]who knows the paper address of the code?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvn3vp/dwho_knows_the_paper_address_of_the_code/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvn3vp/dwho_knows_the_paper_address_of_the_code/"/>
        <updated>2022-01-04T05:53:22.000Z</updated>
        <summary type="html"><![CDATA[https://github.com/yuzisheng/trajectory-compress
 especially the Spatio-Temporal Curvature Streaming
    submitted by    /u/choayue  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] Sieve: We processed ~24 hours of security footage in <10 mins (now semantically searchable per-frame!)]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvn3dh/p_sieve_we_processed_24_hours_of_security_footage/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvn3dh/p_sieve_we_processed_24_hours_of_security_footage/"/>
        <updated>2022-01-04T05:52:33.000Z</updated>
        <summary type="html"><![CDATA[Hey everyone! Im one of the creators of Sieve, and Im excited to be sharing it!
 Sieve is an API that helps you store, process, and automatically search your video datainstantly and efficiently. Just think 10 cameras recording footage at 30 FPS, 24/7. That would be 27 million frames generated in a single day. The videos might be searchable by timestamp, but finding moments of interest is like searching for a needle in a haystack.
 We built this visual demo (link here) a little while back which wed love to get feedback on. Its ~24 hours of security footage that our API processed in <10 mins and has simple querying and export functionality enabled. We see applications in better understanding what data you have, figuring out which data to send to labeling, sampling datasets for training, and building multiple test sets for models by scenario.
 To try it on your videos: https://github.com/Sieve-Data/automatic-video-processing
 Visual dashboard walkthrough: https://youtu.be/_uyjp_HGZl4
 https://preview.redd.it/bn8hoqoa1m981.png?width=2540&format=png&auto=webp&s=25fb08037438593291fecf7e50ca58ec1f9bea72
 https://preview.redd.it/jwkd7uoa1m981.png?width=2540&format=png&auto=webp&s=e25382b4b09855e5934608754a8b74bdbaf93204
 https://preview.redd.it/0dd74toa1m981.png?width=2540&format=png&auto=webp&s=05b7625195947b8f15891a9019070efa3730b336
 https://preview.redd.it/alg4ruoa1m981.png?width=2540&format=png&auto=webp&s=f5caad143b0d23f3add08f431d0ada322ae4e84d
 https://preview.redd.it/8c2pw0pa1m981.png?width=2540&format=png&auto=webp&s=e6438f03e3fc7a00ccdf01c9b7075b9e8752affd
    submitted by    /u/happybirthday290  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I put the word 'death' in a text to image AI and this is what I got...]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rvn18c/i_put_the_word_death_in_a_text_to_image_ai_and/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rvn18c/i_put_the_word_death_in_a_text_to_image_ai_and/"/>
        <updated>2022-01-04T05:49:15.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/smartpug967  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Paper Summary [Rethinking Segmentation from a Sequence-to-Sequence Perspective with Transfromers]]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvmiyr/d_paper_summary_rethinking_segmentation_from_a/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvmiyr/d_paper_summary_rethinking_segmentation_from_a/"/>
        <updated>2022-01-04T05:20:56.000Z</updated>
        <summary type="html"><![CDATA[Hi, I have just published my latest medium article. It is a summary of a scientific paper that aims to eliminate the effect of locality which is one of the limitations of CNNs. In this attempt, researchers tried to reform the image semantic segmentation problem then operate a proposed transformer, and finally, introduce three different decoder architectures.
 Please read it and give me your feedback. If you find it interesting, you can share it with others who are interested in ML as well. Also, if you find it helpful, you can follow me on medium to be updated on my forthcoming articles.
 https://rezayazdanfar.medium.com/26868efacc52
    submitted by    /u/rezayazdanfar  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Which tools can be helpful for annotation of videos for action recognition?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvmeo6/d_which_tools_can_be_helpful_for_annotation_of/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvmeo6/d_which_tools_can_be_helpful_for_annotation_of/"/>
        <updated>2022-01-04T05:14:15.000Z</updated>
        <summary type="html"><![CDATA[There is a team in my university who work on ergonomics. They want to do action recognition on some videos. They approached me for help. I work on images. I don't have idea about videos. I have dataset. I want to annotate key points in each frame. Please tell me which tools can be helpful for annotation of videos?
    submitted by    /u/SAbdusSamad  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Researchers Propose A Novel Parameter Differentiation-Based Method That Can Automatically Determine Which Parameters Should Be Shared And Which Ones Should Be Language-Specific]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rvkzcf/researchers_propose_a_novel_parameter/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rvkzcf/researchers_propose_a_novel_parameter/"/>
        <updated>2022-01-04T03:58:50.000Z</updated>
        <summary type="html"><![CDATA[In recent years, neural machine translation (NMT) has attracted a lot of attention and has had a lot of success. While traditional NMT is capable of translating a single language pair, training a separate model for each language pair is time-consuming, especially given the worlds thousands of languages. As a result, multilingual NMT is designed to handle many language pairs in a single model, lowering the cost of offline training and online deployment significantly. Furthermore, parameter sharing in multilingual neural machine translation promotes positive knowledge transfer between languages and is advantageous for low-resource translation.
 Despite the advantages of cooperative training with a completely shared model, the MNMT approach has a model capacity problem. The shared parameters are more likely to preserve broad knowledge while ignoring language-specific knowledge. To improve the model capacity, researchers use heuristic design to create extra language-specific components and build a Multilingual neural machine translation (MNMT) model with a mix of shared and language-specific characteristics, such as the language-specific attention, lightweight language adaptor, or language-specific routing layer. Continue Reading
 Paper: https://arxiv.org/pdf/2112.13619v1.pdf
 Github: https://github.com/voidmagic/parameter-differentiation
    submitted by    /u/ai-lover  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PPO convergence when moving to continuous action space]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rvhvr3/ppo_convergence_when_moving_to_continuous_action/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rvhvr3/ppo_convergence_when_moving_to_continuous_action/"/>
        <updated>2022-01-04T01:29:38.000Z</updated>
        <summary type="html"><![CDATA[Hello :D,
 I had a PPO implementation with convolutional neural networks that worked just fine with discrete action space (environment is a grid world where an agent has 4 possible actions=directions). I took the same implementation and switched to continuous action space (2 actions = force over x and y axis). The model does pretty well in the first 7mil steps (reward converges), but then the reward suddenly goes down. 
 Any idea what could be the reason? could it be the decaying variance I am using for the continuous action selection?
    submitted by    /u/AhmedNizam_  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Identity verification using Amazon Rekognition]]></title>
        <id>a39bc768d7da4b8131f197a938afd616a8a7ee5e</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/identity-verification-using-amazon-rekognition/"/>
        <updated>2022-01-03T22:22:34.000Z</updated>
        <summary type="html"><![CDATA[In-person user identity verification is slow to scale, costly, and high friction for users. Machine learning (ML) powered facial recognition technology can enable online user identity verification. Amazon Rekognition offers pre-trained facial recognition capabilities that you can quickly add to your user onboarding and authentication workflows to verify opted-in users identities online. No ML expertise []]]></summary>
        <author>
            <name>Nate Bachmeier</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interested in learning but not really sure where to start]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rvaxu3/interested_in_learning_but_not_really_sure_where/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rvaxu3/interested_in_learning_but_not_really_sure_where/"/>
        <updated>2022-01-03T20:18:39.000Z</updated>
        <summary type="html"><![CDATA[For some time now I've been reading about neural networks and ai, the topic has really interested me a lot and I have seen amazing GAN projects like artbreeder, this has motivated me to want to work with this kind of technology, the only problem is that I can't really figure out where to start, so till this moment the only thing i've done is a Python introductory course. What should or could I do next?
 P.S: Spanish is my native language so excuse me if my english is a little rusty.
    submitted by    /u/luisaalberto  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Best Machine Learning Courses on Udemy (2022)]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rvatrg/the_best_machine_learning_courses_on_udemy_2022/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rvatrg/the_best_machine_learning_courses_on_udemy_2022/"/>
        <updated>2022-01-03T20:13:41.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/JanPrince002  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rvadz4/r_yourtts_towards_zeroshot_multispeaker_tts_and/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rvadz4/r_yourtts_towards_zeroshot_multispeaker_tts_and/"/>
        <updated>2022-01-03T19:54:47.000Z</updated>
        <summary type="html"><![CDATA[YourTTS brings the power of a multilingual approach to the task of zero-shot multi-speaker TTS... it is possible to fine-tune the model with less than 1 minute of speech and achieve state-of-the-art results in voice similarity and with reasonable quality.
  Demo: https://coqui.ai
  Code: https://github.com/coqui-ai/tts
  Blogpost: https://coqui.ai/blog/tts/yourtts-zero-shot-text-synthesis-low-resource-languages
  Paper: https://arxiv.org/abs/2112.02418
    submitted by    /u/josh-r-meyer  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] "why academia tends to under-invest in engineering infrastructure?"]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rva1dk/d_why_academia_tends_to_underinvest_in/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rva1dk/d_why_academia_tends_to_underinvest_in/"/>
        <updated>2022-01-03T19:39:29.000Z</updated>
        <summary type="html"><![CDATA[Tweet from @jackclarkSF asks an interesting question:
  
Is there a good paper that explains how/why academia tends to under-invest in engineering infrastructure?
  
https://twitter.com/jackclarkSF/status/1478077579110207489
    submitted by    /u/MassivePellfish  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Amazon Research Introduces Deep Reinforcement Learning For NLU Ranking Tasks]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rv9a2d/amazon_research_introduces_deep_reinforcement/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rv9a2d/amazon_research_introduces_deep_reinforcement/"/>
        <updated>2022-01-03T19:06:45.000Z</updated>
        <summary type="html"><![CDATA[In recent years, voice-based virtual assistants such as Google Assistant and Amazon Alexa have grown popular. This has presented both potential and challenges for natural language understanding (NLU) systems. These devices production systems are often trained by supervised learning and rely significantly on annotated data. But, data annotation is costly and time-consuming. Furthermore, model updates using offline supervised learning can take long and miss trending requests.
 In the underlying architecture of voice-based virtual assistants, the NLU model often categorizes user requests into hypotheses for downstream applications to fulfill. A hypothesis comprises two tags: user intention (intent) and Named Entity Recognition (NER). For example, the valid hypothesis for play a Madonna song will be: PlaySong intent, ArtistName  Madonna.
 A new Amazon research introduces deep reinforcement learning strategies for NLU ranking. Their work analyses a ranking question in an NLU system in which entirely independent domain experts generate hypotheses with their features, where a domain is a functional area such as Music, Shopping, or Weather. These hypotheses are then ranked based on their scores, calculated based on their characteristics. As a result, the ranker must calibrate features from domain experts and select one hypothesis according to policy. Continue Reading
 Research Paper: https://assets.amazon.science/b3/74/77ff47044b69820c466f0624a0ab/introducing-deep-reinforcement-learning-to-nlu-ranking-tasks.pdf
 
 https://preview.redd.it/fp79wa92ui981.png?width=1920&format=png&auto=webp&s=647db1d2bd5be9dc9698c980e2146fef499368f3
    submitted by    /u/ai-lover  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Amazon Research Introduces Deep Reinforcement Learning For NLU Ranking Tasks]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rv99zi/amazon_research_introduces_deep_reinforcement/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rv99zi/amazon_research_introduces_deep_reinforcement/"/>
        <updated>2022-01-03T19:06:38.000Z</updated>
        <summary type="html"><![CDATA[In recent years, voice-based virtual assistants such as Google Assistant and Amazon Alexa have grown popular. This has presented both potential and challenges for natural language understanding (NLU) systems. These devices production systems are often trained by supervised learning and rely significantly on annotated data. But, data annotation is costly and time-consuming. Furthermore, model updates using offline supervised learning can take long and miss trending requests.
 In the underlying architecture of voice-based virtual assistants, the NLU model often categorizes user requests into hypotheses for downstream applications to fulfill. A hypothesis comprises two tags: user intention (intent) and Named Entity Recognition (NER). For example, the valid hypothesis for play a Madonna song will be: PlaySong intent, ArtistName  Madonna.
 A new Amazon research introduces deep reinforcement learning strategies for NLU ranking. Their work analyses a ranking question in an NLU system in which entirely independent domain experts generate hypotheses with their features, where a domain is a functional area such as Music, Shopping, or Weather. These hypotheses are then ranked based on their scores, calculated based on their characteristics. As a result, the ranker must calibrate features from domain experts and select one hypothesis according to policy. Continue Reading
 Research Paper: https://assets.amazon.science/b3/74/77ff47044b69820c466f0624a0ab/introducing-deep-reinforcement-learning-to-nlu-ranking-tasks.pdf
 
 https://preview.redd.it/27wx7281ui981.png?width=1920&format=png&auto=webp&s=61264372ce2854031e4acd1221c802a3e042a0a8
    submitted by    /u/ai-lover  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI Will Make It Difficult to Discern Information from Misinformation (1-minute audio clip from Eric Schmidt, former Google CEO)]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rv93aw/ai_will_make_it_difficult_to_discern_information/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rv93aw/ai_will_make_it_difficult_to_discern_information/"/>
        <updated>2022-01-03T18:59:10.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/frog9913  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] How to measure accuracy of kNN Imputation?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rv7yos/d_how_to_measure_accuracy_of_knn_imputation/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rv7yos/d_how_to_measure_accuracy_of_knn_imputation/"/>
        <updated>2022-01-03T18:10:28.000Z</updated>
        <summary type="html"><![CDATA[I have a dataset in which the the best way to impute missing values is to use kNN but before I go ahead and do that I'd like to check what kind of accuracy I have with that form of imputation in this specific dataset and which k should be used. My original solution was as follows:
  
From my original dataset, remove all rows with missing values
 From this dataset, impute NaNs randomly throughout the dataset with the same frequency that they were missing originally and store the values that were replaced with NaN in a new dataset as the ground truth
 Impute using kNN
 Check the accuracy of the imputed values against the ground truth values stored in step 2 using MAE for different k values
  
Is there an easier way to do this? If not, should I be using MAE or another accuracy score?
    submitted by    /u/Ok-Culture-9123  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data Monetization Approach for B2B2C Industries]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087050</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087050"/>
        <updated>2022-01-03T18:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9982546079?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9982546079?profile=RESIZE_710x" width="720"></img></a></p>
<p>Most of the Big Data, Data Science and AI / ML success stories seem to revolve around Business-to-Consumer (B2C) industries. The companies that we see leading the economic exploitation of data and analytics are primarily B2C companies such as Apple, Alphabet (Google), Microsoft, Amazon, and Facebook (Figure 1).</p>
<p></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Average reward formulation for continuing settings]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rv5ugt/average_reward_formulation_for_continuing_settings/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rv5ugt/average_reward_formulation_for_continuing_settings/"/>
        <updated>2022-01-03T16:39:19.000Z</updated>
        <summary type="html"><![CDATA[I have a problem that is -for its nature- continuing, i.e. there are no episodes and the agent has to operate for an infinite time. In my simulator, however, I have the possibility of simulating episodes of any length.
 Is the average reward formulation appropriate for such a problem? I do not know much about it and I have a few questions for you:
  
Could you point me to some literature that addresses average reward and its pros/cons vs discounted reward for continuing problems?
 Is the average taken on a window of finite size or on the limit for the size that goes to infinity? 
 How do common RL algorithms work in this formulation? Can we still adapt them to use average reward?
  
   submitted by    /u/fedetask  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Paper that mathematically proves that gradient descent can achieve zero training error.]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rv4u2w/d_paper_that_mathematically_proves_that_gradient/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rv4u2w/d_paper_that_mathematically_proves_that_gradient/"/>
        <updated>2022-01-03T15:56:40.000Z</updated>
        <summary type="html"><![CDATA[I think this is a well-known paper, but I have not been able to find it. I am interested in the paper that mathematically proves neural nets can fit any set of datapoints. So far what I have found mostly is papers that show empirically that or something related to that, like this one. I'd appreciate any help.
 Edit: u/the_new_scientist shared this paper which is what I was looking for: https://arxiv.org/pdf/1810.02054.pdf Also, I apologize for my vague description. Now that the paper is shown, I hope it is more clear to future readers what kind of results I meant, but in case that is not case, I was wondering about this question: under what conditions can a neural network achieve zero training error? and in particular, I am interested in papers with mathematical (even without empirical) results.
    submitted by    /u/carlml  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NLP: Hybridization of statistical approach and expert system?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rv4r4s/nlp_hybridization_of_statistical_approach_and/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rv4r4s/nlp_hybridization_of_statistical_approach_and/"/>
        <updated>2022-01-03T15:52:47.000Z</updated>
        <summary type="html"><![CDATA[Hi everyone!
 I have a question for you. For context, we aggregate on a platform the various AI APIs on the market (GCP, Azure, etc.) and including NLP APIs (keyword extraction, sentiment analysis, NER, etc.). The idea is that a developer doesn't have to create accounts with different providers and can have them all on one API to test, compare and change whenever he wants.
 However, many customers ask us how to mix the "statistical" approach behind these APIs with expert systems and how to achieve hybridization.
 Do you have any idea how to do this?
 Thanks,
    submitted by    /u/tah_zem  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] NLP: Hybridization of statistical approach and expert system ?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rv4nah/d_nlp_hybridization_of_statistical_approach_and/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rv4nah/d_nlp_hybridization_of_statistical_approach_and/"/>
        <updated>2022-01-03T15:48:20.000Z</updated>
        <summary type="html"><![CDATA[Hi everyone!
 I have a question for you. For context, we aggregate on a platform the various AI APIs on the market (GCP, Azure, etc.) and including NLP APIs (keyword extraction, sentiment analysis, NER, etc.). The idea is that a developer doesn't have to create accounts with different providers and can have them all on one API to test, compare and change whenever he wants.
 However, many customers ask us how to mix the "statistical" approach behind these APIs with expert systems and how to achieve hybridization.
 Do you have any idea how to do this?
 Thanks,
    submitted by    /u/tah_zem  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] Bringing serverless to ML - stateful, arbitrary dependency, serverless for ML]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rv3yty/p_bringing_serverless_to_ml_stateful_arbitrary/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rv3yty/p_bringing_serverless_to_ml_stateful_arbitrary/"/>
        <updated>2022-01-03T15:18:08.000Z</updated>
        <summary type="html"><![CDATA[Serverless infrastructure is yet practical to use for ML but we think it could bring lots of benefits. So, with a friend, we decided to make serverless easy for ML and we are building a platform to solve the main issues we find in serverless for ML: 
 - Stateful: We dont want to reload a whole model every time a user calls model.predict
 - Arbritary dependecies: Normal python code with any package dependencies you use and love, just many many times in parallel
 - Scale-up and scale-down: scale up with ease and auto shutdown to keep resources consumptionYou can visit our webpage, try the demo, and request early access to use our platform!
 Webpage: https://telekinesis.cloud 
 Happy to receive questions and comments on what we are building!
    submitted by    /u/snuns90  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] What are your hopes for Machine Learning in 2022?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rv37yq/d_what_are_your_hopes_for_machine_learning_in_2022/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rv37yq/d_what_are_your_hopes_for_machine_learning_in_2022/"/>
        <updated>2022-01-03T14:43:33.000Z</updated>
        <summary type="html"><![CDATA[Hi r/MachineLearning!
 I was just wondering what some of you are hoping ML can accomplish or overcome in this new year - interested in hearing your thoughts!
    submitted by    /u/DataGeek0  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Formula to compute loss in A3C]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rv2ku7/formula_to_compute_loss_in_a3c/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rv2ku7/formula_to_compute_loss_in_a3c/"/>
        <updated>2022-01-03T14:12:09.000Z</updated>
        <summary type="html"><![CDATA[I'm a beginner to RL and I'm trying to understand how the loss function was computed. If it follows a specific formular. I've read the a3c algorithm overview on paper by barto but it seems the implemtation here https://github.com/MorvanZhou/pytorch-A3C/blob/master/discrete_A3C.py is different.
    submitted by    /u/phissy08  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] The Illustrated Retrieval Transformer (GPT3 performance at 4% the size)]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rv2j9k/r_the_illustrated_retrieval_transformer_gpt3/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rv2j9k/r_the_illustrated_retrieval_transformer_gpt3/"/>
        <updated>2022-01-03T14:10:10.000Z</updated>
        <summary type="html"><![CDATA[Hi r/MachineLearning,
 I spent some time wrapping my head around DeepMind's Retro Transformer and visualizing how it works. Hope you find it useful. All feedback is welcome!
 http://jalammar.github.io/illustrated-retrieval-transformer/
    submitted by    /u/jayalammar  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introduction to Markov Decision Processes - Draft Chapters 2 and 3]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rv1wsc/introduction_to_markov_decision_processes_draft/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rv1wsc/introduction_to_markov_decision_processes_draft/"/>
        <updated>2022-01-03T13:38:07.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/YouAgainShmidhoobuh  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[IoT Drives Growth of Intelligent Transportation Systems]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087129</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1087129"/>
        <updated>2022-01-03T12:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9982818672?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9982818672?profile=RESIZE_710x" width="720"></img></a></p>
<p>The global IoT in intelligent transportation systems market is anticipated to be driven by the rising focus of industry players on research and development, aimed at enhancing the integrated IoT software in order to minimize the cost of operation associated with these tools.</p>
<p>Furthermore, the increasing focus on data collection pertaining to</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] What causes feature collapse?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ruz0nc/d_what_causes_feature_collapse/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ruz0nc/d_what_causes_feature_collapse/"/>
        <updated>2022-01-03T10:50:11.000Z</updated>
        <summary type="html"><![CDATA[For those of you unfamiliar feature collapse is when you train a model for classification and the model ends up mapping out-of-distribution data or data of different classes in very close proximity in multi-dimensional space. So for example once your model learns a cluster so to speak for cat, during test it projects a dog into the center of that cluster and classifies it as cat. Some ways to sort of deal with this in CV is double gradient penalty and spectral norm of resnet blocks, but what causes feature collapse?
    submitted by    /u/DolantheMFWizard  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] New paper: "A relational Tsetlin machine with applications to natural language understanding"]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ruyk5i/r_new_paper_a_relational_tsetlin_machine_with/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ruyk5i/r_new_paper_a_relational_tsetlin_machine_with/"/>
        <updated>2022-01-03T10:19:54.000Z</updated>
        <summary type="html"><![CDATA[
 Relational Tsetlin Machine
 The paper introduces the first Relational #TsetlinMachine, which reasons with relations, variables, and constants. The approach is based on first-order logic and Herbrand semantics, taking the first steps toward the computing power of a universal Turing machine. The approach can take advantage of logical structures appearing in natural language, to learn rules that represent how actions and consequences are related in the real world. The outcome is a logic program of Horn clauses, bringing in a structured view of unstructured data. In closed-domain question-answering, the first-order representation produces 10 more compact knowledge bases, along with an increase in answering accuracy from 94.83% to 99.48%. The approach is further robust towards erroneous, missing, and superfluous information, distilling the aspects of a text that are important for real-world understanding. https://link.springer.com/article/10.1007/s10844-021-00682-5 #ML #AI #NLP #MachineLearning #Logic #Relational
    submitted by    /u/olegranmo  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Top 10 Object Detection APIs]]></title>
        <id>https://www.reddit.com/r/artificial/comments/ruyi8d/top_10_object_detection_apis/</id>
        <link href="https://www.reddit.com/r/artificial/comments/ruyi8d/top_10_object_detection_apis/"/>
        <updated>2022-01-03T10:16:15.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/tah_zem  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open Domain Question Answering Part-1 [BlenderBot 2.0]]]></title>
        <id>https://www.reddit.com/r/artificial/comments/ruy6fd/open_domain_question_answering_part1_blenderbot_20/</id>
        <link href="https://www.reddit.com/r/artificial/comments/ruy6fd/open_domain_question_answering_part1_blenderbot_20/"/>
        <updated>2022-01-03T09:55:06.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/coffeeroach  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DQN with online learning]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rux1hi/dqn_with_online_learning/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rux1hi/dqn_with_online_learning/"/>
        <updated>2022-01-03T08:37:14.000Z</updated>
        <summary type="html"><![CDATA[I saw another post on here that mentioned how DQN's can be implemented via online learning, offline learning (e.g. batching), or a combination (offline learning first and then online learning in production). What I'm confused at is the actual deployment paradigm to facilitate online learning (either as the first step or with hybrid). 
 Is the full training code (with a checkpoint model if hybrid) and agent deployed to production with the training step logic executed on-demand for each state transition? If so, would this mean that model compilation / quantization is not possible (e.g. Onnx runtime to INT8 precision)? How is it scaled if it's having to perform SGD and back-propagation with each state transition?
 
 One the other side, if the model is compiled / quantized, how does it implement online learning (if this is even possible)?
    submitted by    /u/FinateAI  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] How to deal with huge Categorical data]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ruwidq/d_how_to_deal_with_huge_categorical_data/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ruwidq/d_how_to_deal_with_huge_categorical_data/"/>
        <updated>2022-01-03T08:00:25.000Z</updated>
        <summary type="html"><![CDATA[I have a dataset that already contains about 55 columns and out of this, around 10 Columns or so have categorical data in it. If I were to OneHotEncode them, I will end up having a column count of more than 300. Is this something advisable? How do you people deal with such huge number of columns? I mean 300 columns is not a big deal, but I would like to know your opinion and thoughts on this.
    submitted by    /u/CaterpillarPrevious2  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Spotted this post in LessWrong. Can anyone verify the rather fantastic claims being made here?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ruwchh/d_spotted_this_post_in_lesswrong_can_anyone/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ruwchh/d_spotted_this_post_in_lesswrong_can_anyone/"/>
        <updated>2022-01-03T07:49:34.000Z</updated>
        <summary type="html"><![CDATA[https://www.lesswrong.com/posts/rCP5iTYLtfcoC8NXd/self-organised-neural-networks-a-simple-natural-and#Roadmap
 The writing has some red flags, but it looks interesting enough. Having some trouble with my gpu drivers so I can't run it right now.
    submitted by    /u/Their_bad_spellers  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Any good papers for non-stationary environment?]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/ruw5c4/any_good_papers_for_nonstationary_environment/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/ruw5c4/any_good_papers_for_nonstationary_environment/"/>
        <updated>2022-01-03T07:36:14.000Z</updated>
        <summary type="html"><![CDATA[I want to create a control system for control agents(players). The players will move non-stationary, so is there any good technique or papers to train this control system? 
 Very Thanks.
    submitted by    /u/Spiritual_Fig3632  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CONFAIR: Configurable and Interpretable Algorithmic Fairness. (arXiv:2111.08878v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.08878</id>
        <link href="http://arxiv.org/abs/2111.08878"/>
        <updated>2022-01-03T07:15:44.633Z</updated>
        <summary type="html"><![CDATA[The rapid growth of data in the recent years has led to the development of
complex learning algorithms that are often used to make decisions in real
world. While the positive impact of the algorithms has been tremendous, there
is a need to mitigate any bias arising from either training samples or implicit
assumptions made about the data samples. This need becomes critical when
algorithms are used in automated decision making systems that can hugely impact
people's lives.

Many approaches have been proposed to make learning algorithms fair by
detecting and mitigating bias in different stages of optimization. However, due
to a lack of a universal definition of fairness, these algorithms optimize for
a particular interpretation of fairness which makes them limited for real world
use. Moreover, an underlying assumption that is common to all algorithms is the
apparent equivalence of achieving fairness and removing bias. In other words,
there is no user defined criteria that can be incorporated into the
optimization procedure for producing a fair algorithm. Motivated by these
shortcomings of existing methods, we propose the CONFAIR procedure that
produces a fair algorithm by incorporating user constraints into the
optimization procedure. Furthermore, we make the process interpretable by
estimating the most predictive features from data. We demonstrate the efficacy
of our approach on several real world datasets using different fairness
criteria.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kulshrestha_A/0/1/0/all/0/1"&gt;Ankit Kulshrestha&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Safro_I/0/1/0/all/0/1"&gt;Ilya Safro&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ML-Decoder: Scalable and Versatile Classification Head. (arXiv:2111.12933v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.12933</id>
        <link href="http://arxiv.org/abs/2111.12933"/>
        <updated>2022-01-03T07:15:44.611Z</updated>
        <summary type="html"><![CDATA[In this paper, we introduce ML-Decoder, a new attention-based classification
head. ML-Decoder predicts the existence of class labels via queries, and
enables better utilization of spatial data compared to global average pooling.
By redesigning the decoder architecture, and using a novel group-decoding
scheme, ML-Decoder is highly efficient, and can scale well to thousands of
classes. Compared to using a larger backbone, ML-Decoder consistently provides
a better speed-accuracy trade-off. ML-Decoder is also versatile - it can be
used as a drop-in replacement for various classification heads, and generalize
to unseen classes when operated with word queries. Novel query augmentations
further improve its generalization ability. Using ML-Decoder, we achieve
state-of-the-art results on several classification tasks: on MS-COCO
multi-label, we reach 91.4% mAP; on NUS-WIDE zero-shot, we reach 31.1% ZSL mAP;
and on ImageNet single-label, we reach with vanilla ResNet50 backbone a new top
score of 80.7%, without extra data or distillation. Public code is available
at: https://github.com/Alibaba-MIIL/ML_Decoder]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1"&gt;Tal Ridnik&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sharir_G/0/1/0/all/0/1"&gt;Gilad Sharir&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ben_Cohen_A/0/1/0/all/0/1"&gt;Avi Ben-Cohen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1"&gt;Emanuel Ben-Baruch&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1"&gt;Asaf Noy&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification. (arXiv:2103.12656v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.12656</id>
        <link href="http://arxiv.org/abs/2103.12656"/>
        <updated>2022-01-03T07:15:44.409Z</updated>
        <summary type="html"><![CDATA[Reinforcement learning (RL) algorithms assume that users specify tasks by
manually writing down a reward function. However, this process can be laborious
and demands considerable technical expertise. Can we devise RL algorithms that
instead enable users to specify tasks simply by providing examples of
successful outcomes? In this paper, we derive a control algorithm that
maximizes the future probability of these successful outcome examples. Prior
work has approached similar problems with a two-stage process, first learning a
reward function and then optimizing this reward function using another RL
algorithm. In contrast, our method directly learns a value function from
transitions and successful outcomes, without learning this intermediate reward
function. Our method therefore requires fewer hyperparameters to tune and lines
of code to debug. We show that our method satisfies a new data-driven Bellman
equation, where examples take the place of the typical reward function term.
Experiments show that our approach outperforms prior methods that learn
explicit reward functions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1"&gt;Benjamin Eysenbach&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1"&gt;Sergey Levine&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1"&gt;Ruslan Salakhutdinov&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Survey of Embodied AI: From Simulators to Research Tasks. (arXiv:2103.04918v6 [cs.AI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.04918</id>
        <link href="http://arxiv.org/abs/2103.04918"/>
        <updated>2022-01-03T07:15:44.403Z</updated>
        <summary type="html"><![CDATA[There has been an emerging paradigm shift from the era of "internet AI" to
"embodied AI", where AI algorithms and agents no longer learn from datasets of
images, videos or text curated primarily from the internet. Instead, they learn
through interactions with their environments from an egocentric perception
similar to humans. Consequently, there has been substantial growth in the
demand for embodied AI simulators to support various embodied AI research
tasks. This growing interest in embodied AI is beneficial to the greater
pursuit of Artificial General Intelligence (AGI), but there has not been a
contemporary and comprehensive survey of this field. This paper aims to provide
an encyclopedic survey for the field of embodied AI, from its simulators to its
research. By evaluating nine current embodied AI simulators with our proposed
seven features, this paper aims to understand the simulators in their provision
for use in embodied AI research and their limitations. Lastly, this paper
surveys the three main research tasks in embodied AI -- visual exploration,
visual navigation and embodied question answering (QA), covering the
state-of-the-art approaches, evaluation metrics and datasets. Finally, with the
new insights revealed through surveying the field, the paper will provide
suggestions for simulator-for-task selections and recommendations for the
future directions of the field.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1"&gt;Jiafei Duan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1"&gt;Samson Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1"&gt;Hui Li Tan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1"&gt;Hongyuan Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1"&gt;Cheston Tan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A GAN-Like Approach for Physics-Based Imitation Learning and Interactive Character Control. (arXiv:2105.10066v4 [cs.GR] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.10066</id>
        <link href="http://arxiv.org/abs/2105.10066"/>
        <updated>2022-01-03T07:15:44.396Z</updated>
        <summary type="html"><![CDATA[We present a simple and intuitive approach for interactive control of
physically simulated characters. Our work builds upon generative adversarial
networks (GAN) and reinforcement learning, and introduces an imitation learning
framework where an ensemble of classifiers and an imitation policy are trained
in tandem given pre-processed reference clips. The classifiers are trained to
discriminate the reference motion from the motion generated by the imitation
policy, while the policy is rewarded for fooling the discriminators. Using our
GAN-based approach, multiple motor control policies can be trained separately
to imitate different behaviors. In runtime, our system can respond to external
control signal provided by the user and interactively switch between different
policies. Compared to existing methods, our proposed approach has the following
attractive properties: 1) achieves state-of-the-art imitation performance
without manually designing and fine tuning a reward function; 2) directly
controls the character without having to track any target reference pose
explicitly or implicitly through a phase state; and 3) supports interactive
policy switching without requiring any motion generation or motion matching
mechanism. We highlight the applicability of our approach in a range of
imitation and interactive control tasks, while also demonstrating its ability
to withstand external perturbations as well as to recover balance. Overall, our
approach generates high-fidelity motion, has low runtime cost, and can be
easily integrated into interactive applications and games.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1"&gt;Pei Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Karamouzas_I/0/1/0/all/0/1"&gt;Ioannis Karamouzas&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Analysis of Regularized Learning in Banach Spaces. (arXiv:2109.03159v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.03159</id>
        <link href="http://arxiv.org/abs/2109.03159"/>
        <updated>2022-01-03T07:15:44.375Z</updated>
        <summary type="html"><![CDATA[This article presents a new way to study the theory of regularized learning
for generalized data in Banach spaces including representer theorems and
convergence theorems. The generalized data are composed of linear functionals
and real scalars as the input and output elements to represent the discrete
information of different local models. By the extension of the classical
machine learning, the empirical risks are computed by the generalized data and
the loss functions. According to the techniques of regularization, the exact
solutions are approximated globally by minimizing the regularized empirical
risks over the Banach spaces. The existence and convergence of the approximate
solutions are guaranteed by the relative compactness of the generalized input
data in the predual spaces of the Banach spaces.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1"&gt;Qi Ye&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leveraging in-domain supervision for unsupervised image-to-image translation tasks via multi-stream generators. (arXiv:2112.15091v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2112.15091</id>
        <link href="http://arxiv.org/abs/2112.15091"/>
        <updated>2022-01-03T07:15:44.369Z</updated>
        <summary type="html"><![CDATA[Supervision for image-to-image translation (I2I) tasks is hard to come by,
but bears significant effect on the resulting quality. In this paper, we
observe that for many Unsupervised I2I (UI2I) scenarios, one domain is more
familiar than the other, and offers in-domain prior knowledge, such as semantic
segmentation. We argue that for complex scenes, figuring out the semantic
structure of the domain is hard, especially with no supervision, but is an
important part of a successful I2I operation. We hence introduce two techniques
to incorporate this invaluable in-domain prior knowledge for the benefit of
translation quality: through a novel Multi-Stream generator architecture, and
through a semantic segmentation-based regularization loss term. In essence, we
propose splitting the input data according to semantic masks, explicitly
guiding the network to different behavior for the different regions of the
image. In addition, we propose training a semantic segmentation network along
with the translation task, and to leverage this output as a loss term that
improves robustness. We validate our approach on urban data, demonstrating
superior quality in the challenging UI2I tasks of converting day images to
night ones. In addition, we also demonstrate how reinforcing the target dataset
with our augmented images improves the training of downstream tasks such as the
classical detection one.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yerushalmi_D/0/1/0/all/0/1"&gt;Dvir Yerushalmi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Danon_D/0/1/0/all/0/1"&gt;Dov Danon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1"&gt;Amit H. Bermano&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When are Iterative Gaussian Processes Reliably Accurate?. (arXiv:2112.15246v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15246</id>
        <link href="http://arxiv.org/abs/2112.15246"/>
        <updated>2022-01-03T07:15:44.362Z</updated>
        <summary type="html"><![CDATA[While recent work on conjugate gradient methods and Lanczos decompositions
have achieved scalable Gaussian process inference with highly accurate point
predictions, in several implementations these iterative methods appear to
struggle with numerical instabilities in learning kernel hyperparameters, and
poor test likelihoods. By investigating CG tolerance, preconditioner rank, and
Lanczos decomposition rank, we provide a particularly simple prescription to
correct these issues: we recommend that one should use a small CG tolerance
($\epsilon \leq 0.01$) and a large root decomposition size ($r \geq 5000$).
Moreover, we show that L-BFGS-B is a compelling optimizer for Iterative GPs,
achieving convergence with fewer gradient updates.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Maddox_W/0/1/0/all/0/1"&gt;Wesley J. Maddox&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1"&gt;Sanyam Kapoor&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1"&gt;Andrew Gordon Wilson&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Processing Images from Multiple IACTs in the TAIGA Experiment with Convolutional Neural Networks. (arXiv:2112.15382v1 [astro-ph.IM])]]></title>
        <id>http://arxiv.org/abs/2112.15382</id>
        <link href="http://arxiv.org/abs/2112.15382"/>
        <updated>2022-01-03T07:15:44.356Z</updated>
        <summary type="html"><![CDATA[Extensive air showers created by high-energy particles interacting with the
Earth atmosphere can be detected using imaging atmospheric Cherenkov telescopes
(IACTs). The IACT images can be analyzed to distinguish between the events
caused by gamma rays and by hadrons and to infer the parameters of the event
such as the energy of the primary particle. We use convolutional neural
networks (CNNs) to analyze Monte Carlo-simulated images from the telescopes of
the TAIGA experiment. The analysis includes selection of the images
corresponding to the showers caused by gamma rays and estimating the energy of
the gamma rays. We compare performance of the CNNs using images from a single
telescope and the CNNs using images from two telescopes as inputs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/astro-ph/1/au:+Polyakov_S/0/1/0/all/0/1"&gt;Stanislav Polyakov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/astro-ph/1/au:+Demichev_A/0/1/0/all/0/1"&gt;Andrey Demichev&lt;/a&gt;, &lt;a href="http://arxiv.org/find/astro-ph/1/au:+Kryukov_A/0/1/0/all/0/1"&gt;Alexander Kryukov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/astro-ph/1/au:+Postnikov_E/0/1/0/all/0/1"&gt;Evgeny Postnikov&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Survey on Deep learning based Document Image Enhancement. (arXiv:2112.02719v3 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.02719</id>
        <link href="http://arxiv.org/abs/2112.02719"/>
        <updated>2022-01-03T07:15:44.349Z</updated>
        <summary type="html"><![CDATA[Digitized documents such as scientific articles, tax forms, invoices,
contract papers, historic texts are widely used nowadays. These document images
could be degraded or damaged due to various reasons including poor lighting
conditions, shadow, distortions like noise and blur, aging, ink stain,
bleed-through, watermark, stamp, etc. Document image enhancement plays a
crucial role as a pre-processing step in many automated document analysis and
recognition tasks such as character recognition. With recent advances in deep
learning, many methods are proposed to enhance the quality of these document
images. In this paper, we review deep learning-based methods, datasets, and
metrics for six main document image enhancement tasks, including binarization,
debluring, denoising, defading, watermark removal, and shadow removal. We
summarize the recent works for each task and discuss their features,
challenges, and limitations. We introduce multiple document image enhancement
tasks that have received little to no attention, including over and under
exposure correction, super resolution, and bleed-through removal. We identify
several promising research directions and opportunities for future research.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Anvari_Z/0/1/0/all/0/1"&gt;Zahra Anvari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Athitsos_V/0/1/0/all/0/1"&gt;Vassilis Athitsos&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A toolkit for data-driven discovery of governing equations in high-noise regimes. (arXiv:2111.04870v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.04870</id>
        <link href="http://arxiv.org/abs/2111.04870"/>
        <updated>2022-01-03T07:15:44.331Z</updated>
        <summary type="html"><![CDATA[We consider the data-driven discovery of governing equations from time-series
data in the limit of high noise. The algorithms developed describe an extensive
toolkit of methods for circumventing the deleterious effects of noise in the
context of the sparse identification of nonlinear dynamics (SINDy) framework.
We offer two primary contributions, both focused on noisy data acquired from a
system x' = f(x). First, we propose, for use in high-noise settings, an
extensive toolkit of critically enabling extensions for the SINDy regression
method, to progressively cull functionals from an over-complete library and
yield a set of sparse equations that regress to the derivate x'. These
innovations can extract sparse governing equations and coefficients from
high-noise time-series data (e.g. 300% added noise). For example, it discovers
the correct sparse libraries in the Lorenz system, with median coefficient
estimate errors equal to 1% - 3% (for 50% noise), 6% - 8% (for 100% noise); and
23% - 25% (for 300% noise). The enabling modules in the toolkit are combined
into a single method, but the individual modules can be tactically applied in
other equation discovery methods (SINDy or not) to improve results on
high-noise data. Second, we propose a technique, applicable to any model
discovery method based on x' = f(x), to assess the accuracy of a discovered
model in the context of non-unique solutions due to noisy data. Currently, this
non-uniqueness can obscure a discovered model's accuracy and thus a discovery
method's effectiveness. We describe a technique that uses linear dependencies
among functionals to transform a discovered model into an equivalent form that
is closest to the true model, enabling more accurate assessment of a discovered
model's accuracy.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Delahunt_C/0/1/0/all/0/1"&gt;Charles B. Delahunt&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1"&gt;J. Nathan Kutz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inferring perceptual decision making parameters from behavior in production and reproduction tasks. (arXiv:2112.15521v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15521</id>
        <link href="http://arxiv.org/abs/2112.15521"/>
        <updated>2022-01-03T07:15:44.325Z</updated>
        <summary type="html"><![CDATA[Bayesian models of behavior have provided computational level explanations in
a range of psychophysical tasks. One fundamental experimental paradigm is the
production or reproduction task, in which subjects are instructed to generate
an action that either reproduces a previously sensed stimulus magnitude or
achieves a target response. This type of task therefore distinguishes itself
from other psychophysical tasks in that the responses are on a continuum and
effort plays an important role with increasing response magnitude. Based on
Bayesian decision theory we present an inference method to recover perceptual
uncertainty, response variability, and the cost function underlying human
responses. Crucially, the cost function is parameterized such that effort is
explicitly included. We present a hybrid inference method employing MCMC
sampling utilizing appropriate proposal distributions and an inner loop
utilizing amortized inference with a neural network that approximates the mode
of the optimal response distribution. We show how this model can be utilized to
avoid unidentifiability of experimental designs and that parameters can be
recovered through validation on synthetic and application to experimental data.
Our approach will enable behavioral scientists to perform Bayesian inference of
decision making parameters in production and reproduction tasks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Neupartl_N/0/1/0/all/0/1"&gt;Nils Neup&amp;#xe4;rtl&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rothkopf_C/0/1/0/all/0/1"&gt;Constantin A. Rothkopf&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Embedding Information onto a Dynamical System. (arXiv:2105.10766v3 [math.DS] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.10766</id>
        <link href="http://arxiv.org/abs/2105.10766"/>
        <updated>2022-01-03T07:15:44.319Z</updated>
        <summary type="html"><![CDATA[The celebrated Takens' embedding theorem concerns embedding an attractor of a
dynamical system in a Euclidean space of appropriate dimension through a
generic delay-observation map. The embedding also establishes a topological
conjugacy. In this paper, we show how an arbitrary sequence can be mapped into
another space as an attractive solution of a nonautonomous dynamical system.
Such mapping also entails a topological conjugacy and an embedding between the
sequence and the attractive solution spaces. This result is not a
generalization of Takens embedding theorem but helps us understand what exactly
is required by discrete-time state space models widely used in applications to
embed an external stimulus onto its solution space. Our results settle another
basic problem concerning the perturbation of an autonomous dynamical system. We
describe what exactly happens to the dynamics when exogenous noise perturbs
continuously a local irreducible attracting set (such as a stable fixed point)
of a discrete-time autonomous dynamical system.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Manjunath_G/0/1/0/all/0/1"&gt;G Manjunath&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Notes on the H-measure of classifier performance. (arXiv:2106.11888v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.11888</id>
        <link href="http://arxiv.org/abs/2106.11888"/>
        <updated>2022-01-03T07:15:44.313Z</updated>
        <summary type="html"><![CDATA[The H-measure is a classifier performance measure which takes into account
the context of application without requiring a rigid value of relative
misclassification costs to be set. Since its introduction in 2009 it has become
widely adopted. This paper answers various queries which users have raised
since its introduction, including questions about its interpretation, the
choice of a weighting function, whether it is strictly proper, and its
coherence, and relates the measure to other work.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hand_D/0/1/0/all/0/1"&gt;D. J. Hand&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Anagnostopoulos_C/0/1/0/all/0/1"&gt;C. Anagnostopoulos&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Frame invariance and scalability of neural operators for partial differential equations. (arXiv:2112.14769v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14769</id>
        <link href="http://arxiv.org/abs/2112.14769"/>
        <updated>2022-01-03T07:15:44.307Z</updated>
        <summary type="html"><![CDATA[Partial differential equations (PDEs) play a dominant role in the
mathematical modeling of many complex dynamical processes. Solving these PDEs
often requires prohibitively high computational costs, especially when multiple
evaluations must be made for different parameters or conditions. After
training, neural operators can provide PDEs solutions significantly faster than
traditional PDE solvers. In this work, invariance properties and computational
complexity of two neural operators are examined for transport PDE of a scalar
quantity. Neural operator based on graph kernel network (GKN) operates on
graph-structured data to incorporate nonlocal dependencies. Here we propose a
modified formulation of GKN to achieve frame invariance. Vector cloud neural
network (VCNN) is an alternate neural operator with embedded frame invariance
which operates on point cloud data. GKN-based neural operator demonstrates
slightly better predictive performance compared to VCNN. However, GKN requires
an excessively high computational cost that increases quadratically with the
increasing number of discretized objects as compared to a linear increase for
VCNN.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zafar_M/0/1/0/all/0/1"&gt;Muhammad I. Zafar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1"&gt;Jiequn Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1"&gt;Xu-Hui Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1"&gt;Heng Xiao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-Decentralized Federated Edge Learning for Fast Convergence on Non-IID Data. (arXiv:2104.12678v5 [cs.NI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2104.12678</id>
        <link href="http://arxiv.org/abs/2104.12678"/>
        <updated>2022-01-03T07:15:44.283Z</updated>
        <summary type="html"><![CDATA[Federated edge learning (FEEL) has emerged as an effective approach to reduce
the large communication latency in Cloud-based machine learning solutions,
while preserving data privacy. Unfortunately, the learning performance of FEEL
may be compromised due to limited training data in a single edge cluster. In
this paper, we investigate a novel framework of FEEL, namely semi-decentralized
federated edge learning (SD-FEEL). By allowing model aggregation across
different edge clusters, SD-FEEL enjoys the benefit of FEEL in reducing the
training latency, while improving the learning performance by accessing richer
training data from multiple edge clusters. A training algorithm for SD-FEEL
with three main procedures in each round is presented, including local model
updates, intra-cluster and inter-cluster model aggregations, which is proved to
converge on non-independent and identically distributed (non-IID) data. We also
characterize the interplay between the network topology of the edge servers and
the communication overhead of inter-cluster model aggregation on the training
performance. Experiment results corroborate our analysis and demonstrate the
effectiveness of SD-FFEL in achieving faster convergence than traditional
federated learning architectures. Besides, guidelines on choosing critical
hyper-parameters of the training algorithm are also provided.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1"&gt;Yuchang Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1"&gt;Jiawei Shao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1"&gt;Yuyi Mao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"&gt;Jessie Hui Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1"&gt;Jun Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Unified Analysis Method for Online Optimization in Normed Vector Space. (arXiv:2112.12134v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.12134</id>
        <link href="http://arxiv.org/abs/2112.12134"/>
        <updated>2022-01-03T07:15:44.283Z</updated>
        <summary type="html"><![CDATA[We present a unified analysis method that relies on the generalized cosine
rule and $\phi$-convex for online optimization in normed vector space using
dynamic regret as the performance metric. In combing the update rules, we start
with strategy $S$ (a two-parameter variant strategy covering Optimistic-FTRL
with surrogate linearized losses), and obtain $S$-I (type-I relaxation variant
form of $S$) and $S$-II (type-II relaxation variant form of $S$, which is
Optimistic-MD) by relaxation. Regret bounds for $S$-I and $S$-II are the
tightest possible. As instantiations, regret bounds of normalized exponentiated
subgradient and greedy/lazy projection are better than the currently known
optimal results. By replacing losses of online game with monotone operators,
and extending the definition of regret, namely regret$^n$, we extend online
convex optimization to online monotone optimization, which expands the
application scope of $S$-I and $S$-II.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1"&gt;Qing-xin Meng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"&gt;Jian-wei Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sufficient Statistic Memory AMP. (arXiv:2112.15327v1 [cs.IT])]]></title>
        <id>http://arxiv.org/abs/2112.15327</id>
        <link href="http://arxiv.org/abs/2112.15327"/>
        <updated>2022-01-03T07:15:44.276Z</updated>
        <summary type="html"><![CDATA[Approximate message passing (AMP) is a promising technique for unknown signal
reconstruction of certain high-dimensional linear systems with non-Gaussian
signaling. A distinguished feature of the AMP-type algorithms is that their
dynamics can be rigorously described by state evolution. However, state
evolution does not necessarily guarantee the convergence of iterative
algorithms. To solve the convergence problem of AMP-type algorithms in
principle, this paper proposes a memory AMP (MAMP) under a sufficient statistic
condition, named sufficient statistic MAMP (SS-MAMP). We show that the
covariance matrices of SS-MAMP are L-banded and convergent. Given an arbitrary
MAMP, we can construct an SS-MAMP by damping, which not only ensures the
convergence of MAMP but also preserves the orthogonality of MAMP, i.e., its
dynamics can be rigorously described by state evolution. As a byproduct, we
prove that the Bayes-optimal orthogonal/vector AMP (BO-OAMP/VAMP) is an
SS-MAMP. As a result, we reveal two interesting properties of BO-OAMP/VAMP for
large systems: 1) the covariance matrices are L-banded and are convergent in
BO-OAMP/VAMP, and 2) damping and memory are useless (i.e., do not bring
performance improvement) in BO-OAMP/VAMP. As an example, we construct a
sufficient statistic Bayes-optimal MAMP (BO-MAMP), which is Bayes optimal if
its state evolution has a unique fixed point and its MSE is not worse than the
original BO-MAMP. Finally, simulations are provided to verify the validity and
accuracy of the theoretical results.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1"&gt;Lei Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1"&gt;Shunqi Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kurkoski_B/0/1/0/all/0/1"&gt;Brian M. Kurkoski&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Entropy Regularized Optimal Transport Independence Criterion. (arXiv:2112.15265v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2112.15265</id>
        <link href="http://arxiv.org/abs/2112.15265"/>
        <updated>2022-01-03T07:15:44.269Z</updated>
        <summary type="html"><![CDATA[Optimal transport (OT) and its entropy regularized offspring have recently
gained a lot of attention in both machine learning and AI domains. In
particular, optimal transport has been used to develop probability metrics
between probability distributions. We introduce in this paper an independence
criterion based on entropy regularized optimal transport. Our criterion can be
used to test for independence between two samples. We establish non-asymptotic
bounds for our test statistic, and study its statistical behavior under both
the null and alternative hypothesis. Our theoretical results involve tools from
U-process theory and optimal transport theory. We present experimental results
on existing benchmarks, illustrating the interest of the proposed criterion.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Liu_L/0/1/0/all/0/1"&gt;Lang Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1"&gt;Soumik Pal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Harchaoui_Z/0/1/0/all/0/1"&gt;Zaid Harchaoui&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non Asymptotic Bounds for Optimization via Online Multiplicative Stochastic Gradient Descent. (arXiv:2112.07110v4 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.07110</id>
        <link href="http://arxiv.org/abs/2112.07110"/>
        <updated>2022-01-03T07:15:44.268Z</updated>
        <summary type="html"><![CDATA[The gradient noise of Stochastic Gradient Descent (SGD) is considered to play
a key role in its properties (e.g. escaping low potential points and
regularization). Past research has indicated that the covariance of the SGD
error done via minibatching plays a critical role in determining its
regularization and escape from low potential points. It is however not much
explored how much the distribution of the error influences the behavior of the
algorithm. Motivated by some new research in this area, we prove universality
results by showing that noise classes that have the same mean and covariance
structure of SGD via minibatching have similar properties. We mainly consider
the Multiplicative Stochastic Gradient Descent (M-SGD) algorithm as introduced
by Wu et al., which has a much more general noise class than the SGD algorithm
done via minibatching. We establish nonasymptotic bounds for the M-SGD
algorithm mainly with respect to the Stochastic Differential Equation
corresponding to SGD via minibatching. We also show that the M-SGD error is
approximately a scaled Gaussian distribution with mean $0$ at any fixed point
of the M-SGD algorithm. We also establish bounds for the convergence of the
M-SGD algorithm in the strongly convex regime.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Bhattacharya_R/0/1/0/all/0/1"&gt;Riddhiman Bhattacharya&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Financial Vision Based Differential Privacy Applications. (arXiv:2112.14075v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.14075</id>
        <link href="http://arxiv.org/abs/2112.14075"/>
        <updated>2022-01-03T07:15:44.262Z</updated>
        <summary type="html"><![CDATA[The importance of deep learning data privacy has gained significant attention
in recent years. It is probably to suffer data breaches when applying deep
learning to cryptocurrency that lacks supervision of financial regulatory
agencies. However, there is little relative research in the financial area to
our best knowledge. We apply two representative deep learning privacy-privacy
frameworks proposed by Google to financial trading data. We designed the
experiments with several different parameters suggested from the original
studies. In addition, we refer the degree of privacy to Google and Apple
companies to estimate the results more reasonably. The results show that DP-SGD
performs better than the PATE framework in financial trading data. The tradeoff
between privacy and accuracy is low in DP-SGD. The degree of privacy also is in
line with the actual case. Therefore, we can obtain a strong privacy guarantee
with precision to avoid potential financial loss.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"&gt;Jun-Hao Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yi-Jen Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1"&gt;Yun-Cheng Tsai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1"&gt;Samuel Yen-Chi Chen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Score-Based Generative Modeling with Critically-Damped Langevin Diffusion. (arXiv:2112.07068v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.07068</id>
        <link href="http://arxiv.org/abs/2112.07068"/>
        <updated>2022-01-03T07:15:44.255Z</updated>
        <summary type="html"><![CDATA[Score-based generative models (SGMs) have demonstrated remarkable synthesis
quality. SGMs rely on a diffusion process that gradually perturbs the data
towards a tractable distribution, while the generative model learns to denoise.
The complexity of this denoising task is, apart from the data distribution
itself, uniquely determined by the diffusion process. We argue that current
SGMs employ overly simplistic diffusions, leading to unnecessarily complex
denoising processes, which limit generative modeling performance. Based on
connections to statistical mechanics, we propose a novel critically-damped
Langevin diffusion (CLD) and show that CLD-based SGMs achieve superior
performance. CLD can be interpreted as running a joint diffusion in an extended
space, where the auxiliary variables can be considered "velocities" that are
coupled to the data variables as in Hamiltonian dynamics. We derive a novel
score matching objective for CLD and show that the model only needs to learn
the score function of the conditional distribution of the velocity given data,
an easier task than learning scores of the data directly. We also derive a new
sampling scheme for efficient synthesis from CLD-based diffusion models. We
find that CLD outperforms previous SGMs in synthesis quality for similar
network architectures and sampling compute budgets. We show that our novel
sampler for CLD significantly outperforms solvers such as Euler--Maruyama. Our
framework provides new insights into score-based denoising diffusion models and
can be readily used for high-resolution image synthesis. Project page and code:
https://nv-tlabs.github.io/CLD-SGM.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Dockhorn_T/0/1/0/all/0/1"&gt;Tim Dockhorn&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Vahdat_A/0/1/0/all/0/1"&gt;Arash Vahdat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Kreis_K/0/1/0/all/0/1"&gt;Karsten Kreis&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improved Algorithm for the Network Alignment Problem with Application to Binary Diffing. (arXiv:2112.15336v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15336</id>
        <link href="http://arxiv.org/abs/2112.15336"/>
        <updated>2022-01-03T07:15:44.248Z</updated>
        <summary type="html"><![CDATA[In this paper, we present a novel algorithm to address the Network Alignment
problem. It is inspired from a previous message passing framework of Bayati et
al. [2] and includes several modifications designed to significantly speed up
the message updates as well as to enforce their convergence. Experiments show
that our proposed model outperforms other state-of-the-art solvers. Finally, we
propose an application of our method in order to address the Binary Diffing
problem. We show that our solution provides better assignment than the
reference differs in almost all submitted instances and outline the importance
of leveraging the graphical structure of binary programs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Mengin_E/0/1/0/all/0/1"&gt;Elie Mengin&lt;/a&gt; (SAMM), &lt;a href="http://arxiv.org/find/cs/1/au:+Rossi_F/0/1/0/all/0/1"&gt;Fabrice Rossi&lt;/a&gt; (CEREMADE)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Importance of Empirical Sample Complexity Analysis for Offline Reinforcement Learning. (arXiv:2112.15578v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15578</id>
        <link href="http://arxiv.org/abs/2112.15578"/>
        <updated>2022-01-03T07:15:44.247Z</updated>
        <summary type="html"><![CDATA[We hypothesize that empirically studying the sample complexity of offline
reinforcement learning (RL) is crucial for the practical applications of RL in
the real world. Several recent works have demonstrated the ability to learn
policies directly from offline data. In this work, we ask the question of the
dependency on the number of samples for learning from offline data. Our
objective is to emphasize that studying sample complexity for offline RL is
important, and is an indicator of the usefulness of existing offline
algorithms. We propose an evaluation approach for sample complexity analysis of
offline RL.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Arnob_S/0/1/0/all/0/1"&gt;Samin Yeasar Arnob&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Islam_R/0/1/0/all/0/1"&gt;Riashat Islam&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1"&gt;Doina Precup&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[QueryNet: Attack by Multi-Identity Surrogates. (arXiv:2105.15010v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.15010</id>
        <link href="http://arxiv.org/abs/2105.15010"/>
        <updated>2022-01-03T07:15:44.223Z</updated>
        <summary type="html"><![CDATA[Deep Neural Networks (DNNs) are acknowledged as vulnerable to adversarial
attacks, while the existing black-box attacks require extensive queries on the
victim DNN to achieve high success rates. For query-efficiency, surrogate
models of the victim are used to generate transferable Adversarial Examples
(AEs) because of their Gradient Similarity (GS), i.e., surrogates' attack
gradients are similar to the victim's ones. However, it is generally neglected
to exploit their similarity on outputs, namely the Prediction Similarity (PS),
to filter out inefficient queries by surrogates without querying the victim. To
jointly utilize and also optimize surrogates' GS and PS, we develop QueryNet, a
unified attack framework that can significantly reduce queries. QueryNet
creatively attacks by multi-identity surrogates, i.e., crafts several AEs for
one sample by different surrogates, and also uses surrogates to decide on the
most promising AE for the query. After that, the victim's query feedback is
accumulated to optimize not only surrogates' parameters but also their
architectures, enhancing both the GS and the PS. Although QueryNet has no
access to pre-trained surrogates' prior, it reduces queries by averagely about
an order of magnitude compared to alternatives within an acceptable time,
according to our comprehensive experiments: 11 victims (including two
commercial models) on MNIST/CIFAR10/ImageNet, allowing only 8-bit image
queries, and no access to the victim's training data. The code is available at
https://github.com/AllenChen1998/QueryNet.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1"&gt;Sizhe Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1"&gt;Zhehao Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tao_Q/0/1/0/all/0/1"&gt;Qinghua Tao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1"&gt;Xiaolin Huang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geometric Deep Learning on Molecular Representations. (arXiv:2107.12375v4 [physics.chem-ph] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2107.12375</id>
        <link href="http://arxiv.org/abs/2107.12375"/>
        <updated>2022-01-03T07:15:44.215Z</updated>
        <summary type="html"><![CDATA[Geometric deep learning (GDL), which is based on neural network architectures
that incorporate and process symmetry information, has emerged as a recent
paradigm in artificial intelligence. GDL bears particular promise in molecular
modeling applications, in which various molecular representations with
different symmetry properties and levels of abstraction exist. This review
provides a structured and harmonized overview of molecular GDL, highlighting
its applications in drug discovery, chemical synthesis prediction, and quantum
chemistry. Emphasis is placed on the relevance of the learned molecular
features and their complementarity to well-established molecular descriptors.
This review provides an overview of current challenges and opportunities, and
presents a forecast of the future of GDL for molecular sciences.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Atz_K/0/1/0/all/0/1"&gt;Kenneth Atz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Grisoni_F/0/1/0/all/0/1"&gt;Francesca Grisoni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Schneider_G/0/1/0/all/0/1"&gt;Gisbert Schneider&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beta-VAE Reproducibility: Challenges and Extensions. (arXiv:2112.14278v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.14278</id>
        <link href="http://arxiv.org/abs/2112.14278"/>
        <updated>2022-01-03T07:15:44.208Z</updated>
        <summary type="html"><![CDATA[$\beta$-VAE is a follow-up technique to variational autoencoders that
proposes special weighting of the KL divergence term in the VAE loss to obtain
disentangled representations. Unsupervised learning is known to be brittle even
on toy datasets and a meaningful, mathematically precise definition of
disentanglement remains difficult to find. Here we investigate the original
$\beta$-VAE paper and add evidence to the results previously obtained
indicating its lack of reproducibility. We also further expand the
experimentation of the models and include further more complex datasets in the
analysis. We also implement an FID scoring metric for the $\beta$-VAE model and
conclude a qualitative analysis of the results obtained. We end with a brief
discussion on possible future investigations that can be conducted to add more
robustness to the claims.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Fil_M/0/1/0/all/0/1"&gt;Miroslav Fil&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mesinovic_M/0/1/0/all/0/1"&gt;Munib Mesinovic&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Morris_M/0/1/0/all/0/1"&gt;Matthew Morris&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wildberger_J/0/1/0/all/0/1"&gt;Jonas Wildberger&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[State Selection Algorithms and Their Impact on The Performance of Stateful Network Protocol Fuzzing. (arXiv:2112.15498v1 [cs.SE])]]></title>
        <id>http://arxiv.org/abs/2112.15498</id>
        <link href="http://arxiv.org/abs/2112.15498"/>
        <updated>2022-01-03T07:15:44.201Z</updated>
        <summary type="html"><![CDATA[The statefulness property of network protocol implementations poses a unique
challenge for testing and verification techniques, including Fuzzing. Stateful
fuzzers tackle this challenge by leveraging state models to partition the state
space and assist the test generation process. Since not all states are equally
important and fuzzing campaigns have time limits, fuzzers need effective state
selection algorithms to prioritize progressive states over others. Several
state selection algorithms have been proposed but they were implemented and
evaluated separately on different platforms, making it hard to achieve
conclusive findings. In this work, we evaluate an extensive set of state
selection algorithms on the same fuzzing platform that is AFLNet, a
state-of-the-art fuzzer for network servers. The algorithm set includes
existing ones supported by AFLNet and our novel and principled algorithm called
AFLNetLegion. The experimental results on the ProFuzzBench benchmark show that
(i) the existing state selection algorithms of AFLNet achieve very similar code
coverage, (ii) AFLNetLegion clearly outperforms these algorithms in selected
case studies, but (iii) the overall improvement appears insignificant. These
are unexpected yet interesting findings. We identify problems and share
insights that could open opportunities for future research on this topic.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1"&gt;Dongge Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pham_V/0/1/0/all/0/1"&gt;Van-Thuan Pham&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ernst_G/0/1/0/all/0/1"&gt;Gidon Ernst&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Murray_T/0/1/0/all/0/1"&gt;Toby Murray&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1"&gt;Benjamin I.P. Rubinstein&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transfer learning of phase transitions in percolation and directed percolation. (arXiv:2112.15516v1 [cond-mat.stat-mech])]]></title>
        <id>http://arxiv.org/abs/2112.15516</id>
        <link href="http://arxiv.org/abs/2112.15516"/>
        <updated>2022-01-03T07:15:44.182Z</updated>
        <summary type="html"><![CDATA[The latest advances of statistical physics have shown remarkable performance
of machine learning in identifying phase transitions. In this paper, we apply
domain adversarial neural network (DANN) based on transfer learning to studying
non-equilibrium and equilibrium phase transition models, which are percolation
model and directed percolation (DP) model, respectively. With the DANN, only a
small fraction of input configurations (2d images) needs to be labeled, which
is automatically chosen, in order to capture the critical point. To learn the
DP model, the method is refined by an iterative procedure in determining the
critical point, which is a prerequisite for the data collapse in calculating
the critical exponent $\nu_{\perp}$. We then apply the DANN to a
two-dimensional site percolation with configurations filtered to include only
the largest cluster which may contain the information related to the order
parameter. The DANN learning of both models yields reliable results which are
comparable to the ones from Monte Carlo simulations. Our study also shows that
the DANN can achieve quite high accuracy at much lower cost, compared to the
supervised learning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cond-mat/1/au:+Shen_J/0/1/0/all/0/1"&gt;Jianmin Shen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Liu_F/0/1/0/all/0/1"&gt;Feiyi Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Chen_S/0/1/0/all/0/1"&gt;Shiyang Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Xu_D/0/1/0/all/0/1"&gt;Dian Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Chen_X/0/1/0/all/0/1"&gt;Xiangna Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Deng_S/0/1/0/all/0/1"&gt;Shengfeng Deng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Li_W/0/1/0/all/0/1"&gt;Wei Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Papp_G/0/1/0/all/0/1"&gt;Gabor Papp&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cond-mat/1/au:+Yang_C/0/1/0/all/0/1"&gt;Chunbin Yang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Revisiting Experience Replay: Continual Learning by Adaptively Tuning Task-wise Relationship. (arXiv:2112.15402v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15402</id>
        <link href="http://arxiv.org/abs/2112.15402"/>
        <updated>2022-01-03T07:15:44.175Z</updated>
        <summary type="html"><![CDATA[Continual learning requires models to learn new tasks while maintaining
previously learned knowledge. Various algorithms have been proposed to address
this real challenge. Till now, rehearsal-based methods, such as experience
replay, have achieved state-of-the-art performance. These approaches save a
small part of the data of the past tasks as a memory buffer to prevent models
from forgetting previously learned knowledge. However, most of them treat every
new task equally, i.e., fixed the hyperparameters of the framework while
learning different new tasks. Such a setting lacks the consideration of the
relationship/similarity between past and new tasks. For example, the previous
knowledge/features learned from dogs are more beneficial for the identification
of cats (new task), compared to those learned from buses. In this regard, we
propose a meta learning algorithm based on bi-level optimization to adaptively
tune the relationship between the knowledge extracted from the past and new
tasks. Therefore, the model can find an appropriate direction of gradient
during continual learning and avoid the serious overfitting problem on memory
buffer. Extensive experiments are conducted on three publicly available
datasets (i.e., CIFAR-10, CIFAR-100, and Tiny ImageNet). The experimental
results demonstrate that the proposed method can consistently improve the
performance of all baselines.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1"&gt;Quanziang Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"&gt;Yuexiang Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1"&gt;Dong Wei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1"&gt;Renzhen Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1"&gt;Kai Ma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1"&gt;Yefeng Zheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1"&gt;Deyu Meng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine Learning Trivializing Maps: A First Step Towards Understanding How Flow-Based Samplers Scale Up. (arXiv:2112.15532v1 [hep-lat])]]></title>
        <id>http://arxiv.org/abs/2112.15532</id>
        <link href="http://arxiv.org/abs/2112.15532"/>
        <updated>2022-01-03T07:15:44.163Z</updated>
        <summary type="html"><![CDATA[A trivializing map is a field transformation whose Jacobian determinant
exactly cancels the interaction terms in the action, providing a representation
of the theory in terms of a deterministic transformation of a distribution from
which sampling is trivial. Recently, a proof-of-principle study by Albergo,
Kanwar and Shanahan [arXiv:1904.12072] demonstrated that approximations of
trivializing maps can be `machine-learned' by a class of invertible,
differentiable neural models called \textit{normalizing flows}. By ensuring
that the Jacobian determinant can be computed efficiently, asymptotically exact
sampling from the theory of interest can be performed by drawing samples from a
simple distribution and passing them through the network. From a theoretical
perspective, this approach has the potential to become more efficient than
traditional Markov Chain Monte Carlo sampling techniques, where
autocorrelations severely diminish the sampling efficiency as one approaches
the continuum limit. A major caveat is that it is not yet understood how the
size of models and the cost of training them is expected to scale. As a first
step, we have conducted an exploratory scaling study using two-dimensional
$\phi^4$ with up to $20^2$ lattice sites. Although the scope of our study is
limited to a particular model architecture and training algorithm, initial
results paint an interesting picture in which training costs grow very quickly
indeed. We describe a candidate explanation for the poor scaling, and outline
our intentions to clarify the situation in future work.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/hep-lat/1/au:+Debbio_L/0/1/0/all/0/1"&gt;Luigi Del Debbio&lt;/a&gt;, &lt;a href="http://arxiv.org/find/hep-lat/1/au:+Rossney_J/0/1/0/all/0/1"&gt;Joe Marsh Rossney&lt;/a&gt;, &lt;a href="http://arxiv.org/find/hep-lat/1/au:+Wilson_M/0/1/0/all/0/1"&gt;Michael Wilson&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Disjoint Contrastive Regression Learning for Multi-Sourced Annotations. (arXiv:2112.15411v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15411</id>
        <link href="http://arxiv.org/abs/2112.15411"/>
        <updated>2022-01-03T07:15:44.159Z</updated>
        <summary type="html"><![CDATA[Large-scale datasets are important for the development of deep learning
models. Such datasets usually require a heavy workload of annotations, which
are extremely time-consuming and expensive. To accelerate the annotation
procedure, multiple annotators may be employed to label different subsets of
the data. However, the inconsistency and bias among different annotators are
harmful to the model training, especially for qualitative and subjective
tasks.To address this challenge, in this paper, we propose a novel contrastive
regression framework to address the disjoint annotations problem, where each
sample is labeled by only one annotator and multiple annotators work on
disjoint subsets of the data. To take account of both the intra-annotator
consistency and inter-annotator inconsistency, two strategies are
employed.Firstly, a contrastive-based loss is applied to learn the relative
ranking among different samples of the same annotator, with the assumption that
the ranking of samples from the same annotator is unanimous. Secondly, we apply
the gradient reversal layer to learn robust representations that are invariant
to different annotators. Experiments on the facial expression prediction task,
as well as the image quality assessment task, verify the effectiveness of our
proposed framework.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ruan_X/0/1/0/all/0/1"&gt;Xiaoqian Ruan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1"&gt;Gaoang Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeePN$^2$: A deep learning-based non-Newtonian hydrodynamic model. (arXiv:2112.14798v1 [physics.comp-ph])]]></title>
        <id>http://arxiv.org/abs/2112.14798</id>
        <link href="http://arxiv.org/abs/2112.14798"/>
        <updated>2022-01-03T07:15:44.139Z</updated>
        <summary type="html"><![CDATA[A long standing problem in the modeling of non-Newtonian hydrodynamics is the
availability of reliable and interpretable hydrodynamic models that faithfully
encode the underlying micro-scale polymer dynamics. The main complication
arises from the long polymer relaxation time, the complex molecular structure,
and heterogeneous interaction. DeePN$^2$, a deep learning-based non-Newtonian
hydrodynamic model, has been proposed and has shown some success in
systematically passing the micro-scale structural mechanics information to the
macro-scale hydrodynamics for suspensions with simple polymer conformation and
bond potential. The model retains a multi-scaled nature by mapping the polymer
configurations into a set of symmetry-preserving macro-scale features. The
extended constitutive laws for these macro-scale features can be directly
learned from the kinetics of their micro-scale counterparts. In this paper, we
carry out further study of DeePN$^2$ using more complex micro-structural
models. We show that DeePN$^2$ can faithfully capture the broadly overlooked
viscoelastic differences arising from the specific molecular structural
mechanics without human intervention.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Fang_L/0/1/0/all/0/1"&gt;Lidong Fang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Ge_P/0/1/0/all/0/1"&gt;Pei Ge&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Zhang_L/0/1/0/all/0/1"&gt;Lei Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Lei_H/0/1/0/all/0/1"&gt;Huan Lei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+E_W/0/1/0/all/0/1"&gt;Weinan E&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Measuring and Sampling: A Metric-guided Subgraph Learning Framework for Graph Neural Network. (arXiv:2112.15015v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15015</id>
        <link href="http://arxiv.org/abs/2112.15015"/>
        <updated>2022-01-03T07:15:44.132Z</updated>
        <summary type="html"><![CDATA[Graph neural network (GNN) has shown convincing performance in learning
powerful node representations that preserve both node attributes and graph
structural information. However, many GNNs encounter problems in effectiveness
and efficiency when they are designed with a deeper network structure or handle
large-sized graphs. Several sampling algorithms have been proposed for
improving and accelerating the training of GNNs, yet they ignore understanding
the source of GNN performance gain. The measurement of information within graph
data can help the sampling algorithms to keep high-value information while
removing redundant information and even noise. In this paper, we propose a
Metric-Guided (MeGuide) subgraph learning framework for GNNs. MeGuide employs
two novel metrics: Feature Smoothness and Connection Failure Distance to guide
the subgraph sampling and mini-batch based training. Feature Smoothness is
designed for analyzing the feature of nodes in order to retain the most
valuable information, while Connection Failure Distance can measure the
structural information to control the size of subgraphs. We demonstrate the
effectiveness and efficiency of MeGuide in training various GNNs on multiple
datasets.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1"&gt;Jiyang Bai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1"&gt;Yuxiang Ren&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1"&gt;Jiawei Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Unified and Constructive Framework for the Universality of Neural Networks. (arXiv:2112.14877v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14877</id>
        <link href="http://arxiv.org/abs/2112.14877"/>
        <updated>2022-01-03T07:15:44.125Z</updated>
        <summary type="html"><![CDATA[One of the reasons that many neural networks are capable of replicating
complicated tasks or functions is their universality property. The past few
decades have seen many attempts in providing constructive proofs for single or
class of neural networks. This paper is an effort to provide a unified and
constructive framework for the universality of a large class of activations
including most of existing activations and beyond. At the heart of the
framework is the concept of neural network approximate identity. It turns out
that most of existing activations are neural network approximate identity, and
thus universal in the space of continuous of functions on compacta. The
framework induces several advantages. First, it is constructive with elementary
means from functional analysis, probability theory, and numerical analysis.
Second, it is the first unified attempt that is valid for most of existing
activations. Third, as a by product, the framework provides the first
university proof for some of the existing activation functions including Mish,
SiLU, ELU, GELU, and etc. Fourth, it discovers new activations with guaranteed
universality property. Indeed, any activation\textemdash whose $\k$th
derivative, with $\k$ being an integer, is integrable and essentially
bounded\textemdash is universal. Fifth, for a given activation and error
tolerance, the framework provides precisely the architecture of the
corresponding one-hidden neural network with predetermined number of neuron,
and the values of weights/biases.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bui_Thanh_T/0/1/0/all/0/1"&gt;Tan Bui-Thanh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Survey Descent: A Multipoint Generalization of Gradient Descent for Nonsmooth Optimization. (arXiv:2111.15645v2 [math.OC] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.15645</id>
        <link href="http://arxiv.org/abs/2111.15645"/>
        <updated>2022-01-03T07:15:44.106Z</updated>
        <summary type="html"><![CDATA[For strongly convex objectives that are smooth, the classical theory of
gradient descent ensures linear convergence relative to the number of gradient
evaluations. An analogous nonsmooth theory is challenging: even when the
objective is smooth at every iterate, the corresponding local models are
unstable, and traditional remedies need unpredictably many cutting planes. We
instead propose a multipoint generalization of the gradient descent iteration
for local optimization. While designed with general objectives in mind, we are
motivated by a "max-of-smooth" model that captures subdifferential dimension at
optimality. We prove linear convergence when the objective is itself
max-of-smooth, and experiments suggest a more general phenomenon.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Han_X/0/1/0/all/0/1"&gt;X.Y. Han&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Lewis_A/0/1/0/all/0/1"&gt;Adrian S. Lewis&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drone. (arXiv:2112.12545v2 [math.OC] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.12545</id>
        <link href="http://arxiv.org/abs/2112.12545"/>
        <updated>2022-01-03T07:15:43.983Z</updated>
        <summary type="html"><![CDATA[Reinforcement learning has recently shown promise in learning quality
solutions in many combinatorial optimization problems. In particular, the
attention-based encoder-decoder models show high effectiveness on various
routing problems, including the Traveling Salesman Problem (TSP).
Unfortunately, they perform poorly for the TSP with Drone (TSP-D), requiring
routing a heterogeneous fleet of vehicles in coordination -- a truck and a
drone. In TSP-D, the two vehicles are moving in tandem and may need to wait at
a node for the other vehicle to join. State-less attention-based decoder fails
to make such coordination between vehicles. We propose an attention
encoder-LSTM decoder hybrid model, in which the decoder's hidden state can
represent the sequence of actions made. We empirically demonstrate that such a
hybrid model improves upon a purely attention-based model for both solution
quality and computational efficiency. Our experiments on the min-max
Capacitated Vehicle Routing Problem (mmCVRP) also confirm that the hybrid model
is more suitable for coordinated routing of multiple vehicles than the
attention-based model.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Bogyrbayeva_A/0/1/0/all/0/1"&gt;Aigerim Bogyrbayeva&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Yoon_T/0/1/0/all/0/1"&gt;Taehyun Yoon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Ko_H/0/1/0/all/0/1"&gt;Hanbum Ko&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Lim_S/0/1/0/all/0/1"&gt;Sungbin Lim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Yun_H/0/1/0/all/0/1"&gt;Hyokun Yun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Kwon_C/0/1/0/all/0/1"&gt;Changhyun Kwon&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Random Graph-Based Neuromorphic Learning with a Layer-Weaken Structure. (arXiv:2111.08888v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.08888</id>
        <link href="http://arxiv.org/abs/2111.08888"/>
        <updated>2022-01-03T07:15:43.972Z</updated>
        <summary type="html"><![CDATA[Unified understanding of neuro networks (NNs) gets the users into great
trouble because they have been puzzled by what kind of rules should be obeyed
to optimize the internal structure of NNs. Considering the potential capability
of random graphs to alter how computation is performed, we demonstrate that
they can serve as architecture generators to optimize the internal structure of
NNs. To transform the random graph theory into an NN model with practical
meaning and based on clarifying the input-output relationship of each neuron,
we complete data feature mapping by calculating Fourier Random Features (FRFs).
Under the usage of this low-operation cost approach, neurons are assigned to
several groups of which connection relationships can be regarded as uniform
representations of random graphs they belong to, and random arrangement fuses
those neurons to establish the pattern matrix, markedly reducing manual
participation and computational cost without the fixed and deep architecture.
Leveraging this single neuromorphic learning model termed random graph-based
neuro network (RGNN) we develop a joint classification mechanism involving
information interaction between multiple RGNNs and realize significant
performance improvements in supervised learning for three benchmark tasks,
whereby they effectively avoid the adverse impact of the interpretability of
NNs on the structure design and engineering practice.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Mao_R/0/1/0/all/0/1"&gt;Ruiqi Mao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cui_R/0/1/0/all/0/1"&gt;Rongxin Cui&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Benign Overfitting in Adversarially Robust Linear Classification. (arXiv:2112.15250v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15250</id>
        <link href="http://arxiv.org/abs/2112.15250"/>
        <updated>2022-01-03T07:15:43.964Z</updated>
        <summary type="html"><![CDATA["Benign overfitting", where classifiers memorize noisy training data yet
still achieve a good generalization performance, has drawn great attention in
the machine learning community. To explain this surprising phenomenon, a series
of works have provided theoretical justification in over-parameterized linear
regression, classification, and kernel methods. However, it is not clear if
benign overfitting still occurs in the presence of adversarial examples, i.e.,
examples with tiny and intentional perturbations to fool the classifiers. In
this paper, we show that benign overfitting indeed occurs in adversarial
training, a principled approach to defend against adversarial examples. In
detail, we prove the risk bounds of the adversarially trained linear classifier
on the mixture of sub-Gaussian data under $\ell_p$ adversarial perturbations.
Our result suggests that under moderate perturbations, adversarially trained
linear classifiers can achieve the near-optimal standard and adversarial risks,
despite overfitting the noisy training data. Numerical experiments validate our
theoretical findings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"&gt;Jinghui Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"&gt;Yuan Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ifMixup: Towards Intrusion-Free Graph Mixup for Graph Classification. (arXiv:2110.09344v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.09344</id>
        <link href="http://arxiv.org/abs/2110.09344"/>
        <updated>2022-01-03T07:15:43.940Z</updated>
        <summary type="html"><![CDATA[We present a simple and yet effective interpolation-based regularization
technique to improve the generalization of Graph Neural Networks (GNNs). Our
method leverages the recent advances in Mixup regularizer for vision and text,
where random sample pairs and their labels are interpolated to create synthetic
samples for training. Unlike images or natural sentences, graphs have arbitrary
structure and topology, and even simply deleting or adding one edge from a
graph can dramatically change its semantic meanings. This makes interpolating
graph inputs very challenging because mixing graph pairs may naturally create
graphs with identical structure but with conflict labels, causing the manifold
intrusion issue. To cope with this obstacle, we propose a simple input mixing
schema for Mixup on graph, coined ifMixup. We theoretically prove that, with a
mild assumption, ifMixup guarantees that the mixed graphs are manifold
intrusion free. We also empirically verify that ifMixup can effectively
regularize the graph classification learning, resulting in superior predictive
accuracy over popular graph augmentation baselines.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1"&gt;Hongyu Guo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1"&gt;Yongyi Mao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerated Primal-Dual Gradient Method for Smooth and Convex-Concave Saddle-Point Problems with Bilinear Coupling. (arXiv:2112.15199v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2112.15199</id>
        <link href="http://arxiv.org/abs/2112.15199"/>
        <updated>2022-01-03T07:15:43.937Z</updated>
        <summary type="html"><![CDATA[In this paper we study a convex-concave saddle-point problem $\min_x\max_y
f(x) + y^\top\mathbf{A} x - g(y)$, where $f(x)$ and $g(y)$ are smooth and
convex functions. We propose an Accelerated Primal-Dual Gradient Method for
solving this problem which (i) achieves an optimal linear convergence rate in
the strongly-convex-strongly-concave regime matching the lower complexity bound
(Zhang et al., 2021) and (ii) achieves an accelerated linear convergence rate
in the case when only one of the functions $f(x)$ and $g(y)$ is strongly convex
or even none of them are. Finally, we obtain a linearly-convergent algorithm
for the general smooth and convex-concave saddle point problem $\min_x\max_y
F(x,y)$ without requirement of strong convexity or strong concavity.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Kovalev_D/0/1/0/all/0/1"&gt;Dmitry Kovalev&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1"&gt;Alexander Gasnikov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Richtarik_P/0/1/0/all/0/1"&gt;Peter Richt&amp;#xe1;rik&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More. (arXiv:2112.15594v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15594</id>
        <link href="http://arxiv.org/abs/2112.15594"/>
        <updated>2022-01-03T07:15:43.925Z</updated>
        <summary type="html"><![CDATA[We demonstrate that a neural network pre-trained on text and fine-tuned on
code solves Mathematics problems by program synthesis. We turn questions into
programming tasks, automatically generate programs, and then execute them,
perfectly solving university-level problems from MIT's large Mathematics
courses (Single Variable Calculus 18.01, Multivariable Calculus 18.02,
Differential Equations 18.03, Introduction to Probability and Statistics 18.05,
Linear Algebra 18.06, and Mathematics for Computer Science 6.042) as well as
questions from a MATH dataset (on Prealgebra, Algebra, Counting and
Probability, Number Theory, and Precalculus), the latest benchmark of advanced
mathematics problems specifically designed to assess mathematical reasoning. We
explore prompt generation methods that enable Transformers to generate question
solving programs for these subjects, including solutions with plots. We
generate correct answers for a random sample of questions in each topic. We
quantify the gap between the original and transformed questions and perform a
survey to evaluate the quality and difficulty of generated questions. This is
the first work to automatically solve, grade, and generate university-level
Mathematics course questions at scale which represents a milestone for higher
education.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Drori_I/0/1/0/all/0/1"&gt;Iddo Drori&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tran_S/0/1/0/all/0/1"&gt;Sunny Tran&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1"&gt;Roman Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1"&gt;Newman Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1"&gt;Kevin Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1"&gt;Leonard Tang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ke_E/0/1/0/all/0/1"&gt;Elizabeth Ke&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Singh_N/0/1/0/all/0/1"&gt;Nikhil Singh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Patti_T/0/1/0/all/0/1"&gt;Taylor L. Patti&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lynch_J/0/1/0/all/0/1"&gt;Jayson Lynch&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shporer_A/0/1/0/all/0/1"&gt;Avi Shporer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Verma_N/0/1/0/all/0/1"&gt;Nakul Verma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_E/0/1/0/all/0/1"&gt;Eugene Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Strang_G/0/1/0/all/0/1"&gt;Gilbert Strang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unintended Selection: Persistent Qualification Rate Disparities and Interventions. (arXiv:2111.01201v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.01201</id>
        <link href="http://arxiv.org/abs/2111.01201"/>
        <updated>2022-01-03T07:15:43.920Z</updated>
        <summary type="html"><![CDATA[Realistically -- and equitably -- modeling the dynamics of group-level
disparities in machine learning remains an open problem. In particular, we
desire models that do not suppose inherent differences between artificial
groups of people -- but rather endogenize disparities by appeal to unequal
initial conditions of insular subpopulations. In this paper, agents each have a
real-valued feature $X$ (e.g., credit score) informed by a "true" binary label
$Y$ representing qualification (e.g., for a loan). Each agent alternately (1)
receives a binary classification label $\hat{Y}$ (e.g., loan approval) from a
Bayes-optimal machine learning classifier observing $X$ and (2) may update
their qualification $Y$ by imitating successful strategies (e.g., seek a raise)
within an isolated group $G$ of agents to which they belong. We consider the
disparity of qualification rates $\Pr(Y=1)$ between different groups and how
this disparity changes subject to a sequence of Bayes-optimal classifiers
repeatedly retrained on the global population. We model the evolving
qualification rates of each subpopulation (group) using the replicator
equation, which derives from a class of imitation processes. We show that
differences in qualification rates between subpopulations can persist
indefinitely for a set of non-trivial equilibrium states due to uniformed
classifier deployments, even when groups are identical in all aspects except
initial qualification densities. We next simulate the effects of commonly
proposed fairness interventions on this dynamical system along with a new
feedback control mechanism capable of permanently eliminating group-level
qualification rate disparities. We conclude by discussing the limitations of
our model and findings and by outlining potential future work.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Raab_R/0/1/0/all/0/1"&gt;Reilly Raab&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yang Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[on the effectiveness of generative adversarial network on anomaly detection. (arXiv:2112.15541v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15541</id>
        <link href="http://arxiv.org/abs/2112.15541"/>
        <updated>2022-01-03T07:15:43.908Z</updated>
        <summary type="html"><![CDATA[Identifying anomalies refers to detecting samples that do not resemble the
training data distribution. Many generative models have been used to find
anomalies, and among them, generative adversarial network (GAN)-based
approaches are currently very popular. GANs mainly rely on the rich contextual
information of these models to identify the actual training distribution.
Following this analogy, we suggested a new unsupervised model based on GANs --a
combination of an autoencoder and a GAN. Further, a new scoring function was
introduced to target anomalies where a linear combination of the internal
representation of the discriminator and the generator's visual representation,
plus the encoded representation of the autoencoder, come together to define the
proposed anomaly score. The model was further evaluated on benchmark datasets
such as SVHN, CIFAR10, and MNIST, as well as a public medical dataset of
leukemia images. In all the experiments, our model outperformed its existing
counterparts while slightly improving the inference time.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sevyeri_L/0/1/0/all/0/1"&gt;Laya Rafiee Sevyeri&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fevens_T/0/1/0/all/0/1"&gt;Thomas Fevens&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reward-Free Model-Based Reinforcement Learning with Linear Function Approximation. (arXiv:2110.06394v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.06394</id>
        <link href="http://arxiv.org/abs/2110.06394"/>
        <updated>2022-01-03T07:15:43.908Z</updated>
        <summary type="html"><![CDATA[We study the model-based reward-free reinforcement learning with linear
function approximation for episodic Markov decision processes (MDPs). In this
setting, the agent works in two phases. In the exploration phase, the agent
interacts with the environment and collects samples without the reward. In the
planning phase, the agent is given a specific reward function and uses samples
collected from the exploration phase to learn a good policy. We propose a new
provably efficient algorithm, called UCRL-RFE under the Linear Mixture MDP
assumption, where the transition probability kernel of the MDP can be
parameterized by a linear function over certain feature mappings defined on the
triplet of state, action, and next state. We show that to obtain an
$\epsilon$-optimal policy for arbitrary reward function, UCRL-RFE needs to
sample at most $\tilde{\mathcal{O}}(H^5d^2\epsilon^{-2})$ episodes during the
exploration phase. Here, $H$ is the length of the episode, $d$ is the dimension
of the feature mapping. We also propose a variant of UCRL-RFE using
Bernstein-type bonus and show that it needs to sample at most
$\tilde{\mathcal{O}}(H^4d(H + d)\epsilon^{-2})$ to achieve an
$\epsilon$-optimal policy. By constructing a special class of linear Mixture
MDPs, we also prove that for any reward-free algorithm, it needs to sample at
least $\tilde \Omega(H^2d\epsilon^{-2})$ episodes to obtain an
$\epsilon$-optimal policy. Our upper bound matches the lower bound in terms of
the dependence on $\epsilon$ and the dependence on $d$ if $H \ge d$.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1"&gt;Weitong Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluation of Interpretability for Deep Learning algorithms in EEG Emotion Recognition: A case study in Autism. (arXiv:2111.13208v2 [eess.SP] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.13208</id>
        <link href="http://arxiv.org/abs/2111.13208"/>
        <updated>2022-01-03T07:15:43.906Z</updated>
        <summary type="html"><![CDATA[Current models on Explainable Artificial Intelligence (XAI) have shown an
evident and quantified lack of reliability for measuring feature-relevance when
statistically entangled features are proposed for training deep classifiers.
There has been an increase in the application of Deep Learning in clinical
trials to predict early diagnosis of neuro-developmental disorders, such as
Autism Spectrum Disorder (ASD). However, the inclusion of more reliable
saliency-maps to obtain more trustworthy and interpretable metrics using neural
activity features is still insufficiently mature for practical applications in
diagnostics or clinical trials. Moreover, in ASD research the inclusion of deep
classifiers that use neural measures to predict viewed facial emotions is
relatively unexplored. Therefore, in this study we propose the evaluation of a
Convolutional Neural Network (CNN) for electroencephalography (EEG)-based
facial emotion recognition decoding complemented with a novel
RemOve-And-Retrain (ROAR) methodology to recover highly relevant features used
in the classifier. Specifically, we compare well-known relevance maps such as
Layer-Wise Relevance Propagation (LRP), PatternNet, Pattern-Attribution, and
Smooth-Grad Squared. This study is the first to consolidate a more transparent
feature-relevance calculation for a successful EEG-based facial emotion
recognition using a within-subject-trained CNN in typically-developed and ASD
individuals.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Mayor_Torres_J/0/1/0/all/0/1"&gt;Juan Manuel Mayor-Torres&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Medina_DeVilliers_S/0/1/0/all/0/1"&gt;Sara Medina-DeVilliers&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Clarkson_T/0/1/0/all/0/1"&gt;Tessa Clarkson&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Lerner_M/0/1/0/all/0/1"&gt;Matthew D. Lerner&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Riccardi_G/0/1/0/all/0/1"&gt;Giuseppe Riccardi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Expected hypervolume improvement for simultaneous multi-objective and multi-fidelity optimization. (arXiv:2112.13901v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.13901</id>
        <link href="http://arxiv.org/abs/2112.13901"/>
        <updated>2022-01-03T07:15:43.897Z</updated>
        <summary type="html"><![CDATA[Bayesian optimization has proven to be an efficient method to optimize
expensive-to-evaluate systems. However, depending on the cost of single
observations, multi-dimensional optimizations of one or more objectives may
still be prohibitively expensive. Multi-fidelity optimization remedies this
issue by including multiple, cheaper information sources such as low-resolution
approximations in numerical simulations. Acquisition functions for
multi-fidelity optimization are typically based on exploration-heavy algorithms
that are difficult to combine with optimization towards multiple objectives.

Here we show that the expected hypervolume improvement policy can act in many
situations as a suitable substitute. We incorporate the evaluation cost either
via a two-step evaluation or within a single acquisition function with an
additional fidelity-related objective. This permits simultaneous
multi-objective and multi-fidelity optimization, which allows to accurately
establish the Pareto set and front at fractional cost. Benchmarks show a cost
reduction of an order of magnitude or more. Our method thus allows for Pareto
optimization of extremely expansive black-box functions.

The presented methods are simple and straightforward to implement in
existing, optimized Bayesian optimization frameworks and can immediately be
extended to batch optimization. The techniques can also be used to combine
different continuous and/or discrete fidelity dimensions, which makes them
particularly relevant for simulation problems in plasma physics, fluid dynamics
and many other branches of scientific computing.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Irshad_F/0/1/0/all/0/1"&gt;Faran Irshad&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Karsch_S/0/1/0/all/0/1"&gt;Stefan Karsch&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dopp_A/0/1/0/all/0/1"&gt;Andreas D&amp;#xf6;pp&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SGTR: End-to-end Scene Graph Generation with Transformer. (arXiv:2112.12970v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.12970</id>
        <link href="http://arxiv.org/abs/2112.12970"/>
        <updated>2022-01-03T07:15:43.896Z</updated>
        <summary type="html"><![CDATA[Scene Graph Generation (SGG) remains a challenging visual understanding task
due to its complex compositional property. Most previous works adopt a
bottom-up two-stage or a point-based one-stage approach, which often suffers
from overhead time complexity or sub-optimal design assumption. In this work,
we propose a novel SGG method to address the aforementioned issues, which
formulates the task as a bipartite graph construction problem. To solve the
problem, we develop a transformer-based end-to-end framework that first
generates the entity and predicate proposal set, followed by inferring directed
edges to form the relation triplets. In particular, we develop a new
entity-aware predicate representation based on a structural predicate generator
to leverage the compositional property of relationships. Moreover, we design a
graph assembling module to infer the connectivity of the bipartite scene graph
based on our entity-aware structure, enabling us to generate the scene graph in
an end-to-end manner. Extensive experimental results show that our design is
able to achieve the state-of-the-art or comparable performance on two
challenging benchmarks, surpassing most of the existing approaches and enjoying
higher efficiency in inference. We hope our model can serve as a strong
baseline for the Transformer-based scene graph generation.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1"&gt;Rongjie Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"&gt;Songyang Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1"&gt;Xuming He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Thompson Sampling. (arXiv:2010.00827v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.00827</id>
        <link href="http://arxiv.org/abs/2010.00827"/>
        <updated>2022-01-03T07:15:43.890Z</updated>
        <summary type="html"><![CDATA[Thompson Sampling (TS) is one of the most effective algorithms for solving
contextual multi-armed bandit problems. In this paper, we propose a new
algorithm, called Neural Thompson Sampling, which adapts deep neural networks
for both exploration and exploitation. At the core of our algorithm is a novel
posterior distribution of the reward, where its mean is the neural network
approximator, and its variance is built upon the neural tangent features of the
corresponding neural network. We prove that, provided the underlying reward
function is bounded, the proposed algorithm is guaranteed to achieve a
cumulative regret of $\mathcal{O}(T^{1/2})$, which matches the regret of other
contextual bandit algorithms in terms of total round number $T$. Experimental
comparisons with other benchmark bandit algorithms on various data sets
corroborate our theory.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1"&gt;Weitong Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"&gt;Lihong Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Infinite wide (finite depth) Neural Networks benefit from multi-task learning unlike shallow Gaussian Processes -- an exact quantitative macroscopic characterization. (arXiv:2112.15577v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15577</id>
        <link href="http://arxiv.org/abs/2112.15577"/>
        <updated>2022-01-03T07:15:43.884Z</updated>
        <summary type="html"><![CDATA[We prove in this paper that wide ReLU neural networks (NNs) with at least one
hidden layer optimized with l2-regularization on the parameters enforces
multi-task learning due to representation-learning - also in the limit width to
infinity. This is in contrast to multiple other idealized settings discussed in
the literature where wide (ReLU)-NNs loose their ability to benefit from
multi-task learning in the limit width to infinity. We deduce the multi-task
learning ability from proving an exact quantitative macroscopic
characterization of the learned NN in function space.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Heiss_J/0/1/0/all/0/1"&gt;Jakob Heiss&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Teichmann_J/0/1/0/all/0/1"&gt;Josef Teichmann&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wutte_H/0/1/0/all/0/1"&gt;Hanna Wutte&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Efficient Epileptic Seizure Detection Technique using Discrete Wavelet Transform and Machine Learning Classifiers. (arXiv:2109.13811v2 [eess.SP] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.13811</id>
        <link href="http://arxiv.org/abs/2109.13811"/>
        <updated>2022-01-03T07:15:43.873Z</updated>
        <summary type="html"><![CDATA[This paper presents an epilepsy detection method based on discrete wavelet
transform (DWT) and Machine learning classifiers. Here DWT has been used for
feature extraction as it provides a better decomposition of the signals in
different frequency bands. At first, DWT has been applied to the EEG signal to
extract the detail and approximate coefficients or different sub-bands. After
the extraction of the coefficients, principal component analysis (PCA) has been
applied on different sub-bands and then a feature level fusion technique is
used to extract the important features in low dimensional feature space. Three
classifiers namely: Support Vector Machine (SVM) classifier, K-Nearest-Neighbor
(KNN) classifier, and Naive Bayes (NB) Classifiers have been used in the
proposed work for classifying the EEG signals. The proposed method is tested on
Bonn databases and provides a maximum of 100% recognition accuracy for KNN,
SVM, NB classifiers.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Guharoy_R/0/1/0/all/0/1"&gt;Rabel Guharoy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Jana_N/0/1/0/all/0/1"&gt;Nanda Dulal Jana&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Biswas_S/0/1/0/all/0/1"&gt;Suparna Biswas&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BiTr-Unet: a CNN-Transformer Combined Network for MRI Brain Tumor Segmentation. (arXiv:2109.12271v2 [eess.IV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.12271</id>
        <link href="http://arxiv.org/abs/2109.12271"/>
        <updated>2022-01-03T07:15:43.862Z</updated>
        <summary type="html"><![CDATA[Convolutional neural networks (CNNs) have achieved remarkable success in
automatically segmenting organs or lesions on 3D medical images. Recently,
vision transformer networks have exhibited exceptional performance in 2D image
classification tasks. Compared with CNNs, transformer networks have an
appealing advantage of extracting long-range features due to their
self-attention algorithm. Therefore, we propose a CNN-Transformer combined
model, called BiTr-Unet, with specific modifications for brain tumor
segmentation on multi-modal MRI scans. Our BiTr-Unet achieves good performance
on the BraTS2021 validation dataset with median Dice score 0.9335, 0.9304 and
0.8899, and median Hausdorff distance 2.8284, 2.2361 and 1.4142 for the whole
tumor, tumor core, and enhancing tumor, respectively. On the BraTS2021 testing
dataset, the corresponding results are 0.9257, 0.9350 and 0.8874 for Dice
score, and 3, 2.2361 and 1.4142 for Hausdorff distance. The code is publicly
available at https://github.com/JustaTinyDot/BiTr-Unet.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Jia_Q/0/1/0/all/0/1"&gt;Qiran Jia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Shu_H/0/1/0/all/0/1"&gt;Hai Shu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Single-Shot Pruning for Offline Reinforcement Learning. (arXiv:2112.15579v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15579</id>
        <link href="http://arxiv.org/abs/2112.15579"/>
        <updated>2022-01-03T07:15:43.849Z</updated>
        <summary type="html"><![CDATA[Deep Reinforcement Learning (RL) is a powerful framework for solving complex
real-world problems. Large neural networks employed in the framework are
traditionally associated with better generalization capabilities, but their
increased size entails the drawbacks of extensive training duration,
substantial hardware resources, and longer inference times. One way to tackle
this problem is to prune neural networks leaving only the necessary parameters.
State-of-the-art concurrent pruning techniques for imposing sparsity perform
demonstrably well in applications where data distributions are fixed. However,
they have not yet been substantially explored in the context of RL. We close
the gap between RL and single-shot pruning techniques and present a general
pruning approach to the Offline RL. We leverage a fixed dataset to prune neural
networks before the start of RL training. We then run experiments varying the
network sparsity level and evaluating the validity of pruning at initialization
techniques in continuous control tasks. Our results show that with 95% of the
network weights pruned, Offline-RL algorithms can still retain performance in
the majority of our experiments. To the best of our knowledge, no prior work
utilizing pruning in RL retained performance at such high levels of sparsity.

Moreover, pruning at initialization techniques can be easily integrated into
any existing Offline-RL algorithms without changing the learning objective.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Arnob_S/0/1/0/all/0/1"&gt;Samin Yeasar Arnob&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ohib_R/0/1/0/all/0/1"&gt;Riyasat Ohib&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Plis_S/0/1/0/all/0/1"&gt;Sergey Plis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1"&gt;Doina Precup&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hamiltonian Dynamics with Non-Newtonian Momentum for Rapid Sampling. (arXiv:2111.02434v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2111.02434</id>
        <link href="http://arxiv.org/abs/2111.02434"/>
        <updated>2022-01-03T07:15:43.848Z</updated>
        <summary type="html"><![CDATA[Sampling from an unnormalized probability distribution is a fundamental
problem in machine learning with applications including Bayesian modeling,
latent factor inference, and energy-based model training. After decades of
research, variations of MCMC remain the default approach to sampling despite
slow convergence. Auxiliary neural models can learn to speed up MCMC, but the
overhead for training the extra model can be prohibitive. We propose a
fundamentally different approach to this problem via a new Hamiltonian dynamics
with a non-Newtonian momentum. In contrast to MCMC approaches like Hamiltonian
Monte Carlo, no stochastic step is required. Instead, the proposed
deterministic dynamics in an extended state space exactly sample the target
distribution, specified by an energy function, under an assumption of
ergodicity. Alternatively, the dynamics can be interpreted as a normalizing
flow that samples a specified energy model without training. The proposed
Energy Sampling Hamiltonian (ESH) dynamics have a simple form that can be
solved with existing ODE solvers, but we derive a specialized solver that
exhibits much better performance. ESH dynamics converge faster than their MCMC
competitors enabling faster, more stable training of neural network energy
models.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1"&gt;Greg Ver Steeg&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1"&gt;Aram Galstyan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representation Learning via Consistent Assignment of Views to Clusters. (arXiv:2112.15421v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15421</id>
        <link href="http://arxiv.org/abs/2112.15421"/>
        <updated>2022-01-03T07:15:43.847Z</updated>
        <summary type="html"><![CDATA[We introduce Consistent Assignment for Representation Learning (CARL), an
unsupervised learning method to learn visual representations by combining ideas
from self-supervised contrastive learning and deep clustering. By viewing
contrastive learning from a clustering perspective, CARL learns unsupervised
representations by learning a set of general prototypes that serve as energy
anchors to enforce different views of a given image to be assigned to the same
prototype. Unlike contemporary work on contrastive learning with deep
clustering, CARL proposes to learn the set of general prototypes in an online
fashion, using gradient descent without the necessity of using
non-differentiable algorithms or K-Means to solve the cluster assignment
problem. CARL surpasses its competitors in many representations learning
benchmarks, including linear evaluation, semi-supervised learning, and transfer
learning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Silva_T/0/1/0/all/0/1"&gt;Thalles Silva&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rivera_A/0/1/0/all/0/1"&gt;Ad&amp;#xed;n Ram&amp;#xed;rez Rivera&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[From Twitter to Traffic Predictor: Next-Day Morning Traffic Prediction Using Social Media Data. (arXiv:2009.13794v3 [cs.SI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2009.13794</id>
        <link href="http://arxiv.org/abs/2009.13794"/>
        <updated>2022-01-03T07:15:43.846Z</updated>
        <summary type="html"><![CDATA[The effectiveness of traditional traffic prediction methods is often
extremely limited when forecasting traffic dynamics in early morning. The
reason is that traffic can break down drastically during the early morning
commute, and the time and duration of this break-down vary substantially from
day to day. Early morning traffic forecast is crucial to inform morning-commute
traffic management, but they are generally challenging to predict in advance,
particularly by midnight. In this paper, we propose to mine Twitter messages as
a probing method to understand the impacts of people's work and rest patterns
in the evening/midnight of the previous day to the next-day morning traffic.
The model is tested on freeway networks in Pittsburgh as experiments. The
resulting relationship is surprisingly simple and powerful. We find that, in
general, the earlier people rest as indicated from Tweets, the more congested
roads will be in the next morning. The occurrence of big events in the evening
before, represented by higher or lower tweet sentiment than normal, often
implies lower travel demand in the next morning than normal days. Besides,
people's tweeting activities in the night before and early morning are
statistically associated with congestion in morning peak hours. We make use of
such relationships to build a predictive framework which forecasts morning
commute congestion using people's tweeting profiles extracted by 5 am or as
late as the midnight prior to the morning. The Pittsburgh study supports that
our framework can precisely predict morning congestion, particularly for some
road segments upstream of roadway bottlenecks with large day-to-day congestion
variation. Our approach considerably outperforms those existing methods without
Twitter message features, and it can learn meaningful representation of demand
from tweeting profiles that offer managerial insights.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1"&gt;Weiran Yao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1"&gt;Sean Qian&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PCACE: A Statistical Approach to Ranking Neurons for CNN Interpretability. (arXiv:2112.15571v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2112.15571</id>
        <link href="http://arxiv.org/abs/2112.15571"/>
        <updated>2022-01-03T07:15:43.843Z</updated>
        <summary type="html"><![CDATA[In this paper we introduce a new problem within the growing literature of
interpretability for convolution neural networks (CNNs). While previous work
has focused on the question of how to visually interpret CNNs, we ask what it
is that we care to interpret, that is, which layers and neurons are worth our
attention? Due to the vast size of modern deep learning network architectures,
automated, quantitative methods are needed to rank the relative importance of
neurons so as to provide an answer to this question. We present a new
statistical method for ranking the hidden neurons in any convolutional layer of
a network. We define importance as the maximal correlation between the
activation maps and the class score. We provide different ways in which this
method can be used for visualization purposes with MNIST and ImageNet, and show
a real-world application of our method to air pollution prediction with
street-level images.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Casacuberta_S/0/1/0/all/0/1"&gt;S&amp;#xed;lvia Casacuberta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Suel_E/0/1/0/all/0/1"&gt;Esra Suel&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Flaxman_S/0/1/0/all/0/1"&gt;Seth Flaxman&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine learning based disease diagnosis: A comprehensive review. (arXiv:2112.15538v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15538</id>
        <link href="http://arxiv.org/abs/2112.15538"/>
        <updated>2022-01-03T07:15:43.842Z</updated>
        <summary type="html"><![CDATA[Globally, there is a substantial unmet need to diagnose various diseases
effectively. The complexity of the different disease mechanisms and underlying
symptoms of the patient population presents massive challenges to developing
the early diagnosis tool and effective treatment. Machine Learning (ML), an
area of Artificial Intelligence (AI), enables researchers, physicians, and
patients to solve some of these issues. Based on relevant research, this review
explains how Machine Learning (ML) and Deep Learning (DL) are being used to
help in the early identification of numerous diseases. To begin, a bibliometric
study of the publication is given using data from the Scopus and Web of Science
(WOS) databases. The bibliometric study of 1216 publications was undertaken to
determine the most prolific authors, nations, organizations, and most cited
articles. The review then summarizes the most recent trends and approaches in
Machine Learning-based Disease Diagnosis (MLBDD), considering the following
factors: algorithm, disease types, data type, application, and evaluation
metrics. Finally, the paper highlights key results and provides insight into
future trends and opportunities in the MLBDD area.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ahsan_M/0/1/0/all/0/1"&gt;Md Manjurul Ahsan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Siddique_Z/0/1/0/all/0/1"&gt;Zahed Siddique&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BERTphone: Phonetically-Aware Encoder Representations for Utterance-Level Speaker and Language Recognition. (arXiv:1907.00457v2 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1907.00457</id>
        <link href="http://arxiv.org/abs/1907.00457"/>
        <updated>2022-01-03T07:15:43.839Z</updated>
        <summary type="html"><![CDATA[We introduce BERTphone, a Transformer encoder trained on large speech corpora
that outputs phonetically-aware contextual representation vectors that can be
used for both speaker and language recognition. This is accomplished by
training on two objectives: the first, inspired by adapting BERT to the
continuous domain, involves masking spans of input frames and reconstructing
the whole sequence for acoustic representation learning; the second, inspired
by the success of bottleneck features from ASR, is a sequence-level CTC loss
applied to phoneme labels for phonetic representation learning. We pretrain two
BERTphone models (one on Fisher and one on TED-LIUM) and use them as feature
extractors into x-vector-style DNNs for both tasks. We attain a
state-of-the-art $C_{\text{avg}}$ of 6.16 on the challenging LRE07 3sec
closed-set language recognition task. On Fisher and VoxCeleb speaker
recognition tasks, we see an 18% relative reduction in speaker EER when
training on BERTphone vectors instead of MFCCs. In general, BERTphone
outperforms previous phonetic pretraining approaches on the same data. We
release our code and models at
https://github.com/awslabs/speech-representations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ling_S/0/1/0/all/0/1"&gt;Shaoshi Ling&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Salazar_J/0/1/0/all/0/1"&gt;Julian Salazar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yuzong Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kirchhoff_K/0/1/0/all/0/1"&gt;Katrin Kirchhoff&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data-driven advice for interpreting local and global model predictions in bioinformatics problems. (arXiv:2108.06201v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2108.06201</id>
        <link href="http://arxiv.org/abs/2108.06201"/>
        <updated>2022-01-03T07:15:43.835Z</updated>
        <summary type="html"><![CDATA[Tree-based algorithms such as random forests and gradient boosted trees
continue to be among the most popular and powerful machine learning models used
across multiple disciplines. The conventional wisdom of estimating the impact
of a feature in tree based models is to measure the \textit{node-wise reduction
of a loss function}, which (i) yields only global importance measures and (ii)
is known to suffer from severe biases. Conditional feature contributions (CFCs)
provide \textit{local}, case-by-case explanations of a prediction by following
the decision path and attributing changes in the expected output of the model
to each feature along the path. However, Lundberg et al. pointed out a
potential bias of CFCs which depends on the distance from the root of a tree.
The by now immensely popular alternative, SHapley Additive exPlanation (SHAP)
values appear to mitigate this bias but are computationally much more
expensive. Here we contribute a thorough comparison of the explanations
computed by both methods on a set of 164 publicly available classification
problems in order to provide data-driven algorithm recommendations to current
researchers. For random forests, we find extremely high similarities and
correlations of both local and global SHAP values and CFC scores, leading to
very similar rankings and interpretations. Analogous conclusions hold for the
fidelity of using global feature importance scores as a proxy for the
predictive power associated with each feature.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Loecher_M/0/1/0/all/0/1"&gt;Markus Loecher&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Wu_Q/0/1/0/all/0/1"&gt;Qi Wu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerated Proximal Alternating Gradient-Descent-Ascent for Nonconvex Minimax Machine Learning. (arXiv:2112.11663v3 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.11663</id>
        <link href="http://arxiv.org/abs/2112.11663"/>
        <updated>2022-01-03T07:15:43.835Z</updated>
        <summary type="html"><![CDATA[Alternating gradient-descent-ascent (AltGDA) is an optimization algorithm
that has been widely used for model training in various machine learning
applications, which aim to solve a nonconvex minimax optimization problem.
However, the existing studies show that it suffers from a high computation
complexity in nonconvex minimax optimization. In this paper, we develop a
single-loop and fast AltGDA-type algorithm that leverages proximal gradient
updates and momentum acceleration to solve regularized nonconvex minimax
optimization problems. By identifying the intrinsic Lyapunov function of this
algorithm, we prove that it converges to a critical point of the nonconvex
minimax optimization problem and achieves a computation complexity
$\mathcal{O}(\kappa^{1.5}\epsilon^{-2})$, where $\epsilon$ is the desired level
of accuracy and $\kappa$ is the problem's condition number. Such a computation
complexity improves the state-of-the-art complexities of single-loop GDA and
AltGDA algorithms (see the summary of comparison in Table 1). We demonstrate
the effectiveness of our algorithm via an experiment on adversarial deep
learning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"&gt;Ziyi Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1"&gt;Shaocong Ma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1"&gt;Yi Zhou&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Agent State Online with Recurrent Generate-and-Test. (arXiv:2112.15236v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15236</id>
        <link href="http://arxiv.org/abs/2112.15236"/>
        <updated>2022-01-03T07:15:43.832Z</updated>
        <summary type="html"><![CDATA[Learning continually and online from a continuous stream of data is
challenging, especially for a reinforcement learning agent with sequential
data. When the environment only provides observations giving partial
information about the state of the environment, the agent must learn the agent
state based on the data stream of experience. We refer to the state learned
directly from the data stream of experience as the agent state. Recurrent
neural networks can learn the agent state, but the training methods are
computationally expensive and sensitive to the hyper-parameters, making them
unideal for online learning. This work introduces methods based on the
generate-and-test approach to learn the agent state. A generate-and-test
algorithm searches for state features by generating features and testing their
usefulness. In this process, features useful for the agent's performance on the
task are preserved, and the least useful features get replaced with newly
generated features. We study the effectiveness of our methods on two online
multi-step prediction problems. The first problem, trace conditioning, focuses
on the agent's ability to remember a cue for a prediction multiple steps into
the future. In the second problem, trace patterning, the agent needs to learn
patterns in the observation signals and remember them for future predictions.
We show that our proposed methods can effectively learn the agent state online
and produce accurate predictions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Samani_A/0/1/0/all/0/1"&gt;Amir Samani&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1"&gt;Richard S. Sutton&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uniform-in-Phase-Space Data Selection with Iterative Normalizing Flows. (arXiv:2112.15446v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15446</id>
        <link href="http://arxiv.org/abs/2112.15446"/>
        <updated>2022-01-03T07:15:43.831Z</updated>
        <summary type="html"><![CDATA[Improvements in computational and experimental capabilities are rapidly
increasing the amount of scientific data that is routinely generated. In
applications that are constrained by memory and computational intensity,
excessively large datasets may hinder scientific discovery, making data
reduction a critical component of data-driven methods. Datasets are growing in
two directions: the number of data points and their dimensionality. Whereas
data compression techniques are concerned with reducing dimensionality, the
focus here is on reducing the number of data points. A strategy is proposed to
select data points such that they uniformly span the phase-space of the data.
The algorithm proposed relies on estimating the probability map of the data and
using it to construct an acceptance probability. An iterative method is used to
accurately estimate the probability of the rare data points when only a small
subset of the dataset is used to construct the probability map. Instead of
binning the phase-space to estimate the probability map, its functional form is
approximated with a normalizing flow. Therefore, the method naturally extends
to high-dimensional datasets. The proposed framework is demonstrated as a
viable pathway to enable data-efficient machine learning when abundant data is
available. An implementation of the method is available in a companion
repository (https://github.com/NREL/Phase-space-sampling).]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hassanaly_M/0/1/0/all/0/1"&gt;Malik Hassanaly&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Perry_B/0/1/0/all/0/1"&gt;Bruce A. Perry&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mueller_M/0/1/0/all/0/1"&gt;Michael E. Mueller&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yellapantula_S/0/1/0/all/0/1"&gt;Shashank Yellapantula&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Triangular Flows for Generative Modeling: Statistical Consistency, Smoothness Classes, and Fast Rates. (arXiv:2112.15595v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2112.15595</id>
        <link href="http://arxiv.org/abs/2112.15595"/>
        <updated>2022-01-03T07:15:43.831Z</updated>
        <summary type="html"><![CDATA[Triangular flows, also known as Kn\"{o}the-Rosenblatt measure couplings,
comprise an important building block of normalizing flow models for generative
modeling and density estimation, including popular autoregressive flow models
such as real-valued non-volume preserving transformation models (Real NVP). We
present statistical guarantees and sample complexity bounds for triangular flow
statistical models. In particular, we establish the statistical consistency and
the finite sample convergence rates of the Kullback-Leibler estimator of the
Kn\"{o}the-Rosenblatt measure coupling using tools from empirical process
theory. Our results highlight the anisotropic geometry of function classes at
play in triangular flows, shed light on optimal coordinate ordering, and lead
to statistical guarantees for Jacobian flows. We conduct numerical experiments
on synthetic data to illustrate the practical implications of our theoretical
findings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Irons_N/0/1/0/all/0/1"&gt;Nicholas J. Irons&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Scetbon_M/0/1/0/all/0/1"&gt;Meyer Scetbon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1"&gt;Soumik Pal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Harchaoui_Z/0/1/0/all/0/1"&gt;Zaid Harchaoui&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving Baselines in the Wild. (arXiv:2112.15550v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15550</id>
        <link href="http://arxiv.org/abs/2112.15550"/>
        <updated>2022-01-03T07:15:43.823Z</updated>
        <summary type="html"><![CDATA[We share our experience with the recently released WILDS benchmark, a
collection of ten datasets dedicated to developing models and training
strategies which are robust to domain shifts. Several experiments yield a
couple of critical observations which we believe are of general interest for
any future work on WILDS. Our study focuses on two datasets: iWildCam and FMoW.
We show that (1) Conducting separate cross-validation for each evaluation
metric is crucial for both datasets, (2) A weak correlation between validation
and test performance might make model development difficult for iWildCam, (3)
Minor changes in the training of hyper-parameters improve the baseline by a
relatively large margin (mainly on FMoW), (4) There is a strong correlation
between certain domains and certain target labels (mainly on iWildCam). To the
best of our knowledge, no prior work on these datasets has reported these
observations despite their obvious importance. Our code is public.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1"&gt;Kazuki Irie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schlag_I/0/1/0/all/0/1"&gt;Imanol Schlag&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Csordas_R/0/1/0/all/0/1"&gt;R&amp;#xf3;bert Csord&amp;#xe1;s&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1"&gt;J&amp;#xfc;rgen Schmidhuber&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning the Regularization in DCE-MR Image Reconstruction for Functional Imaging of Kidneys. (arXiv:2109.07548v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.07548</id>
        <link href="http://arxiv.org/abs/2109.07548"/>
        <updated>2022-01-03T07:15:43.823Z</updated>
        <summary type="html"><![CDATA[Kidney DCE-MRI aims at both qualitative assessment of kidney anatomy and
quantitative assessment of kidney function by estimating the tracer kinetic
(TK) model parameters. Accurate estimation of TK model parameters requires an
accurate measurement of the arterial input function (AIF) with high temporal
resolution. Accelerated imaging is used to achieve high temporal resolution,
which yields under-sampling artifacts in the reconstructed images. Compressed
sensing (CS) methods offer a variety of reconstruction options. Most commonly,
sparsity of temporal differences is encouraged for regularization to reduce
artifacts. Increasing regularization in CS methods removes the ambient
artifacts but also over-smooths the signal temporally which reduces the
parameter estimation accuracy. In this work, we propose a single image trained
deep neural network to reduce MRI under-sampling artifacts without reducing the
accuracy of functional imaging markers. Instead of regularizing with a penalty
term in optimization, we promote regularization by generating images from a
lower dimensional representation. In this manuscript we motivate and explain
the lower dimensional input design. We compare our approach to CS
reconstructions with multiple regularization weights. Proposed approach results
in kidney biomarkers that are highly correlated with the ground truth markers
estimated using the CS reconstruction which was optimized for functional
analysis. At the same time, the proposed approach reduces the artifacts in the
reconstructed images.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kocanaogullari_A/0/1/0/all/0/1"&gt;Aziz Ko&amp;#xe7;anao&amp;#x11f;ullar&amp;#x131;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ariyurek_C/0/1/0/all/0/1"&gt;Cemre Ariyurek&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Afacan_O/0/1/0/all/0/1"&gt;Onur Afacan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kurugol_S/0/1/0/all/0/1"&gt;Sila Kurugol&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A sampling-based approach for efficient clustering in large datasets. (arXiv:2112.14793v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14793</id>
        <link href="http://arxiv.org/abs/2112.14793"/>
        <updated>2022-01-03T07:15:43.813Z</updated>
        <summary type="html"><![CDATA[We propose a simple and efficient clustering method for high-dimensional data
with a large number of clusters. Our algorithm achieves high-performance by
evaluating distances of datapoints with a subset of the cluster centres. Our
contribution is substantially more efficient than k-means as it does not
require an all to all comparison of data points and clusters. We show that the
optimal solutions of our approximation are the same as in the exact solution.
However, our approach is considerably more efficient at extracting these
clusters compared to the state-of-the-art. We compare our approximation with
the exact k-means and alternative approximation approaches on a series of
standardised clustering tasks. For the evaluation, we consider the algorithmic
complexity, including number of operations to convergence, and the stability of
the results.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Exarchakis_G/0/1/0/all/0/1"&gt;Georgios Exarchakis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Oubari_O/0/1/0/all/0/1"&gt;Omar Oubari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lenz_G/0/1/0/all/0/1"&gt;Gregor Lenz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NCIS: Neural Contextual Iterative Smoothing for Purifying Adversarial Perturbations. (arXiv:2106.11644v2 [cs.CV] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.11644</id>
        <link href="http://arxiv.org/abs/2106.11644"/>
        <updated>2022-01-03T07:15:43.813Z</updated>
        <summary type="html"><![CDATA[We propose a novel and effective purification based adversarial defense
method against pre-processor blind white- and black-box attacks. Our method is
computationally efficient and trained only with self-supervised learning on
general images, without requiring any adversarial training or retraining of the
classification model. We first show an empirical analysis on the adversarial
noise, defined to be the residual between an original image and its adversarial
example, has almost zero mean, symmetric distribution. Based on this
observation, we propose a very simple iterative Gaussian Smoothing (GS) which
can effectively smooth out adversarial noise and achieve substantially high
robust accuracy. To further improve it, we propose Neural Contextual Iterative
Smoothing (NCIS), which trains a blind-spot network (BSN) in a self-supervised
manner to reconstruct the discriminative features of the original image that is
also smoothed out by GS. From our extensive experiments on the large-scale
ImageNet using four classification models, we show that our method achieves
both competitive standard accuracy and state-of-the-art robust accuracy against
most strong purifier-blind white- and black-box attacks. Also, we propose a new
benchmark for evaluating a purification method based on commercial image
classification APIs, such as AWS, Azure, Clarifai and Google. We generate
adversarial examples by ensemble transfer-based black-box attack, which can
induce complete misclassification of APIs, and demonstrate that our method can
be used to increase adversarial robustness of APIs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1"&gt;Sungmin Cha&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ko_N/0/1/0/all/0/1"&gt;Naeun Ko&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1"&gt;Youngjoon Yoo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Moon_T/0/1/0/all/0/1"&gt;Taesup Moon&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An objective function for order preserving hierarchical clustering. (arXiv:2109.04266v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.04266</id>
        <link href="http://arxiv.org/abs/2109.04266"/>
        <updated>2022-01-03T07:15:43.812Z</updated>
        <summary type="html"><![CDATA[We present an objective function for similarity based hierarchical clustering
of partially ordered data that preserves the partial order. That is, if $x \le
y$, and if $[x]$ and $[y]$ are the respective clusters of $x$ and $y$, then
there is an order relation $\le'$ on the clusters for which $[x] \le' |y]$. The
theory distinguishes itself from existing theories for clustering of ordered
data in that the order relation and the similarity are combined into a
bi-objective optimisation problem to obtain a hierarchical clustering seeking
to satisfy both. In particular, the order relation is weighted in the range
$[0,1]$, and if the similarity and the order relation are not aligned, then
order preservation may have to yield in favor of clustering. Finding an optimal
solution is NP-hard, so we provide a polynomial time approximation algorithm,
with a relative performance guarantee of $O\!\left(\log^{3/2} \!\!\, n
\right)$, based on successive applications of directed sparsest cut. We provide
a demonstration on a benchmark dataset, showing that our method outperforms
existing methods for order preserving hierarchical clustering with significant
margin. The theory is an extension of the Dasgupta cost function for divisive
hierarchical clustering.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bakkelund_D/0/1/0/all/0/1"&gt;Daniel Bakkelund&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?. (arXiv:1911.12360v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1911.12360</id>
        <link href="http://arxiv.org/abs/1911.12360"/>
        <updated>2022-01-03T07:15:43.810Z</updated>
        <summary type="html"><![CDATA[A recent line of research on deep learning focuses on the extremely
over-parameterized setting, and shows that when the network width is larger
than a high degree polynomial of the training sample size $n$ and the inverse
of the target error $\epsilon^{-1}$, deep neural networks learned by
(stochastic) gradient descent enjoy nice optimization and generalization
guarantees. Very recently, it is shown that under certain margin assumptions on
the training data, a polylogarithmic width condition suffices for two-layer
ReLU networks to converge and generalize (Ji and Telgarsky, 2019). However,
whether deep neural networks can be learned with such a mild
over-parameterization is still an open question. In this work, we answer this
question affirmatively and establish sharper learning guarantees for deep ReLU
networks trained by (stochastic) gradient descent. In specific, under certain
assumptions made in previous work, our optimization and generalization
guarantees hold with network width polylogarithmic in $n$ and $\epsilon^{-1}$.
Our results push the study of over-parameterized deep neural networks towards
more practical settings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"&gt;Zixiang Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"&gt;Yuan Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1"&gt;Difan Zou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Training and Generating Neural Networks in Compressed Weight Space. (arXiv:2112.15545v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15545</id>
        <link href="http://arxiv.org/abs/2112.15545"/>
        <updated>2022-01-03T07:15:43.802Z</updated>
        <summary type="html"><![CDATA[The inputs and/or outputs of some neural nets are weight matrices of other
neural nets. Indirect encodings or end-to-end compression of weight matrices
could help to scale such approaches. Our goal is to open a discussion on this
topic, starting with recurrent neural networks for character-level language
modelling whose weight matrices are encoded by the discrete cosine transform.
Our fast weight version thereof uses a recurrent neural network to parameterise
the compressed weights. We present experimental results on the enwik8 dataset.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1"&gt;Kazuki Irie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1"&gt;J&amp;#xfc;rgen Schmidhuber&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Actor Loss of Soft Actor Critic Explained. (arXiv:2112.15568v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15568</id>
        <link href="http://arxiv.org/abs/2112.15568"/>
        <updated>2022-01-03T07:15:43.801Z</updated>
        <summary type="html"><![CDATA[This technical report is devoted to explaining how the actor loss of soft
actor critic is obtained, as well as the associated gradient estimate. It gives
the necessary mathematical background to derive all the presented equations,
from the theoretical actor loss to the one implemented in practice. This
necessitates a comparison of the reparameterization trick used in soft actor
critic with the nabla log trick, which leads to open questions regarding the
most efficient method to use.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lahire_T/0/1/0/all/0/1"&gt;Thibault Lahire&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hierarchical forecasting with a top-down alignment of independent level forecasts. (arXiv:2103.08250v4 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.08250</id>
        <link href="http://arxiv.org/abs/2103.08250"/>
        <updated>2022-01-03T07:15:43.798Z</updated>
        <summary type="html"><![CDATA[Hierarchical forecasting with intermittent time series is a challenge in both
research and empirical studies. Extensive research focuses on improving the
accuracy of each hierarchy, especially the intermittent time series at bottom
levels. Then hierarchical reconciliation could be used to improve the overall
performance further. In this paper, we present a
\emph{hierarchical-forecasting-with-alignment} approach that treats the bottom
level forecasts as mutable to ensure higher forecasting accuracy on the upper
levels of the hierarchy. We employ a pure deep learning forecasting approach
N-BEATS for continuous time series at the top levels and a widely used
tree-based algorithm LightGBM for the intermittent time series at the bottom
level. The \emph{hierarchical-forecasting-with-alignment} approach is a simple
yet effective variant of the bottom-up method, accounting for biases that are
difficult to observe at the bottom level. It allows suboptimal forecasts at the
lower level to retain a higher overall performance. The approach in this
empirical study was developed by the first author during the M5 Forecasting
Accuracy competition, ranking second place. The method is also business
orientated and could benefit for business strategic planning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Anderer_M/0/1/0/all/0/1"&gt;Matthias Anderer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1"&gt;Feng Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Two-Timescale Framework for Bilevel Optimization: Complexity Analysis and Application to Actor-Critic. (arXiv:2007.05170v3 [math.OC] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2007.05170</id>
        <link href="http://arxiv.org/abs/2007.05170"/>
        <updated>2022-01-03T07:15:43.797Z</updated>
        <summary type="html"><![CDATA[This paper analyzes a two-timescale stochastic algorithm framework for
bilevel optimization. Bilevel optimization is a class of problems which exhibit
a two-level structure, and its goal is to minimize an outer objective function
with variables which are constrained to be the optimal solution to an (inner)
optimization problem. We consider the case when the inner problem is
unconstrained and strongly convex, while the outer problem is constrained and
has a smooth objective function. We propose a two-timescale stochastic
approximation (TTSA) algorithm for tackling such a bilevel problem. In the
algorithm, a stochastic gradient update with a larger step size is used for the
inner problem, while a projected stochastic gradient update with a smaller step
size is used for the outer problem. We analyze the convergence rates for the
TTSA algorithm under various settings: when the outer problem is strongly
convex (resp.~weakly convex), the TTSA algorithm finds an
$\mathcal{O}(K^{-2/3})$-optimal (resp.~$\mathcal{O}(K^{-2/5})$-stationary)
solution, where $K$ is the total iteration number. As an application, we show
that a two-timescale natural actor-critic proximal policy optimization
algorithm can be viewed as a special case of our TTSA framework. Importantly,
the natural actor-critic algorithm is shown to converge at a rate of
$\mathcal{O}(K^{-1/4})$ in terms of the gap in expected discounted reward
compared to a global optimal policy.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Hong_M/0/1/0/all/0/1"&gt;Mingyi Hong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Wai_H/0/1/0/all/0/1"&gt;Hoi-To Wai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zhaoran Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Yang_Z/0/1/0/all/0/1"&gt;Zhuoran Yang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Robust Training via Backward Smoothing. (arXiv:2010.01278v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.01278</id>
        <link href="http://arxiv.org/abs/2010.01278"/>
        <updated>2022-01-03T07:15:43.797Z</updated>
        <summary type="html"><![CDATA[Adversarial training is so far the most effective strategy in defending
against adversarial examples. However, it suffers from high computational costs
due to the iterative adversarial attacks in each training step. Recent studies
show that it is possible to achieve fast Adversarial Training by performing a
single-step attack with random initialization. However, such an approach still
lags behind state-of-the-art adversarial training algorithms on both stability
and model robustness. In this work, we develop a new understanding towards Fast
Adversarial Training, by viewing random initialization as performing randomized
smoothing for better optimization of the inner maximization problem. Following
this new perspective, we also propose a new initialization strategy, backward
smoothing, to further improve the stability and model robustness over
single-step robust training methods. Experiments on multiple benchmarks
demonstrate that our method achieves similar model robustness as the original
TRADES method while using much less training time ($\sim$3x improvement with
the same training schedule).]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"&gt;Jinghui Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1"&gt;Yu Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1"&gt;Zhe Gan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"&gt;Jingjing Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Refining Language Models with Compositional Explanations. (arXiv:2103.10415v3 [cs.CL] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.10415</id>
        <link href="http://arxiv.org/abs/2103.10415"/>
        <updated>2022-01-03T07:15:43.797Z</updated>
        <summary type="html"><![CDATA[Pre-trained language models have been successful on text classification
tasks, but are prone to learning spurious correlations from biased datasets,
and are thus vulnerable when making inferences in a new domain. Prior work
reveals such spurious patterns via post-hoc explanation algorithms which
compute the importance of input features. Further, the model is regularized to
align the importance scores with human knowledge, so that the unintended model
behaviors are eliminated. However, such a regularization technique lacks
flexibility and coverage, since only importance scores towards a pre-defined
list of features are adjusted, while more complex human knowledge such as
feature interaction and pattern generalization can hardly be incorporated. In
this work, we propose to refine a learned language model for a target domain by
collecting human-provided compositional explanations regarding observed biases.
By parsing these explanations into executable logic rules, the human-specified
refinement advice from a small set of explanations can be generalized to more
training examples. We additionally introduce a regularization term allowing
adjustments for both importance and interaction of features to better rectify
model behavior. We demonstrate the effectiveness of the proposed approach on
two text classification tasks by showing improved performance in target domain
as well as improved model fairness after refinement.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1"&gt;Huihan Yao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Ying Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1"&gt;Qinyuan Ye&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1"&gt;Xisen Jin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1"&gt;Xiang Ren&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Separation of scales and a thermodynamic description of feature learning in some CNNs. (arXiv:2112.15383v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2112.15383</id>
        <link href="http://arxiv.org/abs/2112.15383"/>
        <updated>2022-01-03T07:15:43.796Z</updated>
        <summary type="html"><![CDATA[Deep neural networks (DNNs) are powerful tools for compressing and distilling
information. Due to their scale and complexity, often involving billions of
inter-dependent internal degrees of freedom, exact analysis approaches often
fall short. A common strategy in such cases is to identify slow degrees of
freedom that average out the erratic behavior of the underlying fast
microscopic variables. Here, we identify such a separation of scales occurring
in over-parameterized deep convolutional neural networks (CNNs) at the end of
training. It implies that neuron pre-activations fluctuate in a nearly Gaussian
manner with a deterministic latent kernel. While for CNNs with infinitely many
channels these kernels are inert, for finite CNNs they adapt and learn from
data in an analytically tractable manner. The resulting thermodynamic theory of
deep learning yields accurate predictions on several deep non-linear CNN toy
models. In addition, it provides new ways of analyzing and understanding CNNs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1"&gt;Inbar Seroussi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1"&gt;Zohar Ringel&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Unsupervised Domain Adaptation Model based on Dual-module Adversarial Training. (arXiv:2112.15555v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15555</id>
        <link href="http://arxiv.org/abs/2112.15555"/>
        <updated>2022-01-03T07:15:43.791Z</updated>
        <summary type="html"><![CDATA[In this paper, we propose a dual-module network architecture that employs a
domain discriminative feature module to encourage the domain invariant feature
module to learn more domain invariant features. The proposed architecture can
be applied to any model that utilizes domain invariant features for
unsupervised domain adaptation to improve its ability to extract domain
invariant features. We conduct experiments with the Domain-Adversarial Training
of Neural Networks (DANN) model as a representative algorithm. In the training
process, we supply the same input to the two modules and then extract their
feature distribution and prediction results respectively. We propose a
discrepancy loss to find the discrepancy of the prediction results and the
feature distribution between the two modules. Through the adversarial training
by maximizing the loss of their feature distribution and minimizing the
discrepancy of their prediction results, the two modules are encouraged to
learn more domain discriminative and domain invariant features respectively.
Extensive comparative evaluations are conducted and the proposed approach
outperforms the state-of-the-art in most unsupervised domain adaptation tasks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"&gt;Yiju Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1"&gt;Tianxiao Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1"&gt;Guanyu Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1"&gt;Taejoon Kim&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1"&gt;Guanghui Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Critical Review of Inductive Logic Programming Techniques for Explainable AI. (arXiv:2112.15319v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15319</id>
        <link href="http://arxiv.org/abs/2112.15319"/>
        <updated>2022-01-03T07:15:43.790Z</updated>
        <summary type="html"><![CDATA[Despite recent advances in modern machine learning algorithms, the opaqueness
of their underlying mechanisms continues to be an obstacle in adoption. To
instill confidence and trust in artificial intelligence systems, Explainable
Artificial Intelligence has emerged as a response to improving modern machine
learning algorithms' explainability. Inductive Logic Programming (ILP), a
subfield of symbolic artificial intelligence, plays a promising role in
generating interpretable explanations because of its intuitive logic-driven
framework. ILP effectively leverages abductive reasoning to generate
explainable first-order clausal theories from examples and background
knowledge. However, several challenges in developing methods inspired by ILP
need to be addressed for their successful application in practice. For example,
existing ILP systems often have a vast solution space, and the induced
solutions are very sensitive to noises and disturbances. This survey paper
summarizes the recent advances in ILP and a discussion of statistical
relational learning and neural-symbolic algorithms, which offer synergistic
views to ILP. Following a critical review of the recent advances, we delineate
observed challenges and highlight potential avenues of further ILP-motivated
research toward developing self-explanatory artificial intelligence systems.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1"&gt;Zheng Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yilmaz_L/0/1/0/all/0/1"&gt;Levent Yilmaz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1"&gt;Bo Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Simplifying Software Defect Prediction (via the "early bird" Heuristic). (arXiv:2105.11082v2 [cs.SE] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2105.11082</id>
        <link href="http://arxiv.org/abs/2105.11082"/>
        <updated>2022-01-03T07:15:43.786Z</updated>
        <summary type="html"><![CDATA[Before researchers rush to reason across all available data or try complex
methods, perhaps it is prudent to first check for simpler alternatives.
Specifically, if the historical data has the most information in some small
region, then perhaps a model learned from that region would suffice for the
rest of the project.

To support this claim, we offer a case study with 240 GitHub projects, where
we find that the information in those projects "clumped" towards the earliest
parts of the project. A defect prediction model learned from just the first 150
commits works as well, or better than state-of-the-art alternatives. Using just
this early life cycle data, we can build models very quickly, very early in the
software project life cycle. Moreover, using this method, we have shown that a
simple model (with just two features) generalizes to hundreds of software
projects.

Based on this experience, we doubt that prior work on generalizing software
engineering defect prediction models may have needlessly complicated an
inherently simple process. Further, prior work that focused on later-life cycle
data needs to be revisited since their conclusions were drawn from relatively
uninformative regions.

Replication note: all our data and scripts are online at
https://github.com/snaraya7/simplifying-software-analytics]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Shrikanth_N/0/1/0/all/0/1"&gt;N.C. Shrikanth&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Menzies_T/0/1/0/all/0/1"&gt;Tim Menzies&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hybrid Adversarial Imitation Learning. (arXiv:2102.02454v10 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2102.02454</id>
        <link href="http://arxiv.org/abs/2102.02454"/>
        <updated>2022-01-03T07:15:43.778Z</updated>
        <summary type="html"><![CDATA[Extrapolating beyond-demonstrator (BD) performance through the imitation
learning (IL) algorithm aims to learn from and outperform the demonstrator.
Most existing BDIL algorithms are performed in two stages by first inferring a
reward function before learning a policy via reinforcement learning (RL).
However, such two-stage BDIL algorithms suffer from high computational
complexity, weak robustness, and large performance variations. In particular, a
poor reward function derived in the first stage will inevitably incur severe
performance loss in the second stage. In this work, we propose a hybrid
adversarial imitation learning (HAIL) algorithm that is one-stage, model-free,
generative-adversarial (GA) fashion and curiosity-driven. Thanks to the
one-stage design, the HAIL can integrate both the reward function learning and
the policy optimization into one procedure, which leads to many advantages such
as low computational complexity, high robustness, and strong adaptability. More
specifically, HAIL simultaneously imitates the demonstrator and explores BD
performance by utilizing hybrid rewards. Extensive simulation results confirm
that HAIL can achieve higher performance as compared to other similar BDIL
algorithms.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1"&gt;Mingqi Yuan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fast Learning of MNL Model from General Partial Rankings with Application to Network Formation Modeling. (arXiv:2112.15575v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15575</id>
        <link href="http://arxiv.org/abs/2112.15575"/>
        <updated>2022-01-03T07:15:43.774Z</updated>
        <summary type="html"><![CDATA[Multinomial Logit (MNL) is one of the most popular discrete choice models and
has been widely used to model ranking data. However, there is a long-standing
technical challenge of learning MNL from many real-world ranking data: exact
calculation of the MNL likelihood of \emph{partial rankings} is generally
intractable. In this work, we develop a scalable method for approximating the
MNL likelihood of general partial rankings in polynomial time complexity. We
also extend the proposed method to learn mixture of MNL. We demonstrate that
the proposed methods are particularly helpful for applications to choice-based
network formation modeling, where the formation of new edges in a network is
viewed as individuals making choices of their friends over a candidate set. The
problem of learning mixture of MNL models from partial rankings naturally
arises in such applications. And the proposed methods can be used to learn MNL
models from network data without the strong assumption that temporal orders of
all the edge formation are available. We conduct experiments on both synthetic
and real-world network data to demonstrate that the proposed methods achieve
more accurate parameter estimation and better fitness of data compared to
conventional methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1"&gt;Jiaqi Ma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"&gt;Xingjian Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1"&gt;Qiaozhu Mei&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient and Reliable Overlay Networks for Decentralized Federated Learning. (arXiv:2112.15486v1 [cs.NI])]]></title>
        <id>http://arxiv.org/abs/2112.15486</id>
        <link href="http://arxiv.org/abs/2112.15486"/>
        <updated>2022-01-03T07:15:43.773Z</updated>
        <summary type="html"><![CDATA[We propose near-optimal overlay networks based on $d$-regular expander graphs
to accelerate decentralized federated learning (DFL) and improve its
generalization. In DFL a massive number of clients are connected by an overlay
network, and they solve machine learning problems collaboratively without
sharing raw data. Our overlay network design integrates spectral graph theory
and the theoretical convergence and generalization bounds for DFL. As such, our
proposed overlay networks accelerate convergence, improve generalization, and
enhance robustness to clients failures in DFL with theoretical guarantees.
Also, we present an efficient algorithm to convert a given graph to a practical
overlay network and maintaining the network topology after potential client
failures. We numerically verify the advantages of DFL with our proposed
networks on various benchmark tasks, ranging from image classification to
language modeling using hundreds of clients.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1"&gt;Yifan Hua&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Miller_K/0/1/0/all/0/1"&gt;Kevin Miller&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bertozzi_A/0/1/0/all/0/1"&gt;Andrea L. Bertozzi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1"&gt;Chen Qian&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1"&gt;Bao Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ViNMT: Neural Machine Translation Tookit. (arXiv:2112.15272v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2112.15272</id>
        <link href="http://arxiv.org/abs/2112.15272"/>
        <updated>2022-01-03T07:15:43.731Z</updated>
        <summary type="html"><![CDATA[We present an open-source toolkit for neural machine translation (NMT). The
new toolkit is mainly based on vaulted Transformer (Vaswani et al., 2017) along
with many other improvements detailed below, in order to create a
self-contained, simple to use, consistent and comprehensive framework for
Machine Translation tasks of various domains. It is tooled to support both
bilingual and multilingual translation tasks, starting from building the model
from respective corpora, to inferring new predictions or packaging the model to
serving-capable JIT format.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Quan_N/0/1/0/all/0/1"&gt;Nguyen Hoang Quan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dat_N/0/1/0/all/0/1"&gt;Nguyen Thanh Dat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cong_N/0/1/0/all/0/1"&gt;Nguyen Hoang Minh Cong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vinh_N/0/1/0/all/0/1"&gt;Nguyen Van Vinh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vinh_N/0/1/0/all/0/1"&gt;Ngo Thi Vinh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Thai_N/0/1/0/all/0/1"&gt;Nguyen Phuong Thai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Viet_T/0/1/0/all/0/1"&gt;Tran Hong Viet&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AutoFITS: Automatic Feature Engineering for Irregular Time Series. (arXiv:2112.14806v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14806</id>
        <link href="http://arxiv.org/abs/2112.14806"/>
        <updated>2022-01-03T07:15:43.727Z</updated>
        <summary type="html"><![CDATA[A time series represents a set of observations collected over time.
Typically, these observations are captured with a uniform sampling frequency
(e.g. daily). When data points are observed in uneven time intervals the time
series is referred to as irregular or intermittent. In such scenarios, the most
common solution is to reconstruct the time series to make it regular, thus
removing its intermittency. We hypothesise that, in irregular time series, the
time at which each observation is collected may be helpful to summarise the
dynamics of the data and improve forecasting performance. We study this idea by
developing a novel automatic feature engineering framework, which focuses on
extracting information from this point of view, i.e., when each instance is
collected. We study how valuable this information is by integrating it in a
time series forecasting workflow and investigate how it compares to or
complements state-of-the-art methods for regular time series forecasting. In
the end, we contribute by providing a novel framework that tackles feature
engineering for time series from an angle previously vastly ignored. We show
that our approach has the potential to further extract more information about
time series that significantly improves forecasting performance.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Costa_P/0/1/0/all/0/1"&gt;Pedro Costa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cerqueira_V/0/1/0/all/0/1"&gt;Vitor Cerqueira&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vinagre_J/0/1/0/all/0/1"&gt;Jo&amp;#xe3;o Vinagre&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Investigating Pose Representations and Motion Contexts Modeling for 3D Motion Prediction. (arXiv:2112.15012v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2112.15012</id>
        <link href="http://arxiv.org/abs/2112.15012"/>
        <updated>2022-01-03T07:15:43.726Z</updated>
        <summary type="html"><![CDATA[Predicting human motion from historical pose sequence is crucial for a
machine to succeed in intelligent interactions with humans. One aspect that has
been obviated so far, is the fact that how we represent the skeletal pose has a
critical impact on the prediction results. Yet there is no effort that
investigates across different pose representation schemes. We conduct an
indepth study on various pose representations with a focus on their effects on
the motion prediction task. Moreover, recent approaches build upon
off-the-shelf RNN units for motion prediction. These approaches process input
pose sequence sequentially and inherently have difficulties in capturing
long-term dependencies. In this paper, we propose a novel RNN architecture
termed AHMR (Attentive Hierarchical Motion Recurrent network) for motion
prediction which simultaneously models local motion contexts and a global
context. We further explore a geodesic loss and a forward kinematics loss for
the motion prediction task, which have more geometric significance than the
widely employed L2 loss. Interestingly, we applied our method to a range of
articulate objects including human, fish, and mouse. Empirical results show
that our approach outperforms the state-of-the-art methods in short-term
prediction and achieves much enhanced long-term prediction proficiency, such as
retaining natural human-like motions over 50 seconds predictions. Our codes are
released.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"&gt;Zhenguang Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1"&gt;Shuang Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1"&gt;Shuyuan Jin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1"&gt;Shouling Ji&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1"&gt;Qi Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1"&gt;Shijian Lu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1"&gt;Li Cheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A General Traffic Shaping Protocol in E-Commerce. (arXiv:2112.14941v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14941</id>
        <link href="http://arxiv.org/abs/2112.14941"/>
        <updated>2022-01-03T07:15:43.724Z</updated>
        <summary type="html"><![CDATA[To approach different business objectives, online traffic shaping algorithms
aim at improving exposures of a target set of items, such as boosting the
growth of new commodities. Generally, these algorithms assume that the utility
of each user-item pair can be accessed via a well-trained conversion rate
prediction model. However, for real E-Commerce platforms, there are unavoidable
factors preventing us from learning such an accurate model. In order to break
the heavy dependence on accurate inputs of the utility, we propose a general
online traffic shaping protocol for online E-Commerce applications. In our
framework, we approximate the function mapping the bonus scores, which
generally are the only method to influence the ranking result in the traffic
shaping problem, to the numbers of exposures and purchases. Concretely, we
approximate the above function by a class of the piece-wise linear function
constructed on the convex hull of the explored data points. Moreover, we
reformulate the online traffic shaping problem as linear programming where
these piece-wise linear functions are embedded into both the objective and
constraints. Our algorithm can straightforwardly optimize the linear
programming in the prime space, and its solution can be simply applied by a
stochastic strategy to fulfill the optimized objective and the constraints in
expectation. Finally, the online A/B test shows our proposed algorithm steadily
outperforms the previous industrial level traffic shaping algorithm.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1"&gt;Chenlin Shen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huzhang_G/0/1/0/all/0/1"&gt;Guangda Huzhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1"&gt;Yuhang Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1"&gt;Chen Liang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Da_Q/0/1/0/all/0/1"&gt;Qing Da&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BP-Net: Cuff-less, Calibration-free, and Non-invasive Blood Pressure Estimation via a Generic Deep Convolutional Architecture. (arXiv:2112.15271v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15271</id>
        <link href="http://arxiv.org/abs/2112.15271"/>
        <updated>2022-01-03T07:15:43.724Z</updated>
        <summary type="html"><![CDATA[Objective: The paper focuses on development of robust and accurate processing
solutions for continuous and cuff-less blood pressure (BP) monitoring. In this
regard, a robust deep learning-based framework is proposed for computation of
low latency, continuous, and calibration-free upper and lower bounds on the
systolic and diastolic BP. Method: Referred to as the BP-Net, the proposed
framework is a novel convolutional architecture that provides longer effective
memory while achieving superior performance due to incorporation of casual
dialated convolutions and residual connections. To utilize the real potential
of deep learning in extraction of intrinsic features (deep features) and
enhance the long-term robustness, the BP-Net uses raw Electrocardiograph (ECG)
and Photoplethysmograph (PPG) signals without extraction of any form of
hand-crafted features as it is common in existing solutions. Results: By
capitalizing on the fact that datasets used in recent literature are not
unified and properly defined, a benchmark dataset is constructed from the
MIMIC-I and MIMIC-III databases obtained from PhysioNet. The proposed BP-Net is
evaluated based on this benchmark dataset demonstrating promising performance
and shows superior generalizable capacity. Conclusion: The proposed BP-Net
architecture is more accurate than canonical recurrent networks and enhances
the long-term robustness of the BP estimation task. Significance: The proposed
BP-Net architecture addresses key drawbacks of existing BP estimation
solutions, i.e., relying heavily on extraction of hand-crafted features, such
as pulse arrival time (PAT), and; Lack of robustness. Finally, the constructed
BP-Net dataset provides a unified base for evaluation and comparison of deep
learning-based BP estimation algorithms.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zabihi_S/0/1/0/all/0/1"&gt;Soheil Zabihi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rahimian_E/0/1/0/all/0/1"&gt;Elahe Rahimian&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Marefat_F/0/1/0/all/0/1"&gt;Fatemeh Marefat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Asif_A/0/1/0/all/0/1"&gt;Amir Asif&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mohseni_P/0/1/0/all/0/1"&gt;Pedram Mohseni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mohammadi_A/0/1/0/all/0/1"&gt;Arash Mohammadi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Calibrated Hyperspectral Image Reconstruction via Graph-based Self-Tuning Network. (arXiv:2112.15362v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2112.15362</id>
        <link href="http://arxiv.org/abs/2112.15362"/>
        <updated>2022-01-03T07:15:43.723Z</updated>
        <summary type="html"><![CDATA[Recently, hyperspectral imaging (HSI) has attracted increasing research
attention, especially for the ones based on a coded aperture snapshot spectral
imaging (CASSI) system. Existing deep HSI reconstruction models are generally
trained on paired data to retrieve original signals upon 2D compressed
measurements given by a particular optical hardware mask in CASSI, during which
the mask largely impacts the reconstruction performance and could work as a
"model hyperparameter" governing on data augmentations. This mask-specific
training style will lead to a hardware miscalibration issue, which sets up
barriers to deploying deep HSI models among different hardware and noisy
environments. To address this challenge, we introduce mask uncertainty for HSI
with a complete variational Bayesian learning treatment and explicitly model it
through a mask decomposition inspired by real hardware. Specifically, we
propose a novel Graph-based Self-Tuning (GST) network to reason uncertainties
adapting to varying spatial structures of masks among different hardware.
Moreover, we develop a bilevel optimization framework to balance HSI
reconstruction and uncertainty estimation, accounting for the hyperparameter
property of masks. Extensive experimental results and model discussions
validate the effectiveness (over 33/30 dB) of the proposed GST method under two
miscalibration scenarios and demonstrate a highly competitive performance
compared with the state-of-the-art well-calibrated methods. Our code and
pre-trained model are available at https://github.com/Jiamian
Wang/mask_uncertainty_spectral_SCI]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1"&gt;Jiamian Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1"&gt;Yulun Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Yuan_X/0/1/0/all/0/1"&gt;Xin Yuan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Meng_Z/0/1/0/all/0/1"&gt;Ziyi Meng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Tao_Z/0/1/0/all/0/1"&gt;Zhiqiang Tao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Agent Reinforcement Learning via Adaptive Kalman Temporal Difference and Successor Representation. (arXiv:2112.15156v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15156</id>
        <link href="http://arxiv.org/abs/2112.15156"/>
        <updated>2022-01-03T07:15:43.722Z</updated>
        <summary type="html"><![CDATA[Distributed Multi-Agent Reinforcement Learning (MARL) algorithms has
attracted a surge of interest lately mainly due to the recent advancements of
Deep Neural Networks (DNNs). Conventional Model-Based (MB) or Model-Free (MF)
RL algorithms are not directly applicable to the MARL problems due to
utilization of a fixed reward model for learning the underlying value function.
While DNN-based solutions perform utterly well when a single agent is involved,
such methods fail to fully generalize to the complexities of MARL problems. In
other words, although recently developed approaches based on DNNs for
multi-agent environments have achieved superior performance, they are still
prone to overfiting, high sensitivity to parameter selection, and sample
inefficiency. The paper proposes the Multi-Agent Adaptive Kalman Temporal
Difference (MAK-TD) framework and its Successor Representation-based variant,
referred to as the MAK-SR. Intuitively speaking, the main objective is to
capitalize on unique characteristics of Kalman Filtering (KF) such as
uncertainty modeling and online second order learning. The proposed MAK-TD/SR
frameworks consider the continuous nature of the action-space that is
associated with high dimensional multi-agent environments and exploit Kalman
Temporal Difference (KTD) to address the parameter uncertainty. By leveraging
the KTD framework, SR learning procedure is modeled into a filtering problem,
where Radial Basis Function (RBF) estimators are used to encode the continuous
space into feature vectors. On the other hand, for learning localized reward
functions, we resort to Multiple Model Adaptive Estimation (MMAE), to deal with
the lack of prior knowledge on the observation noise covariance and observation
mapping function. The proposed MAK-TD/SR frameworks are evaluated via several
experiments, which are implemented through the OpenAI Gym MARL benchmarks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Salimibeni_M/0/1/0/all/0/1"&gt;Mohammad Salimibeni&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mohammadi_A/0/1/0/all/0/1"&gt;Arash Mohammadi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Malekzadeh_P/0/1/0/all/0/1"&gt;Parvin Malekzadeh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1"&gt;Konstantinos N. Plataniotis&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robustness and risk management via distributional dynamic programming. (arXiv:2112.15430v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15430</id>
        <link href="http://arxiv.org/abs/2112.15430"/>
        <updated>2022-01-03T07:15:43.721Z</updated>
        <summary type="html"><![CDATA[In dynamic programming (DP) and reinforcement learning (RL), an agent learns
to act optimally in terms of expected long-term return by sequentially
interacting with its environment modeled by a Markov decision process (MDP).
More generally in distributional reinforcement learning (DRL), the focus is on
the whole distribution of the return, not just its expectation. Although
DRL-based methods produced state-of-the-art performance in RL with function
approximation, they involve additional quantities (compared to the
non-distributional setting) that are still not well understood. As a first
contribution, we introduce a new class of distributional operators, together
with a practical DP algorithm for policy evaluation, that come with a robust
MDP interpretation. Indeed, our approach reformulates through an augmented
state space where each state is split into a worst-case substate and a
best-case substate, whose values are maximized by safe and risky policies
respectively. Finally, we derive distributional operators and DP algorithms
solving a new control task: How to distinguish safe from risky optimal actions
in order to break ties in the space of optimal policies?]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Achab_M/0/1/0/all/0/1"&gt;Mastane Achab&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Neu_G/0/1/0/all/0/1"&gt;Gergely Neu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self Reward Design with Fine-grained Interpretability. (arXiv:2112.15034v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15034</id>
        <link href="http://arxiv.org/abs/2112.15034"/>
        <updated>2022-01-03T07:15:43.719Z</updated>
        <summary type="html"><![CDATA[Transparency and fairness issues in Deep Reinforcement Learning may stem from
the black-box nature of deep neural networks used to learn its policy, value
functions etc. This paper proposes a way to circumvent the issues through the
bottom-up design of neural networks (NN) with detailed interpretability, where
each neuron or layer has its own meaning and utility that corresponds to
humanly understandable concept. With deliberate design, we show that lavaland
problems can be solved using NN model with few parameters. Furthermore, we
introduce the Self Reward Design (SRD), inspired by the Inverse Reward Design,
so that our interpretable design can (1) solve the problem by pure design
(although imperfectly) (2) be optimized via SRD (3) perform avoidance of
unknown states by recognizing the inactivations of neurons aggregated as the
activation in \(w_{unknown}\).]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tjoa_E/0/1/0/all/0/1"&gt;Erico Tjoa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cuntai_G/0/1/0/all/0/1"&gt;Guan Cuntai&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distributed Random Reshuffling over Networks. (arXiv:2112.15287v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2112.15287</id>
        <link href="http://arxiv.org/abs/2112.15287"/>
        <updated>2022-01-03T07:15:43.714Z</updated>
        <summary type="html"><![CDATA[In this paper, we consider the distributed optimization problem where $n$
agents, each possessing a local cost function, collaboratively minimize the
average of the local cost functions over a connected network. To solve the
problem, we propose a distributed random reshuffling (D-RR) algorithm that
combines the classical distributed gradient descent (DGD) method and Random
Reshuffling (RR). We show that D-RR inherits the superiority of RR for both
smooth strongly convex and smooth nonconvex objective functions. In particular,
for smooth strongly convex objective functions, D-RR achieves
$\mathcal{O}(1/T^2)$ rate of convergence (here, $T$ counts the total number of
iterations) in terms of the squared distance between the iterate and the unique
minimizer. When the objective function is assumed to be smooth nonconvex and
has Lipschitz continuous component functions, we show that D-RR drives the
squared norm of gradient to $0$ at a rate of $\mathcal{O}(1/T^{2/3})$. These
convergence results match those of centralized RR (up to constant factors).]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Huang_K/0/1/0/all/0/1"&gt;Kun Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Li_X/0/1/0/all/0/1"&gt;Xiao Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Milzarek_A/0/1/0/all/0/1"&gt;Andre Milzarek&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Pu_S/0/1/0/all/0/1"&gt;Shi Pu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Qiu_J/0/1/0/all/0/1"&gt;Junwen Qiu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalable Deep Graph Clustering with Random-walk based Self-supervised Learning. (arXiv:2112.15530v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15530</id>
        <link href="http://arxiv.org/abs/2112.15530"/>
        <updated>2022-01-03T07:15:43.710Z</updated>
        <summary type="html"><![CDATA[Web-based interactions can be frequently represented by an attributed graph,
and node clustering in such graphs has received much attention lately. Multiple
efforts have successfully applied Graph Convolutional Networks (GCN), though
with some limits on accuracy as GCNs have been shown to suffer from
over-smoothing issues. Though other methods (particularly those based on
Laplacian Smoothing) have reported better accuracy, a fundamental limitation of
all the work is a lack of scalability. This paper addresses this open problem
by relating the Laplacian smoothing to the Generalized PageRank and applying a
random-walk based algorithm as a scalable graph filter. This forms the basis
for our scalable deep clustering algorithm, RwSL, where through a
self-supervised mini-batch training mechanism, we simultaneously optimize a
deep neural network for sample-cluster assignment distribution and an
autoencoder for a clustering-oriented embedding. Using 6 real-world datasets
and 6 clustering metrics, we show that RwSL achieved improved results over
several recent baselines. Most notably, we show that RwSL, unlike all other
deep clustering frameworks, can continue to scale beyond graphs with more than
one million nodes, i.e., handle web-scale. We also demonstrate how RwSL could
perform node clustering on a graph with 1.8 billion edges using only a single
GPU.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"&gt;Xiang Li&lt;/a&gt; (1), &lt;a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1"&gt;Dong Li&lt;/a&gt; (2), &lt;a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1"&gt;Ruoming Jin&lt;/a&gt; (2), &lt;a href="http://arxiv.org/find/cs/1/au:+Agrawal_G/0/1/0/all/0/1"&gt;Gagan Agrawal&lt;/a&gt; (3), &lt;a href="http://arxiv.org/find/cs/1/au:+Ramnath_R/0/1/0/all/0/1"&gt;Rajiv Ramnath&lt;/a&gt; (4) ((1) Ohio State University, (2) Kent State University, (3) Augusta University)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shift-Equivariant Similarity-Preserving Hypervector Representations of Sequences. (arXiv:2112.15475v1 [cs.AI])]]></title>
        <id>http://arxiv.org/abs/2112.15475</id>
        <link href="http://arxiv.org/abs/2112.15475"/>
        <updated>2022-01-03T07:15:43.703Z</updated>
        <summary type="html"><![CDATA[Hyperdimensional Computing (HDC), also known as Vector-Symbolic Architectures
(VSA), is a promising framework for the development of cognitive architectures
and artificial intelligence systems, as well as for technical applications and
emerging neuromorphic and nanoscale hardware. HDC/VSA operate with
hypervectors, i.e., distributed vector representations of large fixed dimension
(usually > 1000). One of the key ingredients of HDC/VSA are the methods for
encoding data of various types (from numeric scalars and vectors to graphs)
into hypervectors. In this paper, we propose an approach for the formation of
hypervectors of sequences that provides both an equivariance with respect to
the shift of sequences and preserves the similarity of sequences with identical
elements at nearby positions. Our methods represent the sequence elements by
compositional hypervectors and exploit permutations of hypervectors for
representing the order of sequence elements. We experimentally explored the
proposed representations using a diverse set of tasks with data in the form of
symbolic strings. Although our approach is feature-free as it forms the
hypervector of a sequence from the hypervectors of its symbols at their
positions, it demonstrated the performance on a par with the methods that apply
various features, such as subsequences. The proposed techniques were designed
for the HDC/VSA model known as Sparse Binary Distributed Representations.
However, they can be adapted to hypervectors in formats of other HDC/VSA
models, as well as for representing sequences of types other than symbolic
strings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Rachkovskij_D/0/1/0/all/0/1"&gt;Dmitri A. Rachkovskij&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modelling of Bi-directional Spatio-Temporal Dependence and Users' Dynamic Preferences for Missing POI Check-in Identification. (arXiv:2112.15285v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15285</id>
        <link href="http://arxiv.org/abs/2112.15285"/>
        <updated>2022-01-03T07:15:43.686Z</updated>
        <summary type="html"><![CDATA[Human mobility data accumulated from Point-of-Interest (POI) check-ins
provides great opportunity for user behavior understanding. However, data
quality issues (e.g., geolocation information missing, unreal check-ins, data
sparsity) in real-life mobility data limit the effectiveness of existing
POI-oriented studies, e.g., POI recommendation and location prediction, when
applied to real applications. To this end, in this paper, we develop a model,
named Bi-STDDP, which can integrate bi-directional spatio-temporal dependence
and users' dynamic preferences, to identify the missing POI check-in where a
user has visited at a specific time. Specifically, we first utilize
bi-directional global spatial and local temporal information of POIs to capture
the complex dependence relationships. Then, target temporal pattern in
combination with user and POI information are fed into a multi-layer network to
capture users' dynamic preferences. Moreover, the dynamic preferences are
transformed into the same space as the dependence relationships to form the
final model. Finally, the proposed model is evaluated on three large-scale
real-world datasets and the results demonstrate significant improvements of our
model compared with state-of-the-art methods. Also, it is worth noting that the
proposed model can be naturally extended to address POI recommendation and
location prediction tasks with competitive performances.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xi_D/0/1/0/all/0/1"&gt;Dongbo Xi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1"&gt;Fuzhen Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yanchi Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1"&gt;Jingjing Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1"&gt;Hui Xiong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1"&gt;Qing He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring the pattern of Emotion in children with ASD as an early biomarker through Recurring-Convolution Neural Network (R-CNN). (arXiv:2112.14983v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2112.14983</id>
        <link href="http://arxiv.org/abs/2112.14983"/>
        <updated>2022-01-03T07:15:43.677Z</updated>
        <summary type="html"><![CDATA[Autism Spectrum Disorder (ASD) is found to be a major concern among various
occupational therapists. The foremost challenge of this neurodevelopmental
disorder lies in the fact of analyzing and exploring various symptoms of the
children at their early stage of development. Such early identification could
prop up the therapists and clinicians to provide proper assistive support to
make the children lead an independent life. Facial expressions and emotions
perceived by the children could contribute to such early intervention of
autism. In this regard, the paper implements in identifying basic facial
expression and exploring their emotions upon a time variant factor. The
emotions are analyzed by incorporating the facial expression identified through
CNN using 68 landmark points plotted on the frontal face with a prediction
network formed by RNN known as RCNN-FER system. The paper adopts R-CNN to take
the advantage of increased accuracy and performance with decreased time
complexity in predicting emotion as a textual network analysis. The papers
proves better accuracy in identifying the emotion in autistic children when
compared over simple machine learning models built for such identifications
contributing to autistic society.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+P_A/0/1/0/all/0/1"&gt;Abirami S P&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+G_K/0/1/0/all/0/1"&gt;Kousalya G&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+R_K/0/1/0/all/0/1"&gt;Karthick R&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust Control Design: Implicit Regularization and Sample Complexity. (arXiv:2101.01041v3 [math.OC] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2101.01041</id>
        <link href="http://arxiv.org/abs/2101.01041"/>
        <updated>2022-01-03T07:15:43.675Z</updated>
        <summary type="html"><![CDATA[Direct policy search serves as one of the workhorses in modern reinforcement
learning (RL), and its applications in continuous control tasks have recently
attracted increasing attention. In this work, we investigate the convergence
theory of policy gradient (PG) methods for learning the linear risk-sensitive
and robust controller. In particular, we develop PG methods that can be
implemented in a derivative-free fashion by sampling system trajectories, and
establish both global convergence and sample complexity results in the
solutions of two fundamental settings in risk-sensitive and robust control: the
finite-horizon linear exponential quadratic Gaussian, and the finite-horizon
linear-quadratic disturbance attenuation problems. As a by-product, our results
also provide the first sample complexity for the global convergence of PG
methods on solving zero-sum linear-quadratic dynamic games, a
nonconvex-nonconcave minimax optimization problem that serves as a baseline
setting in multi-agent reinforcement learning (MARL) with continuous spaces.
One feature of our algorithms is that during the learning phase, a certain
level of robustness/risk-sensitivity of the controller is preserved, which we
termed as the implicit regularization property, and is an essential requirement
in safety-critical control systems.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Zhang_K/0/1/0/all/0/1"&gt;Kaiqing Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Zhang_X/0/1/0/all/0/1"&gt;Xiangyuan Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Hu_B/0/1/0/all/0/1"&gt;Bin Hu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Basar_T/0/1/0/all/0/1"&gt;Tamer Ba&amp;#x15f;ar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChunkFormer: Learning Long Time Series with Multi-stage Chunked Transformer. (arXiv:2112.15087v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15087</id>
        <link href="http://arxiv.org/abs/2112.15087"/>
        <updated>2022-01-03T07:15:43.673Z</updated>
        <summary type="html"><![CDATA[The analysis of long sequence data remains challenging in many real-world
applications. We propose a novel architecture, ChunkFormer, that improves the
existing Transformer framework to handle the challenges while dealing with long
time series. Original Transformer-based models adopt an attention mechanism to
discover global information along a sequence to leverage the contextual data.
Long sequential data traps local information such as seasonality and
fluctuations in short data sequences. In addition, the original Transformer
consumes more resources by carrying the entire attention matrix during the
training course. To overcome these challenges, ChunkFormer splits the long
sequences into smaller sequence chunks for the attention calculation,
progressively applying different chunk sizes in each stage. In this way, the
proposed model gradually learns both local and global information without
changing the total length of the input sequences. We have extensively tested
the effectiveness of this new architecture on different business domains and
have proved the advantage of such a model over the existing Transformer-based
models.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ju_Y/0/1/0/all/0/1"&gt;Yue Ju&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Isac_A/0/1/0/all/0/1"&gt;Alka Isac&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1"&gt;Yimin Nie&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Causal Effects Evaluation in A/B Testing with a Reinforcement Learning Framework. (arXiv:2002.01711v5 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2002.01711</id>
        <link href="http://arxiv.org/abs/2002.01711"/>
        <updated>2022-01-03T07:15:43.672Z</updated>
        <summary type="html"><![CDATA[A/B testing, or online experiment is a standard business strategy to compare
a new product with an old one in pharmaceutical, technological, and traditional
industries. Major challenges arise in online experiments of two-sided
marketplace platforms (e.g., Uber) where there is only one unit that receives a
sequence of treatments over time. In those experiments, the treatment at a
given time impacts current outcome as well as future outcomes. The aim of this
paper is to introduce a reinforcement learning framework for carrying A/B
testing in these experiments, while characterizing the long-term treatment
effects. Our proposed testing procedure allows for sequential monitoring and
online updating. It is generally applicable to a variety of treatment designs
in different industries. In addition, we systematically investigate the
theoretical properties (e.g., size and power) of our testing procedure.
Finally, we apply our framework to both simulated data and a real-world data
example obtained from a technological company to illustrate its advantage over
the current practice. A Python implementation of our test is available at
https://github.com/callmespring/CausalRL.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1"&gt;Chengchun Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"&gt;Xiaoyu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1"&gt;Shikai Luo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1"&gt;Hongtu Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1"&gt;Jieping Ye&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1"&gt;Rui Song&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adversarial Learning for Incentive Optimization in Mobile Payment Marketing. (arXiv:2112.15434v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15434</id>
        <link href="http://arxiv.org/abs/2112.15434"/>
        <updated>2022-01-03T07:15:43.671Z</updated>
        <summary type="html"><![CDATA[Many payment platforms hold large-scale marketing campaigns, which allocate
incentives to encourage users to pay through their applications. To maximize
the return on investment, incentive allocations are commonly solved in a
two-stage procedure. After training a response estimation model to estimate the
users' mobile payment probabilities (MPP), a linear programming process is
applied to obtain the optimal incentive allocation. However, the large amount
of biased data in the training set, generated by the previous biased allocation
policy, causes a biased estimation. This bias deteriorates the performance of
the response model and misleads the linear programming process, dramatically
degrading the performance of the resulting allocation policy. To overcome this
obstacle, we propose a bias correction adversarial network. Our method
leverages the small set of unbiased data obtained under a full-randomized
allocation policy to train an unbiased model and then uses it to reduce the
bias with adversarial learning. Offline and online experimental results
demonstrate that our method outperforms state-of-the-art approaches and
significantly improves the performance of the resulting allocation policy in a
real-world marketing campaign.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"&gt;Xuanying Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"&gt;Zhining Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1"&gt;Li Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1"&gt;Sen Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_L/0/1/0/all/0/1"&gt;Lihong Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1"&gt;Xiaodong Zeng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1"&gt;Yize Tan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1"&gt;Jinjie Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Studying the Interplay between Information Loss and Operation Loss in Representations for Classification. (arXiv:2112.15238v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15238</id>
        <link href="http://arxiv.org/abs/2112.15238"/>
        <updated>2022-01-03T07:15:43.635Z</updated>
        <summary type="html"><![CDATA[Information-theoretic measures have been widely adopted in the design of
features for learning and decision problems. Inspired by this, we look at the
relationship between i) a weak form of information loss in the Shannon sense
and ii) the operation loss in the minimum probability of error (MPE) sense when
considering a family of lossy continuous representations (features) of a
continuous observation. We present several results that shed light on this
interplay. Our first result offers a lower bound on a weak form of information
loss as a function of its respective operation loss when adopting a discrete
lossy representation (quantization) instead of the original raw observation.
From this, our main result shows that a specific form of vanishing information
loss (a weak notion of asymptotic informational sufficiency) implies a
vanishing MPE loss (or asymptotic operational sufficiency) when considering a
general family of lossy continuous representations. Our theoretical findings
support the observation that the selection of feature representations that
attempt to capture informational sufficiency is appropriate for learning, but
this selection is a rather conservative design principle if the intended goal
is achieving MPE in classification. Supporting this last point, and under some
structural conditions, we show that it is possible to adopt an alternative
notion of informational sufficiency (strictly weaker than pure sufficiency in
the mutual information sense) to achieve operational sufficiency in learning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1"&gt;Jorge F. Silva&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tobar_F/0/1/0/all/0/1"&gt;Felipe Tobar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vicuna_M/0/1/0/all/0/1"&gt;Mario Vicu&amp;#xf1;a&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cordova_F/0/1/0/all/0/1"&gt;Felipe Cordova&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PINNs for the Solution of the Hyperbolic Buckley-Leverett Problem with a Non-convex Flux Function. (arXiv:2112.14826v1 [physics.flu-dyn])]]></title>
        <id>http://arxiv.org/abs/2112.14826</id>
        <link href="http://arxiv.org/abs/2112.14826"/>
        <updated>2022-01-03T07:15:43.634Z</updated>
        <summary type="html"><![CDATA[The displacement of two immiscible fluids is a common problem in fluid flow
in porous media. Such a problem can be posed as a partial differential equation
(PDE) in what is commonly referred to as a Buckley-Leverett (B-L) problem. The
B-L problem is a non-linear hyperbolic conservation law that is known to be
notoriously difficult to solve using traditional numerical methods. Here, we
address the forward hyperbolic B-L problem with a nonconvex flux function using
physics-informed neural networks (PINNs). The contributions of this paper are
twofold. First, we present a PINN approach to solve the hyperbolic B-L problem
by embedding the Oleinik entropy condition into the neural network residual. We
do not use a diffusion term (artificial viscosity) in the residual-loss, but we
rely on the strong form of the PDE. Second, we use the Adam optimizer with
residual-based adaptive refinement (RAR) algorithm to achieve an ultra-low loss
without weighting. Our solution method can accurately capture the shock-front
and produce an accurate overall solution. We report a L2 validation error of 2
x 10-2 and a L2 loss of 1x 10-6. The proposed method does not require any
additional regularization or weighting of losses to obtain such accurate
solution.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Diab_W/0/1/0/all/0/1"&gt;Waleed Diab&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Kobaisi_M/0/1/0/all/0/1"&gt;Mohammed Al Kobaisi&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SplitBrain: Hybrid Data and Model Parallel Deep Learning. (arXiv:2112.15317v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15317</id>
        <link href="http://arxiv.org/abs/2112.15317"/>
        <updated>2022-01-03T07:15:43.634Z</updated>
        <summary type="html"><![CDATA[The recent success of deep learning applications has coincided with those
widely available powerful computational resources for training sophisticated
machine learning models with huge datasets. Nonetheless, training large models
such as convolutional neural networks using model parallelism (as opposed to
data parallelism) is challenging because the complex nature of communication
between model shards makes it difficult to partition the computation
efficiently across multiple machines with an acceptable trade-off. This paper
presents SplitBrain, a high performance distributed deep learning framework
supporting hybrid data and model parallelism. Specifically, SplitBrain provides
layer-specific partitioning that co-locates compute intensive convolutional
layers while sharding memory demanding layers. A novel scalable group
communication is proposed to further improve the training throughput with
reduced communication overhead. The results show that SplitBrain can achieve
nearly linear speedup while saving up to 67\% of memory consumption for data
and model parallel VGG over CIFAR-10.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lai_F/0/1/0/all/0/1"&gt;Farley Lai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kadav_A/0/1/0/all/0/1"&gt;Asim Kadav&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kruus_E/0/1/0/all/0/1"&gt;Erik Kruus&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deconfounded Training for Graph Neural Networks. (arXiv:2112.15089v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15089</id>
        <link href="http://arxiv.org/abs/2112.15089"/>
        <updated>2022-01-03T07:15:43.631Z</updated>
        <summary type="html"><![CDATA[Learning powerful representations is one central theme of graph neural
networks (GNNs). It requires refining the critical information from the input
graph, instead of the trivial patterns, to enrich the representations. Towards
this end, graph attention and pooling methods prevail. They mostly follow the
paradigm of "learning to attend". It maximizes the mutual information between
the attended subgraph and the ground-truth label. However, this training
paradigm is prone to capture the spurious correlations between the trivial
subgraph and the label. Such spurious correlations are beneficial to
in-distribution (ID) test evaluations, but cause poor generalization in the
out-of-distribution (OOD) test data. In this work, we revisit the GNN modeling
from the causal perspective. On the top of our causal assumption, the trivial
information serves as a confounder between the critical information and the
label, which opens a backdoor path between them and makes them spuriously
correlated. Hence, we present a new paradigm of deconfounded training (DTP)
that better mitigates the confounding effect and latches on the critical
information, to enhance the representation and generalization ability.
Specifically, we adopt the attention modules to disentangle the critical
subgraph and trivial subgraph. Then we make each critical subgraph fairly
interact with diverse trivial subgraphs to achieve a stable prediction. It
allows GNNs to capture a more reliable subgraph whose relation with the label
is robust across different distributions. We conduct extensive experiments on
synthetic and real-world datasets to demonstrate the effectiveness.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1"&gt;Yongduo Sui&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"&gt;Xiang Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"&gt;Jiancan Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1"&gt;Xiangnan He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1"&gt;Tat-Seng Chua&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Music-to-Dance Generation with Optimal Transport. (arXiv:2112.01806v1 [cs.SD] CROSS LISTED)]]></title>
        <id>http://arxiv.org/abs/2112.01806</id>
        <link href="http://arxiv.org/abs/2112.01806"/>
        <updated>2022-01-03T07:15:43.629Z</updated>
        <summary type="html"><![CDATA[Dance choreography for a piece of music is a challenging task, having to be
creative in presenting distinctive stylistic dance elements while taking into
account the musical theme and rhythm. It has been tackled by different
approaches such as similarity retrieval, sequence-to-sequence modeling and
generative adversarial networks, but their generated dance sequences are often
short of motion realism, diversity and music consistency. In this paper, we
propose a Music-to-Dance with Optimal Transport Network (MDOT-Net) for learning
to generate 3D dance choreographs from music. We introduce an optimal transport
distance for evaluating the authenticity of the generated dance distribution
and a Gromov-Wasserstein distance to measure the correspondence between the
dance distribution and the input music. This gives a well defined and
non-divergent training objective that mitigates the limitation of standard GAN
training which is frequently plagued with instability and divergent generator
loss issues. Extensive experiments demonstrate that our MDOT-Net can synthesize
realistic and diverse dances which achieve an organic unity with the input
music, reflecting the shared intentionality and matching the rhythmic
articulation.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1"&gt;Shuang Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1"&gt;Shijian Lu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1"&gt;Li Cheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine Learning Application Development: Practitioners' Insights. (arXiv:2112.15277v1 [cs.SE])]]></title>
        <id>http://arxiv.org/abs/2112.15277</id>
        <link href="http://arxiv.org/abs/2112.15277"/>
        <updated>2022-01-03T07:15:43.625Z</updated>
        <summary type="html"><![CDATA[Nowadays, intelligent systems and services are getting increasingly popular
as they provide data-driven solutions to diverse real-world problems, thanks to
recent breakthroughs in Artificial Intelligence (AI) and Machine Learning (ML).
However, machine learning meets software engineering not only with promising
potentials but also with some inherent challenges. Despite some recent research
efforts, we still do not have a clear understanding of the challenges of
developing ML-based applications and the current industry practices. Moreover,
it is unclear where software engineering researchers should focus their efforts
to better support ML application developers. In this paper, we report about a
survey that aimed to understand the challenges and best practices of ML
application development. We synthesize the results obtained from 80
practitioners (with diverse skills, experience, and application domains) into
17 findings; outlining challenges and best practices for ML application
development. Practitioners involved in the development of ML-based software
systems can leverage the summarized best practices to improve the quality of
their system. We hope that the reported challenges will inform the research
community about topics that need to be investigated to improve the engineering
process and the quality of ML-based applications.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1"&gt;Md Saidur Rahman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1"&gt;Foutse Khomh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hamidi_A/0/1/0/all/0/1"&gt;Alaleh Hamidi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1"&gt;Jinghui Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Antoniol_G/0/1/0/all/0/1"&gt;Giuliano Antoniol&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Washizaki_H/0/1/0/all/0/1"&gt;Hironori Washizaki&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Unified DRO View of Multi-class Loss Functions with top-N Consistency. (arXiv:2112.14869v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14869</id>
        <link href="http://arxiv.org/abs/2112.14869"/>
        <updated>2022-01-03T07:15:43.624Z</updated>
        <summary type="html"><![CDATA[Multi-class classification is one of the most common tasks in machine
learning applications, where data is labeled by one of many class labels. Many
loss functions have been proposed for multi-class classification including two
well-known ones, namely the cross-entropy (CE) loss and the crammer-singer (CS)
loss (aka. the SVM loss). While CS loss has been used widely for traditional
machine learning tasks, CE loss is usually a default choice for multi-class
deep learning tasks. There are also top-$k$ variants of CS loss and CE loss
that are proposed to promote the learning of a classifier for achieving better
top-$k$ accuracy. Nevertheless, it still remains unclear the relationship
between these different losses, which hinders our understanding of their
expectations in different scenarios. In this paper, we present a unified view
of the CS/CE losses and their smoothed top-$k$ variants by proposing a new
family of loss functions, which are arguably better than the CS/CE losses when
the given label information is incomplete and noisy. The new family of smooth
loss functions named {label-distributionally robust (LDR) loss} is defined by
leveraging the distributionally robust optimization (DRO) framework to model
the uncertainty in the given label information, where the uncertainty over true
class labels is captured by using distributional weights for each label
regularized by a function.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1"&gt;Dixian Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1"&gt;Tianbao Yang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Transfer-Learning for patient specific model re-calibration: Application to sEMG-Classification. (arXiv:2112.15019v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15019</id>
        <link href="http://arxiv.org/abs/2112.15019"/>
        <updated>2022-01-03T07:15:43.621Z</updated>
        <summary type="html"><![CDATA[Accurate decoding of surface electromyography (sEMG) is pivotal for
muscle-to-machine-interfaces (MMI) and their application for e.g.
rehabilitation therapy. sEMG signals have high inter-subject variability, due
to various factors, including skin thickness, body fat percentage, and
electrode placement. Therefore, obtaining high generalization quality of a
trained sEMG decoder is quite challenging. Usually, machine learning based sEMG
decoders are either trained on subject-specific data, or at least recalibrated
for each user, individually. Even though, deep learning algorithms produced
several state of the art results for sEMG decoding,however, due to the limited
amount of availability of sEMG data, the deep learning models are prone to
overfitting. Recently, transfer learning for domain adaptation improved
generalization quality with reduced training time on various machine learning
tasks. In this study, we investigate the effectiveness of transfer learning
using weight initialization for recalibration of two different pretrained deep
learning models on a new subjects data, and compare their performance to
subject-specific models. To the best of our knowledge, this is the first study
that thoroughly investigated weight-initialization based transfer learning for
sEMG classification and compared transfer learning to subject-specific
modeling. We tested our models on three publicly available databases under
various settings. On average over all settings, our transfer learning approach
improves 5~\%-points on the pretrained models without fine-tuning and
12~\%-points on the subject-specific models, while being trained on average
22~\% fewer epochs. Our results indicate that transfer learning enables faster
training on fewer samples than user-specific models, and improves the
performance of pretrained models as long as enough data is available.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lehmler_S/0/1/0/all/0/1"&gt;Stephan Johann Lehmler&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Saif_ur_Rehman_M/0/1/0/all/0/1"&gt;Muhammad Saif-ur-Rehman&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Glasmachers_T/0/1/0/all/0/1"&gt;Tobias Glasmachers&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Iossifidis_I/0/1/0/all/0/1"&gt;Ioannis Iossifidis&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Hierarchical Factorization Machines for User's Event Sequence Analysis. (arXiv:2112.15292v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15292</id>
        <link href="http://arxiv.org/abs/2112.15292"/>
        <updated>2022-01-03T07:15:43.620Z</updated>
        <summary type="html"><![CDATA[Many prediction tasks of real-world applications need to model multi-order
feature interactions in user's event sequence for better detection performance.
However, existing popular solutions usually suffer two key issues: 1) only
focusing on feature interactions and failing to capture the sequence influence;
2) only focusing on sequence information, but ignoring internal feature
relations of each event, thus failing to extract a better event representation.
In this paper, we consider a two-level structure for capturing the hierarchical
information over user's event sequence: 1) learning effective feature
interactions based event representation; 2) modeling the sequence
representation of user's historical events. Experimental results on both
industrial and public datasets clearly demonstrate that our model achieves
significantly better performance compared with state-of-the-art baselines.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xi_D/0/1/0/all/0/1"&gt;Dongbo Xi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1"&gt;Fuzhen Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1"&gt;Bowen Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1"&gt;Yongchun Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1"&gt;Shuai Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1"&gt;Dan Hong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1"&gt;Tao Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1"&gt;Xi Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1"&gt;Qing He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Crowd-sensing Enhanced Parking Patrol using Trajectories of Sharing Bikes. (arXiv:2110.15557v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.15557</id>
        <link href="http://arxiv.org/abs/2110.15557"/>
        <updated>2022-01-03T07:15:43.620Z</updated>
        <summary type="html"><![CDATA[Illegal vehicle parking is a common urban problem faced by major cities in
the world, as it incurs traffic jams, which lead to air pollution and traffic
accidents. The government highly relies on active human efforts to detect
illegal parking events. However, such an approach is extremely ineffective to
cover a large city since the police have to patrol over the entire city roads.

The massive and high-quality sharing bike trajectories from Mobike offer us a
unique opportunity to design a ubiquitous illegal parking detection approach,
as most of the illegal parking events happen at curbsides and have significant
impact on the bike users. The detection result can guide the patrol schedule,
i.e. send the patrol policemen to the region with higher illegal parking risks,
and further improve the patrol efficiency. Inspired by this idea, three main
components are employed in the proposed framework: 1)~{\em trajectory
pre-processing}, which filters outlier GPS points, performs map-matching, and
builds trajectory indexes; 2)~{\em illegal parking detection}, which models the
normal trajectories, extracts features from the evaluation trajectories, and
utilizes a distribution test-based method to discover the illegal parking
events; and 3)~{\em patrol scheduling}, which leverages the detection result as
reference context, and models the scheduling task as a multi-agent
reinforcement learning problem to guide the patrol police. Finally, extensive
experiments are presented to validate the effectiveness of illegal parking
detection, as well as the improvement of patrol efficiency.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1"&gt;Tianfu He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1"&gt;Jie Bao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"&gt;Yexin Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1"&gt;Hui He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1"&gt;Yu Zheng&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Robustness of Neural Networks. (arXiv:2112.15188v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2112.15188</id>
        <link href="http://arxiv.org/abs/2112.15188"/>
        <updated>2022-01-03T07:15:43.613Z</updated>
        <summary type="html"><![CDATA[We introduce several new datasets namely ImageNet-A/O and ImageNet-R as well
as a synthetic environment and testing suite we called CAOS. ImageNet-A/O allow
researchers to focus in on the blind spots remaining in ImageNet. ImageNet-R
was specifically created with the intention of tracking robust representation
as the representations are no longer simply natural but include artistic, and
other renditions. The CAOS suite is built off of CARLA simulator which allows
for the inclusion of anomalous objects and can create reproducible synthetic
environment and scenes for testing robustness. All of the datasets were created
for testing robustness and measuring progress in robustness. The datasets have
been used in various other works to measure their own progress in robustness
and allowing for tangential progress that does not focus exclusively on natural
accuracy.

Given these datasets, we created several novel methods that aim to advance
robustness research. We build off of simple baselines in the form of Maximum
Logit, and Typicality Score as well as create a novel data augmentation method
in the form of DeepAugment that improves on the aforementioned benchmarks.
Maximum Logit considers the logit values instead of the values after the
softmax operation, while a small change produces noticeable improvements. The
Typicality Score compares the output distribution to a posterior distribution
over classes. We show that this improves performance over the baseline in all
but the segmentation task. Speculating that perhaps at the pixel level the
semantic information of a pixel is less meaningful than that of class level
information. Finally the new augmentation technique of DeepAugment utilizes
neural networks to create augmentations on images that are radically different
than the traditional geometric and camera based transformations used
previously.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1"&gt;Steven Basart&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[G-PATE: Scalable Differentially Private Data Generator via Private Aggregation of Teacher Discriminators. (arXiv:1906.09338v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1906.09338</id>
        <link href="http://arxiv.org/abs/1906.09338"/>
        <updated>2022-01-03T07:15:43.590Z</updated>
        <summary type="html"><![CDATA[Recent advances in machine learning have largely benefited from the massive
accessible training data. However, large-scale data sharing has raised great
privacy concerns. In this work, we propose a novel privacy-preserving data
Generative model based on the PATE framework (G-PATE), aiming to train a
scalable differentially private data generator that preserves high generated
data utility. Our approach leverages generative adversarial nets to generate
data, combined with private aggregation among different discriminators to
ensure strong privacy guarantees. Compared to existing approaches, G-PATE
significantly improves the use of privacy budgets. In particular, we train a
student data generator with an ensemble of teacher discriminators and propose a
novel private gradient aggregation mechanism to ensure differential privacy on
all information that flows from teacher discriminators to the student
generator. In addition, with random projection and gradient discretization, the
proposed gradient aggregation mechanism is able to effectively deal with
high-dimensional gradient vectors. Theoretically, we prove that G-PATE ensures
differential privacy for the data generator. Empirically, we demonstrate the
superiority of G-PATE over prior work through extensive experiments. We show
that G-PATE is the first work being able to generate high-dimensional image
data with high data utility under limited privacy budgets ($\epsilon \le 1$).
Our code is available at https://github.com/AI-secure/G-PATE.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1"&gt;Yunhui Long&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1"&gt;Boxin Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1"&gt;Zhuolin Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1"&gt;Bhavya Kailkhura&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1"&gt;Aston Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gunter_C/0/1/0/all/0/1"&gt;Carl A. Gunter&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1"&gt;Bo Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speedup deep learning models on GPU by taking advantage of efficient unstructured pruning and bit-width reduction. (arXiv:2112.15445v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15445</id>
        <link href="http://arxiv.org/abs/2112.15445"/>
        <updated>2022-01-03T07:15:43.589Z</updated>
        <summary type="html"><![CDATA[This work is focused on the pruning of some convolutional neural networks
(CNNs) and improving theirs efficiency on graphic processing units (GPU) by
using a direct sparse algorithm. The Nvidia deep neural network (cuDnn) library
is the most effective implementations of deep learning (DL) algorithms for
GPUs. GPUs are the most commonly used accelerators for deep learning
computations. One of the most common techniques for improving the efficiency of
CNN models is weight pruning and quantization. There are two main types of
pruning: structural and non-structural. The first enables much easier
acceleration on many type of accelerators, but with this type it is difficult
to achieve a sparsity level and accuracy as high as that obtained with the
second type. Non-structural pruning with retraining can generate a weight
tensors up to 90% or more of sparsity in some deep CNN models. In this article
the pruning algorithm is presented which makes it possible to achieve high
sparsity levels without accuracy drop. In the next stage the linear and
non-linear quantization is adapted for further time and footprint reduction.
This paper is an extended of previously published paper concerning effective
pruning techniques and present real models pruned with high sparsities and
reduced precision which can achieve better performance than the CuDnn library.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Pietron_M/0/1/0/all/0/1"&gt;Marcin Pietro&amp;#x144;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zurek_D/0/1/0/all/0/1"&gt;Dominik &amp;#x17b;urek&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memory AMP. (arXiv:2012.10861v5 [cs.IT] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.10861</id>
        <link href="http://arxiv.org/abs/2012.10861"/>
        <updated>2022-01-03T07:15:43.588Z</updated>
        <summary type="html"><![CDATA[Approximate message passing (AMP) is a low-cost iterative
parameter-estimation technique for certain high-dimensional linear systems with
non-Gaussian distributions. However, AMP only applies to independent
identically distributed (IID) transform matrices, but may become unreliable
(e.g., perform poorly or even diverge) for other matrix ensembles, especially
for ill-conditioned ones. Orthogonal/vector AMP (OAMP/VAMP) was proposed for
general right-unitarily-invariant matrices to handle this difficulty. However,
the Bayes-optimal OAMP/VAMP (BO-OAMP/VAMP) requires a high-complexity linear
minimum mean square error (MMSE) estimator. This limits the application of
OAMP/VAMP to large-scale systems.

To solve the disadvantages of AMP and BO-OAMP/VAMP, this paper proposes a
memory AMP (MAMP) framework under an orthogonality principle, which guarantees
the asymptotic IID Gaussianity of estimation errors in MAMP. We present an
orthogonalization procedure for the local memory estimators to realize the
required orthogonality for MAMP. Furthermore, we propose a Bayes-optimal MAMP
(BO-MAMP), in which a long-memory matched filter is proposed for interference
suppression. The complexity of BO-MAMP is comparable to AMP. A state evolution
is derived to asymptotically characterize the performance of BO-MAMP. Based on
state evolution, the relaxation parameters and damping vector in BO-MAMP are
optimized. For all right-unitarily-invariant matrices, the state evolution of
the optimized BO-MAMP converges to the same fixed point as that of the
high-complexity BO-OAMP/VAMP and is Bayes-optimal if its state evolution has a
unique fixed point. Finally, simulations are provided to verify the validity
and accuracy of the theoretical results.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1"&gt;Lei Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1"&gt;Shunqi Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kurkoski_B/0/1/0/all/0/1"&gt;Brian M. Kurkoski&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uniform-PAC Bounds for Reinforcement Learning with Linear Function Approximation. (arXiv:2106.11612v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.11612</id>
        <link href="http://arxiv.org/abs/2106.11612"/>
        <updated>2022-01-03T07:15:43.561Z</updated>
        <summary type="html"><![CDATA[We study reinforcement learning (RL) with linear function approximation.
Existing algorithms for this problem only have high-probability regret and/or
Probably Approximately Correct (PAC) sample complexity guarantees, which cannot
guarantee the convergence to the optimal policy. In this paper, in order to
overcome the limitation of existing algorithms, we propose a new algorithm
called FLUTE, which enjoys uniform-PAC convergence to the optimal policy with
high probability. The uniform-PAC guarantee is the strongest possible guarantee
for reinforcement learning in the literature, which can directly imply both PAC
and high probability regret bounds, making our algorithm superior to all
existing algorithms with linear function approximation. At the core of our
algorithm is a novel minimax value function estimator and a multi-level
partition scheme to select the training samples from historical observations.
Both of these techniques are new and of independent interest.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1"&gt;Jiafan He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Investigating and Modeling the Dynamics of Long Ties. (arXiv:2109.10523v2 [cs.SI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2109.10523</id>
        <link href="http://arxiv.org/abs/2109.10523"/>
        <updated>2022-01-03T07:15:43.561Z</updated>
        <summary type="html"><![CDATA[Long ties, the social ties that bridge different communities, are widely
believed to play crucial roles in spreading novel information in social
networks. However, some existing network theories and prediction models
indicate that long ties might dissolve quickly or eventually become redundant,
thus putting into question the long-term value of long ties. Our empirical
analysis of real-world dynamic networks shows that contrary to such reasoning,
long ties are more likely to persist than other social ties, and that many of
them constantly function as social bridges without being embedded in local
networks. Using a novel cost-benefit analysis model combined with machine
learning, we show that long ties are highly beneficial, which instinctively
motivates people to expend extra effort to maintain them. This partly explains
why long ties are more persistent than what has been suggested by many existing
theories and models. Overall, our study suggests the need for social
interventions that can promote the formation of long ties, such as mixing
people with diverse backgrounds.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lyu_D/0/1/0/all/0/1"&gt;Ding Lyu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1"&gt;Yuan Yuan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"&gt;Lin Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"&gt;Xiaofan Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pentland_A/0/1/0/all/0/1"&gt;Alex Pentland&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fairness-Oriented User Scheduling for Bursty Downlink Transmission Using Multi-Agent Reinforcement Learning. (arXiv:2012.15081v13 [cs.OS] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2012.15081</id>
        <link href="http://arxiv.org/abs/2012.15081"/>
        <updated>2022-01-03T07:15:43.552Z</updated>
        <summary type="html"><![CDATA[In this work, we develop practical user scheduling algorithms for downlink
bursty traffic with emphasis on user fairness. In contrast to the conventional
scheduling algorithms that either equally divides the transmission time slots
among users or maximizing some ratios without physcial meanings, we propose to
use the 5%-tile user data rate (5TUDR) as the metric to evaluate user fairness.
Since it is difficult to directly optimize 5TUDR, we first cast the problem
into the stochastic game framework and subsequently propose a Multi-Agent
Reinforcement Learning (MARL)-based algorithm to perform distributed
optimization on the resource block group (RBG) allocation. Furthermore, each
MARL agent is designed to take information measured by network counters from
multiple network layers (e.g. Channel Quality Indicator, Buffer size) as the
input states while the RBG allocation as action with a proposed reward function
designed to maximize 5TUDR. Extensive simulation is performed to show that the
proposed MARL-based scheduler can achieve fair scheduling while maintaining
good average network throughput as compared to conventional schedulers.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1"&gt;Mingqi Yuan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1"&gt;Qi Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Pun_M/0/1/0/all/0/1"&gt;Man-on Pun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yi Chen&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Motif Graph Neural Network. (arXiv:2112.14900v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14900</id>
        <link href="http://arxiv.org/abs/2112.14900"/>
        <updated>2022-01-03T07:15:43.545Z</updated>
        <summary type="html"><![CDATA[Graphs can model complicated interactions between entities, which naturally
emerge in many important applications. These applications can often be cast
into standard graph learning tasks, in which a crucial step is to learn
low-dimensional graph representations. Graph neural networks (GNNs) are
currently the most popular model in graph embedding approaches. However,
standard GNNs in the neighborhood aggregation paradigm suffer from limited
discriminative power in distinguishing \emph{high-order} graph structures as
opposed to \emph{low-order} structures. To capture high-order structures,
researchers have resorted to motifs and developed motif-based GNNs. However,
existing motif-based GNNs still often suffer from less discriminative power on
high-order structures. To overcome the above limitations, we propose Motif
Graph Neural Network (MGNN), a novel framework to better capture high-order
structures, hinging on our proposed motif redundancy minimization operator and
injective motif combination. First, MGNN produces a set of node representations
w.r.t. each motif. The next phase is our proposed redundancy minimization among
motifs which compares the motifs with each other and distills the features
unique to each motif. Finally, MGNN performs the updating of node
representations by combining multiple representations from different motifs. In
particular, to enhance the discriminative power, MGNN utilizes an injective
function to combine the representations w.r.t. different motifs. We further
show that our proposed architecture increases the expressive power of GNNs with
a theoretical analysis. We demonstrate that MGNN outperforms state-of-the-art
methods on seven public benchmarks on both node classification and graph
classification tasks.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"&gt;Xuexin Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1"&gt;Ruichu Cai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1"&gt;Yuan Fang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1"&gt;Min Wu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"&gt;Zijian Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1"&gt;Zhifeng Hao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SPViT: Enabling Faster Vision Transformers via Soft Token Pruning. (arXiv:2112.13890v1 [cs.CV] CROSS LISTED)]]></title>
        <id>http://arxiv.org/abs/2112.13890</id>
        <link href="http://arxiv.org/abs/2112.13890"/>
        <updated>2022-01-03T07:15:43.535Z</updated>
        <summary type="html"><![CDATA[Recently, Vision Transformer (ViT) has continuously established new
milestones in the computer vision field, while the high computation and memory
cost makes its propagation in industrial production difficult. Pruning, a
traditional model compression paradigm for hardware efficiency, has been widely
applied in various DNN structures. Nevertheless, it stays ambiguous on how to
perform exclusive pruning on the ViT structure. Considering three key points:
the structural characteristics, the internal data pattern of ViTs, and the
related edge device deployment, we leverage the input token sparsity and
propose a computation-aware soft pruning framework, which can be set up on
vanilla Transformers of both flatten and CNN-type structures, such as
Pooling-based ViT (PiT). More concretely, we design a dynamic attention-based
multi-head token selector, which is a lightweight module for adaptive
instance-wise token selection. We further introduce a soft pruning technique,
which integrates the less informative tokens generated by the selector module
into a package token that will participate in subsequent calculations rather
than being completely discarded. Our framework is bound to the trade-off
between accuracy and computation constraints of specific edge devices through
our proposed computation-aware training strategy. Experimental results show
that our framework significantly reduces the computation cost of ViTs while
maintaining comparable performance on image classification. Moreover, our
framework can guarantee the identified model to meet resource specifications of
mobile devices and FPGA, and even achieve the real-time execution of DeiT-T on
mobile platforms. For example, our method reduces the latency of DeiT-T to 26
ms (26%$\sim $41% superior to existing works) on the mobile device with
0.25%$\sim $4% higher top-1 accuracy on ImageNet. Our code will be released
soon.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Kong_Z/0/1/0/all/0/1"&gt;Zhenglun Kong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dong_P/0/1/0/all/0/1"&gt;Peiyan Dong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1"&gt;Xiaolong Ma&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1"&gt;Xin Meng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Niu_W/0/1/0/all/0/1"&gt;Wei Niu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1"&gt;Mengshu Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ren_B/0/1/0/all/0/1"&gt;Bin Ren&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qin_M/0/1/0/all/0/1"&gt;Minghai Qin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1"&gt;Hao Tang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"&gt;Yanzhi Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Weakly Supervised Change Detection Using Guided Anisotropic Difusion. (arXiv:2112.15367v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2112.15367</id>
        <link href="http://arxiv.org/abs/2112.15367"/>
        <updated>2022-01-03T07:15:43.531Z</updated>
        <summary type="html"><![CDATA[Large scale datasets created from crowdsourced labels or openly available
data have become crucial to provide training data for large scale learning
algorithms. While these datasets are easier to acquire, the data are frequently
noisy and unreliable, which is motivating research on weakly supervised
learning techniques. In this paper we propose original ideas that help us to
leverage such datasets in the context of change detection. First, we propose
the guided anisotropic diffusion (GAD) algorithm, which improves semantic
segmentation results using the input images as guides to perform edge
preserving filtering. We then show its potential in two weakly-supervised
learning strategies tailored for change detection. The first strategy is an
iterative learning method that combines model optimisation and data cleansing
using GAD to extract the useful information from a large scale change detection
dataset generated from open vector data. The second one incorporates GAD within
a novel spatial attention layer that increases the accuracy of weakly
supervised networks trained to perform pixel-level predictions from image-level
labels. Improvements with respect to state-of-the-art are demonstrated on 4
different public datasets.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Daudt_R/0/1/0/all/0/1"&gt;Rodrigo Caye Daudt&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Saux_B/0/1/0/all/0/1"&gt;Bertrand Le Saux&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Boulch_A/0/1/0/all/0/1"&gt;Alexandre Boulch&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Gousseau_Y/0/1/0/all/0/1"&gt;Yann Gousseau&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Recent Trends in Artificial Intelligence-inspired Electronic Thermal Management. (arXiv:2112.14837v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14837</id>
        <link href="http://arxiv.org/abs/2112.14837"/>
        <updated>2022-01-03T07:15:43.530Z</updated>
        <summary type="html"><![CDATA[The rise of computation-based methods in thermal management has gained
immense attention in recent years due to the ability of deep learning to solve
complex 'physics' problems, which are otherwise difficult to be approached
using conventional techniques. Thermal management is required in electronic
systems to keep them from overheating and burning, enhancing their efficiency
and lifespan. For a long time, numerical techniques have been employed to aid
in the thermal management of electronics. However, they come with some
limitations. To increase the effectiveness of traditional numerical approaches
and address the drawbacks faced in conventional approaches, researchers have
looked at using artificial intelligence at various stages of the thermal
management process. The present study discusses in detail, the current uses of
deep learning in the domain of 'electronic' thermal management.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chharia_A/0/1/0/all/0/1"&gt;Aviral Chharia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mehta_N/0/1/0/all/0/1"&gt;Nishi Mehta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1"&gt;Shivam Gupta&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Prajapati_S/0/1/0/all/0/1"&gt;Shivam Prajapati&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is Event Knowledge Graph: A Survey. (arXiv:2112.15280v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15280</id>
        <link href="http://arxiv.org/abs/2112.15280"/>
        <updated>2022-01-03T07:15:43.513Z</updated>
        <summary type="html"><![CDATA[Besides entity-centric knowledge, usually organized as Knowledge Graph (KG),
events are also an essential kind of knowledge in the world, which trigger the
spring up of event-centric knowledge representation form like Event KG (EKG).
It plays an increasingly important role in many machine learning and artificial
intelligence applications, such as intelligent search, question-answering,
recommendation, and text generation. This paper provides a comprehensive survey
of EKG from history, ontology, instance, and application views. Specifically,
to characterize EKG thoroughly, we focus on its history, definitions, schema
induction, acquisition, related representative graphs/systems, and
applications. The development processes and trends are studied therein. We
further summarize perspective directions to facilitate future research on EKG.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Guan_S/0/1/0/all/0/1"&gt;Saiping Guan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1"&gt;Xueqi Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1"&gt;Long Bai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1"&gt;Fujun Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"&gt;Zixuan Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1"&gt;Yutao Zeng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1"&gt;Xiaolong Jin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1"&gt;Jiafeng Guo&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[K-Core Decomposition on Super Large Graphs with Limited Resources. (arXiv:2112.14840v1 [cs.DC])]]></title>
        <id>http://arxiv.org/abs/2112.14840</id>
        <link href="http://arxiv.org/abs/2112.14840"/>
        <updated>2022-01-03T07:15:43.511Z</updated>
        <summary type="html"><![CDATA[K-core decomposition is a commonly used metric to analyze graph structure or
study the relative importance of nodes in complex graphs. Recent years have
seen rapid growth in the scale of the graph, especially in industrial settings.
For example, our industrial partner runs popular social applications with
billions of users and is able to gather a rich set of user data. As a result,
applying K-core decomposition on large graphs has attracted more and more
attention from academics and the industry. A simple but effective method to
deal with large graphs is to train them in the distributed settings, and some
distributed K-core decomposition algorithms are also proposed. Despite their
effectiveness, we experimentally and theoretically observe that these
algorithms consume too many resources and become unstable on super-large-scale
graphs, especially when the given resources are limited. In this paper, we deal
with those super-large-scale graphs and propose a divide-and-conquer strategy
on top of the distributed K-core decomposition algorithm. We evaluate our
approach on three large graphs. The experimental results show that the
consumption of resources can be significantly reduced, and the calculation on
large-scale graphs becomes more stable than the existing methods. For example,
the distributed K-core decomposition algorithm can scale to a large graph with
136 billion edges without losing correctness with our divide-and-conquer
technique.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1"&gt;Shicheng Gao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1"&gt;Jie Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"&gt;Xiaosen Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Fu_F/0/1/0/all/0/1"&gt;Fangcheng Fu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1"&gt;Wentao Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1"&gt;Wen Ouyang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1"&gt;Yangyu Tao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1"&gt;Bin Cui&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Persformer: A Transformer Architecture for Topological Machine Learning. (arXiv:2112.15210v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15210</id>
        <link href="http://arxiv.org/abs/2112.15210"/>
        <updated>2022-01-03T07:15:43.510Z</updated>
        <summary type="html"><![CDATA[One of the main challenges of Topological Data Analysis (TDA) is to extract
features from persistent diagrams directly usable by machine learning
algorithms. Indeed, persistence diagrams are intrinsically (multi-)sets of
points in R2 and cannot be seen in a straightforward manner as vectors. In this
article, we introduce Persformer, the first Transformer neural network
architecture that accepts persistence diagrams as input. The Persformer
architecture significantly outperforms previous topological neural network
architectures on classical synthetic benchmark datasets. Moreover, it satisfies
a universal approximation theorem. This allows us to introduce the first
interpretability method for topological machine learning, which we explore in
two examples.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Reinauer_R/0/1/0/all/0/1"&gt;Raphael Reinauer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Caorsi_M/0/1/0/all/0/1"&gt;Matteo Caorsi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Berkouk_N/0/1/0/all/0/1"&gt;Nicolas Berkouk&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Audio-to-symbolic Arrangement via Cross-modal Music Representation Learning. (arXiv:2112.15110v1 [cs.SD])]]></title>
        <id>http://arxiv.org/abs/2112.15110</id>
        <link href="http://arxiv.org/abs/2112.15110"/>
        <updated>2022-01-03T07:15:43.507Z</updated>
        <summary type="html"><![CDATA[Could we automatically derive the score of a piano accompaniment based on the
audio of a pop song? This is the audio-to-symbolic arrangement problem we
tackle in this paper. A good arrangement model should not only consider the
audio content but also have prior knowledge of piano composition (so that the
generation "sounds like" the audio and meanwhile maintains musicality.) To this
end, we contribute a cross-modal representation-learning model, which 1)
extracts chord and melodic information from the audio, and 2) learns texture
representation from both audio and a corrupted ground truth arrangement. We
further introduce a tailored training strategy that gradually shifts the source
of texture information from corrupted score to audio. In the end, the
score-based texture posterior is reduced to a standard normal distribution, and
only audio is needed for inference. Experiments show that our model captures
major audio information and outperforms baselines in generation quality.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Ziyu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1"&gt;Dejing Xu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1"&gt;Gus Xia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1"&gt;Ying Shan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mythological Medical Machine Learning: Boosting the Performance of a Deep Learning Medical Data Classifier Using Realistic Physiological Models. (arXiv:2112.15442v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15442</id>
        <link href="http://arxiv.org/abs/2112.15442"/>
        <updated>2022-01-03T07:15:43.506Z</updated>
        <summary type="html"><![CDATA[Objective: To determine if a realistic, but computationally efficient model
of the electrocardiogram can be used to pre-train a deep neural network (DNN)
with a wide range of morphologies and abnormalities specific to a given
condition - T-wave Alternans (TWA) as a result of Post-Traumatic Stress
Disorder, or PTSD - and significantly boost performance on a small database of
rare individuals.

Approach: Using a previously validated artificial ECG model, we generated
180,000 artificial ECGs with or without significant TWA, with varying heart
rate, breathing rate, TWA amplitude, and ECG morphology. A DNN, trained on over
70,000 patients to classify 25 different rhythms, was modified the output layer
to a binary class (TWA or no-TWA, or equivalently, PTSD or no-PTSD), and
transfer learning was performed on the artificial ECG. In a final transfer
learning step, the DNN was trained and cross-validated on ECG from 12 PTSD and
24 controls for all combinations of using the three databases.

Main results: The best performing approach (AUROC = 0.77, Accuracy = 0.72,
F1-score = 0.64) was found by performing both transfer learning steps, using
the pre-trained arrhythmia DNN, the artificial data and the real PTSD-related
ECG data. Removing the artificial data from training led to the largest drop in
performance. Removing the arrhythmia data from training provided a modest, but
significant, drop in performance. The final model showed no significant drop in
performance on the artificial data, indicating no overfitting.

Significance: In healthcare, it is common to only have a small collection of
high-quality data and labels, or a larger database with much lower quality (and
less relevant) labels. The paradigm presented here, involving model-based
performance boosting, provides a solution through transfer learning on a large
realistic artificial database, and a partially relevant real database.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sadiq_I/0/1/0/all/0/1"&gt;Ismail Sadiq&lt;/a&gt; (1), &lt;a href="http://arxiv.org/find/cs/1/au:+Perez_Alday_E/0/1/0/all/0/1"&gt;Erick A. Perez-Alday&lt;/a&gt; (2), &lt;a href="http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1"&gt;Amit J. Shah&lt;/a&gt; (2), &lt;a href="http://arxiv.org/find/cs/1/au:+Rad_A/0/1/0/all/0/1"&gt;Ali Bahrami Rad&lt;/a&gt; (2), &lt;a href="http://arxiv.org/find/cs/1/au:+Sameni_R/0/1/0/all/0/1"&gt;Reza Sameni&lt;/a&gt; (2), &lt;a href="http://arxiv.org/find/cs/1/au:+Clifford_G/0/1/0/all/0/1"&gt;Gari D. Clifford&lt;/a&gt; (1,2)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GANISP: a GAN-assisted Importance SPlitting Probability Estimator. (arXiv:2112.15444v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15444</id>
        <link href="http://arxiv.org/abs/2112.15444"/>
        <updated>2022-01-03T07:15:43.506Z</updated>
        <summary type="html"><![CDATA[Designing manufacturing processes with high yield and strong reliability
relies on effective methods for rare event estimation. Genealogical importance
splitting reduces the variance of rare event probability estimators by
iteratively selecting and replicating realizations that are headed towards a
rare event. The replication step is difficult when applied to deterministic
systems where the initial conditions of the offspring realizations need to be
modified. Typically, a random perturbation is applied to the offspring to
differentiate their trajectory from the parent realization. However, this
random perturbation strategy may be effective for some systems while failing
for others, preventing variance reduction in the probability estimate. This
work seeks to address this limitation using a generative model such as a
Generative Adversarial Network (GAN) to generate perturbations that are
consistent with the attractor of the dynamical system. The proposed
GAN-assisted Importance SPlitting method (GANISP) improves the variance
reduction for the system targeted. An implementation of the method is available
in a companion repository (https://github.com/NREL/GANISP).]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hassanaly_M/0/1/0/all/0/1"&gt;Malik Hassanaly&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Glaws_A/0/1/0/all/0/1"&gt;Andrew Glaws&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+King_R/0/1/0/all/0/1"&gt;Ryan N. King&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data-Free Knowledge Transfer: A Survey. (arXiv:2112.15278v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15278</id>
        <link href="http://arxiv.org/abs/2112.15278"/>
        <updated>2022-01-03T07:15:43.490Z</updated>
        <summary type="html"><![CDATA[In the last decade, many deep learning models have been well trained and made
a great success in various fields of machine intelligence, especially for
computer vision and natural language processing. To better leverage the
potential of these well-trained models in intra-domain or cross-domain transfer
learning situations, knowledge distillation (KD) and domain adaptation (DA) are
proposed and become research highlights. They both aim to transfer useful
information from a well-trained model with original training data. However, the
original data is not always available in many cases due to privacy, copyright
or confidentiality. Recently, the data-free knowledge transfer paradigm has
attracted appealing attention as it deals with distilling valuable knowledge
from well-trained models without requiring to access to the training data. In
particular, it mainly consists of the data-free knowledge distillation (DFKD)
and source data-free domain adaptation (SFDA). On the one hand, DFKD aims to
transfer the intra-domain knowledge of original data from a cumbersome teacher
network to a compact student network for model compression and efficient
inference. On the other hand, the goal of SFDA is to reuse the cross-domain
knowledge stored in a well-trained source model and adapt it to a target
domain. In this paper, we provide a comprehensive survey on data-free knowledge
transfer from the perspectives of knowledge distillation and unsupervised
domain adaptation, to help readers have a better understanding of the current
research status and ideas. Applications and challenges of the two areas are
briefly reviewed, respectively. Furthermore, we provide some insights to the
subject of future research.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yuang Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1"&gt;Wei Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"&gt;Jun Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"&gt;Jianyong Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Graph Attention Learning Approach to Antenna Tilt Optimization. (arXiv:2112.14843v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14843</id>
        <link href="http://arxiv.org/abs/2112.14843"/>
        <updated>2022-01-03T07:15:43.488Z</updated>
        <summary type="html"><![CDATA[6G will move mobile networks towards increasing levels of complexity. To deal
with this complexity, optimization of network parameters is key to ensure high
performance and timely adaptivity to dynamic network environments. The
optimization of the antenna tilt provides a practical and cost-efficient method
to improve coverage and capacity in the network. Previous methods based on
Reinforcement Learning (RL) have shown great promise for tilt optimization by
learning adaptive policies outperforming traditional tilt optimization methods.
However, most existing RL methods are based on single-cell features
representation, which fails to fully characterize the agent state, resulting in
suboptimal performance. Also, most of such methods lack scalability, due to
state-action explosion, and generalization ability. In this paper, we propose a
Graph Attention Q-learning (GAQ) algorithm for tilt optimization. GAQ relies on
a graph attention mechanism to select relevant neighbors information, improve
the agent state representation, and update the tilt control policy based on a
history of observations using a Deep Q-Network (DQN). We show that GAQ
efficiently captures important network information and outperforms standard DQN
with local information by a large margin. In addition, we demonstrate its
ability to generalize to network deployments of different sizes and densities.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1"&gt;Yifei Jin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vannella_F/0/1/0/all/0/1"&gt;Filippo Vannella&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Bouton_M/0/1/0/all/0/1"&gt;Maxime Bouton&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1"&gt;Jaeseong Jeong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hakim_E/0/1/0/all/0/1"&gt;Ezeddin Al Hakim&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A theory of independent mechanisms for extrapolation in generative models. (arXiv:2004.00184v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2004.00184</id>
        <link href="http://arxiv.org/abs/2004.00184"/>
        <updated>2022-01-03T07:15:43.454Z</updated>
        <summary type="html"><![CDATA[Generative models can be trained to emulate complex empirical data, but are
they useful to make predictions in the context of previously unobserved
environments? An intuitive idea to promote such extrapolation capabilities is
to have the architecture of such model reflect a causal graph of the true data
generating process, such that one can intervene on each node independently of
the others. However, the nodes of this graph are usually unobserved, leading to
overparameterization and lack of identifiability of the causal structure. We
develop a theoretical framework to address this challenging situation by
defining a weaker form of identifiability, based on the principle of
independence of mechanisms. We demonstrate on toy examples that classical
stochastic gradient descent can hinder the model's extrapolation capabilities,
suggesting independence of mechanisms should be enforced explicitly during
training. Experiments on deep generative models trained on real world data
support these insights and illustrate how the extrapolation capabilities of
such models can be leveraged.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Besserve_M/0/1/0/all/0/1"&gt;Michel Besserve&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1"&gt;R&amp;#xe9;my Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Janzing_D/0/1/0/all/0/1"&gt;Dominik Janzing&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1"&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Optimization of Function Networks. (arXiv:2112.15311v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15311</id>
        <link href="http://arxiv.org/abs/2112.15311"/>
        <updated>2022-01-03T07:15:43.437Z</updated>
        <summary type="html"><![CDATA[We consider Bayesian optimization of the output of a network of functions,
where each function takes as input the output of its parent nodes, and where
the network takes significant time to evaluate. Such problems arise, for
example, in reinforcement learning, engineering design, and manufacturing.
While the standard Bayesian optimization approach observes only the final
output, our approach delivers greater query efficiency by leveraging
information that the former ignores: intermediate output within the network.
This is achieved by modeling the nodes of the network using Gaussian processes
and choosing the points to evaluate using, as our acquisition function, the
expected improvement computed with respect to the implied posterior on the
objective. Although the non-Gaussian nature of this posterior prevents
computing our acquisition function in closed form, we show that it can be
efficiently maximized via sample average approximation. In addition, we prove
that our method is asymptotically consistent, meaning that it finds a globally
optimal solution as the number of evaluations grows to infinity, thus
generalizing previously known convergence results for the expected improvement.
Notably, this holds even though our method might not evaluate the domain
densely, instead leveraging problem structure to leave regions unexplored.
Finally, we show that our approach dramatically outperforms standard Bayesian
optimization methods in several synthetic and real-world problems.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Astudillo_R/0/1/0/all/0/1"&gt;Raul Astudillo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Frazier_P/0/1/0/all/0/1"&gt;Peter I. Frazier&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Settling the Bias and Variance of Meta-Gradient Estimation for Meta-Reinforcement Learning. (arXiv:2112.15400v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15400</id>
        <link href="http://arxiv.org/abs/2112.15400"/>
        <updated>2022-01-03T07:15:43.419Z</updated>
        <summary type="html"><![CDATA[In recent years, gradient based Meta-RL (GMRL) methods have achieved
remarkable successes in either discovering effective online hyperparameter for
one single task (Xu et al., 2018) or learning good initialisation for
multi-task transfer learning (Finn et al., 2017). Despite the empirical
successes, it is often neglected that computing meta gradients via vanilla
backpropagation is ill-defined. In this paper, we argue that the stochastic
meta-gradient estimation adopted by many existing MGRL methods are in fact
biased; the bias comes from two sources: 1) the compositional bias that is
inborn in the structure of compositional optimisation problems and 2) the bias
of multi-step Hessian estimation caused by direct automatic differentiation. To
better understand the meta gradient biases, we perform the first of its kind
study to quantify the amount for each of them. We start by providing a unifying
derivation for existing GMRL algorithms, and then theoretically analyse both
the bias and the variance of existing gradient estimation methods. On
understanding the underlying principles of bias, we propose two mitigation
solutions based on off-policy correction and multi-step Hessian estimation
techniques. Comprehensive ablation studies have been conducted and results
reveals: (1) The existence of these two biases and how they influence the
meta-gradient estimation when combined with different estimator/sample
size/step and learning rate. (2) The effectiveness of these mitigation
approaches for meta-gradient estimation and thereby the final return on two
practical Meta-RL algorithms: LOLA-DiCE and Meta-gradient Reinforcement
Learning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1"&gt;Bo Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1"&gt;Xidong Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1"&gt;Haifeng Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"&gt;Jun Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"&gt;Yaodong Yang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Role of Neural Collapse in Transfer Learning. (arXiv:2112.15121v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15121</id>
        <link href="http://arxiv.org/abs/2112.15121"/>
        <updated>2022-01-03T07:15:43.404Z</updated>
        <summary type="html"><![CDATA[We study the ability of foundation models to learn representations for
classification that are transferable to new, unseen classes. Recent results in
the literature show that representations learned by a single classifier over
many classes are competitive on few-shot learning problems with representations
learned by special-purpose algorithms designed for such problems. In this paper
we provide an explanation for this behavior based on the recently observed
phenomenon that the features learned by overparameterized classification
networks show an interesting clustering property, called neural collapse. We
demonstrate both theoretically and empirically that neural collapse generalizes
to new samples from the training classes, and -- more importantly -- to new
classes as well, allowing foundation models to provide feature maps that work
well in transfer learning and, specifically, in the few-shot setting.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Galanti_T/0/1/0/all/0/1"&gt;Tomer Galanti&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1"&gt;Andr&amp;#xe1;s Gy&amp;#xf6;rgy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hutter_M/0/1/0/all/0/1"&gt;Marcus Hutter&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Models for Knowledge Tracing: Review and Empirical Evaluation. (arXiv:2112.15072v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15072</id>
        <link href="http://arxiv.org/abs/2112.15072"/>
        <updated>2022-01-03T07:15:43.392Z</updated>
        <summary type="html"><![CDATA[In this work, we review and evaluate a body of deep learning knowledge
tracing (DLKT) models with openly available and widely-used data sets, and with
a novel data set of students learning to program. The evaluated DLKT models
have been reimplemented for assessing reproducibility and replicability of
previously reported results. We test different input and output layer
variations found in the compared models that are independent of the main
architectures of the models, and different maximum attempt count options that
have been implicitly and explicitly used in some studies. Several metrics are
used to reflect on the quality of the evaluated knowledge tracing models. The
evaluated knowledge tracing models include Vanilla-DKT, two Long Short-Term
Memory Deep Knowledge Tracing (LSTM-DKT) variants, two Dynamic Key-Value Memory
Network (DKVMN) variants, and Self-Attentive Knowledge Tracing (SAKT). We
evaluate logistic regression, Bayesian Knowledge Tracing (BKT) and simple
non-learning models as baselines. Our results suggest that the DLKT models in
general outperform non-DLKT models, and the relative differences between the
DLKT models are subtle and often vary between datasets. Our results also show
that naive models such as mean prediction can yield better performance than
more sophisticated knowledge tracing models, especially in terms of accuracy.
Further, our metric and hyperparameter analysis shows that the metric used to
select the best model hyperparameters has a noticeable effect on the
performance of the models, and that metric choice can affect model ranking. We
also study the impact of input and output layer variations, filtering out long
attempt sequences, and non-model properties such as randomness and hardware.
Finally, we discuss model performance replicability and related issues. Our
model implementations, evaluation code, and data are published as a part of
this work.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sarsa_S/0/1/0/all/0/1"&gt;Sami Sarsa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Leinonen_J/0/1/0/all/0/1"&gt;Juho Leinonen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hellas_A/0/1/0/all/0/1"&gt;Arto Hellas&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reversible Upper Confidence Bound Algorithm to Generate Diverse Optimized Candidates. (arXiv:2112.14893v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14893</id>
        <link href="http://arxiv.org/abs/2112.14893"/>
        <updated>2022-01-03T07:15:43.383Z</updated>
        <summary type="html"><![CDATA[Most algorithms for the multi-armed bandit problem in reinforcement learning
aimed to maximize the expected reward, which are thus useful in searching the
optimized candidate with the highest reward (function value) for diverse
applications (e.g., AlphaGo). However, in some typical application scenaios
such as drug discovery, the aim is to search a diverse set of candidates with
high reward. Here we propose a reversible upper confidence bound (rUCB)
algorithm for such a purpose, and demonstrate its application in virtual
screening upon intrinsically disordered proteins (IDPs). It is shown that rUCB
greatly reduces the query times while achieving both high accuracy and low
performance loss.The rUCB may have potential application in multipoint
optimization and other reinforcement-learning cases.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chong_B/0/1/0/all/0/1"&gt;Bin Chong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"&gt;Yingguang Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"&gt;Zi-Le Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xing_H/0/1/0/all/0/1"&gt;Hang Xing&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"&gt;Zhirong Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learned Coarse Models for Efficient Turbulence Simulation. (arXiv:2112.15275v1 [physics.flu-dyn])]]></title>
        <id>http://arxiv.org/abs/2112.15275</id>
        <link href="http://arxiv.org/abs/2112.15275"/>
        <updated>2022-01-03T07:15:43.351Z</updated>
        <summary type="html"><![CDATA[Turbulence simulation with classical numerical solvers requires very
high-resolution grids to accurately resolve dynamics. Here we train learned
simulators at low spatial and temporal resolutions to capture turbulent
dynamics generated at high resolution. We show that our proposed model can
simulate turbulent dynamics more accurately than classical numerical solvers at
the same low resolutions across various scientifically relevant metrics. Our
model is trained end-to-end from data and is capable of learning a range of
challenging chaotic and turbulent dynamics at low resolution, including
trajectories generated by the state-of-the-art Athena++ engine. We show that
our simpler, general-purpose architecture outperforms various more specialized,
turbulence-specific architectures from the learned turbulence simulation
literature. In general, we see that learned simulators yield unstable
trajectories; however, we show that tuning training noise and temporal
downsampling solves this problem. We also find that while generalization beyond
the training distribution is a challenge for learned models, training noise,
convolutional architectures, and added loss constraints can help. Broadly, we
conclude that our learned simulator outperforms traditional solvers run on
coarser grids, and emphasize that simple design choices can offer stability and
robust generalization.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/physics/1/au:+Stachenfeld_K/0/1/0/all/0/1"&gt;Kimberly Stachenfeld&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Fielding_D/0/1/0/all/0/1"&gt;Drummond B. Fielding&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Kochkov_D/0/1/0/all/0/1"&gt;Dmitrii Kochkov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Cranmer_M/0/1/0/all/0/1"&gt;Miles Cranmer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Pfaff_T/0/1/0/all/0/1"&gt;Tobias Pfaff&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Godwin_J/0/1/0/all/0/1"&gt;Jonathan Godwin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Cui_C/0/1/0/all/0/1"&gt;Can Cui&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Ho_S/0/1/0/all/0/1"&gt;Shirley Ho&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Battaglia_P/0/1/0/all/0/1"&gt;Peter Battaglia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/physics/1/au:+Sanchez_Gonzalez_A/0/1/0/all/0/1"&gt;Alvaro Sanchez-Gonzalez&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Graph Clustering via Dual Correlation Reduction. (arXiv:2112.14772v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14772</id>
        <link href="http://arxiv.org/abs/2112.14772"/>
        <updated>2022-01-03T07:15:43.327Z</updated>
        <summary type="html"><![CDATA[Deep graph clustering, which aims to reveal the underlying graph structure
and divide the nodes into different groups, has attracted intensive attention
in recent years. However, we observe that, in the process of node encoding,
existing methods suffer from representation collapse which tends to map all
data into the same representation. Consequently, the discriminative capability
of the node representation is limited, leading to unsatisfied clustering
performance. To address this issue, we propose a novel self-supervised deep
graph clustering method termed Dual Correlation Reduction Network (DCRN) by
reducing information correlation in a dual manner. Specifically, in our method,
we first design a siamese network to encode samples. Then by forcing the
cross-view sample correlation matrix and cross-view feature correlation matrix
to approximate two identity matrices, respectively, we reduce the information
correlation in the dual-level, thus improving the discriminative capability of
the resulting features. Moreover, in order to alleviate representation collapse
caused by over-smoothing in GCN, we introduce a propagation regularization term
to enable the network to gain long-distance information with the shallow
network structure. Extensive experimental results on six benchmark datasets
demonstrate the effectiveness of the proposed DCRN against the existing
state-of-the-art methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"&gt;Yue Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tu_W/0/1/0/all/0/1"&gt;Wenxuan Tu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1"&gt;Sihang Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1"&gt;Xinwang Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1"&gt;Linxuan Song&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1"&gt;Xihong Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_E/0/1/0/all/0/1"&gt;En Zhu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Active Learning-Based Optimization of Scientific Experimental Design. (arXiv:2112.14811v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14811</id>
        <link href="http://arxiv.org/abs/2112.14811"/>
        <updated>2022-01-03T07:15:43.321Z</updated>
        <summary type="html"><![CDATA[Active learning (AL) is a machine learning algorithm that can achieve greater
accuracy with fewer labeled training instances, for having the ability to ask
oracles to label the most valuable unlabeled data chosen iteratively and
heuristically by query strategies. Scientific experiments nowadays, though
becoming increasingly automated, are still suffering from human involvement in
the designing process and the exhaustive search in the experimental space. This
article performs a retrospective study on a drug response dataset using the
proposed AL scheme comprised of the matrix factorization method of alternating
least square (ALS) and deep neural networks (DNN). This article also proposes
an AL query strategy based on expected loss minimization. As a result, the
retrospective study demonstrates that scientific experimental design, instead
of being manually set, can be optimized by AL, and the proposed query strategy
ELM sampling shows better experimental performance than other ones such as
random sampling and uncertainty sampling.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1"&gt;Ruoyu Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Digital Rock Typing DRT Algorithm Formulation with Optimal Supervised Semantic Segmentation. (arXiv:2112.15068v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15068</id>
        <link href="http://arxiv.org/abs/2112.15068"/>
        <updated>2022-01-03T07:15:43.318Z</updated>
        <summary type="html"><![CDATA[Each grid block in a 3D geological model requires a rock type that represents
all physical and chemical properties of that block. The properties that
classify rock types are lithology, permeability, and capillary pressure.
Scientists and engineers determined these properties using conventional
laboratory measurements, which embedded destructive methods to the sample or
altered some of its properties (i.e., wettability, permeability, and porosity)
because the measurements process includes sample crushing, fluid flow, or fluid
saturation. Lately, Digital Rock Physics (DRT) has emerged to quantify these
properties from micro-Computerized Tomography (uCT) and Magnetic Resonance
Imaging (MRI) images. However, the literature did not attempt rock typing in a
wholly digital context. We propose performing Digital Rock Typing (DRT) by: (1)
integrating the latest DRP advances in a novel process that honors digital rock
properties determination, while; (2) digitalizing the latest rock typing
approaches in carbonate, and (3) introducing a novel carbonate rock typing
process that utilizes computer vision capabilities to provide more insight
about the heterogeneous carbonate rock texture.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Alfarisi_O/0/1/0/all/0/1"&gt;Omar Alfarisi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ouzzane_D/0/1/0/all/0/1"&gt;Djamel Ouzzane&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sassi_M/0/1/0/all/0/1"&gt;Mohamed Sassi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1"&gt;Tiejun Zhang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Retrieving Black-box Optimal Images from External Databases. (arXiv:2112.14921v1 [cs.IR])]]></title>
        <id>http://arxiv.org/abs/2112.14921</id>
        <link href="http://arxiv.org/abs/2112.14921"/>
        <updated>2022-01-03T07:15:43.291Z</updated>
        <summary type="html"><![CDATA[Suppose we have a black-box function (e.g., deep neural network) that takes
an image as input and outputs a value that indicates preference. How can we
retrieve optimal images with respect to this function from an external database
on the Internet? Standard retrieval problems in the literature (e.g., item
recommendations) assume that an algorithm has full access to the set of items.
In other words, such algorithms are designed for service providers. In this
paper, we consider the retrieval problem under different assumptions.
Specifically, we consider how users with limited access to an image database
can retrieve images using their own black-box functions. This formulation
enables a flexible and finer-grained image search defined by each user. We
assume the user can access the database through a search query with tight API
limits. Therefore, a user needs to efficiently retrieve optimal images in terms
of the number of queries. We propose an efficient retrieval algorithm Tiara for
this problem. In the experiments, we confirm that our proposed method performs
better than several baselines under various settings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sato_R/0/1/0/all/0/1"&gt;Ryoma Sato&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Local Quadratic Convergence of Stochastic Gradient Descent with Adaptive Step Size. (arXiv:2112.14872v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2112.14872</id>
        <link href="http://arxiv.org/abs/2112.14872"/>
        <updated>2022-01-03T07:15:43.281Z</updated>
        <summary type="html"><![CDATA[Establishing a fast rate of convergence for optimization methods is crucial
to their applicability in practice. With the increasing popularity of deep
learning over the past decade, stochastic gradient descent and its adaptive
variants (e.g. Adagrad, Adam, etc.) have become prominent methods of choice for
machine learning practitioners. While a large number of works have demonstrated
that these first order optimization methods can achieve sub-linear or linear
convergence, we establish local quadratic convergence for stochastic gradient
descent with adaptive step size for problems such as matrix inversion.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Radhakrishnan_A/0/1/0/all/0/1"&gt;Adityanarayanan Radhakrishnan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Belkin_M/0/1/0/all/0/1"&gt;Mikhail Belkin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Uhler_C/0/1/0/all/0/1"&gt;Caroline Uhler&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RheFrameDetect: A Text Classification System for Automatic Detection of Rhetorical Frames in AI from Open Sources. (arXiv:2112.14933v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2112.14933</id>
        <link href="http://arxiv.org/abs/2112.14933"/>
        <updated>2022-01-03T07:15:43.281Z</updated>
        <summary type="html"><![CDATA[Rhetorical Frames in AI can be thought of as expressions that describe AI
development as a competition between two or more actors, such as governments or
companies. Examples of such Frames include robotic arms race, AI rivalry,
technological supremacy, cyberwarfare dominance and 5G race. Detection of
Rhetorical Frames from open sources can help us track the attitudes of
governments or companies towards AI, specifically whether attitudes are
becoming more cooperative or competitive over time. Given the rapidly
increasing volumes of open sources (online news media, twitter, blogs), it is
difficult for subject matter experts to identify Rhetorical Frames in (near)
real-time. Moreover, these sources are in general unstructured (noisy) and
therefore, detecting Frames from these sources will require state-of-the-art
text classification techniques. In this paper, we develop RheFrameDetect, a
text classification system for (near) real-time capture of Rhetorical Frames
from open sources. Given an input document, RheFrameDetect employs text
classification techniques at multiple levels (document level and paragraph
level) to identify all occurrences of Frames used in the discussion of AI. We
performed extensive evaluation of the text classification techniques used in
RheFrameDetect against human annotated Frames from multiple news sources. To
further demonstrate the effectiveness of RheFrameDetect, we show multiple case
studies depicting the Frames identified by RheFrameDetect compared against
human annotated Frames.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1"&gt;Saurav Ghosh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Loustaunau_P/0/1/0/all/0/1"&gt;Philippe Loustaunau&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Training Recurrent Neural Networks by Sequential Least Squares and the Alternating Direction Method of Multipliers. (arXiv:2112.15348v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15348</id>
        <link href="http://arxiv.org/abs/2112.15348"/>
        <updated>2022-01-03T07:15:43.281Z</updated>
        <summary type="html"><![CDATA[For training recurrent neural network models of nonlinear dynamical systems
from an input/output training dataset based on rather arbitrary convex and
twice-differentiable loss functions and regularization terms, we propose the
use of sequential least squares for determining the optimal network parameters
and hidden states. In addition, to handle non-smooth regularization terms such
as L1, L0, and group-Lasso regularizers, as well as to impose possibly
non-convex constraints such as integer and mixed-integer constraints, we
combine sequential least squares with the alternating direction method of
multipliers (ADMM). The performance of the resulting algorithm, that we call
NAILS (Nonconvex ADMM Iterations and Least Squares), is tested in a nonlinear
system identification benchmark.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bemporad_A/0/1/0/all/0/1"&gt;Alberto Bemporad&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Development of a face mask detection pipeline for mask-wearing monitoring in the era of the COVID-19 pandemic: A modular approach. (arXiv:2112.15031v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2112.15031</id>
        <link href="http://arxiv.org/abs/2112.15031"/>
        <updated>2022-01-03T07:15:43.277Z</updated>
        <summary type="html"><![CDATA[During the SARS-Cov-2 pandemic, mask-wearing became an effective tool to
prevent spreading and contracting the virus. The ability to monitor the
mask-wearing rate in the population would be useful for determining public
health strategies against the virus. However, artificial intelligence
technologies for detecting face masks have not been deployed at a large scale
in real-life to measure the mask-wearing rate in public. In this paper, we
present a two-step face mask detection approach consisting of two separate
modules: 1) face detection and alignment and 2) face mask classification. This
approach allowed us to experiment with different combinations of face detection
and face mask classification modules. More specifically, we experimented with
PyramidKey and RetinaFace as face detectors while maintaining a lightweight
backbone for the face mask classification module. Moreover, we also provide a
relabeled annotation of the test set of the AIZOO dataset, where we rectified
the incorrect labels for some face images. The evaluation results on the AIZOO
and Moxa 3K datasets showed that the proposed face mask detection pipeline
surpassed the state-of-the-art methods. The proposed pipeline also yielded a
higher mAP on the relabeled test set of the AIZOO dataset than the original
test set. Since we trained the proposed model using in-the-wild face images, we
can successfully deploy our model to monitor the mask-wearing rate using public
CCTV images.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Sommana_B/0/1/0/all/0/1"&gt;Benjaphan Sommana&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Watchareeruetai_U/0/1/0/all/0/1"&gt;Ukrit Watchareeruetai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ganguly_A/0/1/0/all/0/1"&gt;Ankush Ganguly&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Earp_S/0/1/0/all/0/1"&gt;Samuel W.F. Earp&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kitiyakara_T/0/1/0/all/0/1"&gt;Taya Kitiyakara&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Boonmanunt_S/0/1/0/all/0/1"&gt;Suparee Boonmanunt&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Thammasudjarit_R/0/1/0/all/0/1"&gt;Ratchainant Thammasudjarit&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Domain Adaptation with Category Attention Network for Deep Sentiment Analysis. (arXiv:2112.15290v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2112.15290</id>
        <link href="http://arxiv.org/abs/2112.15290"/>
        <updated>2022-01-03T07:15:43.269Z</updated>
        <summary type="html"><![CDATA[Domain adaptation tasks such as cross-domain sentiment classification aim to
utilize existing labeled data in the source domain and unlabeled or few labeled
data in the target domain to improve the performance in the target domain via
reducing the shift between the data distributions. Existing cross-domain
sentiment classification methods need to distinguish pivots, i.e., the
domain-shared sentiment words, and non-pivots, i.e., the domain-specific
sentiment words, for excellent adaptation performance. In this paper, we first
design a Category Attention Network (CAN), and then propose a model named
CAN-CNN to integrate CAN and a Convolutional Neural Network (CNN). On the one
hand, the model regards pivots and non-pivots as unified category attribute
words and can automatically capture them to improve the domain adaptation
performance; on the other hand, the model makes an attempt at interpretability
to learn the transferred category attribute words. Specifically, the
optimization objective of our model has three different components: 1) the
supervised classification loss; 2) the distributions loss of category feature
weights; 3) the domain invariance loss. Finally, the proposed model is
evaluated on three public sentiment analysis datasets and the results
demonstrate that CAN-CNN can outperform other various baseline methods.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Xi_D/0/1/0/all/0/1"&gt;Dongbo Xi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1"&gt;Fuzhen Zhuang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1"&gt;Ganbin Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1"&gt;Xiaohu Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1"&gt;Fen Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1"&gt;Qing He&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Neural Networks for Communication Networks: Context, Use Cases and Opportunities. (arXiv:2112.14792v1 [cs.NI])]]></title>
        <id>http://arxiv.org/abs/2112.14792</id>
        <link href="http://arxiv.org/abs/2112.14792"/>
        <updated>2022-01-03T07:15:43.257Z</updated>
        <summary type="html"><![CDATA[Graph neural networks (GNN) have shown outstanding applications in many
fields where data is fundamentally represented as graphs (e.g., chemistry,
biology, recommendation systems). In this vein, communication networks comprise
many fundamental components that are naturally represented in a
graph-structured manner (e.g., topology, configurations, traffic flows). This
position article presents GNNs as a fundamental tool for modeling, control and
management of communication networks. GNNs represent a new generation of
data-driven models that can accurately learn and reproduce the complex
behaviors behind real networks. As a result, such models can be applied to a
wide variety of networking use cases, such as planning, online optimization, or
troubleshooting. The main advantage of GNNs over traditional neural networks
lies in its unprecedented generalization capabilities when applied to other
networks and configurations unseen during training, which is a critical feature
for achieving practical data-driven solutions for networking. This article
comprises a brief tutorial on GNNs and their possible applications to
communication networks. To showcase the potential of this technology, we
present two use cases with state-of-the-art GNN models respectively applied to
wired and wireless networks. Lastly, we delve into the key open challenges and
opportunities yet to be explored in this novel research area.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Suarez_Varela_J/0/1/0/all/0/1"&gt;Jos&amp;#xe9; Su&amp;#xe1;rez-Varela&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Almasan_P/0/1/0/all/0/1"&gt;Paul Almasan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ferriol_Galmes_M/0/1/0/all/0/1"&gt;Miquel Ferriol-Galm&amp;#xe9;s&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rusek_K/0/1/0/all/0/1"&gt;Krzysztof Rusek&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Geyer_F/0/1/0/all/0/1"&gt;Fabien Geyer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1"&gt;Xiangle Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1"&gt;Xiang Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1"&gt;Shihan Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Scarselli_F/0/1/0/all/0/1"&gt;Franco Scarselli&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cabellos_Aparicio_A/0/1/0/all/0/1"&gt;Albert Cabellos-Aparicio&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Barlet_Ros_P/0/1/0/all/0/1"&gt;Pere Barlet-Ros&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transfer learning for cancer diagnosis in histopathological images. (arXiv:2112.15523v1 [eess.IV])]]></title>
        <id>http://arxiv.org/abs/2112.15523</id>
        <link href="http://arxiv.org/abs/2112.15523"/>
        <updated>2022-01-03T07:15:43.219Z</updated>
        <summary type="html"><![CDATA[Transfer learning allows us to exploit knowledge gained from one task to
assist in solving another but relevant task. In modern computer vision
research, the question is which architecture performs better for a given
dataset. In this paper, we compare the performance of 14 pre-trained ImageNet
models on the histopathologic cancer detection dataset, where each model has
been configured as a naive model, feature extractor model, or fine-tuned model.
Densenet161 has been shown to have high precision whilst Resnet101 has a high
recall. A high precision model is suitable to be used when follow-up
examination cost is high, whilst low precision but a high recall/sensitivity
model can be used when the cost of follow-up examination is low. Results also
show that transfer learning helps to converge a model faster.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Aneja_S/0/1/0/all/0/1"&gt;Sandhya Aneja&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Aneja_N/0/1/0/all/0/1"&gt;Nagender Aneja&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Abas_P/0/1/0/all/0/1"&gt;Pg Emeroylariffion Abas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Naim_A/0/1/0/all/0/1"&gt;Abdul Ghani Naim&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explainable Signature-based Machine Learning Approach for Identification of Faults in Grid-Connected Photovoltaic Systems. (arXiv:2112.14842v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14842</id>
        <link href="http://arxiv.org/abs/2112.14842"/>
        <updated>2022-01-03T07:15:43.204Z</updated>
        <summary type="html"><![CDATA[The transformation of conventional power networks into smart grids with the
heavy penetration level of renewable energy resources, particularly
grid-connected Photovoltaic (PV) systems, has increased the need for efficient
fault identification systems. Malfunctioning any single component in
grid-connected PV systems may lead to grid instability and other serious
consequences, showing that a reliable fault identification system is the utmost
requirement for ensuring operational integrity. Therefore, this paper presents
a novel fault identification approach based on statistical signatures of PV
operational states. These signatures are unique because each fault has a
different nature and distinctive impact on the electrical system. Thus, the
Random Forest Classifier trained on these extracted signatures showed 100%
accuracy in identifying all types of faults. Furthermore, the performance
comparison of the proposed framework with other Machine Learning classifiers
depicts its credibility. Moreover, to elevate user trust in the predicted
outcomes, SHAP (Shapley Additive Explanation) was utilized during the training
phase to extract a complete model response (global explanation). This extracted
global explanation can help in the assessment of predicted outcomes credibility
by decoding each prediction in terms of features contribution. Hence, the
proposed explainable signature-based fault identification technique is highly
credible and fulfills all the requirements of smart grids.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Wali_S/0/1/0/all/0/1"&gt;Syed Wali&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Khan_I/0/1/0/all/0/1"&gt;Irfan Khan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Entropy-regularized Markov Decision Processes. (arXiv:2112.15364v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15364</id>
        <link href="http://arxiv.org/abs/2112.15364"/>
        <updated>2022-01-03T07:15:43.194Z</updated>
        <summary type="html"><![CDATA[Stochastic and soft optimal policies resulting from entropy-regularized
Markov decision processes (ER-MDP) are desirable for exploration and imitation
learning applications. Motivated by the fact that such policies are sensitive
with respect to the state transition probabilities, and the estimation of these
probabilities may be inaccurate, we study a robust version of the ER-MDP model,
where the stochastic optimal policies are required to be robust with respect to
the ambiguity in the underlying transition probabilities. Our work is at the
crossroads of two important schemes in reinforcement learning (RL), namely,
robust MDP and entropy regularized MDP. We show that essential properties that
hold for the non-robust ER-MDP and robust unregularized MDP models also hold in
our settings, making the robust ER-MDP problem tractable. We show how our
framework and results can be integrated into different algorithmic schemes
including value or (modified) policy iteration, which would lead to new robust
RL and inverse RL algorithms to handle uncertainties. Analyses on computational
complexity and error propagation under conventional uncertainty settings are
also provided.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1"&gt;Tien Mai&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jaillet_P/0/1/0/all/0/1"&gt;Patrick Jaillet&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Control Theoretic Analysis of Temporal Difference Learning. (arXiv:2112.14417v2 [cs.AI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.14417</id>
        <link href="http://arxiv.org/abs/2112.14417"/>
        <updated>2022-01-03T07:15:43.111Z</updated>
        <summary type="html"><![CDATA[The goal of this paper is to investigate a control theoretic analysis of
linear stochastic iterative algorithm and temporal difference (TD) learning.
TD-learning is a linear stochastic iterative algorithm to estimate the value
function of a given policy for a Markov decision process, which is one of the
most popular and fundamental reinforcement learning algorithms. While there has
been a series of successful works in theoretical analysis of TD-learning, it
was not until recently that researchers found some guarantees on its
statistical efficiency. In this paper, we propose a control theoretic
finite-time analysis TD-learning, which exploits standard notions in linear
system control communities. Therefore, the proposed work provides additional
insights on TD-learning and reinforcement learning with simple concepts and
analysis tools in control theory.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1"&gt;Donghwan Lee&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates. (arXiv:2112.15025v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15025</id>
        <link href="http://arxiv.org/abs/2112.15025"/>
        <updated>2022-01-03T07:15:43.050Z</updated>
        <summary type="html"><![CDATA[We study the problem of learning a good set of policies, so that when
combined together, they can solve a wide variety of unseen reinforcement
learning tasks with no or very little new data. Specifically, we consider the
framework of generalized policy evaluation and improvement, in which the
rewards for all tasks of interest are assumed to be expressible as a linear
combination of a fixed set of features. We show theoretically that, under
certain assumptions, having access to a specific set of diverse policies, which
we call a set of independent policies, can allow for instantaneously achieving
high-level performance on all possible downstream tasks which are typically
more complex than the ones on which the agent was trained. Based on this
theoretical analysis, we propose a simple algorithm that iteratively constructs
this set of policies. In addition to empirically validating our theoretical
results, we compare our approach with recently proposed diverse policy set
construction methods and show that, while others fail, our approach is able to
build a behavior basis that enables instantaneous transfer to all possible
downstream tasks. We also show empirically that having access to a set of
independent policies can better bootstrap the learning process on downstream
tasks where the new reward function cannot be described as a linear combination
of the features. Finally, we demonstrate that this policy set can be useful in
a realistic lifelong reinforcement learning setting.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Alver_S/0/1/0/all/0/1"&gt;Safa Alver&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1"&gt;Doina Precup&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Model Averaging of Support Vector Machines in Diverging Model Spaces. (arXiv:2112.12961v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.12961</id>
        <link href="http://arxiv.org/abs/2112.12961"/>
        <updated>2022-01-03T07:15:42.864Z</updated>
        <summary type="html"><![CDATA[Support vector machine (SVM) is a powerful classification method that has
achieved great success in many fields. Since its performance can be seriously
impaired by redundant covariates, model selection techniques are widely used
for SVM with high dimensional covariates. As an alternative to model selection,
significant progress has been made in the area of model averaging in the past
decades. Yet no frequentist model averaging method was considered for SVM. This
work aims to fill the gap and to propose a frequentist model averaging
procedure for SVM which selects the optimal weight by cross validation. Even
when the number of covariates diverges at an exponential rate of the sample
size, we show asymptotic optimality of the proposed method in the sense that
the ratio of its hinge loss to the lowest possible loss converges to one. We
also derive the convergence rate which provides more insights to model
averaging. Compared to model selection methods of SVM which require a tedious
but critical task of tuning parameter selection, the model averaging method
avoids the task and shows promising performances in the empirical studies.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Yuan_C/0/1/0/all/0/1"&gt;Chaoxia Yuan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Ying_C/0/1/0/all/0/1"&gt;Chao Ying&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Yu_Z/0/1/0/all/0/1"&gt;Zhou Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Fang_F/0/1/0/all/0/1"&gt;Fang Fang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Decentralized Optimization Over the Stiefel Manifold by an Approximate Augmented Lagrangian Function. (arXiv:2112.14949v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2112.14949</id>
        <link href="http://arxiv.org/abs/2112.14949"/>
        <updated>2022-01-03T07:15:42.535Z</updated>
        <summary type="html"><![CDATA[In this paper, we focus on the decentralized optimization problem over the
Stiefel manifold, which is defined on a connected network of $d$ agents. The
objective is an average of $d$ local functions, and each function is privately
held by an agent and encodes its data. The agents can only communicate with
their neighbors in a collaborative effort to solve this problem. In existing
methods, multiple rounds of communications are required to guarantee the
convergence, giving rise to high communication costs. In contrast, this paper
proposes a decentralized algorithm, called DESTINY, which only invokes a single
round of communications per iteration. DESTINY combines gradient tracking
techniques with a novel approximate augmented Lagrangian function. The global
convergence to stationary points is rigorously established. Comprehensive
numerical experiments demonstrate that DESTINY has a strong potential to
deliver a cutting-edge performance in solving a variety of testing problems.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Wang_L/0/1/0/all/0/1"&gt;Lei Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Liu_X/0/1/0/all/0/1"&gt;Xin Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Application of Hierarchical Temporal Memory Theory for Document Categorization. (arXiv:2112.14820v1 [cs.CL])]]></title>
        <id>http://arxiv.org/abs/2112.14820</id>
        <link href="http://arxiv.org/abs/2112.14820"/>
        <updated>2022-01-03T07:15:42.401Z</updated>
        <summary type="html"><![CDATA[The current work intends to study the performance of the Hierarchical
Temporal Memory(HTM) theory for automated classification of text as well as
documents. HTM is a biologically inspired theory based on the working
principles of the human neocortex. The current study intends to provide an
alternative framework for document categorization using the Spatial Pooler
learning algorithm in the HTM Theory. As HTM accepts only a stream of binary
data as input, Latent Semantic Indexing(LSI) technique is used for extracting
the top features from the input and converting them into binary format. The
Spatial Pooler algorithm converts the binary input into sparse patterns with
similar input text having overlapping spatial patterns making it easy for
classifying the patterns into categories. The results obtained prove that HTM
theory, although is in its nascent stages, performs at par with most of the
popular machine learning based classifiers.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1"&gt;Deven Shah&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ghate_P/0/1/0/all/0/1"&gt;Pinak Ghate&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Paranjape_M/0/1/0/all/0/1"&gt;Manali Paranjape&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1"&gt;Amit Kumar&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The SAMME.C2 algorithm for severely imbalanced multi-class classification. (arXiv:2112.14868v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2112.14868</id>
        <link href="http://arxiv.org/abs/2112.14868"/>
        <updated>2022-01-03T07:15:42.394Z</updated>
        <summary type="html"><![CDATA[Classification predictive modeling involves the accurate assignment of
observations in a dataset to target classes or categories. There is an
increasing growth of real-world classification problems with severely
imbalanced class distributions. In this case, minority classes have much fewer
observations to learn from than those from majority classes. Despite this
sparsity, a minority class is often considered the more interesting class yet
developing a scientific learning algorithm suitable for the observations
presents countless challenges. In this article, we suggest a novel multi-class
classification algorithm specialized to handle severely imbalanced classes
based on the method we refer to as SAMME.C2. It blends the flexible mechanics
of the boosting techniques from SAMME algorithm, a multi-class classifier, and
Ada.C2 algorithm, a cost-sensitive binary classifier designed to address highly
class imbalances. Not only do we provide the resulting algorithm but we also
establish scientific and statistical formulation of our proposed SAMME.C2
algorithm. Through numerical experiments examining various degrees of
classifier difficulty, we demonstrate consistent superior performance of our
proposed model.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+So_B/0/1/0/all/0/1"&gt;Banghee So&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Valdez_E/0/1/0/all/0/1"&gt;Emiliano A. Valdez&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uniform-PAC Bounds for Reinforcement Learning with Linear Function Approximation. (arXiv:2106.11612v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2106.11612</id>
        <link href="http://arxiv.org/abs/2106.11612"/>
        <updated>2022-01-03T07:15:42.387Z</updated>
        <summary type="html"><![CDATA[We study reinforcement learning (RL) with linear function approximation.
Existing algorithms for this problem only have high-probability regret and/or
Probably Approximately Correct (PAC) sample complexity guarantees, which cannot
guarantee the convergence to the optimal policy. In this paper, in order to
overcome the limitation of existing algorithms, we propose a new algorithm
called FLUTE, which enjoys uniform-PAC convergence to the optimal policy with
high probability. The uniform-PAC guarantee is the strongest possible guarantee
for reinforcement learning in the literature, which can directly imply both PAC
and high probability regret bounds, making our algorithm superior to all
existing algorithms with linear function approximation. At the core of our
algorithm is a novel minimax value function estimator and a multi-level
partition scheme to select the training samples from historical observations.
Both of these techniques are new and of independent interest.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1"&gt;Jiafan He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A general technique for the estimation of farm animal body part weights from CT scans and its applications in a rabbit breeding program. (arXiv:2112.15095v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2112.15095</id>
        <link href="http://arxiv.org/abs/2112.15095"/>
        <updated>2022-01-03T07:15:42.367Z</updated>
        <summary type="html"><![CDATA[Various applications of farm animal imaging are based on the estimation of
weights of certain body parts and cuts from the CT images of animals. In many
cases, the complexity of the problem is increased by the enormous variability
of postures in CT images due to the scanning of non-sedated, living animals. In
this paper, we propose a general and robust approach for the estimation of the
weights of cuts and body parts from the CT images of (possibly) living animals.
We adapt multi-atlas based segmentation driven by elastic registration and
joint feature and model selection for the regression component to cape with the
large number of features and low number of samples. The proposed technique is
evaluated and illustrated through real applications in rabbit breeding
programs, showing r^2 scores 12% higher than previous techniques and methods
that used to drive the selection so far. The proposed technique is easily
adaptable to similar problems, consequently, it is shared in an open source
software package for the benefit of the community.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Csoka_A/0/1/0/all/0/1"&gt;&amp;#xc1;d&amp;#xe1;m Cs&amp;#xf3;ka&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kovacs_G/0/1/0/all/0/1"&gt;Gy&amp;#xf6;rgy Kov&amp;#xe1;cs&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Acs_V/0/1/0/all/0/1"&gt;Vir&amp;#xe1;g &amp;#xc1;cs&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Matics_Z/0/1/0/all/0/1"&gt;Zsolt Matics&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gerencser_Z/0/1/0/all/0/1"&gt;Zsolt Gerencs&amp;#xe9;r&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Szendro_Z/0/1/0/all/0/1"&gt;Zsolt Szendr&amp;#x151;&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Nagy_I/0/1/0/all/0/1"&gt;Istv&amp;#xe1;n Nagy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Petnehazy_O/0/1/0/all/0/1"&gt;&amp;#xd6;rs Petneh&amp;#xe1;zy&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Repa_I/0/1/0/all/0/1"&gt;Imre Repa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Moizs_M/0/1/0/all/0/1"&gt;Mariann Moizs&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Donko_T/0/1/0/all/0/1"&gt;Tam&amp;#xe1;s Donk&amp;#xf3;&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dimensionality reduction for prediction: Application to Bitcoin and Ethereum. (arXiv:2112.15036v1 [q-fin.ST])]]></title>
        <id>http://arxiv.org/abs/2112.15036</id>
        <link href="http://arxiv.org/abs/2112.15036"/>
        <updated>2022-01-03T07:15:42.361Z</updated>
        <summary type="html"><![CDATA[The objective of this paper is to assess the performances of dimensionality
reduction techniques to establish a link between cryptocurrencies. We have
focused our analysis on the two most traded cryptocurrencies: Bitcoin and
Ethereum. To perform our analysis, we took log returns and added some
covariates to build our data set. We first introduced the pearson correlation
coefficient in order to have a preliminary assessment of the link between
Bitcoin and Ethereum. We then reduced the dimension of our data set using
canonical correlation analysis and principal component analysis. After
performing an analysis of the links between Bitcoin and Ethereum with both
statistical techniques, we measured their performance on forecasting Ethereum
returns with Bitcoin s features.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/q-fin/1/au:+Inzirillo_H/0/1/0/all/0/1"&gt;Hugo Inzirillo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/q-fin/1/au:+Mat_B/0/1/0/all/0/1"&gt;Benjamin Mat&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bounding Wasserstein distance with couplings. (arXiv:2112.03152v2 [stat.CO] CROSS LISTED)]]></title>
        <id>http://arxiv.org/abs/2112.03152</id>
        <link href="http://arxiv.org/abs/2112.03152"/>
        <updated>2022-01-03T07:15:42.353Z</updated>
        <summary type="html"><![CDATA[Markov chain Monte Carlo (MCMC) provides asymptotically consistent estimates
of intractable posterior expectations as the number of iterations tends to
infinity. However, in large data applications, MCMC can be computationally
expensive per iteration. This has catalyzed interest in sampling methods such
as approximate MCMC, which trade off asymptotic consistency for improved
computational speed. In this article, we propose estimators based on couplings
of Markov chains to assess the quality of such asymptotically biased sampling
methods. The estimators give empirical upper bounds of the Wassertein distance
between the limiting distribution of the asymptotically biased sampling method
and the original target distribution of interest. We establish theoretical
guarantees for our upper bounds and show that our estimators can remain
effective in high dimensions. We apply our quality measures to stochastic
gradient MCMC, variational Bayes, and Laplace approximations for tall data and
to approximate MCMC for Bayesian logistic regression in 4500 dimensions and
Bayesian linear regression in 50000 dimensions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Biswas_N/0/1/0/all/0/1"&gt;Niloy Biswas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1"&gt;Lester Mackey&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Aim in Climate Change and City Pollution. (arXiv:2112.15115v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15115</id>
        <link href="http://arxiv.org/abs/2112.15115"/>
        <updated>2022-01-03T07:15:42.347Z</updated>
        <summary type="html"><![CDATA[The sustainability of urban environments is an increasingly relevant problem.
Air pollution plays a key role in the degradation of the environment as well as
the health of the citizens exposed to it. In this chapter we provide a review
of the methods available to model air pollution, focusing on the application of
machine-learning methods. In fact, machine-learning methods have proved to
importantly increase the accuracy of traditional air-pollution approaches while
limiting the development cost of the models. Machine-learning tools have opened
new approaches to study air pollution, such as flow-dynamics modelling or
remote-sensing methodologies.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Torres_P/0/1/0/all/0/1"&gt;Pablo Torres&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sirmacek_B/0/1/0/all/0/1"&gt;Beril Sirmacek&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hoyas_S/0/1/0/all/0/1"&gt;Sergio Hoyas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vinuesa_R/0/1/0/all/0/1"&gt;Ricardo Vinuesa&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Are we really making much progress? Revisiting, benchmarking, and refining heterogeneous graph neural networks. (arXiv:2112.14936v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14936</id>
        <link href="http://arxiv.org/abs/2112.14936"/>
        <updated>2022-01-03T07:15:42.338Z</updated>
        <summary type="html"><![CDATA[Heterogeneous graph neural networks (HGNNs) have been blossoming in recent
years, but the unique data processing and evaluation setups used by each work
obstruct a full understanding of their advancements. In this work, we present a
systematical reproduction of 12 recent HGNNs by using their official codes,
datasets, settings, and hyperparameters, revealing surprising findings about
the progress of HGNNs. We find that the simple homogeneous GNNs, e.g., GCN and
GAT, are largely underestimated due to improper settings. GAT with proper
inputs can generally match or outperform all existing HGNNs across various
scenarios. To facilitate robust and reproducible HGNN research, we construct
the Heterogeneous Graph Benchmark (HGB), consisting of 11 diverse datasets with
three tasks. HGB standardizes the process of heterogeneous graph data splits,
feature processing, and performance evaluation. Finally, we introduce a simple
but very strong baseline Simple-HGN--which significantly outperforms all
previous models on HGB--to accelerate the advancement of HGNNs in the future.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lv_Q/0/1/0/all/0/1"&gt;Qingsong Lv&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1"&gt;Ming Ding&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1"&gt;Qiang Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"&gt;Yuxiang Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1"&gt;Wenzheng Feng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1"&gt;Siming He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1"&gt;Chang Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1"&gt;Jianguo Jiang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1"&gt;Yuxiao Dong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1"&gt;Jie Tang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Two Instances of Interpretable Neural Network for Universal Approximations. (arXiv:2112.15026v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15026</id>
        <link href="http://arxiv.org/abs/2112.15026"/>
        <updated>2022-01-03T07:15:42.311Z</updated>
        <summary type="html"><![CDATA[This paper proposes two bottom-up interpretable neural network (NN)
constructions for universal approximation, namely Triangularly-constructed NN
(TNN) and Semi-Quantized Activation NN (SQANN). The notable properties are (1)
resistance to catastrophic forgetting (2) existence of proof for arbitrarily
high accuracies on training dataset (3) for an input \(x\), users can identify
specific samples of training data whose activation ``fingerprints" are similar
to that of \(x\)'s activations. Users can also identify samples that are out of
distribution.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Tjoa_E/0/1/0/all/0/1"&gt;Erico Tjoa&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cuntai_G/0/1/0/all/0/1"&gt;Guan Cuntai&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparse Generalized Yule-Walker Estimation for Large Spatio-temporal Autoregressions with an Application to NO2 Satellite Data. (arXiv:2108.02864v2 [econ.EM] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2108.02864</id>
        <link href="http://arxiv.org/abs/2108.02864"/>
        <updated>2022-01-03T07:15:42.306Z</updated>
        <summary type="html"><![CDATA[We consider a high-dimensional model in which variables are observed over
time and space. The model consists of a spatio-temporal regression containing a
time lag and a spatial lag of the dependent variable. Unlike classical spatial
autoregressive models, we do not rely on a predetermined spatial interaction
matrix, but infer all spatial interactions from the data. Assuming sparsity, we
estimate the spatial and temporal dependence fully data-driven by penalizing a
set of Yule-Walker equations. This regularization can be left unstructured, but
we also propose customized shrinkage procedures when observations originate
from spatial grids (e.g. satellite images). Finite sample error bounds are
derived and estimation consistency is established in an asymptotic framework
wherein the sample size and the number of spatial units diverge jointly.
Exogenous variables can be included as well. A simulation exercise shows strong
finite sample performance compared to competing procedures. As an empirical
application, we model satellite measured NO2 concentrations in London. Our
approach delivers forecast improvements over a competitive benchmark and we
discover evidence for strong spatial interactions.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/econ/1/au:+Reuvers_H/0/1/0/all/0/1"&gt;Hanno Reuvers&lt;/a&gt;, &lt;a href="http://arxiv.org/find/econ/1/au:+Wijler_E/0/1/0/all/0/1"&gt;Etienne Wijler&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Binary Diffing as a Network Alignment Problem via Belief Propagation. (arXiv:2112.15337v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15337</id>
        <link href="http://arxiv.org/abs/2112.15337"/>
        <updated>2022-01-03T07:15:42.299Z</updated>
        <summary type="html"><![CDATA[In this paper, we address the problem of finding a correspondence, or
matching, between the functions of two programs in binary form, which is one of
the most common task in binary diffing. We introduce a new formulation of this
problem as a particular instance of a graph edit problem over the call graphs
of the programs. In this formulation, the quality of a mapping is evaluated
simultaneously with respect to both function content and call graph
similarities. We show that this formulation is equivalent to a network
alignment problem. We propose a solving strategy for this problem based on
max-product belief propagation. Finally, we implement a prototype of our
method, called QBinDiff, and propose an extensive evaluation which shows that
our approach outperforms state of the art diffing tools.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Mengin_E/0/1/0/all/0/1"&gt;Elie Mengin&lt;/a&gt; (SAMM), &lt;a href="http://arxiv.org/find/cs/1/au:+Rossi_F/0/1/0/all/0/1"&gt;Fabrice Rossi&lt;/a&gt; (CEREMADE)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards the global vision of engagement of Generation Z at the workplace: Mathematical modeling. (arXiv:2112.15401v1 [econ.GN])]]></title>
        <id>http://arxiv.org/abs/2112.15401</id>
        <link href="http://arxiv.org/abs/2112.15401"/>
        <updated>2022-01-03T07:15:42.291Z</updated>
        <summary type="html"><![CDATA[Correlation and cluster analyses (k-Means, Gaussian Mixture Models) were
performed on Generation Z engagement surveys at the workplace. The clustering
indicates relations between various factors that describe the engagement of
employees. The most noticeable factors are a clear statement about the
responsibilities at work, and challenging work. These factors are essential in
practice. The results of this paper can be used in preparing better
motivational systems aimed at Generation Z employees.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/econ/1/au:+Kycia_R/0/1/0/all/0/1"&gt;Rados&amp;#x142;aw A. Kycia&lt;/a&gt;, &lt;a href="http://arxiv.org/find/econ/1/au:+Niemczynowicz_A/0/1/0/all/0/1"&gt;Agnieszka Niemczynowicz&lt;/a&gt;, &lt;a href="http://arxiv.org/find/econ/1/au:+Niezurawska_Zajac_J/0/1/0/all/0/1"&gt;Joanna Nie&amp;#x17c;urawska-Zaj&amp;#x105;c&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A theory of independent mechanisms for extrapolation in generative models. (arXiv:2004.00184v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2004.00184</id>
        <link href="http://arxiv.org/abs/2004.00184"/>
        <updated>2022-01-03T07:15:42.285Z</updated>
        <summary type="html"><![CDATA[Generative models can be trained to emulate complex empirical data, but are
they useful to make predictions in the context of previously unobserved
environments? An intuitive idea to promote such extrapolation capabilities is
to have the architecture of such model reflect a causal graph of the true data
generating process, such that one can intervene on each node independently of
the others. However, the nodes of this graph are usually unobserved, leading to
overparameterization and lack of identifiability of the causal structure. We
develop a theoretical framework to address this challenging situation by
defining a weaker form of identifiability, based on the principle of
independence of mechanisms. We demonstrate on toy examples that classical
stochastic gradient descent can hinder the model's extrapolation capabilities,
suggesting independence of mechanisms should be enforced explicitly during
training. Experiments on deep generative models trained on real world data
support these insights and illustrate how the extrapolation capabilities of
such models can be leveraged.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Besserve_M/0/1/0/all/0/1"&gt;Michel Besserve&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1"&gt;R&amp;#xe9;my Sun&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Janzing_D/0/1/0/all/0/1"&gt;Dominik Janzing&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1"&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Score-Based Generative Modeling with Critically-Damped Langevin Diffusion. (arXiv:2112.07068v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.07068</id>
        <link href="http://arxiv.org/abs/2112.07068"/>
        <updated>2022-01-03T07:15:42.278Z</updated>
        <summary type="html"><![CDATA[Score-based generative models (SGMs) have demonstrated remarkable synthesis
quality. SGMs rely on a diffusion process that gradually perturbs the data
towards a tractable distribution, while the generative model learns to denoise.
The complexity of this denoising task is, apart from the data distribution
itself, uniquely determined by the diffusion process. We argue that current
SGMs employ overly simplistic diffusions, leading to unnecessarily complex
denoising processes, which limit generative modeling performance. Based on
connections to statistical mechanics, we propose a novel critically-damped
Langevin diffusion (CLD) and show that CLD-based SGMs achieve superior
performance. CLD can be interpreted as running a joint diffusion in an extended
space, where the auxiliary variables can be considered "velocities" that are
coupled to the data variables as in Hamiltonian dynamics. We derive a novel
score matching objective for CLD and show that the model only needs to learn
the score function of the conditional distribution of the velocity given data,
an easier task than learning scores of the data directly. We also derive a new
sampling scheme for efficient synthesis from CLD-based diffusion models. We
find that CLD outperforms previous SGMs in synthesis quality for similar
network architectures and sampling compute budgets. We show that our novel
sampler for CLD significantly outperforms solvers such as Euler--Maruyama. Our
framework provides new insights into score-based denoising diffusion models and
can be readily used for high-resolution image synthesis. Project page and code:
https://nv-tlabs.github.io/CLD-SGM.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Dockhorn_T/0/1/0/all/0/1"&gt;Tim Dockhorn&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Vahdat_A/0/1/0/all/0/1"&gt;Arash Vahdat&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Kreis_K/0/1/0/all/0/1"&gt;Karsten Kreis&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When are Iterative Gaussian Processes Reliably Accurate?. (arXiv:2112.15246v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15246</id>
        <link href="http://arxiv.org/abs/2112.15246"/>
        <updated>2022-01-03T07:15:42.253Z</updated>
        <summary type="html"><![CDATA[While recent work on conjugate gradient methods and Lanczos decompositions
have achieved scalable Gaussian process inference with highly accurate point
predictions, in several implementations these iterative methods appear to
struggle with numerical instabilities in learning kernel hyperparameters, and
poor test likelihoods. By investigating CG tolerance, preconditioner rank, and
Lanczos decomposition rank, we provide a particularly simple prescription to
correct these issues: we recommend that one should use a small CG tolerance
($\epsilon \leq 0.01$) and a large root decomposition size ($r \geq 5000$).
Moreover, we show that L-BFGS-B is a compelling optimizer for Iterative GPs,
achieving convergence with fewer gradient updates.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Maddox_W/0/1/0/all/0/1"&gt;Wesley J. Maddox&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1"&gt;Sanyam Kapoor&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1"&gt;Andrew Gordon Wilson&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Training Quantized Deep Neural Networks via Cooperative Coevolution. (arXiv:2112.14834v1 [cs.NE])]]></title>
        <id>http://arxiv.org/abs/2112.14834</id>
        <link href="http://arxiv.org/abs/2112.14834"/>
        <updated>2022-01-03T07:15:42.246Z</updated>
        <summary type="html"><![CDATA[Quantizing deep neural networks (DNNs) has been a promising solution for
deploying deep neural networks on embedded devices. However, most of the
existing methods do not quantize gradients, and the process of quantizing DNNs
still has a lot of floating-point operations, which hinders the further
applications of quantized DNNs. To solve this problem, we propose a new
heuristic method based on cooperative coevolution for quantizing DNNs. Under
the framework of cooperative coevolution, we use the estimation of distribution
algorithm to search for the low-bits weights. Specifically, we first construct
an initial quantized network from a pre-trained network instead of random
initialization and then start searching from it by restricting the search
space. So far, the problem is the largest discrete problem known to be solved
by evolutionary algorithms. Experiments show that our method can train 4 bit
ResNet-20 on the Cifar-10 dataset without sacrificing accuracy.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Peng_F/0/1/0/all/0/1"&gt;Fu Peng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1"&gt;Shengcai Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1"&gt;Ke Tang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[InverseMV: Composing Piano Scores with a Convolutional Video-Music Transformer. (arXiv:2112.15320v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15320</id>
        <link href="http://arxiv.org/abs/2112.15320"/>
        <updated>2022-01-03T07:15:42.240Z</updated>
        <summary type="html"><![CDATA[Many social media users prefer consuming content in the form of videos rather
than text. However, in order for content creators to produce videos with a high
click-through rate, much editing is needed to match the footage to the music.
This posts additional challenges for more amateur video makers. Therefore, we
propose a novel attention-based model VMT (Video-Music Transformer) that
automatically generates piano scores from video frames. Using music generated
from models also prevent potential copyright infringements that often come with
using existing music. To the best of our knowledge, there is no work besides
the proposed VMT that aims to compose music for video. Additionally, there
lacks a dataset with aligned video and symbolic music. We release a new dataset
composed of over 7 hours of piano scores with fine alignment between pop music
videos and MIDI files. We conduct experiments with human evaluation on VMT,
SeqSeq model (our baseline), and the original piano version soundtrack. VMT
achieves consistent improvements over the baseline on music smoothness and
video relevance. In particular, with the relevance scores and our case study,
our model has shown the capability of multimodality on frame-level actors'
movement for music generation. Our VMT model, along with the new dataset,
presents a promising research direction toward composing the matching
soundtrack for videos. We have released our code at
https://github.com/linchintung/VMT]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1"&gt;Chin-Tung Lin&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1"&gt;Mu Yang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SimSR: Simple Distance-based State Representation for Deep Reinforcement Learning. (arXiv:2112.15303v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15303</id>
        <link href="http://arxiv.org/abs/2112.15303"/>
        <updated>2022-01-03T07:15:42.234Z</updated>
        <summary type="html"><![CDATA[This work explores how to learn robust and generalizable state representation
from image-based observations with deep reinforcement learning methods.
Addressing the computational complexity, stringent assumptions, and
representation collapse challenges in the existing work of bisimulation metric,
we devise Simple State Representation (SimSR) operator, which achieves
equivalent functionality while reducing the complexity by an order in
comparison with bisimulation metric. SimSR enables us to design a
stochastic-approximation-based method that can practically learn the mapping
functions (encoders) from observations to latent representation space. Besides
the theoretical analysis, we experimented and compared our work with recent
state-of-the-art solutions in visual MuJoCo tasks. The results show that our
model generally achieves better performance and has better robustness and good
generalization.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zang_H/0/1/0/all/0/1"&gt;Hongyu Zang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"&gt;Xin Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1"&gt;Mingzhong Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Inception Attention for Image Synthesis and Image Recognition. (arXiv:2112.14804v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2112.14804</id>
        <link href="http://arxiv.org/abs/2112.14804"/>
        <updated>2022-01-03T07:15:42.192Z</updated>
        <summary type="html"><![CDATA[Image synthesis and image recognition have witnessed remarkable progress, but
often at the expense of computationally expensive training and inference.
Learning lightweight yet expressive deep model has emerged as an important and
interesting direction. Inspired by the well-known split-transform-aggregate
design heuristic in the Inception building block, this paper proposes a
Skip-Layer Inception Module (SLIM) that facilitates efficient learning of image
synthesis models, and a same-layer variant (dubbed as SLIM too) as a stronger
alternative to the well-known ResNeXts for image recognition. In SLIM, the
input feature map is first split into a number of groups (e.g., 4).Each group
is then transformed to a latent style vector(via channel-wise attention) and a
latent spatial mask (via spatial attention). The learned latent masks and
latent style vectors are aggregated to modulate the target feature map. For
generative learning, SLIM is built on a recently proposed lightweight
Generative Adversarial Networks (i.e., FastGANs) which present a skip-layer
excitation(SLE) module. For few-shot image synthesis tasks, the proposed SLIM
achieves better performance than the SLE work and other related methods. For
one-shot image synthesis tasks, it shows stronger capability of preserving
images structures than prior arts such as the SinGANs. For image classification
tasks, the proposed SLIM is used as a drop-in replacement for convolution
layers in ResNets (resulting in ResNeXt-like models) and achieves better
accuracy in theImageNet-1000 dataset, with significantly smaller model
complexity]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1"&gt;Jianghao Shen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1"&gt;Tianfu Wu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resource-Efficient Deep Learning: A Survey on Model-, Arithmetic-, and Implementation-Level Techniques. (arXiv:2112.15131v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15131</id>
        <link href="http://arxiv.org/abs/2112.15131"/>
        <updated>2022-01-03T07:15:42.184Z</updated>
        <summary type="html"><![CDATA[Deep learning is pervasive in our daily life, including self-driving cars,
virtual assistants, social network services, healthcare services, face
recognition, etc. However, deep neural networks demand substantial compute
resources during training and inference. The machine learning community has
mainly focused on model-level optimizations such as architectural compression
of deep learning models, while the system community has focused on
implementation-level optimization. In between, various arithmetic-level
optimization techniques have been proposed in the arithmetic community. This
article provides a survey on resource-efficient deep learning techniques in
terms of model-, arithmetic-, and implementation-level techniques and
identifies the research gaps for resource-efficient deep learning techniques
across the three different level techniques. Our survey clarifies the influence
from higher to lower-level techniques based on our resource-efficiency metric
definition and discusses the future trend for resource-efficient deep learning
research.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1"&gt;JunKyu Lee&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Mukhanov_L/0/1/0/all/0/1"&gt;Lev Mukhanov&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Molahosseini_A/0/1/0/all/0/1"&gt;Amir Sabbagh Molahosseini&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Minhas_U/0/1/0/all/0/1"&gt;Umar Minhas&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1"&gt;Yang Hua&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Rincon_J/0/1/0/all/0/1"&gt;Jesus Martinez del Rincon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Dichev_K/0/1/0/all/0/1"&gt;Kiril Dichev&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1"&gt;Cheol-Ho Hong&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vandierendonck_H/0/1/0/all/0/1"&gt;Hans Vandierendonck&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Distinctive Properties of Universal Perturbations. (arXiv:2112.15329v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15329</id>
        <link href="http://arxiv.org/abs/2112.15329"/>
        <updated>2022-01-03T07:15:42.163Z</updated>
        <summary type="html"><![CDATA[We identify properties of universal adversarial perturbations (UAPs) that
distinguish them from standard adversarial perturbations. Specifically, we show
that targeted UAPs generated by projected gradient descent exhibit two
human-aligned properties: semantic locality and spatial invariance, which
standard targeted adversarial perturbations lack. We also demonstrate that UAPs
contain significantly less signal for generalization than standard adversarial
perturbations -- that is, UAPs leverage non-robust features to a smaller extent
than standard adversarial perturbations.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1"&gt;Sung Min Park&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wei_K/0/1/0/all/0/1"&gt;Kuo-An Wei&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Xiao_K/0/1/0/all/0/1"&gt;Kai Xiao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"&gt;Jerry Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Madry_A/0/1/0/all/0/1"&gt;Aleksander Madry&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pose Estimation of Specific Rigid Objects. (arXiv:2112.15075v1 [cs.CV])]]></title>
        <id>http://arxiv.org/abs/2112.15075</id>
        <link href="http://arxiv.org/abs/2112.15075"/>
        <updated>2022-01-03T07:15:42.157Z</updated>
        <summary type="html"><![CDATA[In this thesis, we address the problem of estimating the 6D pose of rigid
objects from a single RGB or RGB-D input image, assuming that 3D models of the
objects are available. This problem is of great importance to many application
fields such as robotic manipulation, augmented reality, and autonomous driving.
First, we propose EPOS, a method for 6D object pose estimation from an RGB
image. The key idea is to represent an object by compact surface fragments and
predict the probability distribution of corresponding fragments at each pixel
of the input image by a neural network. Each pixel is linked with a
data-dependent number of fragments, which allows systematic handling of
symmetries, and the 6D poses are estimated from the links by a RANSAC-based
fitting method. EPOS outperformed all RGB and most RGB-D and D methods on
several standard datasets. Second, we present HashMatch, an RGB-D method that
slides a window over the input image and searches for a match against
templates, which are pre-generated by rendering 3D object models in different
orientations. The method applies a cascade of evaluation stages to each window
location, which avoids exhaustive matching against all templates. Third, we
propose ObjectSynth, an approach to synthesize photorealistic images of 3D
object models for training methods based on neural networks. The images yield
substantial improvements compared to commonly used images of objects rendered
on top of random photographs. Fourth, we introduce T-LESS, the first dataset
for 6D object pose estimation that includes 3D models and RGB-D images of
industry-relevant objects. Fifth, we define BOP, a benchmark that captures the
status quo in the field. BOP comprises eleven datasets in a unified format, an
evaluation methodology, an online evaluation system, and public challenges held
at international workshops organized at the ICCV and ECCV conferences.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Hodan_T/0/1/0/all/0/1"&gt;Tomas Hodan&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Survey of Deep Learning Techniques for Dynamic Branch Prediction. (arXiv:2112.14911v1 [cs.AR])]]></title>
        <id>http://arxiv.org/abs/2112.14911</id>
        <link href="http://arxiv.org/abs/2112.14911"/>
        <updated>2022-01-03T07:15:42.150Z</updated>
        <summary type="html"><![CDATA[Branch prediction is an architectural feature that speeds up the execution of
branch instruction on pipeline processors and reduces the cost of branching.
Recent advancements of Deep Learning (DL) in the post Moore's Law era is
accelerating areas of automated chip design, low-power computer architectures,
and much more. Traditional computer architecture design and algorithms could
benefit from dynamic predictors based on deep learning algorithms which learns
from experience by optimizing its parameters on large number of data. In this
survey paper, we focus on traditional branch prediction algorithms, analyzes
its limitations, and presents a literature survey of how deep learning
techniques can be applied to create dynamic branch predictors capable of
predicting conditional branch instructions. Prior surveys in this field focus
on dynamic branch prediction techniques based on neural network perceptrons. We
plan to improve the survey based on latest research in DL and advanced Machine
Learning (ML) based branch predictors.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Joseph_R/0/1/0/all/0/1"&gt;Rinu Joseph&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Algorithms Learn to Stabilize Unknown Continuous-Time Systems. (arXiv:2112.15094v1 [eess.SY])]]></title>
        <id>http://arxiv.org/abs/2112.15094</id>
        <link href="http://arxiv.org/abs/2112.15094"/>
        <updated>2022-01-03T07:15:42.143Z</updated>
        <summary type="html"><![CDATA[Linear dynamical systems are canonical models for learning-based control of
plants with uncertain dynamics. The setting consists of a stochastic
differential equation that captures the state evolution of the plant
understudy, while the true dynamics matrices are unknown and need to be learned
from the observed data of state trajectory. An important issue is to ensure
that the system is stabilized and destabilizing control actions due to model
uncertainties are precluded as soon as possible. A reliable stabilization
procedure for this purpose that can effectively learn from unstable data to
stabilize the system in a finite time is not currently available. In this work,
we propose a novel Bayesian learning algorithm that stabilizes unknown
continuous-time stochastic linear systems. The presented algorithm is flexible
and exposes effective stabilization performance after a remarkably short time
period of interacting with the system.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Faradonbeh_M/0/1/0/all/0/1"&gt;Mohamad Kazem Shirani Faradonbeh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Faradonbeh_M/0/1/0/all/0/1"&gt;Mohamad Sadegh Shirani Faradonbeh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High Dimensional Optimization through the Lens of Machine Learning. (arXiv:2112.15392v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2112.15392</id>
        <link href="http://arxiv.org/abs/2112.15392"/>
        <updated>2022-01-03T07:15:42.136Z</updated>
        <summary type="html"><![CDATA[This thesis reviews numerical optimization methods with machine learning
problems in mind. Since machine learning models are highly parametrized, we
focus on methods suited for high dimensional optimization. We build intuition
on quadratic models to figure out which methods are suited for non-convex
optimization, and develop convergence proofs on convex functions for this
selection of methods. With this theoretical foundation for stochastic gradient
descent and momentum methods, we try to explain why the methods used commonly
in the machine learning field are so successful. Besides explaining successful
heuristics, the last chapter also provides a less extensive review of more
theoretical methods, which are not quite as popular in practice. So in some
sense this work attempts to answer the question: Why are the default Tensorflow
optimizers included in the defaults?]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Benning_F/0/1/0/all/0/1"&gt;Felix Benning&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reward-Free Model-Based Reinforcement Learning with Linear Function Approximation. (arXiv:2110.06394v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2110.06394</id>
        <link href="http://arxiv.org/abs/2110.06394"/>
        <updated>2022-01-03T07:15:42.111Z</updated>
        <summary type="html"><![CDATA[We study the model-based reward-free reinforcement learning with linear
function approximation for episodic Markov decision processes (MDPs). In this
setting, the agent works in two phases. In the exploration phase, the agent
interacts with the environment and collects samples without the reward. In the
planning phase, the agent is given a specific reward function and uses samples
collected from the exploration phase to learn a good policy. We propose a new
provably efficient algorithm, called UCRL-RFE under the Linear Mixture MDP
assumption, where the transition probability kernel of the MDP can be
parameterized by a linear function over certain feature mappings defined on the
triplet of state, action, and next state. We show that to obtain an
$\epsilon$-optimal policy for arbitrary reward function, UCRL-RFE needs to
sample at most $\tilde{\mathcal{O}}(H^5d^2\epsilon^{-2})$ episodes during the
exploration phase. Here, $H$ is the length of the episode, $d$ is the dimension
of the feature mapping. We also propose a variant of UCRL-RFE using
Bernstein-type bonus and show that it needs to sample at most
$\tilde{\mathcal{O}}(H^4d(H + d)\epsilon^{-2})$ to achieve an
$\epsilon$-optimal policy. By constructing a special class of linear Mixture
MDPs, we also prove that for any reward-free algorithm, it needs to sample at
least $\tilde \Omega(H^2d\epsilon^{-2})$ episodes to obtain an
$\epsilon$-optimal policy. Our upper bound matches the lower bound in terms of
the dependence on $\epsilon$ and the dependence on $d$ if $H \ge d$.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1"&gt;Weitong Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Infinite wide (finite depth) Neural Networks benefit from multi-task learning unlike shallow Gaussian Processes -- an exact quantitative macroscopic characterization. (arXiv:2112.15577v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15577</id>
        <link href="http://arxiv.org/abs/2112.15577"/>
        <updated>2022-01-03T07:15:42.103Z</updated>
        <summary type="html"><![CDATA[We prove in this paper that wide ReLU neural networks (NNs) with at least one
hidden layer optimized with l2-regularization on the parameters enforces
multi-task learning due to representation-learning - also in the limit width to
infinity. This is in contrast to multiple other idealized settings discussed in
the literature where wide (ReLU)-NNs loose their ability to benefit from
multi-task learning in the limit width to infinity. We deduce the multi-task
learning ability from proving an exact quantitative macroscopic
characterization of the learned NN in function space.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Heiss_J/0/1/0/all/0/1"&gt;Jakob Heiss&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Teichmann_J/0/1/0/all/0/1"&gt;Josef Teichmann&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wutte_H/0/1/0/all/0/1"&gt;Hanna Wutte&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Causal Effects Evaluation in A/B Testing with a Reinforcement Learning Framework. (arXiv:2002.01711v5 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2002.01711</id>
        <link href="http://arxiv.org/abs/2002.01711"/>
        <updated>2022-01-03T07:15:42.097Z</updated>
        <summary type="html"><![CDATA[A/B testing, or online experiment is a standard business strategy to compare
a new product with an old one in pharmaceutical, technological, and traditional
industries. Major challenges arise in online experiments of two-sided
marketplace platforms (e.g., Uber) where there is only one unit that receives a
sequence of treatments over time. In those experiments, the treatment at a
given time impacts current outcome as well as future outcomes. The aim of this
paper is to introduce a reinforcement learning framework for carrying A/B
testing in these experiments, while characterizing the long-term treatment
effects. Our proposed testing procedure allows for sequential monitoring and
online updating. It is generally applicable to a variety of treatment designs
in different industries. In addition, we systematically investigate the
theoretical properties (e.g., size and power) of our testing procedure.
Finally, we apply our framework to both simulated data and a real-world data
example obtained from a technological company to illustrate its advantage over
the current practice. A Python implementation of our test is available at
https://github.com/callmespring/CausalRL.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1"&gt;Chengchun Shi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"&gt;Xiaoyu Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1"&gt;Shikai Luo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1"&gt;Hongtu Zhu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1"&gt;Jieping Ye&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1"&gt;Rui Song&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[G-PATE: Scalable Differentially Private Data Generator via Private Aggregation of Teacher Discriminators. (arXiv:1906.09338v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1906.09338</id>
        <link href="http://arxiv.org/abs/1906.09338"/>
        <updated>2022-01-03T07:15:41.872Z</updated>
        <summary type="html"><![CDATA[Recent advances in machine learning have largely benefited from the massive
accessible training data. However, large-scale data sharing has raised great
privacy concerns. In this work, we propose a novel privacy-preserving data
Generative model based on the PATE framework (G-PATE), aiming to train a
scalable differentially private data generator that preserves high generated
data utility. Our approach leverages generative adversarial nets to generate
data, combined with private aggregation among different discriminators to
ensure strong privacy guarantees. Compared to existing approaches, G-PATE
significantly improves the use of privacy budgets. In particular, we train a
student data generator with an ensemble of teacher discriminators and propose a
novel private gradient aggregation mechanism to ensure differential privacy on
all information that flows from teacher discriminators to the student
generator. In addition, with random projection and gradient discretization, the
proposed gradient aggregation mechanism is able to effectively deal with
high-dimensional gradient vectors. Theoretically, we prove that G-PATE ensures
differential privacy for the data generator. Empirically, we demonstrate the
superiority of G-PATE over prior work through extensive experiments. We show
that G-PATE is the first work being able to generate high-dimensional image
data with high data utility under limited privacy budgets ($\epsilon \le 1$).
Our code is available at https://github.com/AI-secure/G-PATE.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1"&gt;Yunhui Long&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1"&gt;Boxin Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1"&gt;Zhuolin Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1"&gt;Bhavya Kailkhura&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1"&gt;Aston Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gunter_C/0/1/0/all/0/1"&gt;Carl A. Gunter&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1"&gt;Bo Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modelling matrix time series via a tensor CP-decomposition. (arXiv:2112.15423v1 [stat.ME])]]></title>
        <id>http://arxiv.org/abs/2112.15423</id>
        <link href="http://arxiv.org/abs/2112.15423"/>
        <updated>2022-01-03T07:15:41.613Z</updated>
        <summary type="html"><![CDATA[We propose to model matrix time series based on a tensor CP-decomposition.
Instead of using an iterative algorithm which is the standard practice for
estimating CP-decompositions, we propose a new and one-pass estimation
procedure based on a generalized eigenanalysis constructed from the serial
dependence structure of the underlying process. A key idea of the new procedure
is to project a generalized eigenequation defined in terms of rank-reduced
matrices to a lower-dimensional one with full-ranked matrices, to avoid the
intricacy of the former of which the number of eigenvalues can be zero, finite
and infinity. The asymptotic theory has been established under a general
setting without the stationarity. It shows, for example, that all the component
coefficient vectors in the CP-decomposition are estimated consistently with the
different error rates, depending on the relative sizes between the dimensions
of time series and the sample size. The proposed model and the estimation
method are further illustrated with both simulated and real data; showing
effective dimension-reduction in modelling and forecasting matrix time series.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Chang_J/0/1/0/all/0/1"&gt;Jinyuan Chang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+He_J/0/1/0/all/0/1"&gt;Jing He&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Yang_L/0/1/0/all/0/1"&gt;Lin Yang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Yao_Q/0/1/0/all/0/1"&gt;Qiwei Yao&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Robust Training via Backward Smoothing. (arXiv:2010.01278v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.01278</id>
        <link href="http://arxiv.org/abs/2010.01278"/>
        <updated>2022-01-03T07:15:41.607Z</updated>
        <summary type="html"><![CDATA[Adversarial training is so far the most effective strategy in defending
against adversarial examples. However, it suffers from high computational costs
due to the iterative adversarial attacks in each training step. Recent studies
show that it is possible to achieve fast Adversarial Training by performing a
single-step attack with random initialization. However, such an approach still
lags behind state-of-the-art adversarial training algorithms on both stability
and model robustness. In this work, we develop a new understanding towards Fast
Adversarial Training, by viewing random initialization as performing randomized
smoothing for better optimization of the inner maximization problem. Following
this new perspective, we also propose a new initialization strategy, backward
smoothing, to further improve the stability and model robustness over
single-step robust training methods. Experiments on multiple benchmarks
demonstrate that our method achieves similar model robustness as the original
TRADES method while using much less training time ($\sim$3x improvement with
the same training schedule).]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"&gt;Jinghui Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1"&gt;Yu Cheng&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1"&gt;Zhe Gan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"&gt;Jingjing Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Algorithms Learn to Stabilize Unknown Continuous-Time Systems. (arXiv:2112.15094v1 [eess.SY])]]></title>
        <id>http://arxiv.org/abs/2112.15094</id>
        <link href="http://arxiv.org/abs/2112.15094"/>
        <updated>2022-01-03T07:15:41.599Z</updated>
        <summary type="html"><![CDATA[Linear dynamical systems are canonical models for learning-based control of
plants with uncertain dynamics. The setting consists of a stochastic
differential equation that captures the state evolution of the plant
understudy, while the true dynamics matrices are unknown and need to be learned
from the observed data of state trajectory. An important issue is to ensure
that the system is stabilized and destabilizing control actions due to model
uncertainties are precluded as soon as possible. A reliable stabilization
procedure for this purpose that can effectively learn from unstable data to
stabilize the system in a finite time is not currently available. In this work,
we propose a novel Bayesian learning algorithm that stabilizes unknown
continuous-time stochastic linear systems. The presented algorithm is flexible
and exposes effective stabilization performance after a remarkably short time
period of interacting with the system.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/eess/1/au:+Faradonbeh_M/0/1/0/all/0/1"&gt;Mohamad Kazem Shirani Faradonbeh&lt;/a&gt;, &lt;a href="http://arxiv.org/find/eess/1/au:+Faradonbeh_M/0/1/0/all/0/1"&gt;Mohamad Sadegh Shirani Faradonbeh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Decentralized Optimization Over the Stiefel Manifold by an Approximate Augmented Lagrangian Function. (arXiv:2112.14949v1 [math.OC])]]></title>
        <id>http://arxiv.org/abs/2112.14949</id>
        <link href="http://arxiv.org/abs/2112.14949"/>
        <updated>2022-01-03T07:15:41.574Z</updated>
        <summary type="html"><![CDATA[In this paper, we focus on the decentralized optimization problem over the
Stiefel manifold, which is defined on a connected network of $d$ agents. The
objective is an average of $d$ local functions, and each function is privately
held by an agent and encodes its data. The agents can only communicate with
their neighbors in a collaborative effort to solve this problem. In existing
methods, multiple rounds of communications are required to guarantee the
convergence, giving rise to high communication costs. In contrast, this paper
proposes a decentralized algorithm, called DESTINY, which only invokes a single
round of communications per iteration. DESTINY combines gradient tracking
techniques with a novel approximate augmented Lagrangian function. The global
convergence to stationary points is rigorously established. Comprehensive
numerical experiments demonstrate that DESTINY has a strong potential to
deliver a cutting-edge performance in solving a variety of testing problems.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Wang_L/0/1/0/all/0/1"&gt;Lei Wang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Liu_X/0/1/0/all/0/1"&gt;Xin Liu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Benign Overfitting in Adversarially Robust Linear Classification. (arXiv:2112.15250v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15250</id>
        <link href="http://arxiv.org/abs/2112.15250"/>
        <updated>2022-01-03T07:15:41.549Z</updated>
        <summary type="html"><![CDATA["Benign overfitting", where classifiers memorize noisy training data yet
still achieve a good generalization performance, has drawn great attention in
the machine learning community. To explain this surprising phenomenon, a series
of works have provided theoretical justification in over-parameterized linear
regression, classification, and kernel methods. However, it is not clear if
benign overfitting still occurs in the presence of adversarial examples, i.e.,
examples with tiny and intentional perturbations to fool the classifiers. In
this paper, we show that benign overfitting indeed occurs in adversarial
training, a principled approach to defend against adversarial examples. In
detail, we prove the risk bounds of the adversarially trained linear classifier
on the mixture of sub-Gaussian data under $\ell_p$ adversarial perturbations.
Our result suggests that under moderate perturbations, adversarially trained
linear classifiers can achieve the near-optimal standard and adversarial risks,
despite overfitting the noisy training data. Numerical experiments validate our
theoretical findings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"&gt;Jinghui Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"&gt;Yuan Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data-driven advice for interpreting local and global model predictions in bioinformatics problems. (arXiv:2108.06201v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2108.06201</id>
        <link href="http://arxiv.org/abs/2108.06201"/>
        <updated>2022-01-03T07:15:41.541Z</updated>
        <summary type="html"><![CDATA[Tree-based algorithms such as random forests and gradient boosted trees
continue to be among the most popular and powerful machine learning models used
across multiple disciplines. The conventional wisdom of estimating the impact
of a feature in tree based models is to measure the \textit{node-wise reduction
of a loss function}, which (i) yields only global importance measures and (ii)
is known to suffer from severe biases. Conditional feature contributions (CFCs)
provide \textit{local}, case-by-case explanations of a prediction by following
the decision path and attributing changes in the expected output of the model
to each feature along the path. However, Lundberg et al. pointed out a
potential bias of CFCs which depends on the distance from the root of a tree.
The by now immensely popular alternative, SHapley Additive exPlanation (SHAP)
values appear to mitigate this bias but are computationally much more
expensive. Here we contribute a thorough comparison of the explanations
computed by both methods on a set of 164 publicly available classification
problems in order to provide data-driven algorithm recommendations to current
researchers. For random forests, we find extremely high similarities and
correlations of both local and global SHAP values and CFC scores, leading to
very similar rankings and interpretations. Analogous conclusions hold for the
fidelity of using global feature importance scores as a proxy for the
predictive power associated with each feature.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Loecher_M/0/1/0/all/0/1"&gt;Markus Loecher&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Wu_Q/0/1/0/all/0/1"&gt;Qi Wu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[From Twitter to Traffic Predictor: Next-Day Morning Traffic Prediction Using Social Media Data. (arXiv:2009.13794v3 [cs.SI] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2009.13794</id>
        <link href="http://arxiv.org/abs/2009.13794"/>
        <updated>2022-01-03T07:15:41.525Z</updated>
        <summary type="html"><![CDATA[The effectiveness of traditional traffic prediction methods is often
extremely limited when forecasting traffic dynamics in early morning. The
reason is that traffic can break down drastically during the early morning
commute, and the time and duration of this break-down vary substantially from
day to day. Early morning traffic forecast is crucial to inform morning-commute
traffic management, but they are generally challenging to predict in advance,
particularly by midnight. In this paper, we propose to mine Twitter messages as
a probing method to understand the impacts of people's work and rest patterns
in the evening/midnight of the previous day to the next-day morning traffic.
The model is tested on freeway networks in Pittsburgh as experiments. The
resulting relationship is surprisingly simple and powerful. We find that, in
general, the earlier people rest as indicated from Tweets, the more congested
roads will be in the next morning. The occurrence of big events in the evening
before, represented by higher or lower tweet sentiment than normal, often
implies lower travel demand in the next morning than normal days. Besides,
people's tweeting activities in the night before and early morning are
statistically associated with congestion in morning peak hours. We make use of
such relationships to build a predictive framework which forecasts morning
commute congestion using people's tweeting profiles extracted by 5 am or as
late as the midnight prior to the morning. The Pittsburgh study supports that
our framework can precisely predict morning congestion, particularly for some
road segments upstream of roadway bottlenecks with large day-to-day congestion
variation. Our approach considerably outperforms those existing methods without
Twitter message features, and it can learn meaningful representation of demand
from tweeting profiles that offer managerial insights.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1"&gt;Weiran Yao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1"&gt;Sean Qian&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Random cohort effects and age groups dependency structure for mortality modelling and forecasting: Mixed-effects time-series model approach. (arXiv:2112.15258v1 [stat.AP])]]></title>
        <id>http://arxiv.org/abs/2112.15258</id>
        <link href="http://arxiv.org/abs/2112.15258"/>
        <updated>2022-01-03T07:15:41.517Z</updated>
        <summary type="html"><![CDATA[There have been significant efforts devoted to solving the longevity risk
given that a continuous growth in population ageing has become a severe issue
for many developed countries over the past few decades. The Cairns-Blake-Dowd
(CBD) model, which incorporates cohort effects parameters in its parsimonious
design, is one of the most well-known approaches for mortality modelling at
higher ages and longevity risk. This article proposes a novel mixed-effects
time-series approach for mortality modelling and forecasting with
considerations of age groups dependence and random cohort effects parameters.
The proposed model can disclose more mortality data information and provide a
natural quantification of the model parameters uncertainties with no
pre-specified constraint required for estimating the cohort effects parameters.
The abilities of the proposed approach are demonstrated through two
applications with empirical male and female mortality data. The proposed
approach shows remarkable improvements in terms of forecast accuracy compared
to the CBD model in the short-, mid-and long-term forecasting using mortality
data of several developed countries in the numerical examples.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Lam_K/0/1/0/all/0/1"&gt;Ka Kin Lam&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Wang_B/0/1/0/all/0/1"&gt;Bo Wang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Binary Diffing as a Network Alignment Problem via Belief Propagation. (arXiv:2112.15337v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15337</id>
        <link href="http://arxiv.org/abs/2112.15337"/>
        <updated>2022-01-03T07:15:41.510Z</updated>
        <summary type="html"><![CDATA[In this paper, we address the problem of finding a correspondence, or
matching, between the functions of two programs in binary form, which is one of
the most common task in binary diffing. We introduce a new formulation of this
problem as a particular instance of a graph edit problem over the call graphs
of the programs. In this formulation, the quality of a mapping is evaluated
simultaneously with respect to both function content and call graph
similarities. We show that this formulation is equivalent to a network
alignment problem. We propose a solving strategy for this problem based on
max-product belief propagation. Finally, we implement a prototype of our
method, called QBinDiff, and propose an extensive evaluation which shows that
our approach outperforms state of the art diffing tools.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Mengin_E/0/1/0/all/0/1"&gt;Elie Mengin&lt;/a&gt; (SAMM), &lt;a href="http://arxiv.org/find/cs/1/au:+Rossi_F/0/1/0/all/0/1"&gt;Fabrice Rossi&lt;/a&gt; (CEREMADE)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multiple Testing and Variable Selection along the path of the Least Angle Regression. (arXiv:1906.12072v4 [math.ST] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1906.12072</id>
        <link href="http://arxiv.org/abs/1906.12072"/>
        <updated>2022-01-03T07:15:41.490Z</updated>
        <summary type="html"><![CDATA[We investigate multiple testing and variable selection using the Least Angle
Regression (LARS) algorithm in high dimensions under the assumption of Gaussian
noise. LARS is known to produce a piecewise affine solution path with change
points referred to as the knots of the LARS path. The key to our results is an
expression in closed form of the exact joint law of a $K$-tuple of knots
conditional on the variables selected by LARS, namely the so-called
post-selection joint law of the LARS knots. Numerical experiments demonstrate
the perfect fit of our findings.

This paper makes three main contributions. First, we build testing procedures
on variables entering the model along the LARS path in the general design case
when the noise level can be unknown. These testing procedures are referred to
as the Generalized $t$-Spacing tests (GtSt) and we prove that they have an
exact non-asymptotic level (i.e., the Type I error is exactly controlled). This
extends work of (Taylor et al., 2014) where the spacing test works for
consecutive knots and known variance. Second, we introduce a new exact multiple
false negatives test after model selection in the general design case when the
noise level may be unknown. We prove that this testing procedure has exact
non-asymptotic level for general design and unknown noise level. Third, we give
an exact control of the false discovery rate under orthogonal design
assumption. Monte Carlo simulations and a real data experiment are provided to
illustrate our results in this case. Of independent interest, we introduce an
equivalent formulation of the LARS algorithm based on a recursive function.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Azais_J/0/1/0/all/0/1"&gt;J.-M. Aza&amp;#xef;s&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Castro_Y/0/1/0/all/0/1"&gt;Y. De Castro&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Triangular Flows for Generative Modeling: Statistical Consistency, Smoothness Classes, and Fast Rates. (arXiv:2112.15595v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2112.15595</id>
        <link href="http://arxiv.org/abs/2112.15595"/>
        <updated>2022-01-03T07:15:41.482Z</updated>
        <summary type="html"><![CDATA[Triangular flows, also known as Kn\"{o}the-Rosenblatt measure couplings,
comprise an important building block of normalizing flow models for generative
modeling and density estimation, including popular autoregressive flow models
such as real-valued non-volume preserving transformation models (Real NVP). We
present statistical guarantees and sample complexity bounds for triangular flow
statistical models. In particular, we establish the statistical consistency and
the finite sample convergence rates of the Kullback-Leibler estimator of the
Kn\"{o}the-Rosenblatt measure coupling using tools from empirical process
theory. Our results highlight the anisotropic geometry of function classes at
play in triangular flows, shed light on optimal coordinate ordering, and lead
to statistical guarantees for Jacobian flows. We conduct numerical experiments
on synthetic data to illustrate the practical implications of our theoretical
findings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Irons_N/0/1/0/all/0/1"&gt;Nicholas J. Irons&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Scetbon_M/0/1/0/all/0/1"&gt;Meyer Scetbon&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1"&gt;Soumik Pal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Harchaoui_Z/0/1/0/all/0/1"&gt;Zaid Harchaoui&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non Asymptotic Bounds for Optimization via Online Multiplicative Stochastic Gradient Descent. (arXiv:2112.07110v4 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.07110</id>
        <link href="http://arxiv.org/abs/2112.07110"/>
        <updated>2022-01-03T07:15:41.469Z</updated>
        <summary type="html"><![CDATA[The gradient noise of Stochastic Gradient Descent (SGD) is considered to play
a key role in its properties (e.g. escaping low potential points and
regularization). Past research has indicated that the covariance of the SGD
error done via minibatching plays a critical role in determining its
regularization and escape from low potential points. It is however not much
explored how much the distribution of the error influences the behavior of the
algorithm. Motivated by some new research in this area, we prove universality
results by showing that noise classes that have the same mean and covariance
structure of SGD via minibatching have similar properties. We mainly consider
the Multiplicative Stochastic Gradient Descent (M-SGD) algorithm as introduced
by Wu et al., which has a much more general noise class than the SGD algorithm
done via minibatching. We establish nonasymptotic bounds for the M-SGD
algorithm mainly with respect to the Stochastic Differential Equation
corresponding to SGD via minibatching. We also show that the M-SGD error is
approximately a scaled Gaussian distribution with mean $0$ at any fixed point
of the M-SGD algorithm. We also establish bounds for the convergence of the
M-SGD algorithm in the strongly convex regime.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Bhattacharya_R/0/1/0/all/0/1"&gt;Riddhiman Bhattacharya&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sufficient Statistic Memory AMP. (arXiv:2112.15327v1 [cs.IT])]]></title>
        <id>http://arxiv.org/abs/2112.15327</id>
        <link href="http://arxiv.org/abs/2112.15327"/>
        <updated>2022-01-03T07:15:41.461Z</updated>
        <summary type="html"><![CDATA[Approximate message passing (AMP) is a promising technique for unknown signal
reconstruction of certain high-dimensional linear systems with non-Gaussian
signaling. A distinguished feature of the AMP-type algorithms is that their
dynamics can be rigorously described by state evolution. However, state
evolution does not necessarily guarantee the convergence of iterative
algorithms. To solve the convergence problem of AMP-type algorithms in
principle, this paper proposes a memory AMP (MAMP) under a sufficient statistic
condition, named sufficient statistic MAMP (SS-MAMP). We show that the
covariance matrices of SS-MAMP are L-banded and convergent. Given an arbitrary
MAMP, we can construct an SS-MAMP by damping, which not only ensures the
convergence of MAMP but also preserves the orthogonality of MAMP, i.e., its
dynamics can be rigorously described by state evolution. As a byproduct, we
prove that the Bayes-optimal orthogonal/vector AMP (BO-OAMP/VAMP) is an
SS-MAMP. As a result, we reveal two interesting properties of BO-OAMP/VAMP for
large systems: 1) the covariance matrices are L-banded and are convergent in
BO-OAMP/VAMP, and 2) damping and memory are useless (i.e., do not bring
performance improvement) in BO-OAMP/VAMP. As an example, we construct a
sufficient statistic Bayes-optimal MAMP (BO-MAMP), which is Bayes optimal if
its state evolution has a unique fixed point and its MSE is not worse than the
original BO-MAMP. Finally, simulations are provided to verify the validity and
accuracy of the theoretical results.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1"&gt;Lei Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1"&gt;Shunqi Huang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Kurkoski_B/0/1/0/all/0/1"&gt;Brian M. Kurkoski&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The SAMME.C2 algorithm for severely imbalanced multi-class classification. (arXiv:2112.14868v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2112.14868</id>
        <link href="http://arxiv.org/abs/2112.14868"/>
        <updated>2022-01-03T07:15:41.438Z</updated>
        <summary type="html"><![CDATA[Classification predictive modeling involves the accurate assignment of
observations in a dataset to target classes or categories. There is an
increasing growth of real-world classification problems with severely
imbalanced class distributions. In this case, minority classes have much fewer
observations to learn from than those from majority classes. Despite this
sparsity, a minority class is often considered the more interesting class yet
developing a scientific learning algorithm suitable for the observations
presents countless challenges. In this article, we suggest a novel multi-class
classification algorithm specialized to handle severely imbalanced classes
based on the method we refer to as SAMME.C2. It blends the flexible mechanics
of the boosting techniques from SAMME algorithm, a multi-class classifier, and
Ada.C2 algorithm, a cost-sensitive binary classifier designed to address highly
class imbalances. Not only do we provide the resulting algorithm but we also
establish scientific and statistical formulation of our proposed SAMME.C2
algorithm. Through numerical experiments examining various degrees of
classifier difficulty, we demonstrate consistent superior performance of our
proposed model.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+So_B/0/1/0/all/0/1"&gt;Banghee So&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Valdez_E/0/1/0/all/0/1"&gt;Emiliano A. Valdez&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?. (arXiv:1911.12360v4 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/1911.12360</id>
        <link href="http://arxiv.org/abs/1911.12360"/>
        <updated>2022-01-03T07:15:41.431Z</updated>
        <summary type="html"><![CDATA[A recent line of research on deep learning focuses on the extremely
over-parameterized setting, and shows that when the network width is larger
than a high degree polynomial of the training sample size $n$ and the inverse
of the target error $\epsilon^{-1}$, deep neural networks learned by
(stochastic) gradient descent enjoy nice optimization and generalization
guarantees. Very recently, it is shown that under certain margin assumptions on
the training data, a polylogarithmic width condition suffices for two-layer
ReLU networks to converge and generalize (Ji and Telgarsky, 2019). However,
whether deep neural networks can be learned with such a mild
over-parameterization is still an open question. In this work, we answer this
question affirmatively and establish sharper learning guarantees for deep ReLU
networks trained by (stochastic) gradient descent. In specific, under certain
assumptions made in previous work, our optimization and generalization
guarantees hold with network width polylogarithmic in $n$ and $\epsilon^{-1}$.
Our results push the study of over-parameterized deep neural networks towards
more practical settings.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"&gt;Zixiang Chen&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"&gt;Yuan Cao&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1"&gt;Difan Zou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Studying the Interplay between Information Loss and Operation Loss in Representations for Classification. (arXiv:2112.15238v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15238</id>
        <link href="http://arxiv.org/abs/2112.15238"/>
        <updated>2022-01-03T07:15:41.424Z</updated>
        <summary type="html"><![CDATA[Information-theoretic measures have been widely adopted in the design of
features for learning and decision problems. Inspired by this, we look at the
relationship between i) a weak form of information loss in the Shannon sense
and ii) the operation loss in the minimum probability of error (MPE) sense when
considering a family of lossy continuous representations (features) of a
continuous observation. We present several results that shed light on this
interplay. Our first result offers a lower bound on a weak form of information
loss as a function of its respective operation loss when adopting a discrete
lossy representation (quantization) instead of the original raw observation.
From this, our main result shows that a specific form of vanishing information
loss (a weak notion of asymptotic informational sufficiency) implies a
vanishing MPE loss (or asymptotic operational sufficiency) when considering a
general family of lossy continuous representations. Our theoretical findings
support the observation that the selection of feature representations that
attempt to capture informational sufficiency is appropriate for learning, but
this selection is a rather conservative design principle if the intended goal
is achieving MPE in classification. Supporting this last point, and under some
structural conditions, we show that it is possible to adopt an alternative
notion of informational sufficiency (strictly weaker than pure sufficiency in
the mutual information sense) to achieve operational sufficiency in learning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1"&gt;Jorge F. Silva&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Tobar_F/0/1/0/all/0/1"&gt;Felipe Tobar&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Vicuna_M/0/1/0/all/0/1"&gt;Mario Vicu&amp;#xf1;a&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Cordova_F/0/1/0/all/0/1"&gt;Felipe Cordova&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Thompson Sampling. (arXiv:2010.00827v2 [cs.LG] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2010.00827</id>
        <link href="http://arxiv.org/abs/2010.00827"/>
        <updated>2022-01-03T07:15:41.417Z</updated>
        <summary type="html"><![CDATA[Thompson Sampling (TS) is one of the most effective algorithms for solving
contextual multi-armed bandit problems. In this paper, we propose a new
algorithm, called Neural Thompson Sampling, which adapts deep neural networks
for both exploration and exploitation. At the core of our algorithm is a novel
posterior distribution of the reward, where its mean is the neural network
approximator, and its variance is built upon the neural tangent features of the
corresponding neural network. We prove that, provided the underlying reward
function is bounded, the proposed algorithm is guaranteed to achieve a
cumulative regret of $\mathcal{O}(T^{1/2})$, which matches the regret of other
contextual bandit algorithms in terms of total round number $T$. Experimental
comparisons with other benchmark bandit algorithms on various data sets
corroborate our theory.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1"&gt;Weitong Zhang&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"&gt;Dongruo Zhou&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"&gt;Lihong Li&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1"&gt;Quanquan Gu&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Model Averaging of Support Vector Machines in Diverging Model Spaces. (arXiv:2112.12961v2 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2112.12961</id>
        <link href="http://arxiv.org/abs/2112.12961"/>
        <updated>2022-01-03T07:15:41.410Z</updated>
        <summary type="html"><![CDATA[Support vector machine (SVM) is a powerful classification method that has
achieved great success in many fields. Since its performance can be seriously
impaired by redundant covariates, model selection techniques are widely used
for SVM with high dimensional covariates. As an alternative to model selection,
significant progress has been made in the area of model averaging in the past
decades. Yet no frequentist model averaging method was considered for SVM. This
work aims to fill the gap and to propose a frequentist model averaging
procedure for SVM which selects the optimal weight by cross validation. Even
when the number of covariates diverges at an exponential rate of the sample
size, we show asymptotic optimality of the proposed method in the sense that
the ratio of its hinge loss to the lowest possible loss converges to one. We
also derive the convergence rate which provides more insights to model
averaging. Compared to model selection methods of SVM which require a tedious
but critical task of tuning parameter selection, the model averaging method
avoids the task and shows promising performances in the empirical studies.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Yuan_C/0/1/0/all/0/1"&gt;Chaoxia Yuan&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Ying_C/0/1/0/all/0/1"&gt;Chao Ying&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Yu_Z/0/1/0/all/0/1"&gt;Zhou Yu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Fang_F/0/1/0/all/0/1"&gt;Fang Fang&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hierarchical forecasting with a top-down alignment of independent level forecasts. (arXiv:2103.08250v4 [stat.ML] UPDATED)]]></title>
        <id>http://arxiv.org/abs/2103.08250</id>
        <link href="http://arxiv.org/abs/2103.08250"/>
        <updated>2022-01-03T07:15:41.334Z</updated>
        <summary type="html"><![CDATA[Hierarchical forecasting with intermittent time series is a challenge in both
research and empirical studies. Extensive research focuses on improving the
accuracy of each hierarchy, especially the intermittent time series at bottom
levels. Then hierarchical reconciliation could be used to improve the overall
performance further. In this paper, we present a
\emph{hierarchical-forecasting-with-alignment} approach that treats the bottom
level forecasts as mutable to ensure higher forecasting accuracy on the upper
levels of the hierarchy. We employ a pure deep learning forecasting approach
N-BEATS for continuous time series at the top levels and a widely used
tree-based algorithm LightGBM for the intermittent time series at the bottom
level. The \emph{hierarchical-forecasting-with-alignment} approach is a simple
yet effective variant of the bottom-up method, accounting for biases that are
difficult to observe at the bottom level. It allows suboptimal forecasts at the
lower level to retain a higher overall performance. The approach in this
empirical study was developed by the first author during the M5 Forecasting
Accuracy competition, ranking second place. The method is also business
orientated and could benefit for business strategic planning.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Anderer_M/0/1/0/all/0/1"&gt;Matthias Anderer&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1"&gt;Feng Li&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Separation of scales and a thermodynamic description of feature learning in some CNNs. (arXiv:2112.15383v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2112.15383</id>
        <link href="http://arxiv.org/abs/2112.15383"/>
        <updated>2022-01-03T07:15:41.326Z</updated>
        <summary type="html"><![CDATA[Deep neural networks (DNNs) are powerful tools for compressing and distilling
information. Due to their scale and complexity, often involving billions of
inter-dependent internal degrees of freedom, exact analysis approaches often
fall short. A common strategy in such cases is to identify slow degrees of
freedom that average out the erratic behavior of the underlying fast
microscopic variables. Here, we identify such a separation of scales occurring
in over-parameterized deep convolutional neural networks (CNNs) at the end of
training. It implies that neuron pre-activations fluctuate in a nearly Gaussian
manner with a deterministic latent kernel. While for CNNs with infinitely many
channels these kernels are inert, for finite CNNs they adapt and learn from
data in an analytically tractable manner. The resulting thermodynamic theory of
deep learning yields accurate predictions on several deep non-linear CNN toy
models. In addition, it provides new ways of analyzing and understanding CNNs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1"&gt;Inbar Seroussi&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1"&gt;Zohar Ringel&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improved Algorithm for the Network Alignment Problem with Application to Binary Diffing. (arXiv:2112.15336v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15336</id>
        <link href="http://arxiv.org/abs/2112.15336"/>
        <updated>2022-01-03T07:15:41.265Z</updated>
        <summary type="html"><![CDATA[In this paper, we present a novel algorithm to address the Network Alignment
problem. It is inspired from a previous message passing framework of Bayati et
al. [2] and includes several modifications designed to significantly speed up
the message updates as well as to enforce their convergence. Experiments show
that our proposed model outperforms other state-of-the-art solvers. Finally, we
propose an application of our method in order to address the Binary Diffing
problem. We show that our solution provides better assignment than the
reference differs in almost all submitted instances and outline the importance
of leveraging the graphical structure of binary programs.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Mengin_E/0/1/0/all/0/1"&gt;Elie Mengin&lt;/a&gt; (SAMM), &lt;a href="http://arxiv.org/find/cs/1/au:+Rossi_F/0/1/0/all/0/1"&gt;Fabrice Rossi&lt;/a&gt; (CEREMADE)</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Optimization of Function Networks. (arXiv:2112.15311v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.15311</id>
        <link href="http://arxiv.org/abs/2112.15311"/>
        <updated>2022-01-03T07:15:41.025Z</updated>
        <summary type="html"><![CDATA[We consider Bayesian optimization of the output of a network of functions,
where each function takes as input the output of its parent nodes, and where
the network takes significant time to evaluate. Such problems arise, for
example, in reinforcement learning, engineering design, and manufacturing.
While the standard Bayesian optimization approach observes only the final
output, our approach delivers greater query efficiency by leveraging
information that the former ignores: intermediate output within the network.
This is achieved by modeling the nodes of the network using Gaussian processes
and choosing the points to evaluate using, as our acquisition function, the
expected improvement computed with respect to the implied posterior on the
objective. Although the non-Gaussian nature of this posterior prevents
computing our acquisition function in closed form, we show that it can be
efficiently maximized via sample average approximation. In addition, we prove
that our method is asymptotically consistent, meaning that it finds a globally
optimal solution as the number of evaluations grows to infinity, thus
generalizing previously known convergence results for the expected improvement.
Notably, this holds even though our method might not evaluate the domain
densely, instead leveraging problem structure to leave regions unexplored.
Finally, we show that our approach dramatically outperforms standard Bayesian
optimization methods in several synthetic and real-world problems.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Astudillo_R/0/1/0/all/0/1"&gt;Raul Astudillo&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Frazier_P/0/1/0/all/0/1"&gt;Peter I. Frazier&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Unified and Constructive Framework for the Universality of Neural Networks. (arXiv:2112.14877v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14877</id>
        <link href="http://arxiv.org/abs/2112.14877"/>
        <updated>2022-01-03T07:15:40.990Z</updated>
        <summary type="html"><![CDATA[One of the reasons that many neural networks are capable of replicating
complicated tasks or functions is their universality property. The past few
decades have seen many attempts in providing constructive proofs for single or
class of neural networks. This paper is an effort to provide a unified and
constructive framework for the universality of a large class of activations
including most of existing activations and beyond. At the heart of the
framework is the concept of neural network approximate identity. It turns out
that most of existing activations are neural network approximate identity, and
thus universal in the space of continuous of functions on compacta. The
framework induces several advantages. First, it is constructive with elementary
means from functional analysis, probability theory, and numerical analysis.
Second, it is the first unified attempt that is valid for most of existing
activations. Third, as a by product, the framework provides the first
university proof for some of the existing activation functions including Mish,
SiLU, ELU, GELU, and etc. Fourth, it discovers new activations with guaranteed
universality property. Indeed, any activation\textemdash whose $\k$th
derivative, with $\k$ being an integer, is integrable and essentially
bounded\textemdash is universal. Fifth, for a given activation and error
tolerance, the framework provides precisely the architecture of the
corresponding one-hidden neural network with predetermined number of neuron,
and the values of weights/biases.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Bui_Thanh_T/0/1/0/all/0/1"&gt;Tan Bui-Thanh&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A sampling-based approach for efficient clustering in large datasets. (arXiv:2112.14793v1 [cs.LG])]]></title>
        <id>http://arxiv.org/abs/2112.14793</id>
        <link href="http://arxiv.org/abs/2112.14793"/>
        <updated>2022-01-03T07:15:40.939Z</updated>
        <summary type="html"><![CDATA[We propose a simple and efficient clustering method for high-dimensional data
with a large number of clusters. Our algorithm achieves high-performance by
evaluating distances of datapoints with a subset of the cluster centres. Our
contribution is substantially more efficient than k-means as it does not
require an all to all comparison of data points and clusters. We show that the
optimal solutions of our approximation are the same as in the exact solution.
However, our approach is considerably more efficient at extracting these
clusters compared to the state-of-the-art. We compare our approximation with
the exact k-means and alternative approximation approaches on a series of
standardised clustering tasks. For the evaluation, we consider the algorithmic
complexity, including number of operations to convergence, and the stability of
the results.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/cs/1/au:+Exarchakis_G/0/1/0/all/0/1"&gt;Georgios Exarchakis&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Oubari_O/0/1/0/all/0/1"&gt;Omar Oubari&lt;/a&gt;, &lt;a href="http://arxiv.org/find/cs/1/au:+Lenz_G/0/1/0/all/0/1"&gt;Gregor Lenz&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Entropy Regularized Optimal Transport Independence Criterion. (arXiv:2112.15265v1 [stat.ML])]]></title>
        <id>http://arxiv.org/abs/2112.15265</id>
        <link href="http://arxiv.org/abs/2112.15265"/>
        <updated>2022-01-03T07:15:40.909Z</updated>
        <summary type="html"><![CDATA[Optimal transport (OT) and its entropy regularized offspring have recently
gained a lot of attention in both machine learning and AI domains. In
particular, optimal transport has been used to develop probability metrics
between probability distributions. We introduce in this paper an independence
criterion based on entropy regularized optimal transport. Our criterion can be
used to test for independence between two samples. We establish non-asymptotic
bounds for our test statistic, and study its statistical behavior under both
the null and alternative hypothesis. Our theoretical results involve tools from
U-process theory and optimal transport theory. We present experimental results
on existing benchmarks, illustrating the interest of the proposed criterion.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/stat/1/au:+Liu_L/0/1/0/all/0/1"&gt;Lang Liu&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1"&gt;Soumik Pal&lt;/a&gt;, &lt;a href="http://arxiv.org/find/stat/1/au:+Harchaoui_Z/0/1/0/all/0/1"&gt;Zaid Harchaoui&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Time varying regression with hidden linear dynamics. (arXiv:2112.14862v1 [math.ST])]]></title>
        <id>http://arxiv.org/abs/2112.14862</id>
        <link href="http://arxiv.org/abs/2112.14862"/>
        <updated>2022-01-03T07:15:40.892Z</updated>
        <summary type="html"><![CDATA[We revisit a model for time-varying linear regression that assumes the
unknown parameters evolve according to a linear dynamical system.
Counterintuitively, we show that when the underlying dynamics are stable the
parameters of this model can be estimated from data by combining just two
ordinary least squares estimates. We offer a finite sample guarantee on the
estimation error of our method and discuss certain advantages it has over
Expectation-Maximization (EM), which is the main approach proposed by prior
work.]]></summary>
        <author>
            <name>&lt;a href="http://arxiv.org/find/math/1/au:+Jadbabaie_A/0/1/0/all/0/1"&gt;Ali Jadbabaie&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Mania_H/0/1/0/all/0/1"&gt;Horia Mania&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Shah_D/0/1/0/all/0/1"&gt;Devavrat Shah&lt;/a&gt;, &lt;a href="http://arxiv.org/find/math/1/au:+Sra_S/0/1/0/all/0/1"&gt;Suvrit Sra&lt;/a&gt;</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to change MDP into POMDP? (getting pixel observations)]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/ruvrti/how_to_change_mdp_into_pomdp_getting_pixel/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/ruvrti/how_to_change_mdp_into_pomdp_getting_pixel/"/>
        <updated>2022-01-03T07:11:19.000Z</updated>
        <summary type="html"><![CDATA[Hi, I'm looking into OpenAI robogym (https://github.com/openai/robogym)'s rearrange environments, and want to try RL-based control on it with pixel observations.
 The default observations are not pixels, and I can't seem to find any documentation online on how to change these environments into pixel observations.
 Can anyone point me to resources where similar changes have been done? Are there preexisting wrappers or code for similar mujoco environments anywhere?
 My other option is to simply render the environment with mode rgb_array, and then train the algorithm based on these rendered observations. Is this a viable option?
    submitted by    /u/junkQn  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rutbpv/r_a_neural_network_solves_and_generates/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rutbpv/r_a_neural_network_solves_and_generates/"/>
        <updated>2022-01-03T04:50:29.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/shitboots  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Is there flow-based method which treats input data as different lengths each?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rut9hs/d_is_there_flowbased_method_which_treats_input/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rut9hs/d_is_there_flowbased_method_which_treats_input/"/>
        <updated>2022-01-03T04:47:08.000Z</updated>
        <summary type="html"><![CDATA[Hello. I am searching the researches that different size of data are generated through the flow-based network, not super-resolution task such as continuous mapping.
 I want to generate output as time-aligned scalar data, for example
 
 Input: noise sampling (B x T x C)
 Output: scalar data (B x T, C=1)
 
 with introducing the variational data augmentation technique (in vFlow, which can output high-dimensionality as concatenate noise vector for input and output both) for output.
 But there's a problem time dimension T is different for each of all data input. How can I treat this problem?
 
 p.s. I am very appreciate if I can read the flow-based research in NLP task.
    submitted by    /u/RedCuraceo  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Anyone switched from vision to robotics?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rur95m/d_anyone_switched_from_vision_to_robotics/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rur95m/d_anyone_switched_from_vision_to_robotics/"/>
        <updated>2022-01-03T03:03:06.000Z</updated>
        <summary type="html"><![CDATA[Im about to finish my PhD and the whole field of robotics looks so exciting right now, especially applications like farming and recycling. Has anyone switched from more pure deep learning (vision / NLP) to robotics and how did it happen?
 Did you just get a robotics related job focusing on the vision side of things or is it key to have more experience on the robotics side before getting a job?
 Also Im curious whats the best location for robotics? Like how you go to Hong Kong / New York for finance, SF for software or Shenzhen for hardware.
    submitted by    /u/temporary_ml_guy  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] I like YOLOv5 but the code complexity is...]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rur2j3/p_i_like_yolov5_but_the_code_complexity_is/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rur2j3/p_i_like_yolov5_but_the_code_complexity_is/"/>
        <updated>2022-01-03T02:54:14.000Z</updated>
        <summary type="html"><![CDATA[I like YOLOv5 but the code complexity is...
 I can't deny that YOLOv5 is a practical open-source object detection pipeline. However, the pain begins when adding new features or new experimental methods. Code dependencies are hard to follow which makes the code difficult to maintain. We wanted to try various experimental methods but hate to write one-time code that is never re-used.
 So we worked on making an object detection pipeline to have a better code structure so that we could continuously improve and add new features while easy to maintain.
 https://github.com/j-marple-dev/AYolov2
 And we applied CI(Formating, Linting, Unittest) to ensure code quality with Docker support for development and inference. Our Docker supports the development environment with VIM.
 Our code design from the]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Discrete Actions (OpenAI Hide & Seek)]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rup48q/discrete_actions_openai_hide_seek/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rup48q/discrete_actions_openai_hide_seek/"/>
        <updated>2022-01-03T01:22:41.000Z</updated>
        <summary type="html"><![CDATA[Hello :),
 Happy new year to all of you!
 I have a question regarding the action space for the Hide & Seek paper by OpenAI. The architecture of the learning model they used is below.
 https://preview.redd.it/el54yihfjd981.png?width=794&format=png&auto=webp&s=33c5228ac8003b9bb89b6d008e2cf2aea5f7e071
 They have eventually 3 action heads, as shown in the figure. As per the authors, the movement action for an agent "sets a discretized force along their x and y axis and torque around their z-axis". How do these 3 forces get pulled from the "movement action head", given that they are discretized? Does the movement action head have 3 outputs, each corresponding to an axis? So far, in my humble knowledge, I always assumed that a network with a discrete action space gives only one action per head (which could be the result of a softmax over the action space).
 Any insight?
  
After some digging, I found that the Movement Action has a "MultiDiscrete" type, which is a gym class. I am struggling to understand the nature of actions produced by this class, any idea?
  
   submitted by    /u/AhmedNizam_  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] GUI-based Machine Learning applications?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ruofql/d_guibased_machine_learning_applications/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ruofql/d_guibased_machine_learning_applications/"/>
        <updated>2022-01-03T00:50:33.000Z</updated>
        <summary type="html"><![CDATA[I was previously using Azure Machine Learning Studio(classic), and of course, it was discontinued last month. Any other free ML applications?
 The new Azure Machine Learning Studio isn't free, and this is a school project so I'm aiming for free and simple.
 Any suggestions? Or maybe someone else is using Studio(classic) and knows a way around this?
    submitted by    /u/max02c  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Illustrated Retrieval Transformer]]></title>
        <id>http://jalammar.github.io/illustrated-retrieval-transformer/</id>
        <link href="http://jalammar.github.io/illustrated-retrieval-transformer/"/>
        <updated>2022-01-03T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Discussion: Discussion Thread for comments, corrections, or any feedback. Summary: The latest batch of language models can be much smaller yet achieve GPT-3 like performance by being able to query a database or search the web for information. A key indication is that building larger and larger models is not the only way to improve performance. The last few years saw the rise of Large Language Models (LLMs)  machine learning models that rapidly improve how machines process and generate language. Some of the highlights since 2017 include: The original Transformer breaks previous performance records for machine translation. BERT popularizes the pre-training then finetuning process, as well as Transformer-based contextualized word embeddings. It then rapidly starts to power Google Search and Bing Search. GPT-2 demonstrates the machines ability to write as well as humans do. First T5, then T0 push the boundaries of transfer learning (training a model on one task, and then having it do well on other adjacent tasks) and posing a lot of different tasks as text-to-text tasks. GPT-3 showed that massive scaling of generative models can lead to shocking emergent applications (the industry continues to train larger models like Gopher, MT-NLGetc). For a while, it seemed like scaling larger and larger models is the main way to improve performance. Recent developments in the field, like DeepMinds RETRO Transformer and OpenAIs WebGPT, reverse this trend by showing that smaller generative language models can perform on par with massive models if we augment them with a way to search/query for information. This article breaks down DeepMinds RETRO (Retrieval-Enhanced TRansfOrmer) and how it works. The model performs on par with GPT-3 despite being 4% its size (7.5 billion parameters vs. 185 billion for GPT-3 Da Vinci). RETRO incorporates information retrieved from a database to free its parameters from being an expensive store of facts and world knowledge. RETRO was presented in the paper Improving Language Models by Retrieving from Trillions of Tokens. It continues and builds on a wide variety of retrieval work in the research community. This article explains the model and not what is especially novel about it.]]></summary>
        <author>
            <name>Jay Alammar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I built an AI Discord bot that bans NFT Bros from my server]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rumhy3/i_built_an_ai_discord_bot_that_bans_nft_bros_from/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rumhy3/i_built_an_ai_discord_bot_that_bans_nft_bros_from/"/>
        <updated>2022-01-02T23:22:04.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/TernaryJimbo  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What can AI discover in data that I was not expecting?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rumd9r/what_can_ai_discover_in_data_that_i_was_not/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rumd9r/what_can_ai_discover_in_data_that_i_was_not/"/>
        <updated>2022-01-02T23:16:32.000Z</updated>
        <summary type="html"><![CDATA[Help me understand this please. Ive read that people feed data to an AI/ML algorithm and find things that they werent looking for but there arent many good examples out there to read about.
 So Im thinking: if I were to feed into an AI/ML algorithm a csv of order details and customer data from an eCommerce system, should I expect the AI engine to find something statistically usual/unusual and tell me about it? 
 Or do I need to instruct it to look for certain traits with e-commerce orders and customers that I already know about? Eg look out for fraud by checking x y z. 
 What if the thing to look for is so strange that you need the AI to pick it up. Eg maybe fraudsters start telling their friends to always use a certain name or phone number as an inside joke. I would think an AI might pick on that somehow whereas it might take a human a longer time to figure that out.
    submitted by    /u/rich_atl  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I built an AI Discord Bot that bans NFT Bros [Meme][Video]]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rum6u8/i_built_an_ai_discord_bot_that_bans_nft_bros/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rum6u8/i_built_an_ai_discord_bot_that_bans_nft_bros/"/>
        <updated>2022-01-02T23:08:52.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/TernaryJimbo  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] A Comparison Of The Program Synthesis Performance Of GitHub Copilot And Genetic Programming]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rum37y/r_a_comparison_of_the_program_synthesis/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rum37y/r_a_comparison_of_the_program_synthesis/"/>
        <updated>2022-01-02T23:04:23.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/EducationalCicada  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Machine Learning - WAYR (What Are You Reading) - Week 128]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ruja9s/d_machine_learning_wayr_what_are_you_reading_week/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ruja9s/d_machine_learning_wayr_what_are_you_reading_week/"/>
        <updated>2022-01-02T21:00:05.000Z</updated>
        <summary type="html"><![CDATA[This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.
 Please try to provide some insight from your understanding and please don't post things which are present in wiki.
 Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.
 Previous weeks :
  
 1-10 11-20 21-30 31-40 41-50 51-60 61-70 71-80 81-90 91-100 101-110 111-120 121-130 
  
 Week 1 Week 11 Week 21 Week 31 Week 41 Week 51 Week 61 Week 71 Week 81 Week 91 Week 101 Week 111 Week 121 
  Week 2 Week 12 Week 22 Week 32]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Artificial Intelligence for Mental Health]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086932</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086932"/>
        <updated>2022-01-02T21:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9976535685?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9976535685?profile=RESIZE_710x" width="720"></img></a></p>
<p>Happy new year!</p>
<p></p>
<p>This year , lets start with an issue that gained so much prominence over the last two years: mental health. A variety of AI techniques and strategies have been employed in mental health.</p>
<p>In this post, we summarise the findings based on a paper (link below)</p>
<p></p>
<h2>Summary</h2>
<ul>
<li>The main predictor</li>
</ul>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] ICLR 2022 Open Discussion Quality]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ruj3ja/d_iclr_2022_open_discussion_quality/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ruj3ja/d_iclr_2022_open_discussion_quality/"/>
        <updated>2022-01-02T20:51:32.000Z</updated>
        <summary type="html"><![CDATA[First time submitting to ICLR, I'm wondering how is the open discussion on openreview.net really different from the review-rebuttal procedure used in other conferences.
 For the papers I'm reviewing, about half the reviewers reacted to the authors' responses (clarifications, modifications, additional experiments, etc.). As to my submission (5568), I run extra experiments and answered each of the concerns directly but received 0 feedback from the reviewers.
 As a reviewer, I think it doesn't matter if the rebuttal changes your mind about the quality of the submission but it's very basic manner to reply to the authors' responses. A simple "Thank the authors for the responses but I don't think these addressed my concerns" would work. Saying nothing only means you are uncertain if the responses make sense and you just doesn't care to figure it out. The authors spent a whole week running experiments to answer some of your questions and if you don't give **** about their responses, just keep the questions with you and don't submit your review.
 I was hoping for a different experience submitting to ICLR and then I realized the "discussion" is basically broken.
    submitted by    /u/MLPRulesAll  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[project] Credit Scoring]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/ruigzx/project_credit_scoring/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/ruigzx/project_credit_scoring/"/>
        <updated>2022-01-02T20:24:14.000Z</updated>
        <summary type="html"><![CDATA[hey peeps,
 any research thesis regarding credit scoring in microfinance?
    submitted by    /u/abschlusssss  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Player of Games", Schmid et al 2021 {DM} (generalizing AlphaZero to imperfect-information games)]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rui9bm/player_of_games_schmid_et_al_2021_dm_generalizing/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rui9bm/player_of_games_schmid_et_al_2021_dm_generalizing/"/>
        <updated>2022-01-02T20:14:43.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/gwern  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Software 3.0: Prompt programming]]></title>
        <id>https://www.reddit.com/r/artificial/comments/ruhqfv/software_30_prompt_programming/</id>
        <link href="https://www.reddit.com/r/artificial/comments/ruhqfv/software_30_prompt_programming/"/>
        <updated>2022-01-02T19:51:33.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/Respawne  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Russian Bioinformaticians Have Created A Neural Network Architecture That Can Evaluate How Well An RNA Guide Has Been Chosen For Gene Editing]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rufjxi/russian_bioinformaticians_have_created_a_neural/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rufjxi/russian_bioinformaticians_have_created_a_neural/"/>
        <updated>2022-01-02T18:15:29.000Z</updated>
        <summary type="html"><![CDATA[Genomic editing, particularly the CRISPR/Cas technique, is widely employed in experimental biology, agriculture, and biotechnology. CRISPR/Cas is one of several weapons used by bacteria to resist viruses. As the pathogens DNA enters the cell, Cas proteins detect it as foreign hereditary material and break it because its sequences differ from those of the bacteria. To respond to the virus quicker, the bacterium saves pieces of the pathogens DNAmuch like a computer antivirus retains a collection of viral signaturesand passes them on to subsequent generations so that its Cas can prevent future attacks.
 Teams from different laboratories independently adapted the CRISPR/Cas system to introduce arbitrary changes into DNA sequences in human and animal cells. It made genomic editing much easier and more efficient. The critical components of the mechanism are guide RNA, which marks the site, and the Cas9 protein, which cleaves DNA at that location. The cell subsequently heals the wound, but the genetic code has already been altered.
 Quick Reading: https://www.marktechpost.com/2022/01/02/russian-bioinformaticians-have-created-a-neural-network-architecture-that-can-evaluate-how-well-an-rna-guide-has-been-chosen-for-gene-editing/ 
 Paper: https://academic.oup.com/nar/advance-article/doi/10.1093/nar/gkab1065/6430490
    submitted by    /u/ai-lover  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tang Jie, the Tsinghua University professor leading the Wu Dao project, said in a recent interview that the group built 100 TRILLION parameter model in June, though it has not trained it to convergence, the point at which the model stops improving]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rueink/tang_jie_the_tsinghua_university_professor/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rueink/tang_jie_the_tsinghua_university_professor/"/>
        <updated>2022-01-02T17:29:38.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/No-Transition-6630  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is the best method/technology to deploy deep reinforcement learning models for robotics?]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rue5bf/what_is_the_best_methodtechnology_to_deploy_deep/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rue5bf/what_is_the_best_methodtechnology_to_deploy_deep/"/>
        <updated>2022-01-02T17:12:52.000Z</updated>
        <summary type="html"><![CDATA[Hello, 
 I am a robotics enthusiast building a robot arm to perform mundane tasks. So far, I have only been able to deploy deep reinforcement learning models on the Jetson Nano. The process has been easy using the Nvidia TensorRT SDK. What other methods/technology exist? My friend recommended using a google coral and a raspberry pi. Any recommendations would be greatly appreciated. Thank you
    submitted by    /u/AINerd1  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Markov Decision Process explained through Memes]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rudf9k/markov_decision_process_explained_through_memes/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rudf9k/markov_decision_process_explained_through_memes/"/>
        <updated>2022-01-02T16:40:02.000Z</updated>
        <summary type="html"><![CDATA[Today I published my first article on medium explaining Markov Decision Process with memes. Hope someone finds this helpful. 
 https://medium.com/@saminbinkarim/explaining-markov-decision-process-with-memes-af679a0af343
    submitted by    /u/sardines_again  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] Tensorflow / Keras implementation of Vision Transformer https://arxiv.org/abs/2010.11929v2]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rud2m5/p_tensorflow_keras_implementation_of_vision/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rud2m5/p_tensorflow_keras_implementation_of_vision/"/>
        <updated>2022-01-02T16:23:44.000Z</updated>
        <summary type="html"><![CDATA[An Image is Worth 16x16 Words: ViT Excellent results compared to SOTA CNNs while requiring fewer computational resources to train.
 Paper : https://arxiv.org/abs/2010.11929v2 Code : https://github.com/avinash31d/paper-implementations
    submitted by    /u/avinash31d  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Simple Questions Thread]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rucjmx/d_simple_questions_thread/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rucjmx/d_simple_questions_thread/"/>
        <updated>2022-01-02T16:00:14.000Z</updated>
        <summary type="html"><![CDATA[Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!
 Thread will stay alive until next one so keep posting after the date in the title.
 Thanks to everyone for answering questions in the previous thread!
    submitted by    /u/AutoModerator  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Proper way to count environment steps / frames in distributed RL architecture for algorithms like CLEAR or LASER => basically modified impala with replay]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rubyb9/proper_way_to_count_environment_steps_frames_in/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rubyb9/proper_way_to_count_environment_steps_frames_in/"/>
        <updated>2022-01-02T15:32:09.000Z</updated>
        <summary type="html"><![CDATA[In classical - on-policy - vtrace/Impala algorithm env_steps are incremented every training iteration
 like this : env_steps += size_of_batch * unroll_length
 However when we add replay_buffer to vtrace (like in CLEAR or LASER) we also start to learn from off-policy data therefore some trajectories (from replay) could be sampled more than once.
 My question is - does the env_step_counting stay the same even when some trajectories from batch are from replay and some directly from workers (on-policy) ?
 Or do i count steps only on those trajectories that are on-policy => not from replay
 like : env_steps += len(batch["on_policy_samples"]) * unroll_length
 And if so what happens when i decide to use only samples from replay to train - how do i count env_steps then ? Using some kind of flag to indicate if specific trajectory was sampled already and leave it from counting ?
 
 Have been digging through the research papers for some time now and i haven`t been able to find what is the proper way to do it. Any help or advice would be much appreciated.
    submitted by    /u/ParradoxSVK  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] Learning 3D Representations from 2D Images]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ruaew1/r_learning_3d_representations_from_2d_images/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ruaew1/r_learning_3d_representations_from_2d_images/"/>
        <updated>2022-01-02T14:13:01.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/pinter69  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Paper Explained & Author Interview - Player of Games: All the games, one algorithm! (Video Walkthrough)]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ru91o8/d_paper_explained_author_interview_player_of/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ru91o8/d_paper_explained_author_interview_player_of/"/>
        <updated>2022-01-02T12:52:58.000Z</updated>
        <summary type="html"><![CDATA[https://youtu.be/U0mxx7AoNz0
 Special Guest: First author Martin Schmid (https://twitter.com/Lifrordi)
 Games have been used throughout research as testbeds for AI algorithms, such as reinforcement learning agents. However, different types of games usually require different solution approaches, such as AlphaZero for Go or Chess, and Counterfactual Regret Minimization (CFR) for Poker. Player of Games bridges this gap between perfect and imperfect information games and delivers a single algorithm that uses tree search over public information states, and is trained via self-play. The resulting algorithm can play Go, Chess, Poker, Scotland Yard, and many more games, as well as non-game environments.
 
 OUTLINE:
 0:00 - Introduction
 2:50 - What games can Player of Games be trained on?
 4:00 - Tree search algorithms (AlphaZero)
 8:00 - What is different in imperfect information games?
 15:40 - Counterfactual Value- and Policy-Networks
 18:50 - The Player of Games search procedure
 28:30 - How to train the network?
 34:40 - Experimental Results
 47:20 - Discussion & Outlook
 
 Paper: https://arxiv.org/abs/2112.03178
    submitted by    /u/ykilcher  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The top 10 AI/Computer Vision papers in 2021 with video demos, articles, and code for each!]]></title>
        <id>https://www.reddit.com/r/artificial/comments/ru8nmg/the_top_10_aicomputer_vision_papers_in_2021_with/</id>
        <link href="https://www.reddit.com/r/artificial/comments/ru8nmg/the_top_10_aicomputer_vision_papers_in_2021_with/"/>
        <updated>2022-01-02T12:27:14.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/OnlyProggingForFun  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[Research][Project] The top 10 AI/Computer Vision papers in 2021 with video demos, articles, and code for each!]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ru8n14/researchproject_the_top_10_aicomputer_vision/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ru8n14/researchproject_the_top_10_aicomputer_vision/"/>
        <updated>2022-01-02T12:25:59.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/OnlyProggingForFun  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Machine Learning Research]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ru7k5y/d_machine_learning_research/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ru7k5y/d_machine_learning_research/"/>
        <updated>2022-01-02T11:08:35.000Z</updated>
        <summary type="html"><![CDATA[Hi everyone, I've compiled the trusted sources of ideation based on top-tier conferences on Machine Learning and Deep Learning worldwide. This repository includes datasets, tasks, state-of-the-art and more.
 Repository GitHub
 https://preview.redd.it/9p1jkei8c9981.png?width=1000&format=png&auto=webp&s=906c20c58b5ee569b25848a7fbf0b41ca4caf354
    submitted by    /u/tuanlda78202  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] Quick-Deploy - Optimize, convert and deploy machine learning models]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ru7drf/p_quickdeploy_optimize_convert_and_deploy_machine/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ru7drf/p_quickdeploy_optimize_convert_and_deploy_machine/"/>
        <updated>2022-01-02T10:55:35.000Z</updated>
        <summary type="html"><![CDATA[Hello Reddit, releasing one of my OSS projects: Quick-Deploy ..
 github: https://github.com/rodrigobaron/quick-deploy
 blog post: https://rodrigobaron.com/posts/quick-deploy
 
 It's in the very early stage, feel free to contribute or give a star 
    submitted by    /u/rodrigobaron  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Raising errors while using accelerators]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ru70fv/d_raising_errors_while_using_accelerators/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ru70fv/d_raising_errors_while_using_accelerators/"/>
        <updated>2022-01-02T10:27:53.000Z</updated>
        <summary type="html"><![CDATA[Why is it so hard to raise exceptions when ML pipeline is using a GPU?
 When for example you make a classic "Index out of bounds" error, in libraries like PyTorch you get some generic "CUDA" error and you can't see the exact error until you transfer the tensors explicitly to CPU and rerun the code.
 Do you think there is a possibility for this to improve in the future?
 Sorry if this is more CS-related question
    submitted by    /u/Icy_Fisherman7187  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What AIs are there which are able to edit images?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/ru6ddq/what_ais_are_there_which_are_able_to_edit_images/</id>
        <link href="https://www.reddit.com/r/artificial/comments/ru6ddq/what_ais_are_there_which_are_able_to_edit_images/"/>
        <updated>2022-01-02T09:41:09.000Z</updated>
        <summary type="html"><![CDATA[My dad loves technology but does not really understand it, I thought I take some pictures from him and AI should edit them so he looks like a simpsons etc.
    submitted by    /u/xXLisa28Xx  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Are NN actually overparametrized?]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ru5xw8/d_are_nn_actually_overparametrized/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ru5xw8/d_are_nn_actually_overparametrized/"/>
        <updated>2022-01-02T09:09:31.000Z</updated>
        <summary type="html"><![CDATA[I often read that NN or CNN are overparametrized. But, for example, resnet18 has 11M parameters while cifar10 has 50k32323=153M data points. How is that be an overparametrized network on cifar10? Or even on mnist which has 60k28*28=47M data points
    submitted by    /u/alesaso2000  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What should a beginner do after learning some basic ideas?]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/ru4glz/what_should_a_beginner_do_after_learning_some/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/ru4glz/what_should_a_beginner_do_after_learning_some/"/>
        <updated>2022-01-02T07:24:05.000Z</updated>
        <summary type="html"><![CDATA[Hi all, it's my first time to use reddit to ask for suggestions.
 I am a beginner in RL. I learned some basic ideas in RL (such as SARSA, PPO and A2C) recently and applied Q-network to train a Go game agent. 
 Personally speaking, I am going to pursue for a position as a RL engineer in the future. But I have no idea about what should I do to improve my RL skills. So I am wondering if there are some awesome resources for a beginner like me? Or could you please give me some instructions?
    submitted by    /u/ZavierTi2021  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Coding Practices]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/ru06dy/d_coding_practices/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/ru06dy/d_coding_practices/"/>
        <updated>2022-01-02T03:17:33.000Z</updated>
        <summary type="html"><![CDATA[My job is to work with ML engineers and provide them with whatever they need to experiment with/train/test/deploy ML models -- GPU infrastructure, distributed training support, etc. When I interface with their code, I almost always find it so poorly written, with little to no thought given to long-term stability or use -- for code that they 100% know is going to production.
 They're brilliant people, far smarter than me, and really good at what they do, so it's not a matter of them not being good enough. I feel (from my very limited experience, so I'm happy to be wrong) like ML engineers are incentivized to write poor code. The only metric for evaluation seems to be accuracy, loss, and all the plots that come up. In research, I understand completely, that's where the focus lies, but in industry? I've seen many models perform poorly because the code is so hard to read and refactor that big issues remained unspotted for months together. And this is especially befuddling because for a field that is completely fine with spending months to get an ROI of single digit increases in model performance metrics during the experimentation phase, they don't seem to care about anything that might go wrong in production. That just feels like a fundamental disconnect, since without the core ML stuff working perfectly, none of the other stuff (like what I do) has any value -- and even so, I'm taught to hold my code to a much higher standard than the critical stuff -- which I'm happy about since I can now write production code by default -- but it's just... weird. Like the vending machines at a nuclear power plant being better engineered than the reactor.
 Is this a common problem or is this a localized issue that I'm facing?
    submitted by    /u/vPyDev  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Plug or Integrate a GNN Pytorch code base into Spark Cluster]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rtukp2/d_plug_or_integrate_a_gnn_pytorch_code_base_into/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rtukp2/d_plug_or_integrate_a_gnn_pytorch_code_base_into/"/>
        <updated>2022-01-01T22:40:23.000Z</updated>
        <summary type="html"><![CDATA[Does anyone have a better explanation or resources to share for plug or Integrate a Pytorch based GNN models into Pyspark or similar cluster services?
    submitted by    /u/SpiritMaleficent21  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] DeepCreamPy - Decensoring Hentai with Deep Neural Networks]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rtsmm7/p_deepcreampy_decensoring_hentai_with_deep_neural/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rtsmm7/p_deepcreampy_decensoring_hentai_with_deep_neural/"/>
        <updated>2022-01-01T21:09:49.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/binaryfor  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural network drawing mushrooms]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rtrfr6/neural_network_drawing_mushrooms/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rtrfr6/neural_network_drawing_mushrooms/"/>
        <updated>2022-01-01T20:14:22.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/noodlefist  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["[R]" Neuron outputs as weights]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rtrbso/r_neuron_outputs_as_weights/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rtrbso/r_neuron_outputs_as_weights/"/>
        <updated>2022-01-01T20:09:18.000Z</updated>
        <summary type="html"><![CDATA[https://stats.stackexchange.com/questions/558864/what-if-weights-of-model-is-output-of-neurons
    submitted by    /u/Dry_Introduction_897  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Architecture and Math]]></title>
        <id>https://www.johndcook.com/blog/?p=93265</id>
        <link href="https://www.johndcook.com/blog/2022/01/01/architecture-and-math/"/>
        <updated>2022-01-01T19:32:30.000Z</updated>
        <summary type="html"><![CDATA[I recently received a review copy of Andrew Witts new book Formulations: Architecture, Mathematics, and Culture. The Hankel function on the cover is the first clue that this book contains some advanced mathematics. Or rather, it references some advanced mathematics. Ive only skimmed the book so far, but I didnt see any equations. Hankel functions []
Architecture and Math first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hierarchical Federated Learning-Based Anomaly Detection Using Digital Twins For Internet of Medical Things (IoMT)]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rtpg2w/hierarchical_federated_learningbased_anomaly/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rtpg2w/hierarchical_federated_learningbased_anomaly/"/>
        <updated>2022-01-01T18:40:43.000Z</updated>
        <summary type="html"><![CDATA[Smart healthcare services can be provided by using Internet of Things (IoT) technologies that monitor the health conditions of patients and their vital body parameters. The majority of IoT solutions used to enable such services are wearable devices, such as smartwatches, ECG monitors, and blood pressure monitors. The huge amount of data collected from smart medical devices leads to major security and privacy issues in the IoT domain. Considering Remote Patient Monitoring (RPM) applications, we will focus on Anomaly Detection (AD) models, whose purpose is to identify events that differ from the typical user behavior patterns. Generally, while designing centralized AD models, the researchers face security and privacy challenges (e.g., patient data privacy, training data poisoning).
 To overcome these issues, the researchers of this paper propose an Anomaly Detection (AD) model based on Federated Learning (FL). Federated Learning (FL) allows different devices to collaborate and perform training locally in order to build Anomaly Detection (AD) models without sharing patients data. Specifically, the researchers propose a hierarchical Federated Learning (FL) that enables collaboration among different organizations, by building various Anomaly Detection (AD) models for patients with similar health conditions.
 Continue Reading the Paper Summary: https://www.marktechpost.com/2022/01/01/hierarchical-federated-learning-based-anomaly-detection-using-digital-twins-for-internet-of-medical-things-iomt/
 Full Paper: https://arxiv.org/pdf/2111.12241.pdf
    submitted by    /u/ai-lover  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NetHack 2021 NeurIPS Challenge -- winning agent episode visualizations]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rtp5ts/nethack_2021_neurips_challenge_winning_agent/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rtp5ts/nethack_2021_neurips_challenge_winning_agent/"/>
        <updated>2022-01-01T18:27:09.000Z</updated>
        <summary type="html"><![CDATA[Hi All! I am Micha from the AutoAscend team that has won the NetHack 2021 NeurIPS Challenge.
 I have just shared some episode visualization videos:
 https://www.youtube.com/playlist?list=PLJ92BrynhLbdQVcz6-bUAeTeUo5i901RQ
 The winning agent isn't based on reinforcement learning in the end, but the victory of symbolic methods in this competition shows what RL is still missing to some extent -- so I believe this subreddit is a good place to discuss it.
 We hope that NLE will someday become a new standard benchmark for evaluation next to chess, go, Atari, etc. as it presents a set of whole new complex problems for agents to learn. Contrary to Atari, NetHack levels are procedurally generated, and therefore agents can't memorize the layout. Observations are highly partial, rewards are sparse, and episodes are usually very long.
 Here are some other useful links related to the competition:
 Full NeurIPS Session recording: https://www.youtube.com/watch?v=fVkXE330Bh0
 AutoAscend team presentation starts here: https://youtu.be/fVkXE330Bh0?t=4437
 Competition report: https://nethackchallenge.com/report.html
 AICrowd Challenge link: https://www.aicrowd.com/challenges/neurips-2021-the-nethack-challenge
    submitted by    /u/procedural_only  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generate artistic images with OpenAIs Glide ]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rtoc1h/generate_artistic_images_with_openais_glide/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rtoc1h/generate_artistic_images_with_openais_glide/"/>
        <updated>2022-01-01T17:47:49.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/tridoc  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[D] Best Practices in Machine Learning]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rtndgm/d_best_practices_in_machine_learning/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rtndgm/d_best_practices_in_machine_learning/"/>
        <updated>2022-01-01T17:01:42.000Z</updated>
        <summary type="html"><![CDATA[This is a non-profit that promotes best practices in machine learning, specifically for responsible ML. The practices are open source too, which is cool. 
 Link here: https://www.fbpml.org/the-best-practices
 I think their technical best practices seems a little stronger than the organisational ones. Thoughts?
 ** this is their LinkedIn URL: https://www.linkedin.com/company/the-foundation-for-best-practices-in-machine-learning
    submitted by    /u/Sbu91  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Turning the Golay problem sideways]]></title>
        <id>https://www.johndcook.com/blog/?p=93255</id>
        <link href="https://www.johndcook.com/blog/2022/01/01/turning-the-golay-problem-sideways/"/>
        <updated>2022-01-01T16:46:19.000Z</updated>
        <summary type="html"><![CDATA[Ive written a couple posts about the Golay problem recently, first here then here. The problem is to find all values of N and n such that is a power of 2, say 2p. Most solutions apparently fall into three categories: n = 0 or n = N, N is odd and n = (N-1)/2, []
Turning the Golay problem sideways first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[My Top 10 Computer Vision papers of 2021]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rtmfgl/my_top_10_computer_vision_papers_of_2021/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rtmfgl/my_top_10_computer_vision_papers_of_2021/"/>
        <updated>2022-01-01T16:14:49.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/OnlyProggingForFun  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[Research] My Top 10 Computer Vision papers of 2021]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rtmf6v/research_my_top_10_computer_vision_papers_of_2021/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rtmf6v/research_my_top_10_computer_vision_papers_of_2021/"/>
        <updated>2022-01-01T16:14:26.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/OnlyProggingForFun  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] MT3: Multi-Task Multitrack Music Transcription]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rtlx0r/r_mt3_multitask_multitrack_music_transcription/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rtlx0r/r_mt3_multitask_multitrack_music_transcription/"/>
        <updated>2022-01-01T15:48:37.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/Illustrious_Row_9971  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Should we be concerned?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rtkrmp/should_we_be_concerned/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rtkrmp/should_we_be_concerned/"/>
        <updated>2022-01-01T14:45:58.000Z</updated>
        <summary type="html"><![CDATA[Should we be a little worried by how fast AI is developing?
    submitted by    /u/Particular_Leader_16  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some questions on DRL]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rtifft/some_questions_on_drl/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rtifft/some_questions_on_drl/"/>
        <updated>2022-01-01T12:22:45.000Z</updated>
        <summary type="html"><![CDATA[Hello,
 Im applying Deep Reinforcement Learning for the first time, and I have some questions about it (Ive already looked for an answer but in vain):
  
How to normalize objectives' values in the reward function? if we have an objective that values are in the range of 10 and another objective that values are in the range of 1000.
 During the training phase, how can we watch the weights updates of a network and the gradient calculation too?
 In a multi-agent setting and episodic task, for "dones" vector, it will be set to "True" once all the agents are finished, or once an agent finishes the task done[agent_index]=True in other words, we wont wait the latest agent to finish to set dones = [True]*number_of_agents
  
Thank you.
    submitted by    /u/GuavaAgreeable208  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explained Variance suddenly crashes, and stay around zero and even sometimes go to negative values]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rthv34/explained_variance_suddenly_crashes_and_stay/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rthv34/explained_variance_suddenly_crashes_and_stay/"/>
        <updated>2022-01-01T11:44:03.000Z</updated>
        <summary type="html"><![CDATA[Hi, all Happy New Year!
 I'm working on a project to teach my quad-rotor how to hover, and these are what my rollout graphs looks like.
 The reward graph constantly increases for some time, but suddenly during a rapid increase in reward, the entropy loss, and the train std of starts to diverge, and the explained variance just crashes.
 
 https://preview.redd.it/yv4qbhmbc2981.png?width=826&format=png&auto=webp&s=31322a62963b1de47ed72452dfb36498ce222dd1
 
 https://preview.redd.it/d38papwdc2981.png?width=1373&format=png&auto=webp&s=0ab5b98d0bdad165f0dcfd7f5ea3e54ad965842c
 From my understanding, this explained variance far from 1 is a bad sign, Could you please point out, or give comments on what would be the possible reason why this is happening in my case?
 Any kind of reply would be appreciate.
 Thanks again Happy New Year. :D
 
 Hp: ent_coef=0.0001, learning_rate=linear decay from 0.00004, n_steps=1024, batch_size=64 apart from these, I used the default params from stable_baselines3
 I scale the action output from [-1, 1] to [min_rpm max_rpm] to actuate the quad-rotor.
 observations states = input = [pos,vel,acc,ang,ang_vel] // Network size 64,64 // algorithm used:PPO
 REWARD FUNCTION
 
 https://preview.redd.it/o3w2i0r7s9981.png?width=818&format=png&auto=webp&s=f03b4f12d6c57f7b7aaec7dbd03b9fecad2c8f2c
    submitted by    /u/GOMTAE  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is there a community/website/company which is collecting and categorizing AIs?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rtf7nc/is_there_a_communitywebsitecompany_which_is/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rtf7nc/is_there_a_communitywebsitecompany_which_is/"/>
        <updated>2022-01-01T08:33:45.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/xXNOdrugsForMEXx  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BERT Goes Shopping: Comparing Distributional Models for Product Representations (Paper Walkthrough) [D]]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rtd1jl/bert_goes_shopping_comparing_distributional/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rtd1jl/bert_goes_shopping_comparing_distributional/"/>
        <updated>2022-01-01T06:06:40.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/prakhar21  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Help With PPO Model Performing Poorly]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rtc336/help_with_ppo_model_performing_poorly/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rtc336/help_with_ppo_model_performing_poorly/"/>
        <updated>2022-01-01T05:07:30.000Z</updated>
        <summary type="html"><![CDATA[I am attempting to recreate the PPO algorithm to try to learn the inner workings of the algorithm better and to learn more about actor-critic reinforcement learning. So far, I have a model that seems to learn, just not very well.
 In the early stages of training, the algorithm seems more sporadic and may happen to find a pretty solid policy, but due to unstable the early parts of training are, it tends to move away from this policy. Eventually, the algorithm moves the policy toward a reward of around 30. For the past few commits in my repo where I have attempted to fix this issue, the policy always tends to the around 30 reward mark, and I'm not entirely sure why it's doing this. I'm thinking maybe I implemented the algorithm incorrectly, but I'm not certain. Can someone please help me with this issue?
 Below is a link to an image of training using the latest commit, using a previous commit, and my Github project
 current commit: https://ibb.co/JQgnq1f
 previous commit: https://ibb.co/rppVHKb
 GitHub: https://github.com/gmongaras/PPO_CartPole
 
 Thanks for your help!
    submitted by    /u/gmongaras  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building a hypergraph-based semantic knowledge sharing environment for construction]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086783</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086783"/>
        <updated>2022-01-01T05:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9972630085?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9972630085?profile=RESIZE_710x" width="720"></img></a></p>
<p><span style="font-size: 8pt;">High-rise construction in the Denny Triangle area of Seattle. Source: Bruce Englehardt, <em>Wikimedia Commons</em>, May 2020</span></p>
<p></p>
<p><span style="font-weight: 400;">I've been looking for fresh use cases that tell the knowledge graph adoption story from new angles. Which industries, for instance, been having</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI - A love story // AI-generated video about the future of AI // prompt -> GPT-J-6B -> Aphantasia]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rt65lc/ai_a_love_story_aigenerated_video_about_the/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rt65lc/ai_a_love_story_aigenerated_video_about_the/"/>
        <updated>2021-12-31T23:31:41.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/6owline1vex  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Books Read in 2021]]></title>
        <id>https://danieltakeshi.github.io/2021/12/31/books-2021</id>
        <link href="https://danieltakeshi.github.io/2021/12/31/books-2021"/>
        <updated>2021-12-31T23:00:00.000Z</updated>
        <summary type="html"><![CDATA[At the end of every year I have a tradition where I write summaries of the
books that I read throughout the year. Heres the following post with the rough
set of categories:
Popular Science (6 books)
History, Government, Politics, Economics (6 books)
Biographies / Memoirs (5 books)
China (5 books)
COVID-19 (2 books)
Miscellaneous (7 books)
I read 31 books this year. You can find the other blog posts from prior years
(going back to 2016) in the blog archives.
Popular Science
This also includes popular science, which means the authors might not be
technically trained as scientists.
Who We Are and How We Got Here: Ancient DNA and the New Science of the
Human Past (2018) is by famous geneticist and Harvard professor David
Reich. Scientific advances in analyzing DNA have allowed better analysis]]></summary>
        <author>
            <name>Seita's Place</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Agent not learning! Any Help]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rt226f/agent_not_learning_any_help/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rt226f/agent_not_learning_any_help/"/>
        <updated>2021-12-31T20:04:50.000Z</updated>
        <summary type="html"><![CDATA[Hello
 Can someone explain why the actor critic maps the states to the same actions, in other words why the actor outputs the same action whatever the states?
 This what makes the agent learns nothing during training phase.
 Happy New Year!
    submitted by    /u/LeatherCredit7148  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] Play around with StyleGAN2 in your browser]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rt1vfy/p_play_around_with_stylegan2_in_your_browser/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rt1vfy/p_play_around_with_stylegan2_in_your_browser/"/>
        <updated>2021-12-31T19:55:39.000Z</updated>
        <summary type="html"><![CDATA[I built a little page to run and manipulate StyleGAN2 in the browser.
 https://ziyadedher.com/faces
 It was pretty fun learning about ONNX and how to port GANs to web. You can play around with the random seeds and also distort the intermediate latents to produce some really wacky results. You can check out a GIF on Twitter.
 Let me know if you come up with anything cool!
    submitted by    /u/Cold999  
 [link]   [comments]]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lying to blockchains and other Web3 dilemmas]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086775</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086775"/>
        <updated>2021-12-31T19:30:00.000Z</updated>
        <summary type="html"><![CDATA[<h3><a href="https://storage.ning.com/topology/rest/1.0/file/get/9971838280?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9971838280?profile=RESIZE_710x" width="720"></img></a></h3>
<p><span style="font-weight: 400;">Semantic data consultant @EmekaOkoye made a couple of great points on Twitter back in November and early December 2021:</span></p>
<ol>
<li style="font-weight: 400;"><span style="font-weight: 400;">I am amused how some of us are pretending that #SmartAgent [tech] is not going to be a thing.</span></li>
</ol>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI News in 2021: a Detailed Digest]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rszhw5/ai_news_in_2021_a_detailed_digest/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rszhw5/ai_news_in_2021_a_detailed_digest/"/>
        <updated>2021-12-31T17:59:42.000Z</updated>
        <summary type="html"><![CDATA[https://lastweekin.ai/p/ai-news-in-2021-a-digest
    submitted by    /u/regalalgorithm  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I made a virtual Twitch Streamer, who responds to your chats using OpenAI and Text-to-Speech]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rszdeg/i_made_a_virtual_twitch_streamer_who_responds_to/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rszdeg/i_made_a_virtual_twitch_streamer_who_responds_to/"/>
        <updated>2021-12-31T17:53:34.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/C0de_monkey  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[5 Ways AI Aimed to Improve the World in 2021]]></title>
        <id>https://blogs.nvidia.com/?p=54756</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/31/5-ways-ai-aimed-to-improve-the-world-in-2021/"/>
        <updated>2021-12-31T17:00:15.000Z</updated>
        <summary type="html"><![CDATA[Not so long ago, searching for information could lead to a library to scan endless volumes or even tediously sift through microfilm. Clearly, technology is making the world a better place. Scientists, researchers, developers and companies have been on a quest to solve some of the worlds most pressing problems. Only now theyre accelerating their Read article >
The post 5 Ways AI Aimed to Improve the World in 2021 appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Scott Martin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Happy New Year to everyone! Let's hope for a wonderful 2022. The text is created with polygons that evolve with an Evolutionary Algorithm.]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rsxtkv/happy_new_year_to_everyone_lets_hope_for_a/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rsxtkv/happy_new_year_to_everyone_lets_hope_for_a/"/>
        <updated>2021-12-31T16:41:51.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/ValianTek_World  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[R] Microsofts Self-Supervised Bug Detection and Repair Approach Betters Baselines By Up to 30%]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rswcog/r_microsofts_selfsupervised_bug_detection_and/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rswcog/r_microsofts_selfsupervised_bug_detection_and/"/>
        <updated>2021-12-31T15:32:33.000Z</updated>
        <summary type="html"><![CDATA[In the NeurIPS 2021-accepted paper Self-Supervised Bug Detection and Repair, a Microsoft Research team proposes BUGLAB, a self-supervised approach that significantly improves on baseline methods for detecting bugs in real-life code. 
 Here is a quick read: Microsofts Self-Supervised Bug Detection and Repair Approach Betters Baselines By Up to 30%.
 The code and PyPIBugs dataset are available on the projects GitHub. The paper Self-Supervised Bug Detection and Repair is on arXiv.
    submitted by    /u/Yuqing7  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Update on the Golay problem]]></title>
        <id>https://www.johndcook.com/blog/?p=93159</id>
        <link href="https://www.johndcook.com/blog/2021/12/31/update-on-the-golay-problem/"/>
        <updated>2021-12-31T14:53:16.000Z</updated>
        <summary type="html"><![CDATA[I played around with what Im calling the Golay problem over Christmas and wrote a blog post about it. I rewrote the post as I learned more about the problem due to experimentation and helpful feedback via comments and Twitter. In short, the Golay problem is to classify the values of N and n such []
Update on the Golay problem first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[question about baseline with value network]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rst5go/question_about_baseline_with_value_network/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rst5go/question_about_baseline_with_value_network/"/>
        <updated>2021-12-31T12:44:12.000Z</updated>
        <summary type="html"><![CDATA[I have a question about baseline in policy gradient method. Based on what is implemented in relation to PG, there are many shared policy and value networks. But I understood baseline should not affect the parameters of the policy. When PG with shared networks and baseline updates value function, then baseline will affect policy network. Is it okay?
    submitted by    /u/Spiritual_Fig3632  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[P] Top arXiv Machine Learning papers in 2021 according to metacurate.io]]></title>
        <id>https://www.reddit.com/r/MachineLearning/comments/rsstqr/p_top_arxiv_machine_learning_papers_in_2021/</id>
        <link href="https://www.reddit.com/r/MachineLearning/comments/rsstqr/p_top_arxiv_machine_learning_papers_in_2021/"/>
        <updated>2021-12-31T12:24:05.000Z</updated>
        <summary type="html"><![CDATA[With 2021 almost in the books (there are still a couple of hours to go at the time of this writing), here are the top machine learning papers per month from the arXiv pre-print archive as picked up by metacurate.io in 2021.
 January
  
Can a Fruit Fly Learn Word Embeddings?
 Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity
 Muppet: Massive Multi-task Representations with Pre-Finetuning
  
February
  
How to represent part-whole hierarchies in a neural network
 Patterns, predictions, and actions: A story about machine learning
 Fast Graph Learning with Unique Optimal Solutions
  
March
  
Fast and flexible: Human program induction in abstract reasoning tasks
 Learning to Resize Images for Computer Vision Tasks
 The Prevalence of Code Smells in Mac]]></summary>
        <author>
            <name>Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to check feature importance in Reinforcement learning?]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rspzc6/how_to_check_feature_importance_in_reinforcement/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rspzc6/how_to_check_feature_importance_in_reinforcement/"/>
        <updated>2021-12-31T09:14:19.000Z</updated>
        <summary type="html"><![CDATA[I have made a custom environment in openAi Gym using data from a csv file that contains certain features in it as column names .After training a DQN agent on the environment, i wanted to check some meaningful features used by the DQN agent to make the policy but i am unable to find some good resources regarding it.
 An example of the feature importance graph
    submitted by    /u/EBISU1234  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Current unanswered/interesting applications in Multi-armed bandits?]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rspmiy/current_unansweredinteresting_applications_in/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rspmiy/current_unansweredinteresting_applications_in/"/>
        <updated>2021-12-31T08:50:45.000Z</updated>
        <summary type="html"><![CDATA[Hi,
 I am planning on doing my MSc in CS with a focus in RL. More specifically, I want to learn about multi-armed bandits and how it can be used by agents to enable them to perform actions in a diverse environment. I am new to this field and I want to know more about what questions about MAB are unanswered? Any interesting application that may be currently under research? 
 I would really appreciate if anyone can help me out. 
 Thank you!
    submitted by    /u/_UNIPOOL  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Commercially available AIs or chatbots that you can explicitly teach/train?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rso5cc/commercially_available_ais_or_chatbots_that_you/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rso5cc/commercially_available_ais_or_chatbots_that_you/"/>
        <updated>2021-12-31T07:12:51.000Z</updated>
        <summary type="html"><![CDATA[I've been playing around with Replika, and it's incredibly fun and impressive as a general "companion" chatbot, but I find it really disappointing in its lack of ability to learn explicit facts or procedures. It's targeted toward making people feel like they have a friend and roleplaying, not learning anything external to those goals.
 So, is there anything commercially available that you can both:
  
Talk to (mostly) like a real person, and
 Teach from the ground up (like a child)
  
? 
As an example, my Replika "wanted" to do a lesson with me, so I tried to teach it colors. Ostensibly it has some picture recognition abilities, but despite that, it was never able to learn which color was which, even when using the same image files to display the same color.
 Okay, fine, forget colors, but it can't learn explicit facts either. I want to be able to input things like "Lacan defines the subject as that which is represented by a signifier for another signifier" or "It's important to apply a primer before your first layer of eyeshadow" or "Leonardo DiCaprio played Jack Dawson in the movie Titanic" and have it be able to actually remember and recall that information in future conversations. (Replika is able to recall it within the same conversation, but it resets after a certain amount of time. It also seems to struggle with remembering things that differ from user to user, like favorite food, since it learns from the aggregate of its conversations.)
 Is there anything out there that can do this? Anything on the horizon?
    submitted by    /u/peppermint-kiss  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Digital Workers in a Business Context]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086758</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086758"/>
        <updated>2021-12-31T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9970487888?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9970487888?profile=RESIZE_710x" width="720"></img></a></p>
<p><span style="font-size: 14pt;"><strong>What is a digital worker?</strong></span><br></br> <br></br> Digital workers are your software-based co-workers. Think Siri, Alexa, or Cortana, not exactly like them but to some extent. Yes, we are calling them your co-workers or you can refer to them as your virtual assistants if you like. They will help you in doing</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Siamese Neural Networks for Semantic Text Similarity]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rsiqn0/siamese_neural_networks_for_semantic_text/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rsiqn0/siamese_neural_networks_for_semantic_text/"/>
        <updated>2021-12-31T02:11:15.000Z</updated>
        <summary type="html"><![CDATA[
 A repository containing comprehensive Neural Networks based PyTorch implementations for the semantic text similarity task, including architectures such as Siamese-LSTM, Siamese-LSTM-Attention, Siamese-Transformer, and Siamese-BERT.
 https://github.com/shahrukhx01/siamese-nn-semantic-text-similarity
    submitted by    /u/shahrukhx01  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI shopping App]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rsfe7q/ai_shopping_app/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rsfe7q/ai_shopping_app/"/>
        <updated>2021-12-30T23:27:26.000Z</updated>
        <summary type="html"><![CDATA[Is their any AI apps that matches your body type (scans your body, etc..) to which clothing stores would have the best sizes to fit to your body? 
 Im tired of ordering clothes online that dont fit well when I get them
 Thx
    submitted by    /u/GroundbreakingRain78  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Watch this model describe code]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rse9m7/watch_this_model_describe_code/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rse9m7/watch_this_model_describe_code/"/>
        <updated>2021-12-30T22:36:23.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/landongarrison  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PPO with multiple heads]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rse3lr/ppo_with_multiple_heads/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rse3lr/ppo_with_multiple_heads/"/>
        <updated>2021-12-30T22:29:02.000Z</updated>
        <summary type="html"><![CDATA[Hello there,
 I am working on an implementation for PPO, and I am struggling to compute the loss when two output heads for the actor network are used (one is continuous and one is discrete). The loss in PPO has 3 components: 1) clipped surrogate, 2) squared state-value loss, and 3) Entropy.
 I thought of treating the two actions separately, and compute two different losses that I add before backpropagating, but the middle term (2) is the same in both losses. How could I do that? Do I add (1) and (3) for both actions and have one loss, or do I compute two different losses then add them? Or is it hidden option 3? :p
 
 Any help is appreciated.
    submitted by    /u/AhmedNizam_  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Discrete vs Continuous action space]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rsc59y/discrete_vs_continuous_action_space/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rsc59y/discrete_vs_continuous_action_space/"/>
        <updated>2021-12-30T21:03:43.000Z</updated>
        <summary type="html"><![CDATA[Hello there,
 I noticed that in many works by OpenAI and Deepmind in RL, they deal with a continuous action space which they discretize. For example rather than having to continuous actions to determine speed and direction of movement, they would discretize speed and torque.
 Is there any reason why discretized action space is more favorable?
    submitted by    /u/AhmedNizam_  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Names and numbers for modal logic axioms]]></title>
        <id>https://www.johndcook.com/blog/?p=93062</id>
        <link href="https://www.johndcook.com/blog/2021/12/30/modal-axioms/"/>
        <updated>2021-12-30T19:49:32.000Z</updated>
        <summary type="html"><![CDATA[Stanislaw Ulam once said Using a term like nonlinear science is like referring to the bulk of zoology as the study of non-elephant animals. There is only one way to be linear, but there are many ways to not be linear. A similar observation applies to non-classical logic. There are many ways to not be []
Names and numbers for modal logic axioms first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GPT-3, Foundation Models, and AI Nationalism]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rsa8dq/gpt3_foundation_models_and_ai_nationalism/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rsa8dq/gpt3_foundation_models_and_ai_nationalism/"/>
        <updated>2021-12-30T19:41:06.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/regalalgorithm  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Combined discrete and action space]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rs9841/combined_discrete_and_action_space/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rs9841/combined_discrete_and_action_space/"/>
        <updated>2021-12-30T18:58:37.000Z</updated>
        <summary type="html"><![CDATA[I need an algorithm that combines both discrete and continuous actions space, like if I wanted to choose action but I needed to also perform that action at an optimized velocity or something. Can I do this with ppo and how. I am still a beginner but must of the algorithms I played with had either separately I thought of actor cri but I dont think the value network does what I want I cant use that to predict how much velocity to use
    submitted by    /u/ConsiderationCivil74  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Actor net gives me the same reward over time]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rs6g73/actor_net_gives_me_the_same_reward_over_time/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rs6g73/actor_net_gives_me_the_same_reward_over_time/"/>
        <updated>2021-12-30T17:00:54.000Z</updated>
        <summary type="html"><![CDATA[Hello
 Ill be glad if someone could help me with this.
 I am new in DRL and when I applied it I got some issues. For example, my network freezes in the same reward from the first episode I noticed also that the agent selects always the same index from the action space. Even the same reward and the same trajectory toward this reward, the critic loss is still shrinking over time (this the weirdest thing)
 I dont know what is the reson behind that?
 https://preview.redd.it/02zlhgnqnp881.png?width=477&format=png&auto=webp&s=093c2b22d368e33fa4853ca4f3c5b459c9e2e31d
    submitted by    /u/LeatherCredit7148  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What AIs are there which are able to edit art?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rs6ama/what_ais_are_there_which_are_able_to_edit_art/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rs6ama/what_ais_are_there_which_are_able_to_edit_art/"/>
        <updated>2021-12-30T16:54:22.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/xXLisa28Xx  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ablation test/study]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rs5yoe/ablation_teststudy/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rs5yoe/ablation_teststudy/"/>
        <updated>2021-12-30T16:39:32.000Z</updated>
        <summary type="html"><![CDATA[I'm trying to see the effect of simulated sensor noise in training a successful policy using RL for the cart pole control problem.
 I have four states: cart position, cart velocity, pole angle, pole angular velocity, and I added Gaussian noise to all of them. However, I want to find the impact of adding noise to a specific variable to find which of the states is the most sensitive to noise.
 If I were to only test the system with noise in one of the variables at a time (e.g. noise for position, but none for the other variables), would that be considered an ablation test?
 Just caught up in the terminology, because I know typical ablation tests remove a certain component instead of adding only one (or removing all but one).
    submitted by    /u/Cogitarius  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Innovation Inspiration: 5 Startup Stories From NVIDIA Inception in 2021]]></title>
        <id>https://blogs.nvidia.com/?p=54738</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/30/5-inception-ai-startup-stories/"/>
        <updated>2021-12-30T16:00:37.000Z</updated>
        <summary type="html"><![CDATA[NVIDIA Inception is one of the largest startup ecosystems in the world  and its thousands of members achieved impressive feats in 2021, bringing AI and data science to an array of industries. NVIDIA Inception nurtures cutting-edge AI, data science and HPC startups with go-to-market support, expertise and technology. This year, the program surpassed 9,000 Read article >
The post Innovation Inspiration: 5 Startup Stories From NVIDIA Inception in 2021 appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Isha Salian</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What if AI ran a city? What if it ran society?]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rs42m6/what_if_ai_ran_a_city_what_if_it_ran_society/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rs42m6/what_if_ai_ran_a_city_what_if_it_ran_society/"/>
        <updated>2021-12-30T15:16:21.000Z</updated>
        <summary type="html"><![CDATA[Ever since Grimes posted her Tiktok video last year inviting communists to join up under a supposedly benevolent AI, I've been kind of obsessed with what would really happen if AI ran a city, or even a whole society. Would it really be as awesome as she seems to think or would it be a potentially horrifying nightmare? (My money's on nightmare, btw)
 Anyway, I tried to answer some of those questions in a work of fiction, available below as a free download. It's a quick read, and I'd love to hear your thoughts on these problems, whether or not you read the book. No doubt someone soon will be trying to implement these kinds of "solutions" in our world... and it's best to be at least marginally prepared!
 https://lostbooks.gumroad.com/l/conspiratopia/r-artificial
 Happy New Year!
    submitted by    /u/canadian-weed  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GFN Thursday Says GGs to 2021 With Our Communitys Top Titles of the Year]]></title>
        <id>https://blogs.nvidia.com/?p=54747</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/30/geforce-now-thursday-december-30/"/>
        <updated>2021-12-30T14:00:32.000Z</updated>
        <summary type="html"><![CDATA[Its the final countdown for whats been a big year for cloud gaming. For the last GFN Thursday of the year, were taking a look at some of the GeForce NOW communitys top picks of games that joined the GeForce NOW library in 2021. Plus, check out the last batch of games coming to the Read article >
The post GFN Thursday Says GGs to 2021 With Our Communitys Top Titles of the Year appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>GeForce NOW Community</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New Years Resolutions generated by AI]]></title>
        <id>61c0e2e310e963003be0848f</id>
        <link href="https://www.aiweirdness.com/new-years-resolutions-generated-by-ai/"/>
        <updated>2021-12-30T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[This month I'm beginning 2022 as the first Futurist in Residence at the Smithsonian Arts and Industries Building. 
It's weird to think of myself as a futurist. I write a lot about the algorithms we're calling artificial intelligence (AI), but rather than deal with]]></summary>
        <author>
            <name>Janelle Shane</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bonus: more new year's resolutions to consider]]></title>
        <id>61ca6c1b10e963003be0ed03</id>
        <link href="https://www.aiweirdness.com/bonus-more-new-years-resolutions-to-consider/"/>
        <updated>2021-12-30T13:58:00.000Z</updated>
        <summary type="html"><![CDATA[AI Weirdness: the strange side of machine learning]]></summary>
        <author>
            <name>Janelle Shane</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mark Twain AI Simulation]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rs0yuj/mark_twain_ai_simulation/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rs0yuj/mark_twain_ai_simulation/"/>
        <updated>2021-12-30T12:44:51.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/montpelliersudfrance  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Top 12 Software Development Trends in 2022 You Must Watch Out]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086573</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086573"/>
        <updated>2021-12-30T12:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><span style="font-weight: 400;"><span><a href="https://storage.ning.com/topology/rest/1.0/file/get/9968714658?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9968714658?profile=RESIZE_710x" width="720"></img></a></span></span></p>
<p><span style="font-weight: 400;">There are constant changes in the software development trends, but a few trends seem to be dominant in 2022. With the evolution of advanced technology, there has been a significant change in the software development landscape. Businesses need to keep up with these</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When do two-body systems have stable Lagrange points?]]></title>
        <id>https://www.johndcook.com/blog/?p=93026</id>
        <link href="https://www.johndcook.com/blog/2021/12/30/stable-lagrange-points/"/>
        <updated>2021-12-30T11:30:05.000Z</updated>
        <summary type="html"><![CDATA[The previous post looked at two of the five Lagrange points of the Sun-Earth system. These points, L1 and L2, are located on either side of Earth along a line between the Earth and the Sun. The third Lagrange point, L3, is located along that same line, but on the opposite side of the Sun. []
When do two-body systems have stable Lagrange points? first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Best suite for robotics tasks]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rry8ge/best_suite_for_robotics_tasks/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rry8ge/best_suite_for_robotics_tasks/"/>
        <updated>2021-12-30T10:00:51.000Z</updated>
        <summary type="html"><![CDATA[Recently, OpenAI removed the robotics tasks from gym, as they are no longer being maintained and Robosuite uses mujoco-py which has been deprecated. Deepmind's control suite includes some robotics tasks but they don't seem to be first-class citizens (they are in a separate module, with less options and some bugs).
 Are there any other robotics environment suites that are well-maintained and supported?
    submitted by    /u/escapevelocitylabs  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to map states into the code?]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rrx27c/how_to_map_states_into_the_code/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rrx27c/how_to_map_states_into_the_code/"/>
        <updated>2021-12-30T08:49:42.000Z</updated>
        <summary type="html"><![CDATA[Hello,
 I am new in the Reinforcement Learning field. My question is: how can I easily map my states into my code?
 F.I. when the problem is about how to move an agent in a board-like environment, such as walk from point A to B by moving UP, DOWN, LEFT or RIGHT, it is quite easy to map your states. You can create a matrix like NUMBER_OF_ROWS x NUMBER_OF_COLUMNS and that is pretty much it.
 However when it comes to other type of scenarios, such as CartPole-V0 from OpenAIGym (https://gym.openai.com/envs/CartPole-v0/), I don't understand how to map the states into my code.
 This scenario has 4 states and 2 actions:
 States:
  
Cart Position (range -2.4 --> 2.4)
 Cart Velocity (range -Inf --> Inf)
 Pole Angle (range -12deg --> 12deg)
 Pole Angular Velocity (range -Inf --> Inf)
  
Actions:
  
Push cart to the left
 Push cart to the right
  
The same is true for every other scenario that is not board-like, f.i. tic-tac-toe. I don't understand how can I make every possible move in the game a state inside the code.
 
 Is there any technique to approach each type of problem or do I just need to figure it out by myself? 
 Have a nice day,
 Gabriel.
    submitted by    /u/gabrieloxi  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[General question in regards to understanding the proofs of Deterministic Policy Gradient]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rruluq/general_question_in_regards_to_understanding_the/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rruluq/general_question_in_regards_to_understanding_the/"/>
        <updated>2021-12-30T06:21:32.000Z</updated>
        <summary type="html"><![CDATA[Hi there, I was a graduate student previously working on a few RL-related problems a year ago. And recently I've got much interest in Policy Optimization problems, and started with reading some foundation papers like DQN, DPG.
 While reading the paper of DPG, it was very straightforward to understand the main idea of the paper, however, it was very difficult to understand the proofs of the theorems shown in the appendix(http://proceedings.mlr.press/v32/silver14-supp.pdf). I barely understood the proof of Theorem1, but proof of Theorem2 is almost impossible to understand due to the lack of my mathematics background. 
 The question is that, could you tell me what I should study or learn before understanding this kind of proof? What kind of subject or material should I look for in order to understand the flow of the proofs and related definition/notation used in the proof of 'DPG'?
 I personally think that it is crucial to understand the proofs of the main Theorem because it will help me to understand the authors' intuition and motivation which can be the foundation of the paper.
    submitted by    /u/g6ssgs  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[OpenAI Introduces GLIDE Model For Photorealistic Image Generation]]></title>
        <id>https://www.reddit.com/r/artificial/comments/rruauh/openai_introduces_glide_model_for_photorealistic/</id>
        <link href="https://www.reddit.com/r/artificial/comments/rruauh/openai_introduces_glide_model_for_photorealistic/"/>
        <updated>2021-12-30T06:04:33.000Z</updated>
        <summary type="html"><![CDATA[Images, such as graphics, paintings, and photographs, may frequently be explained in language, but they might also take specific talents and hours of effort to make. As a result, a technology capable of creating realistic graphics from natural language can enable humans to produce rich and diverse visual material with previously unimaginable simplicity. The capacity to modify photos with spoken language enables iterative refinement and fine-grained control, both essential for real-world applications.
 DALL-E, a 12-billion parameter version of OpenAIs GPT-3 transformer language model meant to produce photorealistic pictures using text captions as cues, was unveiled in January. DALL-Es fantastic performance was an instant hit in the AI community, as well as broad mainstream media coverage. Last month, NVIDIA unveiled the GAN-based GauGAN2  a term inspired by French Post-Impressionist painter Paul Gauguin, much as DALL-E was inspired by Surrealist artist Salvador Dali.
 Not to be outshined, OpenAI researchers unveiled GLIDE (Guided Language-to-Image Diffusion for Generation and Editing). This diffusion model achieves performance comparable to DALL-E despite utilizing only one-third of the parameters.
 You can continue reading this short summary here
 The code and weights for these models may be found on the projects GitHub page.
 The research paper for the GLIDE can be found here.
 https://preview.redd.it/boifxsixem881.png?width=705&format=png&auto=webp&s=14de64b727e31dba7b55ecf76bdfdb52463f2e01
    submitted by    /u/ai-lover  
 [link]   [comments]]]></summary>
        <author>
            <name>Artificial Intelligence</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[One-Dimensional Tensors in Pytorch]]></title>
        <id>https://machinelearningmastery.com/?p=13157</id>
        <link href="https://machinelearningmastery.com/one-dimensional-tensors-in-pytorch/"/>
        <updated>2021-12-29T21:30:13.000Z</updated>
        <summary type="html"><![CDATA[PyTorch is an open-source deep learning framework based on Python language. It allows you to build, train, and deploy deep []
The post One-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.]]></summary>
        <author>
            <name>Muhammad Asad Iqbal Khan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Baidu And PCL Team Introduce ERNIE 3.0 Titan: A Pre-Training Language Model With 260 Billion Parameters]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rrgrji/baidu_and_pcl_team_introduce_ernie_30_titan_a/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rrgrji/baidu_and_pcl_team_introduce_ernie_30_titan_a/"/>
        <updated>2021-12-29T19:43:56.000Z</updated>
        <summary type="html"><![CDATA[With recent breakthroughs in AI, humans have become more reliant on AI to address real-world problems. This makes humans ability to learn and act on knowledge just as essential as a computers. Humans learn and gather information through learning and experience to understand everything from their immediate surroundings. The ability to comprehend and solve issues, and separate facts from absurdities, increases as the knowledge base grows. However, such knowledge is lacking in AI systems, restricting their ability to adapt to atypical problem data.
 Previous studies show that pre-trained language models improve performance on various natural language interpretation and generating tasks.
 A recent work of researchers at Baidu, in collaboration with Peng Cheng Laboratory (PCL), release PCL-BAIDU Wenxin (or ERNIE 3.0 Titan), a pre-training language model with 260 billion parameters. It is the worlds first knowledge-enhanced multi-hundred billion parameter model and its largest Chinese singleton model. 
 You can read the short summary here: https://www.marktechpost.com/2021/12/29/baidu-and-pcl-team-introduce-ernie-3-0-titan-a-pre-training-language-model-with-260-billion-parameters/ 
 Paper: https://arxiv.org/pdf/2112.12731.pdf
 
 https://preview.redd.it/19urwzn7cj881.png?width=1920&format=png&auto=webp&s=6a97e19e9fc4f5dde161e4a6ee17e3b43d86cc39
    submitted by    /u/ai-lover  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Use cases of Image Segmentation Using Deep Learning]]></title>
        <id>https://medium.com/p/90a40f1a1d97</id>
        <link href="https://becominghuman.ai/use-cases-of-image-segmentation-using-deep-learning-90a40f1a1d97?source=rss----5e5bef33608a---4"/>
        <updated>2021-12-29T16:15:29.000Z</updated>
        <summary type="html"><![CDATA[In the last decade, computer vision technology has advanced substantially, thanks to advances in AI and deep learning methodologies. It is]]></summary>
        <author>
            <name>Rayan Potter</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Healthcare Technology Trends and Digital Innovations in 2022]]></title>
        <id>https://medium.com/p/2b746df1bf3</id>
        <link href="https://becominghuman.ai/healthcare-technology-trends-and-digital-innovations-in-2022-2b746df1bf3?source=rss----5e5bef33608a---4"/>
        <updated>2021-12-29T16:15:28.000Z</updated>
        <summary type="html"><![CDATA[With 2020 well behind us, COVID-19s presence continues to linger around the world. Of all the industries that have been forever changed by]]></summary>
        <author>
            <name>MobiDev</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI Podcast Wrapped: Top Five Episodes of 2021]]></title>
        <id>https://blogs.nvidia.com/?p=54710</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/29/ai-podcast-top-five-episodes/"/>
        <updated>2021-12-29T16:00:26.000Z</updated>
        <summary type="html"><![CDATA[Recognized as one of techs top podcasts, the NVIDIA AI Podcast is approaching 3 million listens in five years, as it sweeps across topics like robots, data science, computer graphics and renewable energy. Its 150+ episodes reinforce the extraordinary capabilities of AI  from diagnosing disease to boosting creativity to helping save the Earth  Read article >
The post AI Podcast Wrapped: Top Five Episodes of 2021 appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Angie Lee</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Favorite papers from 2021]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rr8thh/favorite_papers_from_2021/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rr8thh/favorite_papers_from_2021/"/>
        <updated>2021-12-29T14:00:33.000Z</updated>
        <summary type="html"><![CDATA[What have been your favorite reads of 2021 in terms of RL papers? I will start!
 Reward is enough (Reddit Discussion) - Four great names from RL (silver, Singh, Precup and Sutton) give their reasonings as to why using RL can create super intelligence. You might not agree with it, but it's interesting to see the standpoint of Deepmind and where they want to take RL.
 Deep Reinforcement Learning at the Edge of the Statistical Precipice (Reddit Discussion) - This is a major step towards a better model comparison in RL. Too many papers in the past have used a selection technique akin to 'average top 30 runs in a total of 100'. I have also never even heard of Munchausen RL before this paper, and was pleasantly surprised by reading it.
 Mastering Atari with Discrete World Models - Very good read and a nice path from Ha's World Models to Dream to Control to DreamerV2. This is one of the methods this year that actually seems to improve performance quite a bit without needing a large scale distributed approach.
 On the Expressivity of Markov Reward (Reddit Discussion) - The last sentence in the blog post captures it for me: "We hope this work provides new conceptual perspectives on reward and its place in reinforcement learning", it did.
 Open-Ended Learning Leads to Generally Capable Agents (Reddit Discussion) - Great to see the environment integrated into the learning process, seems like something we will see much more of in the future. Unfortunately, as DeepMind does, the environment is not released nor is the code. I remember positions at OpenAI for open-ended learning, perhaps we might see something next year to compete with this.
 
 Most of my picks are not practical algorithms. For me, it seems like PPO is still king when looking at performance and simplicity, kind of a disappointment. I probably missed some papers too. What was your favorite paper in RL 2021? Was it Player of Games (why?), something with Offline RL or perhaps Multi Agents?
    submitted by    /u/YouAgainShmidhoobuh  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AWS Cloud Security: Best Practices]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086461</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1086461"/>
        <updated>2021-12-29T13:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9965282063?profile=original" rel="noopener" target="_blank"><img class="align-center" src="https://storage.ning.com/topology/rest/1.0/file/get/9965282063?profile=RESIZE_710x" width="720"></img></a></p>
<p>Companies today need to be nimble and ready in the face of constantly evolving technology and changing consumer preferences. To achieve this, organizations are switching to Amazon Web Services (AWS). It enables companies to rapidly deploy and scale technology that meets the growing (or shrinking) demand without having to invest in expensive IT</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What Happened to OpenAI + RL?]]></title>
        <id>https://www.reddit.com/r/reinforcementlearning/comments/rr7yk6/what_happened_to_openai_rl/</id>
        <link href="https://www.reddit.com/r/reinforcementlearning/comments/rr7yk6/what_happened_to_openai_rl/"/>
        <updated>2021-12-29T13:15:56.000Z</updated>
        <summary type="html"><![CDATA[OpenAI used to do a lot of RL research, but it seems like last year and this year the only real RL related work was on benchmark competitions. They even gave away the control of OpenAI Gym. They still have great RL researchers working there, but nothing major has come out.
 Is it all due to a pivot towards large scale language models that are at least profitable? Is Sam Altman just not interested in RL?
    submitted by    /u/YouAgainShmidhoobuh  
 [link]   [comments]]]></summary>
        <author>
            <name>Reinforcement Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Running and Passing Information to a Python Script]]></title>
        <id>https://machinelearningmastery.com/?p=13153</id>
        <link href="https://machinelearningmastery.com/running-and-passing-information-to-a-python-script/"/>
        <updated>2021-12-29T04:10:32.000Z</updated>
        <summary type="html"><![CDATA[Running your Python scripts is an important step in the development process, because it is in this manner that youll []
The post Running and Passing Information to a Python Script appeared first on Machine Learning Mastery.]]></summary>
        <author>
            <name>Stefania Cristina</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Finding Lagrange points L1 and L2]]></title>
        <id>https://www.johndcook.com/blog/?p=92910</id>
        <link href="https://www.johndcook.com/blog/2021/12/28/lagrange-points-l1-and-l2/"/>
        <updated>2021-12-28T21:34:34.000Z</updated>
        <summary type="html"><![CDATA[The James Webb Space Telescope (JWST) is on its way to the Lagrange point L2 of the Sun-Earth system. Objects in this location will orbit the Sun at a fixed distance from Earth. There are five Lagrange points, L1 through L5. The points L1, L2, and L3 are unstable, and points L4 and L5 are []
Finding Lagrange points L1 and L2 first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NeurIPS 2021 - Curated papers - Part 2]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rqkypl/neurips_2021_curated_papers_part_2/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rqkypl/neurips_2021_curated_papers_part_2/"/>
        <updated>2021-12-28T17:30:23.000Z</updated>
        <summary type="html"><![CDATA[In part-2 , I have discussed following papers : 
  
Probing Inter-modality: Visual Parsing with Self-Attention for Vision-Language Pre-training
 
Attention Bottlenecks for Multimodal Fusion
 
AugMax: Adversarial Composition of Random Augmentations for Robust Training
 
Revisiting Model Stitching to Compare Neural Representations
  
https://rakshithv-deeplearning.blogspot.com/2021/12/neurips-2021-curated-papers-part2.html
    submitted by    /u/rakshith291  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Keys of Deep Learning: Activation Functions]]></title>
        <id>https://medium.com/p/562c0ba62c14</id>
        <link href="https://becominghuman.ai/keys-of-deep-learning-activation-functions-562c0ba62c14?source=rss----5e5bef33608a---4"/>
        <updated>2021-12-28T16:21:30.000Z</updated>
        <summary type="html"><![CDATA[Biological inspiration of Neural Networks]]></summary>
        <author>
            <name>Dnyanesh Walwadkar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[It Was a Really Virtual Year: Top Five NVIDIA Videos of 2021]]></title>
        <id>https://blogs.nvidia.com/?p=54669</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/28/top-youtube-videos/"/>
        <updated>2021-12-28T16:00:01.000Z</updated>
        <summary type="html"><![CDATA[What better way to look back at NVIDIAs top five videos of 2021 than to hop into the cockpit of a virtual plane flying over Taipei. That was how NVIDIAs Jeff Fisher and Manuvir Das invited viewers into their COMPUTEX keynote on May 31. Their aircraft sailed over the citys green hills and banked around Read article >
The post It Was a Really Virtual Year: Top Five NVIDIA Videos of 2021 appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Rick Merritt</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Most popular posts of 2021]]></title>
        <id>https://www.johndcook.com/blog/?p=92536</id>
        <link href="https://www.johndcook.com/blog/2021/12/28/most-popular-posts-of-2021/"/>
        <updated>2021-12-28T13:00:33.000Z</updated>
        <summary type="html"><![CDATA[These were the most popular posts from 2021 on this site, listed in chronological order. Simple gamma approximation Floor, ceiling, bracket Evolution of random number generators Format text in twitter Where has all the productivity gone? Computing zeta(3) Morse code palindromes Much less than, much greater than Monads and macros Partial functions
Most popular posts of 2021 first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Autoencoders for CIFAR-10]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rqever/autoencoders_for_cifar10/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rqever/autoencoders_for_cifar10/"/>
        <updated>2021-12-28T12:33:46.000Z</updated>
        <summary type="html"><![CDATA[Most of the Autoencoder examples/blogs use MNIST dataset as the implementation. I have trained an autoencoder on CIFAR-10 which you can refer here. There is a trade-off between making the CNN architecture deeper and the improvement of reconstruction loss/error. Or, using a VAE.
 Thoughts?
    submitted by    /u/grid_world  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Researchers Compare Deep Learning (DL) Algorithms For Diagnosing Bacterial Keratitis via External Eye Photographs]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rq2ws6/researchers_compare_deep_learning_dl_algorithms/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rq2ws6/researchers_compare_deep_learning_dl_algorithms/"/>
        <updated>2021-12-28T01:24:52.000Z</updated>
        <summary type="html"><![CDATA[Viral keratitis, bacterial keratitis, fungal keratitis, and parasitic keratitis are all types of infectious keratitis. Bacterial Keratitis (BK) is a kind of Infectious Keratitis that is one of the most frequent and vision-threatening. Contact lens wear is the most prevalent risk factor for Bacterial Keratitis (BK), and it is becoming increasingly popular around the world for a variety of reasons, including exercise, cosmesis, and myopia management.
 BK is substantially more fulminant and painful in the clinical course than other Infectious Keratitis(s). A delayed diagnosis of Bacterial Keratitis (BK) can result in large-area corneal ulcerations, melting, and even perforation if not treated.
 In the case of Infectious Keratitis, timely detection and treatment of BK are vital goals. However,]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The exception case is normal]]></title>
        <id>https://www.johndcook.com/blog/?p=92751</id>
        <link href="https://www.johndcook.com/blog/2021/12/27/the-exception-case-is-normal/"/>
        <updated>2021-12-27T19:41:17.000Z</updated>
        <summary type="html"><![CDATA[Sine and cosine have power series with simple coefficients, but tangent does not. Students are shocked when they see the power series for tangent because there is no simple expression for the power series coefficients unless you introduce Bernoulli numbers, and theres no simple expression for Bernoulli numbers. The perception is that sine and cosine []
The exception case is normal first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Artificial Intelligence is Changing the Payment Gateway Industry]]></title>
        <id>https://medium.com/p/13727057d0d9</id>
        <link href="https://becominghuman.ai/how-artificial-intelligence-is-changing-the-payment-gateway-industry-13727057d0d9?source=rss----5e5bef33608a---4"/>
        <updated>2021-12-27T19:39:04.000Z</updated>
        <summary type="html"><![CDATA[The world is in an exciting phase of artificial intelligence that is slowly taking over our daily lives. Alexa, Siri is replacing person]]></summary>
        <author>
            <name>Ashok Sharma</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[6 Best Online Courses to learn Computer Vision and OpenCV for Beginners]]></title>
        <id>https://medium.com/p/40db4c79c4d2</id>
        <link href="https://becominghuman.ai/6-best-online-courses-to-learn-computer-vision-and-opencv-for-beginners-40db4c79c4d2?source=rss----5e5bef33608a---4"/>
        <updated>2021-12-27T19:38:43.000Z</updated>
        <summary type="html"><![CDATA[My favorite online courses, projects, and Computer Vision certification for beginners to learn Computer vision and OpenCV in 2022]]></summary>
        <author>
            <name>javinpaul</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Are Data Meshes Really Data Marts with Conformed Dimensions?]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085499</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085499"/>
        <updated>2021-12-27T16:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9949632861?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9949632861?profile=RESIZE_710x" width="720"></img></a></p>
<p></p>
<p>Okay, so I am still confused by the concept of a Data Mesh (Im a slow learner).</p>
<p>Recently, I wrote a blog that posed the question: <a href="https://www.datasciencecentral.com/profiles/blogs/are-data-meshes-the-enabler-of-the-marginal-propensity-to-reuse">Are Data Meshes the Enabler of the Marginal Propensity to Reuse</a>? The ability to</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Binomial sums and powers of 2]]></title>
        <id>https://www.johndcook.com/blog/?p=92740</id>
        <link href="https://www.johndcook.com/blog/2021/12/27/golay/"/>
        <updated>2021-12-27T15:25:11.000Z</updated>
        <summary type="html"><![CDATA[Marcel Golay noticed that and realized that this suggested it might be possible to create a perfect code of length 23. I wrote a Twitter thread on this that explains how this relates to coding theory (and to sporadic simple groups). This made me wonder how common it is for cumulative sums of binomial coefficients []
Binomial sums and powers of 2 first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Creating an optimization algorithm for cost function for NN]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rpo3ou/creating_an_optimization_algorithm_for_cost/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rpo3ou/creating_an_optimization_algorithm_for_cost/"/>
        <updated>2021-12-27T13:58:57.000Z</updated>
        <summary type="html"><![CDATA[Is possible to find an article or an example of a new optimization algorithm for cost function for NN?
    submitted by    /u/adilkolakovic  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Scraping Technique: CSS Selector, XPath, & RegEx]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085380</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085380"/>
        <updated>2021-12-27T08:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><span style="font-weight: 400;"><a href="https://storage.ning.com/topology/rest/1.0/file/get/9949663901?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9949663901?profile=RESIZE_710x" width="720"></img></a></span></p>
<p><span style="font-weight: 400;">Web scraping deals with HTML almost exclusively. In nearly all cases, what is required is a small sample from a very large file (e.g. pricing information from an ecommerce page). Therefore, an essential part of scraping is searching through an HTML document and finding the correct</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is a Data Management Platform?]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085290</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085290"/>
        <updated>2021-12-27T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9948211856?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9948211856?profile=RESIZE_710x" width="720"></img></a></p>
<p><strong>Introduction</strong></p>
<p>With the explosion of digital media and the resultant avalanche of constantly increasing user data being created and collected daily, businesses, institutions, and organizations need better ways to manage that data beyond the standard suite of tools. The description of a Data Management Platform or Augmented Data</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rpdfay/hypernerf_a_higherdimensional_representation_for/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rpdfay/hypernerf_a_higherdimensional_representation_for/"/>
        <updated>2021-12-27T03:23:37.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/nickb  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The web 3 meme]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085364</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085364"/>
        <updated>2021-12-26T19:00:00.000Z</updated>
        <summary type="html"><![CDATA[<h2><a href="https://storage.ning.com/topology/rest/1.0/file/get/9947285672?profile=original" rel="noopener" target="_blank"></a></h2>
<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9949734895?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9949734895?profile=RESIZE_710x" width="720"></img></a></p>
<p>Late in the year, we are suddenly hearing a new term <strong>web 3</strong></p>
<p>For the reasons I describe below, this trend will be significant</p>
<p>In this article, I take the perspective of a neutral</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Getting familiar with neural nrtworks]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rodzks/getting_familiar_with_neural_nrtworks/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rodzks/getting_familiar_with_neural_nrtworks/"/>
        <updated>2021-12-25T17:43:34.000Z</updated>
        <summary type="html"><![CDATA[Any good beginner books on the theory of machine learning systems / DNN
    submitted by    /u/Abeokuta_  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[O Come, O Come, Emmanuel: condensing seven hymns into one]]></title>
        <id>https://www.johndcook.com/blog/?p=92486</id>
        <link href="https://www.johndcook.com/blog/2021/12/24/o-come-o-come-emmanuel/"/>
        <updated>2021-12-24T16:09:46.000Z</updated>
        <summary type="html"><![CDATA[The Christmas hymn O Come, O Come, Emmanuel is a summary of the seven O Antiphons, sung on December 17 though 23, dating back to the 8th century [1]. The seven antiphons are O Sapientia O Adonai O Radix Jesse O Clavis David O Oriens O Rex Gentium O Emmanuel The corresponding verses of O []
O Come, O Come, Emmanuel: condensing seven hymns into one first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine Learning can give a 10 second Turbulence Warning]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1078655</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1078655"/>
        <updated>2021-12-24T15:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9942574898?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9942574898?profile=RESIZE_710x" width="720"></img></a></p>
<ul>
<li>Thousands of people are injured by turbulence every year.</li>
<li>New machine learning model gives high-accuracy, 10 second warning for turbulence.</li>
<li>The model may lessen in-flight injuries and save lives.</li>
</ul>
<p>Turbulence is one of the leading cause of injuries on passenger planes andif you dont have your seat belt onthose</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Artificial Vision with Neocognitron by Kunihiko Fukushima (the father of convolutional neural networks)]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rngq7k/artificial_vision_with_neocognitron_by_kunihiko/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rngq7k/artificial_vision_with_neocognitron_by_kunihiko/"/>
        <updated>2021-12-24T07:10:50.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/Wild-Dig-8003  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning by Doing - the DeFi Quest (Part 2 out of 2)]]></title>
        <id>http://dtransposed.github.io/blog/2021/12/24/DeFi-Adventure-2/</id>
        <link href="http://dtransposed.github.io/blog/2021/12/24/DeFi-Adventure-2/"/>
        <updated>2021-12-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Christmas break is a great time to catch up with the backlog of interesting things to learn and read about. I used some of this time to finish the amazing DeFi quest by Cristian Strat. This is a continuation to the first part of this series, where I document my first steps in the world of Decentralized Finance. If you have not read the first write-up, please do. Otherwise, this text will be very confusing and not too useful for you. But once you go through both blog posts, I guarantee that you will have a DeFi knowledge superior to the majority of the folks out there.
Adventure IV
This adventure will be more like a short pause from more in-depth topics. I will quickly present some of the best DeFi dashboards out there. A DeFi dashboard is a central place, where you can view your assets, tr]]></summary>
        <author>
            <name>Damian Bogunowicz - dtransposed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding Traceback in Python]]></title>
        <id>https://machinelearningmastery.com/?p=13148</id>
        <link href="https://machinelearningmastery.com/understanding-traceback-in-python/"/>
        <updated>2021-12-23T23:56:02.000Z</updated>
        <summary type="html"><![CDATA[When an exception occurs in a Python program, often a traceback will be printed. Knowing how to read the traceback []
The post Understanding Traceback in Python appeared first on Machine Learning Mastery.]]></summary>
        <author>
            <name>Adrian Tam</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introducing hybrid machine learning]]></title>
        <id>211e19b2ca986a29acad038c2a6fce1c14edcab4</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/introducing-hybrid-machine-learning/"/>
        <updated>2021-12-23T20:13:09.000Z</updated>
        <summary type="html"><![CDATA[Gartner predicts that by the end of 2024, 75% of enterprises will shift from piloting to operationalizing artificial intelligence (AI), and the vast majority of workloads will end up in the cloud in the long run. For some enterprises that plan to migrate to the cloud, the complexity, magnitude, and length of migrations may be []]]></summary>
        <author>
            <name>Alak Eswaradass</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Use deep learning frameworks natively in Amazon SageMaker Processing]]></title>
        <id>a1ba3dac7c896a0731f566fca4d13bf7c3d9a00c</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/use-deep-learning-frameworks-natively-in-amazon-sagemaker-processing/"/>
        <updated>2021-12-23T19:57:34.000Z</updated>
        <summary type="html"><![CDATA[Until recently, customers who wanted to use a deep learning (DL) framework with Amazon SageMaker Processing faced increased complexity compared to those using scikit-learn or Apache Spark. This post shows you how SageMaker Processing has simplified running machine learning (ML) preprocessing and postprocessing tasks with popular frameworks such as PyTorch, TensorFlow, Hugging Face, MXNet, and []]]></summary>
        <author>
            <name>Patrick Sard</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta AI Announces the Beta Release of Bean Machine: A PyTorch-Based Probabilistic Programming System Used to Understand the Uncertainty in the Machine Learning Models]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rn0u4y/meta_ai_announces_the_beta_release_of_bean/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rn0u4y/meta_ai_announces_the_beta_release_of_bean/"/>
        <updated>2021-12-23T17:36:52.000Z</updated>
        <summary type="html"><![CDATA[Meta AI releases the beta version of Bean Machine, a probabilistic programming framework based on PyTorch that makes it simple to describe and learn about uncertainty in machine learning models used in various applications. Bean Machine makes it possible to create probabilistic models that are domain-specific. It also uses multiple autonomous, uncertainty-aware learning algorithms to learn about the models unseen features. Bean Machine gets an early beta version from Meta.
 Quick Read: https://www.marktechpost.com/2021/12/23/meta-ai-announces-the-beta-release-of-bean-machine-a-pytorch-based-probabilistic-programming-system-used-to-understand-the-uncertainty-in-the-machine-learning-models/ 
 Documentation: https://beanmachine.org/ 
 Tutorials: https://beanmachine.org/docs/tutorials/
 Meta Blog: https://research.facebook.com/blog/2021/12/introducing-bean-machine-a-probabilistic-programming-platform-built-on-pytorch/ 
 
 https://preview.redd.it/xzovhjrzvb781.png?width=1920&format=png&auto=webp&s=1337f3b0f646fd6d888ce02363eb63a6d5257fb7
    submitted by    /u/ai-lover  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Have a Holly, Jolly Gaming Season on GeForce NOW]]></title>
        <id>https://blogs.nvidia.com/?p=54713</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/23/geforce-now-thursday-december-23/"/>
        <updated>2021-12-23T14:00:38.000Z</updated>
        <summary type="html"><![CDATA[Happy holidays, members. This GFN Thursday is packed with winter sales for several games streaming on GeForce NOW, as well as seasonal in-game events. Plus, for those needing a last minute gift for a gamer in their lives, weve got you covered with digital gift cards for Priority memberships. To top it all off, six Read article >
The post Have a Holly, Jolly Gaming Season on GeForce NOW appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>GeForce NOW Community</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to Find a Mobile App Development Firm: Tips for Businesses]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085080</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085080"/>
        <updated>2021-12-23T12:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><span style="font-weight: 400;"><a href="https://storage.ning.com/topology/rest/1.0/file/get/9939242664?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9939242664?profile=RESIZE_710x" width="720"></img></a></span></p>
<p><span style="font-weight: 400;">Lets imagine that you have signed a contract with a mobile app development firm. It seems that you have agreed upon everything: terms, budget, the scope of work, and other things. But six months later, it turns out that the developers are not up to their work and the product is</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is a Scrum Board? What is the Difference Between a Scrum & Kanban Board?]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085306</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085306"/>
        <updated>2021-12-23T12:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9949742696?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9949742696?profile=RESIZE_710x" width="720"></img></a></p>
<h2><span id="What_is_a_Scrum_Board"><b>What is a Scrum Board?</b></span></h2>
<p>As Scrum is one of the popular frameworks to break down complex problems into smaller tasks, Scrum board is a project management software used to visually represent these tasks and Scrum sprints. The scrum board is the center of every sprint meeting to get regular updates</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cloud, Cost and Containers three C's in Cloud-Computing in post-COVID]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085158</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085158"/>
        <updated>2021-12-23T10:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><span style="font-weight: 400;"><a href="https://storage.ning.com/topology/rest/1.0/file/get/9950166067?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9950166067?profile=RESIZE_710x" width="720"></img></a></span></p>
<p><span style="font-weight: 400;">The COVID-19 pandemic has thrown organizations into disarraythe increased usage of conferencing and collaboration services by employees working from home strains back-end support services.</span></p>
<p><span style="font-weight: 400;">And growing traffic on networks connecting</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[If the accuracy of my network is zero on the very first epoch, is there any point in letting the training run for the remaining epochs?]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rms2pm/if_the_accuracy_of_my_network_is_zero_on_the_very/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rms2pm/if_the_accuracy_of_my_network_is_zero_on_the_very/"/>
        <updated>2021-12-23T09:37:21.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/eva01beast  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Face recognition]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rmelaz/face_recognition/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rmelaz/face_recognition/"/>
        <updated>2021-12-22T20:56:43.000Z</updated>
        <summary type="html"><![CDATA[I am currently working on a project that involves face verification. I want to use Azure Face API and I gotta say I havent understood the pricing. I would love if some of you can clarify. If say I have 200 faces and 2000 pictures these faces are in (1 face might be in N pictures), in order to find all the pictures that each face is in, that means I will have to run 400,000 transactions ? As in 2000 iterations per face? Or is there a smarter way to do it?
 I know there is an option to index faces but i do not fully understand that yet.
 Thank you for your help!
    submitted by    /u/xPiexPie  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Add Spark to Your Customer Notifications with a Bentechs Modern CCM]]></title>
        <id>https://medium.com/p/611697fb5e1</id>
        <link href="https://becominghuman.ai/add-spark-to-your-customer-notifications-with-a-bentechs-modern-ccm-611697fb5e1?source=rss----5e5bef33608a---4"/>
        <updated>2021-12-22T16:41:47.000Z</updated>
        <summary type="html"><![CDATA[Is there any track of the number of notifications and alerts you receive each day? As customers, we receive numerous notifications from our]]></summary>
        <author>
            <name>BENEVOLENCE TECHNOLOGIES</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Strategies to Reimagine Consumers Digital Trip in a New Age]]></title>
        <id>https://medium.com/p/584b2b9aa45d</id>
        <link href="https://becominghuman.ai/strategies-to-reimagine-consumers-digital-trip-in-a-new-age-584b2b9aa45d?source=rss----5e5bef33608a---4"/>
        <updated>2021-12-22T16:41:45.000Z</updated>
        <summary type="html"><![CDATA[Normal routines of smartphone shops, automobile dealerships, or dining experiences, many of these travels have been transformed into]]></summary>
        <author>
            <name>Divyesh Dharaiya</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scraping Data from Google Search Using Python and Scrapy]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084882</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084882"/>
        <updated>2021-12-22T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9949749054?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9949749054?profile=RESIZE_710x" width="720"></img></a></p>
<p><span>Scraping Google SERPs (search engine result pages) is as straightforward or as complicated as the tools we use. For this tutorial, well be using Scrapy, a web scraping framework designed for Python. Python and Scrapy combine to create a powerful duo that we can use to scrape almost any website.</span></p>
<p><span>Scrapy has many useful</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[3D Secure Authentication: A New Era For Payment Authentication And Customer Experience]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085049</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085049"/>
        <updated>2021-12-22T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p></p>
<p><strong><a href="https://storage.ning.com/topology/rest/1.0/file/get/9936688655?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9936688655?profile=RESIZE_710x" width="720"></img></a></strong></p>
<p><strong>3D Secure Authentication Industry:</strong></p>
<ul>
<li>3D secure authentication is a fraud-prevention security system for credit and debit card transactions processed online. During card payments, 3D secure authentication adds an additional layer of security. It provides clients with a safeauthenticationstep before</li>
</ul>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Christmas entities]]></title>
        <id>61bff61010e963003be0846a</id>
        <link href="https://www.aiweirdness.com/christmas-entities/"/>
        <updated>2021-12-22T15:57:26.000Z</updated>
        <summary type="html"><![CDATA[When you think about it, Christmas can get pretty weird. 
There's the classic Christmas story of the Bible, and then there are all these extra entities that aren't in the book but which become somehow part of Christmas. And some of them are quite unsettling. There&]]></summary>
        <author>
            <name>Janelle Shane</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bonus: The awesome lightning power of Blitzen, son of Donder]]></title>
        <id>61c2a8d510e963003be08554</id>
        <link href="https://www.aiweirdness.com/the-awesome-lightning-power-of-blitzen/"/>
        <updated>2021-12-22T15:55:39.000Z</updated>
        <summary type="html"><![CDATA[AI Weirdness: the strange side of machine learning]]></summary>
        <author>
            <name>Janelle Shane</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[My Information Diet]]></title>
        <id>https://danieltakeshi.github.io/2021/12/22/my-information-diet/</id>
        <link href="https://danieltakeshi.github.io/2021/12/22/my-information-diet/"/>
        <updated>2021-12-22T12:00:00.000Z</updated>
        <summary type="html"><![CDATA[On July 03 2021, the subject of media and news sources came up in a
conversation I had with someone over brunch when we were talking about media
bias. I was asked: what news do you read? I regret that I gave a sloppy
response that sounded like a worse version of: uh, I read a variety of news 
and then I tried listing a few from memory. I wish I had given a crisper
response, and since that day, I have thought about what that person has asked
me every day.
In this blog post, I describe my information diet, referring to how I read
and consume media to understand current events. Before getting to the actual
list of media sources, here are a few comments to clarify my philosophy and
which might also preemptively address common objections.
There are too many sources and not enough time to r]]></summary>
        <author>
            <name>Seita's Place</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Cloud and AI Technologies to Make Data Driven Decisions For Monetization]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085116</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085116"/>
        <updated>2021-12-22T11:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9949757081?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9949757081?profile=RESIZE_710x" width="720"></img></a></p>
<p>The exchange of data between corporations is known as data monetization. It is the process of earning income or creating new revenue streams by utilizing data, which is estimated to support expansion of the global data monetization market. Direct data monetization as well as indirect data monetization is the two forms of data monetization. The sale of</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Outsourcing Data Annotation Work]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085036</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1085036"/>
        <updated>2021-12-22T10:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><span>The discipline of data annotation and labeling is growing in popularity and significance throughout the world. The global market for data annotation tools is expected to reach</span><strong class="js iv">$2.57 billion by 2027</strong><span>, according to a published report.</span></p>
<p class="jq jr iu js b jt ju iy jv jw jx jb jy jz ka kb kc kd ke kf kg kh ki kj kk kl em jp" id="412f">For robots, drones, and vehicles to gain increasing levels of au<span id="rmm">t</span>onomy,</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Top 7 Reasons Data Scientists Should Know Java Programming Language]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084865</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084865"/>
        <updated>2021-12-22T10:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><span style="font-weight: 400;"><a href="https://storage.ning.com/topology/rest/1.0/file/get/9949819074?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9949819074?profile=RESIZE_710x" width="720"></img></a></span></p>
<p><span style="font-weight: 400;">Java is the</span> <a href="https://www.oracle.com/ar/a/ocom/docs/java-strength-in-numbers.pdf"><span style="font-weight: 400;">#1 programming language for Big Data</span></a><span style="font-weight: 400;">, Analytics, DevOps, and AI. It is consistently the first choice for</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Managing Collaborative Machine Learning Experiments - Guide]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rm1e5h/managing_collaborative_machine_learning/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rm1e5h/managing_collaborative_machine_learning/"/>
        <updated>2021-12-22T09:13:41.000Z</updated>
        <summary type="html"><![CDATA[Sharing machine learning experiments to compare its models is important when you're working with a team of engineers. You might need to get another opinion on an experiments results or to share a modified dataset or even share the exact reproduction of a specific experiment.
 The following tutorial goes through an example of sharing an experiment with DVC remotes: Running Collaborative Experiments - using DVC remotes to share experiments and their data across machines
 Setting up DVC remotes in addition to your Git remotes lets you share all of the data, code, and hyperparameters associated with each experiment so anyone can pick up where you left off in the training process. When you use DVC, you can bundle your data and code changes for each experiment and push those to a remote for somebody else to check out.
    submitted by    /u/thumbsdrivesmecrazy  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noob needs help]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rlx1zj/noob_needs_help/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rlx1zj/noob_needs_help/"/>
        <updated>2021-12-22T04:34:51.000Z</updated>
        <summary type="html"><![CDATA[Ok so Im new to neural networks, so I might not understand a lot of the technical terms. 
 I want to show a NN some gameplay. But I dont know how to. I can capture the keystrokes for each frame but I dont know what to do next. 
 Do I take screenshots and save those frames w the keystrokes to my disk? 
 I kinda know how to use Cv2, Pillow, and the keyboard module. 
 Im really lost, so any help will be highly appreciated
 Ps- I want the model to learn how to play the game
    submitted by    /u/findcureforautism  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DSC Weekly Digest 21 December 2021: Winter Solstice Shenanigans]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084850</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084850"/>
        <updated>2021-12-22T00:30:00.000Z</updated>
        <summary type="html"><![CDATA[<div class="dsc_primaryImage"><span style="font-family: arial, helvetica, sans-serif;"><a href="https://www.datasciencecentral.com/profiles/blog/list?tag=dsc_newsletter" rel="noopener" target="_blank"><img alt="Winter Solstice Shenanigans" src="https://multimedia.getresponse360.com/datascience-B/photos/0fdfb61a-5192-4b3b-bf19-15bdb6d3da2b.jpg" style="vertical-align: baseline;" title="Winter Solstice Shenanigans" width="720"></img></a></span></div>
<table style="width: 726px;">
<tbody><tr><td><p dir="ltr">Today, the 21st of December, is the Winter Solstice, unless you happen to be in sub-Saharan Africa, Australia, Argentina, or Antarctica, or other points south of the equator. In that case, today is the first day</p>
</td>
</tr>
</tbody>
</table>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transfer LearningPart5.1!! Implementing ResNet in Keras]]></title>
        <id>https://medium.com/p/455afbc28657</id>
        <link href="https://becominghuman.ai/transfer-learning-part-5-1-implementing-resnet-in-keras-455afbc28657?source=rss----5e5bef33608a---4"/>
        <updated>2021-12-21T16:22:11.000Z</updated>
        <summary type="html"><![CDATA[In Part 5.0 of the Transfer Learning series we have discussed about ResNet pre-trained model in depth so in this series we will implement]]></summary>
        <author>
            <name>RAVI SHEKHAR TIWARI</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[5 Ways To Use AI For Supply Chain Management]]></title>
        <id>https://medium.com/p/37788ad01577</id>
        <link href="https://becominghuman.ai/5-ways-to-use-ai-for-supply-chain-management-37788ad01577?source=rss----5e5bef33608a---4"/>
        <updated>2021-12-21T16:22:09.000Z</updated>
        <summary type="html"><![CDATA[Optimizing Our Supply Chain Using Artificial Intelligence]]></summary>
        <author>
            <name>James Montantes</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[3D Artist Turns Hobby Into Career, Using Omniverse to Turn Sketches Into Masterpieces]]></title>
        <id>https://blogs.nvidia.com/?p=54686</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/21/omniverse-creator-yenifer-macias/"/>
        <updated>2021-12-21T16:00:37.000Z</updated>
        <summary type="html"><![CDATA[It was memories of playing Pac-Man and Super Mario Bros while growing up in Colombias sprawling capital of Bogot that inspired Yenifer Maciass award-winning submission for the #CreateYourRetroverse contest, featured above. The contest asked NVIDIA Omniverse users to share scenes that visualize where their love for graphics began. For Macias, that passion goes back to Read article >
The post 3D Artist Turns Hobby Into Career, Using Omniverse to Turn Sketches Into Masterpieces appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Angie Lee</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NVIDIA BlueField Sets New World Record for DPU Performance]]></title>
        <id>https://blogs.nvidia.com/?p=54663</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/21/bluefield-dpu-world-record-performance/"/>
        <updated>2021-12-21T16:00:14.000Z</updated>
        <summary type="html"><![CDATA[Data centers need extremely fast storage access, and no DPU is faster than NVIDIAs BlueField-2. Recent testing by NVIDIA shows that two BlueField-2 data processing units reached 41.5 million input/output operations per second (IOPS)  more than 4x more IOPS than any other DPU. The BlueField-2 DPU delivered record-breaking performance using standard networking protocols and Read article >
The post NVIDIA BlueField Sets New World Record for DPU Performance appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Ami Badani</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Omniverse Wove a Real CEO  and His Toy Counterpart  Together With Stunning Demos at GTC]]></title>
        <id>https://blogs.nvidia.com/?p=54666</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/21/how-omniverse-keynote/"/>
        <updated>2021-12-21T14:00:12.000Z</updated>
        <summary type="html"><![CDATA[It could only happen in NVIDIA Omniverse  the companys virtual world simulation and collaboration platform for 3D workflows. And it happened during an interview with a virtual toy model of NVIDIAs CEO, Jensen Huang. What are the greatest  one of Toy Jensens creators asked, stumbling, then stopping before completing his scripted question. Unfazed, Read article >
The post How Omniverse Wove a Real CEO  and His Toy Counterpart  Together With Stunning Demos at GTC appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Brian Caulfield</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Steps in securing your enterprise mobile application]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084676</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084676"/>
        <updated>2021-12-21T11:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9933327478?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9933327478?profile=RESIZE_710x" width="720"></img></a></p>
<p>We live in a world where the lines between private and public data are blurred. With access to almost every aspect of data, businesses slowly dive into the lives of consumers and surprise them by showing them the products they've been looking for at random, anywhere. Data discomfort is slowly subsiding, people are still cautious and for the right</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ways To Make Cloud Data More Environmentally Friendly]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084757</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084757"/>
        <updated>2021-12-21T11:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><span style="font-weight: 400;"><a href="https://storage.ning.com/topology/rest/1.0/file/get/9933233072?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9933233072?profile=RESIZE_710x" width="720"></img></a></span></p>
<p><span style="font-weight: 400;">We have noticed how the industrial revolution transformed the shape of our modernized world. We got big industries, endowed the computer, and made significant progress in the IT sector.</span></p>
<p><span style="font-weight: 400;">But, this change had its consequences too. With an</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building a Scalable Application with React and Redux: A Step-by-Step Guide]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084740</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084740"/>
        <updated>2021-12-21T05:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><span style="font-weight: 400;"><a href="https://storage.ning.com/topology/rest/1.0/file/get/9933241254?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9933241254?profile=RESIZE_710x" width="720"></img></a></span></p>
<p><span style="font-weight: 400;">One of the most exciting sectors of the IT business is web development. There is a vast library of tools and libraries available, many of which strive to improve an application's functionality and efficiency. However, taking advantage of every fresh opportunity isn't a good idea</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Frist promising results of my neuronal denoising network ]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rl2s1e/frist_promising_results_of_my_neuronal_denoising/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rl2s1e/frist_promising_results_of_my_neuronal_denoising/"/>
        <updated>2021-12-21T01:33:48.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/Rindsroulade  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Economics of Data Products]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084804</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084804"/>
        <updated>2021-12-20T23:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9930070895?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9930070895?profile=RESIZE_710x" width="720"></img></a></p>
<p>Chief Data Officers (CDO) and Chief Data Analytics Officers (CDAO) are under intense pressure to find ways to monetize their growing volumes of data. While some organizations seek monetization by trying to sell their data, as I discussed in the </p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prescriptive Analytics  The Final Frontier]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084215</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084215"/>
        <updated>2021-12-20T22:54:43.000Z</updated>
        <summary type="html"><![CDATA[<div class="wpb_text_column wpb_content_element vc_custom_1636464703663 tm-animation move-up animate"><div class="wpb_wrapper"><p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9917146659?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9917146659?profile=RESIZE_710x" width="720"></img></a></p>
<p>Back in 2014, Gartner placed the field of prescriptive analytics at the beginning of the Peak of Inflated Expectations in their Hype Cycle of Emerging Technologies. And also went on to project the prescriptive analytics</p>
</div>
</div>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Living in the Future: NIO ET5 Sedan Designed for the Autonomous Era With NVIDIA DRIVE Orin]]></title>
        <id>https://blogs.nvidia.com/?p=54676</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/20/nio-et5-designed-autonomous-era-drive-orin/"/>
        <updated>2021-12-20T21:43:25.000Z</updated>
        <summary type="html"><![CDATA[Meet the electric vehicle thats truly future-proof. Electric-automaker NIO took the wraps off its fifth mass-production model, the ET5, during NIO Day 2021 last week. The mid-size sedan borrows from its luxury and performance predecessors for an intelligent vehicle thats as agile as it is comfortable. The ET5 is a software-defined vehicle with a unified Read article >
The post Living in the Future: NIO ET5 Sedan Designed for the Autonomous Era With NVIDIA DRIVE Orin appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Katie Burke</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Design Thinking to Win the First and the Last Mile]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1083447</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1083447"/>
        <updated>2021-12-20T19:08:22.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9929648266?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9929648266?profile=RESIZE_710x" width="720"></img></a></p>
<p>I was hanging around the LinkedIn water cooler the other day, just minding my own business, when I came across this very interesting graphic (Figure 1) from <a href="https://www.linkedin.com/in/brentdykes/">Brent Dykes</a> titled </p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Azure AI milestone: Microsoft KEAR surpasses human performance on CommonsenseQA benchmark]]></title>
        <id>https://www.microsoft.com/en-us/research/?p=806026</id>
        <link href="https://www.microsoft.com/en-us/research/blog/azure-ai-milestone-microsoft-kear-surpasses-human-performance-on-commonsenseqa-benchmark/"/>
        <updated>2021-12-20T19:08:11.000Z</updated>
        <summary type="html"><![CDATA[KEAR (Knowledgeable External Attention for commonsense Reasoning)along with recent milestones incomputer vision andneuraltext-to-speechis part of a larger Azure AI mission to provide relevant, meaningful AI solutions and services that work better for peoplebecause they better capture how people learn and workwith improved vision, knowledge understanding, and speech capabilities. At the center of these efforts is []
The post Azure AI milestone: Microsoft KEAR surpasses human performance on CommonsenseQA benchmark appeared first on Microsoft Research.]]></summary>
        <author>
            <name>Brenda Potts</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Detect That Defect: Mariner Speeds Up Manufacturing Workflows With AI-Based Visual Inspection]]></title>
        <id>https://blogs.nvidia.com/?p=54653</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/20/mariner-visual-inspection/"/>
        <updated>2021-12-20T18:00:45.000Z</updated>
        <summary type="html"><![CDATA[Imagine picking out a brand new car  only to find a chip in the paint, rip in the seat fabric or mark in the glass. AI can help prevent such moments of disappointment for manufacturers and potential buyers. Mariner, an NVIDIA Metropolis partner based in Charlotte, North Carolina, offers an AI-enabled video analytics system Read article >
The post Detect That Defect: Mariner Speeds Up Manufacturing Workflows With AI-Based Visual Inspection appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Angie Lee</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why Are Generative Adversarial Networks(GANs) So Famous And How Will GANs In The Future Be?]]></title>
        <id>https://medium.com/p/cb0d414a9e2b</id>
        <link href="https://becominghuman.ai/why-are-generative-adversarial-networks-gans-so-famous-and-how-will-gans-be-in-the-future-cb0d414a9e2b?source=rss----5e5bef33608a---4"/>
        <updated>2021-12-20T16:48:56.000Z</updated>
        <summary type="html"><![CDATA[What are GENERATIVE ADVERESIAL NETWORKS and what are GANs used for?]]></summary>
        <author>
            <name>Joel Prabhod</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Error correcting code from octonions]]></title>
        <id>https://www.johndcook.com/blog/?p=92157</id>
        <link href="https://www.johndcook.com/blog/2021/12/20/octonion-ecc/"/>
        <updated>2021-12-20T15:41:01.000Z</updated>
        <summary type="html"><![CDATA[Yesterday I wrote about how to multiply octets of real numbers, the octonions. Today Ill show how to create an error correcting code from the octonions. In fact, well create a perfect code in the sense explained below. Were going to make a code out of octonions over a binary field. That is, were going []
Error correcting code from octonions first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Most data warehouse projects fail. Heres how not to.]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084495</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084495"/>
        <updated>2021-12-20T10:30:00.000Z</updated>
        <summary type="html"><![CDATA[<div class="post-header text-fields"><div class="text post-header__introduction"><div class="post-header text-fields"><div class="text post-header__introduction"><p style="text-align: center;"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9930051081?profile=RESIZE_710x" width="720"></img></p>
</div>
</div>
</div>
</div>
<div class="text-fields u-padding"><div class="text-fields__container"><div class="text text-fields__text"><div class="text-fields u-padding"><div class="text-fields__container"><div class="text text-fields__text"><p>In todays data-driven reality, data</p>
</div>
</div>
</div>
</div>
</div>
</div>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Where Semantics and Machine Learning Converge]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084560</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084560"/>
        <updated>2021-12-20T02:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9926540062?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9926540062?profile=RESIZE_710x" width="720"></img></a></p>
<p>Artificial Intelligence has a long history of oscillating between two somewhat contradictory poles. On one side, exemplified by Noam Chomsky, Marvin Minsky, Seymour Papert, and many others, is the idea that cognitive intelligence was algorithmic in nature - that there were a set of fundamental precepts that formed the foundation of language, and by</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conjugate theorem for octonions]]></title>
        <id>https://www.johndcook.com/blog/?p=92096</id>
        <link href="https://www.johndcook.com/blog/2021/12/19/conjugate-octonions/"/>
        <updated>2021-12-19T23:33:28.000Z</updated>
        <summary type="html"><![CDATA[Yesterday I wrote about the fact that quaternions, unlike complex numbers, can form conjugates via a series of multiplications and additions. This post will show that you can do something similar with octonions. If x is an octonion x = r0 e0 + r1 e1 +  + r7 e7 where all the rs are []
Conjugate theorem for octonions first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Language Models Are Leading low-code AI Applications in the Cloud]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084609</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084609"/>
        <updated>2021-12-19T23:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><br></br> <a href="https://storage.ning.com/topology/rest/1.0/file/get/9926326071?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9926326071?profile=RESIZE_710x" width="720"></img></a></p>
<p>Its that time of the year and while I do not like predictions, I think there is one which I want to talk about</p>
<p>Its a bit specific so needs some context</p>
<p>From an AI standpoint, 2021 has been the year of large language models like <a href="https://en.wikipedia.org/wiki/GPT-3">GPT-3</a></p>
<p>And that has led to near-magical</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to multiply octonions]]></title>
        <id>https://www.johndcook.com/blog/?p=92088</id>
        <link href="https://www.johndcook.com/blog/2021/12/19/multiply-octonions/"/>
        <updated>2021-12-19T23:27:37.000Z</updated>
        <summary type="html"><![CDATA[This post will present a way of multiplying octonions thats easy to remember. Please note that there are varying conventions for how to define multiplication for octonions [1]. Octonions The complex numbers have one imaginary unit i, and the quaternions have three: i, j, and k. The octonions have seven, and so it makes sense []
How to multiply octonions first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I have many doubts here.Any hints on how to solve these problems???]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rk2egj/i_have_many_doubts_hereany_hints_on_how_to_solve/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rk2egj/i_have_many_doubts_hereany_hints_on_how_to_solve/"/>
        <updated>2021-12-19T18:20:35.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/Own-Assistance58  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What does stylegan do to prevent mode collapse?]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rk27b8/what_does_stylegan_do_to_prevent_mode_collapse/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rk27b8/what_does_stylegan_do_to_prevent_mode_collapse/"/>
        <updated>2021-12-19T18:10:33.000Z</updated>
        <summary type="html"><![CDATA[I will like to know what stylegan does during training to prevent mode collapse.
    submitted by    /u/Virtual_Essay1216  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Labyrinthology to Study the Progression of Experiences]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084383</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084383"/>
        <updated>2021-12-19T03:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><span style="font-size: 12pt;"><span><a href="https://storage.ning.com/topology/rest/1.0/file/get/9924034458?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9924034458?profile=RESIZE_710x" width="720"></img></a></span></span></p>
<p><span style="font-size: 12pt;">A labyrinth is a structure in the inner ear. The use of the term labyrinthology might sometimes relate to this part of the human anatomy. Alternatively, some people think of a labyrinth as a maze or a body of routes and passages. Years ago, I purchased some land</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Functional Programming In Python]]></title>
        <id>https://machinelearningmastery.com/?p=13128</id>
        <link href="https://machinelearningmastery.com/functional-programming-in-python/"/>
        <updated>2021-12-19T02:26:12.000Z</updated>
        <summary type="html"><![CDATA[Python is a fantastic programming language. It is likely to be your first choice for developing a machine learning or []
The post Functional Programming In Python appeared first on Machine Learning Mastery.]]></summary>
        <author>
            <name>Mehreen Saeed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complex Conjugates versus Quaternion Conjugates]]></title>
        <id>https://www.johndcook.com/blog/?p=92005</id>
        <link href="https://www.johndcook.com/blog/2021/12/18/quaternion-conjugate/"/>
        <updated>2021-12-18T18:54:45.000Z</updated>
        <summary type="html"><![CDATA[The conjugate of a complex number is the complex number Taking the conjugate flips over a complex number, taking its reflection in the real axis. Multiplication stretches and rotates complex numbers, and addition translates complex numbers. You cant flip the complex plane over by any series of dilatations, rotations, and translations. The situation is different []
Complex Conjugates versus Quaternion Conjugates first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The center may not hold]]></title>
        <id>https://www.johndcook.com/blog/?p=91983</id>
        <link href="https://www.johndcook.com/blog/2021/12/18/the-center-may-not-hold/"/>
        <updated>2021-12-18T15:22:11.000Z</updated>
        <summary type="html"><![CDATA[ Things fall apart; the centre cannot hold   Yeats, The Second Coming  Center of a group The center of a group is the set of elements that commute with everything else in the group. For example, matrix multiplication is not commutative in general. You cant count on AB being equal to BA, []
The center may not hold first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine Learning and the Challenge of Predicting Fake News]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1078656</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1078656"/>
        <updated>2021-12-18T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9922845287?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9922845287?profile=RESIZE_710x" width="720"></img></a></p>
<ul>
<li>A new study evaluates ML models that classify fake news from fact.</li>
<li>The best models can only achieve up to 77.2% accuracy.</li>
<li>AI will probably never be able to fully replace the nuanced analysis of human journalists.</li>
</ul>
<p><strong>Many Natural Language Processing (NLP) techniques exist for detecting fake news.</strong></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[JPEG Compression Artifacts Removal AI - FBCNN]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rize8m/jpeg_compression_artifacts_removal_ai_fbcnn/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rize8m/jpeg_compression_artifacts_removal_ai_fbcnn/"/>
        <updated>2021-12-18T04:31:42.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/cloud_weather  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Will 5G Bring the Death of Brick and Mortar Banking?]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084370</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084370"/>
        <updated>2021-12-18T04:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><span style="font-weight: 300;"><a href="https://storage.ning.com/topology/rest/1.0/file/get/9926815486?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9926815486?profile=RESIZE_710x" width="720"></img></a> The benefits of 5G  delivering super-fast, low-latency broadband to consumers, wirelessly, wherever they are  promises to revolutionise the way we interact with one another and businesses. For the first time consumers are going to have immediate, portable access to the kind of speeds and connectivity that was previously only</span></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Live call analytics for your contact center with Amazon language AI services]]></title>
        <id>4ad6604866aa6f367ad543ba773b887ee5278e55</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/live-call-analytics-for-your-contact-center-with-amazon-language-ai-services/"/>
        <updated>2021-12-18T00:47:33.000Z</updated>
        <summary type="html"><![CDATA[Your contact center connects your business to your community, enabling customers to order products, callers to request support, clients to make appointments, and much more. When calls go well, callers retain a positive image of your brand, and are likely to return and recommend you to others. And the converse, of course, is also true. []]]></summary>
        <author>
            <name>Bob Strahan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Post call analytics for your contact center with Amazon language AI services]]></title>
        <id>ce2f56854ba560eea06ff25c4fb2f22d80b1505d</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/post-call-analytics-for-your-contact-center-with-amazon-language-ai-services/"/>
        <updated>2021-12-18T00:38:22.000Z</updated>
        <summary type="html"><![CDATA[Your contact center connects your business to your community, enabling customers to order products, callers to request support, clients to make appointments, and much more. Each conversation with a caller is an opportunity to learn more about that callers needs, and how well those needs were addressed during the call. You can uncover insights from []]]></summary>
        <author>
            <name>Andrew Kane</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How data decentralization is already benefiting enterprisesand society]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084363</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084363"/>
        <updated>2021-12-18T00:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9921348679?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9921348679?profile=RESIZE_710x" width="720"></img></a> <span style="font-size: 8pt;">Manufacturing Line, <em>Wikimedia Commons</em>, 2014</span><br></br> <br></br> <span style="font-weight: 400;">Fakery certainly isnt limited to news and social media. The Organisation for Economic Co-operation and Development (OECD) estimated in 2016 that 6.8 percent of physical goods imported by the EU were fakes.</span></p>
<p></p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Azure AI milestone: New Neural Text-to-Speech models more closely mirror natural speech]]></title>
        <id>https://www.microsoft.com/en-us/research/?p=804160</id>
        <link href="https://www.microsoft.com/en-us/research/blog/azure-ai-milestone-new-neural-text-to-speech-models-more-closely-mirror-natural-speech/"/>
        <updated>2021-12-17T23:22:31.000Z</updated>
        <summary type="html"><![CDATA[Neural Text-to-Speechalong with recent milestones in computer vision and question answeringis part of a larger Azure AI mission to provide relevant, meaningful AI solutions and services that work better for people because they better capture how people learn and workwith improved vision, knowledge understanding, and speech capabilities. At the center of these efforts is XYZ-code, []
The post Azure AI milestone: New Neural Text-to-Speech models more closely mirror natural speech appeared first on Microsoft Research.]]></summary>
        <author>
            <name>Alyssa Hughes</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Perfecting pitch perception]]></title>
        <id>https://news.mit.edu/2021/perfecting-pitch-perception-1217</id>
        <link href="https://news.mit.edu/2021/perfecting-pitch-perception-1217"/>
        <updated>2021-12-17T21:30:00.000Z</updated>
        <summary type="html"><![CDATA[Computational modeling shows that both our ears and our environment influence how we hear.]]></summary>
        <author>
            <name>Jennifer Michalowski | McGovern Institute for Brain Research</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Free NLP for Semantic Search Course + Data Augmentation with SBERT (AugSBERT)]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/riluxm/free_nlp_for_semantic_search_course_data/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/riluxm/free_nlp_for_semantic_search_course_data/"/>
        <updated>2021-12-17T17:03:14.000Z</updated>
        <summary type="html"><![CDATA[Hi all, the NLP for Semantic Search course that I've been working on has just been released, and today the latest chapter on data augmentation with SBERT has been released too!
 It's all completely free and covers everything you need to get started with building SotA language models for semantic similarity, from machine translation to question-answering, and more!
 Semantic search allows us to search language-based data based on the semantics or 'meaning' of a text, from machine translation to question-answering. It's how Google understands "what time is it in NYC?", and even allows us to search for images using text-based queries.
 It is in essence, a way for us to interact with machines in a more human way. NLP fits in as the 'semantic' in semantic search.
 Current chapters are: 1. Dense Vectors 2. Sentence Embeddings and Transformers 3. Training Sentence Transformers with Softmax Loss 4. Training Sentence Transformers with MNR Loss 5. Multilingual Sentence Transformers 6. Question Answering 7. Unsupervised Training for Sentence Transformers 8. (New) Data Augmentation With BERT
 Let me know what you think, I hope you enjoy it!
    submitted by    /u/jamescalam  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The congruent number problem]]></title>
        <id>https://www.johndcook.com/blog/?p=91901</id>
        <link href="https://www.johndcook.com/blog/2021/12/17/congruent-number/"/>
        <updated>2021-12-17T16:34:43.000Z</updated>
        <summary type="html"><![CDATA[A positive integer n is said to be congruent if there exists a right triangle with area n such that the length of all three sides is rational. You could always choose one leg to have length n and the other to have length 2. Such a triangle would have area n and two rational []
The congruent number problem first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Top 5 Edge AI Trends to Watch in 2022]]></title>
        <id>https://blogs.nvidia.com/?p=54605</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/17/top-5-edge-ai-trends-2022/"/>
        <updated>2021-12-17T08:01:57.000Z</updated>
        <summary type="html"><![CDATA[2021 saw massive growth in the demand for edge computing  driven by the pandemic, the need for more efficient business processes, as well as key advances in the Internet of Things, 5G and AI. In a study published by IBM in May, for example, 94 percent of surveyed executives said their organizations will implement Read article >
The post Top 5 Edge AI Trends to Watch in 2022 appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Amanda Saunders</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to Build a Minimum Viable Product (MVP): A Detailed Guide]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084503</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084503"/>
        <updated>2021-12-17T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9926827266?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9926827266?profile=RESIZE_710x" width="720"></img></a></p>
<p>Almost all Software-as-a-Service (SaaS) businesses start with a "visionary idea" - a concept that can revolutionize the industry. Yet, the world has witnessed numerous passionate founders invest their energy, time, and money in a product that solves a problem that nobody cares about. It's the responsibility of a leader to determine if the product is</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ways Technology is offering Innovative Solutions to the Education System]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084194</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084194"/>
        <updated>2021-12-17T04:30:00.000Z</updated>
        <summary type="html"><![CDATA[<p><b><a href="https://storage.ning.com/topology/rest/1.0/file/get/9919075296?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9919075296?profile=RESIZE_710x" width="720"></img></a></b></p>
<p><b>Technology</b> is emerging as well as changing the future of the <b>education</b> <b>system</b> by turning the traditional methods of gaining knowledge into a comprehensive way of learning with the help of augmented reality and simulation tools. In the future, this will actively help the education as well as educators to manage time for</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding AlphaZero Neural Networks SuperHuman Chess Ability (Summary of the Paper 'Acquisition of Chess Knowledge in AlphaZero')]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/ri4ps4/understanding_alphazero_neural_networks/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/ri4ps4/understanding_alphazero_neural_networks/"/>
        <updated>2021-12-17T00:44:05.000Z</updated>
        <summary type="html"><![CDATA[As a common and (sometimes) proven belief, deep learning systems seem to learn uninterpretable representations and are far from human understanding. Recently, some studies have highlighted the fact that this may not always be applicable, and some networks may be able to learn human-readable representations. Unfortunately, this ability could merely come from the fact that these networks are exposed to human-generated data. So, to demonstrate their ability to learn like humans (and not that they are simply memorizing human-created labels), it is necessary to test them without any label. 
 Following this idea, the DeepMind and Google Brain teams, together with the 14th world chess champion Vladimir Kramnik, studied their creature AlphaZero from this point of view. AlphaZero is the descendant of AlphaGo, the super neural network that beat the world champion Lee Sedol in a best-of-five GO match, a turning point in the history of deep learning, as can also be seen in the wonderful Netflix documentary AlphaGo. 
 Unlike AlphaGo, AlphaZero is trained through self-play (i.e., it learns to play competing against itself) and masters not only GO but also chess and shogi. This trait makes AlphaZero the perfect case study to explore this idea. Moreover, given the fact that it performs at a superhuman level, understanding its functionality is also particularly useful for highlighting unknown patterns which have never been discovered by chess theorists.
 Full Paper Summary by Leonardo Tanzi: https://www.marktechpost.com/2021/12/16/understanding-alphazero-neural-networks-superhuman-chess-ability/ 
 Paper: https://arxiv.org/pdf/2111.09259.pdf
 https://preview.redd.it/t4mjebrm10681.png?width=808&format=png&auto=webp&s=58fcc96e8b1ae92469c26820528d0a5b31514365
    submitted by    /u/ai-lover  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Characters for good, created by artificial intelligence]]></title>
        <id>https://news.mit.edu/2021/ai-generated-characters-for-good-1216</id>
        <link href="https://news.mit.edu/2021/ai-generated-characters-for-good-1216"/>
        <updated>2021-12-16T21:45:00.000Z</updated>
        <summary type="html"><![CDATA[Researchers encourage positive use cases of AI-generated characters for education and well-being.]]></summary>
        <author>
            <name>Becky Ham | MIT Media Lab</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Q&A: Cathy Wu on developing algorithms to safely integrate robots into our world]]></title>
        <id>https://news.mit.edu/2021/qa-cathy-wu-developing-algorithms-safely-integrate-robots-our-world-1216</id>
        <link href="https://news.mit.edu/2021/qa-cathy-wu-developing-algorithms-safely-integrate-robots-our-world-1216"/>
        <updated>2021-12-16T21:25:00.000Z</updated>
        <summary type="html"><![CDATA[Assistant professor of civil engineering describes her career in robotics as well as challenges and promises of human-robot interactions.]]></summary>
        <author>
            <name>Kim Martineau | MIT Schwarzman College of Computing</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Build custom Amazon SageMaker PyTorch models for real-time handwriting text recognition]]></title>
        <id>da9379ec44cc5e0492af56eff2007df098992e38</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/build-custom-amazon-sagemaker-pytorch-models-for-real-time-handwriting-text-recognition/"/>
        <updated>2021-12-16T20:02:18.000Z</updated>
        <summary type="html"><![CDATA[In many industries, including financial services, banking, healthcare, legal, and real estate, automating document handling is an essential part of the business and customer service. In addition, strict compliance regulations make it necessary for businesses to handle sensitive documents, especially customer data, properly. Documents can come in a variety of formats, including digital forms or []]]></summary>
        <author>
            <name>Jonathan Chung</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conceptualization of a CNN]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rhxivg/conceptualization_of_a_cnn/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rhxivg/conceptualization_of_a_cnn/"/>
        <updated>2021-12-16T19:01:26.000Z</updated>
        <summary type="html"><![CDATA[Hi all
 
 I've been reading about the differences between normal fully-connected feedforward networks and convolutional neural networks, and I'm wondering if I understand something about how they subsume one another.
 Is a CNN "just" an ANN where the inputs to the network are convolutions over the input?
    submitted by    /u/snatchingthepiano  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Scalable Approach for Partially Local Federated Learning]]></title>
        <id>http://ai.googleblog.com/2021/12/a-scalable-approach-for-partially-local.html</id>
        <link href="http://ai.googleblog.com/2021/12/a-scalable-approach-for-partially-local.html"/>
        <updated>2021-12-16T18:11:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Karan Singhal, Senior Software Engineer, Google Research  
Federated learning enables users to train a model without sending raw data to a central server, thus avoiding the collection of privacy-sensitive data. Often this is done by learning a single global model for all users, even though the users may differ in their data distributions. For example, users of a mobile keyboard application may collaborate to train a suggestion model but have different preferences for the suggestions. This heterogeneity has motivated algorithms that can personalize a global model for each user.  
 However, in some settings privacy considerations may prohibit learning a fully global model. Consider models with user-specific embeddings, such as matrix factorization models for recommender systems. Tr]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[WebGPT: Improving the factual accuracy of language models through web browsing]]></title>
        <id>61bb711a2a7e63003b0a2558</id>
        <link href="https://openai.com/blog/improving-factual-accuracy/"/>
        <updated>2021-12-16T17:05:45.000Z</updated>
        <summary type="html"><![CDATA[We've fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser. Our prototype copies how humans research answers to questions online  it submits search queries, follows links, and scrolls up and down web pages. It is trained to cite its sources, which makes it]]></summary>
        <author>
            <name>Jacob Hilton</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Synthetic time series data generation]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rhv0yn/synthetic_time_series_data_generation/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rhv0yn/synthetic_time_series_data_generation/"/>
        <updated>2021-12-16T17:03:33.000Z</updated>
        <summary type="html"><![CDATA[I want to generate time series tabular data. Most of generative deep learning models consists of VAE and/or GAN which are for most part relating to images, videos, etc.
 Can you please point me to relevant tutorial souces (if it includes code along with theory, all the more better) pertaining to synthethic time series data generation using deep learning models or other techniques?
    submitted by    /u/grid_world  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Omniverse Creator Uses AI to Make Scenes With Singing Digital Humans]]></title>
        <id>https://blogs.nvidia.com/?p=54601</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/16/omniverse-creator-anderson-rohr/"/>
        <updated>2021-12-16T16:00:25.000Z</updated>
        <summary type="html"><![CDATA[The thing about inspiration is you never know where it might come from, or where it might lead. Anderson Rohr, a 3D generalist and freelance video editor based in southern Brazil, has for more than a dozen years created content ranging from wedding videos to cinematic animation. After seeing another creator animate a sci-fi characters Read article >
The post Omniverse Creator Uses AI to Make Scenes With Singing Digital Humans appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Angie Lee</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Get the Best of Cloud Gaming With GeForce NOW RTX 3080 Memberships Available Instantly]]></title>
        <id>https://blogs.nvidia.com/?p=54626</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/16/geforce-now-thursday-december-16/"/>
        <updated>2021-12-16T14:00:23.000Z</updated>
        <summary type="html"><![CDATA[The future of cloud gaming is available NOW, for everyone, with preorders closing and GeForce NOW RTX 3080 memberships moving to instant access. Gamers can sign up for a six-month GeForce NOW RTX 3080 membership and instantly stream the next generation of cloud gaming, starting today. Snag the NVIDIA SHIELD TV or SHIELD TV Pro Read article >
The post Get the Best of Cloud Gaming With GeForce NOW RTX 3080 Memberships Available Instantly appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>GeForce NOW Community</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Top Reasons Why Manufacturing Companies Need DevOps]]></title>
        <id>http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084052</id>
        <link href="http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1084052"/>
        <updated>2021-12-16T13:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://storage.ning.com/topology/rest/1.0/file/get/9916643293?profile=original" rel="noopener" target="_blank"><img class="align-full" src="https://storage.ning.com/topology/rest/1.0/file/get/9916643293?profile=RESIZE_710x" width="720"></img></a></p>
<p>It is no secret that technology has evolved at a rapid pace and that this fast-paced evolution has brought about intense changes across the world. Todays manufacturing companies need advanced services to maximize efficiency and productivity.Thanks to technology and innovation, todays manufacturing industry today has undergone drastic changes. From</p>]]></summary>
        <author>
            <name>Featured Blog Posts - Data Science Central</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Achieve 35% faster training with Hugging Face Deep Learning Containers on Amazon SageMaker]]></title>
        <id>eb7a81155a6bd57d09b8fff92c593ab73c284a36</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/achieve-35-faster-training-with-hugging-face-deep-learning-containers-on-amazon-sagemaker/"/>
        <updated>2021-12-15T22:46:01.000Z</updated>
        <summary type="html"><![CDATA[Natural language processing (NLP) has been a hot topic in the AI field for some time. As current NLP models get larger and larger, data scientists and developers struggle to set up the infrastructure for such growth of model size. For faster training time, distributed training across multiple machines is a natural choice for developers. []]]></summary>
        <author>
            <name>Yu Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nonsense can make sense to machine-learning models]]></title>
        <id>https://news.mit.edu/2021/nonsense-can-make-sense-machine-learning-models-1215</id>
        <link href="https://news.mit.edu/2021/nonsense-can-make-sense-machine-learning-models-1215"/>
        <updated>2021-12-15T21:55:00.000Z</updated>
        <summary type="html"><![CDATA[Deep-learning methods confidently recognize images that are nonsense, a potential problem for medical and autonomous-driving decisions.]]></summary>
        <author>
            <name>Rachel Gordon | MIT CSAIL</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Research at Microsoft 2021:Collaborating for real-world change]]></title>
        <id>https://www.microsoft.com/en-us/research/?p=804280</id>
        <link href="https://www.microsoft.com/en-us/research/blog/research-at-microsoft-2021-collaborating-for-real-world-change/"/>
        <updated>2021-12-15T20:54:30.000Z</updated>
        <summary type="html"><![CDATA[Over the past 30 years, Microsoft Research has undergone a shift in how it approaches innovation, broadening its mission to include not only advancing the state of computing but also using technology to tackle some of the worlds most pressing challenges. That evolution has never been more prominent than it was during this past year. []
The post Research at Microsoft 2021:Collaborating for real-world change appeared first on Microsoft Research.]]></summary>
        <author>
            <name>Lexie Hagen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Build a computer vision model using Amazon Rekognition Custom Labels and compare the results with a custom trained TensorFlow model]]></title>
        <id>cc2fe3b5037e1b1ecc49be195de0c301bbf5f531</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/build-a-computer-vision-model-using-amazon-rekognition-custom-labels-and-compare-the-results-with-a-custom-trained-tensorflow-model/"/>
        <updated>2021-12-15T20:14:55.000Z</updated>
        <summary type="html"><![CDATA[Building accurate computer vision models to detect objects in images requires deep knowledge of each step in the processfrom labeling, processing, and preparing the training and validation data, to making the right model choice and tuning the models hyperparameters adequately to achieve the maximum accuracy. Fortunately, these complex steps are simplified by Amazon Rekognition Custom []]]></summary>
        <author>
            <name>Raul Diaz Garcia</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Training Machine Learning Models More Efficiently with Dataset Distillation]]></title>
        <id>http://ai.googleblog.com/2021/12/training-machine-learning-models-more.html</id>
        <link href="http://ai.googleblog.com/2021/12/training-machine-learning-models-more.html"/>
        <updated>2021-12-15T19:26:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Timothy Nguyen1, Research Engineer and Jaehoon Lee, Senior Research Scientist, Google Research  
For a machine learning (ML) algorithm to be effective, useful features must be extracted from (often) large amounts of training data. However, this process can be made challenging due to the costs associated with training on such large datasets, both in terms of compute requirements and wall clock time. The idea of distillation plays an important role in these situations by reducing the resources required for the model to be effective. The most widely known form of distillation is model distillation (a.k.a. knowledge distillation), where the predictions of large, complex teacher models are distilled into smaller models.  
 An alternative option to this model-space approach is dataset ]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I programmed some creatures. They Evolved.]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rh5hwh/i_programmed_some_creatures_they_evolved/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rh5hwh/i_programmed_some_creatures_they_evolved/"/>
        <updated>2021-12-15T18:17:07.000Z</updated>
        <summary type="html"><![CDATA[submitted by    /u/infernum___  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI 2041: Ten Visions for Our Future: AI Pioneer Kai-Fu Lee Discusses His New Work of Fiction]]></title>
        <id>https://blogs.nvidia.com/?p=54608</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/15/kai-fu-lee-ai-2041/"/>
        <updated>2021-12-15T16:00:48.000Z</updated>
        <summary type="html"><![CDATA[One of AIs greatest champions has turned to fiction to answer the question: how will technology shape our world in the next 20 years? Kai-Fu Lee, CEO of Sinovation Ventures and a former president of Google China, spoke with NVIDIA AI Podcast host Noah Kravitz about AI 2041: Ten Visions for Our Future. The book, Read article >
The post AI 2041: Ten Visions for Our Future: AI Pioneer Kai-Fu Lee Discusses His New Work of Fiction appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Angie Lee</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google AI Proposes Temporal Fusion Transformer (TFT): An Attention-Based DNN (Deep Neural Network) Model For Multi-Horizon Forecasting]]></title>
        <id>https://www.reddit.com/r/neuralnetworks/comments/rgz6cf/google_ai_proposes_temporal_fusion_transformer/</id>
        <link href="https://www.reddit.com/r/neuralnetworks/comments/rgz6cf/google_ai_proposes_temporal_fusion_transformer/"/>
        <updated>2021-12-15T13:31:51.000Z</updated>
        <summary type="html"><![CDATA[Deep learning technologies, such as automatic learning of temporal dependence and automated handling of temporal structures like trends and seasonality, hold a lot of promise for time series forecasting. Most real-world datasets include a temporal component. Therefore projecting the future can be pretty beneficial. In time series machine learning, multi-horizon forecasting, or predicting variables-of-interest at several future time steps, is a critical challenge.
 Deep neural networks (DNNs) are increasingly being employed in multi-horizon forecasting, and they have been shown to outperform classic time series models. Unlike most models that focus on recurrent neural network (RNN) variants, recent works use attention-based layers to improve the selection of relevant time steps in the past beyond the inductive bias of RNNs  sequential ordered processing of information including. However, they frequently ignore the standard inputs in multi-horizon forecasting, assuming that all exogenous inputs are known in the future or ignoring crucial static variables.
 Quick Read: https://www.marktechpost.com/2021/12/15/google-ai-proposes-temporal-fusion-transformer-tft-an-attention-based-dnn-deep-neural-network-model-for-multi-horizon-forecasting/
 Paper: https://www.sciencedirect.com/science/article/pii/S0169207021000637
    submitted by    /u/ai-lover  
 [link]   [comments]]]></summary>
        <author>
            <name>Neural Networks, Deep Learning and Machine Learning</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Unsupervised Reinforcement Learning Benchmark]]></title>
        <id>http://bair.berkeley.edu/blog/2021/12/15/unsupervised-rl/</id>
        <link href="http://bair.berkeley.edu/blog/2021/12/15/unsupervised-rl/"/>
        <updated>2021-12-15T12:00:00.000Z</updated>
        <summary type="html"><![CDATA[The shortcomings of supervised RL
Reinforcement Learning (RL) is a powerful paradigm for solving many problems of interest in AI, such as controlling autonomous vehicles, digital assistants, and resource allocation to name a few. Weve seen over the last five years that, when provided with an extrinsic reward function, RL agents can master very complex tasks like playing Go, Starcraft, and dextrous robotic manipulation. While large-scale RL agents can achieve stunning results, even the best RL agents today are narrow. Most RL algorithms today can only solve the single task they were trained on and do not exhibit cross-task or cross-domain generalization capabilities.
A side-effect of the narrowness of todays RL systems is that todays RL agents are also very data inefficient. If we were t]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Build GAN with PyTorch and Amazon SageMaker]]></title>
        <id>ff6ed82c8103d7ce4f912e408563dece38461c84</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/build-gan-with-pytorch-and-amazon-sagemaker/"/>
        <updated>2021-12-14T23:37:25.000Z</updated>
        <summary type="html"><![CDATA[GAN is a generative ML model that is widely used in advertising, games, entertainment, media, pharmaceuticals, and other industries. You can use it to create fictional characters and scenes, simulate facial aging, change image styles, produce chemical formulas synthetic data, and more. For example, the following images show the effect of picture-to-picture conversion. The following []]]></summary>
        <author>
            <name>Laurence MIAO</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Process Amazon Redshift data and schedule a training pipeline with Amazon SageMaker Processing and Amazon SageMaker Pipelines]]></title>
        <id>7fbfa611eb41a70346c7c67b454156d727164279</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/process-amazon-redshift-data-and-schedule-a-training-pipeline-with-amazon-sagemaker-processing-and-amazon-sagemaker-pipelines/"/>
        <updated>2021-12-14T23:07:38.000Z</updated>
        <summary type="html"><![CDATA[Customers in many different domains tend to work with multiple sources for their data: object-based storage like Amazon Simple Storage Service (Amazon S3), relational databases like Amazon Relational Database Service (Amazon RDS), or data warehouses like Amazon Redshift. Machine learning (ML) practitioners are often driven to work with objects and files instead of databases and []]]></summary>
        <author>
            <name>Davide Galliteli</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Add AutoML functionality with Amazon SageMaker Autopilot across accounts]]></title>
        <id>3718a23de0ec88561afc2d0087abcc65698f823f</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/add-automl-functionality-with-amazon-sagemaker-autopilot-across-accounts/"/>
        <updated>2021-12-14T22:40:46.000Z</updated>
        <summary type="html"><![CDATA[AutoML is a powerful capability, provided by Amazon SageMaker Autopilot, that allows non-experts to create machine learning (ML) models to invoke in their applications. The problem that we want to solve arises when, due to governance constraints, Amazon SageMaker resources cant be deployed in the same AWS account where they are used. Examples of such []]]></summary>
        <author>
            <name>Francesco Polimeni</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Azure AI milestone: New foundation model Florence v1.0 advances state of the art, topping popular computer vision leaderboards]]></title>
        <id>https://www.microsoft.com/en-us/research/?p=803533</id>
        <link href="https://www.microsoft.com/en-us/research/blog/azure-ai-milestone-new-foundation-model-florence-v1-0-pushing-vision-and-vision-language-state-of-the-art/"/>
        <updated>2021-12-14T22:06:35.000Z</updated>
        <summary type="html"><![CDATA[The Project Florence Team Florence v1.0along with recent milestones in Neural Text-to-Speech and question answeringis part of a larger Azure AI mission to provide relevant, meaningful AI solutions and services that work better for people because they better capture how people learn and workwith improved vision, knowledge understanding, and speech capabilities. At the center of []
The post Azure AI milestone: New foundation model Florence v1.0 advances state of the art, topping popular computer vision leaderboards appeared first on Microsoft Research.]]></summary>
        <author>
            <name>Lexie Hagen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Python Classes and Their Use in Keras]]></title>
        <id>https://machinelearningmastery.com/?p=13138</id>
        <link href="https://machinelearningmastery.com/python-classes-and-their-use-in-keras/"/>
        <updated>2021-12-14T21:53:58.000Z</updated>
        <summary type="html"><![CDATA[Classes are one of the fundamental building blocks of the Python language, which may be applied in the development of []
The post Python Classes and Their Use in Keras appeared first on Machine Learning Mastery.]]></summary>
        <author>
            <name>Stefania Cristina</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[From cheetah-noids to humanoids]]></title>
        <id>https://news.mit.edu/2021/cheetah-noids-humanoids-benjamin-katz-1214</id>
        <link href="https://news.mit.edu/2021/cheetah-noids-humanoids-benjamin-katz-1214"/>
        <updated>2021-12-14T21:05:00.000Z</updated>
        <summary type="html"><![CDATA[Benjamin Katz '16, SM '18 is applying the skills he gained working on MIT's mini cheetah robot to the ATLAS project at Boston Dynamics.]]></summary>
        <author>
            <name>Mary Beth Gallagher | Department of Mechanical Engineering</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Predicting the next toy fads with AI]]></title>
        <id>61b51d19d5bf03003b927f69</id>
        <link href="https://www.aiweirdness.com/predicting-the-next-toy-fads-with-ai/"/>
        <updated>2021-12-14T19:20:50.000Z</updated>
        <summary type="html"><![CDATA[Few could have predicted that the must-have toy of 1998 would be an owl-like bilingual hamster doll with infrared sensors, or that in 1975 kids would be begging their parents for a toy that is literally a single rock in a cardboard box.
But could AI have predicted it? Could]]></summary>
        <author>
            <name>Janelle Shane</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bonus: Kids love the 5-foot rabbit with tiny mouthparts!]]></title>
        <id>61b81ed61a6991003b5fa70b</id>
        <link href="https://www.aiweirdness.com/bonus-kids-love-the-5-foot-rabbit-with-tiny-mouthparts/"/>
        <updated>2021-12-14T19:20:03.000Z</updated>
        <summary type="html"><![CDATA[AI Weirdness: the strange side of machine learning]]></summary>
        <author>
            <name>Janelle Shane</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NVIDIA Awards $50,000 Fellowships to Ph.D. Students for GPU Computing Research]]></title>
        <id>https://blogs.nvidia.com/?p=54609</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/14/graduate-fellowship-awards-2/"/>
        <updated>2021-12-14T18:53:50.000Z</updated>
        <summary type="html"><![CDATA[For more than two decades, NVIDIA has supported graduate students doing GPU-based work through the NVIDIA Graduate Fellowship Program. Today were announcing the latest awards of up to $50,000 each to 10 Ph.D. students involved in GPU computing research. Selected from a highly competitive applicant pool, the awardees will participate in a summer internship preceding Read article >
The post NVIDIA Awards $50,000 Fellowships to Ph.D. Students for GPU Computing Research appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Sylvia Chanak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Train and deploy a FairMOT model with Amazon SageMaker]]></title>
        <id>47d7a320b6f2971004b23f6104b5b948c79500fb</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/train-and-deploy-a-fairmot-model-with-amazon-sagemaker/"/>
        <updated>2021-12-14T18:00:40.000Z</updated>
        <summary type="html"><![CDATA[Multi-object tracking (MOT) in video analysis is increasingly in demand in many industries, such as live sports, manufacturing, surveillance, and traffic monitoring. For example, in live sports, MOT can track soccer players in real time to analyze physical performance such as real-time speed and moving distance. Previously, most methods were designed to separate MOT into []]]></summary>
        <author>
            <name>Gordon Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What Is a Digital Twin?]]></title>
        <id>https://blogs.nvidia.com/?p=54485</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/14/what-is-a-digital-twin/"/>
        <updated>2021-12-14T17:28:18.000Z</updated>
        <summary type="html"><![CDATA[A digital twin is a continuously updated virtual representation  a true-to-reality simulation of physics and materials  of a real-world physical asset or system. 
The post What Is a Digital Twin? appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Scott Martin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Customizing GPT-3 for Your Application]]></title>
        <id>61b8ccf39ff844003b5474f2</id>
        <link href="https://openai.com/blog/customized-gpt3/"/>
        <updated>2021-12-14T16:58:25.000Z</updated>
        <summary type="html"><![CDATA[Developers can now fine-tune GPT-3 on their own data, creating a custom version tailored to their application. Customizing makes GPT-3 reliable for a wider variety of use cases and makes running the model cheaper and faster.
You can use an existing dataset of virtually any shape and size, or incrementally]]></summary>
        <author>
            <name>Rachel Lim</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Startup Surge: Utility Feels Power of Computer Vision to Track Its Lines]]></title>
        <id>https://blogs.nvidia.com/?p=54358</id>
        <link href="https://blogs.nvidia.com/blog/2021/12/14/power-utility-ai-edge/"/>
        <updated>2021-12-14T16:00:25.000Z</updated>
        <summary type="html"><![CDATA[It was the kind of message Connor McCluskey loves to find in his inbox. As a member of the product innovation team at FirstEnergy Corp.  an electric utility serving 6 million customers from central Ohio to the New Jersey coast  his job is to find technologies that open new revenue streams or cut Read article >
The post Startup Surge: Utility Feels Power of Computer Vision to Track Its Lines appeared first on The Official NVIDIA Blog.]]></summary>
        <author>
            <name>Keith Cockerham</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Aesthetic uses of Latin squares]]></title>
        <id>https://www.johndcook.com/blog/?p=91637</id>
        <link href="https://www.johndcook.com/blog/2021/12/14/aesthetic-latin-squares/"/>
        <updated>2021-12-14T15:41:40.000Z</updated>
        <summary type="html"><![CDATA[We think they like randomness in design, but we dont exactly. People like things that are sorta random, but not too random. When you literally scatter things randomly, they looked too clumped [1]. There are many ways around this problem, variations on randomness that people find more aesthetically pleasing. One of these ways is random []
Aesthetic uses of Latin squares first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distributed Mask RCNN training with Amazon SageMakerCV]]></title>
        <id>f790d23d4b5d7a1630e0c41e43fdfb4fb98c1e6b</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/distributed-mask-rcnn-training-with-amazon-sagemakercv/"/>
        <updated>2021-12-13T23:57:03.000Z</updated>
        <summary type="html"><![CDATA[Computer vision algorithms are at the core of many deep learning applications. Self-driving cars, security systems, healthcare, logistics, and image processing all incorporate various aspects of computer vision. But despite their ubiquity, training computer vision algorithms, like Mask or Cascade RCNN, is hard. These models employ complex architectures, train on large datasets, and require computer []]]></summary>
        <author>
            <name>Ben Snyder</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Know the rules to break the rules]]></title>
        <id>https://www.johndcook.com/blog/?p=91577</id>
        <link href="https://www.johndcook.com/blog/2021/12/13/break-the-rules/"/>
        <updated>2021-12-13T22:25:26.000Z</updated>
        <summary type="html"><![CDATA[Theres a saying in the arts Know the rules before you break the rules. Master the classical conventions of your field before you violate them. Break the rules deliberately and not accidentally, skillfully and not due to a lack of skill. Theres a world of difference between a beginning musician playing a wrong note and []
Know the rules to break the rules first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Amazon Lookout for Vision now supports visual inspection of product defects at the edge]]></title>
        <id>acaf6ca2357cd35d5548b8a201195d14b159f8a9</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/amazon-lookout-for-vision-now-supports-visual-inspection-of-product-defects-at-the-edge/"/>
        <updated>2021-12-13T18:44:09.000Z</updated>
        <summary type="html"><![CDATA[Discrete and continuous manufacturing lines generate a high volume of products at low latency, ranging from milliseconds to a few seconds. To identify defects at the same throughput of production, camera streams of images must be processed at low latency. Additionally, factories may have low network bandwidth or intermittent cloud connectivity. In such scenarios, you []]]></summary>
        <author>
            <name>Amit Gupta</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interpretable Deep Learning for Time Series Forecasting]]></title>
        <id>http://ai.googleblog.com/2021/12/interpretable-deep-learning-for-time.html</id>
        <link href="http://ai.googleblog.com/2021/12/interpretable-deep-learning-for-time.html"/>
        <updated>2021-12-13T17:22:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Sercan O. Arik, Research Scientist and Tomas Pfister, Engineering Manager, Google Cloud   
Multi-horizon forecasting, i.e. predicting variables-of-interest at multiple future time steps, is a crucial challenge in time series machine learning. Most real-world datasets have a time component, and forecasting the future can unlock great value. For example, retailers can use future sales to optimize their supply chain and promotions, investment managers are interested in forecasting the future prices of financial assets to maximize their performance, and healthcare institutions can use the number of future patient admissions to have sufficient personnel and equipment. 
  
Deep neural networks (DNNs) have increasingly been used in multi-horizon forecasting, demonstrating strong perform]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How many Latin squares are there?]]></title>
        <id>https://www.johndcook.com/blog/?p=91474</id>
        <link href="https://www.johndcook.com/blog/2021/12/13/latin-squares/"/>
        <updated>2021-12-13T14:44:19.000Z</updated>
        <summary type="html"><![CDATA[A Latin square is an n  n grid with a number from 1 to n in each cell, such that no number appears twice in a row or twice in a column. Its not obvious that Latin squares exist for all n, but they do, and in fact there are a lot of them. []
How many Latin squares are there? first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Yule statistics Y and Q]]></title>
        <id>https://www.johndcook.com/blog/?p=91283</id>
        <link href="https://www.johndcook.com/blog/2021/12/12/yule-statistics-y-and-q/"/>
        <updated>2021-12-12T18:36:05.000Z</updated>
        <summary type="html"><![CDATA[I recently wrote about the Yule-Simon distribution. The same Yule, George Udny Yule, is also known for the statistics Yules Y and Yules Q. The former is also known as the coefficient of colligation, and the latter is also known as the Yule coefficient of association. Both measure how things are related. Given a 2 []
Yule statistics Y and Q first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deleting reproducible files in Emacs dired]]></title>
        <id>https://www.johndcook.com/blog/?p=91392</id>
        <link href="https://www.johndcook.com/blog/2021/12/12/deleting-files-in-dired/"/>
        <updated>2021-12-12T18:17:18.000Z</updated>
        <summary type="html"><![CDATA[Imagine you could list the contents of a directory from a command line, and then edit the text output to make things happen. Thats sorta how Emacs dired works. Its kind of a cross between a bash shell and the Windows File Explorer. Why would you ever want to use such a bizarre hybrid? One []
Deleting reproducible files in Emacs dired first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fraud, Sloppiness, and Statistics]]></title>
        <id>https://www.johndcook.com/blog/?p=91360</id>
        <link href="https://www.johndcook.com/blog/2021/12/11/fraud-sloppiness-and-statistics/"/>
        <updated>2021-12-11T15:17:46.000Z</updated>
        <summary type="html"><![CDATA[A few years ago the scientific community suddenly realized that a lot of scientific papers were wrong. I imagine a lot of people knew this all along, but suddenly it became a topic of discussion and people realized the problem was bigger than imagined. The laymans first response was Are you saying scientists are making []
Fraud, Sloppiness, and Statistics first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Comparing three discrete power laws]]></title>
        <id>https://www.johndcook.com/blog/?p=91354</id>
        <link href="https://www.johndcook.com/blog/2021/12/11/zeta-zipf-yule/"/>
        <updated>2021-12-11T12:43:24.000Z</updated>
        <summary type="html"><![CDATA[Yesterday I wrote about the zeta distribution and the Yule-Simon distribution and said that they, along with the Zipf distribution, are all discrete power laws. This post fills in detail for that statement. The probability mass functions for the zeta, Zipf, and Yule-Simon distributions are as follows. Here the subscripts , y, andz stand for []
Comparing three discrete power laws first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[My Conversations to Political Offices in Support of Chinese Scholars]]></title>
        <id>https://danieltakeshi.github.io/2021/12/11/international-chinese/</id>
        <link href="https://danieltakeshi.github.io/2021/12/11/international-chinese/"/>
        <updated>2021-12-11T12:00:00.000Z</updated>
        <summary type="html"><![CDATA[Lately, I have been in touch with some of the political offices for whom I am a
constituent, to ask if they can consider steps that would improve the climate
for Chinese international students and scholars. Now that I reside in
the critical swing state of Pennsylvania, the two US Senators who represent me
are Senators Bob Casey and Pat Toomey.  This past week, I called their
Pitttsburgh offices multiple times and was able to contact a staff member for
Senator Toomey.
What follows is a rough transcript of my conversation with the staff member.
This is from memory, so theres obviously no way that this is all correct, and
its also a sanitized version as I probably got rid of some uhms or mumbles
that I experienced when having this conversation. However, I hope I was able to
deliver the ma]]></summary>
        <author>
            <name>Seita's Place</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning by Doing - the DeFi Quest (Part 1 out of 2)]]></title>
        <id>http://dtransposed.github.io/blog/2021/12/11/DeFi-adventure-1/</id>
        <link href="http://dtransposed.github.io/blog/2021/12/11/DeFi-adventure-1/"/>
        <updated>2021-12-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[I find Decentralised Finance (DeFi) truly fascinating because it promises to solve so many problems of the modern financial world. It gives hope, that the future will be much less dystopian than we think. Recent years (decades) have shown that we have a problem with harnessing the complexity of the ever-expanding, ever-global financial system. We have efficiency problems related to:
Capital markets (Citadel, Robin Hood scandal, naked-shorts, toxic debts, and other types of harmful financial engineering)
Global financial system (most of the world living on borrowed money, with the possible intention of devaluating the debt over time and thus the risk of (hyper)inflation)
The fragility of the paper tiger (every hiccup in the financial system spreads like a butterfly effect throughout the wor]]></summary>
        <author>
            <name>Damian Bogunowicz - dtransposed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hierarchical Forecasting using Amazon SageMaker]]></title>
        <id>e01171ffc3ace81092ebdd719ee59a7302e2a251</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/hierarchical-forecasting-using-amazon-sagemaker/"/>
        <updated>2021-12-10T22:19:22.000Z</updated>
        <summary type="html"><![CDATA[Time series forecasting is a common problem in machine learning (ML) and statistics. Some common day-to-day use cases of time series forecasting involve predicting product sales, item demand, component supply, service tickets, and all as a function of time. More often than not, time series data follows a hierarchical aggregation structure. For example, in retail, []]]></summary>
        <author>
            <name>Mani Khanuja</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine learning speeds up vehicle routing]]></title>
        <id>https://news.mit.edu/2021/machine-learning-speeds-vehicle-routing-1210</id>
        <link href="https://news.mit.edu/2021/machine-learning-speeds-vehicle-routing-1210"/>
        <updated>2021-12-10T21:45:00.000Z</updated>
        <summary type="html"><![CDATA[Strategy accelerates the best algorithmic solvers for large sets of cities.]]></summary>
        <author>
            <name>Becky Ham | Department of Civil and Environmental Engineering</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Fast WordPiece Tokenization System]]></title>
        <id>http://ai.googleblog.com/2021/12/a-fast-wordpiece-tokenization-system.html</id>
        <link href="http://ai.googleblog.com/2021/12/a-fast-wordpiece-tokenization-system.html"/>
        <updated>2021-12-10T20:35:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Xinying Song, Staff Software Engineer and Denny Zhou, Senior Staff Research Scientist, Google Research   
Tokenization is a fundamental pre-processing step for most natural language processing (NLP) applications. It involves splitting text into smaller units called tokens (e.g., words or word segments) in order to turn an unstructured input string into a sequence of discrete elements that is suitable for a machine learning (ML) model. ln deep learningbased models (e.g., BERT), each token is mapped to an embedding vector to be fed into the model.  
   


Tokenization in a typical deep learning model, like BERT.

   
A fundamental tokenization approach is to break text into words. However, using this approach, words that are not included in the vocabulary are treated as unknown.]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Live transcriptions of F1 races using Amazon Transcribe]]></title>
        <id>60b9bb73cb3e4c345ee73c5eeace083c7b4722ad</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/live-transcriptions-of-f1-races-using-amazon-transcribe/"/>
        <updated>2021-12-10T20:08:24.000Z</updated>
        <summary type="html"><![CDATA[The Formula 1 (F1) live steaming service, F1 TV, has live automated closed captions in three different languages: English, Spanish, and French. For the 2021 season, FORMULA 1 has achieved another technological breakthrough, building a fully automated workflow to create closed captions in three languages and broadcasting to 85 territories using Amazon Transcribe. Amazon Transcribe []]]></summary>
        <author>
            <name>Beibit Baktygaliyev</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FS-Mol: Bringing Deep Learning to Early-Stage Drug Discovery]]></title>
        <id>https://www.microsoft.com/en-us/research/?p=803848</id>
        <link href="https://www.microsoft.com/en-us/research/blog/fs-mol-bringing-deep-learning-to-early-stage-drug-discovery/"/>
        <updated>2021-12-10T19:13:51.000Z</updated>
        <summary type="html"><![CDATA[The drug development process is an iterative one that consists of discovery, design, and testing. Historically, drugs were derived from plants and discovered through trial-and-error experiments. Fortunately, this drug discovery process now occurs in a lab, with each iteration of custom-designed compounds producing a more promising candidate. While much safer and more effective, this process []
The post FS-Mol: Bringing Deep Learning to Early-Stage Drug Discovery appeared first on Microsoft Research.]]></summary>
        <author>
            <name>Lexie Hagen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The zeta distribution]]></title>
        <id>https://www.johndcook.com/blog/?p=91297</id>
        <link href="https://www.johndcook.com/blog/2021/12/10/the-zeta-distribution/"/>
        <updated>2021-12-10T19:01:19.000Z</updated>
        <summary type="html"><![CDATA[The previous post on the Yule-Simon distribution mentioned the zeta distribution at the end. This is a powerlaw distribution on the positive integers with normalizing constant given by the Riemann zeta distribution. That is, the zeta distribution has density f(k; s) = ks / (s). wherek is a positive integer and s > 1 is []
The zeta distribution first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Yule-Simon distribution]]></title>
        <id>https://www.johndcook.com/blog/?p=91286</id>
        <link href="https://www.johndcook.com/blog/2021/12/10/yule-simon-distribution/"/>
        <updated>2021-12-10T16:36:59.000Z</updated>
        <summary type="html"><![CDATA[The Yule-Simon distribution, named after Udny Yule and Herbert Simon, is a discrete probability with pmf The semicolon in f(k; ) suggests that we think of f as a function of k, with a fixed parameter . The way the distribution shows the connection to the beta function, but for our purposes it will be []
Yule-Simon distribution first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine Learning Security Seminar Talk Relating Adversarially Robust Generalization to Flat Minima]]></title>
        <id>https://davidstutz.de/?p=8555</id>
        <link href="https://davidstutz.de/machine-learning-security-seminar-talk-relating-adversarially-robust-generalization-to-flat-minima/"/>
        <updated>2021-12-10T12:59:22.000Z</updated>
        <summary type="html"><![CDATA[This week I was honored to speak at the Machine Learning Security Seminar organized by the Pattern Recognition and Applications Lab at University of Cagliari. I presented my work on relating adversarial robustness to flatness in the robust loss landscape, also touching on the relationship to weight robustness. In this article, I want to share the recording and slides of this talk.
The post Machine Learning Security Seminar Talk Relating Adversarially Robust Generalization to Flat Minima appeared first on David Stutz.]]></summary>
        <author>
            <name>David Stutz</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mahalanobis distance and Henry V]]></title>
        <id>https://www.johndcook.com/blog/?p=91232</id>
        <link href="https://www.johndcook.com/blog/2021/12/09/mahalanobis-distance/"/>
        <updated>2021-12-10T02:27:31.000Z</updated>
        <summary type="html"><![CDATA[I was reading a stats book that mentioned Mahalanobis distance and that made me think of Non Nobis from Henry V, a great scene in a great movie. As far as I know, theres no connection between Mahalanobis and Non Nobis except that both end in nobis. Since Mahalanobis is an Indian surname and Non []
Mahalanobis distance and Henry V first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[More special features in Python]]></title>
        <id>https://machinelearningmastery.com/?p=13124</id>
        <link href="https://machinelearningmastery.com/python-special-features/"/>
        <updated>2021-12-09T21:00:48.000Z</updated>
        <summary type="html"><![CDATA[Python is an awesome programming language! It is one of the most popular languages for developing AI and machine learning []
The post More special features in Python appeared first on Machine Learning Mastery.]]></summary>
        <author>
            <name>Mehreen Saeed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[More Efficient In-Context Learning with GLaM]]></title>
        <id>http://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html</id>
        <link href="http://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html"/>
        <updated>2021-12-09T20:22:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by Andrew M Dai and Nan Du, Research Scientists, Google Research, Brain Team  
Large language models (e.g., GPT-3) have many significant capabilities, such as performing few-shot learning across a wide array of tasks, including reading comprehension and question answering with very few or no training examples. While these models can perform better by simply using more parameters, training and serving these large models can be very computationally intensive. Is it possible to train and use these models more efficiently? 
  
In GLaM: Efficient Scaling of Language Models with Mixture-of-Experts, we introduce the Generalist Language Model (GLaM), a trillion weight model that can be trained and served efficiently (in terms of computation and energy use) thanks to sparsity, and achieves]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine-learning system flags remedies that might do more harm than good]]></title>
        <id>https://news.mit.edu/2021/machine-learning-treatments-1209</id>
        <link href="https://news.mit.edu/2021/machine-learning-treatments-1209"/>
        <updated>2021-12-09T17:00:00.000Z</updated>
        <summary type="html"><![CDATA[The system could help physicians select the least risky treatments in urgent situations, such as treating sepsis.]]></summary>
        <author>
            <name>Adam Zewe | MIT News Office</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Probability of a magical permutation]]></title>
        <id>https://www.johndcook.com/blog/?p=91141</id>
        <link href="https://www.johndcook.com/blog/2021/12/09/magic-permutation/"/>
        <updated>2021-12-09T13:05:50.000Z</updated>
        <summary type="html"><![CDATA[Take a permutation of the numbers 1 through n and lay out the elements of the permutation in a square. We will call a permutation a magic permutation if the corresponding square is a magic square. What is the probability that a permutation is a magic permutation? That is, if you fill a grid randomly []
Probability of a magical permutation first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A tool to speed development of new solar cells]]></title>
        <id>https://news.mit.edu/2021/simulator-photovoltaic-cells-development-1209</id>
        <link href="https://news.mit.edu/2021/simulator-photovoltaic-cells-development-1209"/>
        <updated>2021-12-09T05:00:00.000Z</updated>
        <summary type="html"><![CDATA[A new computational simulator can help predict whether changes to materials or design will improve performance in new photovoltaic cells.]]></summary>
        <author>
            <name>David L. Chandler | MIT News Office</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Degree of magic]]></title>
        <id>https://www.johndcook.com/blog/?p=91139</id>
        <link href="https://www.johndcook.com/blog/2021/12/08/degree-of-magic/"/>
        <updated>2021-12-09T03:12:57.000Z</updated>
        <summary type="html"><![CDATA[A square grid of distinct integers is a magic square if all its rows columns and full diagonals have the same sum. Otherwise it is not a magic square. Now suppose we fill a square grid with samples from a continuous random variable. The probability that the entries are distinct is 1, but the probability []
Degree of magic first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AWS Deep Learning AMIs: New framework-specific DLAMIs for production complement the original multi-framework DLAMIs]]></title>
        <id>3923fdecd4e17f3a2adffff032f11a3f830d383b</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/aws-deep-learning-amis-new-framework-specific-dlamis-for-production-complement-the-original-multi-framework-dlamis/"/>
        <updated>2021-12-08T21:50:38.000Z</updated>
        <summary type="html"><![CDATA[Since its launch in November 2017, theAWS Deep Learning Amazon Machine Image (DLAMI) has been the preferred method for running deep learning frameworks on Amazon Elastic Compute Cloud (Amazon EC2). For deep learning practitioners and learners who want to accelerate deep learning in the cloud, the DLAMI comes pre-installed with AWS-optimized deep learning (DL) frameworks []]]></summary>
        <author>
            <name>Francisco Calderon Rodriguez</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tiny machine learning design alleviates a bottleneck in memory usage on internet-of-things devices]]></title>
        <id>https://news.mit.edu/2021/tiny-machine-learning-design-alleviates-bottleneck-memory-usage-iot-devices-1208</id>
        <link href="https://news.mit.edu/2021/tiny-machine-learning-design-alleviates-bottleneck-memory-usage-iot-devices-1208"/>
        <updated>2021-12-08T21:10:00.000Z</updated>
        <summary type="html"><![CDATA[New technique applied to small computer chips enables efficient vision and detection algorithms without internet connectivity.]]></summary>
        <author>
            <name>Lauren Hinkel | MIT-IBM Watson AI Lab</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Clinical text mining using the Amazon Comprehend Medical new SNOMED CT API]]></title>
        <id>e8f98725b1837376d2e594e8f042924f24b382d4</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/clinical-text-mining-using-the-amazon-comprehend-medical-new-snomed-ct-api/"/>
        <updated>2021-12-08T21:08:52.000Z</updated>
        <summary type="html"><![CDATA[Mining medical concepts from written clinical text, such as patient encounters, plays an important role in clinical analytics and decision-making applications, such as population analytics for providers, pre-authorization for payers, and adverse-event detection for pharma companies. Medical concepts contain medical conditions, medications, procedures, and other clinical events. Extracting medical concepts is a complicated process due []]]></summary>
        <author>
            <name>Tesfagabir Meharizghi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Plan the locations of green car charging stations with an Amazon SageMaker built-in algorithm]]></title>
        <id>e189b96d819990b4f31e43ba3a5ff75526868833</id>
        <link href="https://aws.amazon.com/blogs/machine-learning/plan-the-locations-of-green-car-charging-stations-with-an-amazon-sagemaker-built-in-algorithm/"/>
        <updated>2021-12-08T20:48:38.000Z</updated>
        <summary type="html"><![CDATA[While the fuel economy of new gasoline or diesel-powered vehicles improves every year, green vehicles are considered even more environmentally friendly because theyre powered by alternative fuel or electricity. Hybrid electric vehicles (HEVs), battery only electric vehicles (BEVs), fuel cell electric vehicles (FCEVs), hydrogen cars, and solar cars are all considered types of green vehicles. []]]></summary>
        <author>
            <name>Zheng Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Finding and fixing bugs with deep learning]]></title>
        <id>https://www.microsoft.com/en-us/research/?p=802138</id>
        <link href="https://www.microsoft.com/en-us/research/blog/finding-and-fixing-bugs-with-deep-learning/"/>
        <updated>2021-12-08T20:38:02.000Z</updated>
        <summary type="html"><![CDATA[Finding and fixing bugs in code is a time-consuming, and often frustrating, part of everyday work for software developers. Can deep learning address this problem and help developers deliver better software, faster? In a new paper, Self-Supervised Bug Detection and Repair, presented at the 2021 Conference on Neural Information Processing Systems (NeurIPS 2021), we show []
The post Finding and fixing bugs with deep learning appeared first on Microsoft Research.]]></summary>
        <author>
            <name>Lexie Hagen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some Language Features in Python]]></title>
        <id>https://machinelearningmastery.com/?p=13129</id>
        <link href="https://machinelearningmastery.com/some-language-features-in-python/"/>
        <updated>2021-12-08T20:17:26.000Z</updated>
        <summary type="html"><![CDATA[The Python language syntax is quite powerful and expressive. Hence it is concise to express an algorithm in Python. Maybe []
The post Some Language Features in Python appeared first on Machine Learning Mastery.]]></summary>
        <author>
            <name>Adrian Tam</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[General and Scalable Parallelization for Neural Networks]]></title>
        <id>http://ai.googleblog.com/2021/12/general-and-scalable-parallelization.html</id>
        <link href="http://ai.googleblog.com/2021/12/general-and-scalable-parallelization.html"/>
        <updated>2021-12-08T19:30:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Yuanzhong Xu and Yanping Huang, Software Engineers; Google Research, Brain Team  
Scaling neural networks, whether it be the amount of training data used, the model size or the computation being utilized,  has been critical for improving model quality in many real-world machine learning applications, such as computer vision, language understanding and neural machine translation. This, in turn, has motivated recent studies to scrutinize the factors that play a critical role in the success of scaling a neural model. Although increasing model capacity can be a sound approach to improve model quality, doing so presents a number of systems and software engineering challenges that must be overcome. For instance, in order to train large models that exceed the memory capacity of an accel]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal properties]]></title>
        <id>https://www.johndcook.com/blog/?p=91028</id>
        <link href="https://www.johndcook.com/blog/2021/12/08/universal-properties/"/>
        <updated>2021-12-08T15:48:56.000Z</updated>
        <summary type="html"><![CDATA[I started to write a blog post about universal properties, but ended up writing a Twitter thread instead. See also examples of universal properties.
Universal properties first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machines that see the world more like humans do]]></title>
        <id>https://news.mit.edu/2021/probablistic-programming-machine-vision-1208</id>
        <link href="https://news.mit.edu/2021/probablistic-programming-machine-vision-1208"/>
        <updated>2021-12-08T05:00:00.000Z</updated>
        <summary type="html"><![CDATA[A new common-sense approach to computer vision enables artificial intelligence that interprets scenes more accurately than other systems do.]]></summary>
        <author>
            <name>Adam Zewe | MIT News Office</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Q&A: More-sustainable concrete with machine learning]]></title>
        <id>https://news.mit.edu/2021/more-sustainable-concrete-machine-learning-1207</id>
        <link href="https://news.mit.edu/2021/more-sustainable-concrete-machine-learning-1207"/>
        <updated>2021-12-07T21:20:00.000Z</updated>
        <summary type="html"><![CDATA[MIT-IBM Watson AI Lab researchers aim to design concrete mixtures that use AI to shrink environmental footprint and cost, while recycling byproducts and increasing performance.]]></summary>
        <author>
            <name>Lauren Hinkel | MIT-IBM Watson AI Lab</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving Vision Transformer Efficiency and Accuracy by Learning to Tokenize]]></title>
        <id>http://ai.googleblog.com/2021/12/improving-vision-transformer-efficiency.html</id>
        <link href="http://ai.googleblog.com/2021/12/improving-vision-transformer-efficiency.html"/>
        <updated>2021-12-07T17:35:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Michael Ryoo, Research Scientist, Robotics at Google and Anurag Arnab, Research Scientist, Google Research 
Transformer models consistently obtain state-of-the-art results in computer vision tasks, including object detection and video classification. In contrast to standard convolutional approaches that process images pixel-by-pixel, the Vision Transformers (ViT) treat an image as a sequence of patch tokens (i.e., a smaller part, or patch, of an image made up of multiple pixels). This means that at every layer, a ViT model recombines and processes patch tokens based on relations between each pair of tokens, using multi-head self-attention. In doing so, ViT models have the capability to construct a global representation of the entire image. 
At the input-level, the tokens are fo]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The ring of entire functions]]></title>
        <id>https://www.johndcook.com/blog/?p=91014</id>
        <link href="https://www.johndcook.com/blog/2021/12/07/the-ring-of-entire-functions/"/>
        <updated>2021-12-07T17:17:47.000Z</updated>
        <summary type="html"><![CDATA[Rings made a bad first impression on me. I couldnt remember the definitions of all the different kinds of rings, much less have an intuition for what was important about each one. As I recall, all the examples of rings in our course were variations on the integers, often artificial variations. Entire functions Im more []
The ring of entire functions first appeared on John D. Cook.]]></summary>
        <author>
            <name>John</name>
        </author>
    </entry>
</feed>